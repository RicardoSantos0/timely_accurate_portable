{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thesis notebook 4.2. - NOVA IMS\n",
    "\n",
    "### Aplication of SMOTE - Keeping Outliers\n",
    "\n",
    "### Non-temporal data representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary modules/libraries\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import warnings\n",
    "import time\n",
    "import plotly.express as px\n",
    "\n",
    "#tqdm to monitor progress\n",
    "from tqdm.notebook import tqdm, trange\n",
    "tqdm.pandas(desc=\"Progress\")\n",
    "\n",
    "#time related features\n",
    "from datetime import timedelta\n",
    "from copy import copy, deepcopy\n",
    "\n",
    "from lightgbm import LGBMModel,LGBMClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, MinMaxScaler, StandardScaler, RobustScaler, QuantileTransformer,PowerTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from math import ceil\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import train_test_split, KFold, RepeatedKFold, RepeatedStratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif, RFE, RFECV, SelectFromModel\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from collections import Counter\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.cluster import AgglomerativeClustering , KMeans, DBSCAN\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier, StackingClassifier\n",
    "from sklearn.linear_model import LogisticRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "\n",
    "from sklearn.datasets import make_classification, load_digits\n",
    "from sklearn import svm\n",
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB, ComplementNB, BernoulliNB\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, recall_score, classification_report, average_precision_score, precision_recall_curve\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variables that may come in handy\n",
    "#course threshold sets the % duration that will be considered (1 = 100%)\n",
    "duration_threshold = [0.1, 0.25, 0.33, 0.5, 1]\n",
    "\n",
    "#colors for vizualizations\n",
    "nova_ims_colors = ['#BFD72F', '#5C666C']\n",
    "\n",
    "#standard color for student aggregates\n",
    "student_color = '#474838'\n",
    "\n",
    "#standard color for course aggragates\n",
    "course_color = '#1B3D2F'\n",
    "\n",
    "#standard continuous colormap\n",
    "standard_cmap = 'viridis_r'\n",
    "\n",
    "#Function designed to deal with multiindex and flatten it\n",
    "def flattenHierarchicalCol(col,sep = '_'):\n",
    "    '''converts multiindex columns into single index columns while retaining the hierarchical components'''\n",
    "    if not type(col) is tuple:\n",
    "        return col\n",
    "    else:\n",
    "        new_col = ''\n",
    "        for leveli,level in enumerate(col):\n",
    "            if not level == '':\n",
    "                if not leveli == 0:\n",
    "                    new_col += sep\n",
    "                new_col += level\n",
    "        return new_col\n",
    "    \n",
    "#number of replicas - number of repeats of stratified k fold - in this case 10\n",
    "replicas = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports dataframes\n",
    "course_programs = pd.read_excel(\"../Data/Modeling Stage/Nova_IMS_Non_temporal_Datasets.xlsx\", \n",
    "                                dtype = {\n",
    "                                    'course_encoding' : object,\n",
    "                                    'cd_curso' :  object,\n",
    "                                    'courseid' : object,\n",
    "                                    'userid' : object},\n",
    "                               sheet_name = None)\n",
    "\n",
    "#drop unnamed 0 column\n",
    "for i in course_programs:\n",
    "    course_programs[i].drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "    \n",
    "#save tables \n",
    "class_list = pd.read_csv('../Data/Modeling Stage/Nova_IMS_updated_classlist.csv', \n",
    "                         dtype = {\n",
    "                                   'course_encoding': object,\n",
    "                                   'cd_curso' :  object,\n",
    "                                   'courseid' : object,\n",
    "                                   },\n",
    "                        parse_dates = ['Week before start', 'Start Date',\n",
    "                                       'End Date', 'Date_threshold_10',\n",
    "                                      'Date_threshold_25', 'Date_threshold_33', 'Date_threshold_50',\n",
    "                                      'Date_threshold_100']).drop('Unnamed: 0', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Number of clicks</th>\n",
       "      <th>Number of sessions</th>\n",
       "      <th>Largest period of inactivity (h)</th>\n",
       "      <th>Total time online (min)</th>\n",
       "      <th>Average session duration (min)</th>\n",
       "      <th>Start of Session 1 (%)</th>\n",
       "      <th>Start of Session 2 (%)</th>\n",
       "      <th>Start of Session 3 (%)</th>\n",
       "      <th>Start of Session 4 (%)</th>\n",
       "      <th>Start of Session 5 (%)</th>\n",
       "      <th>...</th>\n",
       "      <th>Forum posts</th>\n",
       "      <th>Number of days</th>\n",
       "      <th>Clicks per day</th>\n",
       "      <th>Clicks per session</th>\n",
       "      <th>Clicks (% of course total)</th>\n",
       "      <th>Submissions (% of course total)</th>\n",
       "      <th>Days with no interaction (%)</th>\n",
       "      <th>exam_mark</th>\n",
       "      <th>final_mark</th>\n",
       "      <th>Average grade of assignments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10186.000000</td>\n",
       "      <td>10186.000000</td>\n",
       "      <td>10186.000000</td>\n",
       "      <td>10186.000000</td>\n",
       "      <td>10186.000000</td>\n",
       "      <td>10186.000000</td>\n",
       "      <td>9861.000000</td>\n",
       "      <td>9402.000000</td>\n",
       "      <td>8775.000000</td>\n",
       "      <td>8040.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>10186.000000</td>\n",
       "      <td>10186.000000</td>\n",
       "      <td>10186.000000</td>\n",
       "      <td>10186.000000</td>\n",
       "      <td>285.000000</td>\n",
       "      <td>10186.000000</td>\n",
       "      <td>11297.000000</td>\n",
       "      <td>11297.000000</td>\n",
       "      <td>357.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>40.197035</td>\n",
       "      <td>9.940997</td>\n",
       "      <td>124.593643</td>\n",
       "      <td>75.613587</td>\n",
       "      <td>7.664978</td>\n",
       "      <td>0.233302</td>\n",
       "      <td>2.260167</td>\n",
       "      <td>3.666584</td>\n",
       "      <td>4.729155</td>\n",
       "      <td>5.606280</td>\n",
       "      <td>...</td>\n",
       "      <td>1.136752</td>\n",
       "      <td>23.339682</td>\n",
       "      <td>1.740594</td>\n",
       "      <td>4.124444</td>\n",
       "      <td>1.767131</td>\n",
       "      <td>3.859649</td>\n",
       "      <td>67.894256</td>\n",
       "      <td>14.613615</td>\n",
       "      <td>15.039648</td>\n",
       "      <td>16.525994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>35.736811</td>\n",
       "      <td>7.887983</td>\n",
       "      <td>58.954004</td>\n",
       "      <td>80.995556</td>\n",
       "      <td>6.992485</td>\n",
       "      <td>4.166322</td>\n",
       "      <td>4.169601</td>\n",
       "      <td>4.317537</td>\n",
       "      <td>4.337221</td>\n",
       "      <td>4.353308</td>\n",
       "      <td>...</td>\n",
       "      <td>0.413271</td>\n",
       "      <td>2.977657</td>\n",
       "      <td>1.564818</td>\n",
       "      <td>2.327887</td>\n",
       "      <td>3.078103</td>\n",
       "      <td>10.202270</td>\n",
       "      <td>15.725294</td>\n",
       "      <td>3.930387</td>\n",
       "      <td>3.524007</td>\n",
       "      <td>3.372336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-11.666667</td>\n",
       "      <td>-11.666667</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>-10.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.010033</td>\n",
       "      <td>0.354610</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>89.766667</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.851786</td>\n",
       "      <td>-2.189781</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.459854</td>\n",
       "      <td>2.189781</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0.760000</td>\n",
       "      <td>2.700532</td>\n",
       "      <td>0.626132</td>\n",
       "      <td>1.063830</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>15.630000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>31.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>123.316667</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>6.235294</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.729927</td>\n",
       "      <td>2.919708</td>\n",
       "      <td>4.379562</td>\n",
       "      <td>5.109489</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>1.360000</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.135225</td>\n",
       "      <td>2.580645</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>17.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>52.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>165.979167</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>10.600000</td>\n",
       "      <td>2.189781</td>\n",
       "      <td>5.109489</td>\n",
       "      <td>6.569343</td>\n",
       "      <td>7.299270</td>\n",
       "      <td>8.759124</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>2.277778</td>\n",
       "      <td>4.952381</td>\n",
       "      <td>2.050012</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>18.560000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>620.000000</td>\n",
       "      <td>104.000000</td>\n",
       "      <td>507.483333</td>\n",
       "      <td>987.000000</td>\n",
       "      <td>147.000000</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>16.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>26.388889</td>\n",
       "      <td>51.666667</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Number of clicks  Number of sessions  Largest period of inactivity (h)  \\\n",
       "count      10186.000000        10186.000000                      10186.000000   \n",
       "mean          40.197035            9.940997                        124.593643   \n",
       "std           35.736811            7.887983                         58.954004   \n",
       "min            1.000000            1.000000                          0.000000   \n",
       "25%           17.000000            5.000000                         89.766667   \n",
       "50%           31.000000            8.000000                        123.316667   \n",
       "75%           52.000000           13.000000                        165.979167   \n",
       "max          620.000000          104.000000                        507.483333   \n",
       "\n",
       "       Total time online (min)  Average session duration (min)  \\\n",
       "count             10186.000000                    10186.000000   \n",
       "mean                 75.613587                        7.664978   \n",
       "std                  80.995556                        6.992485   \n",
       "min                   0.000000                        0.000000   \n",
       "25%                  20.000000                        2.851786   \n",
       "50%                  54.000000                        6.235294   \n",
       "75%                 106.000000                       10.600000   \n",
       "max                 987.000000                      147.000000   \n",
       "\n",
       "       Start of Session 1 (%)  Start of Session 2 (%)  Start of Session 3 (%)  \\\n",
       "count            10186.000000             9861.000000             9402.000000   \n",
       "mean                 0.233302                2.260167                3.666584   \n",
       "std                  4.166322                4.169601                4.317537   \n",
       "min                -11.666667              -11.666667              -10.000000   \n",
       "25%                 -2.189781                0.000000                0.000000   \n",
       "50%                  0.000000                0.729927                2.919708   \n",
       "75%                  2.189781                5.109489                6.569343   \n",
       "max                 16.666667               16.666667               16.666667   \n",
       "\n",
       "       Start of Session 4 (%)  Start of Session 5 (%)  ...  Forum posts  \\\n",
       "count             8775.000000             8040.000000  ...   117.000000   \n",
       "mean                 4.729155                5.606280  ...     1.136752   \n",
       "std                  4.337221                4.353308  ...     0.413271   \n",
       "min                -10.000000              -10.000000  ...     1.000000   \n",
       "25%                  1.459854                2.189781  ...     1.000000   \n",
       "50%                  4.379562                5.109489  ...     1.000000   \n",
       "75%                  7.299270                8.759124  ...     1.000000   \n",
       "max                 16.666667               16.666667  ...     3.000000   \n",
       "\n",
       "       Number of days  Clicks per day  Clicks per session  \\\n",
       "count    10186.000000    10186.000000        10186.000000   \n",
       "mean        23.339682        1.740594            4.124444   \n",
       "std          2.977657        1.564818            2.327887   \n",
       "min         18.000000        0.040000            1.000000   \n",
       "25%         25.000000        0.760000            2.700532   \n",
       "50%         25.000000        1.360000            3.666667   \n",
       "75%         25.000000        2.277778            4.952381   \n",
       "max         25.000000       26.388889           51.666667   \n",
       "\n",
       "       Clicks (% of course total)  Submissions (% of course total)  \\\n",
       "count                10186.000000                       285.000000   \n",
       "mean                     1.767131                         3.859649   \n",
       "std                      3.078103                        10.202270   \n",
       "min                      0.010033                         0.354610   \n",
       "25%                      0.626132                         1.063830   \n",
       "50%                      1.135225                         2.580645   \n",
       "75%                      2.050012                         2.857143   \n",
       "max                    100.000000                       100.000000   \n",
       "\n",
       "       Days with no interaction (%)     exam_mark    final_mark  \\\n",
       "count                  10186.000000  11297.000000  11297.000000   \n",
       "mean                      67.894256     14.613615     15.039648   \n",
       "std                       15.725294      3.930387      3.524007   \n",
       "min                        0.000000      0.000000      0.000000   \n",
       "25%                       60.000000     13.000000     14.000000   \n",
       "50%                       72.000000     16.000000     16.000000   \n",
       "75%                       80.000000     17.000000     17.000000   \n",
       "max                       96.000000     20.000000     20.000000   \n",
       "\n",
       "       Average grade of assignments  \n",
       "count                    357.000000  \n",
       "mean                      16.525994  \n",
       "std                        3.372336  \n",
       "min                        0.000000  \n",
       "25%                       15.630000  \n",
       "50%                       17.380000  \n",
       "75%                       18.560000  \n",
       "max                       20.000000  \n",
       "\n",
       "[8 rows x 36 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "course_programs['Date_threshold_10'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Stage: Data understanding Stage\n",
    "\n",
    "#### INITIAL EXPLORATION, CLEANING & FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time period: Date_threshold_10\n",
      "\n",
      "  course_encoding cd_curso semestre courseid userid  Number of clicks  \\\n",
      "0               0     4281       S1   200101    417              71.0   \n",
      "1               0     4281       S1   200101   1042              33.0   \n",
      "2               0     4281       S1   200101   1100              37.0   \n",
      "3               0     4281       S1   200101   2674              14.0   \n",
      "4               0     4281       S1   200101   3802              36.0   \n",
      "\n",
      "   Number of sessions  Largest period of inactivity (h)  \\\n",
      "0                16.0                        167.533333   \n",
      "1                16.0                         72.950000   \n",
      "2                11.0                        115.983333   \n",
      "3                 2.0                         59.983333   \n",
      "4                 8.0                        159.683333   \n",
      "\n",
      "   Total time online (min)  Average session duration (min)  ...  Forum posts  \\\n",
      "0                    100.0                        6.250000  ...          NaN   \n",
      "1                     12.0                        0.750000  ...          NaN   \n",
      "2                     25.0                        2.272727  ...          NaN   \n",
      "3                     21.0                       10.500000  ...          NaN   \n",
      "4                     30.0                        3.750000  ...          NaN   \n",
      "\n",
      "   Number of days  Clicks per day  Clicks per session  \\\n",
      "0            25.0            2.84            4.437500   \n",
      "1            25.0            1.32            2.062500   \n",
      "2            25.0            1.48            3.363636   \n",
      "3            25.0            0.56            7.000000   \n",
      "4            25.0            1.44            4.500000   \n",
      "\n",
      "   Clicks (% of course total)  Submissions (% of course total)  \\\n",
      "0                    2.556716                              NaN   \n",
      "1                    1.188333                              NaN   \n",
      "2                    1.332373                              NaN   \n",
      "3                    0.504141                              NaN   \n",
      "4                    1.296363                              NaN   \n",
      "\n",
      "   Days with no interaction (%)  exam_mark  final_mark  \\\n",
      "0                          64.0       12.0        12.0   \n",
      "1                          60.0       15.0        15.0   \n",
      "2                          68.0       16.0        16.0   \n",
      "3                          92.0       16.0        16.0   \n",
      "4                          76.0       16.0        16.0   \n",
      "\n",
      "   Average grade of assignments  \n",
      "0                           NaN  \n",
      "1                           NaN  \n",
      "2                           NaN  \n",
      "3                           NaN  \n",
      "4                           NaN  \n",
      "\n",
      "[5 rows x 41 columns]\n",
      "\n",
      "Time period: Date_threshold_25\n",
      "\n",
      "  course_encoding cd_curso semestre courseid userid  Number of clicks  \\\n",
      "0               0     4281       S1   200101    417             123.0   \n",
      "1               0     4281       S1   200101   1042              74.0   \n",
      "2               0     4281       S1   200101   1100              82.0   \n",
      "3               0     4281       S1   200101   2674              67.0   \n",
      "4               0     4281       S1   200101   3802              62.0   \n",
      "\n",
      "   Number of sessions  Largest period of inactivity (h)  \\\n",
      "0                26.0                        167.533333   \n",
      "1                26.0                        101.483333   \n",
      "2                20.0                        281.766667   \n",
      "3                 7.0                        166.516667   \n",
      "4                13.0                        188.333333   \n",
      "\n",
      "   Total time online (min)  Average session duration (min)  ...  Forum posts  \\\n",
      "0                    200.0                        7.692308  ...          NaN   \n",
      "1                     83.0                        3.192308  ...          NaN   \n",
      "2                    110.0                        5.500000  ...          NaN   \n",
      "3                    147.0                       21.000000  ...          NaN   \n",
      "4                    117.0                        9.000000  ...          NaN   \n",
      "\n",
      "   Number of days  Clicks per day  Clicks per session  \\\n",
      "0            46.0        2.673913            4.730769   \n",
      "1            46.0        1.608696            2.846154   \n",
      "2            46.0        1.782609            4.100000   \n",
      "3            46.0        1.456522            9.571429   \n",
      "4            46.0        1.347826            4.769231   \n",
      "\n",
      "   Clicks (% of course total)  Submissions (% of course total)  \\\n",
      "0                    2.143978                              NaN   \n",
      "1                    1.289873                              NaN   \n",
      "2                    1.429318                              NaN   \n",
      "3                    1.167858                              NaN   \n",
      "4                    1.080704                              NaN   \n",
      "\n",
      "   Days with no interaction (%)  exam_mark  final_mark  \\\n",
      "0                     67.391304       12.0        12.0   \n",
      "1                     58.695652       15.0        15.0   \n",
      "2                     71.739130       16.0        16.0   \n",
      "3                     84.782609       16.0        16.0   \n",
      "4                     78.260870       16.0        16.0   \n",
      "\n",
      "   Average grade of assignments  \n",
      "0                           NaN  \n",
      "1                           NaN  \n",
      "2                           NaN  \n",
      "3                           NaN  \n",
      "4                           NaN  \n",
      "\n",
      "[5 rows x 41 columns]\n",
      "\n",
      "Time period: Date_threshold_33\n",
      "\n",
      "  course_encoding cd_curso semestre courseid userid  Number of clicks  \\\n",
      "0               0     4281       S1   200101    417             129.0   \n",
      "1               0     4281       S1   200101   1042              86.0   \n",
      "2               0     4281       S1   200101   1100              82.0   \n",
      "3               0     4281       S1   200101   2674              69.0   \n",
      "4               0     4281       S1   200101   3802              70.0   \n",
      "\n",
      "   Number of sessions  Largest period of inactivity (h)  \\\n",
      "0                28.0                        167.533333   \n",
      "1                28.0                        101.483333   \n",
      "2                20.0                        281.766667   \n",
      "3                 8.0                        168.266667   \n",
      "4                15.0                        188.333333   \n",
      "\n",
      "   Total time online (min)  Average session duration (min)  ...  Forum posts  \\\n",
      "0                    203.0                        7.250000  ...          NaN   \n",
      "1                    125.0                        4.464286  ...          NaN   \n",
      "2                    110.0                        5.500000  ...          NaN   \n",
      "3                    147.0                       18.375000  ...          NaN   \n",
      "4                    121.0                        8.066667  ...          NaN   \n",
      "\n",
      "   Number of days  Clicks per day  Clicks per session  \\\n",
      "0            53.0        2.433962            4.607143   \n",
      "1            53.0        1.622642            3.071429   \n",
      "2            53.0        1.547170            4.100000   \n",
      "3            53.0        1.301887            8.625000   \n",
      "4            53.0        1.320755            4.666667   \n",
      "\n",
      "   Clicks (% of course total)  Submissions (% of course total)  \\\n",
      "0                    2.035021                              NaN   \n",
      "1                    1.356681                              NaN   \n",
      "2                    1.293579                              NaN   \n",
      "3                    1.088500                              NaN   \n",
      "4                    1.104275                              NaN   \n",
      "\n",
      "   Days with no interaction (%)  exam_mark  final_mark  \\\n",
      "0                     69.811321       12.0        12.0   \n",
      "1                     60.377358       15.0        15.0   \n",
      "2                     75.471698       16.0        16.0   \n",
      "3                     84.905660       16.0        16.0   \n",
      "4                     79.245283       16.0        16.0   \n",
      "\n",
      "   Average grade of assignments  \n",
      "0                           NaN  \n",
      "1                           NaN  \n",
      "2                           NaN  \n",
      "3                           NaN  \n",
      "4                           NaN  \n",
      "\n",
      "[5 rows x 41 columns]\n",
      "\n",
      "Time period: Date_threshold_50\n",
      "\n",
      "  course_encoding cd_curso semestre courseid userid  Number of clicks  \\\n",
      "0               0     4281       S1   200101    417             165.0   \n",
      "1               0     4281       S1   200101   1042             201.0   \n",
      "2               0     4281       S1   200101   1100             182.0   \n",
      "3               0     4281       S1   200101   2674             137.0   \n",
      "4               0     4281       S1   200101   3802              98.0   \n",
      "\n",
      "   Number of sessions  Largest period of inactivity (h)  \\\n",
      "0                37.0                        194.366667   \n",
      "1                50.0                        190.716667   \n",
      "2                35.0                        384.933333   \n",
      "3                18.0                        216.300000   \n",
      "4                20.0                        190.983333   \n",
      "\n",
      "   Total time online (min)  Average session duration (min)  ...  Forum posts  \\\n",
      "0                    215.0                        5.810811  ...          NaN   \n",
      "1                    415.0                        8.300000  ...          NaN   \n",
      "2                    202.0                        5.771429  ...          NaN   \n",
      "3                    191.0                       10.611111  ...          NaN   \n",
      "4                    181.0                        9.050000  ...          NaN   \n",
      "\n",
      "   Number of days  Clicks per day  Clicks per session  \\\n",
      "0            81.0        2.037037            4.459459   \n",
      "1            81.0        2.481481            4.020000   \n",
      "2            81.0        2.246914            5.200000   \n",
      "3            81.0        1.691358            7.611111   \n",
      "4            81.0        1.209877            4.900000   \n",
      "\n",
      "   Clicks (% of course total)  Submissions (% of course total)  \\\n",
      "0                    1.345511                              NaN   \n",
      "1                    1.639077                              NaN   \n",
      "2                    1.484139                              NaN   \n",
      "3                    1.117182                              NaN   \n",
      "4                    0.799152                              NaN   \n",
      "\n",
      "   Days with no interaction (%)  exam_mark  final_mark  \\\n",
      "0                     69.135802       12.0        12.0   \n",
      "1                     60.493827       15.0        15.0   \n",
      "2                     70.370370       16.0        16.0   \n",
      "3                     79.012346       16.0        16.0   \n",
      "4                     80.246914       16.0        16.0   \n",
      "\n",
      "   Average grade of assignments  \n",
      "0                           NaN  \n",
      "1                           NaN  \n",
      "2                           NaN  \n",
      "3                           NaN  \n",
      "4                           NaN  \n",
      "\n",
      "[5 rows x 41 columns]\n",
      "\n",
      "Time period: Date_threshold_100\n",
      "\n",
      "  course_encoding cd_curso semestre courseid userid  Number of clicks  \\\n",
      "0               0     4281       S1   200101    417               234   \n",
      "1               0     4281       S1   200101   1042               279   \n",
      "2               0     4281       S1   200101   1100               243   \n",
      "3               0     4281       S1   200101   2674               200   \n",
      "4               0     4281       S1   200101   3802               243   \n",
      "\n",
      "   Number of sessions  Largest period of inactivity (h)  \\\n",
      "0                  58                        542.650000   \n",
      "1                  71                        217.250000   \n",
      "2                  53                        384.933333   \n",
      "3                  32                        378.000000   \n",
      "4                  46                        366.000000   \n",
      "\n",
      "   Total time online (min)  Average session duration (min)  ...  Forum posts  \\\n",
      "0                    284.0                        4.896552  ...          NaN   \n",
      "1                    614.0                        8.647887  ...          NaN   \n",
      "2                    258.0                        4.867925  ...          NaN   \n",
      "3                    260.0                        8.125000  ...          NaN   \n",
      "4                    389.0                        8.456522  ...          NaN   \n",
      "\n",
      "   Number of days  Clicks per day  Clicks per session  \\\n",
      "0             151        1.549669            4.034483   \n",
      "1             151        1.847682            3.929577   \n",
      "2             151        1.609272            4.584906   \n",
      "3             151        1.324503            6.250000   \n",
      "4             151        1.609272            5.282609   \n",
      "\n",
      "   Clicks (% of course total)  Submissions (% of course total)  \\\n",
      "0                    1.312910                              NaN   \n",
      "1                    1.565393                              NaN   \n",
      "2                    1.363407                              NaN   \n",
      "3                    1.122146                              NaN   \n",
      "4                    1.363407                              NaN   \n",
      "\n",
      "   Days with no interaction (%)  exam_mark  final_mark  \\\n",
      "0                     66.887417       12.0        12.0   \n",
      "1                     61.589404       15.0        15.0   \n",
      "2                     68.874172       16.0        16.0   \n",
      "3                     74.834437       16.0        16.0   \n",
      "4                     73.509934       16.0        16.0   \n",
      "\n",
      "   Average grade of assignments  \n",
      "0                           NaN  \n",
      "1                           NaN  \n",
      "2                           NaN  \n",
      "3                           NaN  \n",
      "4                           NaN  \n",
      "\n",
      "[5 rows x 41 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step1 - Take a look at the datesets\n",
    "for i in course_programs:\n",
    "    print(f'Time period: {i}\\n\\n{course_programs[i].head()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11297 entries, 0 to 11296\n",
      "Data columns (total 41 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   course_encoding                   11297 non-null  object \n",
      " 1   cd_curso                          11297 non-null  object \n",
      " 2   semestre                          11297 non-null  object \n",
      " 3   courseid                          11297 non-null  object \n",
      " 4   userid                            11297 non-null  object \n",
      " 5   Number of clicks                  10186 non-null  float64\n",
      " 6   Number of sessions                10186 non-null  float64\n",
      " 7   Largest period of inactivity (h)  10186 non-null  float64\n",
      " 8   Total time online (min)           10186 non-null  float64\n",
      " 9   Average session duration (min)    10186 non-null  float64\n",
      " 10  Start of Session 1 (%)            10186 non-null  float64\n",
      " 11  Start of Session 2 (%)            9861 non-null   float64\n",
      " 12  Start of Session 3 (%)            9402 non-null   float64\n",
      " 13  Start of Session 4 (%)            8775 non-null   float64\n",
      " 14  Start of Session 5 (%)            8040 non-null   float64\n",
      " 15  Start of Session 6 (%)            7237 non-null   float64\n",
      " 16  Start of Session 7 (%)            6408 non-null   float64\n",
      " 17  Start of Session 8 (%)            5620 non-null   float64\n",
      " 18  Start of Session 9 (%)            4858 non-null   float64\n",
      " 19  Start of Session 10 (%)           4162 non-null   float64\n",
      " 20  Days with no interaction          10186 non-null  float64\n",
      " 21  Clicks on forum                   5347 non-null   float64\n",
      " 22  Links viewed                      5793 non-null   float64\n",
      " 23  Clicks on folder                  3848 non-null   float64\n",
      " 24  Clicks on course                  10183 non-null  float64\n",
      " 25  Resources viewed                  7968 non-null   float64\n",
      " 26  Discussions viewed                3161 non-null   float64\n",
      " 27  Quizzes started                   275 non-null    float64\n",
      " 28  Files downloaded                  1367 non-null   float64\n",
      " 29  Assignments submitted             285 non-null    float64\n",
      " 30  Assignments viewed                662 non-null    float64\n",
      " 31  Forum posts                       117 non-null    float64\n",
      " 32  Number of days                    10186 non-null  float64\n",
      " 33  Clicks per day                    10186 non-null  float64\n",
      " 34  Clicks per session                10186 non-null  float64\n",
      " 35  Clicks (% of course total)        10186 non-null  float64\n",
      " 36  Submissions (% of course total)   285 non-null    float64\n",
      " 37  Days with no interaction (%)      10186 non-null  float64\n",
      " 38  exam_mark                         11297 non-null  float64\n",
      " 39  final_mark                        11297 non-null  float64\n",
      " 40  Average grade of assignments      357 non-null    float64\n",
      "dtypes: float64(36), object(5)\n",
      "memory usage: 3.5+ MB\n",
      "Time period: Date_threshold_10\n",
      "\n",
      "None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11297 entries, 0 to 11296\n",
      "Data columns (total 41 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   course_encoding                   11297 non-null  object \n",
      " 1   cd_curso                          11297 non-null  object \n",
      " 2   semestre                          11297 non-null  object \n",
      " 3   courseid                          11297 non-null  object \n",
      " 4   userid                            11297 non-null  object \n",
      " 5   Number of clicks                  11045 non-null  float64\n",
      " 6   Number of sessions                11045 non-null  float64\n",
      " 7   Largest period of inactivity (h)  11045 non-null  float64\n",
      " 8   Total time online (min)           11045 non-null  float64\n",
      " 9   Average session duration (min)    11045 non-null  float64\n",
      " 10  Start of Session 1 (%)            11045 non-null  float64\n",
      " 11  Start of Session 2 (%)            10878 non-null  float64\n",
      " 12  Start of Session 3 (%)            10715 non-null  float64\n",
      " 13  Start of Session 4 (%)            10484 non-null  float64\n",
      " 14  Start of Session 5 (%)            10238 non-null  float64\n",
      " 15  Start of Session 6 (%)            9944 non-null   float64\n",
      " 16  Start of Session 7 (%)            9583 non-null   float64\n",
      " 17  Start of Session 8 (%)            9192 non-null   float64\n",
      " 18  Start of Session 9 (%)            8747 non-null   float64\n",
      " 19  Start of Session 10 (%)           8264 non-null   float64\n",
      " 20  Days with no interaction          11045 non-null  float64\n",
      " 21  Clicks on forum                   6548 non-null   float64\n",
      " 22  Links viewed                      6919 non-null   float64\n",
      " 23  Clicks on folder                  5086 non-null   float64\n",
      " 24  Clicks on course                  11044 non-null  float64\n",
      " 25  Resources viewed                  9477 non-null   float64\n",
      " 26  Discussions viewed                4171 non-null   float64\n",
      " 27  Quizzes started                   749 non-null    float64\n",
      " 28  Files downloaded                  2025 non-null   float64\n",
      " 29  Assignments submitted             733 non-null    float64\n",
      " 30  Assignments viewed                1345 non-null   float64\n",
      " 31  Forum posts                       191 non-null    float64\n",
      " 32  Number of days                    11045 non-null  float64\n",
      " 33  Clicks per day                    11045 non-null  float64\n",
      " 34  Clicks per session                11045 non-null  float64\n",
      " 35  Clicks (% of course total)        11045 non-null  float64\n",
      " 36  Submissions (% of course total)   733 non-null    float64\n",
      " 37  Days with no interaction (%)      11045 non-null  float64\n",
      " 38  exam_mark                         11297 non-null  float64\n",
      " 39  final_mark                        11297 non-null  float64\n",
      " 40  Average grade of assignments      1147 non-null   float64\n",
      "dtypes: float64(36), object(5)\n",
      "memory usage: 3.5+ MB\n",
      "Time period: Date_threshold_25\n",
      "\n",
      "None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11297 entries, 0 to 11296\n",
      "Data columns (total 41 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   course_encoding                   11297 non-null  object \n",
      " 1   cd_curso                          11297 non-null  object \n",
      " 2   semestre                          11297 non-null  object \n",
      " 3   courseid                          11297 non-null  object \n",
      " 4   userid                            11297 non-null  object \n",
      " 5   Number of clicks                  11142 non-null  float64\n",
      " 6   Number of sessions                11142 non-null  float64\n",
      " 7   Largest period of inactivity (h)  11142 non-null  float64\n",
      " 8   Total time online (min)           11142 non-null  float64\n",
      " 9   Average session duration (min)    11142 non-null  float64\n",
      " 10  Start of Session 1 (%)            11142 non-null  float64\n",
      " 11  Start of Session 2 (%)            11017 non-null  float64\n",
      " 12  Start of Session 3 (%)            10882 non-null  float64\n",
      " 13  Start of Session 4 (%)            10736 non-null  float64\n",
      " 14  Start of Session 5 (%)            10583 non-null  float64\n",
      " 15  Start of Session 6 (%)            10384 non-null  float64\n",
      " 16  Start of Session 7 (%)            10153 non-null  float64\n",
      " 17  Start of Session 8 (%)            9863 non-null   float64\n",
      " 18  Start of Session 9 (%)            9552 non-null   float64\n",
      " 19  Start of Session 10 (%)           9192 non-null   float64\n",
      " 20  Days with no interaction          11142 non-null  float64\n",
      " 21  Clicks on forum                   6842 non-null   float64\n",
      " 22  Links viewed                      7246 non-null   float64\n",
      " 23  Clicks on folder                  5337 non-null   float64\n",
      " 24  Clicks on course                  11141 non-null  float64\n",
      " 25  Resources viewed                  9783 non-null   float64\n",
      " 26  Discussions viewed                4422 non-null   float64\n",
      " 27  Quizzes started                   1033 non-null   float64\n",
      " 28  Files downloaded                  2154 non-null   float64\n",
      " 29  Assignments submitted             880 non-null    float64\n",
      " 30  Assignments viewed                1733 non-null   float64\n",
      " 31  Forum posts                       212 non-null    float64\n",
      " 32  Number of days                    11142 non-null  float64\n",
      " 33  Clicks per day                    11142 non-null  float64\n",
      " 34  Clicks per session                11142 non-null  float64\n",
      " 35  Clicks (% of course total)        11142 non-null  float64\n",
      " 36  Submissions (% of course total)   880 non-null    float64\n",
      " 37  Days with no interaction (%)      11142 non-null  float64\n",
      " 38  exam_mark                         11297 non-null  float64\n",
      " 39  final_mark                        11297 non-null  float64\n",
      " 40  Average grade of assignments      1840 non-null   float64\n",
      "dtypes: float64(36), object(5)\n",
      "memory usage: 3.5+ MB\n",
      "Time period: Date_threshold_33\n",
      "\n",
      "None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11297 entries, 0 to 11296\n",
      "Data columns (total 41 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   course_encoding                   11297 non-null  object \n",
      " 1   cd_curso                          11297 non-null  object \n",
      " 2   semestre                          11297 non-null  object \n",
      " 3   courseid                          11297 non-null  object \n",
      " 4   userid                            11297 non-null  object \n",
      " 5   Number of clicks                  11220 non-null  float64\n",
      " 6   Number of sessions                11220 non-null  float64\n",
      " 7   Largest period of inactivity (h)  11220 non-null  float64\n",
      " 8   Total time online (min)           11220 non-null  float64\n",
      " 9   Average session duration (min)    11220 non-null  float64\n",
      " 10  Start of Session 1 (%)            11220 non-null  float64\n",
      " 11  Start of Session 2 (%)            11134 non-null  float64\n",
      " 12  Start of Session 3 (%)            11059 non-null  float64\n",
      " 13  Start of Session 4 (%)            10964 non-null  float64\n",
      " 14  Start of Session 5 (%)            10865 non-null  float64\n",
      " 15  Start of Session 6 (%)            10776 non-null  float64\n",
      " 16  Start of Session 7 (%)            10650 non-null  float64\n",
      " 17  Start of Session 8 (%)            10508 non-null  float64\n",
      " 18  Start of Session 9 (%)            10361 non-null  float64\n",
      " 19  Start of Session 10 (%)           10183 non-null  float64\n",
      " 20  Days with no interaction          11220 non-null  float64\n",
      " 21  Clicks on forum                   7498 non-null   float64\n",
      " 22  Links viewed                      7548 non-null   float64\n",
      " 23  Clicks on folder                  5791 non-null   float64\n",
      " 24  Clicks on course                  11218 non-null  float64\n",
      " 25  Resources viewed                  10055 non-null  float64\n",
      " 26  Discussions viewed                5107 non-null   float64\n",
      " 27  Quizzes started                   1561 non-null   float64\n",
      " 28  Files downloaded                  2437 non-null   float64\n",
      " 29  Assignments submitted             1579 non-null   float64\n",
      " 30  Assignments viewed                2654 non-null   float64\n",
      " 31  Forum posts                       266 non-null    float64\n",
      " 32  Number of days                    11220 non-null  float64\n",
      " 33  Clicks per day                    11220 non-null  float64\n",
      " 34  Clicks per session                11220 non-null  float64\n",
      " 35  Clicks (% of course total)        11220 non-null  float64\n",
      " 36  Submissions (% of course total)   1579 non-null   float64\n",
      " 37  Days with no interaction (%)      11220 non-null  float64\n",
      " 38  exam_mark                         11297 non-null  float64\n",
      " 39  final_mark                        11297 non-null  float64\n",
      " 40  Average grade of assignments      2967 non-null   float64\n",
      "dtypes: float64(36), object(5)\n",
      "memory usage: 3.5+ MB\n",
      "Time period: Date_threshold_50\n",
      "\n",
      "None\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 11297 entries, 0 to 11296\n",
      "Data columns (total 41 columns):\n",
      " #   Column                            Non-Null Count  Dtype  \n",
      "---  ------                            --------------  -----  \n",
      " 0   course_encoding                   11297 non-null  object \n",
      " 1   cd_curso                          11297 non-null  object \n",
      " 2   semestre                          11297 non-null  object \n",
      " 3   courseid                          11297 non-null  object \n",
      " 4   userid                            11297 non-null  object \n",
      " 5   Number of clicks                  11297 non-null  int64  \n",
      " 6   Number of sessions                11297 non-null  int64  \n",
      " 7   Largest period of inactivity (h)  11297 non-null  float64\n",
      " 8   Total time online (min)           11297 non-null  float64\n",
      " 9   Average session duration (min)    11297 non-null  float64\n",
      " 10  Start of Session 1 (%)            11297 non-null  float64\n",
      " 11  Start of Session 2 (%)            11252 non-null  float64\n",
      " 12  Start of Session 3 (%)            11223 non-null  float64\n",
      " 13  Start of Session 4 (%)            11183 non-null  float64\n",
      " 14  Start of Session 5 (%)            11147 non-null  float64\n",
      " 15  Start of Session 6 (%)            11113 non-null  float64\n",
      " 16  Start of Session 7 (%)            11076 non-null  float64\n",
      " 17  Start of Session 8 (%)            11042 non-null  float64\n",
      " 18  Start of Session 9 (%)            10983 non-null  float64\n",
      " 19  Start of Session 10 (%)           10925 non-null  float64\n",
      " 20  Days with no interaction          11297 non-null  int64  \n",
      " 21  Clicks on forum                   8612 non-null   float64\n",
      " 22  Links viewed                      7933 non-null   float64\n",
      " 23  Clicks on folder                  6664 non-null   float64\n",
      " 24  Clicks on course                  11296 non-null  float64\n",
      " 25  Resources viewed                  10388 non-null  float64\n",
      " 26  Discussions viewed                6560 non-null   float64\n",
      " 27  Quizzes started                   5451 non-null   float64\n",
      " 28  Files downloaded                  2909 non-null   float64\n",
      " 29  Assignments submitted             4006 non-null   float64\n",
      " 30  Assignments viewed                4592 non-null   float64\n",
      " 31  Forum posts                       402 non-null    float64\n",
      " 32  Number of days                    11297 non-null  int64  \n",
      " 33  Clicks per day                    11297 non-null  float64\n",
      " 34  Clicks per session                11297 non-null  float64\n",
      " 35  Clicks (% of course total)        11297 non-null  float64\n",
      " 36  Submissions (% of course total)   4006 non-null   float64\n",
      " 37  Days with no interaction (%)      11297 non-null  float64\n",
      " 38  exam_mark                         11297 non-null  float64\n",
      " 39  final_mark                        11297 non-null  float64\n",
      " 40  Average grade of assignments      8090 non-null   float64\n",
      "dtypes: float64(32), int64(4), object(5)\n",
      "memory usage: 3.5+ MB\n",
      "Time period: Date_threshold_100\n",
      "\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Step1 - Take a look at the datesets\n",
    "for i in course_programs:\n",
    "    print(f'Time period: {i}\\n\\n{course_programs[i].info()}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d536ea2f838f42c399c2001d78567dcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time period: Date_threshold_10\n",
      "\n",
      "        course_encoding  cd_curso semestre  courseid   userid  \\\n",
      "count           11297.0   11297.0    11297   11297.0  11297.0   \n",
      "unique            181.0      15.0        6     146.0   1677.0   \n",
      "top               150.0    9434.0       S1  200167.0   3178.0   \n",
      "freq              178.0    2857.0     4566     276.0     15.0   \n",
      "mean                NaN       NaN      NaN       NaN      NaN   \n",
      "std                 NaN       NaN      NaN       NaN      NaN   \n",
      "min                 NaN       NaN      NaN       NaN      NaN   \n",
      "25%                 NaN       NaN      NaN       NaN      NaN   \n",
      "50%                 NaN       NaN      NaN       NaN      NaN   \n",
      "75%                 NaN       NaN      NaN       NaN      NaN   \n",
      "max                 NaN       NaN      NaN       NaN      NaN   \n",
      "\n",
      "        Number of clicks  Number of sessions  \\\n",
      "count       10186.000000        10186.000000   \n",
      "unique               NaN                 NaN   \n",
      "top                  NaN                 NaN   \n",
      "freq                 NaN                 NaN   \n",
      "mean           40.197035            9.940997   \n",
      "std            35.736811            7.887983   \n",
      "min             1.000000            1.000000   \n",
      "25%            17.000000            5.000000   \n",
      "50%            31.000000            8.000000   \n",
      "75%            52.000000           13.000000   \n",
      "max           620.000000          104.000000   \n",
      "\n",
      "        Largest period of inactivity (h)  Total time online (min)  \\\n",
      "count                       10186.000000             10186.000000   \n",
      "unique                               NaN                      NaN   \n",
      "top                                  NaN                      NaN   \n",
      "freq                                 NaN                      NaN   \n",
      "mean                          124.593643                75.613587   \n",
      "std                            58.954004                80.995556   \n",
      "min                             0.000000                 0.000000   \n",
      "25%                            89.766667                20.000000   \n",
      "50%                           123.316667                54.000000   \n",
      "75%                           165.979167               106.000000   \n",
      "max                           507.483333               987.000000   \n",
      "\n",
      "        Average session duration (min)  ...  Forum posts  Number of days  \\\n",
      "count                     10186.000000  ...   117.000000    10186.000000   \n",
      "unique                             NaN  ...          NaN             NaN   \n",
      "top                                NaN  ...          NaN             NaN   \n",
      "freq                               NaN  ...          NaN             NaN   \n",
      "mean                          7.664978  ...     1.136752       23.339682   \n",
      "std                           6.992485  ...     0.413271        2.977657   \n",
      "min                           0.000000  ...     1.000000       18.000000   \n",
      "25%                           2.851786  ...     1.000000       25.000000   \n",
      "50%                           6.235294  ...     1.000000       25.000000   \n",
      "75%                          10.600000  ...     1.000000       25.000000   \n",
      "max                         147.000000  ...     3.000000       25.000000   \n",
      "\n",
      "        Clicks per day  Clicks per session  Clicks (% of course total)  \\\n",
      "count     10186.000000        10186.000000                10186.000000   \n",
      "unique             NaN                 NaN                         NaN   \n",
      "top                NaN                 NaN                         NaN   \n",
      "freq               NaN                 NaN                         NaN   \n",
      "mean          1.740594            4.124444                    1.767131   \n",
      "std           1.564818            2.327887                    3.078103   \n",
      "min           0.040000            1.000000                    0.010033   \n",
      "25%           0.760000            2.700532                    0.626132   \n",
      "50%           1.360000            3.666667                    1.135225   \n",
      "75%           2.277778            4.952381                    2.050012   \n",
      "max          26.388889           51.666667                  100.000000   \n",
      "\n",
      "        Submissions (% of course total)  Days with no interaction (%)  \\\n",
      "count                        285.000000                  10186.000000   \n",
      "unique                              NaN                           NaN   \n",
      "top                                 NaN                           NaN   \n",
      "freq                                NaN                           NaN   \n",
      "mean                           3.859649                     67.894256   \n",
      "std                           10.202270                     15.725294   \n",
      "min                            0.354610                      0.000000   \n",
      "25%                            1.063830                     60.000000   \n",
      "50%                            2.580645                     72.000000   \n",
      "75%                            2.857143                     80.000000   \n",
      "max                          100.000000                     96.000000   \n",
      "\n",
      "           exam_mark    final_mark  Average grade of assignments  \n",
      "count   11297.000000  11297.000000                    357.000000  \n",
      "unique           NaN           NaN                           NaN  \n",
      "top              NaN           NaN                           NaN  \n",
      "freq             NaN           NaN                           NaN  \n",
      "mean       14.613615     15.039648                     16.525994  \n",
      "std         3.930387      3.524007                      3.372336  \n",
      "min         0.000000      0.000000                      0.000000  \n",
      "25%        13.000000     14.000000                     15.630000  \n",
      "50%        16.000000     16.000000                     17.380000  \n",
      "75%        17.000000     17.000000                     18.560000  \n",
      "max        20.000000     20.000000                     20.000000  \n",
      "\n",
      "[11 rows x 41 columns]\n",
      "\n",
      "Time period: Date_threshold_25\n",
      "\n",
      "        course_encoding  cd_curso semestre  courseid   userid  \\\n",
      "count           11297.0   11297.0    11297   11297.0  11297.0   \n",
      "unique            181.0      15.0        6     146.0   1677.0   \n",
      "top               150.0    9434.0       S1  200167.0   3178.0   \n",
      "freq              178.0    2857.0     4566     276.0     15.0   \n",
      "mean                NaN       NaN      NaN       NaN      NaN   \n",
      "std                 NaN       NaN      NaN       NaN      NaN   \n",
      "min                 NaN       NaN      NaN       NaN      NaN   \n",
      "25%                 NaN       NaN      NaN       NaN      NaN   \n",
      "50%                 NaN       NaN      NaN       NaN      NaN   \n",
      "75%                 NaN       NaN      NaN       NaN      NaN   \n",
      "max                 NaN       NaN      NaN       NaN      NaN   \n",
      "\n",
      "        Number of clicks  Number of sessions  \\\n",
      "count       11045.000000        11045.000000   \n",
      "unique               NaN                 NaN   \n",
      "top                  NaN                 NaN   \n",
      "freq                 NaN                 NaN   \n",
      "mean           71.444455           17.818742   \n",
      "std            56.529663           13.380581   \n",
      "min             1.000000            1.000000   \n",
      "25%            34.000000            9.000000   \n",
      "50%            59.000000           15.000000   \n",
      "75%            94.000000           23.000000   \n",
      "max           718.000000          154.000000   \n",
      "\n",
      "        Largest period of inactivity (h)  Total time online (min)  \\\n",
      "count                       11045.000000             11045.000000   \n",
      "unique                               NaN                      NaN   \n",
      "top                                  NaN                      NaN   \n",
      "freq                                 NaN                      NaN   \n",
      "mean                          171.187629               134.481123   \n",
      "std                            88.275621               128.009578   \n",
      "min                             0.000000                 0.000000   \n",
      "25%                           121.383333                46.000000   \n",
      "50%                           166.083333               103.000000   \n",
      "75%                           172.933333               186.000000   \n",
      "max                           906.716667              1900.000000   \n",
      "\n",
      "        Average session duration (min)  ...  Forum posts  Number of days  \\\n",
      "count                     11045.000000  ...   191.000000    11045.000000   \n",
      "unique                             NaN  ...          NaN             NaN   \n",
      "top                                NaN  ...          NaN             NaN   \n",
      "freq                               NaN  ...          NaN             NaN   \n",
      "mean                          7.421140  ...     1.282723       41.706836   \n",
      "std                           5.360270  ...     0.610147        8.095001   \n",
      "min                           0.000000  ...     1.000000       25.000000   \n",
      "25%                           3.857143  ...     1.000000       46.000000   \n",
      "50%                           6.571429  ...     1.000000       46.000000   \n",
      "75%                          10.000000  ...     1.000000       46.000000   \n",
      "max                         147.000000  ...     5.000000       46.000000   \n",
      "\n",
      "        Clicks per day  Clicks per session  Clicks (% of course total)  \\\n",
      "count     11045.000000        11045.000000                11045.000000   \n",
      "unique             NaN                 NaN                         NaN   \n",
      "top                NaN                 NaN                         NaN   \n",
      "freq               NaN                 NaN                         NaN   \n",
      "mean          1.750061            4.106914                    1.638751   \n",
      "std           1.407298            1.949984                    1.891193   \n",
      "min           0.021739            1.000000                    0.006821   \n",
      "25%           0.840000            2.923077                    0.667577   \n",
      "50%           1.413043            3.750000                    1.190476   \n",
      "75%           2.280000            4.823529                    2.059801   \n",
      "max          21.560000           33.142857                   75.000000   \n",
      "\n",
      "        Submissions (% of course total)  Days with no interaction (%)  \\\n",
      "count                        733.000000                  11045.000000   \n",
      "unique                              NaN                           NaN   \n",
      "top                                 NaN                           NaN   \n",
      "freq                                NaN                           NaN   \n",
      "mean                           3.819918                     65.196689   \n",
      "std                            6.588256                     15.608789   \n",
      "min                            0.188147                      0.000000   \n",
      "25%                            1.034807                     56.521739   \n",
      "50%                            2.116402                     67.391304   \n",
      "75%                            4.166667                     76.086957   \n",
      "max                          100.000000                     96.000000   \n",
      "\n",
      "           exam_mark    final_mark  Average grade of assignments  \n",
      "count   11297.000000  11297.000000                   1147.000000  \n",
      "unique           NaN           NaN                           NaN  \n",
      "top              NaN           NaN                           NaN  \n",
      "freq             NaN           NaN                           NaN  \n",
      "mean       14.613615     15.039648                     14.289217  \n",
      "std         3.930387      3.524007                      4.170245  \n",
      "min         0.000000      0.000000                      0.000000  \n",
      "25%        13.000000     14.000000                     12.600000  \n",
      "50%        16.000000     16.000000                     15.300000  \n",
      "75%        17.000000     17.000000                     17.345000  \n",
      "max        20.000000     20.000000                     20.000000  \n",
      "\n",
      "[11 rows x 41 columns]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time period: Date_threshold_33\n",
      "\n",
      "        course_encoding  cd_curso semestre  courseid   userid  \\\n",
      "count           11297.0   11297.0    11297   11297.0  11297.0   \n",
      "unique            181.0      15.0        6     146.0   1677.0   \n",
      "top               150.0    9434.0       S1  200167.0   3178.0   \n",
      "freq              178.0    2857.0     4566     276.0     15.0   \n",
      "mean                NaN       NaN      NaN       NaN      NaN   \n",
      "std                 NaN       NaN      NaN       NaN      NaN   \n",
      "min                 NaN       NaN      NaN       NaN      NaN   \n",
      "25%                 NaN       NaN      NaN       NaN      NaN   \n",
      "50%                 NaN       NaN      NaN       NaN      NaN   \n",
      "75%                 NaN       NaN      NaN       NaN      NaN   \n",
      "max                 NaN       NaN      NaN       NaN      NaN   \n",
      "\n",
      "        Number of clicks  Number of sessions  \\\n",
      "count       11142.000000        11142.000000   \n",
      "unique               NaN                 NaN   \n",
      "top                  NaN                 NaN   \n",
      "freq                 NaN                 NaN   \n",
      "mean           84.853348           20.923443   \n",
      "std            65.597676           15.130767   \n",
      "min             1.000000            1.000000   \n",
      "25%            43.000000           11.000000   \n",
      "50%            71.000000           18.000000   \n",
      "75%           110.000000           27.000000   \n",
      "max           985.000000          184.000000   \n",
      "\n",
      "        Largest period of inactivity (h)  Total time online (min)  \\\n",
      "count                       11142.000000             11142.000000   \n",
      "unique                               NaN                      NaN   \n",
      "top                                  NaN                      NaN   \n",
      "freq                                 NaN                      NaN   \n",
      "mean                          185.076713               158.122240   \n",
      "std                            98.217403               145.778837   \n",
      "min                             0.000000                 0.000000   \n",
      "25%                           139.433333                59.000000   \n",
      "50%                           167.466667               124.000000   \n",
      "75%                           193.683333               215.000000   \n",
      "max                          1067.016667              2897.000000   \n",
      "\n",
      "        Average session duration (min)  ...  Forum posts  Number of days  \\\n",
      "count                     11142.000000  ...   212.000000    11142.000000   \n",
      "unique                             NaN  ...          NaN             NaN   \n",
      "top                                NaN  ...          NaN             NaN   \n",
      "freq                               NaN  ...          NaN             NaN   \n",
      "mean                          7.418410  ...     1.372642       48.714683   \n",
      "std                           4.819474  ...     0.651507        8.090137   \n",
      "min                           0.000000  ...     1.000000       32.000000   \n",
      "25%                           4.142857  ...     1.000000       53.000000   \n",
      "50%                           6.680909  ...     1.000000       53.000000   \n",
      "75%                           9.875000  ...     2.000000       53.000000   \n",
      "max                          73.500000  ...     5.000000       53.000000   \n",
      "\n",
      "        Clicks per day  Clicks per session  Clicks (% of course total)  \\\n",
      "count     11142.000000        11142.000000                11142.000000   \n",
      "unique             NaN                 NaN                         NaN   \n",
      "top                NaN                 NaN                         NaN   \n",
      "freq               NaN                 NaN                         NaN   \n",
      "mean          1.778139            4.177254                    1.624484   \n",
      "std           1.411957            1.962882                    1.836901   \n",
      "min           0.018868            1.000000                    0.006269   \n",
      "25%           0.886792            3.000000                    0.685363   \n",
      "50%           1.461538            3.833333                    1.186758   \n",
      "75%           2.283019            4.900000                    2.046447   \n",
      "max          28.437500           47.400000                   75.862069   \n",
      "\n",
      "        Submissions (% of course total)  Days with no interaction (%)  \\\n",
      "count                        880.000000                  11142.000000   \n",
      "unique                              NaN                           NaN   \n",
      "top                                 NaN                           NaN   \n",
      "freq                                NaN                           NaN   \n",
      "mean                           3.636364                     65.105610   \n",
      "std                            4.274730                     15.081097   \n",
      "min                            0.157853                      0.000000   \n",
      "25%                            1.000000                     56.603774   \n",
      "50%                            2.197802                     67.924528   \n",
      "75%                            4.123711                     75.471698   \n",
      "max                           40.000000                     96.226415   \n",
      "\n",
      "           exam_mark    final_mark  Average grade of assignments  \n",
      "count   11297.000000  11297.000000                   1840.000000  \n",
      "unique           NaN           NaN                           NaN  \n",
      "top              NaN           NaN                           NaN  \n",
      "freq             NaN           NaN                           NaN  \n",
      "mean       14.613615     15.039648                     15.011688  \n",
      "std         3.930387      3.524007                      4.193597  \n",
      "min         0.000000      0.000000                      0.000000  \n",
      "25%        13.000000     14.000000                     13.457500  \n",
      "50%        16.000000     16.000000                     16.000000  \n",
      "75%        17.000000     17.000000                     18.000000  \n",
      "max        20.000000     20.000000                     20.000000  \n",
      "\n",
      "[11 rows x 41 columns]\n",
      "\n",
      "Time period: Date_threshold_50\n",
      "\n",
      "        course_encoding  cd_curso semestre  courseid   userid  \\\n",
      "count           11297.0   11297.0    11297   11297.0  11297.0   \n",
      "unique            181.0      15.0        6     146.0   1677.0   \n",
      "top               150.0    9434.0       S1  200167.0   3178.0   \n",
      "freq              178.0    2857.0     4566     276.0     15.0   \n",
      "mean                NaN       NaN      NaN       NaN      NaN   \n",
      "std                 NaN       NaN      NaN       NaN      NaN   \n",
      "min                 NaN       NaN      NaN       NaN      NaN   \n",
      "25%                 NaN       NaN      NaN       NaN      NaN   \n",
      "50%                 NaN       NaN      NaN       NaN      NaN   \n",
      "75%                 NaN       NaN      NaN       NaN      NaN   \n",
      "max                 NaN       NaN      NaN       NaN      NaN   \n",
      "\n",
      "        Number of clicks  Number of sessions  \\\n",
      "count       11220.000000        11220.000000   \n",
      "unique               NaN                 NaN   \n",
      "top                  NaN                 NaN   \n",
      "freq                 NaN                 NaN   \n",
      "mean          126.088324           30.364795   \n",
      "std            96.616399           21.698400   \n",
      "min             1.000000            1.000000   \n",
      "25%            63.000000           17.000000   \n",
      "50%           105.000000           26.000000   \n",
      "75%           165.000000           39.000000   \n",
      "max          1546.000000          307.000000   \n",
      "\n",
      "        Largest period of inactivity (h)  Total time online (min)  \\\n",
      "count                       11220.000000             11220.000000   \n",
      "unique                               NaN                      NaN   \n",
      "top                                  NaN                      NaN   \n",
      "freq                                 NaN                      NaN   \n",
      "mean                          281.720046               229.468538   \n",
      "std                           172.317250               204.568731   \n",
      "min                             0.000000                 0.000000   \n",
      "25%                           167.395833                89.000000   \n",
      "50%                           242.300000               181.000000   \n",
      "75%                           336.066667               312.000000   \n",
      "max                          1701.316667              3917.000000   \n",
      "\n",
      "        Average session duration (min)  ...  Forum posts  Number of days  \\\n",
      "count                     11220.000000  ...   266.000000    11220.000000   \n",
      "unique                             NaN  ...          NaN             NaN   \n",
      "top                                NaN  ...          NaN             NaN   \n",
      "freq                               NaN  ...          NaN             NaN   \n",
      "mean                          7.342788  ...     1.597744       72.460250   \n",
      "std                           4.284869  ...     0.923404       16.157492   \n",
      "min                           0.000000  ...     1.000000       39.000000   \n",
      "25%                           4.438643  ...     1.000000       81.000000   \n",
      "50%                           6.809524  ...     1.000000       81.000000   \n",
      "75%                           9.647059  ...     2.000000       81.000000   \n",
      "max                          69.000000  ...     7.000000       81.000000   \n",
      "\n",
      "        Clicks per day  Clicks per session  Clicks (% of course total)  \\\n",
      "count     11220.000000        11220.000000                11220.000000   \n",
      "unique             NaN                 NaN                         NaN   \n",
      "top                NaN                 NaN                         NaN   \n",
      "freq               NaN                 NaN                         NaN   \n",
      "mean          1.790627            4.262777                    1.613191   \n",
      "std           1.392101            1.991168                    1.717130   \n",
      "min           0.012346            1.000000                    0.004627   \n",
      "25%           0.901235            3.130435                    0.707646   \n",
      "50%           1.493827            3.923077                    1.194583   \n",
      "75%           2.307930            4.928571                    2.038340   \n",
      "max          28.743590           49.000000                   72.413793   \n",
      "\n",
      "        Submissions (% of course total)  Days with no interaction (%)  \\\n",
      "count                       1579.000000                  11220.000000   \n",
      "unique                              NaN                           NaN   \n",
      "top                                 NaN                           NaN   \n",
      "freq                                NaN                           NaN   \n",
      "mean                           3.419886                     66.094478   \n",
      "std                            4.840964                     14.232462   \n",
      "min                            0.105708                      1.234568   \n",
      "25%                            1.000000                     58.024691   \n",
      "50%                            1.941748                     67.901235   \n",
      "75%                            4.545455                     76.543210   \n",
      "max                          100.000000                     97.435897   \n",
      "\n",
      "           exam_mark    final_mark  Average grade of assignments  \n",
      "count   11297.000000  11297.000000                   2967.000000  \n",
      "unique           NaN           NaN                           NaN  \n",
      "top              NaN           NaN                           NaN  \n",
      "freq             NaN           NaN                           NaN  \n",
      "mean       14.613615     15.039648                     14.433730  \n",
      "std         3.930387      3.524007                      4.205944  \n",
      "min         0.000000      0.000000                      0.000000  \n",
      "25%        13.000000     14.000000                     12.262500  \n",
      "50%        16.000000     16.000000                     15.500000  \n",
      "75%        17.000000     17.000000                     17.500000  \n",
      "max        20.000000     20.000000                     20.000000  \n",
      "\n",
      "[11 rows x 41 columns]\n",
      "\n",
      "Time period: Date_threshold_100\n",
      "\n",
      "        course_encoding  cd_curso semestre  courseid   userid  \\\n",
      "count           11297.0   11297.0    11297   11297.0  11297.0   \n",
      "unique            181.0      15.0        6     146.0   1677.0   \n",
      "top               150.0    9434.0       S1  200167.0   3178.0   \n",
      "freq              178.0    2857.0     4566     276.0     15.0   \n",
      "mean                NaN       NaN      NaN       NaN      NaN   \n",
      "std                 NaN       NaN      NaN       NaN      NaN   \n",
      "min                 NaN       NaN      NaN       NaN      NaN   \n",
      "25%                 NaN       NaN      NaN       NaN      NaN   \n",
      "50%                 NaN       NaN      NaN       NaN      NaN   \n",
      "75%                 NaN       NaN      NaN       NaN      NaN   \n",
      "max                 NaN       NaN      NaN       NaN      NaN   \n",
      "\n",
      "        Number of clicks  Number of sessions  \\\n",
      "count       11297.000000        11297.000000   \n",
      "unique               NaN                 NaN   \n",
      "top                  NaN                 NaN   \n",
      "freq                 NaN                 NaN   \n",
      "mean          258.101266           51.631849   \n",
      "std           172.005062           34.404286   \n",
      "min             1.000000            1.000000   \n",
      "25%           145.000000           30.000000   \n",
      "50%           230.000000           46.000000   \n",
      "75%           334.000000           66.000000   \n",
      "max          2607.000000          480.000000   \n",
      "\n",
      "        Largest period of inactivity (h)  Total time online (min)  \\\n",
      "count                       11297.000000             11297.000000   \n",
      "unique                               NaN                      NaN   \n",
      "top                                  NaN                      NaN   \n",
      "freq                                 NaN                      NaN   \n",
      "mean                          430.471779               426.164114   \n",
      "std                           274.595329               354.607162   \n",
      "min                             0.000000                 0.000000   \n",
      "25%                           258.666667               199.000000   \n",
      "50%                           361.383333               357.000000   \n",
      "75%                           507.600000               568.000000   \n",
      "max                          2911.800000             11618.000000   \n",
      "\n",
      "        Average session duration (min)  ...  Forum posts  Number of days  \\\n",
      "count                     11297.000000  ...   402.000000    11297.000000   \n",
      "unique                             NaN  ...          NaN             NaN   \n",
      "top                                NaN  ...          NaN             NaN   \n",
      "freq                               NaN  ...          NaN             NaN   \n",
      "mean                          8.159609  ...     1.751244      135.097725   \n",
      "std                           5.150949  ...     1.135600       29.960946   \n",
      "min                           0.000000  ...     1.000000       74.000000   \n",
      "25%                           5.521739  ...     1.000000      151.000000   \n",
      "50%                           7.700000  ...     1.000000      151.000000   \n",
      "75%                          10.239130  ...     2.000000      151.000000   \n",
      "max                         352.060606  ...    10.000000      151.000000   \n",
      "\n",
      "        Clicks per day  Clicks per session  Clicks (% of course total)  \\\n",
      "count     11297.000000        11297.000000                11297.000000   \n",
      "unique             NaN                 NaN                         NaN   \n",
      "top                NaN                 NaN                         NaN   \n",
      "freq               NaN                 NaN                         NaN   \n",
      "mean          1.969906            5.262625                    1.602195   \n",
      "std           1.358103            2.672772                    1.446617   \n",
      "min           0.006623            1.000000                    0.001638   \n",
      "25%           1.105960            3.750000                    0.736842   \n",
      "50%           1.708609            4.691176                    1.215004   \n",
      "75%           2.529801            6.015625                    2.054576   \n",
      "max          35.229730           49.625000                   69.736842   \n",
      "\n",
      "        Submissions (% of course total)  Days with no interaction (%)  \\\n",
      "count                       4006.000000                  11297.000000   \n",
      "unique                              NaN                           NaN   \n",
      "top                                 NaN                           NaN   \n",
      "freq                                NaN                           NaN   \n",
      "mean                           2.770844                     63.625087   \n",
      "std                            4.698940                     11.886023   \n",
      "min                            0.100604                      4.635762   \n",
      "25%                            0.865801                     56.953642   \n",
      "50%                            1.694915                     65.263158   \n",
      "75%                            3.288854                     71.578947   \n",
      "max                          100.000000                     92.715232   \n",
      "\n",
      "           exam_mark    final_mark  Average grade of assignments  \n",
      "count   11297.000000  11297.000000                   8090.000000  \n",
      "unique           NaN           NaN                           NaN  \n",
      "top              NaN           NaN                           NaN  \n",
      "freq             NaN           NaN                           NaN  \n",
      "mean       14.613615     15.039648                     14.534261  \n",
      "std         3.930387      3.524007                      3.448651  \n",
      "min         0.000000      0.000000                      0.000000  \n",
      "25%        13.000000     14.000000                     12.880625  \n",
      "50%        16.000000     16.000000                     15.300000  \n",
      "75%        17.000000     17.000000                     17.000000  \n",
      "max        20.000000     20.000000                     20.000000  \n",
      "\n",
      "[11 rows x 41 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#describe method\n",
    "for i in tqdm(course_programs):\n",
    "    print(f'Time period: {i}\\n\\n{course_programs[i].describe(include = \"all\")}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SOME DATA EXPLORATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa061aa4c74a42b8bce5170ba873c923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date_threshold_10\n"
     ]
    }
   ],
   "source": [
    "#then we plot an histogram with all courses, we are not interested in keeping courses with a number of students inferior to 10\n",
    "sns.set_theme(context='paper', style='whitegrid', font='Calibri', rc={\"figure.figsize\":(16, 10)}, font_scale=2)\n",
    "\n",
    "#Plot the distributions of each feature \n",
    "for i in tqdm(course_programs):\n",
    "    print(i)\n",
    "    course_programs[i].hist(figsize=(16, 20), bins=100, xlabelsize=8, ylabelsize=8, color = student_color)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting target:\n",
    "\n",
    "As stated, we will predict the exam grade as it does not depend direcly from assignment grades.\n",
    "\n",
    "We will use a double classification problem:\n",
    "\n",
    "**Problem 1**: Identify students at risk of failure. In the portuguese system, a student passes if the final grade greater or equal to 10. Students who do not meet the threshold fail. When it comes to exams, the difference is not as clear cut. For simplicity, we will consider exam grade to be less or equal to 10 - same with final grade. \n",
    "\n",
    "**Problem 2**: Identify high performing students. The classification of high performers is not unanymous. A simple solution would be consider as high performers all students whose grade is greater or equal to a certain threshold (say 17/20). There are issues with this approach however:\n",
    "\n",
    "    - different teachers have different criteria for grading and their grading decisions. We can look at the top 20% of students in each course as identify them as the high performers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dicts with proposed gifted student threshold\n",
    "exam_gifted_threshold = course_programs['Date_threshold_100'].groupby('course_encoding')['exam_mark'].quantile(.85).to_dict()\n",
    "final_gifted_threshold = course_programs['Date_threshold_100'].groupby('course_encoding')['final_mark'].quantile(.85).to_dict()\n",
    "\n",
    "#create loops for targets\n",
    "for i in tqdm(course_programs):\n",
    "    print(i)\n",
    "    \n",
    "    #create new columns with the threshold of grades\n",
    "    course_programs[i]['exam_gifted_threshold'] = course_programs[i]['exam_mark'].map(exam_gifted_threshold)\n",
    "    course_programs[i]['final_gifted_threshold'] = course_programs[i]['final_mark'].map(final_gifted_threshold)\n",
    "    \n",
    "    #deal with risk of failure\n",
    "    course_programs[i]['exam_fail'] = np.where(course_programs[i]['exam_mark'] > 11, 0, 1) #at risk in exam\n",
    "    course_programs[i]['final_fail'] = np.where(course_programs[i]['final_mark'] > 11, 0, 1) #at risk in final grade   \n",
    "    \n",
    "    #deal with gifted classification\n",
    "    course_programs[i]['exam_gifted'] = np.where(course_programs[i]['exam_mark'] >= course_programs[i]['exam_gifted_threshold'],\n",
    "                                                                                                                            1, 0) #gifted students according to exam grade\n",
    "    course_programs[i]['final_gifted'] = np.where(course_programs[i]['final_mark'] >= course_programs[i]['final_gifted_threshold'],\n",
    "                                                                                                                            1, 0) #gifted students according to final grade\n",
    "    \n",
    "    #delete threshold columns, \n",
    "    course_programs[i].drop(['exam_gifted_threshold', 'final_gifted_threshold'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_programs['Date_threshold_100'].describe(include = 'all').T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Looking for Group (Course) Aggregates\n",
    "\n",
    "We will look at the 100% duration logs in order to make most of our verification. After all, the 100% duration threshold will be the basis for comparison.\n",
    "\n",
    "We will, for now, use the following immediate criteria for exclusion:\n",
    "1. Median % of days with no interaction > 80%,\n",
    "2. To have 0 mean for at-risk students or gifted students."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "aggregates = course_programs['Date_threshold_10'].groupby('course_encoding').agg({\n",
    "                                                                'userid' :  [('Number of users','nunique')],\n",
    "                                                                'Number of sessions' : ['min', 'mean', 'median', 'max'],\n",
    "                                                                'Clicks per day' : ['min', 'mean', 'median', 'max'],\n",
    "                                                                'Days with no interaction (%)' : ['min', 'mean', 'median', 'max'], \n",
    "                                                                'exam_fail' : 'mean',\n",
    "                                                                'final_fail' : 'mean',\n",
    "                                                                'exam_gifted' : 'mean',\n",
    "                                                                'final_gifted' : 'mean',                                                                \n",
    "                                                                    })\n",
    "#show all\n",
    "with pd.option_context(\"display.max_rows\", None):\n",
    "    display(aggregates)\n",
    "    \n",
    "        #same for session features\n",
    "aggregates.columns = aggregates.columns.map(flattenHierarchicalCol)\n",
    "aggregates.reset_index(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only keep rows that fulfill the criteria - median user with less than 80% days without interaction \n",
    "aggregates = aggregates[~((aggregates['Days with no interaction (%)_median'] > 85) | (aggregates['exam_fail_mean'] == 0) | (aggregates['exam_gifted_mean'] == 0))]\n",
    "courses_to_keep = aggregates['course_encoding'].unique()\n",
    "\n",
    "#filtering dataset for all course durations\n",
    "for i in tqdm(course_programs):\n",
    "    course_programs[i] = course_programs[i][course_programs[i]['course_encoding'].isin(courses_to_keep)].reset_index(drop = True)\n",
    "\n",
    "course_programs['Date_threshold_100'].describe(include = 'all').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "course_programs['Date_threshold_100'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Organizar features\n",
    "targets = ['exam_fail', 'final_fail', 'exam_gifted', 'final_gifted']\n",
    "\n",
    "numeric_feat = [ 'Number of clicks', 'Number of sessions',\n",
    "       'Largest period of inactivity (h)', 'Total time online (min)',\n",
    "       'Average session duration (min)', 'Start of Session 1 (%)',\n",
    "       'Start of Session 2 (%)', 'Start of Session 3 (%)',\n",
    "       'Start of Session 4 (%)', 'Start of Session 5 (%)',\n",
    "       'Start of Session 6 (%)', 'Start of Session 7 (%)',\n",
    "       'Start of Session 8 (%)', 'Start of Session 9 (%)',\n",
    "       'Start of Session 10 (%)', 'Days with no interaction',\n",
    "       'Clicks on forum', 'Links viewed', 'Clicks on folder',\n",
    "       'Clicks on course', 'Resources viewed', 'Discussions viewed',\n",
    "       'Quizzes started', 'Files downloaded', 'Assignments submitted',\n",
    "       'Assignments viewed', 'Forum posts', 'Number of days', 'Clicks per day',\n",
    "       'Clicks per session', 'Clicks (% of course total)',\n",
    "       'Submissions (% of course total)', 'Days with no interaction (%)']\n",
    "\n",
    "#optional features -> assignment grades\n",
    "#optional_feats =[]\n",
    "\n",
    "#binary_feat = []\n",
    "\n",
    "#categorical_feat = []\n",
    "\n",
    "#date = []\n",
    "\n",
    "drop_feat = ['cd_curso', 'semestre', 'courseid', 'exam_mark', 'final_mark', 'Average grade of assignments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Data Quality Report for Continuous Features\n",
    "\n",
    "def DescribeContinuousFeatures(Continuous_Features, dataset):\n",
    "    Continuous_Head = ['Count', 'Missing Values (%)', 'Cardinality', 'Minimum', '1st Qrt.', 'Mean', 'Median', '3rd Qrt.', 'Maximum', 'Std. Dev.']\n",
    "    Continuous_Describe = pd.DataFrame(index=Continuous_Features, columns=Continuous_Head)\n",
    "    Continuous_Describe.index.name = 'Feature Name'\n",
    "    columns = dataset[Continuous_Features]\n",
    "\n",
    "#Total Number of Instances\n",
    "    Continuous_Describe[Continuous_Head[0]] = columns.count()\n",
    "\n",
    "#Percentage of instances that has Missing Values (sabendo à partida que nenhuma variável contínua tem missings)\n",
    "    Continuous_Describe[Continuous_Head[1]] = columns.isnull().sum() * 100 / len(dataset)\n",
    "    \n",
    "#Cardinality of each feature (cardinality measures the number of Distinct Values)\n",
    "    Continuous_Describe[Continuous_Head[2]] = columns.nunique()\n",
    "\n",
    "#Minimum Value\n",
    "    Continuous_Describe[Continuous_Head[3]] = columns.min()\n",
    "\n",
    "#1ST Quartile\n",
    "    Continuous_Describe[Continuous_Head[4]] = columns.quantile(0.25)\n",
    "\n",
    "#Mean\n",
    "    Continuous_Describe[Continuous_Head[5]] = round(columns.mean(), 2)\n",
    "\n",
    "#Median\n",
    "    Continuous_Describe[Continuous_Head[6]] = columns.median()\n",
    "\n",
    "#3rd Quartile\n",
    "    Continuous_Describe[Continuous_Head[7]] = columns.quantile(0.75)\n",
    "\n",
    "#Maximum Value\n",
    "    Continuous_Describe[Continuous_Head[8]] = columns.max()\n",
    "\n",
    "#Standard Deviation\n",
    "    Continuous_Describe[Continuous_Head[9]] = round(columns.std(),2)\n",
    "    \n",
    "    return Continuous_Describe\n",
    "\n",
    "for i in tqdm(course_programs):\n",
    "    print(f'{i}\\n\\n{DescribeContinuousFeatures(numeric_feat,course_programs[i])}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cell below may be commented for faster computation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sns.set_theme(context='paper', style='whitegrid', font='Calibri', font_scale=2)\n",
    "\n",
    "# for i in tqdm(course_programs):\n",
    "    \n",
    "#     print(i)\n",
    "#     #perform a very simple pairplot\n",
    "#     g = sns.PairGrid(course_programs[i][numeric_feat], corner = True)\n",
    "    \n",
    "#     #frequency histogram on diagonal\n",
    "#     g.map_diag(sns.histplot, color = 'grey', stat = 'frequency', kde = True)\n",
    "    \n",
    "#     #regplot is a scatter with regression line\n",
    "#     g.map_offdiag(sns.regplot, fit_reg=True, x_jitter=.1, color = course_color,  marker = 'x')\n",
    "    \n",
    "#     # Layout\n",
    "#     plt.subplots_adjust(top=0.95)\n",
    "#     plt.title(\"Pairwise Relationship of Numerical Variables\", fontweight=\"bold\")\n",
    "    \n",
    "#     plt.savefig(f'../Images/numerical_feats_{i}_pair.png', transparent=True, dpi=300)\n",
    "#     plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def cor_heatmap(cor):\n",
    "#     plt.figure(figsize=(32,32))\n",
    "#     return sns.heatmap(data = cor, annot = True, cmap = standard_cmap, fmt='.1',\n",
    "#                 vmin = -1, vmax = 1,\n",
    "#                )\n",
    "    \n",
    "# sns.set_theme(context='paper', style='whitegrid', font='Calibri', rc={\"figure.figsize\":(32, 32)}, font_scale=2)\n",
    "\n",
    "# for i in tqdm(course_programs):\n",
    "#     print(i)\n",
    "#     cor_spearman = course_programs[i][numeric_feat].corr(method = 'spearman')\n",
    "#     g = cor_heatmap(cor_spearman)\n",
    "#     fig = g.get_figure()\n",
    "#     fig.savefig(f'../Images/numerical_feats_{i}_heat.png', transparent=True, dpi=300)\n",
    "#     plt.close(\"all\")\n",
    "    \n",
    "# del g, fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Immediate observations\n",
    "\n",
    "Very low correlations throughout most metric features, eith the exception of a couple.\n",
    "Still need to verify what to do concerning outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to Call later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_selection_table(dataset, target):\n",
    "\n",
    "    feature_df = dataset.copy()\n",
    "    \n",
    "    X = feature_df.drop(targets,axis=1)\n",
    "    y = feature_df[target]\n",
    "    num_feats=len(X.columns)\n",
    "    X_norm = MinMaxScaler().fit_transform(X)\n",
    "\n",
    "    #RFE\n",
    "    rfe_selector = RFE(estimator=DecisionTreeClassifier(), step=2)\n",
    "    rfe_selector.fit(X_norm, y)\n",
    "    rfe_support = rfe_selector.get_support()\n",
    "    rfe_feature = X.loc[:,rfe_support].columns.tolist()\n",
    "\n",
    "    #RFECV\n",
    "    rfecv_selector = RFECV(estimator=DecisionTreeClassifier(), step=1, cv=5, scoring='f1_weighted', \n",
    "                          min_features_to_select = 10)\n",
    "    rfecv_selector = rfecv_selector.fit(X_norm, y)\n",
    "    rfecv_support = rfecv_selector.support_\n",
    "    rfecv_feature = X.loc[:,rfecv_support].columns.tolist()\n",
    "\n",
    "    #Logistic regression\n",
    "    embeded_lr_selector = SelectFromModel(LogisticRegression(penalty=\"l2\"), max_features=num_feats)\n",
    "    embeded_lr_selector.fit(X_norm, y)\n",
    "    embeded_lr_support = embeded_lr_selector.get_support()\n",
    "    embeded_lr_feature = X.loc[:,embeded_lr_support].columns.tolist()\n",
    "\n",
    "    #RandomForest \n",
    "    embeded_rf_selector = SelectFromModel(RandomForestClassifier(n_estimators=100), max_features=num_feats)\n",
    "    embeded_rf_selector.fit(X, y)\n",
    "    embeded_rf_support = embeded_rf_selector.get_support()\n",
    "    embeded_rf_feature = X.loc[:,embeded_rf_support].columns.tolist()\n",
    "\n",
    "\n",
    "    #LGBMClassifier\n",
    "    lgbc=LGBMClassifier(n_estimators=500, learning_rate=0.05, num_leaves=32, colsample_bytree=0.2,\n",
    "                reg_alpha=3, reg_lambda=1, min_split_gain=0.01, min_child_weight=40)\n",
    "    embeded_lgb_selector = SelectFromModel(lgbc, max_features=num_feats)\n",
    "    embeded_lgb_selector.fit(X, y)\n",
    "    embeded_lgb_support = embeded_lgb_selector.get_support()\n",
    "    embeded_lgb_feature = X.loc[:,embeded_lgb_support].columns.tolist()\n",
    "\n",
    "    #Lasso\n",
    "    reg = LassoCV(random_state=123) \n",
    "    reg.fit(X=X,y=y)\n",
    "    lasso_coef = pd.Series(reg.coef_,index = X.columns)\n",
    "\n",
    "    #Ridge\n",
    "    ridge = RidgeCV()\n",
    "    ridge.fit(X=X,y=y)\n",
    "    coef_ridge = pd.Series(ridge.coef_,index = X.columns)\n",
    "\n",
    "    #Elastic \n",
    "    elast = ElasticNetCV(cv=5, random_state=123)\n",
    "    elast.fit(X, y)\n",
    "    elast_coef = pd.Series(elast.coef_,index = X.columns)\n",
    "\n",
    "    # put all selection together\n",
    "    feature_selection_df = pd.DataFrame({'Feature':X.columns, 'RFE':rfe_support,'RFECV':rfecv_support, 'Logistics':embeded_lr_support,\n",
    "                                        'Random Forest':embeded_rf_support, 'LightGBM':embeded_lgb_support, 'Lasso':lasso_coef != 0, 'Ridge':coef_ridge != 0, 'Elastic':elast_coef != 0})\n",
    "    # count the selected times for each feature\n",
    "    feature_selection_df['Total'] = np.sum(feature_selection_df, axis=1)\n",
    "    \n",
    "    # display the top 100\n",
    "    feature_selection_df = feature_selection_df.sort_values(['Total'] , ascending=False)\n",
    "    feature_selection_df.set_index('Feature',inplace=True)\n",
    "    feature_selection_df\n",
    "    \n",
    "    return feature_df,feature_selection_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(dataset,scaler):\n",
    "    \n",
    "    if scaler == 'MinMax':\n",
    "        pt = MinMaxScaler()\n",
    "    elif scaler == 'Standard':\n",
    "        pt = StandardScaler()\n",
    "    elif scaler == 'Robust':\n",
    "        pt = RobustScaler()\n",
    "    elif scaler == 'Quantile':\n",
    "        pt = QuantileTransformer()\n",
    "    else:\n",
    "        pt = PowerTransformer(method='yeo-johnson')\n",
    "    \n",
    "    data = pt.fit_transform(dataset)\n",
    "    \n",
    "    # convert the array back to a dataframe\n",
    "    normalized_df = pd.DataFrame(data,columns=dataset.columns)\n",
    "    return normalized_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting data preparation:\n",
    "\n",
    "\n",
    "## Start by Calling the Funtions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Dropping non relevant features\n",
    "feature_df_dict = {}\n",
    "feature_selection_df_dict = {}\n",
    "\n",
    "for i in tqdm(course_programs):\n",
    "    print(i)\n",
    "    \n",
    "    #create subordinate dicts\n",
    "    feature_df_dict[f'{(i)}'] = {}\n",
    "    feature_selection_df_dict[f'{(i)}'] = {}\n",
    "    \n",
    "    data_prep_df = course_programs[i].drop(columns = drop_feat).set_index(['course_encoding', 'userid'])\n",
    "    #for now, fill nans with 0\n",
    "    data_prep_df = data_prep_df.fillna(0)\n",
    "    \n",
    "    #set x and y\n",
    "    X = data_prep_df.drop(columns = targets)\n",
    "    y = data_prep_df[targets]\n",
    "\n",
    "    #run feature selection\n",
    "    for k in tqdm(list(y.columns)):\n",
    "        print(k)\n",
    "        feature_df_dict[i][k],feature_selection_df_dict[i][k] = feature_selection_table(data_prep_df, k)\n",
    "        print(feature_selection_df_dict[i][k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### It will be important to save these results of features selection. \n",
    "We will create an excel file for each duration threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas.io.parsers import ExcelWriter\n",
    "for i in tqdm(feature_selection_df_dict.keys()):\n",
    "    with pd.ExcelWriter(f\"../Data/Modeling Stage/Feature Selection/Nova_IMS_feature_selection_{i}_no_assign.xlsx\") as writer:  \n",
    "    #saving file for setor comercial\n",
    "    \n",
    "        for sheet in targets:\n",
    "            feature_selection_df_dict[i][sheet].to_excel(writer, sheet_name=str(sheet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_df_dict[i][k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_data = deepcopy(feature_df_dict)\n",
    "\n",
    "#now  cutting features to obtain results\n",
    "for i in tqdm(feature_df_dict):\n",
    "    \n",
    "    for k in targets:\n",
    "        normalized_data[i][k] = feature_df_dict[i][k][feature_selection_df_dict[i][k].loc[feature_selection_df_dict[i][k]['Total'] >3].index.tolist()]\n",
    "        #general normalization\n",
    "        normalized_data[i][k] = normalize(normalized_data[i][k],'Standard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL TESTING & SELECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first part of this section will hinge on defining the functions to use during model selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run desired model\n",
    "def run_model(model_name, X, y):\n",
    "    \n",
    "    ###STANDALONE MODELS\n",
    "    ###Baseline Classifier - most frequent class\n",
    "    if model_name == 'Baseline - Majority Class':\n",
    "        model = DummyClassifier(strategy=\"most_frequent\").fit(X, y)\n",
    "    if model_name == 'KNN':\n",
    "        #Manhattan distance, which should work better for high dimensional datasets\n",
    "        #weights to attribute higher weight to closer neighbors; seems to improve score highly\n",
    "        model = KNeighborsClassifier(n_neighbors=10, weights='distance').fit(X, y) #\n",
    "    if model_name == 'LR':\n",
    "        model = LogisticRegression(tol=1e-05, solver='liblinear', penalty='l1', max_iter =200).fit(X, y) #\n",
    "    if model_name == 'NB': \n",
    "        model = GaussianNB().fit(X, y)\n",
    "    if model_name == 'BNB': #\n",
    "        model = BernoulliNB().fit(X, y)\n",
    "#     if model_name == 'MNB': #\n",
    "#         model = MultinomialNB().fit(X, y)\n",
    "    if model_name == 'MLP': #\n",
    "        model = MLPClassifier(alpha=0.01, hidden_layer_sizes = (20,20), activation = 'relu', solver = 'adam', learning_rate = 'adaptive', verbose = 0, learning_rate_init = 0.02).fit(X, y)\n",
    "    if model_name == 'CART DT':\n",
    "        model = DecisionTreeClassifier(criterion='gini', max_depth=10).fit(X, y)\n",
    "    if model_name == 'J48 DT':\n",
    "        model = DecisionTreeClassifier(criterion = \"entropy\", max_depth=10).fit(X, y)        \n",
    "    if model_name == 'SVM': #\n",
    "        model = svm.SVC(tol = 0.01, probability = True, gamma='scale', kernel='rbf', C = 1).fit(X, y)\n",
    "    \n",
    "    ###ENSEMBLES\n",
    "    if model_name == 'RF':\n",
    "        model = RandomForestClassifier(max_depth = 10, random_state = 15, n_estimators=500, min_samples_leaf = 3).fit(X, y) #max_features=6, #max_depth é super imp para reduzir overfitting! #min_samples_lead highly reduces overfitting!\n",
    "    if model_name == 'AdaBoost':\n",
    "        model = AdaBoostClassifier(n_estimators = 95, learning_rate = 0.8, random_state = 15).fit(X, y) #importante que GSearchCV em DT maximizado!\n",
    "    if model_name == 'GBoost':\n",
    "        model = GradientBoostingClassifier(n_estimators=175, learning_rate=0.1, random_state=15).fit(X, y)\n",
    "    if model_name == 'ExtraTree':\n",
    "        model = ExtraTreesClassifier(n_estimators=175, criterion='entropy', max_depth = 10, min_samples_split= 50).fit(X, y)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#averages scores of each run (for the present model) in each iteration of Repeated 10-fold CV that has been called\n",
    "def avg_score(method,X,y, model_name):\n",
    "    \n",
    "    f1micro_train = []\n",
    "    f1micro_val = []\n",
    "    precision_train = []\n",
    "    precision_val = []\n",
    "    recall_train = []\n",
    "    recall_val = []\n",
    "    timer = []\n",
    "    cm_holder = []\n",
    "    test_holder = []\n",
    "    auc_train = []\n",
    "    auc_val = []\n",
    "    \n",
    "    \n",
    "    averaged_confusion_matrix=None\n",
    "    \n",
    "    for train_index, val_index in method.split(X,y):\n",
    "        X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "        y_train, y_val = y.iloc[train_index], y.iloc[val_index]\n",
    "        \n",
    "        #Oversampling with SMOTE\n",
    "        over = SMOTE()\n",
    "        X_train, y_train = over.fit_resample(X_train, y_train)\n",
    "        \n",
    "        begin = time.perf_counter()\n",
    "        model = run_model(model_name, X_train, y_train)\n",
    "        end = time.perf_counter()\n",
    "        \n",
    "        labels_train = model.predict(X_train)\n",
    "        labels_val = model.predict(X_val)\n",
    "        \n",
    "        f1micro_train.append(f1_score(y_train, labels_train, average='micro'))\n",
    "        f1micro_val.append(f1_score(y_val, labels_val, average='micro'))\n",
    "        \n",
    "        precision_train.append(precision_score(y_train, labels_train))\n",
    "        precision_val.append(precision_score(y_val, labels_val))\n",
    "        \n",
    "        recall_train.append(recall_score(y_train, labels_train))\n",
    "        recall_val.append(recall_score(y_val, labels_val))\n",
    "        \n",
    "        auc_train.append(roc_auc_score(y_train,model.predict_proba(X_train)[:,1]))\n",
    "        auc_val.append(roc_auc_score(y_val,model.predict_proba(X_val)[:,1]))\n",
    "        \n",
    "        timer.append(end-begin)\n",
    "        \n",
    "        cm_holder.append(confusion_matrix(y_val, labels_val))\n",
    "        \n",
    "    model = run_model(model_name, X,y)\n",
    "    labels_test = model.predict(X_test)\n",
    "    \n",
    "    f1micro_test = f1_score(y_test, labels_test, average='micro')\n",
    "    precision_test = precision_score(y_test, labels_test)\n",
    "    recall_test = recall_score(y_test, labels_test)\n",
    "    \n",
    "    #SVM does not allow probabilities\n",
    "    try:\n",
    "        auc_test = roc_auc_score(y_test,model.predict_proba(X_test)[:,1])\n",
    "        \n",
    "    except:\n",
    "        auc_test = np.nan\n",
    "    \n",
    "    print(f'Classification Report for {model_name}:\\nTest Data\\n{classification_report(y_test, labels_test)}\\n' + \n",
    "         f'Confusion Matrix:\\n {confusion_matrix(y_test, labels_test)}\\n')\n",
    "    \n",
    "    # calculate the average and the std for each measure (accuracy, time and number of iterations)\n",
    "    avg_time = round(np.mean(timer),3)\n",
    "    avg_f1_train = round(np.mean(f1micro_train),3)\n",
    "    avg_f1_val = round(np.mean(f1micro_val),3)\n",
    "    avg_f1_test = round(np.mean(f1micro_test),3)\n",
    "    avg_precision_train = round(np.mean(precision_train),3)\n",
    "    avg_precision_val = round(np.mean(precision_val),3)\n",
    "    avg_precision_test = round(precision_test,3)\n",
    "    avg_recall_train = round(np.mean(recall_train),3)\n",
    "    avg_recall_val = round(np.mean(recall_val),3)\n",
    "    avg_recall_test = round(recall_test,3)\n",
    "    avg_auc_train = round(np.mean(auc_train),3)\n",
    "    avg_auc_val = round(np.mean(auc_val),3)\n",
    "    avg_auc_test = round(auc_test,3)\n",
    "    \n",
    "    \n",
    "    std_time = round(np.std(timer),3)\n",
    "    std_f1_train = round(np.std(f1micro_train),3)\n",
    "    std_f1_val = round(np.std(f1micro_test),3)\n",
    "    std_precision_train = round(np.std(precision_train),3)\n",
    "    std_precision_val = round(np.std(precision_val),3)\n",
    "    std_recall_train = round(np.std(recall_train),3)\n",
    "    std_recall_val = round(np.std(recall_val),3)\n",
    "    std_auc_train = round(np.std(auc_train),3)\n",
    "    std_auc_val = round(np.std(auc_val),3)\n",
    "    \n",
    "    averaged_confusion_matrix = np.mean(cm_holder, axis = 0).round(2)\n",
    "    \n",
    "    #from sklearn.metrics import cohen_kappa_score\n",
    "    return str(avg_time) + '+/-' + str(std_time), str(avg_f1_train) + '+/-' + str(std_f1_train), str(avg_f1_val) + '+/-' + str(std_f1_val), str(avg_f1_test), str(avg_precision_train) + '+/-' + str(std_precision_train), str(avg_precision_val) + '+/-' + str(std_precision_val), str(avg_precision_test), str(avg_recall_train) + '+/-' + str(std_recall_train), str(avg_recall_val) + '+/-' + str(std_recall_val), str(avg_recall_test), str(avg_auc_train)+ '+/-' + str(std_auc_train), str(avg_auc_val)+ '+/-' + str(std_auc_val), str(avg_auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plt_bar(models, f1micro_train, f1micro_val, f1micro_test, path, date, target):\n",
    "    \n",
    "    sns.set_theme(context='paper', style='whitegrid', font='Calibri', font_scale=2)\n",
    "    \n",
    "    #Creates a figure and a set of subplots\n",
    "    fig, ax = plt.subplots(figsize = (20, 12))\n",
    "\n",
    "    #set width of bar\n",
    "    barwidth = 0.3\n",
    "\n",
    "    #set position of bar on X axis\n",
    "    pos_train = np.arange(len(f1micro_test))\n",
    "    pos_val = np.arange(len(f1micro_test))+0.3\n",
    "    pos_test = np.arange(len(f1micro_test))+0.6\n",
    "    \n",
    "    #convert to number\n",
    "    f1micro_train = [float(i.split('+')[0]) for i in f1micro_train]\n",
    "    f1micro_val = [float(i.split('+')[0]) for i in f1micro_val]\n",
    "    f1micro_test = [float(i.split('+')[0]) for i in f1micro_test]\n",
    "    \n",
    "    #makes the plot\n",
    "    plt.bar(pos_train, f1micro_train, color= nova_ims_colors[0], width=barwidth, edgecolor='white', label='Train')\n",
    "    plt.bar(pos_val, f1micro_val, color=course_color, width=barwidth, edgecolor='white', label='Validation')\n",
    "    plt.bar(pos_test, f1micro_test, color=student_color, width=barwidth, edgecolor='white', label='Test')\n",
    "    \n",
    "    #sets x, y labels\n",
    "    ax.set(xlabel = 'Model', ylabel = 'Accuracy')\n",
    "\n",
    "    #sets x ticks locations and designation\n",
    "    ax.set_xticks((pos_train+pos_val+pos_test)/3)\n",
    "    ax.set_xticklabels(models, rotation='vertical')\n",
    "    \n",
    "    #ads title to the plot\n",
    "    plt.title(f'10-fold Repeated Cross-Validation Results\\nData: {date}, Target:{target}', fontweight=\"bold\")\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    #removes box to make the plot prettier\n",
    "    plt.box(on=None)\n",
    "\n",
    "    #Creates (pretty) legend\n",
    "    plt.legend(frameon=False)\n",
    "    \n",
    "    plt.savefig(path, transparent=True, dpi=300)\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_roc_pr(models, X, y, path_roc, path_pr, date, target):  \n",
    "    \n",
    "    sns.set_theme(context='paper', style='whitegrid', font='Calibri', font_scale=2)\n",
    "    # Below for loop iterates through your models list\n",
    "    for m in models:\n",
    "        model = m['model']\n",
    "        y_pred=model.predict(X) # predict the test data\n",
    "    #Compute False postive rate, and True positive rate\n",
    "        fpr, tpr, _ = roc_curve(y, model.predict_proba(X)[:,1])\n",
    "    #Calculate AUC\n",
    "        auc = roc_auc_score(y,model.predict_proba(X)[:,1])\n",
    "    #Plot\n",
    "        plt.plot(fpr, tpr, label='%s ROC (area = %0.4f)' % (m['label'], auc))\n",
    "    #Makes it pretty!\n",
    "    #plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Specificity (False Positive Rate)', fontweight = 'bold')\n",
    "    plt.ylabel('Sensitivity (True Positive Rate)', fontweight = 'bold')\n",
    "    plt.title(f'ROC Curve Test\\nData: {date}, Target:{target}', fontweight = 'bold')\n",
    "    plt.legend(loc=\"lower right\", frameon=False)\n",
    "    #save fig\n",
    "    plt.savefig(path_roc, transparent=True, dpi=300)\n",
    "    plt.close(\"all\")\n",
    "\n",
    "    \n",
    "    # Below for loop iterates through your models list\n",
    "    for m in models:\n",
    "        model = m['model']\n",
    "        y_pred=model.predict(X) # predict the test data\n",
    "    #Compute Precision and Recall\n",
    "        precision, recall, _ = precision_recall_curve(y, model.predict_proba(X)[:,1])\n",
    "    #Calculate AP\n",
    "        ap = average_precision_score(y, model.predict_proba(X)[:,1])\n",
    "    #Plot\n",
    "        plt.plot(recall, precision, label='%s AP (area = %0.4f)' % (m['label'], ap))\n",
    "    #Makes it pretty!\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Recall (Positive Predictive Value)', fontweight=\"bold\")\n",
    "    plt.ylabel('Precision (True Positive Rate)', fontweight=\"bold\")\n",
    "    plt.title(f'Precision-Recall Curve Test\\nData: {date}, Target:{target}', fontweight=\"bold\")\n",
    "    plt.legend(loc=\"lower left\", frameon=False)\n",
    "    \n",
    "    #save fig\n",
    "    plt.savefig(path_pr, transparent=True, dpi=300)\n",
    "    plt.close(\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One more thing to do is to give a proper name to each plot label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_names = {\n",
    "             'Date_threshold_10': '10% of Course Duration',   \n",
    "             'Date_threshold_25': '25% of Course Duration', \n",
    "             'Date_threshold_33': '33% of Course Duration', \n",
    "             'Date_threshold_50': '50% of Course Duration', \n",
    "             'Date_threshold_100':'100% of Course Duration', \n",
    "            }\n",
    "\n",
    "target_names = {\n",
    "                'exam_fail' : 'At risk - Exam Grade',\n",
    "                'final_fail' : 'At risk - Final Grade', \n",
    "                'exam_gifted' : 'High performer - Exam Grade', \n",
    "                'final_gifted': 'High performer - Final Grade'\n",
    "                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, we try and arrange everything in order to train the models we get for every combination of Date Thresholds and Targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#first, we create dict where we will store results for every date_threshold and target\n",
    "results_normal_models = {}\n",
    "\n",
    "for i in tqdm(normalized_data):\n",
    "    \n",
    "    print(i)\n",
    "    #create a second dict for the date threshold\n",
    "    results_normal_models[i] = {}\n",
    "    \n",
    "    #now, we start working with each instance of target\n",
    "    for k in tqdm(targets):\n",
    "        print(k)\n",
    "        \n",
    "        #start with train test split\n",
    "        X = normalized_data[i][k]\n",
    "        X_train_val, X_test, y_train_val, y_test = train_test_split(X,\n",
    "                                                  y[k],\n",
    "                                                  test_size = 0.20,\n",
    "                                                  random_state = 15,\n",
    "                                                  shuffle=True,\n",
    "                                                  stratify=y)\n",
    "        \n",
    "        #runs each Repeated (10) 10-fold Cross-Validation in all tested models by calling function avg_score and prints resutls with multiple metrics for each\n",
    "        method_cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=replicas, random_state = 15)\n",
    "        \n",
    "        results_Dummy = avg_score(method_cv, X_train_val, y_train_val, 'Baseline - Majority Class')\n",
    "        results_KNN = avg_score(method_cv, X_train_val, y_train_val, 'KNN')\n",
    "        results_LR = avg_score(method_cv, X_train_val, y_train_val, 'LR')\n",
    "        results_NB = avg_score(method_cv, X_train_val, y_train_val, 'NB')\n",
    "        results_BNB = avg_score(method_cv, X_train_val, y_train_val, 'BNB')\n",
    "        results_NN = avg_score(method_cv, X_train_val, y_train_val, 'MLP')\n",
    "        results_CART_DT = avg_score(method_cv, X_train_val, y_train_val, 'CART DT')\n",
    "        results_J48_DT = avg_score(method_cv, X_train_val, y_train_val, 'J48 DT')\n",
    "        resultsSVM = avg_score(method_cv, X_train_val, y_train_val, 'SVM')\n",
    "        \n",
    "        results_models = [results_Dummy, results_KNN, results_LR, results_NB, results_BNB, results_NN, results_CART_DT, results_J48_DT, resultsSVM]\n",
    "\n",
    "        f1micro_train = []\n",
    "        f1micro_val = []\n",
    "        f1micro_test = []\n",
    "\n",
    "        precision_train = []\n",
    "        precision_val = []\n",
    "        precision_test = []\n",
    "\n",
    "        recall_train = []\n",
    "        recall_val = []\n",
    "        recall_test = []\n",
    "\n",
    "        auc_train = []\n",
    "        auc_val = []\n",
    "        auc_test = []\n",
    "        \n",
    "        times = []\n",
    "\n",
    "        #organizes data for futher plotting\n",
    "        for j, model in enumerate(results_models):\n",
    "    \n",
    "            f1micro_train.append(results_models[j][1])\n",
    "            f1micro_val.append(results_models[j][2])\n",
    "            f1micro_test.append(results_models[j][3])\n",
    "    \n",
    "            precision_train.append(results_models[j][4])\n",
    "            precision_val.append(results_models[j][5])\n",
    "            precision_test.append(results_models[j][6])\n",
    "    \n",
    "            recall_train.append(results_models[j][7])\n",
    "            recall_val.append(results_models[j][8])\n",
    "            recall_test.append(results_models[j][9])\n",
    "            \n",
    "            auc_train.append(results_models[j][10])\n",
    "            auc_val.append(results_models[j][11])\n",
    "            auc_test.append(results_models[j][12])\n",
    "            \n",
    "            times.append(results_models[j][0])\n",
    "    \n",
    "        result = [f1micro_train, f1micro_val, f1micro_test, precision_train, precision_val, precision_test, recall_train, recall_val, recall_test, auc_train, auc_val, auc_test, times]\n",
    "\n",
    "        results_normal_models[i][k] = pd.DataFrame(result, index = ['Train Accuracy (F1 Score micro)', 'Validation Accuracy (F1 Score micro)', 'Test Accuracy (F1 Score micro)', 'Precision Train', 'Precision Validation', 'Precision Test', 'Recall Train', 'Recall Validation', 'Recall Test', \n",
    "                                                                    'AUC - Train', 'AUC - Validation', 'AUC - Test', 'Time'],  \n",
    "                                                   columns = ['Baseline - Majority Class', 'KNN', 'LR', 'NB', 'BNB', 'NN', 'CART DT', 'J48 DT', 'SVM'])\n",
    "            \n",
    "        #setting up paths for plots\n",
    "        path_bar = f'../Images/IMS/Non temporal models/{i}/normal_no_assign_results_bar_{k}_SMOTE.png'\n",
    "        path_pr = f'../Images/IMS/Non temporal models/{i}/normal_no_assign_precision_recall_{k}_SMOTE.png'\n",
    "        path_roc = f'../Images/IMS/Non temporal models/{i}/normal_no_assign_roc_{k}_SMOTE.png'\n",
    "        \n",
    "        #get bar graphs\n",
    "        models = ['Baseline - Majority Class', 'KNN', 'LR', 'NB', 'BNB', 'MLP', 'CART DT', 'J48 DT', 'SVM']\n",
    "        plt_bar(models, f1micro_train, f1micro_val, f1micro_test, path_bar, date_names[i], target_names[k])\n",
    "        \n",
    "        #get roc and precision recall curves\n",
    "        # Add models to list of models to incorporte in ROC curve\n",
    "        models = [{'label': 'Majority Class', 'model': run_model('Baseline - Majority Class', X_train_val, y_train_val),},\n",
    "            {'label': 'KNN', 'model': run_model('KNN', X_train_val, y_train_val),},\n",
    "          {'label': 'LR', 'model': run_model('LR', X_train_val, y_train_val),},\n",
    "          {'label': 'NB','model': run_model('NB', X_train_val, y_train_val),},\n",
    "          {'label': 'BNB', 'model': run_model('BNB', X_train_val, y_train_val),},\n",
    "          {'label': 'MLP', 'model': run_model('MLP', X_train_val, y_train_val),},\n",
    "          {'label': 'CART DT', 'model': run_model('CART DT', X_train_val, y_train_val),},\n",
    "          {'label': 'J48 DT', 'model': run_model('J48 DT', X_train_val, y_train_val),},      ] \n",
    "            #SVM not included coz there's no probs!\n",
    "    \n",
    "        plot_roc_pr(models, X_test, y_test, path_roc, path_pr, date_names[i], target_names[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_normal_models[i][k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas.io.parsers import ExcelWriter\n",
    "for i in tqdm(results_normal_models.keys()):\n",
    "    with pd.ExcelWriter(f\"../Data/Modeling Stage/Results/IMS/Non temporal models/simple_models_no_assign_results_{i}_{replicas}_replicas_SMOTE.xlsx\") as writer:  \n",
    "    #saving file for setor comercial\n",
    "    \n",
    "        for sheet in targets:\n",
    "            results_normal_models[i][sheet].to_excel(writer, sheet_name=str(sheet))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We repeat the process for ensemble classifiers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first, we create dict where we will store results for every date_threshold and target\n",
    "results_ensemble_models = {}\n",
    "\n",
    "for i in tqdm(normalized_data):\n",
    "    \n",
    "    print(i)\n",
    "    #create a second dict for the date threshold\n",
    "    results_ensemble_models[i] = {}\n",
    "    \n",
    "    #now, we start working with each instance of target\n",
    "    for k in tqdm(targets):\n",
    "        print(k)\n",
    "        \n",
    "        #start with train test split\n",
    "        X = normalized_data[i][k]\n",
    "        X_train_val, X_test, y_train_val, y_test = train_test_split(X,\n",
    "                                                  y[k],\n",
    "                                                  test_size = 0.20,\n",
    "                                                  random_state = 15,\n",
    "                                                  shuffle=True,\n",
    "                                                  stratify=y)\n",
    "        \n",
    "        method_cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=replicas, random_state = 15)\n",
    "        \n",
    "        results_Dummy = avg_score(method_cv, X_train_val, y_train_val, 'Baseline - Majority Class')\n",
    "        results_RF = avg_score(method_cv, X_train_val, y_train_val, 'RF')\n",
    "        results_AdaBoost = avg_score(method_cv, X_train_val, y_train_val, 'AdaBoost')\n",
    "        results_GBoost = avg_score(method_cv, X_train_val, y_train_val, 'GBoost')\n",
    "        results_Xtra = avg_score(method_cv, X_train_val, y_train_val, 'ExtraTree')\n",
    "        \n",
    "        results_models = [results_Dummy, results_RF, results_AdaBoost, results_GBoost, results_Xtra]\n",
    "        \n",
    "        f1micro_train = []\n",
    "        f1micro_val = []\n",
    "        f1micro_test = []\n",
    "\n",
    "        precision_train = []\n",
    "        precision_val = []\n",
    "        precision_test = []\n",
    "\n",
    "        recall_train = []\n",
    "        recall_val = []\n",
    "        recall_test = []\n",
    "\n",
    "        auc_train = []\n",
    "        auc_val = []\n",
    "        auc_test = []\n",
    "        \n",
    "        times = []\n",
    "\n",
    "        #organizes data for futher plotting\n",
    "        for j, model in enumerate(results_models):\n",
    "    \n",
    "            f1micro_train.append(results_models[j][1])\n",
    "            f1micro_val.append(results_models[j][2])\n",
    "            f1micro_test.append(results_models[j][3])\n",
    "    \n",
    "            precision_train.append(results_models[j][4])\n",
    "            precision_val.append(results_models[j][5])\n",
    "            precision_test.append(results_models[j][6])\n",
    "    \n",
    "            recall_train.append(results_models[j][7])\n",
    "            recall_val.append(results_models[j][8])\n",
    "            recall_test.append(results_models[j][9])\n",
    "            \n",
    "            auc_train.append(results_models[j][10])\n",
    "            auc_val.append(results_models[j][11])\n",
    "            auc_test.append(results_models[j][12])\n",
    "            \n",
    "            times.append(results_models[j][0])\n",
    "    \n",
    "        result = [f1micro_train, f1micro_val, f1micro_test, precision_train, precision_val, precision_test, recall_train, recall_val, recall_test, auc_train, auc_val, auc_test, times]\n",
    "\n",
    "        results_normal_models[i][k] = pd.DataFrame(result, index = ['Train Accuracy (F1 Score micro)', 'Validation Accuracy (F1 Score micro)', 'Test Accuracy (F1 Score micro)', 'Precision Train', 'Precision Validation', 'Precision Test', 'Recall Train', 'Recall Validation', 'Recall Test', \n",
    "                                                                    'AUC - Train', 'AUC - Validation', 'AUC - Test', 'Time'],  \n",
    "                                                     columns = ['Baseline - Majority Class', 'RF', 'AdaBoost', 'GBoost', 'ExtraTree'])\n",
    "            \n",
    "        #bar\n",
    "        #setting up paths for plots\n",
    "        path_bar = f'../Images/IMS/Non temporal models/{i}/ensemble_no_assign_results_bar_{k}_SMOTE.png'\n",
    "        path_pr = f'../Images/IMS/Non temporal models/{i}/ensemble_no_assign_precision_recall_{k}_SMOTE.png'\n",
    "        path_roc = f'../Images/IMS/Non temporal models/{i}/ensemble_no_assign_roc_{k}_SMOTE.png'\n",
    "        \n",
    "        #get bar graphs\n",
    "        models = ['Baseline - Majority Class', 'RF', 'AdaBoost', 'GBoost', 'ExtraTree']\n",
    "        plt_bar(models, f1micro_train, f1micro_val, f1micro_test, path_bar, date_names[i], target_names[k])\n",
    "        \n",
    "        # Add models to list of models to incorporte in ROC curve\n",
    "        models = [{'label': 'Majority Class', 'model': run_model('Baseline - Majority Class', X_train_val, y_train_val),},\n",
    "          {'label': 'RF', 'model': run_model('RF', X_train_val, y_train_val),},\n",
    "          {'label': 'AdaBoost', 'model': run_model('AdaBoost', X_train_val, y_train_val),},\n",
    "          {'label': 'GBoost', 'model': run_model('GBoost', X_train_val, y_train_val),},\n",
    "          {'label': 'ExtraTree', 'model': run_model('ExtraTree', X_train_val, y_train_val),}]\n",
    "\n",
    "\n",
    "        plot_roc_pr(models, X_test, y_test, path_roc, path_pr, date_names[i], target_names[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pandas.io.parsers import ExcelWriter\n",
    "for i in tqdm(results_ensemble_models.keys()):\n",
    "    with pd.ExcelWriter(f\"../Data/Modeling Stage/Results/IMS/Non temporal models/ensemble_models_no_assign_results_{i}_{replicas}_replicas_SMOTE.xlsx\") as writer:  \n",
    "    \n",
    "    #saving file for setor comercial\n",
    "        for sheet in targets:\n",
    "            results_ensemble_models[i][sheet].to_excel(writer, sheet_name=str(sheet))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
