{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84eda90e",
   "metadata": {},
   "source": [
    "### Thesis notebook 4.3. - NOVA IMS\n",
    "\n",
    "#### LSTM - Temporal data representation\n",
    "\n",
    "In this notebook, we will finally start our application of temporal representation using LSTMs and bi-directional LSTMs.\n",
    "The argument for the usage of Deep Learning stems from the fact that sequences themselves encode information that can be extracted using Recurrent Neural Networks and, more specifically, Long Short Term Memory Units.\n",
    "\n",
    "#### First Step: Setup a PyTorch environment that enables the use of GPU for training. \n",
    "\n",
    "The following cell wll confirm that the GPU will be the default device to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f27844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pycuda.driver as cuda\n",
    "\n",
    "cuda.init()\n",
    "## Get Id of default device\n",
    "torch.cuda.current_device()\n",
    "# 0\n",
    "cuda.Device(0).name() # '0' is the id of your GPU\n",
    "\n",
    "#set all tensors to gpu\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d95429e",
   "metadata": {},
   "source": [
    "#### Second Step: Import the relevant packages and declare global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6c2d97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary modules/libraries\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "#tqdm to monitor progress\n",
    "from tqdm.notebook import tqdm, trange\n",
    "tqdm.pandas(desc=\"Progress\")\n",
    "\n",
    "#time related features\n",
    "from datetime import timedelta\n",
    "from copy import copy, deepcopy\n",
    "\n",
    "#vizualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#imblearn, scalers, kfold and metrics\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, QuantileTransformer,PowerTransformer\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold, RepeatedStratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, recall_score, classification_report, average_precision_score, precision_recall_curve\n",
    "\n",
    "#import torch related\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable \n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "\n",
    "#and optimizer of learning rate\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "#import pytorch modules\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6c3f1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variables that may come in handy\n",
    "#course threshold sets the % duration that will be considered (1 = 100%)\n",
    "duration_threshold = [0.1, 0.25, 0.33, 0.5, 1]\n",
    "\n",
    "#colors for vizualizations\n",
    "nova_ims_colors = ['#BFD72F', '#5C666C']\n",
    "\n",
    "#standard color for student aggregates\n",
    "student_color = '#474838'\n",
    "\n",
    "#standard color for course aggragates\n",
    "course_color = '#1B3D2F'\n",
    "\n",
    "#standard continuous colormap\n",
    "standard_cmap = 'viridis_r'\n",
    "\n",
    "#Function designed to deal with multiindex and flatten it\n",
    "def flattenHierarchicalCol(col,sep = '_'):\n",
    "    '''converts multiindex columns into single index columns while retaining the hierarchical components'''\n",
    "    if not type(col) is tuple:\n",
    "        return col\n",
    "    else:\n",
    "        new_col = ''\n",
    "        for leveli,level in enumerate(col):\n",
    "            if not level == '':\n",
    "                if not leveli == 0:\n",
    "                    new_col += sep\n",
    "                new_col += level\n",
    "        return new_col\n",
    "    \n",
    "#number of replicas - number of repeats of stratified k fold - in this case 10\n",
    "replicas = 5\n",
    "\n",
    "#names to display on result figures\n",
    "date_names = {\n",
    "             'Date_threshold_10': '10% of Course Duration',   \n",
    "             'Date_threshold_25': '25% of Course Duration', \n",
    "             'Date_threshold_33': '33% of Course Duration', \n",
    "             'Date_threshold_50': '50% of Course Duration', \n",
    "             'Date_threshold_100':'100% of Course Duration', \n",
    "            }\n",
    "\n",
    "target_names = {\n",
    "                'exam_fail' : 'At risk - Exam Grade',\n",
    "                'final_fail' : 'At risk - Final Grade', \n",
    "                'exam_gifted' : 'High performer - Exam Grade', \n",
    "                'final_gifted': 'High performer - Final Grade'\n",
    "                }\n",
    "\n",
    "#targets\n",
    "targets = ['exam_fail', 'exam_gifted']\n",
    "temporal_columns = ['0 to 4%', '4 to 8%', '8 to 12%', '12 to 16%', '16 to 20%', '20 to 24%',\n",
    "       '24 to 28%', '28 to 32%', '32 to 36%', '36 to 40%', '40 to 44%',\n",
    "       '44 to 48%', '48 to 52%', '52 to 56%', '56 to 60%', '60 to 64%',\n",
    "       '64 to 68%', '68 to 72%', '72 to 76%', '76 to 80%', '80 to 84%',\n",
    "       '84 to 88%', '88 to 92%', '92 to 96%', '96 to 100%']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c5ddb6",
   "metadata": {},
   "source": [
    "#### Step 3: Import data and take a preliminary look at it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8a23ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports dataframes\n",
    "course_programs = pd.read_excel(\"../Data/Modeling Stage/Nova_IMS_Temporal_Datasets_25_splits.xlsx\", \n",
    "                                dtype = {\n",
    "                                    'course_encoding' : int,\n",
    "                                    'userid' : int},\n",
    "                               sheet_name = None)\n",
    "\n",
    "#save tables \n",
    "student_list = pd.read_csv('../Data/Modeling Stage/Nova_IMS_Filtered_targets.csv', \n",
    "                         dtype = {\n",
    "                                   'course_encoding': int,\n",
    "                                   'userid' : int,\n",
    "                                   })\n",
    "\n",
    "#drop unnamed 0 column\n",
    "for i in course_programs:\n",
    "        \n",
    "    #merge with the targets we calculated on the other \n",
    "    course_programs[i] = course_programs[i].merge(student_list, on = ['course_encoding', 'userid'], how = 'inner')\n",
    "    course_programs[i].drop(['Unnamed: 0', 'exam_mark', 'final_mark'], axis = 1, inplace = True)\n",
    "    \n",
    "    #convert results to object\n",
    "    course_programs[i]['course_encoding'], course_programs[i]['userid'] = course_programs[i]['course_encoding'].astype(object), course_programs[i]['userid'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bc3c84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9296 entries, 0 to 9295\n",
      "Data columns (total 29 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   course_encoding  9296 non-null   object\n",
      " 1   userid           9296 non-null   object\n",
      " 2   0 to 4%          9296 non-null   int64 \n",
      " 3   4 to 8%          9296 non-null   int64 \n",
      " 4   8 to 12%         9296 non-null   int64 \n",
      " 5   12 to 16%        9296 non-null   int64 \n",
      " 6   16 to 20%        9296 non-null   int64 \n",
      " 7   20 to 24%        9296 non-null   int64 \n",
      " 8   24 to 28%        9296 non-null   int64 \n",
      " 9   28 to 32%        9296 non-null   int64 \n",
      " 10  32 to 36%        9296 non-null   int64 \n",
      " 11  36 to 40%        9296 non-null   int64 \n",
      " 12  40 to 44%        9296 non-null   int64 \n",
      " 13  44 to 48%        9296 non-null   int64 \n",
      " 14  48 to 52%        9296 non-null   int64 \n",
      " 15  52 to 56%        9296 non-null   int64 \n",
      " 16  56 to 60%        9296 non-null   int64 \n",
      " 17  60 to 64%        9296 non-null   int64 \n",
      " 18  64 to 68%        9296 non-null   int64 \n",
      " 19  68 to 72%        9296 non-null   int64 \n",
      " 20  72 to 76%        9296 non-null   int64 \n",
      " 21  76 to 80%        9296 non-null   int64 \n",
      " 22  80 to 84%        9296 non-null   int64 \n",
      " 23  84 to 88%        9296 non-null   int64 \n",
      " 24  88 to 92%        9296 non-null   int64 \n",
      " 25  92 to 96%        9296 non-null   int64 \n",
      " 26  96 to 100%       9296 non-null   int64 \n",
      " 27  exam_fail        9296 non-null   int64 \n",
      " 28  exam_gifted      9296 non-null   int64 \n",
      "dtypes: int64(27), object(2)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "course_programs['Date_threshold_100'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4a751ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_encoding</th>\n",
       "      <th>userid</th>\n",
       "      <th>0 to 4%</th>\n",
       "      <th>4 to 8%</th>\n",
       "      <th>8 to 12%</th>\n",
       "      <th>12 to 16%</th>\n",
       "      <th>16 to 20%</th>\n",
       "      <th>20 to 24%</th>\n",
       "      <th>24 to 28%</th>\n",
       "      <th>28 to 32%</th>\n",
       "      <th>...</th>\n",
       "      <th>68 to 72%</th>\n",
       "      <th>72 to 76%</th>\n",
       "      <th>76 to 80%</th>\n",
       "      <th>80 to 84%</th>\n",
       "      <th>84 to 88%</th>\n",
       "      <th>88 to 92%</th>\n",
       "      <th>92 to 96%</th>\n",
       "      <th>96 to 100%</th>\n",
       "      <th>exam_fail</th>\n",
       "      <th>exam_gifted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9296.0</td>\n",
       "      <td>9296.0</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.0</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>138.0</td>\n",
       "      <td>1590.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>150.0</td>\n",
       "      <td>3178.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>178.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.081863</td>\n",
       "      <td>8.307874</td>\n",
       "      <td>10.752797</td>\n",
       "      <td>11.193739</td>\n",
       "      <td>10.127797</td>\n",
       "      <td>8.966652</td>\n",
       "      <td>10.545396</td>\n",
       "      <td>11.445245</td>\n",
       "      <td>...</td>\n",
       "      <td>11.379410</td>\n",
       "      <td>9.643718</td>\n",
       "      <td>11.718051</td>\n",
       "      <td>13.136403</td>\n",
       "      <td>22.827883</td>\n",
       "      <td>27.341007</td>\n",
       "      <td>12.599613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.201377</td>\n",
       "      <td>0.276893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.526351</td>\n",
       "      <td>13.580025</td>\n",
       "      <td>13.626754</td>\n",
       "      <td>16.400023</td>\n",
       "      <td>14.291254</td>\n",
       "      <td>12.180177</td>\n",
       "      <td>13.507892</td>\n",
       "      <td>15.932226</td>\n",
       "      <td>...</td>\n",
       "      <td>18.633052</td>\n",
       "      <td>22.561365</td>\n",
       "      <td>28.186874</td>\n",
       "      <td>36.690068</td>\n",
       "      <td>47.158607</td>\n",
       "      <td>54.963959</td>\n",
       "      <td>35.194597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.401051</td>\n",
       "      <td>0.447487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>619.000000</td>\n",
       "      <td>315.000000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>320.000000</td>\n",
       "      <td>947.000000</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>1091.000000</td>\n",
       "      <td>604.000000</td>\n",
       "      <td>747.000000</td>\n",
       "      <td>407.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        course_encoding  userid      0 to 4%      4 to 8%     8 to 12%  \\\n",
       "count            9296.0  9296.0  9296.000000  9296.000000  9296.000000   \n",
       "unique            138.0  1590.0          NaN          NaN          NaN   \n",
       "top               150.0  3178.0          NaN          NaN          NaN   \n",
       "freq              178.0    14.0          NaN          NaN          NaN   \n",
       "mean                NaN     NaN     1.081863     8.307874    10.752797   \n",
       "std                 NaN     NaN     3.526351    13.580025    13.626754   \n",
       "min                 NaN     NaN     0.000000     0.000000     0.000000   \n",
       "25%                 NaN     NaN     0.000000     0.000000     1.000000   \n",
       "50%                 NaN     NaN     0.000000     2.000000     7.000000   \n",
       "75%                 NaN     NaN     1.000000    12.000000    15.000000   \n",
       "max                 NaN     NaN    66.000000   269.000000   360.000000   \n",
       "\n",
       "          12 to 16%    16 to 20%    20 to 24%    24 to 28%    28 to 32%  ...  \\\n",
       "count   9296.000000  9296.000000  9296.000000  9296.000000  9296.000000  ...   \n",
       "unique          NaN          NaN          NaN          NaN          NaN  ...   \n",
       "top             NaN          NaN          NaN          NaN          NaN  ...   \n",
       "freq            NaN          NaN          NaN          NaN          NaN  ...   \n",
       "mean      11.193739    10.127797     8.966652    10.545396    11.445245  ...   \n",
       "std       16.400023    14.291254    12.180177    13.507892    15.932226  ...   \n",
       "min        0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%        2.000000     2.000000     1.000000     2.000000     3.000000  ...   \n",
       "50%        7.000000     6.000000     5.000000     7.000000     7.000000  ...   \n",
       "75%       15.000000    13.000000    13.000000    14.000000    14.000000  ...   \n",
       "max      619.000000   315.000000   248.000000   268.000000   237.000000  ...   \n",
       "\n",
       "          68 to 72%    72 to 76%    76 to 80%    80 to 84%    84 to 88%  \\\n",
       "count   9296.000000  9296.000000  9296.000000  9296.000000  9296.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      11.379410     9.643718    11.718051    13.136403    22.827883   \n",
       "std       18.633052    22.561365    28.186874    36.690068    47.158607   \n",
       "min        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%        5.000000     3.000000     2.000000     2.000000     4.000000   \n",
       "75%       14.000000    11.000000    10.000000    10.000000    23.000000   \n",
       "max      320.000000   947.000000   614.000000  1091.000000   604.000000   \n",
       "\n",
       "          88 to 92%    92 to 96%  96 to 100%    exam_fail  exam_gifted  \n",
       "count   9296.000000  9296.000000      9296.0  9296.000000  9296.000000  \n",
       "unique          NaN          NaN         NaN          NaN          NaN  \n",
       "top             NaN          NaN         NaN          NaN          NaN  \n",
       "freq            NaN          NaN         NaN          NaN          NaN  \n",
       "mean      27.341007    12.599613         0.0     0.201377     0.276893  \n",
       "std       54.963959    35.194597         0.0     0.401051     0.447487  \n",
       "min        0.000000     0.000000         0.0     0.000000     0.000000  \n",
       "25%        0.000000     0.000000         0.0     0.000000     0.000000  \n",
       "50%        2.000000     0.000000         0.0     0.000000     0.000000  \n",
       "75%       27.000000     5.000000         0.0     0.000000     1.000000  \n",
       "max      747.000000   407.000000         0.0     1.000000     1.000000  \n",
       "\n",
       "[11 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "course_programs['Date_threshold_100'].describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3291817",
   "metadata": {},
   "source": [
    "In our first attempt, we will use the absolute number of clicks made by each student - scaled using standard scaler. \n",
    "Therefore, we can start by immediately placing our course encoding/userid pairings into the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be722ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(train, test, scaler):\n",
    "    \n",
    "    if scaler == 'MinMax':\n",
    "        pt = MinMaxScaler()\n",
    "    elif scaler == 'Standard':\n",
    "        pt = StandardScaler()\n",
    "    elif scaler == 'Robust':\n",
    "        pt = RobustScaler()\n",
    "    elif scaler == 'Quantile':\n",
    "        pt = QuantileTransformer()\n",
    "    else:\n",
    "        pt = PowerTransformer(method='yeo-johnson')\n",
    "    \n",
    "    data_train = pt.fit_transform(train)\n",
    "    data_test = pt.transform(test)\n",
    "    # convert the array back to a dataframe\n",
    "    normalized_train = pd.DataFrame(data_train,columns=train.columns)\n",
    "    normalized_test = pd.DataFrame(data_test,columns=test.columns)\n",
    "        \n",
    "    return normalized_train, normalized_test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4d5475",
   "metadata": {},
   "source": [
    "#### Implementing Cross-Validation with Deep Learning Model\n",
    "\n",
    "**1. Create the Deep Learning Model**\n",
    "\n",
    "In this instance, we will follow-up with on the approach used in Chen & Cui - CrossEntropyLoss with applied over a softmax layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a16bd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Uni(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(LSTM_Uni, self).__init__()\n",
    "        self.num_classes = num_classes #number of classes\n",
    "        self.num_layers = num_layers #number of layers\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size = hidden_size #hidden state\n",
    "        self.seq_length = seq_length #sequence length\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first = True) #lstm\n",
    "        \n",
    "        self.dropout = nn.Dropout(p = 0.5)\n",
    "    \n",
    "        self.fc = nn.Linear(self.hidden_size, num_classes) #fully connected last layer\n",
    "\n",
    "    def forward(self,x):\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) #hidden state\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) #internal state\n",
    "        \n",
    "        #Xavier_init for both H_0 and C_0\n",
    "        torch.nn.init.xavier_normal_(h_0)\n",
    "        torch.nn.init.xavier_normal_(c_0)\n",
    "        \n",
    "        # Propagate input through LSTM\n",
    "        lstm_out, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
    "        last_output = hn.view(-1, self.hidden_size) #reshaping the data for Dense layer next\n",
    "        \n",
    "        #we are interested in only keeping the last output\n",
    "        drop_out = self.dropout(last_output)\n",
    "        pre_softmax = self.fc(drop_out) #Final Output - dense\n",
    "        return pre_softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c356bd",
   "metadata": {},
   "source": [
    "**2. Define the train and validation Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25b29a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model,dataloader,loss_fn,optimizer):\n",
    "    \n",
    "    train_loss,train_correct=0.0,0 \n",
    "    model.train()\n",
    "    for X, labels in dataloader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)\n",
    "        loss = loss_fn(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * X.size(0)\n",
    "        scores, predictions = torch.max(F.log_softmax(output.data), 1)\n",
    "        train_correct += (predictions == labels).sum().item()\n",
    "        \n",
    "    return train_loss,train_correct\n",
    "  \n",
    "def valid_epoch(model,dataloader,loss_fn):\n",
    "    valid_loss, val_correct = 0.0, 0\n",
    "    targets = []\n",
    "    y_pred = []\n",
    "    probability_1 = []\n",
    "    \n",
    "    model.eval()\n",
    "    for X, labels in dataloader:\n",
    "\n",
    "        output = model(X)\n",
    "        loss=loss_fn(output,labels)\n",
    "        valid_loss+=loss.item()*X.size(0)\n",
    "        probability_1.append(F.softmax(output.data)[:,1])\n",
    "        predictions = torch.argmax(output, dim=1)\n",
    "        val_correct+=(predictions == labels).sum().item()\n",
    "        targets.append(labels)\n",
    "        y_pred.append(predictions)\n",
    "    \n",
    "    #concat all results\n",
    "    targets = torch.cat(targets).data.cpu().numpy()\n",
    "    y_pred = torch.cat(y_pred).data.cpu().numpy()\n",
    "    probability_1 = torch.cat(probability_1).data.cpu().numpy()\n",
    "    \n",
    "    #calculate precision, recall and AUC score\n",
    "    \n",
    "    precision = precision_score(targets, y_pred)\n",
    "    recall = recall_score(targets, y_pred)\n",
    "    auroc = roc_auc_score(targets, probability_1)\n",
    "    \n",
    "    #return all\n",
    "    return valid_loss,val_correct, precision, recall, auroc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4543fb3",
   "metadata": {},
   "source": [
    "**3. Define main hyperparameters of the model, including splits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcbbef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "num_epochs = 200 #50 epochs\n",
    "learning_rate = 0.01 #0.001 lr\n",
    "input_size = 1 #number of features\n",
    "hidden_size = 60 #number of features in hidden state\n",
    "num_layers = 1 #number of stacked lstm layers\n",
    "\n",
    "#Shape of Output as required for SoftMax Classifier\n",
    "num_classes = 2 #output shape\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "k=10\n",
    "splits= RepeatedStratifiedKFold(n_splits=k, n_repeats=replicas, random_state=15) #kfold of 10 with 30 replicas\n",
    "criterion = nn.CrossEntropyLoss()    # cross-entropy for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20713d9",
   "metadata": {},
   "source": [
    "**4. Make the splits and Start Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "45544589",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94086c4a5c274924aa551635f598e426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date_threshold_25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "304c36a98f3145409bcba447a1041fcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exam_fail\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e083d6e2f6a24feaa030759f9ef3d09e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "083570cf423047f8867e9ac1a857301e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best Accuracy found: 79.84%\n",
      "Epoch: 1\n",
      "Epoch:10/200 AVG Training Loss:0.504 AVG Validation Loss:0.496 AVG Training Acc 79.68 % AVG Validation Acc 79.84 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.486 AVG Validation Loss:0.477 AVG Training Acc 79.87 % AVG Validation Acc 79.84 %\n",
      "New Best Accuracy found: 79.97%\n",
      "Epoch: 22\n",
      "Epoch:30/200 AVG Training Loss:0.482 AVG Validation Loss:0.476 AVG Training Acc 80.08 % AVG Validation Acc 79.84 %\n",
      "Epoch:40/200 AVG Training Loss:0.476 AVG Validation Loss:0.481 AVG Training Acc 80.20 % AVG Validation Acc 79.84 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.472 AVG Validation Loss:0.477 AVG Training Acc 80.01 % AVG Validation Acc 79.84 %\n",
      "Epoch:60/200 AVG Training Loss:0.471 AVG Validation Loss:0.478 AVG Training Acc 80.08 % AVG Validation Acc 79.44 %\n",
      "Epoch:70/200 AVG Training Loss:0.469 AVG Validation Loss:0.480 AVG Training Acc 79.99 % AVG Validation Acc 79.44 %\n",
      "Epoch:80/200 AVG Training Loss:0.469 AVG Validation Loss:0.482 AVG Training Acc 80.20 % AVG Validation Acc 79.17 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.467 AVG Validation Loss:0.482 AVG Training Acc 80.14 % AVG Validation Acc 79.44 %\n",
      "Epoch:100/200 AVG Training Loss:0.466 AVG Validation Loss:0.481 AVG Training Acc 80.26 % AVG Validation Acc 79.30 %\n",
      "Epoch:110/200 AVG Training Loss:0.468 AVG Validation Loss:0.482 AVG Training Acc 80.17 % AVG Validation Acc 79.17 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.466 AVG Validation Loss:0.482 AVG Training Acc 80.39 % AVG Validation Acc 79.30 %\n",
      "Epoch:130/200 AVG Training Loss:0.468 AVG Validation Loss:0.482 AVG Training Acc 80.13 % AVG Validation Acc 79.17 %\n",
      "Epoch:140/200 AVG Training Loss:0.467 AVG Validation Loss:0.481 AVG Training Acc 80.23 % AVG Validation Acc 79.17 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.465 AVG Validation Loss:0.482 AVG Training Acc 80.30 % AVG Validation Acc 79.30 %\n",
      "Epoch:160/200 AVG Training Loss:0.467 AVG Validation Loss:0.482 AVG Training Acc 80.16 % AVG Validation Acc 79.30 %\n",
      "Epoch:170/200 AVG Training Loss:0.467 AVG Validation Loss:0.482 AVG Training Acc 80.36 % AVG Validation Acc 79.44 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.467 AVG Validation Loss:0.481 AVG Training Acc 80.27 % AVG Validation Acc 79.44 %\n",
      "Epoch:190/200 AVG Training Loss:0.467 AVG Validation Loss:0.482 AVG Training Acc 80.41 % AVG Validation Acc 79.44 %\n",
      "Epoch:200/200 AVG Training Loss:0.466 AVG Validation Loss:0.482 AVG Training Acc 80.22 % AVG Validation Acc 79.30 %\n",
      "Split 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e817f7ab9f048a6bdcf20d4f12f7e13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.486 AVG Validation Loss:0.491 AVG Training Acc 79.93 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.477 AVG Validation Loss:0.480 AVG Training Acc 79.96 % AVG Validation Acc 79.84 %\n",
      "Epoch:30/200 AVG Training Loss:0.471 AVG Validation Loss:0.484 AVG Training Acc 80.19 % AVG Validation Acc 79.84 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.454 AVG Validation Loss:0.481 AVG Training Acc 80.60 % AVG Validation Acc 79.70 %\n",
      "Epoch:50/200 AVG Training Loss:0.440 AVG Validation Loss:0.490 AVG Training Acc 80.78 % AVG Validation Acc 78.76 %\n",
      "Epoch:60/200 AVG Training Loss:0.423 AVG Validation Loss:0.493 AVG Training Acc 81.56 % AVG Validation Acc 78.49 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.413 AVG Validation Loss:0.513 AVG Training Acc 81.74 % AVG Validation Acc 78.90 %\n",
      "Epoch:80/200 AVG Training Loss:0.411 AVG Validation Loss:0.514 AVG Training Acc 82.26 % AVG Validation Acc 78.49 %\n",
      "Epoch:90/200 AVG Training Loss:0.406 AVG Validation Loss:0.524 AVG Training Acc 82.08 % AVG Validation Acc 77.69 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.406 AVG Validation Loss:0.521 AVG Training Acc 82.04 % AVG Validation Acc 77.96 %\n",
      "Epoch:110/200 AVG Training Loss:0.405 AVG Validation Loss:0.520 AVG Training Acc 82.13 % AVG Validation Acc 77.96 %\n",
      "Epoch:120/200 AVG Training Loss:0.405 AVG Validation Loss:0.527 AVG Training Acc 82.31 % AVG Validation Acc 77.55 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.407 AVG Validation Loss:0.527 AVG Training Acc 82.20 % AVG Validation Acc 77.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.403 AVG Validation Loss:0.523 AVG Training Acc 82.19 % AVG Validation Acc 77.55 %\n",
      "Epoch:150/200 AVG Training Loss:0.403 AVG Validation Loss:0.526 AVG Training Acc 82.40 % AVG Validation Acc 77.96 %\n",
      "Epoch:160/200 AVG Training Loss:0.405 AVG Validation Loss:0.526 AVG Training Acc 82.44 % AVG Validation Acc 77.96 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.402 AVG Validation Loss:0.530 AVG Training Acc 82.37 % AVG Validation Acc 77.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.404 AVG Validation Loss:0.526 AVG Training Acc 82.29 % AVG Validation Acc 77.82 %\n",
      "Epoch:190/200 AVG Training Loss:0.404 AVG Validation Loss:0.526 AVG Training Acc 82.34 % AVG Validation Acc 78.09 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.402 AVG Validation Loss:0.528 AVG Training Acc 82.38 % AVG Validation Acc 78.23 %\n",
      "Split 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de1693f144fc4c91ac781bf5e4ebb644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.488 AVG Validation Loss:0.481 AVG Training Acc 79.78 % AVG Validation Acc 80.11 %\n",
      "New Best Accuracy found: 80.11%\n",
      "Epoch: 10\n",
      "New Best Accuracy found: 80.24%\n",
      "Epoch: 12\n",
      "Epoch:20/200 AVG Training Loss:0.481 AVG Validation Loss:0.471 AVG Training Acc 79.83 % AVG Validation Acc 80.24 %\n",
      "New Best Accuracy found: 80.38%\n",
      "Epoch: 28\n",
      "New Best Accuracy found: 80.51%\n",
      "Epoch: 29\n",
      "Epoch:30/200 AVG Training Loss:0.466 AVG Validation Loss:0.468 AVG Training Acc 80.10 % AVG Validation Acc 80.51 %\n",
      "Epoch:40/200 AVG Training Loss:0.454 AVG Validation Loss:0.472 AVG Training Acc 80.42 % AVG Validation Acc 79.97 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.424 AVG Validation Loss:0.487 AVG Training Acc 81.10 % AVG Validation Acc 79.17 %\n",
      "Epoch:60/200 AVG Training Loss:0.400 AVG Validation Loss:0.512 AVG Training Acc 82.14 % AVG Validation Acc 78.23 %\n",
      "Epoch:70/200 AVG Training Loss:0.382 AVG Validation Loss:0.541 AVG Training Acc 83.23 % AVG Validation Acc 77.02 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.371 AVG Validation Loss:0.530 AVG Training Acc 83.49 % AVG Validation Acc 77.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.365 AVG Validation Loss:0.534 AVG Training Acc 83.94 % AVG Validation Acc 77.28 %\n",
      "Epoch:100/200 AVG Training Loss:0.370 AVG Validation Loss:0.540 AVG Training Acc 83.29 % AVG Validation Acc 77.69 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.361 AVG Validation Loss:0.541 AVG Training Acc 83.95 % AVG Validation Acc 77.42 %\n",
      "Epoch:120/200 AVG Training Loss:0.360 AVG Validation Loss:0.538 AVG Training Acc 84.07 % AVG Validation Acc 77.82 %\n",
      "Epoch:130/200 AVG Training Loss:0.365 AVG Validation Loss:0.548 AVG Training Acc 83.41 % AVG Validation Acc 77.02 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.364 AVG Validation Loss:0.531 AVG Training Acc 83.59 % AVG Validation Acc 77.69 %\n",
      "Epoch:150/200 AVG Training Loss:0.362 AVG Validation Loss:0.537 AVG Training Acc 83.86 % AVG Validation Acc 77.69 %\n",
      "Epoch:160/200 AVG Training Loss:0.363 AVG Validation Loss:0.539 AVG Training Acc 83.89 % AVG Validation Acc 77.82 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.363 AVG Validation Loss:0.540 AVG Training Acc 84.16 % AVG Validation Acc 77.55 %\n",
      "Epoch:180/200 AVG Training Loss:0.363 AVG Validation Loss:0.546 AVG Training Acc 83.82 % AVG Validation Acc 77.42 %\n",
      "Epoch:190/200 AVG Training Loss:0.361 AVG Validation Loss:0.551 AVG Training Acc 84.10 % AVG Validation Acc 77.15 %\n",
      "Epoch   198: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.362 AVG Validation Loss:0.540 AVG Training Acc 84.12 % AVG Validation Acc 77.28 %\n",
      "Split 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "189e616e3a784b2f979d740119649f16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.487 AVG Validation Loss:0.489 AVG Training Acc 79.78 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.477 AVG Validation Loss:0.486 AVG Training Acc 79.92 % AVG Validation Acc 80.11 %\n",
      "Epoch:30/200 AVG Training Loss:0.469 AVG Validation Loss:0.492 AVG Training Acc 79.99 % AVG Validation Acc 79.70 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.436 AVG Validation Loss:0.511 AVG Training Acc 80.87 % AVG Validation Acc 78.76 %\n",
      "Epoch:50/200 AVG Training Loss:0.413 AVG Validation Loss:0.556 AVG Training Acc 81.41 % AVG Validation Acc 78.23 %\n",
      "Epoch:60/200 AVG Training Loss:0.396 AVG Validation Loss:0.583 AVG Training Acc 81.78 % AVG Validation Acc 77.96 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.386 AVG Validation Loss:0.650 AVG Training Acc 82.62 % AVG Validation Acc 77.15 %\n",
      "Epoch:80/200 AVG Training Loss:0.372 AVG Validation Loss:0.650 AVG Training Acc 82.58 % AVG Validation Acc 77.42 %\n",
      "Epoch:90/200 AVG Training Loss:0.366 AVG Validation Loss:0.649 AVG Training Acc 83.29 % AVG Validation Acc 77.42 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.365 AVG Validation Loss:0.647 AVG Training Acc 83.59 % AVG Validation Acc 77.82 %\n",
      "Epoch:110/200 AVG Training Loss:0.367 AVG Validation Loss:0.661 AVG Training Acc 83.44 % AVG Validation Acc 77.28 %\n",
      "Epoch:120/200 AVG Training Loss:0.364 AVG Validation Loss:0.661 AVG Training Acc 83.59 % AVG Validation Acc 77.28 %\n",
      "Epoch:130/200 AVG Training Loss:0.365 AVG Validation Loss:0.667 AVG Training Acc 82.99 % AVG Validation Acc 77.69 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.365 AVG Validation Loss:0.663 AVG Training Acc 83.41 % AVG Validation Acc 77.28 %\n",
      "Epoch:150/200 AVG Training Loss:0.365 AVG Validation Loss:0.666 AVG Training Acc 83.32 % AVG Validation Acc 77.28 %\n",
      "Epoch:160/200 AVG Training Loss:0.364 AVG Validation Loss:0.685 AVG Training Acc 83.23 % AVG Validation Acc 77.28 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.366 AVG Validation Loss:0.660 AVG Training Acc 83.11 % AVG Validation Acc 77.15 %\n",
      "Epoch:180/200 AVG Training Loss:0.360 AVG Validation Loss:0.658 AVG Training Acc 83.67 % AVG Validation Acc 77.82 %\n",
      "Epoch:190/200 AVG Training Loss:0.364 AVG Validation Loss:0.658 AVG Training Acc 83.29 % AVG Validation Acc 77.02 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.362 AVG Validation Loss:0.671 AVG Training Acc 83.34 % AVG Validation Acc 77.28 %\n",
      "Split 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f2bae2726d34b32803847907d6f091a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 79.51 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.472 AVG Validation Loss:0.504 AVG Training Acc 79.87 % AVG Validation Acc 79.84 %\n",
      "Epoch:30/200 AVG Training Loss:0.466 AVG Validation Loss:0.500 AVG Training Acc 80.27 % AVG Validation Acc 79.30 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.441 AVG Validation Loss:0.514 AVG Training Acc 80.81 % AVG Validation Acc 79.44 %\n",
      "Epoch:50/200 AVG Training Loss:0.425 AVG Validation Loss:0.523 AVG Training Acc 81.20 % AVG Validation Acc 78.49 %\n",
      "Epoch:60/200 AVG Training Loss:0.406 AVG Validation Loss:0.543 AVG Training Acc 82.20 % AVG Validation Acc 75.81 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.399 AVG Validation Loss:0.547 AVG Training Acc 82.17 % AVG Validation Acc 77.02 %\n",
      "Epoch:80/200 AVG Training Loss:0.398 AVG Validation Loss:0.544 AVG Training Acc 82.11 % AVG Validation Acc 77.42 %\n",
      "Epoch:90/200 AVG Training Loss:0.395 AVG Validation Loss:0.553 AVG Training Acc 82.41 % AVG Validation Acc 77.28 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.392 AVG Validation Loss:0.551 AVG Training Acc 82.77 % AVG Validation Acc 77.55 %\n",
      "Epoch:110/200 AVG Training Loss:0.394 AVG Validation Loss:0.551 AVG Training Acc 82.31 % AVG Validation Acc 77.42 %\n",
      "Epoch:120/200 AVG Training Loss:0.392 AVG Validation Loss:0.553 AVG Training Acc 83.14 % AVG Validation Acc 77.42 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.393 AVG Validation Loss:0.555 AVG Training Acc 82.65 % AVG Validation Acc 76.75 %\n",
      "Epoch:140/200 AVG Training Loss:0.393 AVG Validation Loss:0.547 AVG Training Acc 82.59 % AVG Validation Acc 77.42 %\n",
      "Epoch:150/200 AVG Training Loss:0.389 AVG Validation Loss:0.556 AVG Training Acc 82.99 % AVG Validation Acc 77.55 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.393 AVG Validation Loss:0.552 AVG Training Acc 82.95 % AVG Validation Acc 76.88 %\n",
      "Epoch:170/200 AVG Training Loss:0.392 AVG Validation Loss:0.553 AVG Training Acc 82.34 % AVG Validation Acc 76.88 %\n",
      "Epoch:180/200 AVG Training Loss:0.393 AVG Validation Loss:0.545 AVG Training Acc 82.83 % AVG Validation Acc 77.42 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.393 AVG Validation Loss:0.551 AVG Training Acc 82.59 % AVG Validation Acc 77.28 %\n",
      "Epoch:200/200 AVG Training Loss:0.393 AVG Validation Loss:0.550 AVG Training Acc 82.32 % AVG Validation Acc 77.28 %\n",
      "Split 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea727a137d254f9a8a3850e17933f38a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.483 AVG Validation Loss:0.487 AVG Training Acc 79.77 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.474 AVG Validation Loss:0.494 AVG Training Acc 80.01 % AVG Validation Acc 79.70 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.451 AVG Validation Loss:0.498 AVG Training Acc 80.13 % AVG Validation Acc 80.24 %\n",
      "Epoch:40/200 AVG Training Loss:0.434 AVG Validation Loss:0.523 AVG Training Acc 80.93 % AVG Validation Acc 79.97 %\n",
      "Epoch:50/200 AVG Training Loss:0.419 AVG Validation Loss:0.547 AVG Training Acc 81.32 % AVG Validation Acc 79.03 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.401 AVG Validation Loss:0.587 AVG Training Acc 81.66 % AVG Validation Acc 78.09 %\n",
      "Epoch:70/200 AVG Training Loss:0.395 AVG Validation Loss:0.599 AVG Training Acc 82.13 % AVG Validation Acc 77.55 %\n",
      "Epoch:80/200 AVG Training Loss:0.392 AVG Validation Loss:0.600 AVG Training Acc 82.41 % AVG Validation Acc 77.28 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.391 AVG Validation Loss:0.599 AVG Training Acc 82.25 % AVG Validation Acc 77.55 %\n",
      "Epoch:100/200 AVG Training Loss:0.388 AVG Validation Loss:0.603 AVG Training Acc 82.37 % AVG Validation Acc 77.42 %\n",
      "Epoch:110/200 AVG Training Loss:0.388 AVG Validation Loss:0.609 AVG Training Acc 82.43 % AVG Validation Acc 77.55 %\n",
      "Epoch:120/200 AVG Training Loss:0.391 AVG Validation Loss:0.608 AVG Training Acc 82.35 % AVG Validation Acc 77.55 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.389 AVG Validation Loss:0.607 AVG Training Acc 82.53 % AVG Validation Acc 77.02 %\n",
      "Epoch:140/200 AVG Training Loss:0.391 AVG Validation Loss:0.605 AVG Training Acc 82.50 % AVG Validation Acc 77.15 %\n",
      "Epoch:150/200 AVG Training Loss:0.391 AVG Validation Loss:0.600 AVG Training Acc 82.22 % AVG Validation Acc 77.55 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.389 AVG Validation Loss:0.606 AVG Training Acc 82.61 % AVG Validation Acc 77.69 %\n",
      "Epoch:170/200 AVG Training Loss:0.392 AVG Validation Loss:0.600 AVG Training Acc 82.49 % AVG Validation Acc 77.42 %\n",
      "Epoch:180/200 AVG Training Loss:0.392 AVG Validation Loss:0.606 AVG Training Acc 82.55 % AVG Validation Acc 77.55 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.392 AVG Validation Loss:0.604 AVG Training Acc 82.41 % AVG Validation Acc 77.55 %\n",
      "Epoch:200/200 AVG Training Loss:0.388 AVG Validation Loss:0.602 AVG Training Acc 82.71 % AVG Validation Acc 77.42 %\n",
      "Split 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa6f3451d4824c0ba109539c8598948a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.485 AVG Validation Loss:0.492 AVG Training Acc 79.84 % AVG Validation Acc 79.54 %\n",
      "Epoch:20/200 AVG Training Loss:0.478 AVG Validation Loss:0.483 AVG Training Acc 79.89 % AVG Validation Acc 79.81 %\n",
      "Epoch:30/200 AVG Training Loss:0.468 AVG Validation Loss:0.495 AVG Training Acc 80.08 % AVG Validation Acc 79.27 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.432 AVG Validation Loss:0.499 AVG Training Acc 81.16 % AVG Validation Acc 79.41 %\n",
      "Epoch:50/200 AVG Training Loss:0.416 AVG Validation Loss:0.510 AVG Training Acc 81.94 % AVG Validation Acc 78.06 %\n",
      "Epoch:60/200 AVG Training Loss:0.397 AVG Validation Loss:0.544 AVG Training Acc 82.86 % AVG Validation Acc 77.39 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.385 AVG Validation Loss:0.550 AVG Training Acc 83.51 % AVG Validation Acc 77.39 %\n",
      "Epoch:80/200 AVG Training Loss:0.381 AVG Validation Loss:0.543 AVG Training Acc 83.55 % AVG Validation Acc 77.39 %\n",
      "Epoch:90/200 AVG Training Loss:0.380 AVG Validation Loss:0.542 AVG Training Acc 83.36 % AVG Validation Acc 77.25 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.373 AVG Validation Loss:0.547 AVG Training Acc 84.21 % AVG Validation Acc 76.99 %\n",
      "Epoch:110/200 AVG Training Loss:0.374 AVG Validation Loss:0.547 AVG Training Acc 83.98 % AVG Validation Acc 76.85 %\n",
      "Epoch:120/200 AVG Training Loss:0.372 AVG Validation Loss:0.551 AVG Training Acc 83.43 % AVG Validation Acc 76.45 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.374 AVG Validation Loss:0.545 AVG Training Acc 83.30 % AVG Validation Acc 77.12 %\n",
      "Epoch:140/200 AVG Training Loss:0.376 AVG Validation Loss:0.552 AVG Training Acc 83.51 % AVG Validation Acc 77.12 %\n",
      "Epoch:150/200 AVG Training Loss:0.377 AVG Validation Loss:0.546 AVG Training Acc 83.51 % AVG Validation Acc 77.25 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.374 AVG Validation Loss:0.552 AVG Training Acc 83.82 % AVG Validation Acc 77.12 %\n",
      "Epoch:170/200 AVG Training Loss:0.374 AVG Validation Loss:0.549 AVG Training Acc 83.82 % AVG Validation Acc 76.99 %\n",
      "Epoch:180/200 AVG Training Loss:0.374 AVG Validation Loss:0.546 AVG Training Acc 83.89 % AVG Validation Acc 76.99 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.375 AVG Validation Loss:0.546 AVG Training Acc 83.70 % AVG Validation Acc 76.99 %\n",
      "Epoch:200/200 AVG Training Loss:0.371 AVG Validation Loss:0.550 AVG Training Acc 84.00 % AVG Validation Acc 76.45 %\n",
      "Split 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9397ae79edbd4ffda0bae0b5cdcb0200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.486 AVG Validation Loss:0.478 AVG Training Acc 79.86 % AVG Validation Acc 79.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.480 AVG Validation Loss:0.479 AVG Training Acc 79.98 % AVG Validation Acc 80.08 %\n",
      "New Best Accuracy found: 80.89%\n",
      "Epoch: 29\n",
      "Epoch:30/200 AVG Training Loss:0.470 AVG Validation Loss:0.470 AVG Training Acc 80.20 % AVG Validation Acc 80.35 %\n",
      "Epoch:40/200 AVG Training Loss:0.455 AVG Validation Loss:0.476 AVG Training Acc 80.70 % AVG Validation Acc 80.48 %\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.424 AVG Validation Loss:0.490 AVG Training Acc 81.79 % AVG Validation Acc 80.48 %\n",
      "New Best Accuracy found: 81.02%\n",
      "Epoch: 53\n",
      "New Best Accuracy found: 81.29%\n",
      "Epoch: 54\n",
      "Epoch:60/200 AVG Training Loss:0.412 AVG Validation Loss:0.502 AVG Training Acc 81.94 % AVG Validation Acc 80.75 %\n",
      "Epoch:70/200 AVG Training Loss:0.396 AVG Validation Loss:0.518 AVG Training Acc 82.82 % AVG Validation Acc 80.48 %\n",
      "Epoch    71: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.390 AVG Validation Loss:0.524 AVG Training Acc 83.39 % AVG Validation Acc 81.02 %\n",
      "Epoch:90/200 AVG Training Loss:0.388 AVG Validation Loss:0.529 AVG Training Acc 83.28 % AVG Validation Acc 81.16 %\n",
      "Epoch:100/200 AVG Training Loss:0.385 AVG Validation Loss:0.526 AVG Training Acc 83.25 % AVG Validation Acc 81.02 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.383 AVG Validation Loss:0.525 AVG Training Acc 83.40 % AVG Validation Acc 81.43 %\n",
      "New Best Accuracy found: 81.43%\n",
      "Epoch: 110\n",
      "Epoch:120/200 AVG Training Loss:0.384 AVG Validation Loss:0.527 AVG Training Acc 83.42 % AVG Validation Acc 81.29 %\n",
      "Epoch:130/200 AVG Training Loss:0.383 AVG Validation Loss:0.527 AVG Training Acc 83.48 % AVG Validation Acc 81.02 %\n",
      "Epoch   133: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.386 AVG Validation Loss:0.526 AVG Training Acc 83.28 % AVG Validation Acc 81.02 %\n",
      "New Best Accuracy found: 81.56%\n",
      "Epoch: 148\n",
      "Epoch:150/200 AVG Training Loss:0.382 AVG Validation Loss:0.524 AVG Training Acc 83.42 % AVG Validation Acc 81.16 %\n",
      "Epoch:160/200 AVG Training Loss:0.386 AVG Validation Loss:0.530 AVG Training Acc 83.16 % AVG Validation Acc 81.16 %\n",
      "Epoch   164: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.386 AVG Validation Loss:0.527 AVG Training Acc 83.12 % AVG Validation Acc 81.16 %\n",
      "Epoch:180/200 AVG Training Loss:0.385 AVG Validation Loss:0.535 AVG Training Acc 83.24 % AVG Validation Acc 81.16 %\n",
      "Epoch:190/200 AVG Training Loss:0.384 AVG Validation Loss:0.530 AVG Training Acc 83.43 % AVG Validation Acc 81.02 %\n",
      "Epoch   195: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.384 AVG Validation Loss:0.528 AVG Training Acc 83.33 % AVG Validation Acc 81.02 %\n",
      "Split 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac80fa70dae4bb68418765891fb1b71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.486 AVG Validation Loss:0.487 AVG Training Acc 79.75 % AVG Validation Acc 79.95 %\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.471 AVG Validation Loss:0.487 AVG Training Acc 79.99 % AVG Validation Acc 78.87 %\n",
      "Epoch:30/200 AVG Training Loss:0.461 AVG Validation Loss:0.486 AVG Training Acc 80.38 % AVG Validation Acc 79.41 %\n",
      "Epoch:40/200 AVG Training Loss:0.451 AVG Validation Loss:0.493 AVG Training Acc 80.73 % AVG Validation Acc 78.47 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.440 AVG Validation Loss:0.500 AVG Training Acc 81.44 % AVG Validation Acc 78.73 %\n",
      "Epoch:60/200 AVG Training Loss:0.439 AVG Validation Loss:0.502 AVG Training Acc 81.46 % AVG Validation Acc 78.87 %\n",
      "Epoch:70/200 AVG Training Loss:0.435 AVG Validation Loss:0.504 AVG Training Acc 81.70 % AVG Validation Acc 78.60 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.434 AVG Validation Loss:0.505 AVG Training Acc 81.65 % AVG Validation Acc 78.60 %\n",
      "Epoch:90/200 AVG Training Loss:0.433 AVG Validation Loss:0.505 AVG Training Acc 81.53 % AVG Validation Acc 78.60 %\n",
      "Epoch:100/200 AVG Training Loss:0.434 AVG Validation Loss:0.505 AVG Training Acc 81.82 % AVG Validation Acc 78.60 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.433 AVG Validation Loss:0.507 AVG Training Acc 81.67 % AVG Validation Acc 78.47 %\n",
      "Epoch:120/200 AVG Training Loss:0.432 AVG Validation Loss:0.505 AVG Training Acc 81.50 % AVG Validation Acc 78.33 %\n",
      "Epoch:130/200 AVG Training Loss:0.432 AVG Validation Loss:0.506 AVG Training Acc 81.62 % AVG Validation Acc 78.47 %\n",
      "Epoch:140/200 AVG Training Loss:0.432 AVG Validation Loss:0.506 AVG Training Acc 81.68 % AVG Validation Acc 78.47 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.433 AVG Validation Loss:0.504 AVG Training Acc 81.52 % AVG Validation Acc 78.47 %\n",
      "Epoch:160/200 AVG Training Loss:0.433 AVG Validation Loss:0.506 AVG Training Acc 81.61 % AVG Validation Acc 78.33 %\n",
      "Epoch:170/200 AVG Training Loss:0.432 AVG Validation Loss:0.506 AVG Training Acc 81.94 % AVG Validation Acc 78.47 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.433 AVG Validation Loss:0.505 AVG Training Acc 81.71 % AVG Validation Acc 78.47 %\n",
      "Epoch:190/200 AVG Training Loss:0.433 AVG Validation Loss:0.506 AVG Training Acc 81.68 % AVG Validation Acc 78.47 %\n",
      "Epoch:200/200 AVG Training Loss:0.432 AVG Validation Loss:0.505 AVG Training Acc 81.76 % AVG Validation Acc 78.47 %\n",
      "Split 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d76b4a806d247548aea8079c105a88b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 79.81 % AVG Validation Acc 79.81 %\n",
      "Epoch:20/200 AVG Training Loss:0.481 AVG Validation Loss:0.486 AVG Training Acc 79.93 % AVG Validation Acc 79.81 %\n",
      "Epoch:30/200 AVG Training Loss:0.467 AVG Validation Loss:0.492 AVG Training Acc 80.20 % AVG Validation Acc 79.95 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.434 AVG Validation Loss:0.497 AVG Training Acc 81.08 % AVG Validation Acc 79.95 %\n",
      "Epoch:50/200 AVG Training Loss:0.412 AVG Validation Loss:0.512 AVG Training Acc 81.53 % AVG Validation Acc 79.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.398 AVG Validation Loss:0.531 AVG Training Acc 82.40 % AVG Validation Acc 78.60 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.388 AVG Validation Loss:0.532 AVG Training Acc 82.95 % AVG Validation Acc 78.06 %\n",
      "Epoch:80/200 AVG Training Loss:0.382 AVG Validation Loss:0.548 AVG Training Acc 83.09 % AVG Validation Acc 78.06 %\n",
      "Epoch:90/200 AVG Training Loss:0.376 AVG Validation Loss:0.543 AVG Training Acc 83.51 % AVG Validation Acc 78.20 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.381 AVG Validation Loss:0.544 AVG Training Acc 83.03 % AVG Validation Acc 77.66 %\n",
      "Epoch:110/200 AVG Training Loss:0.377 AVG Validation Loss:0.557 AVG Training Acc 83.21 % AVG Validation Acc 77.39 %\n",
      "Epoch:120/200 AVG Training Loss:0.376 AVG Validation Loss:0.552 AVG Training Acc 83.39 % AVG Validation Acc 77.66 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.376 AVG Validation Loss:0.552 AVG Training Acc 83.28 % AVG Validation Acc 77.66 %\n",
      "Epoch:140/200 AVG Training Loss:0.374 AVG Validation Loss:0.553 AVG Training Acc 83.27 % AVG Validation Acc 77.66 %\n",
      "Epoch:150/200 AVG Training Loss:0.379 AVG Validation Loss:0.551 AVG Training Acc 83.30 % AVG Validation Acc 77.25 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.376 AVG Validation Loss:0.551 AVG Training Acc 83.10 % AVG Validation Acc 77.25 %\n",
      "Epoch:170/200 AVG Training Loss:0.377 AVG Validation Loss:0.552 AVG Training Acc 83.45 % AVG Validation Acc 77.79 %\n",
      "Epoch:180/200 AVG Training Loss:0.377 AVG Validation Loss:0.548 AVG Training Acc 83.42 % AVG Validation Acc 77.93 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.377 AVG Validation Loss:0.558 AVG Training Acc 83.25 % AVG Validation Acc 77.12 %\n",
      "Epoch:200/200 AVG Training Loss:0.377 AVG Validation Loss:0.553 AVG Training Acc 83.54 % AVG Validation Acc 77.79 %\n",
      "Split 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99c6983fe8d1490990d209e0490b45de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.485 AVG Validation Loss:0.490 AVG Training Acc 79.99 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.474 AVG Validation Loss:0.479 AVG Training Acc 80.11 % AVG Validation Acc 79.84 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.450 AVG Validation Loss:0.481 AVG Training Acc 80.86 % AVG Validation Acc 79.44 %\n",
      "Epoch:40/200 AVG Training Loss:0.439 AVG Validation Loss:0.488 AVG Training Acc 81.50 % AVG Validation Acc 78.90 %\n",
      "Epoch:50/200 AVG Training Loss:0.427 AVG Validation Loss:0.498 AVG Training Acc 81.96 % AVG Validation Acc 78.90 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.417 AVG Validation Loss:0.504 AVG Training Acc 82.37 % AVG Validation Acc 78.36 %\n",
      "Epoch:70/200 AVG Training Loss:0.412 AVG Validation Loss:0.503 AVG Training Acc 82.32 % AVG Validation Acc 78.49 %\n",
      "Epoch:80/200 AVG Training Loss:0.412 AVG Validation Loss:0.508 AVG Training Acc 82.37 % AVG Validation Acc 78.23 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.411 AVG Validation Loss:0.510 AVG Training Acc 82.65 % AVG Validation Acc 78.23 %\n",
      "Epoch:100/200 AVG Training Loss:0.410 AVG Validation Loss:0.507 AVG Training Acc 82.71 % AVG Validation Acc 78.09 %\n",
      "Epoch:110/200 AVG Training Loss:0.411 AVG Validation Loss:0.507 AVG Training Acc 82.55 % AVG Validation Acc 78.36 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.407 AVG Validation Loss:0.514 AVG Training Acc 82.37 % AVG Validation Acc 77.96 %\n",
      "Epoch:130/200 AVG Training Loss:0.412 AVG Validation Loss:0.513 AVG Training Acc 82.50 % AVG Validation Acc 78.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.413 AVG Validation Loss:0.508 AVG Training Acc 82.25 % AVG Validation Acc 78.09 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.408 AVG Validation Loss:0.513 AVG Training Acc 82.74 % AVG Validation Acc 78.23 %\n",
      "Epoch:160/200 AVG Training Loss:0.411 AVG Validation Loss:0.508 AVG Training Acc 82.44 % AVG Validation Acc 78.36 %\n",
      "Epoch:170/200 AVG Training Loss:0.411 AVG Validation Loss:0.507 AVG Training Acc 82.56 % AVG Validation Acc 78.23 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.407 AVG Validation Loss:0.512 AVG Training Acc 82.58 % AVG Validation Acc 77.96 %\n",
      "Epoch:190/200 AVG Training Loss:0.411 AVG Validation Loss:0.511 AVG Training Acc 82.23 % AVG Validation Acc 77.96 %\n",
      "Epoch:200/200 AVG Training Loss:0.410 AVG Validation Loss:0.508 AVG Training Acc 82.47 % AVG Validation Acc 77.96 %\n",
      "Split 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8c70c6707d7434bbea870616510cd4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.484 AVG Validation Loss:0.485 AVG Training Acc 79.87 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.475 AVG Validation Loss:0.489 AVG Training Acc 80.10 % AVG Validation Acc 79.70 %\n",
      "Epoch:30/200 AVG Training Loss:0.466 AVG Validation Loss:0.489 AVG Training Acc 80.16 % AVG Validation Acc 79.57 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.428 AVG Validation Loss:0.502 AVG Training Acc 81.41 % AVG Validation Acc 79.03 %\n",
      "Epoch:50/200 AVG Training Loss:0.408 AVG Validation Loss:0.524 AVG Training Acc 82.10 % AVG Validation Acc 77.82 %\n",
      "Epoch:60/200 AVG Training Loss:0.393 AVG Validation Loss:0.548 AVG Training Acc 82.34 % AVG Validation Acc 77.96 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.387 AVG Validation Loss:0.547 AVG Training Acc 82.93 % AVG Validation Acc 78.36 %\n",
      "Epoch:80/200 AVG Training Loss:0.381 AVG Validation Loss:0.561 AVG Training Acc 83.08 % AVG Validation Acc 77.55 %\n",
      "Epoch:90/200 AVG Training Loss:0.381 AVG Validation Loss:0.559 AVG Training Acc 83.35 % AVG Validation Acc 77.02 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.378 AVG Validation Loss:0.556 AVG Training Acc 83.61 % AVG Validation Acc 77.96 %\n",
      "Epoch:110/200 AVG Training Loss:0.376 AVG Validation Loss:0.559 AVG Training Acc 83.25 % AVG Validation Acc 77.82 %\n",
      "Epoch:120/200 AVG Training Loss:0.376 AVG Validation Loss:0.563 AVG Training Acc 83.65 % AVG Validation Acc 77.82 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.377 AVG Validation Loss:0.565 AVG Training Acc 83.16 % AVG Validation Acc 77.28 %\n",
      "Epoch:140/200 AVG Training Loss:0.377 AVG Validation Loss:0.563 AVG Training Acc 83.38 % AVG Validation Acc 77.69 %\n",
      "Epoch:150/200 AVG Training Loss:0.378 AVG Validation Loss:0.571 AVG Training Acc 83.47 % AVG Validation Acc 77.69 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.376 AVG Validation Loss:0.561 AVG Training Acc 83.25 % AVG Validation Acc 78.09 %\n",
      "Epoch:170/200 AVG Training Loss:0.376 AVG Validation Loss:0.564 AVG Training Acc 83.56 % AVG Validation Acc 77.28 %\n",
      "Epoch:180/200 AVG Training Loss:0.374 AVG Validation Loss:0.559 AVG Training Acc 83.62 % AVG Validation Acc 78.09 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.378 AVG Validation Loss:0.554 AVG Training Acc 83.59 % AVG Validation Acc 77.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.375 AVG Validation Loss:0.562 AVG Training Acc 83.61 % AVG Validation Acc 77.28 %\n",
      "Split 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dceee5faaa6c42798199de59f58fd1a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.489 AVG Validation Loss:0.484 AVG Training Acc 79.74 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.475 AVG Validation Loss:0.494 AVG Training Acc 79.90 % AVG Validation Acc 79.97 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.461 AVG Validation Loss:0.487 AVG Training Acc 79.99 % AVG Validation Acc 80.11 %\n",
      "Epoch:40/200 AVG Training Loss:0.452 AVG Validation Loss:0.487 AVG Training Acc 80.20 % AVG Validation Acc 80.38 %\n",
      "Epoch:50/200 AVG Training Loss:0.446 AVG Validation Loss:0.488 AVG Training Acc 80.48 % AVG Validation Acc 80.24 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.439 AVG Validation Loss:0.494 AVG Training Acc 80.75 % AVG Validation Acc 79.97 %\n",
      "Epoch:70/200 AVG Training Loss:0.437 AVG Validation Loss:0.496 AVG Training Acc 80.77 % AVG Validation Acc 79.70 %\n",
      "Epoch:80/200 AVG Training Loss:0.436 AVG Validation Loss:0.498 AVG Training Acc 80.89 % AVG Validation Acc 79.84 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.433 AVG Validation Loss:0.498 AVG Training Acc 81.10 % AVG Validation Acc 79.70 %\n",
      "Epoch:100/200 AVG Training Loss:0.435 AVG Validation Loss:0.499 AVG Training Acc 81.02 % AVG Validation Acc 79.70 %\n",
      "Epoch:110/200 AVG Training Loss:0.437 AVG Validation Loss:0.498 AVG Training Acc 80.72 % AVG Validation Acc 80.38 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.436 AVG Validation Loss:0.500 AVG Training Acc 80.66 % AVG Validation Acc 79.84 %\n",
      "Epoch:130/200 AVG Training Loss:0.435 AVG Validation Loss:0.499 AVG Training Acc 81.02 % AVG Validation Acc 79.84 %\n",
      "Epoch:140/200 AVG Training Loss:0.435 AVG Validation Loss:0.498 AVG Training Acc 80.99 % AVG Validation Acc 79.70 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.435 AVG Validation Loss:0.498 AVG Training Acc 80.68 % AVG Validation Acc 80.11 %\n",
      "Epoch:160/200 AVG Training Loss:0.433 AVG Validation Loss:0.499 AVG Training Acc 81.07 % AVG Validation Acc 79.97 %\n",
      "Epoch:170/200 AVG Training Loss:0.436 AVG Validation Loss:0.499 AVG Training Acc 80.84 % AVG Validation Acc 79.97 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.437 AVG Validation Loss:0.500 AVG Training Acc 80.78 % AVG Validation Acc 79.84 %\n",
      "Epoch:190/200 AVG Training Loss:0.436 AVG Validation Loss:0.499 AVG Training Acc 80.89 % AVG Validation Acc 79.57 %\n",
      "Epoch:200/200 AVG Training Loss:0.436 AVG Validation Loss:0.499 AVG Training Acc 81.17 % AVG Validation Acc 79.57 %\n",
      "Split 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb5d7f6790c54930a7662eb5bddc6aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 79.92 % AVG Validation Acc 79.57 %\n",
      "Epoch:20/200 AVG Training Loss:0.472 AVG Validation Loss:0.492 AVG Training Acc 80.11 % AVG Validation Acc 79.57 %\n",
      "Epoch:30/200 AVG Training Loss:0.460 AVG Validation Loss:0.488 AVG Training Acc 80.25 % AVG Validation Acc 79.44 %\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.436 AVG Validation Loss:0.497 AVG Training Acc 80.98 % AVG Validation Acc 78.90 %\n",
      "Epoch:50/200 AVG Training Loss:0.410 AVG Validation Loss:0.529 AVG Training Acc 81.60 % AVG Validation Acc 78.36 %\n",
      "Epoch:60/200 AVG Training Loss:0.387 AVG Validation Loss:0.539 AVG Training Acc 82.43 % AVG Validation Acc 78.36 %\n",
      "Epoch:70/200 AVG Training Loss:0.373 AVG Validation Loss:0.562 AVG Training Acc 83.40 % AVG Validation Acc 78.09 %\n",
      "Epoch    70: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.359 AVG Validation Loss:0.577 AVG Training Acc 83.67 % AVG Validation Acc 77.55 %\n",
      "Epoch:90/200 AVG Training Loss:0.360 AVG Validation Loss:0.583 AVG Training Acc 83.71 % AVG Validation Acc 77.69 %\n",
      "Epoch:100/200 AVG Training Loss:0.357 AVG Validation Loss:0.581 AVG Training Acc 84.32 % AVG Validation Acc 77.55 %\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.355 AVG Validation Loss:0.584 AVG Training Acc 84.01 % AVG Validation Acc 77.28 %\n",
      "Epoch:120/200 AVG Training Loss:0.359 AVG Validation Loss:0.583 AVG Training Acc 83.92 % AVG Validation Acc 77.42 %\n",
      "Epoch:130/200 AVG Training Loss:0.355 AVG Validation Loss:0.587 AVG Training Acc 84.44 % AVG Validation Acc 77.28 %\n",
      "Epoch   132: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.352 AVG Validation Loss:0.580 AVG Training Acc 84.12 % AVG Validation Acc 77.69 %\n",
      "Epoch:150/200 AVG Training Loss:0.353 AVG Validation Loss:0.589 AVG Training Acc 84.18 % AVG Validation Acc 77.28 %\n",
      "Epoch:160/200 AVG Training Loss:0.353 AVG Validation Loss:0.587 AVG Training Acc 84.01 % AVG Validation Acc 77.96 %\n",
      "Epoch   163: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.358 AVG Validation Loss:0.580 AVG Training Acc 83.80 % AVG Validation Acc 77.28 %\n",
      "Epoch:180/200 AVG Training Loss:0.351 AVG Validation Loss:0.572 AVG Training Acc 84.26 % AVG Validation Acc 78.23 %\n",
      "Epoch:190/200 AVG Training Loss:0.355 AVG Validation Loss:0.592 AVG Training Acc 84.19 % AVG Validation Acc 76.75 %\n",
      "Epoch   194: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.354 AVG Validation Loss:0.589 AVG Training Acc 84.15 % AVG Validation Acc 77.42 %\n",
      "Split 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d76bd64104bc40cea99004cd8d4f56ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.482 AVG Validation Loss:0.487 AVG Training Acc 79.75 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.468 AVG Validation Loss:0.502 AVG Training Acc 79.86 % AVG Validation Acc 79.84 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.445 AVG Validation Loss:0.519 AVG Training Acc 80.25 % AVG Validation Acc 79.44 %\n",
      "Epoch:40/200 AVG Training Loss:0.427 AVG Validation Loss:0.552 AVG Training Acc 81.16 % AVG Validation Acc 78.76 %\n",
      "Epoch:50/200 AVG Training Loss:0.409 AVG Validation Loss:0.579 AVG Training Acc 81.66 % AVG Validation Acc 79.03 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.402 AVG Validation Loss:0.570 AVG Training Acc 82.08 % AVG Validation Acc 79.30 %\n",
      "Epoch:70/200 AVG Training Loss:0.398 AVG Validation Loss:0.583 AVG Training Acc 81.93 % AVG Validation Acc 79.17 %\n",
      "Epoch:80/200 AVG Training Loss:0.393 AVG Validation Loss:0.585 AVG Training Acc 82.26 % AVG Validation Acc 78.63 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.394 AVG Validation Loss:0.590 AVG Training Acc 82.40 % AVG Validation Acc 78.36 %\n",
      "Epoch:100/200 AVG Training Loss:0.395 AVG Validation Loss:0.590 AVG Training Acc 82.25 % AVG Validation Acc 78.49 %\n",
      "Epoch:110/200 AVG Training Loss:0.394 AVG Validation Loss:0.594 AVG Training Acc 82.10 % AVG Validation Acc 78.09 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.392 AVG Validation Loss:0.595 AVG Training Acc 82.28 % AVG Validation Acc 78.36 %\n",
      "Epoch:130/200 AVG Training Loss:0.392 AVG Validation Loss:0.591 AVG Training Acc 82.53 % AVG Validation Acc 78.36 %\n",
      "Epoch:140/200 AVG Training Loss:0.394 AVG Validation Loss:0.598 AVG Training Acc 82.22 % AVG Validation Acc 78.23 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.392 AVG Validation Loss:0.589 AVG Training Acc 82.58 % AVG Validation Acc 78.36 %\n",
      "Epoch:160/200 AVG Training Loss:0.394 AVG Validation Loss:0.593 AVG Training Acc 82.26 % AVG Validation Acc 78.63 %\n",
      "Epoch:170/200 AVG Training Loss:0.390 AVG Validation Loss:0.593 AVG Training Acc 82.58 % AVG Validation Acc 78.63 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.393 AVG Validation Loss:0.595 AVG Training Acc 81.80 % AVG Validation Acc 78.23 %\n",
      "Epoch:190/200 AVG Training Loss:0.394 AVG Validation Loss:0.593 AVG Training Acc 81.96 % AVG Validation Acc 78.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.391 AVG Validation Loss:0.593 AVG Training Acc 82.55 % AVG Validation Acc 78.23 %\n",
      "Split 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a86071ce2b35454aa94c7ca94548a6bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.486 AVG Validation Loss:0.481 AVG Training Acc 79.78 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.477 AVG Validation Loss:0.480 AVG Training Acc 80.01 % AVG Validation Acc 79.70 %\n",
      "Epoch:30/200 AVG Training Loss:0.473 AVG Validation Loss:0.475 AVG Training Acc 79.77 % AVG Validation Acc 79.84 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.440 AVG Validation Loss:0.474 AVG Training Acc 81.01 % AVG Validation Acc 79.70 %\n",
      "Epoch:50/200 AVG Training Loss:0.416 AVG Validation Loss:0.490 AVG Training Acc 81.49 % AVG Validation Acc 79.30 %\n",
      "Epoch:60/200 AVG Training Loss:0.404 AVG Validation Loss:0.509 AVG Training Acc 81.75 % AVG Validation Acc 78.90 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.387 AVG Validation Loss:0.528 AVG Training Acc 82.79 % AVG Validation Acc 76.61 %\n",
      "Epoch:80/200 AVG Training Loss:0.386 AVG Validation Loss:0.528 AVG Training Acc 82.76 % AVG Validation Acc 77.02 %\n",
      "Epoch:90/200 AVG Training Loss:0.384 AVG Validation Loss:0.540 AVG Training Acc 82.76 % AVG Validation Acc 77.02 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.380 AVG Validation Loss:0.532 AVG Training Acc 82.65 % AVG Validation Acc 77.42 %\n",
      "Epoch:110/200 AVG Training Loss:0.380 AVG Validation Loss:0.532 AVG Training Acc 82.92 % AVG Validation Acc 77.15 %\n",
      "Epoch:120/200 AVG Training Loss:0.379 AVG Validation Loss:0.544 AVG Training Acc 83.07 % AVG Validation Acc 76.88 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.378 AVG Validation Loss:0.544 AVG Training Acc 82.83 % AVG Validation Acc 76.75 %\n",
      "Epoch:140/200 AVG Training Loss:0.380 AVG Validation Loss:0.532 AVG Training Acc 82.77 % AVG Validation Acc 77.15 %\n",
      "Epoch:150/200 AVG Training Loss:0.379 AVG Validation Loss:0.543 AVG Training Acc 83.11 % AVG Validation Acc 77.15 %\n",
      "Epoch:160/200 AVG Training Loss:0.379 AVG Validation Loss:0.547 AVG Training Acc 83.20 % AVG Validation Acc 76.88 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.382 AVG Validation Loss:0.538 AVG Training Acc 83.23 % AVG Validation Acc 77.69 %\n",
      "Epoch:180/200 AVG Training Loss:0.378 AVG Validation Loss:0.549 AVG Training Acc 83.13 % AVG Validation Acc 76.48 %\n",
      "Epoch:190/200 AVG Training Loss:0.379 AVG Validation Loss:0.544 AVG Training Acc 83.31 % AVG Validation Acc 77.42 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.379 AVG Validation Loss:0.547 AVG Training Acc 83.07 % AVG Validation Acc 76.88 %\n",
      "Split 17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6c6f00aad39487d9df981cd12b41a65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.487 AVG Validation Loss:0.487 AVG Training Acc 79.78 % AVG Validation Acc 79.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.477 AVG Validation Loss:0.489 AVG Training Acc 79.98 % AVG Validation Acc 79.54 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.459 AVG Validation Loss:0.489 AVG Training Acc 80.43 % AVG Validation Acc 79.41 %\n",
      "Epoch:40/200 AVG Training Loss:0.450 AVG Validation Loss:0.505 AVG Training Acc 80.91 % AVG Validation Acc 79.54 %\n",
      "Epoch:50/200 AVG Training Loss:0.434 AVG Validation Loss:0.508 AVG Training Acc 81.25 % AVG Validation Acc 79.68 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.419 AVG Validation Loss:0.532 AVG Training Acc 81.23 % AVG Validation Acc 79.41 %\n",
      "Epoch:70/200 AVG Training Loss:0.417 AVG Validation Loss:0.530 AVG Training Acc 81.58 % AVG Validation Acc 79.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.416 AVG Validation Loss:0.529 AVG Training Acc 81.77 % AVG Validation Acc 79.27 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.412 AVG Validation Loss:0.532 AVG Training Acc 81.76 % AVG Validation Acc 79.54 %\n",
      "Epoch:100/200 AVG Training Loss:0.412 AVG Validation Loss:0.537 AVG Training Acc 81.68 % AVG Validation Acc 79.27 %\n",
      "Epoch:110/200 AVG Training Loss:0.411 AVG Validation Loss:0.530 AVG Training Acc 81.52 % AVG Validation Acc 79.27 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.412 AVG Validation Loss:0.533 AVG Training Acc 81.79 % AVG Validation Acc 79.54 %\n",
      "Epoch:130/200 AVG Training Loss:0.409 AVG Validation Loss:0.530 AVG Training Acc 81.61 % AVG Validation Acc 79.41 %\n",
      "Epoch:140/200 AVG Training Loss:0.411 AVG Validation Loss:0.533 AVG Training Acc 82.03 % AVG Validation Acc 79.54 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.412 AVG Validation Loss:0.538 AVG Training Acc 81.85 % AVG Validation Acc 79.00 %\n",
      "Epoch:160/200 AVG Training Loss:0.414 AVG Validation Loss:0.534 AVG Training Acc 81.73 % AVG Validation Acc 79.41 %\n",
      "Epoch:170/200 AVG Training Loss:0.410 AVG Validation Loss:0.537 AVG Training Acc 81.56 % AVG Validation Acc 79.41 %\n",
      "Epoch:180/200 AVG Training Loss:0.413 AVG Validation Loss:0.527 AVG Training Acc 81.74 % AVG Validation Acc 79.68 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.411 AVG Validation Loss:0.532 AVG Training Acc 81.58 % AVG Validation Acc 79.54 %\n",
      "Epoch:200/200 AVG Training Loss:0.411 AVG Validation Loss:0.533 AVG Training Acc 81.65 % AVG Validation Acc 79.00 %\n",
      "Split 18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30e11d7ed46643118cab24871c748c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 79.80 % AVG Validation Acc 79.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.473 AVG Validation Loss:0.488 AVG Training Acc 79.87 % AVG Validation Acc 80.08 %\n",
      "Epoch:30/200 AVG Training Loss:0.507 AVG Validation Loss:0.496 AVG Training Acc 79.50 % AVG Validation Acc 79.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.471 AVG Validation Loss:0.500 AVG Training Acc 80.10 % AVG Validation Acc 80.08 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.453 AVG Validation Loss:0.492 AVG Training Acc 80.59 % AVG Validation Acc 79.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.439 AVG Validation Loss:0.505 AVG Training Acc 81.20 % AVG Validation Acc 78.33 %\n",
      "Epoch:70/200 AVG Training Loss:0.432 AVG Validation Loss:0.511 AVG Training Acc 81.29 % AVG Validation Acc 78.20 %\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.418 AVG Validation Loss:0.531 AVG Training Acc 82.19 % AVG Validation Acc 77.25 %\n",
      "Epoch:90/200 AVG Training Loss:0.415 AVG Validation Loss:0.531 AVG Training Acc 82.21 % AVG Validation Acc 77.79 %\n",
      "Epoch:100/200 AVG Training Loss:0.415 AVG Validation Loss:0.529 AVG Training Acc 82.06 % AVG Validation Acc 77.79 %\n",
      "Epoch   104: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.414 AVG Validation Loss:0.529 AVG Training Acc 81.98 % AVG Validation Acc 77.66 %\n",
      "Epoch:120/200 AVG Training Loss:0.418 AVG Validation Loss:0.530 AVG Training Acc 82.38 % AVG Validation Acc 77.66 %\n",
      "Epoch:130/200 AVG Training Loss:0.411 AVG Validation Loss:0.532 AVG Training Acc 82.16 % AVG Validation Acc 77.66 %\n",
      "Epoch   135: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.414 AVG Validation Loss:0.527 AVG Training Acc 82.67 % AVG Validation Acc 77.79 %\n",
      "Epoch:150/200 AVG Training Loss:0.414 AVG Validation Loss:0.530 AVG Training Acc 82.44 % AVG Validation Acc 77.66 %\n",
      "Epoch:160/200 AVG Training Loss:0.415 AVG Validation Loss:0.531 AVG Training Acc 82.04 % AVG Validation Acc 77.52 %\n",
      "Epoch   166: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.411 AVG Validation Loss:0.528 AVG Training Acc 82.47 % AVG Validation Acc 77.79 %\n",
      "Epoch:180/200 AVG Training Loss:0.414 AVG Validation Loss:0.531 AVG Training Acc 82.15 % AVG Validation Acc 77.39 %\n",
      "Epoch:190/200 AVG Training Loss:0.414 AVG Validation Loss:0.530 AVG Training Acc 82.10 % AVG Validation Acc 77.66 %\n",
      "Epoch   197: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.415 AVG Validation Loss:0.531 AVG Training Acc 82.00 % AVG Validation Acc 77.52 %\n",
      "Split 19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea9c02197aa048198e9c5d99cc519705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.485 AVG Validation Loss:0.482 AVG Training Acc 79.75 % AVG Validation Acc 79.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.481 AVG Validation Loss:0.482 AVG Training Acc 79.56 % AVG Validation Acc 80.08 %\n",
      "Epoch:30/200 AVG Training Loss:0.475 AVG Validation Loss:0.480 AVG Training Acc 80.19 % AVG Validation Acc 79.95 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.455 AVG Validation Loss:0.488 AVG Training Acc 80.97 % AVG Validation Acc 79.27 %\n",
      "Epoch:50/200 AVG Training Loss:0.441 AVG Validation Loss:0.501 AVG Training Acc 81.37 % AVG Validation Acc 79.41 %\n",
      "Epoch:60/200 AVG Training Loss:0.426 AVG Validation Loss:0.521 AVG Training Acc 82.01 % AVG Validation Acc 79.00 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.414 AVG Validation Loss:0.532 AVG Training Acc 82.27 % AVG Validation Acc 78.73 %\n",
      "Epoch:80/200 AVG Training Loss:0.409 AVG Validation Loss:0.541 AVG Training Acc 82.38 % AVG Validation Acc 78.47 %\n",
      "Epoch:90/200 AVG Training Loss:0.409 AVG Validation Loss:0.540 AVG Training Acc 82.40 % AVG Validation Acc 78.87 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.406 AVG Validation Loss:0.540 AVG Training Acc 82.34 % AVG Validation Acc 79.00 %\n",
      "Epoch:110/200 AVG Training Loss:0.408 AVG Validation Loss:0.547 AVG Training Acc 82.31 % AVG Validation Acc 78.06 %\n",
      "Epoch:120/200 AVG Training Loss:0.404 AVG Validation Loss:0.547 AVG Training Acc 82.52 % AVG Validation Acc 78.06 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.406 AVG Validation Loss:0.544 AVG Training Acc 82.74 % AVG Validation Acc 78.47 %\n",
      "Epoch:140/200 AVG Training Loss:0.405 AVG Validation Loss:0.543 AVG Training Acc 82.52 % AVG Validation Acc 78.33 %\n",
      "Epoch:150/200 AVG Training Loss:0.408 AVG Validation Loss:0.546 AVG Training Acc 82.34 % AVG Validation Acc 78.73 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.405 AVG Validation Loss:0.548 AVG Training Acc 82.85 % AVG Validation Acc 78.20 %\n",
      "Epoch:170/200 AVG Training Loss:0.405 AVG Validation Loss:0.549 AVG Training Acc 82.65 % AVG Validation Acc 77.93 %\n",
      "Epoch:180/200 AVG Training Loss:0.405 AVG Validation Loss:0.544 AVG Training Acc 82.58 % AVG Validation Acc 78.20 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.403 AVG Validation Loss:0.545 AVG Training Acc 82.76 % AVG Validation Acc 78.47 %\n",
      "Epoch:200/200 AVG Training Loss:0.406 AVG Validation Loss:0.543 AVG Training Acc 82.74 % AVG Validation Acc 78.33 %\n",
      "Split 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed420f86129447be9e3f2b7b5c0acccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 79.92 % AVG Validation Acc 79.81 %\n",
      "Epoch:20/200 AVG Training Loss:0.480 AVG Validation Loss:0.487 AVG Training Acc 79.68 % AVG Validation Acc 79.81 %\n",
      "Epoch:30/200 AVG Training Loss:0.468 AVG Validation Loss:0.480 AVG Training Acc 80.10 % AVG Validation Acc 79.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.456 AVG Validation Loss:0.479 AVG Training Acc 80.20 % AVG Validation Acc 79.95 %\n",
      "Epoch:50/200 AVG Training Loss:0.454 AVG Validation Loss:0.487 AVG Training Acc 80.55 % AVG Validation Acc 79.95 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.435 AVG Validation Loss:0.488 AVG Training Acc 81.11 % AVG Validation Acc 79.68 %\n",
      "Epoch:70/200 AVG Training Loss:0.407 AVG Validation Loss:0.512 AVG Training Acc 81.86 % AVG Validation Acc 79.00 %\n",
      "Epoch:80/200 AVG Training Loss:0.390 AVG Validation Loss:0.548 AVG Training Acc 82.21 % AVG Validation Acc 79.14 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.376 AVG Validation Loss:0.564 AVG Training Acc 82.73 % AVG Validation Acc 78.33 %\n",
      "Epoch:100/200 AVG Training Loss:0.375 AVG Validation Loss:0.567 AVG Training Acc 82.74 % AVG Validation Acc 78.47 %\n",
      "Epoch:110/200 AVG Training Loss:0.371 AVG Validation Loss:0.567 AVG Training Acc 83.39 % AVG Validation Acc 78.60 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.371 AVG Validation Loss:0.575 AVG Training Acc 82.68 % AVG Validation Acc 79.00 %\n",
      "Epoch:130/200 AVG Training Loss:0.375 AVG Validation Loss:0.577 AVG Training Acc 82.68 % AVG Validation Acc 78.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.372 AVG Validation Loss:0.571 AVG Training Acc 83.15 % AVG Validation Acc 78.87 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.368 AVG Validation Loss:0.578 AVG Training Acc 83.01 % AVG Validation Acc 78.73 %\n",
      "Epoch:160/200 AVG Training Loss:0.369 AVG Validation Loss:0.570 AVG Training Acc 83.07 % AVG Validation Acc 79.27 %\n",
      "Epoch:170/200 AVG Training Loss:0.365 AVG Validation Loss:0.576 AVG Training Acc 83.03 % AVG Validation Acc 78.33 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.367 AVG Validation Loss:0.571 AVG Training Acc 83.46 % AVG Validation Acc 79.00 %\n",
      "Epoch:190/200 AVG Training Loss:0.369 AVG Validation Loss:0.574 AVG Training Acc 82.83 % AVG Validation Acc 78.73 %\n",
      "Epoch:200/200 AVG Training Loss:0.367 AVG Validation Loss:0.572 AVG Training Acc 82.88 % AVG Validation Acc 78.73 %\n",
      "Split 21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c84fe122c7d5498b9df4b9720636e2ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.479 AVG Validation Loss:0.499 AVG Training Acc 79.84 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.467 AVG Validation Loss:0.494 AVG Training Acc 79.69 % AVG Validation Acc 80.24 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.442 AVG Validation Loss:0.515 AVG Training Acc 80.65 % AVG Validation Acc 78.36 %\n",
      "Epoch:40/200 AVG Training Loss:0.426 AVG Validation Loss:0.537 AVG Training Acc 81.07 % AVG Validation Acc 77.96 %\n",
      "Epoch:50/200 AVG Training Loss:0.412 AVG Validation Loss:0.562 AVG Training Acc 81.81 % AVG Validation Acc 76.21 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.400 AVG Validation Loss:0.566 AVG Training Acc 82.17 % AVG Validation Acc 76.34 %\n",
      "Epoch:70/200 AVG Training Loss:0.398 AVG Validation Loss:0.574 AVG Training Acc 82.19 % AVG Validation Acc 76.48 %\n",
      "Epoch:80/200 AVG Training Loss:0.396 AVG Validation Loss:0.578 AVG Training Acc 82.16 % AVG Validation Acc 76.61 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.393 AVG Validation Loss:0.580 AVG Training Acc 82.53 % AVG Validation Acc 76.75 %\n",
      "Epoch:100/200 AVG Training Loss:0.393 AVG Validation Loss:0.579 AVG Training Acc 82.55 % AVG Validation Acc 75.94 %\n",
      "Epoch:110/200 AVG Training Loss:0.391 AVG Validation Loss:0.578 AVG Training Acc 82.35 % AVG Validation Acc 76.75 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.394 AVG Validation Loss:0.580 AVG Training Acc 82.22 % AVG Validation Acc 76.34 %\n",
      "Epoch:130/200 AVG Training Loss:0.394 AVG Validation Loss:0.580 AVG Training Acc 82.32 % AVG Validation Acc 76.34 %\n",
      "Epoch:140/200 AVG Training Loss:0.391 AVG Validation Loss:0.585 AVG Training Acc 82.46 % AVG Validation Acc 76.48 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.392 AVG Validation Loss:0.583 AVG Training Acc 82.58 % AVG Validation Acc 76.34 %\n",
      "Epoch:160/200 AVG Training Loss:0.394 AVG Validation Loss:0.582 AVG Training Acc 82.13 % AVG Validation Acc 76.48 %\n",
      "Epoch:170/200 AVG Training Loss:0.394 AVG Validation Loss:0.575 AVG Training Acc 82.14 % AVG Validation Acc 77.02 %\n",
      "Epoch:180/200 AVG Training Loss:0.392 AVG Validation Loss:0.583 AVG Training Acc 82.46 % AVG Validation Acc 76.48 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.391 AVG Validation Loss:0.584 AVG Training Acc 82.19 % AVG Validation Acc 76.75 %\n",
      "Epoch:200/200 AVG Training Loss:0.393 AVG Validation Loss:0.581 AVG Training Acc 82.41 % AVG Validation Acc 76.61 %\n",
      "Split 22\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e563077d7d64dd185f3ed569d0101da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.488 AVG Validation Loss:0.480 AVG Training Acc 79.83 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.475 AVG Validation Loss:0.473 AVG Training Acc 79.92 % AVG Validation Acc 79.70 %\n",
      "Epoch:30/200 AVG Training Loss:0.461 AVG Validation Loss:0.489 AVG Training Acc 80.04 % AVG Validation Acc 79.57 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.434 AVG Validation Loss:0.484 AVG Training Acc 81.02 % AVG Validation Acc 79.57 %\n",
      "Epoch:50/200 AVG Training Loss:0.411 AVG Validation Loss:0.507 AVG Training Acc 81.86 % AVG Validation Acc 77.69 %\n",
      "Epoch:60/200 AVG Training Loss:0.388 AVG Validation Loss:0.534 AVG Training Acc 82.95 % AVG Validation Acc 77.82 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.367 AVG Validation Loss:0.558 AVG Training Acc 84.19 % AVG Validation Acc 77.15 %\n",
      "Epoch:80/200 AVG Training Loss:0.362 AVG Validation Loss:0.562 AVG Training Acc 84.35 % AVG Validation Acc 77.28 %\n",
      "Epoch:90/200 AVG Training Loss:0.363 AVG Validation Loss:0.567 AVG Training Acc 84.16 % AVG Validation Acc 77.28 %\n",
      "Epoch:100/200 AVG Training Loss:0.358 AVG Validation Loss:0.576 AVG Training Acc 84.74 % AVG Validation Acc 76.48 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.360 AVG Validation Loss:0.572 AVG Training Acc 84.70 % AVG Validation Acc 76.61 %\n",
      "Epoch:120/200 AVG Training Loss:0.357 AVG Validation Loss:0.573 AVG Training Acc 84.43 % AVG Validation Acc 76.48 %\n",
      "Epoch:130/200 AVG Training Loss:0.358 AVG Validation Loss:0.569 AVG Training Acc 84.43 % AVG Validation Acc 77.02 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.359 AVG Validation Loss:0.568 AVG Training Acc 84.68 % AVG Validation Acc 76.88 %\n",
      "Epoch:150/200 AVG Training Loss:0.354 AVG Validation Loss:0.582 AVG Training Acc 84.79 % AVG Validation Acc 77.02 %\n",
      "Epoch:160/200 AVG Training Loss:0.357 AVG Validation Loss:0.572 AVG Training Acc 84.73 % AVG Validation Acc 77.15 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.359 AVG Validation Loss:0.580 AVG Training Acc 84.44 % AVG Validation Acc 76.75 %\n",
      "Epoch:180/200 AVG Training Loss:0.357 AVG Validation Loss:0.578 AVG Training Acc 84.92 % AVG Validation Acc 76.48 %\n",
      "Epoch:190/200 AVG Training Loss:0.358 AVG Validation Loss:0.575 AVG Training Acc 84.71 % AVG Validation Acc 77.02 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.358 AVG Validation Loss:0.577 AVG Training Acc 85.01 % AVG Validation Acc 76.88 %\n",
      "Split 23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64f3f1521f594894887cf5ebaaef7765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 79.83 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.476 AVG Validation Loss:0.460 AVG Training Acc 79.93 % AVG Validation Acc 79.97 %\n",
      "Epoch:30/200 AVG Training Loss:0.472 AVG Validation Loss:0.466 AVG Training Acc 79.92 % AVG Validation Acc 79.97 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.453 AVG Validation Loss:0.460 AVG Training Acc 80.20 % AVG Validation Acc 79.70 %\n",
      "Epoch:50/200 AVG Training Loss:0.439 AVG Validation Loss:0.472 AVG Training Acc 80.66 % AVG Validation Acc 79.70 %\n",
      "Epoch:60/200 AVG Training Loss:0.426 AVG Validation Loss:0.474 AVG Training Acc 81.04 % AVG Validation Acc 79.97 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.413 AVG Validation Loss:0.481 AVG Training Acc 81.53 % AVG Validation Acc 80.24 %\n",
      "Epoch:80/200 AVG Training Loss:0.414 AVG Validation Loss:0.483 AVG Training Acc 81.25 % AVG Validation Acc 80.24 %\n",
      "Epoch:90/200 AVG Training Loss:0.411 AVG Validation Loss:0.489 AVG Training Acc 81.53 % AVG Validation Acc 80.24 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.408 AVG Validation Loss:0.487 AVG Training Acc 82.11 % AVG Validation Acc 79.84 %\n",
      "Epoch:110/200 AVG Training Loss:0.410 AVG Validation Loss:0.489 AVG Training Acc 81.62 % AVG Validation Acc 79.97 %\n",
      "Epoch:120/200 AVG Training Loss:0.410 AVG Validation Loss:0.489 AVG Training Acc 81.59 % AVG Validation Acc 80.11 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.408 AVG Validation Loss:0.489 AVG Training Acc 81.72 % AVG Validation Acc 79.84 %\n",
      "Epoch:140/200 AVG Training Loss:0.410 AVG Validation Loss:0.487 AVG Training Acc 81.49 % AVG Validation Acc 79.84 %\n",
      "Epoch:150/200 AVG Training Loss:0.411 AVG Validation Loss:0.492 AVG Training Acc 81.62 % AVG Validation Acc 79.84 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.409 AVG Validation Loss:0.490 AVG Training Acc 81.58 % AVG Validation Acc 79.97 %\n",
      "Epoch:170/200 AVG Training Loss:0.408 AVG Validation Loss:0.488 AVG Training Acc 81.75 % AVG Validation Acc 80.11 %\n",
      "Epoch:180/200 AVG Training Loss:0.406 AVG Validation Loss:0.491 AVG Training Acc 81.53 % AVG Validation Acc 80.11 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.410 AVG Validation Loss:0.493 AVG Training Acc 81.50 % AVG Validation Acc 79.70 %\n",
      "Epoch:200/200 AVG Training Loss:0.410 AVG Validation Loss:0.492 AVG Training Acc 81.38 % AVG Validation Acc 79.57 %\n",
      "Split 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "996c36ed19064ead83202213fe12f432",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.485 AVG Validation Loss:0.490 AVG Training Acc 79.75 % AVG Validation Acc 79.84 %\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.473 AVG Validation Loss:0.486 AVG Training Acc 80.13 % AVG Validation Acc 79.17 %\n",
      "Epoch:30/200 AVG Training Loss:0.468 AVG Validation Loss:0.490 AVG Training Acc 80.07 % AVG Validation Acc 79.17 %\n",
      "Epoch:40/200 AVG Training Loss:0.463 AVG Validation Loss:0.488 AVG Training Acc 80.51 % AVG Validation Acc 79.03 %\n",
      "Epoch:50/200 AVG Training Loss:0.453 AVG Validation Loss:0.489 AVG Training Acc 80.81 % AVG Validation Acc 79.03 %\n",
      "Epoch:60/200 AVG Training Loss:0.444 AVG Validation Loss:0.494 AVG Training Acc 81.02 % AVG Validation Acc 78.49 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.433 AVG Validation Loss:0.497 AVG Training Acc 81.52 % AVG Validation Acc 78.23 %\n",
      "Epoch:80/200 AVG Training Loss:0.428 AVG Validation Loss:0.498 AVG Training Acc 81.75 % AVG Validation Acc 78.23 %\n",
      "Epoch:90/200 AVG Training Loss:0.427 AVG Validation Loss:0.501 AVG Training Acc 81.59 % AVG Validation Acc 77.96 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.424 AVG Validation Loss:0.500 AVG Training Acc 81.50 % AVG Validation Acc 77.96 %\n",
      "Epoch:110/200 AVG Training Loss:0.424 AVG Validation Loss:0.501 AVG Training Acc 81.53 % AVG Validation Acc 78.23 %\n",
      "Epoch:120/200 AVG Training Loss:0.426 AVG Validation Loss:0.501 AVG Training Acc 81.47 % AVG Validation Acc 78.23 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.425 AVG Validation Loss:0.501 AVG Training Acc 81.68 % AVG Validation Acc 77.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.426 AVG Validation Loss:0.503 AVG Training Acc 81.78 % AVG Validation Acc 78.09 %\n",
      "Epoch:150/200 AVG Training Loss:0.425 AVG Validation Loss:0.500 AVG Training Acc 81.72 % AVG Validation Acc 78.23 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.426 AVG Validation Loss:0.501 AVG Training Acc 81.68 % AVG Validation Acc 78.09 %\n",
      "Epoch:170/200 AVG Training Loss:0.425 AVG Validation Loss:0.501 AVG Training Acc 81.65 % AVG Validation Acc 78.23 %\n",
      "Epoch:180/200 AVG Training Loss:0.425 AVG Validation Loss:0.502 AVG Training Acc 81.87 % AVG Validation Acc 78.09 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.425 AVG Validation Loss:0.500 AVG Training Acc 81.56 % AVG Validation Acc 78.09 %\n",
      "Epoch:200/200 AVG Training Loss:0.426 AVG Validation Loss:0.500 AVG Training Acc 81.52 % AVG Validation Acc 78.09 %\n",
      "Split 25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff0caab7b754c67be3cc097aa63a08c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.484 AVG Validation Loss:0.493 AVG Training Acc 79.75 % AVG Validation Acc 79.70 %\n",
      "Epoch:20/200 AVG Training Loss:0.473 AVG Validation Loss:0.500 AVG Training Acc 80.07 % AVG Validation Acc 79.84 %\n",
      "Epoch:30/200 AVG Training Loss:0.465 AVG Validation Loss:0.497 AVG Training Acc 80.11 % AVG Validation Acc 79.57 %\n",
      "Epoch:40/200 AVG Training Loss:0.463 AVG Validation Loss:0.512 AVG Training Acc 80.32 % AVG Validation Acc 79.97 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.418 AVG Validation Loss:0.520 AVG Training Acc 81.69 % AVG Validation Acc 78.49 %\n",
      "Epoch:60/200 AVG Training Loss:0.399 AVG Validation Loss:0.542 AVG Training Acc 82.71 % AVG Validation Acc 77.02 %\n",
      "Epoch:70/200 AVG Training Loss:0.385 AVG Validation Loss:0.567 AVG Training Acc 83.44 % AVG Validation Acc 77.02 %\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.371 AVG Validation Loss:0.581 AVG Training Acc 83.82 % AVG Validation Acc 77.42 %\n",
      "Epoch:90/200 AVG Training Loss:0.369 AVG Validation Loss:0.584 AVG Training Acc 84.07 % AVG Validation Acc 77.02 %\n",
      "Epoch:100/200 AVG Training Loss:0.364 AVG Validation Loss:0.590 AVG Training Acc 83.98 % AVG Validation Acc 76.61 %\n",
      "Epoch   104: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.367 AVG Validation Loss:0.597 AVG Training Acc 83.58 % AVG Validation Acc 75.81 %\n",
      "Epoch:120/200 AVG Training Loss:0.362 AVG Validation Loss:0.593 AVG Training Acc 84.16 % AVG Validation Acc 76.08 %\n",
      "Epoch:130/200 AVG Training Loss:0.363 AVG Validation Loss:0.582 AVG Training Acc 84.09 % AVG Validation Acc 76.21 %\n",
      "Epoch   135: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.361 AVG Validation Loss:0.599 AVG Training Acc 84.29 % AVG Validation Acc 76.34 %\n",
      "Epoch:150/200 AVG Training Loss:0.362 AVG Validation Loss:0.598 AVG Training Acc 84.41 % AVG Validation Acc 76.08 %\n",
      "Epoch:160/200 AVG Training Loss:0.364 AVG Validation Loss:0.584 AVG Training Acc 84.10 % AVG Validation Acc 76.88 %\n",
      "Epoch   166: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.362 AVG Validation Loss:0.607 AVG Training Acc 84.25 % AVG Validation Acc 76.34 %\n",
      "Epoch:180/200 AVG Training Loss:0.363 AVG Validation Loss:0.589 AVG Training Acc 84.25 % AVG Validation Acc 76.34 %\n",
      "Epoch:190/200 AVG Training Loss:0.361 AVG Validation Loss:0.587 AVG Training Acc 83.95 % AVG Validation Acc 77.02 %\n",
      "Epoch   197: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.362 AVG Validation Loss:0.596 AVG Training Acc 84.07 % AVG Validation Acc 76.61 %\n",
      "Split 26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f6b19385fb44e888475d9d8d7e84775",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.484 AVG Validation Loss:0.498 AVG Training Acc 80.05 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.474 AVG Validation Loss:0.505 AVG Training Acc 80.08 % AVG Validation Acc 79.44 %\n",
      "Epoch:30/200 AVG Training Loss:0.466 AVG Validation Loss:0.499 AVG Training Acc 80.38 % AVG Validation Acc 79.57 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.429 AVG Validation Loss:0.509 AVG Training Acc 81.56 % AVG Validation Acc 79.03 %\n",
      "Epoch:50/200 AVG Training Loss:0.403 AVG Validation Loss:0.541 AVG Training Acc 82.58 % AVG Validation Acc 77.69 %\n",
      "Epoch:60/200 AVG Training Loss:0.378 AVG Validation Loss:0.602 AVG Training Acc 83.70 % AVG Validation Acc 75.81 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.363 AVG Validation Loss:0.617 AVG Training Acc 84.55 % AVG Validation Acc 75.81 %\n",
      "Epoch:80/200 AVG Training Loss:0.360 AVG Validation Loss:0.628 AVG Training Acc 84.70 % AVG Validation Acc 76.21 %\n",
      "Epoch:90/200 AVG Training Loss:0.354 AVG Validation Loss:0.638 AVG Training Acc 85.07 % AVG Validation Acc 75.81 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.350 AVG Validation Loss:0.647 AVG Training Acc 85.34 % AVG Validation Acc 75.67 %\n",
      "Epoch:110/200 AVG Training Loss:0.350 AVG Validation Loss:0.635 AVG Training Acc 85.33 % AVG Validation Acc 76.21 %\n",
      "Epoch:120/200 AVG Training Loss:0.350 AVG Validation Loss:0.627 AVG Training Acc 85.30 % AVG Validation Acc 76.48 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.350 AVG Validation Loss:0.641 AVG Training Acc 85.13 % AVG Validation Acc 75.81 %\n",
      "Epoch:140/200 AVG Training Loss:0.350 AVG Validation Loss:0.640 AVG Training Acc 85.39 % AVG Validation Acc 75.94 %\n",
      "Epoch:150/200 AVG Training Loss:0.350 AVG Validation Loss:0.662 AVG Training Acc 85.24 % AVG Validation Acc 75.81 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.350 AVG Validation Loss:0.648 AVG Training Acc 85.12 % AVG Validation Acc 75.67 %\n",
      "Epoch:170/200 AVG Training Loss:0.353 AVG Validation Loss:0.649 AVG Training Acc 85.15 % AVG Validation Acc 76.08 %\n",
      "Epoch:180/200 AVG Training Loss:0.348 AVG Validation Loss:0.644 AVG Training Acc 85.18 % AVG Validation Acc 75.40 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.349 AVG Validation Loss:0.641 AVG Training Acc 85.34 % AVG Validation Acc 76.21 %\n",
      "Epoch:200/200 AVG Training Loss:0.350 AVG Validation Loss:0.641 AVG Training Acc 85.55 % AVG Validation Acc 75.94 %\n",
      "Split 27\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6f234cc9544454e9ef23e30524154e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.481 AVG Validation Loss:0.488 AVG Training Acc 79.81 % AVG Validation Acc 79.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.472 AVG Validation Loss:0.498 AVG Training Acc 79.96 % AVG Validation Acc 79.81 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.457 AVG Validation Loss:0.491 AVG Training Acc 80.14 % AVG Validation Acc 79.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.446 AVG Validation Loss:0.508 AVG Training Acc 80.20 % AVG Validation Acc 79.81 %\n",
      "Epoch:50/200 AVG Training Loss:0.434 AVG Validation Loss:0.526 AVG Training Acc 80.67 % AVG Validation Acc 79.54 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.426 AVG Validation Loss:0.519 AVG Training Acc 80.70 % AVG Validation Acc 79.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.421 AVG Validation Loss:0.523 AVG Training Acc 81.31 % AVG Validation Acc 79.00 %\n",
      "Epoch:80/200 AVG Training Loss:0.420 AVG Validation Loss:0.525 AVG Training Acc 81.35 % AVG Validation Acc 78.06 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.418 AVG Validation Loss:0.525 AVG Training Acc 81.47 % AVG Validation Acc 78.33 %\n",
      "Epoch:100/200 AVG Training Loss:0.418 AVG Validation Loss:0.528 AVG Training Acc 81.46 % AVG Validation Acc 78.20 %\n",
      "Epoch:110/200 AVG Training Loss:0.422 AVG Validation Loss:0.526 AVG Training Acc 81.23 % AVG Validation Acc 78.20 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.420 AVG Validation Loss:0.522 AVG Training Acc 81.28 % AVG Validation Acc 78.33 %\n",
      "Epoch:130/200 AVG Training Loss:0.419 AVG Validation Loss:0.531 AVG Training Acc 81.55 % AVG Validation Acc 78.33 %\n",
      "Epoch:140/200 AVG Training Loss:0.419 AVG Validation Loss:0.524 AVG Training Acc 81.28 % AVG Validation Acc 78.60 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.419 AVG Validation Loss:0.528 AVG Training Acc 81.35 % AVG Validation Acc 78.06 %\n",
      "Epoch:160/200 AVG Training Loss:0.420 AVG Validation Loss:0.534 AVG Training Acc 81.31 % AVG Validation Acc 78.06 %\n",
      "Epoch:170/200 AVG Training Loss:0.422 AVG Validation Loss:0.524 AVG Training Acc 81.11 % AVG Validation Acc 78.06 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.421 AVG Validation Loss:0.527 AVG Training Acc 81.29 % AVG Validation Acc 78.20 %\n",
      "Epoch:190/200 AVG Training Loss:0.419 AVG Validation Loss:0.528 AVG Training Acc 81.11 % AVG Validation Acc 78.06 %\n",
      "Epoch:200/200 AVG Training Loss:0.418 AVG Validation Loss:0.526 AVG Training Acc 81.52 % AVG Validation Acc 78.20 %\n",
      "Split 28\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c030291b6cd14bfb8690a04133b5f9d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.486 AVG Validation Loss:0.493 AVG Training Acc 79.80 % AVG Validation Acc 79.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.468 AVG Validation Loss:0.495 AVG Training Acc 79.75 % AVG Validation Acc 79.68 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.444 AVG Validation Loss:0.508 AVG Training Acc 80.67 % AVG Validation Acc 80.48 %\n",
      "Epoch:40/200 AVG Training Loss:0.427 AVG Validation Loss:0.521 AVG Training Acc 81.22 % AVG Validation Acc 79.95 %\n",
      "Epoch:50/200 AVG Training Loss:0.412 AVG Validation Loss:0.550 AVG Training Acc 81.52 % AVG Validation Acc 79.68 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.399 AVG Validation Loss:0.570 AVG Training Acc 81.86 % AVG Validation Acc 79.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.395 AVG Validation Loss:0.572 AVG Training Acc 82.13 % AVG Validation Acc 78.60 %\n",
      "Epoch:80/200 AVG Training Loss:0.393 AVG Validation Loss:0.573 AVG Training Acc 82.24 % AVG Validation Acc 78.60 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.391 AVG Validation Loss:0.572 AVG Training Acc 82.29 % AVG Validation Acc 78.87 %\n",
      "Epoch:100/200 AVG Training Loss:0.390 AVG Validation Loss:0.575 AVG Training Acc 82.68 % AVG Validation Acc 78.73 %\n",
      "Epoch:110/200 AVG Training Loss:0.389 AVG Validation Loss:0.581 AVG Training Acc 82.71 % AVG Validation Acc 78.33 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.391 AVG Validation Loss:0.582 AVG Training Acc 82.70 % AVG Validation Acc 78.20 %\n",
      "Epoch:130/200 AVG Training Loss:0.390 AVG Validation Loss:0.575 AVG Training Acc 82.53 % AVG Validation Acc 78.47 %\n",
      "Epoch:140/200 AVG Training Loss:0.393 AVG Validation Loss:0.576 AVG Training Acc 82.03 % AVG Validation Acc 78.60 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.389 AVG Validation Loss:0.578 AVG Training Acc 82.21 % AVG Validation Acc 79.00 %\n",
      "Epoch:160/200 AVG Training Loss:0.392 AVG Validation Loss:0.583 AVG Training Acc 82.28 % AVG Validation Acc 78.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.390 AVG Validation Loss:0.578 AVG Training Acc 82.19 % AVG Validation Acc 79.00 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.391 AVG Validation Loss:0.574 AVG Training Acc 82.53 % AVG Validation Acc 78.73 %\n",
      "Epoch:190/200 AVG Training Loss:0.388 AVG Validation Loss:0.578 AVG Training Acc 82.61 % AVG Validation Acc 78.73 %\n",
      "Epoch:200/200 AVG Training Loss:0.390 AVG Validation Loss:0.577 AVG Training Acc 82.40 % AVG Validation Acc 78.87 %\n",
      "Split 29\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "146210db68854c7f831f390686bb29cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.485 AVG Validation Loss:0.485 AVG Training Acc 79.89 % AVG Validation Acc 79.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.479 AVG Validation Loss:0.484 AVG Training Acc 79.86 % AVG Validation Acc 79.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.469 AVG Validation Loss:0.494 AVG Training Acc 80.11 % AVG Validation Acc 79.95 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.444 AVG Validation Loss:0.480 AVG Training Acc 81.19 % AVG Validation Acc 80.35 %\n",
      "Epoch:50/200 AVG Training Loss:0.428 AVG Validation Loss:0.502 AVG Training Acc 81.41 % AVG Validation Acc 79.68 %\n",
      "Epoch:60/200 AVG Training Loss:0.414 AVG Validation Loss:0.522 AVG Training Acc 82.03 % AVG Validation Acc 79.81 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.401 AVG Validation Loss:0.543 AVG Training Acc 82.32 % AVG Validation Acc 79.27 %\n",
      "Epoch:80/200 AVG Training Loss:0.398 AVG Validation Loss:0.548 AVG Training Acc 82.74 % AVG Validation Acc 79.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.397 AVG Validation Loss:0.560 AVG Training Acc 82.44 % AVG Validation Acc 79.27 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.394 AVG Validation Loss:0.553 AVG Training Acc 82.53 % AVG Validation Acc 79.27 %\n",
      "Epoch:110/200 AVG Training Loss:0.395 AVG Validation Loss:0.556 AVG Training Acc 82.71 % AVG Validation Acc 79.41 %\n",
      "Epoch:120/200 AVG Training Loss:0.396 AVG Validation Loss:0.568 AVG Training Acc 82.40 % AVG Validation Acc 79.27 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.395 AVG Validation Loss:0.556 AVG Training Acc 82.52 % AVG Validation Acc 79.54 %\n",
      "Epoch:140/200 AVG Training Loss:0.394 AVG Validation Loss:0.560 AVG Training Acc 82.50 % AVG Validation Acc 79.14 %\n",
      "Epoch:150/200 AVG Training Loss:0.395 AVG Validation Loss:0.561 AVG Training Acc 82.49 % AVG Validation Acc 79.00 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.394 AVG Validation Loss:0.555 AVG Training Acc 82.44 % AVG Validation Acc 79.00 %\n",
      "Epoch:170/200 AVG Training Loss:0.394 AVG Validation Loss:0.563 AVG Training Acc 82.47 % AVG Validation Acc 79.27 %\n",
      "Epoch:180/200 AVG Training Loss:0.394 AVG Validation Loss:0.562 AVG Training Acc 82.38 % AVG Validation Acc 79.14 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.395 AVG Validation Loss:0.565 AVG Training Acc 83.03 % AVG Validation Acc 79.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.394 AVG Validation Loss:0.560 AVG Training Acc 82.62 % AVG Validation Acc 79.41 %\n",
      "Split 30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4173a168dad443caa5f8296a22d19830",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.485 AVG Validation Loss:0.480 AVG Training Acc 79.96 % AVG Validation Acc 79.27 %\n",
      "Epoch:20/200 AVG Training Loss:0.478 AVG Validation Loss:0.475 AVG Training Acc 79.96 % AVG Validation Acc 79.54 %\n",
      "Epoch:30/200 AVG Training Loss:0.478 AVG Validation Loss:0.473 AVG Training Acc 79.98 % AVG Validation Acc 79.81 %\n",
      "Epoch:40/200 AVG Training Loss:0.452 AVG Validation Loss:0.468 AVG Training Acc 80.85 % AVG Validation Acc 79.68 %\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.420 AVG Validation Loss:0.491 AVG Training Acc 81.53 % AVG Validation Acc 78.87 %\n",
      "Epoch:60/200 AVG Training Loss:0.408 AVG Validation Loss:0.520 AVG Training Acc 82.12 % AVG Validation Acc 79.00 %\n",
      "Epoch:70/200 AVG Training Loss:0.389 AVG Validation Loss:0.554 AVG Training Acc 82.71 % AVG Validation Acc 78.06 %\n",
      "Epoch    71: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.381 AVG Validation Loss:0.558 AVG Training Acc 82.86 % AVG Validation Acc 78.20 %\n",
      "Epoch:90/200 AVG Training Loss:0.380 AVG Validation Loss:0.577 AVG Training Acc 82.70 % AVG Validation Acc 77.93 %\n",
      "Epoch:100/200 AVG Training Loss:0.378 AVG Validation Loss:0.581 AVG Training Acc 82.98 % AVG Validation Acc 77.93 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.377 AVG Validation Loss:0.582 AVG Training Acc 82.86 % AVG Validation Acc 77.66 %\n",
      "Epoch:120/200 AVG Training Loss:0.375 AVG Validation Loss:0.582 AVG Training Acc 82.92 % AVG Validation Acc 77.93 %\n",
      "Epoch:130/200 AVG Training Loss:0.374 AVG Validation Loss:0.580 AVG Training Acc 82.83 % AVG Validation Acc 77.79 %\n",
      "Epoch   133: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.376 AVG Validation Loss:0.589 AVG Training Acc 82.98 % AVG Validation Acc 77.25 %\n",
      "Epoch:150/200 AVG Training Loss:0.377 AVG Validation Loss:0.579 AVG Training Acc 82.74 % AVG Validation Acc 77.66 %\n",
      "Epoch:160/200 AVG Training Loss:0.379 AVG Validation Loss:0.581 AVG Training Acc 82.92 % AVG Validation Acc 77.66 %\n",
      "Epoch   164: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.377 AVG Validation Loss:0.573 AVG Training Acc 82.68 % AVG Validation Acc 77.93 %\n",
      "Epoch:180/200 AVG Training Loss:0.377 AVG Validation Loss:0.577 AVG Training Acc 82.79 % AVG Validation Acc 77.79 %\n",
      "Epoch:190/200 AVG Training Loss:0.375 AVG Validation Loss:0.582 AVG Training Acc 82.76 % AVG Validation Acc 77.79 %\n",
      "Epoch   195: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.378 AVG Validation Loss:0.575 AVG Training Acc 82.59 % AVG Validation Acc 77.66 %\n",
      "Split 31\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e100384ae44e43eba889427b1cb9a53a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.486 AVG Validation Loss:0.492 AVG Training Acc 79.93 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.475 AVG Validation Loss:0.485 AVG Training Acc 79.98 % AVG Validation Acc 79.97 %\n",
      "Epoch:30/200 AVG Training Loss:0.476 AVG Validation Loss:0.480 AVG Training Acc 79.96 % AVG Validation Acc 79.97 %\n",
      "Epoch:40/200 AVG Training Loss:0.468 AVG Validation Loss:0.484 AVG Training Acc 80.22 % AVG Validation Acc 79.84 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.432 AVG Validation Loss:0.492 AVG Training Acc 81.49 % AVG Validation Acc 79.57 %\n",
      "Epoch:60/200 AVG Training Loss:0.414 AVG Validation Loss:0.525 AVG Training Acc 82.04 % AVG Validation Acc 79.30 %\n",
      "Epoch:70/200 AVG Training Loss:0.399 AVG Validation Loss:0.563 AVG Training Acc 82.43 % AVG Validation Acc 79.17 %\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.391 AVG Validation Loss:0.562 AVG Training Acc 82.58 % AVG Validation Acc 79.03 %\n",
      "Epoch:90/200 AVG Training Loss:0.387 AVG Validation Loss:0.559 AVG Training Acc 82.90 % AVG Validation Acc 78.63 %\n",
      "Epoch:100/200 AVG Training Loss:0.385 AVG Validation Loss:0.572 AVG Training Acc 82.92 % AVG Validation Acc 78.90 %\n",
      "Epoch   104: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.383 AVG Validation Loss:0.577 AVG Training Acc 83.14 % AVG Validation Acc 78.90 %\n",
      "Epoch:120/200 AVG Training Loss:0.382 AVG Validation Loss:0.577 AVG Training Acc 83.31 % AVG Validation Acc 78.49 %\n",
      "Epoch:130/200 AVG Training Loss:0.384 AVG Validation Loss:0.580 AVG Training Acc 82.80 % AVG Validation Acc 79.17 %\n",
      "Epoch   135: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.380 AVG Validation Loss:0.580 AVG Training Acc 83.14 % AVG Validation Acc 78.09 %\n",
      "Epoch:150/200 AVG Training Loss:0.384 AVG Validation Loss:0.573 AVG Training Acc 82.88 % AVG Validation Acc 78.90 %\n",
      "Epoch:160/200 AVG Training Loss:0.381 AVG Validation Loss:0.578 AVG Training Acc 83.14 % AVG Validation Acc 78.90 %\n",
      "Epoch   166: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.380 AVG Validation Loss:0.587 AVG Training Acc 83.56 % AVG Validation Acc 78.63 %\n",
      "Epoch:180/200 AVG Training Loss:0.381 AVG Validation Loss:0.582 AVG Training Acc 83.26 % AVG Validation Acc 78.49 %\n",
      "Epoch:190/200 AVG Training Loss:0.381 AVG Validation Loss:0.579 AVG Training Acc 83.32 % AVG Validation Acc 78.76 %\n",
      "Epoch   197: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.384 AVG Validation Loss:0.577 AVG Training Acc 83.01 % AVG Validation Acc 78.90 %\n",
      "Split 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfcbeab1c87c4a819a5f6afb08487d75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 79.89 % AVG Validation Acc 79.70 %\n",
      "Epoch:20/200 AVG Training Loss:0.472 AVG Validation Loss:0.486 AVG Training Acc 80.04 % AVG Validation Acc 79.57 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.459 AVG Validation Loss:0.486 AVG Training Acc 80.54 % AVG Validation Acc 79.57 %\n",
      "Epoch:40/200 AVG Training Loss:0.446 AVG Validation Loss:0.494 AVG Training Acc 80.83 % AVG Validation Acc 79.30 %\n",
      "Epoch:50/200 AVG Training Loss:0.438 AVG Validation Loss:0.499 AVG Training Acc 80.87 % AVG Validation Acc 78.90 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.427 AVG Validation Loss:0.506 AVG Training Acc 81.62 % AVG Validation Acc 78.49 %\n",
      "Epoch:70/200 AVG Training Loss:0.423 AVG Validation Loss:0.507 AVG Training Acc 81.59 % AVG Validation Acc 78.63 %\n",
      "Epoch:80/200 AVG Training Loss:0.425 AVG Validation Loss:0.506 AVG Training Acc 81.55 % AVG Validation Acc 78.36 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.421 AVG Validation Loss:0.509 AVG Training Acc 81.63 % AVG Validation Acc 78.23 %\n",
      "Epoch:100/200 AVG Training Loss:0.423 AVG Validation Loss:0.505 AVG Training Acc 81.71 % AVG Validation Acc 78.36 %\n",
      "Epoch:110/200 AVG Training Loss:0.423 AVG Validation Loss:0.508 AVG Training Acc 81.50 % AVG Validation Acc 78.23 %\n",
      "Epoch:120/200 AVG Training Loss:0.423 AVG Validation Loss:0.509 AVG Training Acc 81.58 % AVG Validation Acc 78.36 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.422 AVG Validation Loss:0.510 AVG Training Acc 81.78 % AVG Validation Acc 78.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.420 AVG Validation Loss:0.507 AVG Training Acc 81.98 % AVG Validation Acc 78.23 %\n",
      "Epoch:150/200 AVG Training Loss:0.421 AVG Validation Loss:0.509 AVG Training Acc 81.58 % AVG Validation Acc 78.36 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.420 AVG Validation Loss:0.510 AVG Training Acc 81.75 % AVG Validation Acc 78.49 %\n",
      "Epoch:170/200 AVG Training Loss:0.421 AVG Validation Loss:0.506 AVG Training Acc 81.52 % AVG Validation Acc 78.63 %\n",
      "Epoch:180/200 AVG Training Loss:0.422 AVG Validation Loss:0.511 AVG Training Acc 81.65 % AVG Validation Acc 77.96 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.422 AVG Validation Loss:0.511 AVG Training Acc 81.41 % AVG Validation Acc 77.96 %\n",
      "Epoch:200/200 AVG Training Loss:0.420 AVG Validation Loss:0.510 AVG Training Acc 81.71 % AVG Validation Acc 78.23 %\n",
      "Split 33\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cbd0da63d9a4e33af29c641b4aec206",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 79.87 % AVG Validation Acc 79.84 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.468 AVG Validation Loss:0.483 AVG Training Acc 80.25 % AVG Validation Acc 79.70 %\n",
      "Epoch:30/200 AVG Training Loss:0.463 AVG Validation Loss:0.484 AVG Training Acc 80.14 % AVG Validation Acc 79.97 %\n",
      "Epoch:40/200 AVG Training Loss:0.458 AVG Validation Loss:0.488 AVG Training Acc 80.35 % AVG Validation Acc 79.30 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.450 AVG Validation Loss:0.489 AVG Training Acc 80.60 % AVG Validation Acc 79.70 %\n",
      "Epoch:60/200 AVG Training Loss:0.447 AVG Validation Loss:0.493 AVG Training Acc 80.71 % AVG Validation Acc 79.30 %\n",
      "Epoch:70/200 AVG Training Loss:0.445 AVG Validation Loss:0.496 AVG Training Acc 80.78 % AVG Validation Acc 79.30 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.443 AVG Validation Loss:0.498 AVG Training Acc 81.11 % AVG Validation Acc 79.17 %\n",
      "Epoch:90/200 AVG Training Loss:0.441 AVG Validation Loss:0.497 AVG Training Acc 81.16 % AVG Validation Acc 79.17 %\n",
      "Epoch:100/200 AVG Training Loss:0.443 AVG Validation Loss:0.497 AVG Training Acc 81.05 % AVG Validation Acc 79.17 %\n",
      "Epoch:110/200 AVG Training Loss:0.441 AVG Validation Loss:0.499 AVG Training Acc 81.10 % AVG Validation Acc 79.03 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.443 AVG Validation Loss:0.498 AVG Training Acc 81.08 % AVG Validation Acc 79.03 %\n",
      "Epoch:130/200 AVG Training Loss:0.442 AVG Validation Loss:0.499 AVG Training Acc 81.11 % AVG Validation Acc 79.03 %\n",
      "Epoch:140/200 AVG Training Loss:0.443 AVG Validation Loss:0.499 AVG Training Acc 80.83 % AVG Validation Acc 79.03 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.442 AVG Validation Loss:0.498 AVG Training Acc 81.17 % AVG Validation Acc 79.30 %\n",
      "Epoch:160/200 AVG Training Loss:0.443 AVG Validation Loss:0.498 AVG Training Acc 81.10 % AVG Validation Acc 79.44 %\n",
      "Epoch:170/200 AVG Training Loss:0.444 AVG Validation Loss:0.496 AVG Training Acc 81.10 % AVG Validation Acc 79.30 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.442 AVG Validation Loss:0.498 AVG Training Acc 81.22 % AVG Validation Acc 79.17 %\n",
      "Epoch:190/200 AVG Training Loss:0.442 AVG Validation Loss:0.499 AVG Training Acc 81.10 % AVG Validation Acc 79.03 %\n",
      "Epoch:200/200 AVG Training Loss:0.441 AVG Validation Loss:0.496 AVG Training Acc 81.13 % AVG Validation Acc 78.76 %\n",
      "Split 34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0f119044bf442a7a683391d2c376175",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 79.84 % AVG Validation Acc 79.97 %\n",
      "Epoch:20/200 AVG Training Loss:0.471 AVG Validation Loss:0.474 AVG Training Acc 79.95 % AVG Validation Acc 80.11 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.450 AVG Validation Loss:0.488 AVG Training Acc 80.68 % AVG Validation Acc 78.76 %\n",
      "Epoch:40/200 AVG Training Loss:0.424 AVG Validation Loss:0.505 AVG Training Acc 81.16 % AVG Validation Acc 77.82 %\n",
      "Epoch:50/200 AVG Training Loss:0.403 AVG Validation Loss:0.551 AVG Training Acc 81.74 % AVG Validation Acc 77.28 %\n",
      "Epoch:60/200 AVG Training Loss:0.394 AVG Validation Loss:0.572 AVG Training Acc 82.11 % AVG Validation Acc 77.28 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.378 AVG Validation Loss:0.590 AVG Training Acc 82.95 % AVG Validation Acc 76.75 %\n",
      "Epoch:80/200 AVG Training Loss:0.376 AVG Validation Loss:0.597 AVG Training Acc 83.26 % AVG Validation Acc 76.08 %\n",
      "Epoch:90/200 AVG Training Loss:0.374 AVG Validation Loss:0.612 AVG Training Acc 82.93 % AVG Validation Acc 76.48 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.370 AVG Validation Loss:0.607 AVG Training Acc 83.34 % AVG Validation Acc 76.48 %\n",
      "Epoch:110/200 AVG Training Loss:0.372 AVG Validation Loss:0.612 AVG Training Acc 83.37 % AVG Validation Acc 76.61 %\n",
      "Epoch:120/200 AVG Training Loss:0.372 AVG Validation Loss:0.605 AVG Training Acc 83.41 % AVG Validation Acc 76.34 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.370 AVG Validation Loss:0.605 AVG Training Acc 83.35 % AVG Validation Acc 76.34 %\n",
      "Epoch:140/200 AVG Training Loss:0.372 AVG Validation Loss:0.607 AVG Training Acc 83.08 % AVG Validation Acc 76.08 %\n",
      "Epoch:150/200 AVG Training Loss:0.370 AVG Validation Loss:0.613 AVG Training Acc 83.26 % AVG Validation Acc 76.61 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.371 AVG Validation Loss:0.609 AVG Training Acc 83.55 % AVG Validation Acc 76.08 %\n",
      "Epoch:170/200 AVG Training Loss:0.369 AVG Validation Loss:0.610 AVG Training Acc 83.73 % AVG Validation Acc 76.61 %\n",
      "Epoch:180/200 AVG Training Loss:0.370 AVG Validation Loss:0.602 AVG Training Acc 83.79 % AVG Validation Acc 76.48 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.370 AVG Validation Loss:0.610 AVG Training Acc 83.35 % AVG Validation Acc 75.94 %\n",
      "Epoch:200/200 AVG Training Loss:0.369 AVG Validation Loss:0.616 AVG Training Acc 83.41 % AVG Validation Acc 76.48 %\n",
      "Split 35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca3d6d5192094565b49800961894a3d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.484 AVG Validation Loss:0.488 AVG Training Acc 79.90 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.474 AVG Validation Loss:0.491 AVG Training Acc 80.01 % AVG Validation Acc 79.84 %\n",
      "Epoch:30/200 AVG Training Loss:0.468 AVG Validation Loss:0.490 AVG Training Acc 80.14 % AVG Validation Acc 79.97 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.431 AVG Validation Loss:0.498 AVG Training Acc 81.44 % AVG Validation Acc 79.70 %\n",
      "Epoch:50/200 AVG Training Loss:0.414 AVG Validation Loss:0.509 AVG Training Acc 81.87 % AVG Validation Acc 78.09 %\n",
      "Epoch:60/200 AVG Training Loss:0.394 AVG Validation Loss:0.521 AVG Training Acc 83.05 % AVG Validation Acc 77.55 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.385 AVG Validation Loss:0.537 AVG Training Acc 83.55 % AVG Validation Acc 77.42 %\n",
      "Epoch:80/200 AVG Training Loss:0.382 AVG Validation Loss:0.544 AVG Training Acc 83.76 % AVG Validation Acc 77.42 %\n",
      "Epoch:90/200 AVG Training Loss:0.381 AVG Validation Loss:0.545 AVG Training Acc 83.76 % AVG Validation Acc 77.15 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.377 AVG Validation Loss:0.544 AVG Training Acc 83.98 % AVG Validation Acc 77.55 %\n",
      "Epoch:110/200 AVG Training Loss:0.377 AVG Validation Loss:0.543 AVG Training Acc 83.92 % AVG Validation Acc 77.02 %\n",
      "Epoch:120/200 AVG Training Loss:0.377 AVG Validation Loss:0.541 AVG Training Acc 83.70 % AVG Validation Acc 76.88 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.376 AVG Validation Loss:0.548 AVG Training Acc 83.86 % AVG Validation Acc 76.75 %\n",
      "Epoch:140/200 AVG Training Loss:0.377 AVG Validation Loss:0.547 AVG Training Acc 83.97 % AVG Validation Acc 77.28 %\n",
      "Epoch:150/200 AVG Training Loss:0.377 AVG Validation Loss:0.544 AVG Training Acc 83.86 % AVG Validation Acc 77.15 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.377 AVG Validation Loss:0.549 AVG Training Acc 84.07 % AVG Validation Acc 77.55 %\n",
      "Epoch:170/200 AVG Training Loss:0.378 AVG Validation Loss:0.545 AVG Training Acc 83.67 % AVG Validation Acc 77.28 %\n",
      "Epoch:180/200 AVG Training Loss:0.377 AVG Validation Loss:0.550 AVG Training Acc 83.98 % AVG Validation Acc 77.15 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.377 AVG Validation Loss:0.545 AVG Training Acc 83.65 % AVG Validation Acc 77.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.375 AVG Validation Loss:0.546 AVG Training Acc 83.92 % AVG Validation Acc 77.15 %\n",
      "Split 36\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fffb07257b354344916880021d64290f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 79.86 % AVG Validation Acc 79.84 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.471 AVG Validation Loss:0.478 AVG Training Acc 80.17 % AVG Validation Acc 79.97 %\n",
      "Epoch:30/200 AVG Training Loss:0.459 AVG Validation Loss:0.478 AVG Training Acc 80.22 % AVG Validation Acc 79.84 %\n",
      "Epoch:40/200 AVG Training Loss:0.452 AVG Validation Loss:0.477 AVG Training Acc 80.38 % AVG Validation Acc 79.57 %\n",
      "Epoch:50/200 AVG Training Loss:0.442 AVG Validation Loss:0.489 AVG Training Acc 80.81 % AVG Validation Acc 79.44 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.436 AVG Validation Loss:0.490 AVG Training Acc 80.84 % AVG Validation Acc 79.44 %\n",
      "Epoch:70/200 AVG Training Loss:0.433 AVG Validation Loss:0.496 AVG Training Acc 80.90 % AVG Validation Acc 79.70 %\n",
      "Epoch:80/200 AVG Training Loss:0.432 AVG Validation Loss:0.499 AVG Training Acc 80.87 % AVG Validation Acc 79.70 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.431 AVG Validation Loss:0.497 AVG Training Acc 80.99 % AVG Validation Acc 79.84 %\n",
      "Epoch:100/200 AVG Training Loss:0.430 AVG Validation Loss:0.498 AVG Training Acc 81.11 % AVG Validation Acc 79.84 %\n",
      "Epoch:110/200 AVG Training Loss:0.429 AVG Validation Loss:0.500 AVG Training Acc 80.99 % AVG Validation Acc 79.57 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.431 AVG Validation Loss:0.501 AVG Training Acc 80.92 % AVG Validation Acc 79.03 %\n",
      "Epoch:130/200 AVG Training Loss:0.429 AVG Validation Loss:0.497 AVG Training Acc 81.01 % AVG Validation Acc 79.97 %\n",
      "Epoch:140/200 AVG Training Loss:0.428 AVG Validation Loss:0.499 AVG Training Acc 80.93 % AVG Validation Acc 79.17 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.432 AVG Validation Loss:0.495 AVG Training Acc 80.93 % AVG Validation Acc 79.57 %\n",
      "Epoch:160/200 AVG Training Loss:0.431 AVG Validation Loss:0.496 AVG Training Acc 80.84 % AVG Validation Acc 79.03 %\n",
      "Epoch:170/200 AVG Training Loss:0.430 AVG Validation Loss:0.499 AVG Training Acc 80.83 % AVG Validation Acc 79.44 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.430 AVG Validation Loss:0.495 AVG Training Acc 81.08 % AVG Validation Acc 79.57 %\n",
      "Epoch:190/200 AVG Training Loss:0.431 AVG Validation Loss:0.499 AVG Training Acc 81.19 % AVG Validation Acc 79.57 %\n",
      "Epoch:200/200 AVG Training Loss:0.429 AVG Validation Loss:0.500 AVG Training Acc 81.29 % AVG Validation Acc 79.70 %\n",
      "Split 37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4281bc72ef6246fcb11f36dde5c33492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 79.65 % AVG Validation Acc 79.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.475 AVG Validation Loss:0.486 AVG Training Acc 79.68 % AVG Validation Acc 80.22 %\n",
      "Epoch:30/200 AVG Training Loss:0.462 AVG Validation Loss:0.486 AVG Training Acc 80.34 % AVG Validation Acc 80.22 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.443 AVG Validation Loss:0.503 AVG Training Acc 80.91 % AVG Validation Acc 80.08 %\n",
      "Epoch:50/200 AVG Training Loss:0.418 AVG Validation Loss:0.533 AVG Training Acc 81.37 % AVG Validation Acc 77.66 %\n",
      "Epoch:60/200 AVG Training Loss:0.403 AVG Validation Loss:0.565 AVG Training Acc 82.34 % AVG Validation Acc 78.33 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.386 AVG Validation Loss:0.580 AVG Training Acc 83.22 % AVG Validation Acc 78.47 %\n",
      "Epoch:80/200 AVG Training Loss:0.377 AVG Validation Loss:0.613 AVG Training Acc 83.56 % AVG Validation Acc 77.66 %\n",
      "Epoch:90/200 AVG Training Loss:0.377 AVG Validation Loss:0.614 AVG Training Acc 83.48 % AVG Validation Acc 77.66 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.376 AVG Validation Loss:0.633 AVG Training Acc 83.33 % AVG Validation Acc 77.25 %\n",
      "Epoch:110/200 AVG Training Loss:0.375 AVG Validation Loss:0.625 AVG Training Acc 83.34 % AVG Validation Acc 77.79 %\n",
      "Epoch:120/200 AVG Training Loss:0.378 AVG Validation Loss:0.631 AVG Training Acc 83.09 % AVG Validation Acc 77.66 %\n",
      "Epoch:130/200 AVG Training Loss:0.376 AVG Validation Loss:0.628 AVG Training Acc 83.70 % AVG Validation Acc 77.79 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.374 AVG Validation Loss:0.640 AVG Training Acc 83.42 % AVG Validation Acc 76.85 %\n",
      "Epoch:150/200 AVG Training Loss:0.378 AVG Validation Loss:0.624 AVG Training Acc 83.18 % AVG Validation Acc 77.39 %\n",
      "Epoch:160/200 AVG Training Loss:0.375 AVG Validation Loss:0.642 AVG Training Acc 83.33 % AVG Validation Acc 77.52 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.378 AVG Validation Loss:0.616 AVG Training Acc 83.33 % AVG Validation Acc 77.79 %\n",
      "Epoch:180/200 AVG Training Loss:0.377 AVG Validation Loss:0.631 AVG Training Acc 83.06 % AVG Validation Acc 77.93 %\n",
      "Epoch:190/200 AVG Training Loss:0.377 AVG Validation Loss:0.631 AVG Training Acc 83.37 % AVG Validation Acc 77.79 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.374 AVG Validation Loss:0.622 AVG Training Acc 83.62 % AVG Validation Acc 78.06 %\n",
      "Split 38\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda2926d9a3e43ba9ec45ce45975a2aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 79.80 % AVG Validation Acc 79.95 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.473 AVG Validation Loss:0.489 AVG Training Acc 80.31 % AVG Validation Acc 79.68 %\n",
      "Epoch:30/200 AVG Training Loss:0.461 AVG Validation Loss:0.492 AVG Training Acc 80.34 % AVG Validation Acc 79.54 %\n",
      "Epoch:40/200 AVG Training Loss:0.454 AVG Validation Loss:0.494 AVG Training Acc 80.85 % AVG Validation Acc 79.54 %\n",
      "Epoch:50/200 AVG Training Loss:0.448 AVG Validation Loss:0.508 AVG Training Acc 80.77 % AVG Validation Acc 78.60 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.441 AVG Validation Loss:0.510 AVG Training Acc 80.97 % AVG Validation Acc 78.20 %\n",
      "Epoch:70/200 AVG Training Loss:0.440 AVG Validation Loss:0.512 AVG Training Acc 81.08 % AVG Validation Acc 78.47 %\n",
      "Epoch:80/200 AVG Training Loss:0.442 AVG Validation Loss:0.512 AVG Training Acc 81.02 % AVG Validation Acc 78.73 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.437 AVG Validation Loss:0.512 AVG Training Acc 81.14 % AVG Validation Acc 78.60 %\n",
      "Epoch:100/200 AVG Training Loss:0.438 AVG Validation Loss:0.514 AVG Training Acc 81.34 % AVG Validation Acc 78.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.440 AVG Validation Loss:0.516 AVG Training Acc 81.34 % AVG Validation Acc 78.60 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.439 AVG Validation Loss:0.515 AVG Training Acc 81.16 % AVG Validation Acc 78.60 %\n",
      "Epoch:130/200 AVG Training Loss:0.439 AVG Validation Loss:0.514 AVG Training Acc 81.25 % AVG Validation Acc 78.60 %\n",
      "Epoch:140/200 AVG Training Loss:0.438 AVG Validation Loss:0.515 AVG Training Acc 81.13 % AVG Validation Acc 78.47 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.437 AVG Validation Loss:0.515 AVG Training Acc 81.28 % AVG Validation Acc 78.47 %\n",
      "Epoch:160/200 AVG Training Loss:0.439 AVG Validation Loss:0.514 AVG Training Acc 81.13 % AVG Validation Acc 79.27 %\n",
      "Epoch:170/200 AVG Training Loss:0.439 AVG Validation Loss:0.513 AVG Training Acc 81.25 % AVG Validation Acc 78.60 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.441 AVG Validation Loss:0.513 AVG Training Acc 81.19 % AVG Validation Acc 79.00 %\n",
      "Epoch:190/200 AVG Training Loss:0.438 AVG Validation Loss:0.515 AVG Training Acc 81.28 % AVG Validation Acc 78.87 %\n",
      "Epoch:200/200 AVG Training Loss:0.439 AVG Validation Loss:0.514 AVG Training Acc 81.29 % AVG Validation Acc 78.73 %\n",
      "Split 39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59b1df0d8a1d4b7db72824ea24475162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.484 AVG Validation Loss:0.489 AVG Training Acc 79.89 % AVG Validation Acc 79.95 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.468 AVG Validation Loss:0.479 AVG Training Acc 80.05 % AVG Validation Acc 79.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.447 AVG Validation Loss:0.482 AVG Training Acc 80.59 % AVG Validation Acc 79.68 %\n",
      "Epoch:40/200 AVG Training Loss:0.425 AVG Validation Loss:0.490 AVG Training Acc 81.37 % AVG Validation Acc 79.54 %\n",
      "Epoch:50/200 AVG Training Loss:0.412 AVG Validation Loss:0.512 AVG Training Acc 81.80 % AVG Validation Acc 78.60 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.404 AVG Validation Loss:0.515 AVG Training Acc 82.21 % AVG Validation Acc 79.00 %\n",
      "Epoch:70/200 AVG Training Loss:0.398 AVG Validation Loss:0.516 AVG Training Acc 82.50 % AVG Validation Acc 78.20 %\n",
      "Epoch:80/200 AVG Training Loss:0.398 AVG Validation Loss:0.519 AVG Training Acc 82.44 % AVG Validation Acc 78.60 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.395 AVG Validation Loss:0.523 AVG Training Acc 82.95 % AVG Validation Acc 77.93 %\n",
      "Epoch:100/200 AVG Training Loss:0.397 AVG Validation Loss:0.520 AVG Training Acc 82.67 % AVG Validation Acc 78.20 %\n",
      "Epoch:110/200 AVG Training Loss:0.394 AVG Validation Loss:0.524 AVG Training Acc 82.41 % AVG Validation Acc 77.93 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.394 AVG Validation Loss:0.521 AVG Training Acc 82.40 % AVG Validation Acc 77.66 %\n",
      "Epoch:130/200 AVG Training Loss:0.393 AVG Validation Loss:0.522 AVG Training Acc 82.68 % AVG Validation Acc 78.20 %\n",
      "Epoch:140/200 AVG Training Loss:0.392 AVG Validation Loss:0.523 AVG Training Acc 82.89 % AVG Validation Acc 77.93 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.394 AVG Validation Loss:0.523 AVG Training Acc 82.68 % AVG Validation Acc 77.93 %\n",
      "Epoch:160/200 AVG Training Loss:0.392 AVG Validation Loss:0.526 AVG Training Acc 82.85 % AVG Validation Acc 78.06 %\n",
      "Epoch:170/200 AVG Training Loss:0.396 AVG Validation Loss:0.526 AVG Training Acc 82.55 % AVG Validation Acc 78.06 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.393 AVG Validation Loss:0.519 AVG Training Acc 82.92 % AVG Validation Acc 77.79 %\n",
      "Epoch:190/200 AVG Training Loss:0.393 AVG Validation Loss:0.525 AVG Training Acc 83.03 % AVG Validation Acc 78.06 %\n",
      "Epoch:200/200 AVG Training Loss:0.393 AVG Validation Loss:0.522 AVG Training Acc 82.77 % AVG Validation Acc 78.47 %\n",
      "Split 40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b47d698dfd4d5e949ad7ad1bb66022",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.487 AVG Validation Loss:0.480 AVG Training Acc 79.90 % AVG Validation Acc 79.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.485 AVG Validation Loss:0.478 AVG Training Acc 80.01 % AVG Validation Acc 79.95 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.462 AVG Validation Loss:0.467 AVG Training Acc 80.02 % AVG Validation Acc 79.68 %\n",
      "Epoch:40/200 AVG Training Loss:0.452 AVG Validation Loss:0.472 AVG Training Acc 80.43 % AVG Validation Acc 79.54 %\n",
      "Epoch:50/200 AVG Training Loss:0.447 AVG Validation Loss:0.474 AVG Training Acc 80.46 % AVG Validation Acc 79.41 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.436 AVG Validation Loss:0.476 AVG Training Acc 80.64 % AVG Validation Acc 79.81 %\n",
      "Epoch:70/200 AVG Training Loss:0.435 AVG Validation Loss:0.480 AVG Training Acc 80.59 % AVG Validation Acc 80.08 %\n",
      "Epoch:80/200 AVG Training Loss:0.435 AVG Validation Loss:0.479 AVG Training Acc 80.80 % AVG Validation Acc 79.54 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.432 AVG Validation Loss:0.479 AVG Training Acc 80.82 % AVG Validation Acc 79.81 %\n",
      "Epoch:100/200 AVG Training Loss:0.433 AVG Validation Loss:0.480 AVG Training Acc 81.10 % AVG Validation Acc 79.81 %\n",
      "Epoch:110/200 AVG Training Loss:0.435 AVG Validation Loss:0.482 AVG Training Acc 80.91 % AVG Validation Acc 79.68 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.434 AVG Validation Loss:0.480 AVG Training Acc 81.04 % AVG Validation Acc 79.54 %\n",
      "Epoch:130/200 AVG Training Loss:0.433 AVG Validation Loss:0.480 AVG Training Acc 80.94 % AVG Validation Acc 80.08 %\n",
      "Epoch:140/200 AVG Training Loss:0.434 AVG Validation Loss:0.481 AVG Training Acc 80.74 % AVG Validation Acc 79.54 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.432 AVG Validation Loss:0.481 AVG Training Acc 80.98 % AVG Validation Acc 79.81 %\n",
      "Epoch:160/200 AVG Training Loss:0.434 AVG Validation Loss:0.479 AVG Training Acc 80.86 % AVG Validation Acc 79.27 %\n",
      "Epoch:170/200 AVG Training Loss:0.432 AVG Validation Loss:0.481 AVG Training Acc 80.58 % AVG Validation Acc 79.54 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.432 AVG Validation Loss:0.481 AVG Training Acc 81.02 % AVG Validation Acc 79.41 %\n",
      "Epoch:190/200 AVG Training Loss:0.432 AVG Validation Loss:0.483 AVG Training Acc 80.88 % AVG Validation Acc 79.27 %\n",
      "Epoch:200/200 AVG Training Loss:0.433 AVG Validation Loss:0.482 AVG Training Acc 80.80 % AVG Validation Acc 79.41 %\n",
      "Split 41\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "552f9052673d499fb1cc20e926e7f29b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.485 AVG Validation Loss:0.483 AVG Training Acc 79.84 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.473 AVG Validation Loss:0.480 AVG Training Acc 79.93 % AVG Validation Acc 79.57 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.454 AVG Validation Loss:0.488 AVG Training Acc 80.44 % AVG Validation Acc 79.30 %\n",
      "Epoch:40/200 AVG Training Loss:0.442 AVG Validation Loss:0.508 AVG Training Acc 81.16 % AVG Validation Acc 78.23 %\n",
      "Epoch:50/200 AVG Training Loss:0.432 AVG Validation Loss:0.517 AVG Training Acc 81.16 % AVG Validation Acc 78.49 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.419 AVG Validation Loss:0.546 AVG Training Acc 81.59 % AVG Validation Acc 78.36 %\n",
      "Epoch:70/200 AVG Training Loss:0.417 AVG Validation Loss:0.549 AVG Training Acc 82.17 % AVG Validation Acc 78.49 %\n",
      "Epoch:80/200 AVG Training Loss:0.417 AVG Validation Loss:0.554 AVG Training Acc 81.81 % AVG Validation Acc 78.36 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.416 AVG Validation Loss:0.557 AVG Training Acc 81.86 % AVG Validation Acc 77.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.416 AVG Validation Loss:0.558 AVG Training Acc 82.04 % AVG Validation Acc 78.09 %\n",
      "Epoch:110/200 AVG Training Loss:0.414 AVG Validation Loss:0.558 AVG Training Acc 81.96 % AVG Validation Acc 78.49 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.415 AVG Validation Loss:0.559 AVG Training Acc 81.86 % AVG Validation Acc 78.49 %\n",
      "Epoch:130/200 AVG Training Loss:0.415 AVG Validation Loss:0.556 AVG Training Acc 82.08 % AVG Validation Acc 78.36 %\n",
      "Epoch:140/200 AVG Training Loss:0.414 AVG Validation Loss:0.556 AVG Training Acc 81.99 % AVG Validation Acc 77.96 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.415 AVG Validation Loss:0.558 AVG Training Acc 82.10 % AVG Validation Acc 78.36 %\n",
      "Epoch:160/200 AVG Training Loss:0.417 AVG Validation Loss:0.559 AVG Training Acc 82.01 % AVG Validation Acc 78.49 %\n",
      "Epoch:170/200 AVG Training Loss:0.415 AVG Validation Loss:0.555 AVG Training Acc 81.80 % AVG Validation Acc 78.49 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.412 AVG Validation Loss:0.557 AVG Training Acc 82.17 % AVG Validation Acc 78.09 %\n",
      "Epoch:190/200 AVG Training Loss:0.415 AVG Validation Loss:0.558 AVG Training Acc 81.83 % AVG Validation Acc 78.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.414 AVG Validation Loss:0.554 AVG Training Acc 82.01 % AVG Validation Acc 78.36 %\n",
      "Split 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd340215a6a742918df4a175f6841684",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.483 AVG Validation Loss:0.496 AVG Training Acc 79.71 % AVG Validation Acc 79.70 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.463 AVG Validation Loss:0.500 AVG Training Acc 79.95 % AVG Validation Acc 79.70 %\n",
      "Epoch:30/200 AVG Training Loss:0.454 AVG Validation Loss:0.514 AVG Training Acc 80.13 % AVG Validation Acc 79.57 %\n",
      "Epoch:40/200 AVG Training Loss:0.445 AVG Validation Loss:0.522 AVG Training Acc 80.16 % AVG Validation Acc 79.44 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.435 AVG Validation Loss:0.540 AVG Training Acc 80.80 % AVG Validation Acc 78.76 %\n",
      "Epoch:60/200 AVG Training Loss:0.431 AVG Validation Loss:0.544 AVG Training Acc 80.50 % AVG Validation Acc 78.63 %\n",
      "Epoch:70/200 AVG Training Loss:0.428 AVG Validation Loss:0.546 AVG Training Acc 80.68 % AVG Validation Acc 78.76 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.425 AVG Validation Loss:0.549 AVG Training Acc 80.69 % AVG Validation Acc 78.76 %\n",
      "Epoch:90/200 AVG Training Loss:0.427 AVG Validation Loss:0.558 AVG Training Acc 80.45 % AVG Validation Acc 78.90 %\n",
      "Epoch:100/200 AVG Training Loss:0.423 AVG Validation Loss:0.560 AVG Training Acc 80.95 % AVG Validation Acc 78.90 %\n",
      "Epoch:110/200 AVG Training Loss:0.426 AVG Validation Loss:0.552 AVG Training Acc 80.86 % AVG Validation Acc 78.90 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.424 AVG Validation Loss:0.551 AVG Training Acc 80.89 % AVG Validation Acc 78.90 %\n",
      "Epoch:130/200 AVG Training Loss:0.424 AVG Validation Loss:0.551 AVG Training Acc 80.63 % AVG Validation Acc 78.76 %\n",
      "Epoch:140/200 AVG Training Loss:0.424 AVG Validation Loss:0.550 AVG Training Acc 81.16 % AVG Validation Acc 78.90 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.425 AVG Validation Loss:0.550 AVG Training Acc 80.53 % AVG Validation Acc 78.63 %\n",
      "Epoch:160/200 AVG Training Loss:0.426 AVG Validation Loss:0.551 AVG Training Acc 80.44 % AVG Validation Acc 78.76 %\n",
      "Epoch:170/200 AVG Training Loss:0.425 AVG Validation Loss:0.551 AVG Training Acc 80.57 % AVG Validation Acc 78.90 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.423 AVG Validation Loss:0.551 AVG Training Acc 80.93 % AVG Validation Acc 78.76 %\n",
      "Epoch:190/200 AVG Training Loss:0.424 AVG Validation Loss:0.551 AVG Training Acc 80.93 % AVG Validation Acc 78.76 %\n",
      "Epoch:200/200 AVG Training Loss:0.423 AVG Validation Loss:0.550 AVG Training Acc 80.89 % AVG Validation Acc 78.76 %\n",
      "Split 43\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0229b3f3710a4c178a25e081703fb8aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.484 AVG Validation Loss:0.490 AVG Training Acc 79.84 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.472 AVG Validation Loss:0.469 AVG Training Acc 79.80 % AVG Validation Acc 80.11 %\n",
      "Epoch:30/200 AVG Training Loss:0.461 AVG Validation Loss:0.478 AVG Training Acc 80.33 % AVG Validation Acc 80.24 %\n",
      "Epoch:40/200 AVG Training Loss:0.452 AVG Validation Loss:0.469 AVG Training Acc 80.38 % AVG Validation Acc 80.24 %\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.416 AVG Validation Loss:0.472 AVG Training Acc 81.35 % AVG Validation Acc 80.38 %\n",
      "Epoch:60/200 AVG Training Loss:0.400 AVG Validation Loss:0.489 AVG Training Acc 82.17 % AVG Validation Acc 79.44 %\n",
      "Epoch:70/200 AVG Training Loss:0.385 AVG Validation Loss:0.502 AVG Training Acc 82.80 % AVG Validation Acc 79.70 %\n",
      "Epoch    71: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.376 AVG Validation Loss:0.509 AVG Training Acc 83.13 % AVG Validation Acc 79.03 %\n",
      "Epoch:90/200 AVG Training Loss:0.374 AVG Validation Loss:0.508 AVG Training Acc 83.07 % AVG Validation Acc 79.70 %\n",
      "Epoch:100/200 AVG Training Loss:0.371 AVG Validation Loss:0.513 AVG Training Acc 82.92 % AVG Validation Acc 79.84 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.370 AVG Validation Loss:0.514 AVG Training Acc 83.34 % AVG Validation Acc 79.44 %\n",
      "Epoch:120/200 AVG Training Loss:0.370 AVG Validation Loss:0.508 AVG Training Acc 83.10 % AVG Validation Acc 79.44 %\n",
      "Epoch:130/200 AVG Training Loss:0.366 AVG Validation Loss:0.512 AVG Training Acc 83.67 % AVG Validation Acc 79.84 %\n",
      "Epoch   133: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.369 AVG Validation Loss:0.510 AVG Training Acc 83.11 % AVG Validation Acc 80.11 %\n",
      "Epoch:150/200 AVG Training Loss:0.369 AVG Validation Loss:0.519 AVG Training Acc 83.16 % AVG Validation Acc 79.44 %\n",
      "Epoch:160/200 AVG Training Loss:0.368 AVG Validation Loss:0.512 AVG Training Acc 83.41 % AVG Validation Acc 79.57 %\n",
      "Epoch   164: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.370 AVG Validation Loss:0.514 AVG Training Acc 82.89 % AVG Validation Acc 79.17 %\n",
      "Epoch:180/200 AVG Training Loss:0.370 AVG Validation Loss:0.507 AVG Training Acc 83.17 % AVG Validation Acc 79.57 %\n",
      "Epoch:190/200 AVG Training Loss:0.369 AVG Validation Loss:0.512 AVG Training Acc 83.22 % AVG Validation Acc 79.57 %\n",
      "Epoch   195: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.371 AVG Validation Loss:0.506 AVG Training Acc 82.70 % AVG Validation Acc 79.70 %\n",
      "Split 44\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6deb8e4149de400b9347bd0e20709f63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 79.75 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.471 AVG Validation Loss:0.492 AVG Training Acc 80.17 % AVG Validation Acc 80.24 %\n",
      "Epoch:30/200 AVG Training Loss:0.461 AVG Validation Loss:0.488 AVG Training Acc 80.42 % AVG Validation Acc 80.11 %\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.450 AVG Validation Loss:0.505 AVG Training Acc 80.72 % AVG Validation Acc 80.11 %\n",
      "Epoch:50/200 AVG Training Loss:0.409 AVG Validation Loss:0.520 AVG Training Acc 81.84 % AVG Validation Acc 79.30 %\n",
      "Epoch:60/200 AVG Training Loss:0.390 AVG Validation Loss:0.546 AVG Training Acc 83.10 % AVG Validation Acc 78.90 %\n",
      "Epoch:70/200 AVG Training Loss:0.377 AVG Validation Loss:0.574 AVG Training Acc 83.35 % AVG Validation Acc 78.09 %\n",
      "Epoch    70: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.363 AVG Validation Loss:0.582 AVG Training Acc 83.67 % AVG Validation Acc 78.23 %\n",
      "Epoch:90/200 AVG Training Loss:0.363 AVG Validation Loss:0.588 AVG Training Acc 83.41 % AVG Validation Acc 77.02 %\n",
      "Epoch:100/200 AVG Training Loss:0.357 AVG Validation Loss:0.601 AVG Training Acc 83.97 % AVG Validation Acc 77.28 %\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.357 AVG Validation Loss:0.597 AVG Training Acc 83.91 % AVG Validation Acc 77.55 %\n",
      "Epoch:120/200 AVG Training Loss:0.356 AVG Validation Loss:0.599 AVG Training Acc 84.18 % AVG Validation Acc 77.28 %\n",
      "Epoch:130/200 AVG Training Loss:0.356 AVG Validation Loss:0.605 AVG Training Acc 84.41 % AVG Validation Acc 77.55 %\n",
      "Epoch   132: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.356 AVG Validation Loss:0.603 AVG Training Acc 83.92 % AVG Validation Acc 77.28 %\n",
      "Epoch:150/200 AVG Training Loss:0.358 AVG Validation Loss:0.603 AVG Training Acc 83.76 % AVG Validation Acc 77.28 %\n",
      "Epoch:160/200 AVG Training Loss:0.355 AVG Validation Loss:0.599 AVG Training Acc 84.13 % AVG Validation Acc 77.55 %\n",
      "Epoch   163: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.353 AVG Validation Loss:0.601 AVG Training Acc 84.18 % AVG Validation Acc 77.42 %\n",
      "Epoch:180/200 AVG Training Loss:0.357 AVG Validation Loss:0.600 AVG Training Acc 84.15 % AVG Validation Acc 77.42 %\n",
      "Epoch:190/200 AVG Training Loss:0.358 AVG Validation Loss:0.599 AVG Training Acc 84.03 % AVG Validation Acc 77.82 %\n",
      "Epoch   194: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.358 AVG Validation Loss:0.602 AVG Training Acc 84.22 % AVG Validation Acc 77.42 %\n",
      "Split 45\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a89a040c424aeea70111075e7cb4c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.485 AVG Validation Loss:0.491 AVG Training Acc 79.87 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.476 AVG Validation Loss:0.486 AVG Training Acc 79.77 % AVG Validation Acc 79.84 %\n",
      "Epoch:30/200 AVG Training Loss:0.467 AVG Validation Loss:0.486 AVG Training Acc 79.81 % AVG Validation Acc 79.84 %\n",
      "Epoch:40/200 AVG Training Loss:0.451 AVG Validation Loss:0.485 AVG Training Acc 80.33 % AVG Validation Acc 79.97 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.412 AVG Validation Loss:0.515 AVG Training Acc 81.43 % AVG Validation Acc 79.03 %\n",
      "Epoch:60/200 AVG Training Loss:0.388 AVG Validation Loss:0.582 AVG Training Acc 82.58 % AVG Validation Acc 79.17 %\n",
      "Epoch:70/200 AVG Training Loss:0.371 AVG Validation Loss:0.639 AVG Training Acc 82.99 % AVG Validation Acc 77.69 %\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.356 AVG Validation Loss:0.672 AVG Training Acc 83.55 % AVG Validation Acc 77.42 %\n",
      "Epoch:90/200 AVG Training Loss:0.358 AVG Validation Loss:0.666 AVG Training Acc 83.29 % AVG Validation Acc 77.42 %\n",
      "Epoch:100/200 AVG Training Loss:0.355 AVG Validation Loss:0.665 AVG Training Acc 83.52 % AVG Validation Acc 77.28 %\n",
      "Epoch   104: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.352 AVG Validation Loss:0.687 AVG Training Acc 83.61 % AVG Validation Acc 76.88 %\n",
      "Epoch:120/200 AVG Training Loss:0.352 AVG Validation Loss:0.690 AVG Training Acc 83.65 % AVG Validation Acc 77.42 %\n",
      "Epoch:130/200 AVG Training Loss:0.349 AVG Validation Loss:0.690 AVG Training Acc 83.71 % AVG Validation Acc 77.02 %\n",
      "Epoch   135: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.345 AVG Validation Loss:0.684 AVG Training Acc 84.34 % AVG Validation Acc 77.42 %\n",
      "Epoch:150/200 AVG Training Loss:0.351 AVG Validation Loss:0.694 AVG Training Acc 83.43 % AVG Validation Acc 76.48 %\n",
      "Epoch:160/200 AVG Training Loss:0.347 AVG Validation Loss:0.692 AVG Training Acc 83.92 % AVG Validation Acc 76.61 %\n",
      "Epoch   166: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.349 AVG Validation Loss:0.693 AVG Training Acc 84.03 % AVG Validation Acc 77.15 %\n",
      "Epoch:180/200 AVG Training Loss:0.352 AVG Validation Loss:0.677 AVG Training Acc 83.71 % AVG Validation Acc 77.42 %\n",
      "Epoch:190/200 AVG Training Loss:0.352 AVG Validation Loss:0.677 AVG Training Acc 83.25 % AVG Validation Acc 77.28 %\n",
      "Epoch   197: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.350 AVG Validation Loss:0.689 AVG Training Acc 83.62 % AVG Validation Acc 77.15 %\n",
      "Split 46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f4f3fff5907427b98155f6d71c8c4f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.483 AVG Validation Loss:0.480 AVG Training Acc 79.93 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.477 AVG Validation Loss:0.491 AVG Training Acc 79.84 % AVG Validation Acc 79.70 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.458 AVG Validation Loss:0.489 AVG Training Acc 80.26 % AVG Validation Acc 79.57 %\n",
      "Epoch:40/200 AVG Training Loss:0.450 AVG Validation Loss:0.497 AVG Training Acc 80.30 % AVG Validation Acc 79.44 %\n",
      "Epoch:50/200 AVG Training Loss:0.440 AVG Validation Loss:0.504 AVG Training Acc 80.57 % AVG Validation Acc 79.44 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.431 AVG Validation Loss:0.514 AVG Training Acc 81.20 % AVG Validation Acc 79.44 %\n",
      "Epoch:70/200 AVG Training Loss:0.432 AVG Validation Loss:0.512 AVG Training Acc 81.14 % AVG Validation Acc 79.44 %\n",
      "Epoch:80/200 AVG Training Loss:0.428 AVG Validation Loss:0.520 AVG Training Acc 81.46 % AVG Validation Acc 79.30 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.429 AVG Validation Loss:0.517 AVG Training Acc 81.40 % AVG Validation Acc 79.03 %\n",
      "Epoch:100/200 AVG Training Loss:0.426 AVG Validation Loss:0.518 AVG Training Acc 81.69 % AVG Validation Acc 79.57 %\n",
      "Epoch:110/200 AVG Training Loss:0.427 AVG Validation Loss:0.521 AVG Training Acc 81.41 % AVG Validation Acc 79.44 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.429 AVG Validation Loss:0.519 AVG Training Acc 81.13 % AVG Validation Acc 79.44 %\n",
      "Epoch:130/200 AVG Training Loss:0.426 AVG Validation Loss:0.520 AVG Training Acc 81.55 % AVG Validation Acc 79.44 %\n",
      "Epoch:140/200 AVG Training Loss:0.428 AVG Validation Loss:0.523 AVG Training Acc 81.46 % AVG Validation Acc 79.44 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.428 AVG Validation Loss:0.521 AVG Training Acc 81.55 % AVG Validation Acc 79.30 %\n",
      "Epoch:160/200 AVG Training Loss:0.428 AVG Validation Loss:0.518 AVG Training Acc 81.40 % AVG Validation Acc 79.57 %\n",
      "Epoch:170/200 AVG Training Loss:0.430 AVG Validation Loss:0.521 AVG Training Acc 81.43 % AVG Validation Acc 79.30 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.427 AVG Validation Loss:0.518 AVG Training Acc 81.60 % AVG Validation Acc 79.57 %\n",
      "Epoch:190/200 AVG Training Loss:0.427 AVG Validation Loss:0.515 AVG Training Acc 81.38 % AVG Validation Acc 79.30 %\n",
      "Epoch:200/200 AVG Training Loss:0.429 AVG Validation Loss:0.520 AVG Training Acc 81.25 % AVG Validation Acc 79.03 %\n",
      "Split 47\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fda465829bea4e02926c71f4329b5a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.483 AVG Validation Loss:0.479 AVG Training Acc 79.78 % AVG Validation Acc 80.08 %\n",
      "Epoch:20/200 AVG Training Loss:0.471 AVG Validation Loss:0.484 AVG Training Acc 79.89 % AVG Validation Acc 80.35 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.447 AVG Validation Loss:0.482 AVG Training Acc 80.38 % AVG Validation Acc 80.22 %\n",
      "Epoch:40/200 AVG Training Loss:0.434 AVG Validation Loss:0.492 AVG Training Acc 80.74 % AVG Validation Acc 79.95 %\n",
      "Epoch:50/200 AVG Training Loss:0.424 AVG Validation Loss:0.507 AVG Training Acc 80.94 % AVG Validation Acc 79.41 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.409 AVG Validation Loss:0.512 AVG Training Acc 81.68 % AVG Validation Acc 79.68 %\n",
      "Epoch:70/200 AVG Training Loss:0.408 AVG Validation Loss:0.523 AVG Training Acc 81.44 % AVG Validation Acc 79.27 %\n",
      "Epoch:80/200 AVG Training Loss:0.404 AVG Validation Loss:0.529 AVG Training Acc 82.01 % AVG Validation Acc 78.33 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.403 AVG Validation Loss:0.536 AVG Training Acc 82.09 % AVG Validation Acc 78.87 %\n",
      "Epoch:100/200 AVG Training Loss:0.403 AVG Validation Loss:0.538 AVG Training Acc 81.82 % AVG Validation Acc 78.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.397 AVG Validation Loss:0.531 AVG Training Acc 82.25 % AVG Validation Acc 78.60 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.404 AVG Validation Loss:0.532 AVG Training Acc 81.85 % AVG Validation Acc 78.73 %\n",
      "Epoch:130/200 AVG Training Loss:0.399 AVG Validation Loss:0.537 AVG Training Acc 82.01 % AVG Validation Acc 78.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.400 AVG Validation Loss:0.533 AVG Training Acc 82.04 % AVG Validation Acc 79.14 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.399 AVG Validation Loss:0.545 AVG Training Acc 82.12 % AVG Validation Acc 79.00 %\n",
      "Epoch:160/200 AVG Training Loss:0.401 AVG Validation Loss:0.535 AVG Training Acc 82.24 % AVG Validation Acc 78.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.397 AVG Validation Loss:0.538 AVG Training Acc 82.43 % AVG Validation Acc 79.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.400 AVG Validation Loss:0.536 AVG Training Acc 81.82 % AVG Validation Acc 78.47 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.401 AVG Validation Loss:0.551 AVG Training Acc 82.01 % AVG Validation Acc 78.60 %\n",
      "Epoch:200/200 AVG Training Loss:0.399 AVG Validation Loss:0.537 AVG Training Acc 82.06 % AVG Validation Acc 78.60 %\n",
      "Split 48\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25c6edaf186e4124b4a38aea94596a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.483 AVG Validation Loss:0.493 AVG Training Acc 79.77 % AVG Validation Acc 79.81 %\n",
      "Epoch:20/200 AVG Training Loss:0.473 AVG Validation Loss:0.482 AVG Training Acc 79.83 % AVG Validation Acc 79.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.484 AVG Validation Loss:0.482 AVG Training Acc 79.73 % AVG Validation Acc 79.95 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.442 AVG Validation Loss:0.494 AVG Training Acc 80.76 % AVG Validation Acc 79.41 %\n",
      "Epoch:50/200 AVG Training Loss:0.421 AVG Validation Loss:0.512 AVG Training Acc 81.95 % AVG Validation Acc 78.73 %\n",
      "Epoch:60/200 AVG Training Loss:0.402 AVG Validation Loss:0.551 AVG Training Acc 82.27 % AVG Validation Acc 79.00 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.388 AVG Validation Loss:0.564 AVG Training Acc 83.15 % AVG Validation Acc 77.39 %\n",
      "Epoch:80/200 AVG Training Loss:0.382 AVG Validation Loss:0.565 AVG Training Acc 82.97 % AVG Validation Acc 77.52 %\n",
      "Epoch:90/200 AVG Training Loss:0.382 AVG Validation Loss:0.566 AVG Training Acc 83.22 % AVG Validation Acc 77.25 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.382 AVG Validation Loss:0.576 AVG Training Acc 83.28 % AVG Validation Acc 77.52 %\n",
      "Epoch:110/200 AVG Training Loss:0.378 AVG Validation Loss:0.571 AVG Training Acc 83.39 % AVG Validation Acc 77.25 %\n",
      "Epoch:120/200 AVG Training Loss:0.380 AVG Validation Loss:0.572 AVG Training Acc 83.28 % AVG Validation Acc 77.39 %\n",
      "Epoch:130/200 AVG Training Loss:0.380 AVG Validation Loss:0.572 AVG Training Acc 83.40 % AVG Validation Acc 77.66 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.377 AVG Validation Loss:0.581 AVG Training Acc 83.12 % AVG Validation Acc 77.66 %\n",
      "Epoch:150/200 AVG Training Loss:0.379 AVG Validation Loss:0.574 AVG Training Acc 83.34 % AVG Validation Acc 77.66 %\n",
      "Epoch:160/200 AVG Training Loss:0.378 AVG Validation Loss:0.571 AVG Training Acc 83.13 % AVG Validation Acc 78.06 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.376 AVG Validation Loss:0.575 AVG Training Acc 83.45 % AVG Validation Acc 77.12 %\n",
      "Epoch:180/200 AVG Training Loss:0.380 AVG Validation Loss:0.575 AVG Training Acc 83.27 % AVG Validation Acc 77.66 %\n",
      "Epoch:190/200 AVG Training Loss:0.379 AVG Validation Loss:0.584 AVG Training Acc 83.48 % AVG Validation Acc 77.25 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.379 AVG Validation Loss:0.570 AVG Training Acc 83.45 % AVG Validation Acc 77.66 %\n",
      "Split 49\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f34dff4f1d74eb8b118db443c826122",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.483 AVG Validation Loss:0.489 AVG Training Acc 79.80 % AVG Validation Acc 79.81 %\n",
      "Epoch:20/200 AVG Training Loss:0.469 AVG Validation Loss:0.481 AVG Training Acc 80.14 % AVG Validation Acc 79.68 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.441 AVG Validation Loss:0.483 AVG Training Acc 80.94 % AVG Validation Acc 79.68 %\n",
      "Epoch:40/200 AVG Training Loss:0.411 AVG Validation Loss:0.515 AVG Training Acc 81.95 % AVG Validation Acc 78.20 %\n",
      "Epoch:50/200 AVG Training Loss:0.389 AVG Validation Loss:0.543 AVG Training Acc 82.83 % AVG Validation Acc 77.12 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.362 AVG Validation Loss:0.587 AVG Training Acc 83.91 % AVG Validation Acc 76.72 %\n",
      "Epoch:70/200 AVG Training Loss:0.360 AVG Validation Loss:0.593 AVG Training Acc 84.06 % AVG Validation Acc 76.31 %\n",
      "Epoch:80/200 AVG Training Loss:0.352 AVG Validation Loss:0.598 AVG Training Acc 84.13 % AVG Validation Acc 76.31 %\n",
      "Epoch:90/200 AVG Training Loss:0.355 AVG Validation Loss:0.610 AVG Training Acc 84.28 % AVG Validation Acc 75.91 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.353 AVG Validation Loss:0.603 AVG Training Acc 84.09 % AVG Validation Acc 76.18 %\n",
      "Epoch:110/200 AVG Training Loss:0.354 AVG Validation Loss:0.605 AVG Training Acc 84.10 % AVG Validation Acc 76.58 %\n",
      "Epoch:120/200 AVG Training Loss:0.348 AVG Validation Loss:0.596 AVG Training Acc 84.15 % AVG Validation Acc 76.18 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.353 AVG Validation Loss:0.608 AVG Training Acc 84.54 % AVG Validation Acc 76.72 %\n",
      "Epoch:140/200 AVG Training Loss:0.347 AVG Validation Loss:0.605 AVG Training Acc 84.13 % AVG Validation Acc 76.18 %\n",
      "Epoch:150/200 AVG Training Loss:0.350 AVG Validation Loss:0.600 AVG Training Acc 84.28 % AVG Validation Acc 76.85 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.351 AVG Validation Loss:0.610 AVG Training Acc 84.22 % AVG Validation Acc 76.18 %\n",
      "Epoch:170/200 AVG Training Loss:0.350 AVG Validation Loss:0.600 AVG Training Acc 84.28 % AVG Validation Acc 76.72 %\n",
      "Epoch:180/200 AVG Training Loss:0.349 AVG Validation Loss:0.606 AVG Training Acc 84.73 % AVG Validation Acc 76.31 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.348 AVG Validation Loss:0.602 AVG Training Acc 84.18 % AVG Validation Acc 76.31 %\n",
      "Epoch:200/200 AVG Training Loss:0.348 AVG Validation Loss:0.606 AVG Training Acc 84.34 % AVG Validation Acc 76.04 %\n",
      "Split 50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46eb4219912642daa25263e0203756e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.483 AVG Validation Loss:0.492 AVG Training Acc 79.84 % AVG Validation Acc 79.81 %\n",
      "Epoch:20/200 AVG Training Loss:0.472 AVG Validation Loss:0.482 AVG Training Acc 80.19 % AVG Validation Acc 79.54 %\n",
      "Epoch:30/200 AVG Training Loss:0.464 AVG Validation Loss:0.497 AVG Training Acc 80.38 % AVG Validation Acc 79.27 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.437 AVG Validation Loss:0.518 AVG Training Acc 81.14 % AVG Validation Acc 78.87 %\n",
      "Epoch:50/200 AVG Training Loss:0.423 AVG Validation Loss:0.548 AVG Training Acc 81.74 % AVG Validation Acc 78.20 %\n",
      "Epoch:60/200 AVG Training Loss:0.415 AVG Validation Loss:0.570 AVG Training Acc 81.73 % AVG Validation Acc 78.20 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.406 AVG Validation Loss:0.572 AVG Training Acc 82.34 % AVG Validation Acc 78.73 %\n",
      "Epoch:80/200 AVG Training Loss:0.403 AVG Validation Loss:0.578 AVG Training Acc 82.22 % AVG Validation Acc 78.73 %\n",
      "Epoch:90/200 AVG Training Loss:0.403 AVG Validation Loss:0.587 AVG Training Acc 82.67 % AVG Validation Acc 78.47 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.403 AVG Validation Loss:0.579 AVG Training Acc 82.41 % AVG Validation Acc 79.27 %\n",
      "Epoch:110/200 AVG Training Loss:0.398 AVG Validation Loss:0.580 AVG Training Acc 82.65 % AVG Validation Acc 78.87 %\n",
      "Epoch:120/200 AVG Training Loss:0.399 AVG Validation Loss:0.582 AVG Training Acc 82.98 % AVG Validation Acc 78.87 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.398 AVG Validation Loss:0.574 AVG Training Acc 82.38 % AVG Validation Acc 79.00 %\n",
      "Epoch:140/200 AVG Training Loss:0.401 AVG Validation Loss:0.579 AVG Training Acc 82.28 % AVG Validation Acc 78.73 %\n",
      "Epoch:150/200 AVG Training Loss:0.397 AVG Validation Loss:0.584 AVG Training Acc 82.24 % AVG Validation Acc 78.33 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.401 AVG Validation Loss:0.575 AVG Training Acc 82.28 % AVG Validation Acc 79.00 %\n",
      "Epoch:170/200 AVG Training Loss:0.398 AVG Validation Loss:0.578 AVG Training Acc 82.55 % AVG Validation Acc 79.00 %\n",
      "Epoch:180/200 AVG Training Loss:0.399 AVG Validation Loss:0.579 AVG Training Acc 82.25 % AVG Validation Acc 79.14 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.401 AVG Validation Loss:0.581 AVG Training Acc 82.43 % AVG Validation Acc 78.87 %\n",
      "Epoch:200/200 AVG Training Loss:0.401 AVG Validation Loss:0.575 AVG Training Acc 82.53 % AVG Validation Acc 78.87 %\n",
      "exam_gifted\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0f10dce6f464b29b2560a4e04175482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2c334ce01af4b14a349adb614693e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best Accuracy found: 72.31%\n",
      "Epoch: 1\n",
      "Epoch:10/200 AVG Training Loss:0.587 AVG Validation Loss:0.587 AVG Training Acc 72.31 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.585 AVG Validation Loss:0.585 AVG Training Acc 72.31 % AVG Validation Acc 72.31 %\n",
      "New Best Accuracy found: 72.45%\n",
      "Epoch: 28\n",
      "Epoch:30/200 AVG Training Loss:0.584 AVG Validation Loss:0.580 AVG Training Acc 72.27 % AVG Validation Acc 72.31 %\n",
      "New Best Accuracy found: 72.58%\n",
      "Epoch: 32\n",
      "New Best Accuracy found: 72.72%\n",
      "Epoch: 34\n",
      "Epoch:40/200 AVG Training Loss:0.584 AVG Validation Loss:0.582 AVG Training Acc 72.25 % AVG Validation Acc 72.31 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.575 AVG Validation Loss:0.582 AVG Training Acc 72.83 % AVG Validation Acc 72.31 %\n",
      "Epoch:60/200 AVG Training Loss:0.569 AVG Validation Loss:0.583 AVG Training Acc 73.06 % AVG Validation Acc 72.18 %\n",
      "Epoch:70/200 AVG Training Loss:0.565 AVG Validation Loss:0.587 AVG Training Acc 73.30 % AVG Validation Acc 72.04 %\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.562 AVG Validation Loss:0.589 AVG Training Acc 73.54 % AVG Validation Acc 71.77 %\n",
      "Epoch:90/200 AVG Training Loss:0.561 AVG Validation Loss:0.594 AVG Training Acc 73.66 % AVG Validation Acc 71.64 %\n",
      "Epoch:100/200 AVG Training Loss:0.559 AVG Validation Loss:0.590 AVG Training Acc 73.70 % AVG Validation Acc 71.64 %\n",
      "Epoch   104: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.560 AVG Validation Loss:0.589 AVG Training Acc 73.71 % AVG Validation Acc 71.91 %\n",
      "Epoch:120/200 AVG Training Loss:0.560 AVG Validation Loss:0.591 AVG Training Acc 73.55 % AVG Validation Acc 71.51 %\n",
      "Epoch:130/200 AVG Training Loss:0.559 AVG Validation Loss:0.595 AVG Training Acc 73.68 % AVG Validation Acc 71.91 %\n",
      "Epoch   135: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.559 AVG Validation Loss:0.592 AVG Training Acc 73.82 % AVG Validation Acc 71.91 %\n",
      "Epoch:150/200 AVG Training Loss:0.559 AVG Validation Loss:0.593 AVG Training Acc 73.67 % AVG Validation Acc 71.77 %\n",
      "Epoch:160/200 AVG Training Loss:0.559 AVG Validation Loss:0.594 AVG Training Acc 73.71 % AVG Validation Acc 71.64 %\n",
      "Epoch   166: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.559 AVG Validation Loss:0.592 AVG Training Acc 73.73 % AVG Validation Acc 71.64 %\n",
      "Epoch:180/200 AVG Training Loss:0.559 AVG Validation Loss:0.593 AVG Training Acc 73.55 % AVG Validation Acc 71.77 %\n",
      "Epoch:190/200 AVG Training Loss:0.558 AVG Validation Loss:0.594 AVG Training Acc 73.71 % AVG Validation Acc 71.64 %\n",
      "Epoch   197: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.558 AVG Validation Loss:0.590 AVG Training Acc 73.76 % AVG Validation Acc 71.51 %\n",
      "Split 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7787ba4508ee446e8f6cf6c8621d43dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.587 AVG Validation Loss:0.588 AVG Training Acc 72.31 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.584 AVG Validation Loss:0.586 AVG Training Acc 72.28 % AVG Validation Acc 72.31 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.577 AVG Validation Loss:0.593 AVG Training Acc 72.52 % AVG Validation Acc 71.24 %\n",
      "Epoch:40/200 AVG Training Loss:0.572 AVG Validation Loss:0.593 AVG Training Acc 72.98 % AVG Validation Acc 71.51 %\n",
      "Epoch:50/200 AVG Training Loss:0.567 AVG Validation Loss:0.599 AVG Training Acc 73.21 % AVG Validation Acc 71.10 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.562 AVG Validation Loss:0.593 AVG Training Acc 73.31 % AVG Validation Acc 71.64 %\n",
      "Epoch:70/200 AVG Training Loss:0.561 AVG Validation Loss:0.595 AVG Training Acc 73.27 % AVG Validation Acc 71.51 %\n",
      "Epoch:80/200 AVG Training Loss:0.559 AVG Validation Loss:0.594 AVG Training Acc 73.52 % AVG Validation Acc 71.51 %\n",
      "Epoch:90/200 AVG Training Loss:0.559 AVG Validation Loss:0.594 AVG Training Acc 73.33 % AVG Validation Acc 71.51 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.558 AVG Validation Loss:0.594 AVG Training Acc 73.45 % AVG Validation Acc 71.64 %\n",
      "Epoch:110/200 AVG Training Loss:0.559 AVG Validation Loss:0.595 AVG Training Acc 73.45 % AVG Validation Acc 71.51 %\n",
      "Epoch:120/200 AVG Training Loss:0.558 AVG Validation Loss:0.593 AVG Training Acc 73.66 % AVG Validation Acc 71.64 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.558 AVG Validation Loss:0.595 AVG Training Acc 73.67 % AVG Validation Acc 71.51 %\n",
      "Epoch:140/200 AVG Training Loss:0.558 AVG Validation Loss:0.594 AVG Training Acc 73.61 % AVG Validation Acc 71.37 %\n",
      "Epoch:150/200 AVG Training Loss:0.559 AVG Validation Loss:0.594 AVG Training Acc 73.34 % AVG Validation Acc 71.51 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.557 AVG Validation Loss:0.594 AVG Training Acc 73.43 % AVG Validation Acc 71.64 %\n",
      "Epoch:170/200 AVG Training Loss:0.558 AVG Validation Loss:0.594 AVG Training Acc 73.58 % AVG Validation Acc 71.37 %\n",
      "Epoch:180/200 AVG Training Loss:0.560 AVG Validation Loss:0.595 AVG Training Acc 73.21 % AVG Validation Acc 71.64 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.559 AVG Validation Loss:0.595 AVG Training Acc 73.48 % AVG Validation Acc 71.24 %\n",
      "Epoch:200/200 AVG Training Loss:0.558 AVG Validation Loss:0.594 AVG Training Acc 73.45 % AVG Validation Acc 71.64 %\n",
      "Split 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbde1b6b5b66482ab15bf139294f6bf9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.586 AVG Validation Loss:0.583 AVG Training Acc 72.31 % AVG Validation Acc 72.31 %\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.583 AVG Validation Loss:0.582 AVG Training Acc 72.31 % AVG Validation Acc 72.31 %\n",
      "Epoch:30/200 AVG Training Loss:0.582 AVG Validation Loss:0.580 AVG Training Acc 72.31 % AVG Validation Acc 72.45 %\n",
      "New Best Accuracy found: 72.85%\n",
      "Epoch: 37\n",
      "Epoch:40/200 AVG Training Loss:0.581 AVG Validation Loss:0.582 AVG Training Acc 72.46 % AVG Validation Acc 72.45 %\n",
      "Epoch:50/200 AVG Training Loss:0.580 AVG Validation Loss:0.579 AVG Training Acc 72.38 % AVG Validation Acc 72.31 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.578 AVG Validation Loss:0.578 AVG Training Acc 72.52 % AVG Validation Acc 72.85 %\n",
      "Epoch:70/200 AVG Training Loss:0.579 AVG Validation Loss:0.578 AVG Training Acc 72.50 % AVG Validation Acc 72.72 %\n",
      "Epoch:80/200 AVG Training Loss:0.579 AVG Validation Loss:0.578 AVG Training Acc 72.44 % AVG Validation Acc 72.58 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.578 AVG Validation Loss:0.578 AVG Training Acc 72.52 % AVG Validation Acc 72.58 %\n",
      "Epoch:100/200 AVG Training Loss:0.578 AVG Validation Loss:0.578 AVG Training Acc 72.56 % AVG Validation Acc 72.58 %\n",
      "Epoch:110/200 AVG Training Loss:0.578 AVG Validation Loss:0.578 AVG Training Acc 72.55 % AVG Validation Acc 72.58 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.579 AVG Validation Loss:0.578 AVG Training Acc 72.58 % AVG Validation Acc 72.58 %\n",
      "Epoch:130/200 AVG Training Loss:0.577 AVG Validation Loss:0.578 AVG Training Acc 72.53 % AVG Validation Acc 72.58 %\n",
      "Epoch:140/200 AVG Training Loss:0.578 AVG Validation Loss:0.578 AVG Training Acc 72.55 % AVG Validation Acc 72.58 %\n",
      "Epoch:150/200 AVG Training Loss:0.578 AVG Validation Loss:0.578 AVG Training Acc 72.56 % AVG Validation Acc 72.58 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.578 AVG Validation Loss:0.578 AVG Training Acc 72.58 % AVG Validation Acc 72.58 %\n",
      "Epoch:170/200 AVG Training Loss:0.577 AVG Validation Loss:0.578 AVG Training Acc 72.53 % AVG Validation Acc 72.58 %\n",
      "Epoch:180/200 AVG Training Loss:0.577 AVG Validation Loss:0.578 AVG Training Acc 72.62 % AVG Validation Acc 72.58 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.577 AVG Validation Loss:0.578 AVG Training Acc 72.56 % AVG Validation Acc 72.58 %\n",
      "Epoch:200/200 AVG Training Loss:0.578 AVG Validation Loss:0.578 AVG Training Acc 72.59 % AVG Validation Acc 72.58 %\n",
      "Split 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019692d8b4284c4997b495ee5071b004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.588 AVG Validation Loss:0.585 AVG Training Acc 72.31 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.585 AVG Validation Loss:0.583 AVG Training Acc 72.28 % AVG Validation Acc 72.31 %\n",
      "Epoch:30/200 AVG Training Loss:0.581 AVG Validation Loss:0.585 AVG Training Acc 72.34 % AVG Validation Acc 72.72 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.574 AVG Validation Loss:0.584 AVG Training Acc 72.68 % AVG Validation Acc 72.31 %\n",
      "Epoch:50/200 AVG Training Loss:0.565 AVG Validation Loss:0.589 AVG Training Acc 73.28 % AVG Validation Acc 72.45 %\n",
      "Epoch:60/200 AVG Training Loss:0.558 AVG Validation Loss:0.598 AVG Training Acc 73.61 % AVG Validation Acc 72.04 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.558 AVG Validation Loss:0.603 AVG Training Acc 73.55 % AVG Validation Acc 72.18 %\n",
      "Epoch:80/200 AVG Training Loss:0.548 AVG Validation Loss:0.600 AVG Training Acc 74.12 % AVG Validation Acc 72.18 %\n",
      "Epoch:90/200 AVG Training Loss:0.545 AVG Validation Loss:0.605 AVG Training Acc 74.21 % AVG Validation Acc 71.64 %\n",
      "Epoch:100/200 AVG Training Loss:0.543 AVG Validation Loss:0.603 AVG Training Acc 74.42 % AVG Validation Acc 72.31 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.545 AVG Validation Loss:0.598 AVG Training Acc 74.54 % AVG Validation Acc 72.31 %\n",
      "Epoch:120/200 AVG Training Loss:0.544 AVG Validation Loss:0.605 AVG Training Acc 73.94 % AVG Validation Acc 72.04 %\n",
      "Epoch:130/200 AVG Training Loss:0.542 AVG Validation Loss:0.607 AVG Training Acc 74.31 % AVG Validation Acc 72.18 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.543 AVG Validation Loss:0.606 AVG Training Acc 74.21 % AVG Validation Acc 72.04 %\n",
      "Epoch:150/200 AVG Training Loss:0.546 AVG Validation Loss:0.605 AVG Training Acc 74.09 % AVG Validation Acc 72.18 %\n",
      "Epoch:160/200 AVG Training Loss:0.544 AVG Validation Loss:0.604 AVG Training Acc 74.27 % AVG Validation Acc 72.18 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.546 AVG Validation Loss:0.602 AVG Training Acc 74.28 % AVG Validation Acc 72.04 %\n",
      "Epoch:180/200 AVG Training Loss:0.545 AVG Validation Loss:0.606 AVG Training Acc 74.15 % AVG Validation Acc 72.31 %\n",
      "Epoch:190/200 AVG Training Loss:0.544 AVG Validation Loss:0.603 AVG Training Acc 73.97 % AVG Validation Acc 72.18 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.542 AVG Validation Loss:0.607 AVG Training Acc 74.51 % AVG Validation Acc 71.91 %\n",
      "Split 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ee07e345464f54b6b9cb3ce828bbcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.587 AVG Validation Loss:0.584 AVG Training Acc 72.31 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.583 AVG Validation Loss:0.585 AVG Training Acc 72.33 % AVG Validation Acc 72.58 %\n",
      "Epoch:30/200 AVG Training Loss:0.580 AVG Validation Loss:0.586 AVG Training Acc 72.52 % AVG Validation Acc 72.45 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.572 AVG Validation Loss:0.584 AVG Training Acc 73.00 % AVG Validation Acc 72.58 %\n",
      "Epoch:50/200 AVG Training Loss:0.568 AVG Validation Loss:0.588 AVG Training Acc 73.07 % AVG Validation Acc 72.45 %\n",
      "Epoch:60/200 AVG Training Loss:0.562 AVG Validation Loss:0.596 AVG Training Acc 73.30 % AVG Validation Acc 72.45 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.559 AVG Validation Loss:0.598 AVG Training Acc 73.42 % AVG Validation Acc 72.04 %\n",
      "Epoch:80/200 AVG Training Loss:0.557 AVG Validation Loss:0.600 AVG Training Acc 73.48 % AVG Validation Acc 72.18 %\n",
      "Epoch:90/200 AVG Training Loss:0.557 AVG Validation Loss:0.599 AVG Training Acc 73.46 % AVG Validation Acc 72.31 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.555 AVG Validation Loss:0.599 AVG Training Acc 73.61 % AVG Validation Acc 72.18 %\n",
      "Epoch:110/200 AVG Training Loss:0.556 AVG Validation Loss:0.602 AVG Training Acc 73.55 % AVG Validation Acc 71.64 %\n",
      "Epoch:120/200 AVG Training Loss:0.554 AVG Validation Loss:0.602 AVG Training Acc 73.43 % AVG Validation Acc 72.04 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.558 AVG Validation Loss:0.602 AVG Training Acc 73.36 % AVG Validation Acc 72.31 %\n",
      "Epoch:140/200 AVG Training Loss:0.555 AVG Validation Loss:0.603 AVG Training Acc 73.52 % AVG Validation Acc 72.18 %\n",
      "Epoch:150/200 AVG Training Loss:0.554 AVG Validation Loss:0.601 AVG Training Acc 73.49 % AVG Validation Acc 72.18 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.556 AVG Validation Loss:0.603 AVG Training Acc 73.54 % AVG Validation Acc 72.31 %\n",
      "Epoch:170/200 AVG Training Loss:0.555 AVG Validation Loss:0.604 AVG Training Acc 73.52 % AVG Validation Acc 72.04 %\n",
      "Epoch:180/200 AVG Training Loss:0.556 AVG Validation Loss:0.602 AVG Training Acc 73.34 % AVG Validation Acc 72.18 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.556 AVG Validation Loss:0.604 AVG Training Acc 73.46 % AVG Validation Acc 71.77 %\n",
      "Epoch:200/200 AVG Training Loss:0.557 AVG Validation Loss:0.603 AVG Training Acc 73.46 % AVG Validation Acc 72.04 %\n",
      "Split 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bf3d87e405e47a599d7d1db06f9f4b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.586 AVG Validation Loss:0.589 AVG Training Acc 72.30 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.583 AVG Validation Loss:0.589 AVG Training Acc 72.28 % AVG Validation Acc 72.31 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.579 AVG Validation Loss:0.590 AVG Training Acc 72.50 % AVG Validation Acc 71.77 %\n",
      "Epoch:40/200 AVG Training Loss:0.577 AVG Validation Loss:0.592 AVG Training Acc 72.70 % AVG Validation Acc 71.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.575 AVG Validation Loss:0.593 AVG Training Acc 73.00 % AVG Validation Acc 71.51 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.571 AVG Validation Loss:0.592 AVG Training Acc 73.16 % AVG Validation Acc 72.04 %\n",
      "Epoch:70/200 AVG Training Loss:0.574 AVG Validation Loss:0.591 AVG Training Acc 73.06 % AVG Validation Acc 72.18 %\n",
      "Epoch:80/200 AVG Training Loss:0.569 AVG Validation Loss:0.592 AVG Training Acc 73.25 % AVG Validation Acc 72.18 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.569 AVG Validation Loss:0.593 AVG Training Acc 73.36 % AVG Validation Acc 71.91 %\n",
      "Epoch:100/200 AVG Training Loss:0.571 AVG Validation Loss:0.593 AVG Training Acc 73.15 % AVG Validation Acc 72.04 %\n",
      "Epoch:110/200 AVG Training Loss:0.570 AVG Validation Loss:0.593 AVG Training Acc 73.21 % AVG Validation Acc 71.91 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.570 AVG Validation Loss:0.593 AVG Training Acc 73.30 % AVG Validation Acc 72.04 %\n",
      "Epoch:130/200 AVG Training Loss:0.569 AVG Validation Loss:0.593 AVG Training Acc 73.21 % AVG Validation Acc 71.91 %\n",
      "Epoch:140/200 AVG Training Loss:0.569 AVG Validation Loss:0.593 AVG Training Acc 73.33 % AVG Validation Acc 72.04 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.570 AVG Validation Loss:0.593 AVG Training Acc 73.06 % AVG Validation Acc 72.04 %\n",
      "Epoch:160/200 AVG Training Loss:0.569 AVG Validation Loss:0.593 AVG Training Acc 73.24 % AVG Validation Acc 71.91 %\n",
      "Epoch:170/200 AVG Training Loss:0.570 AVG Validation Loss:0.594 AVG Training Acc 73.34 % AVG Validation Acc 71.91 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.571 AVG Validation Loss:0.594 AVG Training Acc 73.16 % AVG Validation Acc 72.04 %\n",
      "Epoch:190/200 AVG Training Loss:0.570 AVG Validation Loss:0.594 AVG Training Acc 73.37 % AVG Validation Acc 72.18 %\n",
      "Epoch:200/200 AVG Training Loss:0.569 AVG Validation Loss:0.594 AVG Training Acc 73.40 % AVG Validation Acc 71.91 %\n",
      "Split 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e511fd3b5d7742f3bcd105f04a648656",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.586 AVG Validation Loss:0.585 AVG Training Acc 72.30 % AVG Validation Acc 72.41 %\n",
      "Epoch:20/200 AVG Training Loss:0.585 AVG Validation Loss:0.584 AVG Training Acc 72.30 % AVG Validation Acc 72.41 %\n",
      "Epoch:30/200 AVG Training Loss:0.581 AVG Validation Loss:0.584 AVG Training Acc 72.34 % AVG Validation Acc 72.41 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.575 AVG Validation Loss:0.584 AVG Training Acc 72.58 % AVG Validation Acc 72.27 %\n",
      "Epoch:50/200 AVG Training Loss:0.571 AVG Validation Loss:0.587 AVG Training Acc 72.72 % AVG Validation Acc 72.41 %\n",
      "Epoch:60/200 AVG Training Loss:0.568 AVG Validation Loss:0.594 AVG Training Acc 73.03 % AVG Validation Acc 72.54 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.562 AVG Validation Loss:0.599 AVG Training Acc 73.14 % AVG Validation Acc 72.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.564 AVG Validation Loss:0.601 AVG Training Acc 73.06 % AVG Validation Acc 72.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.563 AVG Validation Loss:0.599 AVG Training Acc 73.18 % AVG Validation Acc 72.27 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.563 AVG Validation Loss:0.603 AVG Training Acc 72.99 % AVG Validation Acc 72.27 %\n",
      "Epoch:110/200 AVG Training Loss:0.561 AVG Validation Loss:0.600 AVG Training Acc 73.23 % AVG Validation Acc 72.27 %\n",
      "Epoch:120/200 AVG Training Loss:0.562 AVG Validation Loss:0.602 AVG Training Acc 73.03 % AVG Validation Acc 72.27 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.562 AVG Validation Loss:0.601 AVG Training Acc 73.11 % AVG Validation Acc 72.27 %\n",
      "Epoch:140/200 AVG Training Loss:0.562 AVG Validation Loss:0.603 AVG Training Acc 73.26 % AVG Validation Acc 72.27 %\n",
      "Epoch:150/200 AVG Training Loss:0.562 AVG Validation Loss:0.601 AVG Training Acc 73.14 % AVG Validation Acc 72.27 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.562 AVG Validation Loss:0.601 AVG Training Acc 73.05 % AVG Validation Acc 72.27 %\n",
      "Epoch:170/200 AVG Training Loss:0.562 AVG Validation Loss:0.602 AVG Training Acc 73.06 % AVG Validation Acc 72.27 %\n",
      "Epoch:180/200 AVG Training Loss:0.561 AVG Validation Loss:0.603 AVG Training Acc 73.35 % AVG Validation Acc 72.27 %\n",
      "Epoch:190/200 AVG Training Loss:0.562 AVG Validation Loss:0.601 AVG Training Acc 73.32 % AVG Validation Acc 72.27 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.561 AVG Validation Loss:0.601 AVG Training Acc 73.14 % AVG Validation Acc 72.27 %\n",
      "Split 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588fd0fc9be7420f89f772347d4a4e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.589 AVG Validation Loss:0.584 AVG Training Acc 72.31 % AVG Validation Acc 72.27 %\n",
      "Epoch:20/200 AVG Training Loss:0.584 AVG Validation Loss:0.581 AVG Training Acc 72.27 % AVG Validation Acc 72.27 %\n",
      "Epoch:30/200 AVG Training Loss:0.580 AVG Validation Loss:0.581 AVG Training Acc 72.55 % AVG Validation Acc 72.41 %\n",
      "Epoch:40/200 AVG Training Loss:0.578 AVG Validation Loss:0.583 AVG Training Acc 72.69 % AVG Validation Acc 72.41 %\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.560 AVG Validation Loss:0.592 AVG Training Acc 73.17 % AVG Validation Acc 71.47 %\n",
      "Epoch:60/200 AVG Training Loss:0.547 AVG Validation Loss:0.611 AVG Training Acc 74.39 % AVG Validation Acc 69.99 %\n",
      "Epoch:70/200 AVG Training Loss:0.535 AVG Validation Loss:0.622 AVG Training Acc 74.63 % AVG Validation Acc 70.12 %\n",
      "Epoch    71: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.525 AVG Validation Loss:0.633 AVG Training Acc 75.50 % AVG Validation Acc 70.26 %\n",
      "Epoch:90/200 AVG Training Loss:0.524 AVG Validation Loss:0.650 AVG Training Acc 75.44 % AVG Validation Acc 69.58 %\n",
      "Epoch:100/200 AVG Training Loss:0.520 AVG Validation Loss:0.645 AVG Training Acc 75.86 % AVG Validation Acc 70.12 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.520 AVG Validation Loss:0.652 AVG Training Acc 75.96 % AVG Validation Acc 69.85 %\n",
      "Epoch:120/200 AVG Training Loss:0.522 AVG Validation Loss:0.646 AVG Training Acc 75.60 % AVG Validation Acc 69.85 %\n",
      "Epoch:130/200 AVG Training Loss:0.520 AVG Validation Loss:0.646 AVG Training Acc 75.41 % AVG Validation Acc 70.26 %\n",
      "Epoch   133: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.521 AVG Validation Loss:0.649 AVG Training Acc 75.45 % AVG Validation Acc 69.99 %\n",
      "Epoch:150/200 AVG Training Loss:0.521 AVG Validation Loss:0.648 AVG Training Acc 75.86 % AVG Validation Acc 69.85 %\n",
      "Epoch:160/200 AVG Training Loss:0.519 AVG Validation Loss:0.647 AVG Training Acc 75.59 % AVG Validation Acc 70.12 %\n",
      "Epoch   164: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.518 AVG Validation Loss:0.651 AVG Training Acc 75.93 % AVG Validation Acc 69.45 %\n",
      "Epoch:180/200 AVG Training Loss:0.519 AVG Validation Loss:0.647 AVG Training Acc 75.54 % AVG Validation Acc 69.99 %\n",
      "Epoch:190/200 AVG Training Loss:0.519 AVG Validation Loss:0.648 AVG Training Acc 75.66 % AVG Validation Acc 69.99 %\n",
      "Epoch   195: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.521 AVG Validation Loss:0.651 AVG Training Acc 75.50 % AVG Validation Acc 69.58 %\n",
      "Split 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b58cb591301409bac741e249979fc85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.586 AVG Validation Loss:0.585 AVG Training Acc 72.31 % AVG Validation Acc 72.27 %\n",
      "Epoch:20/200 AVG Training Loss:0.585 AVG Validation Loss:0.582 AVG Training Acc 72.31 % AVG Validation Acc 72.27 %\n",
      "Epoch:30/200 AVG Training Loss:0.582 AVG Validation Loss:0.585 AVG Training Acc 72.46 % AVG Validation Acc 72.41 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.571 AVG Validation Loss:0.595 AVG Training Acc 73.15 % AVG Validation Acc 71.33 %\n",
      "Epoch:50/200 AVG Training Loss:0.567 AVG Validation Loss:0.601 AVG Training Acc 73.06 % AVG Validation Acc 71.20 %\n",
      "Epoch:60/200 AVG Training Loss:0.559 AVG Validation Loss:0.612 AVG Training Acc 73.48 % AVG Validation Acc 70.52 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.556 AVG Validation Loss:0.617 AVG Training Acc 74.08 % AVG Validation Acc 70.52 %\n",
      "Epoch:80/200 AVG Training Loss:0.554 AVG Validation Loss:0.622 AVG Training Acc 73.82 % AVG Validation Acc 70.12 %\n",
      "Epoch:90/200 AVG Training Loss:0.554 AVG Validation Loss:0.621 AVG Training Acc 73.79 % AVG Validation Acc 70.26 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.552 AVG Validation Loss:0.625 AVG Training Acc 73.94 % AVG Validation Acc 69.99 %\n",
      "Epoch:110/200 AVG Training Loss:0.551 AVG Validation Loss:0.625 AVG Training Acc 73.73 % AVG Validation Acc 69.99 %\n",
      "Epoch:120/200 AVG Training Loss:0.553 AVG Validation Loss:0.624 AVG Training Acc 73.85 % AVG Validation Acc 69.99 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.552 AVG Validation Loss:0.625 AVG Training Acc 73.90 % AVG Validation Acc 69.99 %\n",
      "Epoch:140/200 AVG Training Loss:0.552 AVG Validation Loss:0.623 AVG Training Acc 73.91 % AVG Validation Acc 69.99 %\n",
      "Epoch:150/200 AVG Training Loss:0.552 AVG Validation Loss:0.625 AVG Training Acc 73.94 % AVG Validation Acc 69.99 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.551 AVG Validation Loss:0.623 AVG Training Acc 73.94 % AVG Validation Acc 69.85 %\n",
      "Epoch:170/200 AVG Training Loss:0.551 AVG Validation Loss:0.625 AVG Training Acc 74.03 % AVG Validation Acc 70.12 %\n",
      "Epoch:180/200 AVG Training Loss:0.552 AVG Validation Loss:0.624 AVG Training Acc 73.91 % AVG Validation Acc 70.12 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.550 AVG Validation Loss:0.622 AVG Training Acc 73.96 % AVG Validation Acc 69.99 %\n",
      "Epoch:200/200 AVG Training Loss:0.550 AVG Validation Loss:0.624 AVG Training Acc 73.90 % AVG Validation Acc 69.85 %\n",
      "Split 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4ac293a0baa49548ae0c4d735cc9992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.586 AVG Validation Loss:0.589 AVG Training Acc 72.31 % AVG Validation Acc 72.27 %\n",
      "Epoch:20/200 AVG Training Loss:0.584 AVG Validation Loss:0.589 AVG Training Acc 72.34 % AVG Validation Acc 72.27 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.578 AVG Validation Loss:0.589 AVG Training Acc 72.51 % AVG Validation Acc 72.41 %\n",
      "Epoch:40/200 AVG Training Loss:0.571 AVG Validation Loss:0.593 AVG Training Acc 72.97 % AVG Validation Acc 71.87 %\n",
      "Epoch:50/200 AVG Training Loss:0.566 AVG Validation Loss:0.612 AVG Training Acc 73.51 % AVG Validation Acc 71.60 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.562 AVG Validation Loss:0.624 AVG Training Acc 73.79 % AVG Validation Acc 71.33 %\n",
      "Epoch:70/200 AVG Training Loss:0.559 AVG Validation Loss:0.634 AVG Training Acc 74.03 % AVG Validation Acc 71.06 %\n",
      "Epoch:80/200 AVG Training Loss:0.558 AVG Validation Loss:0.636 AVG Training Acc 73.97 % AVG Validation Acc 70.93 %\n",
      "Epoch:90/200 AVG Training Loss:0.557 AVG Validation Loss:0.634 AVG Training Acc 74.14 % AVG Validation Acc 70.93 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.557 AVG Validation Loss:0.639 AVG Training Acc 74.05 % AVG Validation Acc 71.20 %\n",
      "Epoch:110/200 AVG Training Loss:0.558 AVG Validation Loss:0.642 AVG Training Acc 74.06 % AVG Validation Acc 71.06 %\n",
      "Epoch:120/200 AVG Training Loss:0.556 AVG Validation Loss:0.642 AVG Training Acc 74.00 % AVG Validation Acc 70.79 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.557 AVG Validation Loss:0.643 AVG Training Acc 74.06 % AVG Validation Acc 70.93 %\n",
      "Epoch:140/200 AVG Training Loss:0.556 AVG Validation Loss:0.641 AVG Training Acc 74.20 % AVG Validation Acc 70.66 %\n",
      "Epoch:150/200 AVG Training Loss:0.557 AVG Validation Loss:0.642 AVG Training Acc 74.09 % AVG Validation Acc 70.52 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.556 AVG Validation Loss:0.636 AVG Training Acc 74.12 % AVG Validation Acc 71.06 %\n",
      "Epoch:170/200 AVG Training Loss:0.556 AVG Validation Loss:0.640 AVG Training Acc 74.12 % AVG Validation Acc 71.06 %\n",
      "Epoch:180/200 AVG Training Loss:0.558 AVG Validation Loss:0.638 AVG Training Acc 74.06 % AVG Validation Acc 70.79 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.557 AVG Validation Loss:0.641 AVG Training Acc 74.14 % AVG Validation Acc 71.06 %\n",
      "Epoch:200/200 AVG Training Loss:0.557 AVG Validation Loss:0.642 AVG Training Acc 74.11 % AVG Validation Acc 70.66 %\n",
      "Split 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08811ccc78d644f59536e1b6b129254b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.588 AVG Validation Loss:0.583 AVG Training Acc 72.31 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.585 AVG Validation Loss:0.581 AVG Training Acc 72.30 % AVG Validation Acc 72.31 %\n",
      "Epoch:30/200 AVG Training Loss:0.581 AVG Validation Loss:0.586 AVG Training Acc 72.55 % AVG Validation Acc 72.31 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.577 AVG Validation Loss:0.588 AVG Training Acc 72.65 % AVG Validation Acc 71.77 %\n",
      "Epoch:50/200 AVG Training Loss:0.572 AVG Validation Loss:0.595 AVG Training Acc 73.01 % AVG Validation Acc 71.37 %\n",
      "Epoch:60/200 AVG Training Loss:0.568 AVG Validation Loss:0.601 AVG Training Acc 73.13 % AVG Validation Acc 71.24 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.563 AVG Validation Loss:0.614 AVG Training Acc 73.18 % AVG Validation Acc 71.24 %\n",
      "Epoch:80/200 AVG Training Loss:0.561 AVG Validation Loss:0.615 AVG Training Acc 73.49 % AVG Validation Acc 70.97 %\n",
      "Epoch:90/200 AVG Training Loss:0.561 AVG Validation Loss:0.618 AVG Training Acc 73.37 % AVG Validation Acc 70.83 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.559 AVG Validation Loss:0.620 AVG Training Acc 73.49 % AVG Validation Acc 71.24 %\n",
      "Epoch:110/200 AVG Training Loss:0.559 AVG Validation Loss:0.622 AVG Training Acc 73.30 % AVG Validation Acc 71.24 %\n",
      "Epoch:120/200 AVG Training Loss:0.560 AVG Validation Loss:0.621 AVG Training Acc 73.49 % AVG Validation Acc 71.10 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.559 AVG Validation Loss:0.621 AVG Training Acc 73.51 % AVG Validation Acc 70.83 %\n",
      "Epoch:140/200 AVG Training Loss:0.559 AVG Validation Loss:0.620 AVG Training Acc 73.57 % AVG Validation Acc 70.97 %\n",
      "Epoch:150/200 AVG Training Loss:0.558 AVG Validation Loss:0.622 AVG Training Acc 73.45 % AVG Validation Acc 70.70 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.559 AVG Validation Loss:0.620 AVG Training Acc 73.51 % AVG Validation Acc 70.97 %\n",
      "Epoch:170/200 AVG Training Loss:0.560 AVG Validation Loss:0.622 AVG Training Acc 73.33 % AVG Validation Acc 71.24 %\n",
      "Epoch:180/200 AVG Training Loss:0.560 AVG Validation Loss:0.622 AVG Training Acc 73.71 % AVG Validation Acc 70.97 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.559 AVG Validation Loss:0.620 AVG Training Acc 73.46 % AVG Validation Acc 70.97 %\n",
      "Epoch:200/200 AVG Training Loss:0.558 AVG Validation Loss:0.619 AVG Training Acc 73.71 % AVG Validation Acc 71.10 %\n",
      "Split 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2f1b27b36e14a72a6e022db1a406b52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.587 AVG Validation Loss:0.586 AVG Training Acc 72.30 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.583 AVG Validation Loss:0.583 AVG Training Acc 72.22 % AVG Validation Acc 72.31 %\n",
      "Epoch:30/200 AVG Training Loss:0.582 AVG Validation Loss:0.583 AVG Training Acc 72.37 % AVG Validation Acc 71.91 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.573 AVG Validation Loss:0.590 AVG Training Acc 72.83 % AVG Validation Acc 72.18 %\n",
      "Epoch:50/200 AVG Training Loss:0.562 AVG Validation Loss:0.601 AVG Training Acc 73.15 % AVG Validation Acc 71.64 %\n",
      "Epoch:60/200 AVG Training Loss:0.553 AVG Validation Loss:0.608 AVG Training Acc 73.73 % AVG Validation Acc 71.77 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.544 AVG Validation Loss:0.625 AVG Training Acc 74.04 % AVG Validation Acc 71.91 %\n",
      "Epoch:80/200 AVG Training Loss:0.541 AVG Validation Loss:0.630 AVG Training Acc 74.04 % AVG Validation Acc 71.64 %\n",
      "Epoch:90/200 AVG Training Loss:0.540 AVG Validation Loss:0.626 AVG Training Acc 74.13 % AVG Validation Acc 71.91 %\n",
      "Epoch:100/200 AVG Training Loss:0.538 AVG Validation Loss:0.627 AVG Training Acc 74.34 % AVG Validation Acc 71.77 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.539 AVG Validation Loss:0.630 AVG Training Acc 74.28 % AVG Validation Acc 71.91 %\n",
      "Epoch:120/200 AVG Training Loss:0.538 AVG Validation Loss:0.632 AVG Training Acc 74.43 % AVG Validation Acc 71.51 %\n",
      "Epoch:130/200 AVG Training Loss:0.538 AVG Validation Loss:0.634 AVG Training Acc 74.30 % AVG Validation Acc 71.77 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.539 AVG Validation Loss:0.637 AVG Training Acc 74.30 % AVG Validation Acc 71.51 %\n",
      "Epoch:150/200 AVG Training Loss:0.539 AVG Validation Loss:0.636 AVG Training Acc 74.27 % AVG Validation Acc 71.51 %\n",
      "Epoch:160/200 AVG Training Loss:0.537 AVG Validation Loss:0.635 AVG Training Acc 74.37 % AVG Validation Acc 71.51 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.540 AVG Validation Loss:0.632 AVG Training Acc 74.40 % AVG Validation Acc 71.64 %\n",
      "Epoch:180/200 AVG Training Loss:0.539 AVG Validation Loss:0.636 AVG Training Acc 74.33 % AVG Validation Acc 71.64 %\n",
      "Epoch:190/200 AVG Training Loss:0.538 AVG Validation Loss:0.638 AVG Training Acc 74.21 % AVG Validation Acc 71.64 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.539 AVG Validation Loss:0.637 AVG Training Acc 74.27 % AVG Validation Acc 71.37 %\n",
      "Split 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99f2c0e566b042be9f009bc1b19bdf4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.586 AVG Validation Loss:0.582 AVG Training Acc 72.31 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.585 AVG Validation Loss:0.581 AVG Training Acc 72.30 % AVG Validation Acc 72.31 %\n",
      "Epoch:30/200 AVG Training Loss:0.581 AVG Validation Loss:0.584 AVG Training Acc 72.30 % AVG Validation Acc 72.45 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.576 AVG Validation Loss:0.585 AVG Training Acc 72.53 % AVG Validation Acc 72.31 %\n",
      "Epoch:50/200 AVG Training Loss:0.573 AVG Validation Loss:0.585 AVG Training Acc 72.56 % AVG Validation Acc 72.31 %\n",
      "Epoch:60/200 AVG Training Loss:0.569 AVG Validation Loss:0.588 AVG Training Acc 73.10 % AVG Validation Acc 72.31 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.565 AVG Validation Loss:0.587 AVG Training Acc 73.28 % AVG Validation Acc 72.31 %\n",
      "Epoch:80/200 AVG Training Loss:0.563 AVG Validation Loss:0.591 AVG Training Acc 73.45 % AVG Validation Acc 72.18 %\n",
      "Epoch:90/200 AVG Training Loss:0.563 AVG Validation Loss:0.589 AVG Training Acc 73.39 % AVG Validation Acc 72.45 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.560 AVG Validation Loss:0.590 AVG Training Acc 73.70 % AVG Validation Acc 72.18 %\n",
      "Epoch:110/200 AVG Training Loss:0.562 AVG Validation Loss:0.589 AVG Training Acc 73.22 % AVG Validation Acc 72.04 %\n",
      "Epoch:120/200 AVG Training Loss:0.563 AVG Validation Loss:0.591 AVG Training Acc 73.18 % AVG Validation Acc 71.91 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.562 AVG Validation Loss:0.588 AVG Training Acc 73.46 % AVG Validation Acc 72.18 %\n",
      "Epoch:140/200 AVG Training Loss:0.562 AVG Validation Loss:0.587 AVG Training Acc 73.34 % AVG Validation Acc 72.04 %\n",
      "Epoch:150/200 AVG Training Loss:0.562 AVG Validation Loss:0.591 AVG Training Acc 73.33 % AVG Validation Acc 72.31 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.561 AVG Validation Loss:0.590 AVG Training Acc 73.48 % AVG Validation Acc 71.91 %\n",
      "Epoch:170/200 AVG Training Loss:0.562 AVG Validation Loss:0.589 AVG Training Acc 73.57 % AVG Validation Acc 71.91 %\n",
      "Epoch:180/200 AVG Training Loss:0.562 AVG Validation Loss:0.591 AVG Training Acc 73.39 % AVG Validation Acc 72.04 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.563 AVG Validation Loss:0.590 AVG Training Acc 73.28 % AVG Validation Acc 72.04 %\n",
      "Epoch:200/200 AVG Training Loss:0.562 AVG Validation Loss:0.591 AVG Training Acc 73.33 % AVG Validation Acc 72.04 %\n",
      "Split 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26d932a4d27d4b8096f1bdad50c11c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.587 AVG Validation Loss:0.585 AVG Training Acc 72.31 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.586 AVG Validation Loss:0.584 AVG Training Acc 72.25 % AVG Validation Acc 72.31 %\n",
      "Epoch:30/200 AVG Training Loss:0.583 AVG Validation Loss:0.583 AVG Training Acc 72.36 % AVG Validation Acc 72.31 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.576 AVG Validation Loss:0.584 AVG Training Acc 72.89 % AVG Validation Acc 71.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.572 AVG Validation Loss:0.588 AVG Training Acc 73.18 % AVG Validation Acc 71.91 %\n",
      "Epoch:60/200 AVG Training Loss:0.565 AVG Validation Loss:0.597 AVG Training Acc 73.85 % AVG Validation Acc 71.24 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.559 AVG Validation Loss:0.609 AVG Training Acc 74.19 % AVG Validation Acc 70.97 %\n",
      "Epoch:80/200 AVG Training Loss:0.558 AVG Validation Loss:0.611 AVG Training Acc 74.10 % AVG Validation Acc 71.10 %\n",
      "Epoch:90/200 AVG Training Loss:0.556 AVG Validation Loss:0.614 AVG Training Acc 74.27 % AVG Validation Acc 71.10 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.557 AVG Validation Loss:0.616 AVG Training Acc 74.21 % AVG Validation Acc 70.97 %\n",
      "Epoch:110/200 AVG Training Loss:0.556 AVG Validation Loss:0.617 AVG Training Acc 74.24 % AVG Validation Acc 71.10 %\n",
      "Epoch:120/200 AVG Training Loss:0.556 AVG Validation Loss:0.616 AVG Training Acc 74.27 % AVG Validation Acc 71.10 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.557 AVG Validation Loss:0.617 AVG Training Acc 73.98 % AVG Validation Acc 71.24 %\n",
      "Epoch:140/200 AVG Training Loss:0.555 AVG Validation Loss:0.615 AVG Training Acc 74.42 % AVG Validation Acc 71.37 %\n",
      "Epoch:150/200 AVG Training Loss:0.554 AVG Validation Loss:0.618 AVG Training Acc 74.55 % AVG Validation Acc 71.10 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.555 AVG Validation Loss:0.616 AVG Training Acc 74.39 % AVG Validation Acc 70.97 %\n",
      "Epoch:170/200 AVG Training Loss:0.555 AVG Validation Loss:0.617 AVG Training Acc 74.42 % AVG Validation Acc 71.24 %\n",
      "Epoch:180/200 AVG Training Loss:0.554 AVG Validation Loss:0.615 AVG Training Acc 74.39 % AVG Validation Acc 71.24 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.554 AVG Validation Loss:0.616 AVG Training Acc 74.40 % AVG Validation Acc 70.97 %\n",
      "Epoch:200/200 AVG Training Loss:0.555 AVG Validation Loss:0.617 AVG Training Acc 74.25 % AVG Validation Acc 71.24 %\n",
      "Split 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e97f7643ad03430682f7467124777ae9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.586 AVG Validation Loss:0.589 AVG Training Acc 72.34 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.582 AVG Validation Loss:0.591 AVG Training Acc 72.25 % AVG Validation Acc 72.31 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.576 AVG Validation Loss:0.600 AVG Training Acc 72.59 % AVG Validation Acc 72.04 %\n",
      "Epoch:40/200 AVG Training Loss:0.572 AVG Validation Loss:0.603 AVG Training Acc 72.52 % AVG Validation Acc 72.18 %\n",
      "Epoch:50/200 AVG Training Loss:0.567 AVG Validation Loss:0.606 AVG Training Acc 73.00 % AVG Validation Acc 71.91 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.562 AVG Validation Loss:0.613 AVG Training Acc 72.97 % AVG Validation Acc 71.24 %\n",
      "Epoch:70/200 AVG Training Loss:0.560 AVG Validation Loss:0.615 AVG Training Acc 73.01 % AVG Validation Acc 71.37 %\n",
      "Epoch:80/200 AVG Training Loss:0.560 AVG Validation Loss:0.611 AVG Training Acc 73.66 % AVG Validation Acc 71.24 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.559 AVG Validation Loss:0.613 AVG Training Acc 73.42 % AVG Validation Acc 71.10 %\n",
      "Epoch:100/200 AVG Training Loss:0.562 AVG Validation Loss:0.612 AVG Training Acc 73.01 % AVG Validation Acc 71.10 %\n",
      "Epoch:110/200 AVG Training Loss:0.559 AVG Validation Loss:0.611 AVG Training Acc 73.43 % AVG Validation Acc 71.24 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.560 AVG Validation Loss:0.612 AVG Training Acc 73.30 % AVG Validation Acc 71.10 %\n",
      "Epoch:130/200 AVG Training Loss:0.559 AVG Validation Loss:0.613 AVG Training Acc 73.43 % AVG Validation Acc 71.24 %\n",
      "Epoch:140/200 AVG Training Loss:0.559 AVG Validation Loss:0.612 AVG Training Acc 73.51 % AVG Validation Acc 71.10 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.560 AVG Validation Loss:0.612 AVG Training Acc 73.30 % AVG Validation Acc 71.37 %\n",
      "Epoch:160/200 AVG Training Loss:0.558 AVG Validation Loss:0.612 AVG Training Acc 73.49 % AVG Validation Acc 70.97 %\n",
      "Epoch:170/200 AVG Training Loss:0.559 AVG Validation Loss:0.612 AVG Training Acc 73.39 % AVG Validation Acc 71.10 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.561 AVG Validation Loss:0.610 AVG Training Acc 73.33 % AVG Validation Acc 71.24 %\n",
      "Epoch:190/200 AVG Training Loss:0.559 AVG Validation Loss:0.612 AVG Training Acc 73.19 % AVG Validation Acc 71.10 %\n",
      "Epoch:200/200 AVG Training Loss:0.560 AVG Validation Loss:0.613 AVG Training Acc 73.42 % AVG Validation Acc 71.10 %\n",
      "Split 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc3cf09d2e84699a2a9f3ddfc94dcc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.586 AVG Validation Loss:0.587 AVG Training Acc 72.30 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.584 AVG Validation Loss:0.585 AVG Training Acc 72.27 % AVG Validation Acc 72.31 %\n",
      "Epoch:30/200 AVG Training Loss:0.583 AVG Validation Loss:0.587 AVG Training Acc 72.30 % AVG Validation Acc 72.31 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.577 AVG Validation Loss:0.587 AVG Training Acc 72.44 % AVG Validation Acc 71.77 %\n",
      "Epoch:50/200 AVG Training Loss:0.574 AVG Validation Loss:0.587 AVG Training Acc 72.85 % AVG Validation Acc 71.64 %\n",
      "Epoch:60/200 AVG Training Loss:0.572 AVG Validation Loss:0.591 AVG Training Acc 72.97 % AVG Validation Acc 71.77 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.568 AVG Validation Loss:0.594 AVG Training Acc 73.19 % AVG Validation Acc 71.24 %\n",
      "Epoch:80/200 AVG Training Loss:0.567 AVG Validation Loss:0.594 AVG Training Acc 73.57 % AVG Validation Acc 71.37 %\n",
      "Epoch:90/200 AVG Training Loss:0.567 AVG Validation Loss:0.593 AVG Training Acc 73.39 % AVG Validation Acc 71.64 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.568 AVG Validation Loss:0.593 AVG Training Acc 73.33 % AVG Validation Acc 71.64 %\n",
      "Epoch:110/200 AVG Training Loss:0.569 AVG Validation Loss:0.594 AVG Training Acc 73.10 % AVG Validation Acc 71.64 %\n",
      "Epoch:120/200 AVG Training Loss:0.568 AVG Validation Loss:0.594 AVG Training Acc 73.13 % AVG Validation Acc 71.37 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.567 AVG Validation Loss:0.593 AVG Training Acc 73.22 % AVG Validation Acc 71.51 %\n",
      "Epoch:140/200 AVG Training Loss:0.567 AVG Validation Loss:0.594 AVG Training Acc 73.33 % AVG Validation Acc 71.64 %\n",
      "Epoch:150/200 AVG Training Loss:0.568 AVG Validation Loss:0.594 AVG Training Acc 73.34 % AVG Validation Acc 71.51 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.568 AVG Validation Loss:0.594 AVG Training Acc 73.16 % AVG Validation Acc 71.51 %\n",
      "Epoch:170/200 AVG Training Loss:0.568 AVG Validation Loss:0.593 AVG Training Acc 73.48 % AVG Validation Acc 71.64 %\n",
      "Epoch:180/200 AVG Training Loss:0.568 AVG Validation Loss:0.594 AVG Training Acc 73.27 % AVG Validation Acc 71.51 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.567 AVG Validation Loss:0.593 AVG Training Acc 73.42 % AVG Validation Acc 71.37 %\n",
      "Epoch:200/200 AVG Training Loss:0.567 AVG Validation Loss:0.593 AVG Training Acc 73.15 % AVG Validation Acc 71.77 %\n",
      "Split 17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "099cbfdf58ea44269e6b3ac4dce2de58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.587 AVG Validation Loss:0.586 AVG Training Acc 72.30 % AVG Validation Acc 72.41 %\n",
      "Epoch:20/200 AVG Training Loss:0.584 AVG Validation Loss:0.584 AVG Training Acc 72.25 % AVG Validation Acc 72.41 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.576 AVG Validation Loss:0.585 AVG Training Acc 72.66 % AVG Validation Acc 72.54 %\n",
      "Epoch:40/200 AVG Training Loss:0.572 AVG Validation Loss:0.587 AVG Training Acc 72.72 % AVG Validation Acc 72.54 %\n",
      "New Best Accuracy found: 72.95%\n",
      "Epoch: 43\n",
      "Epoch:50/200 AVG Training Loss:0.565 AVG Validation Loss:0.594 AVG Training Acc 73.17 % AVG Validation Acc 72.01 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.561 AVG Validation Loss:0.595 AVG Training Acc 73.61 % AVG Validation Acc 72.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.558 AVG Validation Loss:0.597 AVG Training Acc 73.52 % AVG Validation Acc 71.74 %\n",
      "Epoch:80/200 AVG Training Loss:0.558 AVG Validation Loss:0.597 AVG Training Acc 73.60 % AVG Validation Acc 71.87 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.554 AVG Validation Loss:0.599 AVG Training Acc 73.82 % AVG Validation Acc 71.87 %\n",
      "Epoch:100/200 AVG Training Loss:0.555 AVG Validation Loss:0.600 AVG Training Acc 74.03 % AVG Validation Acc 71.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.554 AVG Validation Loss:0.599 AVG Training Acc 74.02 % AVG Validation Acc 71.60 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.555 AVG Validation Loss:0.600 AVG Training Acc 73.90 % AVG Validation Acc 71.60 %\n",
      "Epoch:130/200 AVG Training Loss:0.557 AVG Validation Loss:0.600 AVG Training Acc 73.72 % AVG Validation Acc 71.60 %\n",
      "Epoch:140/200 AVG Training Loss:0.554 AVG Validation Loss:0.600 AVG Training Acc 73.91 % AVG Validation Acc 71.74 %\n",
      "Epoch:150/200 AVG Training Loss:0.555 AVG Validation Loss:0.598 AVG Training Acc 73.78 % AVG Validation Acc 71.60 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.554 AVG Validation Loss:0.600 AVG Training Acc 73.90 % AVG Validation Acc 72.01 %\n",
      "Epoch:170/200 AVG Training Loss:0.556 AVG Validation Loss:0.602 AVG Training Acc 73.73 % AVG Validation Acc 71.33 %\n",
      "Epoch:180/200 AVG Training Loss:0.554 AVG Validation Loss:0.600 AVG Training Acc 74.08 % AVG Validation Acc 71.87 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.556 AVG Validation Loss:0.599 AVG Training Acc 73.73 % AVG Validation Acc 71.87 %\n",
      "Epoch:200/200 AVG Training Loss:0.554 AVG Validation Loss:0.599 AVG Training Acc 73.94 % AVG Validation Acc 71.87 %\n",
      "Split 18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74875ad7fb16453982863c1d9b7959c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.587 AVG Validation Loss:0.587 AVG Training Acc 72.30 % AVG Validation Acc 72.27 %\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.581 AVG Validation Loss:0.588 AVG Training Acc 72.31 % AVG Validation Acc 72.27 %\n",
      "Epoch:30/200 AVG Training Loss:0.579 AVG Validation Loss:0.589 AVG Training Acc 72.40 % AVG Validation Acc 72.41 %\n",
      "Epoch:40/200 AVG Training Loss:0.579 AVG Validation Loss:0.593 AVG Training Acc 72.48 % AVG Validation Acc 72.14 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.577 AVG Validation Loss:0.593 AVG Training Acc 72.63 % AVG Validation Acc 72.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.577 AVG Validation Loss:0.593 AVG Training Acc 72.45 % AVG Validation Acc 72.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.577 AVG Validation Loss:0.593 AVG Training Acc 72.43 % AVG Validation Acc 72.14 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.576 AVG Validation Loss:0.593 AVG Training Acc 72.52 % AVG Validation Acc 72.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.576 AVG Validation Loss:0.594 AVG Training Acc 72.52 % AVG Validation Acc 72.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.575 AVG Validation Loss:0.594 AVG Training Acc 72.55 % AVG Validation Acc 72.14 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.575 AVG Validation Loss:0.593 AVG Training Acc 72.51 % AVG Validation Acc 72.14 %\n",
      "Epoch:120/200 AVG Training Loss:0.576 AVG Validation Loss:0.593 AVG Training Acc 72.51 % AVG Validation Acc 72.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.576 AVG Validation Loss:0.593 AVG Training Acc 72.54 % AVG Validation Acc 72.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.576 AVG Validation Loss:0.593 AVG Training Acc 72.52 % AVG Validation Acc 72.14 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.575 AVG Validation Loss:0.593 AVG Training Acc 72.57 % AVG Validation Acc 72.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.575 AVG Validation Loss:0.594 AVG Training Acc 72.46 % AVG Validation Acc 72.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.577 AVG Validation Loss:0.594 AVG Training Acc 72.52 % AVG Validation Acc 72.14 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.575 AVG Validation Loss:0.594 AVG Training Acc 72.51 % AVG Validation Acc 72.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.576 AVG Validation Loss:0.593 AVG Training Acc 72.54 % AVG Validation Acc 72.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.577 AVG Validation Loss:0.594 AVG Training Acc 72.54 % AVG Validation Acc 72.14 %\n",
      "Split 19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be2940922ac4495fb44ab2bb238afa48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.587 AVG Validation Loss:0.586 AVG Training Acc 72.30 % AVG Validation Acc 72.27 %\n",
      "Epoch:20/200 AVG Training Loss:0.584 AVG Validation Loss:0.584 AVG Training Acc 72.28 % AVG Validation Acc 72.27 %\n",
      "Epoch:30/200 AVG Training Loss:0.583 AVG Validation Loss:0.581 AVG Training Acc 72.39 % AVG Validation Acc 72.27 %\n",
      "Epoch:40/200 AVG Training Loss:0.579 AVG Validation Loss:0.580 AVG Training Acc 72.30 % AVG Validation Acc 72.68 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.567 AVG Validation Loss:0.586 AVG Training Acc 72.96 % AVG Validation Acc 72.01 %\n",
      "Epoch:60/200 AVG Training Loss:0.557 AVG Validation Loss:0.591 AVG Training Acc 73.36 % AVG Validation Acc 71.87 %\n",
      "Epoch:70/200 AVG Training Loss:0.546 AVG Validation Loss:0.594 AVG Training Acc 74.14 % AVG Validation Acc 72.54 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.533 AVG Validation Loss:0.608 AVG Training Acc 75.21 % AVG Validation Acc 71.60 %\n",
      "Epoch:90/200 AVG Training Loss:0.531 AVG Validation Loss:0.610 AVG Training Acc 74.85 % AVG Validation Acc 71.20 %\n",
      "Epoch:100/200 AVG Training Loss:0.528 AVG Validation Loss:0.615 AVG Training Acc 75.17 % AVG Validation Acc 71.33 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.526 AVG Validation Loss:0.618 AVG Training Acc 75.17 % AVG Validation Acc 71.20 %\n",
      "Epoch:120/200 AVG Training Loss:0.523 AVG Validation Loss:0.619 AVG Training Acc 75.32 % AVG Validation Acc 70.66 %\n",
      "Epoch:130/200 AVG Training Loss:0.528 AVG Validation Loss:0.615 AVG Training Acc 74.93 % AVG Validation Acc 71.74 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.527 AVG Validation Loss:0.617 AVG Training Acc 75.11 % AVG Validation Acc 70.93 %\n",
      "Epoch:150/200 AVG Training Loss:0.527 AVG Validation Loss:0.615 AVG Training Acc 75.24 % AVG Validation Acc 70.79 %\n",
      "Epoch:160/200 AVG Training Loss:0.527 AVG Validation Loss:0.620 AVG Training Acc 75.11 % AVG Validation Acc 71.06 %\n",
      "Epoch:170/200 AVG Training Loss:0.526 AVG Validation Loss:0.618 AVG Training Acc 75.53 % AVG Validation Acc 71.20 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.524 AVG Validation Loss:0.620 AVG Training Acc 75.24 % AVG Validation Acc 71.20 %\n",
      "Epoch:190/200 AVG Training Loss:0.524 AVG Validation Loss:0.616 AVG Training Acc 75.44 % AVG Validation Acc 71.33 %\n",
      "Epoch:200/200 AVG Training Loss:0.523 AVG Validation Loss:0.617 AVG Training Acc 75.35 % AVG Validation Acc 71.33 %\n",
      "Split 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36838d22340f4d8497878768a7abc789",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.586 AVG Validation Loss:0.583 AVG Training Acc 72.31 % AVG Validation Acc 72.27 %\n",
      "Epoch:20/200 AVG Training Loss:0.584 AVG Validation Loss:0.584 AVG Training Acc 72.30 % AVG Validation Acc 72.27 %\n",
      "Epoch:30/200 AVG Training Loss:0.583 AVG Validation Loss:0.584 AVG Training Acc 72.30 % AVG Validation Acc 72.27 %\n",
      "Epoch:40/200 AVG Training Loss:0.578 AVG Validation Loss:0.589 AVG Training Acc 72.42 % AVG Validation Acc 71.60 %\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.570 AVG Validation Loss:0.582 AVG Training Acc 73.00 % AVG Validation Acc 72.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.564 AVG Validation Loss:0.586 AVG Training Acc 73.26 % AVG Validation Acc 72.01 %\n",
      "Epoch:70/200 AVG Training Loss:0.556 AVG Validation Loss:0.601 AVG Training Acc 73.45 % AVG Validation Acc 71.87 %\n",
      "Epoch    71: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.553 AVG Validation Loss:0.604 AVG Training Acc 73.73 % AVG Validation Acc 71.60 %\n",
      "Epoch:90/200 AVG Training Loss:0.554 AVG Validation Loss:0.607 AVG Training Acc 73.57 % AVG Validation Acc 71.33 %\n",
      "Epoch:100/200 AVG Training Loss:0.551 AVG Validation Loss:0.608 AVG Training Acc 73.84 % AVG Validation Acc 71.33 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.551 AVG Validation Loss:0.608 AVG Training Acc 73.96 % AVG Validation Acc 71.33 %\n",
      "Epoch:120/200 AVG Training Loss:0.549 AVG Validation Loss:0.608 AVG Training Acc 73.94 % AVG Validation Acc 71.33 %\n",
      "Epoch:130/200 AVG Training Loss:0.550 AVG Validation Loss:0.606 AVG Training Acc 74.02 % AVG Validation Acc 71.60 %\n",
      "Epoch   133: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.552 AVG Validation Loss:0.607 AVG Training Acc 73.93 % AVG Validation Acc 71.20 %\n",
      "Epoch:150/200 AVG Training Loss:0.551 AVG Validation Loss:0.607 AVG Training Acc 73.67 % AVG Validation Acc 71.20 %\n",
      "Epoch:160/200 AVG Training Loss:0.553 AVG Validation Loss:0.608 AVG Training Acc 73.61 % AVG Validation Acc 71.20 %\n",
      "Epoch   164: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.550 AVG Validation Loss:0.608 AVG Training Acc 73.87 % AVG Validation Acc 71.20 %\n",
      "Epoch:180/200 AVG Training Loss:0.551 AVG Validation Loss:0.607 AVG Training Acc 73.79 % AVG Validation Acc 71.33 %\n",
      "Epoch:190/200 AVG Training Loss:0.552 AVG Validation Loss:0.608 AVG Training Acc 73.69 % AVG Validation Acc 71.06 %\n",
      "Epoch   195: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.549 AVG Validation Loss:0.608 AVG Training Acc 73.84 % AVG Validation Acc 71.20 %\n",
      "Split 21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55a1eab423c14579958447eba8e45ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.587 AVG Validation Loss:0.590 AVG Training Acc 72.31 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.584 AVG Validation Loss:0.581 AVG Training Acc 72.31 % AVG Validation Acc 72.31 %\n",
      "Epoch:30/200 AVG Training Loss:0.582 AVG Validation Loss:0.583 AVG Training Acc 72.28 % AVG Validation Acc 72.31 %\n",
      "New Best Accuracy found: 72.98%\n",
      "Epoch: 39\n",
      "Epoch:40/200 AVG Training Loss:0.580 AVG Validation Loss:0.580 AVG Training Acc 72.46 % AVG Validation Acc 72.31 %\n",
      "Epoch:50/200 AVG Training Loss:0.579 AVG Validation Loss:0.582 AVG Training Acc 72.24 % AVG Validation Acc 72.45 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.568 AVG Validation Loss:0.587 AVG Training Acc 72.98 % AVG Validation Acc 72.04 %\n",
      "Epoch:70/200 AVG Training Loss:0.559 AVG Validation Loss:0.596 AVG Training Acc 73.22 % AVG Validation Acc 72.31 %\n",
      "Epoch:80/200 AVG Training Loss:0.554 AVG Validation Loss:0.613 AVG Training Acc 73.61 % AVG Validation Acc 72.45 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.550 AVG Validation Loss:0.618 AVG Training Acc 73.91 % AVG Validation Acc 72.31 %\n",
      "Epoch:100/200 AVG Training Loss:0.548 AVG Validation Loss:0.622 AVG Training Acc 73.86 % AVG Validation Acc 72.31 %\n",
      "Epoch:110/200 AVG Training Loss:0.546 AVG Validation Loss:0.620 AVG Training Acc 73.83 % AVG Validation Acc 72.45 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.546 AVG Validation Loss:0.622 AVG Training Acc 73.80 % AVG Validation Acc 72.18 %\n",
      "Epoch:130/200 AVG Training Loss:0.546 AVG Validation Loss:0.621 AVG Training Acc 74.01 % AVG Validation Acc 72.04 %\n",
      "Epoch:140/200 AVG Training Loss:0.546 AVG Validation Loss:0.623 AVG Training Acc 73.76 % AVG Validation Acc 72.18 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.545 AVG Validation Loss:0.623 AVG Training Acc 73.98 % AVG Validation Acc 72.04 %\n",
      "Epoch:160/200 AVG Training Loss:0.544 AVG Validation Loss:0.623 AVG Training Acc 74.10 % AVG Validation Acc 72.31 %\n",
      "Epoch:170/200 AVG Training Loss:0.546 AVG Validation Loss:0.625 AVG Training Acc 73.94 % AVG Validation Acc 71.77 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.546 AVG Validation Loss:0.621 AVG Training Acc 73.97 % AVG Validation Acc 71.91 %\n",
      "Epoch:190/200 AVG Training Loss:0.545 AVG Validation Loss:0.623 AVG Training Acc 73.88 % AVG Validation Acc 71.91 %\n",
      "Epoch:200/200 AVG Training Loss:0.543 AVG Validation Loss:0.623 AVG Training Acc 73.95 % AVG Validation Acc 72.04 %\n",
      "Split 22\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b86f574caaf94104b8903dd9f1dc70bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.586 AVG Validation Loss:0.587 AVG Training Acc 72.25 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.582 AVG Validation Loss:0.586 AVG Training Acc 72.47 % AVG Validation Acc 72.04 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.574 AVG Validation Loss:0.591 AVG Training Acc 72.85 % AVG Validation Acc 71.77 %\n",
      "Epoch:40/200 AVG Training Loss:0.566 AVG Validation Loss:0.605 AVG Training Acc 73.06 % AVG Validation Acc 70.97 %\n",
      "Epoch:50/200 AVG Training Loss:0.560 AVG Validation Loss:0.617 AVG Training Acc 73.68 % AVG Validation Acc 71.24 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.555 AVG Validation Loss:0.625 AVG Training Acc 73.74 % AVG Validation Acc 70.43 %\n",
      "Epoch:70/200 AVG Training Loss:0.553 AVG Validation Loss:0.625 AVG Training Acc 73.95 % AVG Validation Acc 70.43 %\n",
      "Epoch:80/200 AVG Training Loss:0.552 AVG Validation Loss:0.630 AVG Training Acc 73.66 % AVG Validation Acc 70.56 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.550 AVG Validation Loss:0.633 AVG Training Acc 73.79 % AVG Validation Acc 70.56 %\n",
      "Epoch:100/200 AVG Training Loss:0.551 AVG Validation Loss:0.636 AVG Training Acc 73.68 % AVG Validation Acc 70.43 %\n",
      "Epoch:110/200 AVG Training Loss:0.551 AVG Validation Loss:0.638 AVG Training Acc 74.12 % AVG Validation Acc 70.56 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.550 AVG Validation Loss:0.637 AVG Training Acc 73.89 % AVG Validation Acc 70.56 %\n",
      "Epoch:130/200 AVG Training Loss:0.550 AVG Validation Loss:0.639 AVG Training Acc 74.10 % AVG Validation Acc 70.43 %\n",
      "Epoch:140/200 AVG Training Loss:0.550 AVG Validation Loss:0.636 AVG Training Acc 74.15 % AVG Validation Acc 70.70 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.550 AVG Validation Loss:0.637 AVG Training Acc 73.91 % AVG Validation Acc 70.70 %\n",
      "Epoch:160/200 AVG Training Loss:0.550 AVG Validation Loss:0.635 AVG Training Acc 74.15 % AVG Validation Acc 70.56 %\n",
      "Epoch:170/200 AVG Training Loss:0.550 AVG Validation Loss:0.634 AVG Training Acc 74.22 % AVG Validation Acc 70.70 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.549 AVG Validation Loss:0.633 AVG Training Acc 74.30 % AVG Validation Acc 70.56 %\n",
      "Epoch:190/200 AVG Training Loss:0.551 AVG Validation Loss:0.635 AVG Training Acc 73.94 % AVG Validation Acc 70.70 %\n",
      "Epoch:200/200 AVG Training Loss:0.550 AVG Validation Loss:0.636 AVG Training Acc 74.27 % AVG Validation Acc 70.43 %\n",
      "Split 23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "535b6247619e4e169efadff7f3961e5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.587 AVG Validation Loss:0.588 AVG Training Acc 72.31 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.584 AVG Validation Loss:0.586 AVG Training Acc 72.36 % AVG Validation Acc 72.31 %\n",
      "Epoch:30/200 AVG Training Loss:0.581 AVG Validation Loss:0.592 AVG Training Acc 72.40 % AVG Validation Acc 71.91 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.568 AVG Validation Loss:0.597 AVG Training Acc 73.10 % AVG Validation Acc 72.04 %\n",
      "Epoch:50/200 AVG Training Loss:0.565 AVG Validation Loss:0.606 AVG Training Acc 73.18 % AVG Validation Acc 71.91 %\n",
      "Epoch:60/200 AVG Training Loss:0.558 AVG Validation Loss:0.612 AVG Training Acc 73.52 % AVG Validation Acc 71.77 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.554 AVG Validation Loss:0.615 AVG Training Acc 73.66 % AVG Validation Acc 71.37 %\n",
      "Epoch:80/200 AVG Training Loss:0.552 AVG Validation Loss:0.619 AVG Training Acc 73.92 % AVG Validation Acc 71.10 %\n",
      "Epoch:90/200 AVG Training Loss:0.551 AVG Validation Loss:0.627 AVG Training Acc 73.85 % AVG Validation Acc 71.10 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.552 AVG Validation Loss:0.621 AVG Training Acc 73.95 % AVG Validation Acc 71.10 %\n",
      "Epoch:110/200 AVG Training Loss:0.551 AVG Validation Loss:0.617 AVG Training Acc 74.18 % AVG Validation Acc 71.51 %\n",
      "Epoch:120/200 AVG Training Loss:0.551 AVG Validation Loss:0.623 AVG Training Acc 73.95 % AVG Validation Acc 71.10 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.551 AVG Validation Loss:0.620 AVG Training Acc 73.89 % AVG Validation Acc 71.64 %\n",
      "Epoch:140/200 AVG Training Loss:0.553 AVG Validation Loss:0.627 AVG Training Acc 73.95 % AVG Validation Acc 71.24 %\n",
      "Epoch:150/200 AVG Training Loss:0.551 AVG Validation Loss:0.626 AVG Training Acc 73.89 % AVG Validation Acc 71.24 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.552 AVG Validation Loss:0.626 AVG Training Acc 73.88 % AVG Validation Acc 71.10 %\n",
      "Epoch:170/200 AVG Training Loss:0.552 AVG Validation Loss:0.624 AVG Training Acc 73.70 % AVG Validation Acc 71.37 %\n",
      "Epoch:180/200 AVG Training Loss:0.552 AVG Validation Loss:0.629 AVG Training Acc 73.95 % AVG Validation Acc 70.70 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.551 AVG Validation Loss:0.623 AVG Training Acc 74.09 % AVG Validation Acc 71.24 %\n",
      "Epoch:200/200 AVG Training Loss:0.551 AVG Validation Loss:0.627 AVG Training Acc 73.94 % AVG Validation Acc 71.10 %\n",
      "Split 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e823b2ed02a43628c228da383a37e9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.587 AVG Validation Loss:0.585 AVG Training Acc 72.31 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.595 AVG Validation Loss:0.597 AVG Training Acc 72.13 % AVG Validation Acc 72.31 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.584 AVG Validation Loss:0.582 AVG Training Acc 72.33 % AVG Validation Acc 72.31 %\n",
      "Epoch:40/200 AVG Training Loss:0.584 AVG Validation Loss:0.581 AVG Training Acc 72.40 % AVG Validation Acc 72.31 %\n",
      "Epoch:50/200 AVG Training Loss:0.580 AVG Validation Loss:0.582 AVG Training Acc 72.37 % AVG Validation Acc 72.31 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.581 AVG Validation Loss:0.584 AVG Training Acc 72.30 % AVG Validation Acc 72.31 %\n",
      "Epoch:70/200 AVG Training Loss:0.581 AVG Validation Loss:0.584 AVG Training Acc 72.38 % AVG Validation Acc 72.31 %\n",
      "Epoch:80/200 AVG Training Loss:0.579 AVG Validation Loss:0.585 AVG Training Acc 72.37 % AVG Validation Acc 72.31 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.579 AVG Validation Loss:0.584 AVG Training Acc 72.53 % AVG Validation Acc 72.31 %\n",
      "Epoch:100/200 AVG Training Loss:0.580 AVG Validation Loss:0.584 AVG Training Acc 72.46 % AVG Validation Acc 72.31 %\n",
      "Epoch:110/200 AVG Training Loss:0.578 AVG Validation Loss:0.584 AVG Training Acc 72.56 % AVG Validation Acc 72.31 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.579 AVG Validation Loss:0.584 AVG Training Acc 72.30 % AVG Validation Acc 72.31 %\n",
      "Epoch:130/200 AVG Training Loss:0.578 AVG Validation Loss:0.583 AVG Training Acc 72.43 % AVG Validation Acc 72.31 %\n",
      "Epoch:140/200 AVG Training Loss:0.578 AVG Validation Loss:0.584 AVG Training Acc 72.41 % AVG Validation Acc 72.31 %\n",
      "Epoch:150/200 AVG Training Loss:0.580 AVG Validation Loss:0.584 AVG Training Acc 72.52 % AVG Validation Acc 72.31 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.579 AVG Validation Loss:0.584 AVG Training Acc 72.44 % AVG Validation Acc 72.31 %\n",
      "Epoch:170/200 AVG Training Loss:0.578 AVG Validation Loss:0.584 AVG Training Acc 72.53 % AVG Validation Acc 72.31 %\n",
      "Epoch:180/200 AVG Training Loss:0.580 AVG Validation Loss:0.583 AVG Training Acc 72.50 % AVG Validation Acc 72.31 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.578 AVG Validation Loss:0.584 AVG Training Acc 72.65 % AVG Validation Acc 72.31 %\n",
      "Epoch:200/200 AVG Training Loss:0.578 AVG Validation Loss:0.583 AVG Training Acc 72.41 % AVG Validation Acc 72.31 %\n",
      "Split 25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6516fe31f9b474ab37e51b37ffa4894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.587 AVG Validation Loss:0.589 AVG Training Acc 72.34 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.585 AVG Validation Loss:0.593 AVG Training Acc 72.24 % AVG Validation Acc 71.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.581 AVG Validation Loss:0.585 AVG Training Acc 72.30 % AVG Validation Acc 72.31 %\n",
      "Epoch:40/200 AVG Training Loss:0.579 AVG Validation Loss:0.590 AVG Training Acc 72.44 % AVG Validation Acc 72.04 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.569 AVG Validation Loss:0.599 AVG Training Acc 73.03 % AVG Validation Acc 71.64 %\n",
      "Epoch:60/200 AVG Training Loss:0.560 AVG Validation Loss:0.601 AVG Training Acc 73.22 % AVG Validation Acc 70.83 %\n",
      "Epoch:70/200 AVG Training Loss:0.554 AVG Validation Loss:0.618 AVG Training Acc 73.36 % AVG Validation Acc 70.30 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.544 AVG Validation Loss:0.632 AVG Training Acc 74.15 % AVG Validation Acc 70.16 %\n",
      "Epoch:90/200 AVG Training Loss:0.544 AVG Validation Loss:0.636 AVG Training Acc 73.94 % AVG Validation Acc 70.16 %\n",
      "Epoch:100/200 AVG Training Loss:0.545 AVG Validation Loss:0.637 AVG Training Acc 73.80 % AVG Validation Acc 70.56 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.540 AVG Validation Loss:0.642 AVG Training Acc 74.31 % AVG Validation Acc 70.16 %\n",
      "Epoch:120/200 AVG Training Loss:0.542 AVG Validation Loss:0.641 AVG Training Acc 73.94 % AVG Validation Acc 70.30 %\n",
      "Epoch:130/200 AVG Training Loss:0.541 AVG Validation Loss:0.639 AVG Training Acc 74.30 % AVG Validation Acc 70.56 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.540 AVG Validation Loss:0.639 AVG Training Acc 74.27 % AVG Validation Acc 69.76 %\n",
      "Epoch:150/200 AVG Training Loss:0.538 AVG Validation Loss:0.639 AVG Training Acc 74.15 % AVG Validation Acc 70.56 %\n",
      "Epoch:160/200 AVG Training Loss:0.540 AVG Validation Loss:0.643 AVG Training Acc 74.09 % AVG Validation Acc 70.43 %\n",
      "Epoch:170/200 AVG Training Loss:0.540 AVG Validation Loss:0.640 AVG Training Acc 74.24 % AVG Validation Acc 70.30 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.540 AVG Validation Loss:0.642 AVG Training Acc 74.16 % AVG Validation Acc 70.43 %\n",
      "Epoch:190/200 AVG Training Loss:0.541 AVG Validation Loss:0.640 AVG Training Acc 73.94 % AVG Validation Acc 70.03 %\n",
      "Epoch:200/200 AVG Training Loss:0.542 AVG Validation Loss:0.637 AVG Training Acc 73.95 % AVG Validation Acc 70.30 %\n",
      "Split 26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "224bcd12944c4ab49caa62e555c61ba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.586 AVG Validation Loss:0.587 AVG Training Acc 72.31 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.585 AVG Validation Loss:0.584 AVG Training Acc 72.22 % AVG Validation Acc 72.31 %\n",
      "Epoch:30/200 AVG Training Loss:0.583 AVG Validation Loss:0.582 AVG Training Acc 72.33 % AVG Validation Acc 72.31 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.577 AVG Validation Loss:0.583 AVG Training Acc 72.50 % AVG Validation Acc 72.18 %\n",
      "Epoch:50/200 AVG Training Loss:0.573 AVG Validation Loss:0.588 AVG Training Acc 72.73 % AVG Validation Acc 71.91 %\n",
      "Epoch:60/200 AVG Training Loss:0.568 AVG Validation Loss:0.591 AVG Training Acc 72.97 % AVG Validation Acc 71.10 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.562 AVG Validation Loss:0.595 AVG Training Acc 73.21 % AVG Validation Acc 70.43 %\n",
      "Epoch:80/200 AVG Training Loss:0.561 AVG Validation Loss:0.597 AVG Training Acc 73.46 % AVG Validation Acc 70.30 %\n",
      "Epoch:90/200 AVG Training Loss:0.560 AVG Validation Loss:0.599 AVG Training Acc 73.34 % AVG Validation Acc 70.03 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.559 AVG Validation Loss:0.599 AVG Training Acc 73.45 % AVG Validation Acc 70.03 %\n",
      "Epoch:110/200 AVG Training Loss:0.558 AVG Validation Loss:0.598 AVG Training Acc 73.68 % AVG Validation Acc 70.56 %\n",
      "Epoch:120/200 AVG Training Loss:0.558 AVG Validation Loss:0.600 AVG Training Acc 73.68 % AVG Validation Acc 70.16 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.557 AVG Validation Loss:0.599 AVG Training Acc 73.57 % AVG Validation Acc 70.16 %\n",
      "Epoch:140/200 AVG Training Loss:0.558 AVG Validation Loss:0.599 AVG Training Acc 73.60 % AVG Validation Acc 70.16 %\n",
      "Epoch:150/200 AVG Training Loss:0.558 AVG Validation Loss:0.599 AVG Training Acc 73.63 % AVG Validation Acc 70.16 %\n",
      "Epoch:160/200 AVG Training Loss:0.557 AVG Validation Loss:0.599 AVG Training Acc 73.46 % AVG Validation Acc 70.30 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.559 AVG Validation Loss:0.599 AVG Training Acc 73.55 % AVG Validation Acc 70.03 %\n",
      "Epoch:180/200 AVG Training Loss:0.559 AVG Validation Loss:0.599 AVG Training Acc 73.43 % AVG Validation Acc 70.30 %\n",
      "Epoch:190/200 AVG Training Loss:0.560 AVG Validation Loss:0.598 AVG Training Acc 73.55 % AVG Validation Acc 70.43 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.560 AVG Validation Loss:0.598 AVG Training Acc 73.16 % AVG Validation Acc 70.16 %\n",
      "Split 27\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44f9166c631d4c7d890e82f40933efa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.588 AVG Validation Loss:0.588 AVG Training Acc 72.30 % AVG Validation Acc 72.41 %\n",
      "Epoch:20/200 AVG Training Loss:0.585 AVG Validation Loss:0.585 AVG Training Acc 72.30 % AVG Validation Acc 72.41 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.581 AVG Validation Loss:0.584 AVG Training Acc 72.36 % AVG Validation Acc 72.41 %\n",
      "Epoch:40/200 AVG Training Loss:0.578 AVG Validation Loss:0.584 AVG Training Acc 72.42 % AVG Validation Acc 72.54 %\n",
      "Epoch:50/200 AVG Training Loss:0.578 AVG Validation Loss:0.584 AVG Training Acc 72.54 % AVG Validation Acc 72.41 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.577 AVG Validation Loss:0.584 AVG Training Acc 72.42 % AVG Validation Acc 72.41 %\n",
      "Epoch:70/200 AVG Training Loss:0.575 AVG Validation Loss:0.584 AVG Training Acc 72.45 % AVG Validation Acc 72.41 %\n",
      "Epoch:80/200 AVG Training Loss:0.575 AVG Validation Loss:0.584 AVG Training Acc 72.57 % AVG Validation Acc 72.54 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.576 AVG Validation Loss:0.584 AVG Training Acc 72.46 % AVG Validation Acc 72.41 %\n",
      "Epoch:100/200 AVG Training Loss:0.576 AVG Validation Loss:0.584 AVG Training Acc 72.48 % AVG Validation Acc 72.41 %\n",
      "Epoch:110/200 AVG Training Loss:0.575 AVG Validation Loss:0.584 AVG Training Acc 72.46 % AVG Validation Acc 72.41 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.574 AVG Validation Loss:0.584 AVG Training Acc 72.60 % AVG Validation Acc 72.41 %\n",
      "Epoch:130/200 AVG Training Loss:0.576 AVG Validation Loss:0.584 AVG Training Acc 72.49 % AVG Validation Acc 72.41 %\n",
      "Epoch:140/200 AVG Training Loss:0.576 AVG Validation Loss:0.584 AVG Training Acc 72.45 % AVG Validation Acc 72.41 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.577 AVG Validation Loss:0.584 AVG Training Acc 72.61 % AVG Validation Acc 72.41 %\n",
      "Epoch:160/200 AVG Training Loss:0.576 AVG Validation Loss:0.584 AVG Training Acc 72.60 % AVG Validation Acc 72.41 %\n",
      "Epoch:170/200 AVG Training Loss:0.576 AVG Validation Loss:0.584 AVG Training Acc 72.54 % AVG Validation Acc 72.41 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.576 AVG Validation Loss:0.584 AVG Training Acc 72.36 % AVG Validation Acc 72.41 %\n",
      "Epoch:190/200 AVG Training Loss:0.575 AVG Validation Loss:0.584 AVG Training Acc 72.54 % AVG Validation Acc 72.41 %\n",
      "Epoch:200/200 AVG Training Loss:0.575 AVG Validation Loss:0.584 AVG Training Acc 72.52 % AVG Validation Acc 72.41 %\n",
      "Split 28\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3924bb3d97a4584b92e2e81c14a9b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.588 AVG Validation Loss:0.586 AVG Training Acc 72.19 % AVG Validation Acc 72.27 %\n",
      "Epoch:20/200 AVG Training Loss:0.583 AVG Validation Loss:0.585 AVG Training Acc 72.39 % AVG Validation Acc 72.14 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.574 AVG Validation Loss:0.593 AVG Training Acc 73.12 % AVG Validation Acc 71.47 %\n",
      "Epoch:40/200 AVG Training Loss:0.569 AVG Validation Loss:0.607 AVG Training Acc 73.41 % AVG Validation Acc 70.93 %\n",
      "Epoch:50/200 AVG Training Loss:0.563 AVG Validation Loss:0.621 AVG Training Acc 73.72 % AVG Validation Acc 70.93 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.560 AVG Validation Loss:0.619 AVG Training Acc 74.00 % AVG Validation Acc 70.93 %\n",
      "Epoch:70/200 AVG Training Loss:0.556 AVG Validation Loss:0.623 AVG Training Acc 74.11 % AVG Validation Acc 70.66 %\n",
      "Epoch:80/200 AVG Training Loss:0.556 AVG Validation Loss:0.626 AVG Training Acc 74.27 % AVG Validation Acc 71.06 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.554 AVG Validation Loss:0.630 AVG Training Acc 74.27 % AVG Validation Acc 70.66 %\n",
      "Epoch:100/200 AVG Training Loss:0.555 AVG Validation Loss:0.628 AVG Training Acc 74.23 % AVG Validation Acc 70.93 %\n",
      "Epoch:110/200 AVG Training Loss:0.554 AVG Validation Loss:0.629 AVG Training Acc 74.42 % AVG Validation Acc 70.79 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.553 AVG Validation Loss:0.631 AVG Training Acc 74.32 % AVG Validation Acc 71.06 %\n",
      "Epoch:130/200 AVG Training Loss:0.554 AVG Validation Loss:0.629 AVG Training Acc 74.17 % AVG Validation Acc 70.93 %\n",
      "Epoch:140/200 AVG Training Loss:0.555 AVG Validation Loss:0.629 AVG Training Acc 74.36 % AVG Validation Acc 70.79 %\n",
      "Epoch:150/200 AVG Training Loss:0.552 AVG Validation Loss:0.629 AVG Training Acc 74.42 % AVG Validation Acc 70.93 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.554 AVG Validation Loss:0.630 AVG Training Acc 74.39 % AVG Validation Acc 70.52 %\n",
      "Epoch:170/200 AVG Training Loss:0.553 AVG Validation Loss:0.630 AVG Training Acc 74.47 % AVG Validation Acc 70.79 %\n",
      "Epoch:180/200 AVG Training Loss:0.554 AVG Validation Loss:0.626 AVG Training Acc 74.27 % AVG Validation Acc 70.79 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.554 AVG Validation Loss:0.629 AVG Training Acc 74.42 % AVG Validation Acc 70.93 %\n",
      "Epoch:200/200 AVG Training Loss:0.553 AVG Validation Loss:0.633 AVG Training Acc 74.23 % AVG Validation Acc 70.52 %\n",
      "Split 29\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "670ed3eff005493c9656a48f16af2c59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.587 AVG Validation Loss:0.585 AVG Training Acc 72.28 % AVG Validation Acc 72.27 %\n",
      "Epoch:20/200 AVG Training Loss:0.584 AVG Validation Loss:0.582 AVG Training Acc 72.34 % AVG Validation Acc 72.27 %\n",
      "Epoch:30/200 AVG Training Loss:0.582 AVG Validation Loss:0.583 AVG Training Acc 72.37 % AVG Validation Acc 72.68 %\n",
      "Epoch:40/200 AVG Training Loss:0.585 AVG Validation Loss:0.580 AVG Training Acc 72.18 % AVG Validation Acc 72.27 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.570 AVG Validation Loss:0.585 AVG Training Acc 72.85 % AVG Validation Acc 71.06 %\n",
      "Epoch:60/200 AVG Training Loss:0.565 AVG Validation Loss:0.590 AVG Training Acc 73.61 % AVG Validation Acc 71.06 %\n",
      "Epoch:70/200 AVG Training Loss:0.559 AVG Validation Loss:0.593 AVG Training Acc 73.90 % AVG Validation Acc 71.60 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.554 AVG Validation Loss:0.600 AVG Training Acc 74.21 % AVG Validation Acc 71.33 %\n",
      "Epoch:90/200 AVG Training Loss:0.553 AVG Validation Loss:0.603 AVG Training Acc 74.54 % AVG Validation Acc 71.20 %\n",
      "Epoch:100/200 AVG Training Loss:0.552 AVG Validation Loss:0.600 AVG Training Acc 74.57 % AVG Validation Acc 71.87 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.552 AVG Validation Loss:0.604 AVG Training Acc 74.53 % AVG Validation Acc 71.47 %\n",
      "Epoch:120/200 AVG Training Loss:0.550 AVG Validation Loss:0.600 AVG Training Acc 74.51 % AVG Validation Acc 71.74 %\n",
      "Epoch:130/200 AVG Training Loss:0.550 AVG Validation Loss:0.598 AVG Training Acc 74.63 % AVG Validation Acc 71.74 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.550 AVG Validation Loss:0.603 AVG Training Acc 74.75 % AVG Validation Acc 71.33 %\n",
      "Epoch:150/200 AVG Training Loss:0.553 AVG Validation Loss:0.602 AVG Training Acc 74.39 % AVG Validation Acc 71.33 %\n",
      "Epoch:160/200 AVG Training Loss:0.551 AVG Validation Loss:0.603 AVG Training Acc 74.48 % AVG Validation Acc 71.47 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.550 AVG Validation Loss:0.600 AVG Training Acc 74.88 % AVG Validation Acc 72.01 %\n",
      "Epoch:180/200 AVG Training Loss:0.550 AVG Validation Loss:0.602 AVG Training Acc 74.20 % AVG Validation Acc 71.33 %\n",
      "Epoch:190/200 AVG Training Loss:0.552 AVG Validation Loss:0.603 AVG Training Acc 74.36 % AVG Validation Acc 71.47 %\n",
      "Epoch   198: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.553 AVG Validation Loss:0.601 AVG Training Acc 74.36 % AVG Validation Acc 71.47 %\n",
      "Split 30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1055eb75e312448db62e36a9b8512bf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.586 AVG Validation Loss:0.585 AVG Training Acc 72.31 % AVG Validation Acc 72.27 %\n",
      "Epoch:20/200 AVG Training Loss:0.584 AVG Validation Loss:0.587 AVG Training Acc 72.27 % AVG Validation Acc 72.27 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.576 AVG Validation Loss:0.590 AVG Training Acc 72.43 % AVG Validation Acc 72.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.573 AVG Validation Loss:0.591 AVG Training Acc 72.76 % AVG Validation Acc 71.74 %\n",
      "Epoch:50/200 AVG Training Loss:0.572 AVG Validation Loss:0.592 AVG Training Acc 72.79 % AVG Validation Acc 71.74 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.568 AVG Validation Loss:0.596 AVG Training Acc 72.90 % AVG Validation Acc 71.20 %\n",
      "Epoch:70/200 AVG Training Loss:0.567 AVG Validation Loss:0.599 AVG Training Acc 73.09 % AVG Validation Acc 71.06 %\n",
      "Epoch:80/200 AVG Training Loss:0.565 AVG Validation Loss:0.602 AVG Training Acc 73.03 % AVG Validation Acc 70.93 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.566 AVG Validation Loss:0.601 AVG Training Acc 73.09 % AVG Validation Acc 71.06 %\n",
      "Epoch:100/200 AVG Training Loss:0.564 AVG Validation Loss:0.601 AVG Training Acc 73.18 % AVG Validation Acc 71.06 %\n",
      "Epoch:110/200 AVG Training Loss:0.563 AVG Validation Loss:0.602 AVG Training Acc 73.20 % AVG Validation Acc 70.93 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.564 AVG Validation Loss:0.602 AVG Training Acc 73.26 % AVG Validation Acc 70.79 %\n",
      "Epoch:130/200 AVG Training Loss:0.563 AVG Validation Loss:0.601 AVG Training Acc 73.21 % AVG Validation Acc 71.06 %\n",
      "Epoch:140/200 AVG Training Loss:0.565 AVG Validation Loss:0.601 AVG Training Acc 73.30 % AVG Validation Acc 71.20 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.566 AVG Validation Loss:0.602 AVG Training Acc 73.05 % AVG Validation Acc 70.79 %\n",
      "Epoch:160/200 AVG Training Loss:0.564 AVG Validation Loss:0.601 AVG Training Acc 73.11 % AVG Validation Acc 71.20 %\n",
      "Epoch:170/200 AVG Training Loss:0.563 AVG Validation Loss:0.601 AVG Training Acc 73.15 % AVG Validation Acc 71.20 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.564 AVG Validation Loss:0.601 AVG Training Acc 73.20 % AVG Validation Acc 70.93 %\n",
      "Epoch:190/200 AVG Training Loss:0.563 AVG Validation Loss:0.602 AVG Training Acc 73.27 % AVG Validation Acc 71.20 %\n",
      "Epoch:200/200 AVG Training Loss:0.565 AVG Validation Loss:0.602 AVG Training Acc 73.18 % AVG Validation Acc 71.20 %\n",
      "Split 31\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3010555d0a4e4b909ecdd2c345618422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.587 AVG Validation Loss:0.589 AVG Training Acc 72.31 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.583 AVG Validation Loss:0.587 AVG Training Acc 72.27 % AVG Validation Acc 72.31 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.578 AVG Validation Loss:0.591 AVG Training Acc 72.53 % AVG Validation Acc 71.91 %\n",
      "Epoch:40/200 AVG Training Loss:0.573 AVG Validation Loss:0.594 AVG Training Acc 72.70 % AVG Validation Acc 71.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.568 AVG Validation Loss:0.601 AVG Training Acc 72.95 % AVG Validation Acc 71.37 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.564 AVG Validation Loss:0.605 AVG Training Acc 73.30 % AVG Validation Acc 71.37 %\n",
      "Epoch:70/200 AVG Training Loss:0.562 AVG Validation Loss:0.607 AVG Training Acc 73.40 % AVG Validation Acc 71.64 %\n",
      "Epoch:80/200 AVG Training Loss:0.562 AVG Validation Loss:0.609 AVG Training Acc 73.55 % AVG Validation Acc 71.51 %\n",
      "Epoch:90/200 AVG Training Loss:0.561 AVG Validation Loss:0.610 AVG Training Acc 73.43 % AVG Validation Acc 71.51 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.562 AVG Validation Loss:0.611 AVG Training Acc 73.46 % AVG Validation Acc 71.64 %\n",
      "Epoch:110/200 AVG Training Loss:0.560 AVG Validation Loss:0.608 AVG Training Acc 73.39 % AVG Validation Acc 71.64 %\n",
      "Epoch:120/200 AVG Training Loss:0.560 AVG Validation Loss:0.608 AVG Training Acc 73.48 % AVG Validation Acc 71.37 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.559 AVG Validation Loss:0.612 AVG Training Acc 73.61 % AVG Validation Acc 71.51 %\n",
      "Epoch:140/200 AVG Training Loss:0.561 AVG Validation Loss:0.610 AVG Training Acc 73.43 % AVG Validation Acc 71.37 %\n",
      "Epoch:150/200 AVG Training Loss:0.561 AVG Validation Loss:0.609 AVG Training Acc 73.33 % AVG Validation Acc 71.51 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.561 AVG Validation Loss:0.608 AVG Training Acc 73.28 % AVG Validation Acc 71.51 %\n",
      "Epoch:170/200 AVG Training Loss:0.561 AVG Validation Loss:0.608 AVG Training Acc 73.45 % AVG Validation Acc 71.77 %\n",
      "Epoch:180/200 AVG Training Loss:0.560 AVG Validation Loss:0.609 AVG Training Acc 73.37 % AVG Validation Acc 71.64 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.561 AVG Validation Loss:0.607 AVG Training Acc 73.30 % AVG Validation Acc 71.64 %\n",
      "Epoch:200/200 AVG Training Loss:0.559 AVG Validation Loss:0.609 AVG Training Acc 73.37 % AVG Validation Acc 71.64 %\n",
      "Split 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3c46bf8209540d7b00faf69eef84245",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.587 AVG Validation Loss:0.584 AVG Training Acc 72.25 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.583 AVG Validation Loss:0.582 AVG Training Acc 72.33 % AVG Validation Acc 72.31 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.579 AVG Validation Loss:0.589 AVG Training Acc 72.40 % AVG Validation Acc 72.31 %\n",
      "Epoch:40/200 AVG Training Loss:0.573 AVG Validation Loss:0.593 AVG Training Acc 72.95 % AVG Validation Acc 71.64 %\n",
      "Epoch:50/200 AVG Training Loss:0.568 AVG Validation Loss:0.597 AVG Training Acc 73.21 % AVG Validation Acc 70.97 %\n",
      "Epoch:60/200 AVG Training Loss:0.562 AVG Validation Loss:0.600 AVG Training Acc 73.92 % AVG Validation Acc 70.70 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.558 AVG Validation Loss:0.605 AVG Training Acc 73.61 % AVG Validation Acc 70.56 %\n",
      "Epoch:80/200 AVG Training Loss:0.557 AVG Validation Loss:0.607 AVG Training Acc 73.80 % AVG Validation Acc 70.43 %\n",
      "Epoch:90/200 AVG Training Loss:0.555 AVG Validation Loss:0.607 AVG Training Acc 73.94 % AVG Validation Acc 70.70 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.555 AVG Validation Loss:0.608 AVG Training Acc 73.95 % AVG Validation Acc 70.56 %\n",
      "Epoch:110/200 AVG Training Loss:0.554 AVG Validation Loss:0.610 AVG Training Acc 74.03 % AVG Validation Acc 70.56 %\n",
      "Epoch:120/200 AVG Training Loss:0.555 AVG Validation Loss:0.608 AVG Training Acc 74.00 % AVG Validation Acc 70.56 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.555 AVG Validation Loss:0.608 AVG Training Acc 73.88 % AVG Validation Acc 70.83 %\n",
      "Epoch:140/200 AVG Training Loss:0.556 AVG Validation Loss:0.609 AVG Training Acc 73.91 % AVG Validation Acc 70.83 %\n",
      "Epoch:150/200 AVG Training Loss:0.556 AVG Validation Loss:0.608 AVG Training Acc 74.03 % AVG Validation Acc 70.56 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.555 AVG Validation Loss:0.610 AVG Training Acc 73.97 % AVG Validation Acc 70.56 %\n",
      "Epoch:170/200 AVG Training Loss:0.557 AVG Validation Loss:0.606 AVG Training Acc 73.98 % AVG Validation Acc 70.56 %\n",
      "Epoch:180/200 AVG Training Loss:0.555 AVG Validation Loss:0.607 AVG Training Acc 74.01 % AVG Validation Acc 70.70 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.555 AVG Validation Loss:0.609 AVG Training Acc 74.19 % AVG Validation Acc 70.70 %\n",
      "Epoch:200/200 AVG Training Loss:0.555 AVG Validation Loss:0.611 AVG Training Acc 74.04 % AVG Validation Acc 70.56 %\n",
      "Split 33\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0f67ca1387a40868eab78cbddf6e7af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.586 AVG Validation Loss:0.586 AVG Training Acc 72.31 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.585 AVG Validation Loss:0.582 AVG Training Acc 72.37 % AVG Validation Acc 72.31 %\n",
      "Epoch:30/200 AVG Training Loss:0.584 AVG Validation Loss:0.583 AVG Training Acc 72.38 % AVG Validation Acc 72.31 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.578 AVG Validation Loss:0.580 AVG Training Acc 72.65 % AVG Validation Acc 71.77 %\n",
      "Epoch:50/200 AVG Training Loss:0.576 AVG Validation Loss:0.581 AVG Training Acc 72.65 % AVG Validation Acc 71.37 %\n",
      "Epoch:60/200 AVG Training Loss:0.572 AVG Validation Loss:0.587 AVG Training Acc 72.91 % AVG Validation Acc 71.24 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.569 AVG Validation Loss:0.589 AVG Training Acc 73.12 % AVG Validation Acc 70.83 %\n",
      "Epoch:80/200 AVG Training Loss:0.569 AVG Validation Loss:0.591 AVG Training Acc 72.95 % AVG Validation Acc 70.97 %\n",
      "Epoch:90/200 AVG Training Loss:0.567 AVG Validation Loss:0.594 AVG Training Acc 73.04 % AVG Validation Acc 70.97 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.567 AVG Validation Loss:0.594 AVG Training Acc 73.18 % AVG Validation Acc 70.97 %\n",
      "Epoch:110/200 AVG Training Loss:0.567 AVG Validation Loss:0.594 AVG Training Acc 72.98 % AVG Validation Acc 70.97 %\n",
      "Epoch:120/200 AVG Training Loss:0.568 AVG Validation Loss:0.594 AVG Training Acc 73.00 % AVG Validation Acc 71.10 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.566 AVG Validation Loss:0.594 AVG Training Acc 73.06 % AVG Validation Acc 71.10 %\n",
      "Epoch:140/200 AVG Training Loss:0.567 AVG Validation Loss:0.594 AVG Training Acc 73.03 % AVG Validation Acc 71.10 %\n",
      "Epoch:150/200 AVG Training Loss:0.567 AVG Validation Loss:0.595 AVG Training Acc 73.19 % AVG Validation Acc 71.10 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.568 AVG Validation Loss:0.594 AVG Training Acc 73.06 % AVG Validation Acc 71.10 %\n",
      "Epoch:170/200 AVG Training Loss:0.567 AVG Validation Loss:0.595 AVG Training Acc 73.03 % AVG Validation Acc 71.10 %\n",
      "Epoch:180/200 AVG Training Loss:0.568 AVG Validation Loss:0.595 AVG Training Acc 73.00 % AVG Validation Acc 71.10 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.568 AVG Validation Loss:0.594 AVG Training Acc 72.94 % AVG Validation Acc 71.10 %\n",
      "Epoch:200/200 AVG Training Loss:0.567 AVG Validation Loss:0.595 AVG Training Acc 72.82 % AVG Validation Acc 71.10 %\n",
      "Split 34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9d8e216df574e96b4d6899e1e737bd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.594 AVG Validation Loss:0.588 AVG Training Acc 72.07 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.583 AVG Validation Loss:0.584 AVG Training Acc 72.37 % AVG Validation Acc 72.31 %\n",
      "Epoch:30/200 AVG Training Loss:0.583 AVG Validation Loss:0.587 AVG Training Acc 72.47 % AVG Validation Acc 72.31 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.569 AVG Validation Loss:0.594 AVG Training Acc 72.94 % AVG Validation Acc 72.18 %\n",
      "Epoch:50/200 AVG Training Loss:0.562 AVG Validation Loss:0.604 AVG Training Acc 73.61 % AVG Validation Acc 70.97 %\n",
      "Epoch:60/200 AVG Training Loss:0.555 AVG Validation Loss:0.609 AVG Training Acc 73.97 % AVG Validation Acc 71.10 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.551 AVG Validation Loss:0.622 AVG Training Acc 74.51 % AVG Validation Acc 70.43 %\n",
      "Epoch:80/200 AVG Training Loss:0.550 AVG Validation Loss:0.623 AVG Training Acc 74.60 % AVG Validation Acc 70.56 %\n",
      "Epoch:90/200 AVG Training Loss:0.548 AVG Validation Loss:0.623 AVG Training Acc 74.88 % AVG Validation Acc 70.56 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.547 AVG Validation Loss:0.621 AVG Training Acc 74.75 % AVG Validation Acc 70.30 %\n",
      "Epoch:110/200 AVG Training Loss:0.544 AVG Validation Loss:0.621 AVG Training Acc 75.00 % AVG Validation Acc 70.30 %\n",
      "Epoch:120/200 AVG Training Loss:0.546 AVG Validation Loss:0.626 AVG Training Acc 74.67 % AVG Validation Acc 70.43 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.548 AVG Validation Loss:0.625 AVG Training Acc 74.67 % AVG Validation Acc 69.89 %\n",
      "Epoch:140/200 AVG Training Loss:0.548 AVG Validation Loss:0.626 AVG Training Acc 74.75 % AVG Validation Acc 70.30 %\n",
      "Epoch:150/200 AVG Training Loss:0.545 AVG Validation Loss:0.623 AVG Training Acc 74.76 % AVG Validation Acc 70.30 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.548 AVG Validation Loss:0.622 AVG Training Acc 74.70 % AVG Validation Acc 69.89 %\n",
      "Epoch:170/200 AVG Training Loss:0.546 AVG Validation Loss:0.624 AVG Training Acc 74.91 % AVG Validation Acc 70.16 %\n",
      "Epoch:180/200 AVG Training Loss:0.548 AVG Validation Loss:0.623 AVG Training Acc 74.85 % AVG Validation Acc 70.16 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.546 AVG Validation Loss:0.626 AVG Training Acc 74.87 % AVG Validation Acc 70.30 %\n",
      "Epoch:200/200 AVG Training Loss:0.548 AVG Validation Loss:0.623 AVG Training Acc 74.48 % AVG Validation Acc 70.03 %\n",
      "Split 35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b56fdc680074beb96c8c882163de8aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.587 AVG Validation Loss:0.583 AVG Training Acc 72.31 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.585 AVG Validation Loss:0.588 AVG Training Acc 72.30 % AVG Validation Acc 72.31 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.581 AVG Validation Loss:0.585 AVG Training Acc 72.36 % AVG Validation Acc 72.31 %\n",
      "Epoch:40/200 AVG Training Loss:0.580 AVG Validation Loss:0.582 AVG Training Acc 72.46 % AVG Validation Acc 72.45 %\n",
      "Epoch:50/200 AVG Training Loss:0.577 AVG Validation Loss:0.587 AVG Training Acc 72.36 % AVG Validation Acc 72.72 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.575 AVG Validation Loss:0.592 AVG Training Acc 72.71 % AVG Validation Acc 72.18 %\n",
      "Epoch:70/200 AVG Training Loss:0.574 AVG Validation Loss:0.593 AVG Training Acc 72.68 % AVG Validation Acc 72.31 %\n",
      "Epoch:80/200 AVG Training Loss:0.573 AVG Validation Loss:0.593 AVG Training Acc 72.83 % AVG Validation Acc 71.91 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.572 AVG Validation Loss:0.592 AVG Training Acc 72.88 % AVG Validation Acc 72.18 %\n",
      "Epoch:100/200 AVG Training Loss:0.572 AVG Validation Loss:0.593 AVG Training Acc 72.85 % AVG Validation Acc 72.04 %\n",
      "Epoch:110/200 AVG Training Loss:0.575 AVG Validation Loss:0.594 AVG Training Acc 72.86 % AVG Validation Acc 72.04 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.573 AVG Validation Loss:0.593 AVG Training Acc 72.79 % AVG Validation Acc 72.18 %\n",
      "Epoch:130/200 AVG Training Loss:0.572 AVG Validation Loss:0.593 AVG Training Acc 72.73 % AVG Validation Acc 72.31 %\n",
      "Epoch:140/200 AVG Training Loss:0.572 AVG Validation Loss:0.592 AVG Training Acc 72.73 % AVG Validation Acc 72.18 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.573 AVG Validation Loss:0.593 AVG Training Acc 72.89 % AVG Validation Acc 72.04 %\n",
      "Epoch:160/200 AVG Training Loss:0.573 AVG Validation Loss:0.593 AVG Training Acc 72.80 % AVG Validation Acc 72.18 %\n",
      "Epoch:170/200 AVG Training Loss:0.572 AVG Validation Loss:0.593 AVG Training Acc 72.92 % AVG Validation Acc 72.04 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.572 AVG Validation Loss:0.593 AVG Training Acc 72.79 % AVG Validation Acc 72.04 %\n",
      "Epoch:190/200 AVG Training Loss:0.574 AVG Validation Loss:0.593 AVG Training Acc 72.79 % AVG Validation Acc 72.04 %\n",
      "Epoch:200/200 AVG Training Loss:0.572 AVG Validation Loss:0.593 AVG Training Acc 72.91 % AVG Validation Acc 72.04 %\n",
      "Split 36\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda211ad801841bcb9beb4c7e4f58329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.587 AVG Validation Loss:0.587 AVG Training Acc 72.31 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.586 AVG Validation Loss:0.587 AVG Training Acc 72.24 % AVG Validation Acc 72.31 %\n",
      "Epoch:30/200 AVG Training Loss:0.581 AVG Validation Loss:0.583 AVG Training Acc 72.41 % AVG Validation Acc 72.18 %\n",
      "Epoch:40/200 AVG Training Loss:0.577 AVG Validation Loss:0.587 AVG Training Acc 72.50 % AVG Validation Acc 72.72 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.553 AVG Validation Loss:0.595 AVG Training Acc 73.52 % AVG Validation Acc 70.97 %\n",
      "Epoch:60/200 AVG Training Loss:0.532 AVG Validation Loss:0.615 AVG Training Acc 75.70 % AVG Validation Acc 70.56 %\n",
      "Epoch:70/200 AVG Training Loss:0.513 AVG Validation Loss:0.629 AVG Training Acc 76.67 % AVG Validation Acc 69.09 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.501 AVG Validation Loss:0.656 AVG Training Acc 77.62 % AVG Validation Acc 68.28 %\n",
      "Epoch:90/200 AVG Training Loss:0.498 AVG Validation Loss:0.655 AVG Training Acc 77.78 % AVG Validation Acc 68.82 %\n",
      "Epoch:100/200 AVG Training Loss:0.494 AVG Validation Loss:0.680 AVG Training Acc 77.78 % AVG Validation Acc 68.41 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.490 AVG Validation Loss:0.675 AVG Training Acc 78.56 % AVG Validation Acc 67.61 %\n",
      "Epoch:120/200 AVG Training Loss:0.492 AVG Validation Loss:0.691 AVG Training Acc 78.35 % AVG Validation Acc 68.01 %\n",
      "Epoch:130/200 AVG Training Loss:0.492 AVG Validation Loss:0.670 AVG Training Acc 78.00 % AVG Validation Acc 68.41 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.495 AVG Validation Loss:0.687 AVG Training Acc 78.03 % AVG Validation Acc 68.28 %\n",
      "Epoch:150/200 AVG Training Loss:0.494 AVG Validation Loss:0.668 AVG Training Acc 78.05 % AVG Validation Acc 68.15 %\n",
      "Epoch:160/200 AVG Training Loss:0.493 AVG Validation Loss:0.675 AVG Training Acc 77.81 % AVG Validation Acc 67.74 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.495 AVG Validation Loss:0.681 AVG Training Acc 78.14 % AVG Validation Acc 68.28 %\n",
      "Epoch:180/200 AVG Training Loss:0.494 AVG Validation Loss:0.666 AVG Training Acc 77.72 % AVG Validation Acc 68.68 %\n",
      "Epoch:190/200 AVG Training Loss:0.495 AVG Validation Loss:0.690 AVG Training Acc 78.02 % AVG Validation Acc 68.41 %\n",
      "Epoch:200/200 AVG Training Loss:0.491 AVG Validation Loss:0.693 AVG Training Acc 78.05 % AVG Validation Acc 68.01 %\n",
      "Epoch   200: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Split 37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "300dccc0042649e8af7e611d86c2fcfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.587 AVG Validation Loss:0.586 AVG Training Acc 72.30 % AVG Validation Acc 72.41 %\n",
      "Epoch:20/200 AVG Training Loss:0.584 AVG Validation Loss:0.581 AVG Training Acc 72.22 % AVG Validation Acc 72.41 %\n",
      "Epoch:30/200 AVG Training Loss:0.582 AVG Validation Loss:0.581 AVG Training Acc 72.19 % AVG Validation Acc 72.54 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.573 AVG Validation Loss:0.590 AVG Training Acc 72.67 % AVG Validation Acc 72.01 %\n",
      "Epoch:50/200 AVG Training Loss:0.568 AVG Validation Loss:0.596 AVG Training Acc 72.85 % AVG Validation Acc 71.20 %\n",
      "Epoch:60/200 AVG Training Loss:0.563 AVG Validation Loss:0.605 AVG Training Acc 72.79 % AVG Validation Acc 70.66 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.558 AVG Validation Loss:0.605 AVG Training Acc 73.45 % AVG Validation Acc 71.06 %\n",
      "Epoch:80/200 AVG Training Loss:0.557 AVG Validation Loss:0.605 AVG Training Acc 73.66 % AVG Validation Acc 71.06 %\n",
      "Epoch:90/200 AVG Training Loss:0.555 AVG Validation Loss:0.607 AVG Training Acc 73.75 % AVG Validation Acc 71.06 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.556 AVG Validation Loss:0.610 AVG Training Acc 73.70 % AVG Validation Acc 71.20 %\n",
      "Epoch:110/200 AVG Training Loss:0.554 AVG Validation Loss:0.611 AVG Training Acc 73.70 % AVG Validation Acc 71.06 %\n",
      "Epoch:120/200 AVG Training Loss:0.553 AVG Validation Loss:0.610 AVG Training Acc 73.72 % AVG Validation Acc 71.33 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.552 AVG Validation Loss:0.609 AVG Training Acc 73.79 % AVG Validation Acc 71.60 %\n",
      "Epoch:140/200 AVG Training Loss:0.552 AVG Validation Loss:0.610 AVG Training Acc 73.85 % AVG Validation Acc 71.60 %\n",
      "Epoch:150/200 AVG Training Loss:0.554 AVG Validation Loss:0.610 AVG Training Acc 73.73 % AVG Validation Acc 71.20 %\n",
      "Epoch:160/200 AVG Training Loss:0.553 AVG Validation Loss:0.610 AVG Training Acc 73.90 % AVG Validation Acc 71.33 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.551 AVG Validation Loss:0.610 AVG Training Acc 74.03 % AVG Validation Acc 71.33 %\n",
      "Epoch:180/200 AVG Training Loss:0.552 AVG Validation Loss:0.606 AVG Training Acc 73.69 % AVG Validation Acc 71.60 %\n",
      "Epoch:190/200 AVG Training Loss:0.553 AVG Validation Loss:0.608 AVG Training Acc 73.93 % AVG Validation Acc 71.33 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.553 AVG Validation Loss:0.608 AVG Training Acc 73.72 % AVG Validation Acc 71.47 %\n",
      "Split 38\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb5c7cf765fa4e1ba9edd1499ca27c78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.586 AVG Validation Loss:0.585 AVG Training Acc 72.30 % AVG Validation Acc 72.27 %\n",
      "Epoch:20/200 AVG Training Loss:0.583 AVG Validation Loss:0.585 AVG Training Acc 72.36 % AVG Validation Acc 72.27 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.573 AVG Validation Loss:0.596 AVG Training Acc 72.72 % AVG Validation Acc 71.06 %\n",
      "Epoch:40/200 AVG Training Loss:0.567 AVG Validation Loss:0.604 AVG Training Acc 73.15 % AVG Validation Acc 70.79 %\n",
      "Epoch:50/200 AVG Training Loss:0.562 AVG Validation Loss:0.609 AVG Training Acc 73.54 % AVG Validation Acc 71.06 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.557 AVG Validation Loss:0.612 AVG Training Acc 73.72 % AVG Validation Acc 71.20 %\n",
      "Epoch:70/200 AVG Training Loss:0.554 AVG Validation Loss:0.618 AVG Training Acc 73.79 % AVG Validation Acc 70.93 %\n",
      "Epoch:80/200 AVG Training Loss:0.553 AVG Validation Loss:0.625 AVG Training Acc 73.54 % AVG Validation Acc 70.52 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.553 AVG Validation Loss:0.626 AVG Training Acc 73.85 % AVG Validation Acc 70.66 %\n",
      "Epoch:100/200 AVG Training Loss:0.553 AVG Validation Loss:0.626 AVG Training Acc 73.69 % AVG Validation Acc 71.06 %\n",
      "Epoch:110/200 AVG Training Loss:0.553 AVG Validation Loss:0.626 AVG Training Acc 73.79 % AVG Validation Acc 70.79 %\n",
      "Epoch:120/200 AVG Training Loss:0.551 AVG Validation Loss:0.626 AVG Training Acc 74.09 % AVG Validation Acc 70.93 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.553 AVG Validation Loss:0.628 AVG Training Acc 73.78 % AVG Validation Acc 70.79 %\n",
      "Epoch:140/200 AVG Training Loss:0.552 AVG Validation Loss:0.629 AVG Training Acc 73.76 % AVG Validation Acc 70.93 %\n",
      "Epoch:150/200 AVG Training Loss:0.552 AVG Validation Loss:0.631 AVG Training Acc 73.75 % AVG Validation Acc 70.39 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.551 AVG Validation Loss:0.629 AVG Training Acc 73.99 % AVG Validation Acc 70.66 %\n",
      "Epoch:170/200 AVG Training Loss:0.553 AVG Validation Loss:0.629 AVG Training Acc 73.73 % AVG Validation Acc 70.52 %\n",
      "Epoch:180/200 AVG Training Loss:0.552 AVG Validation Loss:0.627 AVG Training Acc 73.97 % AVG Validation Acc 70.93 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.551 AVG Validation Loss:0.631 AVG Training Acc 74.02 % AVG Validation Acc 70.39 %\n",
      "Epoch:200/200 AVG Training Loss:0.553 AVG Validation Loss:0.632 AVG Training Acc 73.57 % AVG Validation Acc 70.66 %\n",
      "Split 39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fc81c27261b4a82ae83924cfcea1a68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.586 AVG Validation Loss:0.587 AVG Training Acc 72.33 % AVG Validation Acc 72.27 %\n",
      "Epoch:20/200 AVG Training Loss:0.583 AVG Validation Loss:0.585 AVG Training Acc 72.36 % AVG Validation Acc 72.41 %\n",
      "Epoch:30/200 AVG Training Loss:0.580 AVG Validation Loss:0.583 AVG Training Acc 72.51 % AVG Validation Acc 72.41 %\n",
      "New Best Accuracy found: 73.22%\n",
      "Epoch: 36\n",
      "Epoch:40/200 AVG Training Loss:0.570 AVG Validation Loss:0.590 AVG Training Acc 73.02 % AVG Validation Acc 72.27 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.548 AVG Validation Loss:0.612 AVG Training Acc 73.91 % AVG Validation Acc 72.27 %\n",
      "Epoch:60/200 AVG Training Loss:0.525 AVG Validation Loss:0.629 AVG Training Acc 75.39 % AVG Validation Acc 71.87 %\n",
      "Epoch:70/200 AVG Training Loss:0.508 AVG Validation Loss:0.657 AVG Training Acc 76.14 % AVG Validation Acc 71.06 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.494 AVG Validation Loss:0.667 AVG Training Acc 76.95 % AVG Validation Acc 69.99 %\n",
      "Epoch:90/200 AVG Training Loss:0.489 AVG Validation Loss:0.689 AVG Training Acc 77.10 % AVG Validation Acc 69.72 %\n",
      "Epoch:100/200 AVG Training Loss:0.488 AVG Validation Loss:0.694 AVG Training Acc 76.81 % AVG Validation Acc 68.64 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.489 AVG Validation Loss:0.693 AVG Training Acc 77.24 % AVG Validation Acc 69.72 %\n",
      "Epoch:120/200 AVG Training Loss:0.486 AVG Validation Loss:0.691 AVG Training Acc 77.39 % AVG Validation Acc 69.18 %\n",
      "Epoch:130/200 AVG Training Loss:0.486 AVG Validation Loss:0.690 AVG Training Acc 77.41 % AVG Validation Acc 68.91 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.694 AVG Training Acc 77.11 % AVG Validation Acc 69.45 %\n",
      "Epoch:150/200 AVG Training Loss:0.487 AVG Validation Loss:0.692 AVG Training Acc 77.29 % AVG Validation Acc 69.04 %\n",
      "Epoch:160/200 AVG Training Loss:0.490 AVG Validation Loss:0.696 AVG Training Acc 76.95 % AVG Validation Acc 69.18 %\n",
      "Epoch:170/200 AVG Training Loss:0.486 AVG Validation Loss:0.690 AVG Training Acc 76.95 % AVG Validation Acc 69.72 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.485 AVG Validation Loss:0.698 AVG Training Acc 77.48 % AVG Validation Acc 69.04 %\n",
      "Epoch:190/200 AVG Training Loss:0.486 AVG Validation Loss:0.699 AVG Training Acc 77.05 % AVG Validation Acc 69.45 %\n",
      "Epoch:200/200 AVG Training Loss:0.486 AVG Validation Loss:0.701 AVG Training Acc 77.27 % AVG Validation Acc 69.45 %\n",
      "Split 40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea5a4386a961405da644295b84d96c0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.587 AVG Validation Loss:0.585 AVG Training Acc 72.31 % AVG Validation Acc 72.27 %\n",
      "Epoch:20/200 AVG Training Loss:0.584 AVG Validation Loss:0.585 AVG Training Acc 72.27 % AVG Validation Acc 72.27 %\n",
      "Epoch:30/200 AVG Training Loss:0.580 AVG Validation Loss:0.584 AVG Training Acc 72.49 % AVG Validation Acc 72.27 %\n",
      "Epoch:40/200 AVG Training Loss:0.589 AVG Validation Loss:0.590 AVG Training Acc 72.25 % AVG Validation Acc 72.27 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.567 AVG Validation Loss:0.593 AVG Training Acc 73.08 % AVG Validation Acc 71.33 %\n",
      "Epoch:60/200 AVG Training Loss:0.559 AVG Validation Loss:0.601 AVG Training Acc 73.79 % AVG Validation Acc 70.93 %\n",
      "Epoch:70/200 AVG Training Loss:0.548 AVG Validation Loss:0.611 AVG Training Acc 74.75 % AVG Validation Acc 70.66 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.537 AVG Validation Loss:0.615 AVG Training Acc 75.66 % AVG Validation Acc 70.66 %\n",
      "Epoch:90/200 AVG Training Loss:0.536 AVG Validation Loss:0.620 AVG Training Acc 75.83 % AVG Validation Acc 70.52 %\n",
      "Epoch:100/200 AVG Training Loss:0.533 AVG Validation Loss:0.622 AVG Training Acc 75.84 % AVG Validation Acc 70.12 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.532 AVG Validation Loss:0.619 AVG Training Acc 75.78 % AVG Validation Acc 70.52 %\n",
      "Epoch:120/200 AVG Training Loss:0.534 AVG Validation Loss:0.624 AVG Training Acc 75.60 % AVG Validation Acc 70.39 %\n",
      "Epoch:130/200 AVG Training Loss:0.534 AVG Validation Loss:0.614 AVG Training Acc 75.72 % AVG Validation Acc 70.66 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.531 AVG Validation Loss:0.619 AVG Training Acc 75.63 % AVG Validation Acc 70.39 %\n",
      "Epoch:150/200 AVG Training Loss:0.533 AVG Validation Loss:0.617 AVG Training Acc 75.69 % AVG Validation Acc 70.66 %\n",
      "Epoch:160/200 AVG Training Loss:0.531 AVG Validation Loss:0.619 AVG Training Acc 75.63 % AVG Validation Acc 70.39 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.532 AVG Validation Loss:0.619 AVG Training Acc 75.72 % AVG Validation Acc 70.52 %\n",
      "Epoch:180/200 AVG Training Loss:0.533 AVG Validation Loss:0.622 AVG Training Acc 75.96 % AVG Validation Acc 70.39 %\n",
      "Epoch:190/200 AVG Training Loss:0.532 AVG Validation Loss:0.623 AVG Training Acc 75.86 % AVG Validation Acc 70.52 %\n",
      "Epoch   198: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.532 AVG Validation Loss:0.623 AVG Training Acc 75.51 % AVG Validation Acc 70.52 %\n",
      "Split 41\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71b6aed595a8489eae08fbcb2fdc4ee9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.586 AVG Validation Loss:0.588 AVG Training Acc 72.21 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.582 AVG Validation Loss:0.586 AVG Training Acc 72.27 % AVG Validation Acc 72.31 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.579 AVG Validation Loss:0.587 AVG Training Acc 72.40 % AVG Validation Acc 72.04 %\n",
      "Epoch:40/200 AVG Training Loss:0.575 AVG Validation Loss:0.589 AVG Training Acc 72.49 % AVG Validation Acc 71.64 %\n",
      "Epoch:50/200 AVG Training Loss:0.572 AVG Validation Loss:0.592 AVG Training Acc 72.71 % AVG Validation Acc 71.91 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.564 AVG Validation Loss:0.599 AVG Training Acc 73.19 % AVG Validation Acc 71.10 %\n",
      "Epoch:70/200 AVG Training Loss:0.562 AVG Validation Loss:0.603 AVG Training Acc 73.19 % AVG Validation Acc 70.56 %\n",
      "Epoch:80/200 AVG Training Loss:0.562 AVG Validation Loss:0.603 AVG Training Acc 72.98 % AVG Validation Acc 70.30 %\n",
      "Epoch:90/200 AVG Training Loss:0.562 AVG Validation Loss:0.603 AVG Training Acc 73.21 % AVG Validation Acc 70.70 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.561 AVG Validation Loss:0.604 AVG Training Acc 72.98 % AVG Validation Acc 70.43 %\n",
      "Epoch:110/200 AVG Training Loss:0.561 AVG Validation Loss:0.604 AVG Training Acc 73.40 % AVG Validation Acc 70.43 %\n",
      "Epoch:120/200 AVG Training Loss:0.560 AVG Validation Loss:0.605 AVG Training Acc 73.43 % AVG Validation Acc 70.56 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.561 AVG Validation Loss:0.605 AVG Training Acc 73.24 % AVG Validation Acc 70.43 %\n",
      "Epoch:140/200 AVG Training Loss:0.560 AVG Validation Loss:0.605 AVG Training Acc 73.15 % AVG Validation Acc 70.43 %\n",
      "Epoch:150/200 AVG Training Loss:0.559 AVG Validation Loss:0.604 AVG Training Acc 73.51 % AVG Validation Acc 70.43 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.560 AVG Validation Loss:0.604 AVG Training Acc 73.22 % AVG Validation Acc 70.43 %\n",
      "Epoch:170/200 AVG Training Loss:0.560 AVG Validation Loss:0.604 AVG Training Acc 72.94 % AVG Validation Acc 70.30 %\n",
      "Epoch:180/200 AVG Training Loss:0.560 AVG Validation Loss:0.606 AVG Training Acc 73.12 % AVG Validation Acc 70.56 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.559 AVG Validation Loss:0.604 AVG Training Acc 73.34 % AVG Validation Acc 70.43 %\n",
      "Epoch:200/200 AVG Training Loss:0.561 AVG Validation Loss:0.605 AVG Training Acc 73.34 % AVG Validation Acc 70.30 %\n",
      "Split 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d475daf27d94ba78f11a6d33406a983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.590 AVG Validation Loss:0.589 AVG Training Acc 72.31 % AVG Validation Acc 72.31 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.584 AVG Validation Loss:0.588 AVG Training Acc 72.31 % AVG Validation Acc 72.31 %\n",
      "Epoch:30/200 AVG Training Loss:0.581 AVG Validation Loss:0.589 AVG Training Acc 72.34 % AVG Validation Acc 72.31 %\n",
      "Epoch:40/200 AVG Training Loss:0.580 AVG Validation Loss:0.589 AVG Training Acc 72.31 % AVG Validation Acc 72.04 %\n",
      "Epoch:50/200 AVG Training Loss:0.579 AVG Validation Loss:0.590 AVG Training Acc 72.61 % AVG Validation Acc 72.18 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.579 AVG Validation Loss:0.589 AVG Training Acc 72.68 % AVG Validation Acc 72.18 %\n",
      "Epoch:70/200 AVG Training Loss:0.578 AVG Validation Loss:0.589 AVG Training Acc 72.71 % AVG Validation Acc 72.04 %\n",
      "Epoch:80/200 AVG Training Loss:0.578 AVG Validation Loss:0.588 AVG Training Acc 72.52 % AVG Validation Acc 71.91 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.578 AVG Validation Loss:0.588 AVG Training Acc 72.56 % AVG Validation Acc 72.18 %\n",
      "Epoch:100/200 AVG Training Loss:0.578 AVG Validation Loss:0.589 AVG Training Acc 72.62 % AVG Validation Acc 71.91 %\n",
      "Epoch:110/200 AVG Training Loss:0.578 AVG Validation Loss:0.588 AVG Training Acc 72.65 % AVG Validation Acc 72.04 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.578 AVG Validation Loss:0.588 AVG Training Acc 72.56 % AVG Validation Acc 72.04 %\n",
      "Epoch:130/200 AVG Training Loss:0.578 AVG Validation Loss:0.589 AVG Training Acc 72.58 % AVG Validation Acc 72.18 %\n",
      "Epoch:140/200 AVG Training Loss:0.578 AVG Validation Loss:0.588 AVG Training Acc 72.59 % AVG Validation Acc 72.04 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.578 AVG Validation Loss:0.589 AVG Training Acc 72.77 % AVG Validation Acc 71.91 %\n",
      "Epoch:160/200 AVG Training Loss:0.578 AVG Validation Loss:0.588 AVG Training Acc 72.49 % AVG Validation Acc 71.91 %\n",
      "Epoch:170/200 AVG Training Loss:0.577 AVG Validation Loss:0.588 AVG Training Acc 72.71 % AVG Validation Acc 71.91 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.577 AVG Validation Loss:0.588 AVG Training Acc 72.61 % AVG Validation Acc 71.91 %\n",
      "Epoch:190/200 AVG Training Loss:0.578 AVG Validation Loss:0.588 AVG Training Acc 72.46 % AVG Validation Acc 72.18 %\n",
      "Epoch:200/200 AVG Training Loss:0.577 AVG Validation Loss:0.588 AVG Training Acc 72.65 % AVG Validation Acc 71.91 %\n",
      "Split 43\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f38b73ea751438fb446d8b3cfef3781",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.587 AVG Validation Loss:0.587 AVG Training Acc 72.31 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.585 AVG Validation Loss:0.584 AVG Training Acc 72.30 % AVG Validation Acc 72.31 %\n",
      "Epoch:30/200 AVG Training Loss:0.582 AVG Validation Loss:0.587 AVG Training Acc 72.43 % AVG Validation Acc 71.91 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.573 AVG Validation Loss:0.595 AVG Training Acc 72.71 % AVG Validation Acc 71.64 %\n",
      "Epoch:50/200 AVG Training Loss:0.569 AVG Validation Loss:0.598 AVG Training Acc 73.12 % AVG Validation Acc 71.64 %\n",
      "Epoch:60/200 AVG Training Loss:0.561 AVG Validation Loss:0.607 AVG Training Acc 73.66 % AVG Validation Acc 70.97 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.557 AVG Validation Loss:0.616 AVG Training Acc 73.73 % AVG Validation Acc 70.43 %\n",
      "Epoch:80/200 AVG Training Loss:0.551 AVG Validation Loss:0.620 AVG Training Acc 74.15 % AVG Validation Acc 70.30 %\n",
      "Epoch:90/200 AVG Training Loss:0.554 AVG Validation Loss:0.619 AVG Training Acc 73.98 % AVG Validation Acc 70.83 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.550 AVG Validation Loss:0.622 AVG Training Acc 74.48 % AVG Validation Acc 70.70 %\n",
      "Epoch:110/200 AVG Training Loss:0.551 AVG Validation Loss:0.620 AVG Training Acc 74.36 % AVG Validation Acc 70.83 %\n",
      "Epoch:120/200 AVG Training Loss:0.550 AVG Validation Loss:0.619 AVG Training Acc 74.45 % AVG Validation Acc 70.97 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.550 AVG Validation Loss:0.620 AVG Training Acc 74.31 % AVG Validation Acc 70.97 %\n",
      "Epoch:140/200 AVG Training Loss:0.550 AVG Validation Loss:0.620 AVG Training Acc 74.54 % AVG Validation Acc 70.83 %\n",
      "Epoch:150/200 AVG Training Loss:0.550 AVG Validation Loss:0.619 AVG Training Acc 74.51 % AVG Validation Acc 70.97 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.549 AVG Validation Loss:0.620 AVG Training Acc 74.55 % AVG Validation Acc 70.97 %\n",
      "Epoch:170/200 AVG Training Loss:0.551 AVG Validation Loss:0.622 AVG Training Acc 74.30 % AVG Validation Acc 70.97 %\n",
      "Epoch:180/200 AVG Training Loss:0.550 AVG Validation Loss:0.620 AVG Training Acc 74.37 % AVG Validation Acc 70.83 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.550 AVG Validation Loss:0.619 AVG Training Acc 74.45 % AVG Validation Acc 70.97 %\n",
      "Epoch:200/200 AVG Training Loss:0.549 AVG Validation Loss:0.622 AVG Training Acc 74.37 % AVG Validation Acc 70.83 %\n",
      "Split 44\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6646eaf1bb1a4ccc8e5f69beaf994d00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.587 AVG Validation Loss:0.585 AVG Training Acc 72.31 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.583 AVG Validation Loss:0.582 AVG Training Acc 72.34 % AVG Validation Acc 72.31 %\n",
      "Epoch:30/200 AVG Training Loss:0.580 AVG Validation Loss:0.584 AVG Training Acc 72.36 % AVG Validation Acc 72.04 %\n",
      "Epoch:40/200 AVG Training Loss:0.579 AVG Validation Loss:0.588 AVG Training Acc 72.43 % AVG Validation Acc 72.18 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.564 AVG Validation Loss:0.591 AVG Training Acc 73.19 % AVG Validation Acc 72.45 %\n",
      "Epoch:60/200 AVG Training Loss:0.554 AVG Validation Loss:0.602 AVG Training Acc 73.89 % AVG Validation Acc 70.97 %\n",
      "Epoch:70/200 AVG Training Loss:0.546 AVG Validation Loss:0.616 AVG Training Acc 74.34 % AVG Validation Acc 70.70 %\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.539 AVG Validation Loss:0.624 AVG Training Acc 74.99 % AVG Validation Acc 70.70 %\n",
      "Epoch:90/200 AVG Training Loss:0.537 AVG Validation Loss:0.625 AVG Training Acc 74.94 % AVG Validation Acc 70.43 %\n",
      "Epoch:100/200 AVG Training Loss:0.535 AVG Validation Loss:0.622 AVG Training Acc 75.06 % AVG Validation Acc 70.70 %\n",
      "Epoch   104: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.534 AVG Validation Loss:0.623 AVG Training Acc 75.18 % AVG Validation Acc 70.43 %\n",
      "Epoch:120/200 AVG Training Loss:0.534 AVG Validation Loss:0.623 AVG Training Acc 75.30 % AVG Validation Acc 70.30 %\n",
      "Epoch:130/200 AVG Training Loss:0.534 AVG Validation Loss:0.627 AVG Training Acc 75.06 % AVG Validation Acc 70.43 %\n",
      "Epoch   135: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.534 AVG Validation Loss:0.627 AVG Training Acc 75.13 % AVG Validation Acc 70.43 %\n",
      "Epoch:150/200 AVG Training Loss:0.533 AVG Validation Loss:0.625 AVG Training Acc 75.33 % AVG Validation Acc 70.97 %\n",
      "Epoch:160/200 AVG Training Loss:0.534 AVG Validation Loss:0.626 AVG Training Acc 74.99 % AVG Validation Acc 71.24 %\n",
      "Epoch   166: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.533 AVG Validation Loss:0.626 AVG Training Acc 75.21 % AVG Validation Acc 70.56 %\n",
      "Epoch:180/200 AVG Training Loss:0.536 AVG Validation Loss:0.624 AVG Training Acc 74.93 % AVG Validation Acc 70.83 %\n",
      "Epoch:190/200 AVG Training Loss:0.534 AVG Validation Loss:0.628 AVG Training Acc 75.18 % AVG Validation Acc 70.43 %\n",
      "Epoch   197: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.534 AVG Validation Loss:0.622 AVG Training Acc 75.15 % AVG Validation Acc 70.43 %\n",
      "Split 45\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eda8a822b7184fd4be42d796d6623572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.586 AVG Validation Loss:0.585 AVG Training Acc 72.31 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.583 AVG Validation Loss:0.584 AVG Training Acc 72.33 % AVG Validation Acc 72.31 %\n",
      "Epoch:30/200 AVG Training Loss:0.579 AVG Validation Loss:0.587 AVG Training Acc 72.40 % AVG Validation Acc 72.18 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.571 AVG Validation Loss:0.587 AVG Training Acc 72.89 % AVG Validation Acc 72.18 %\n",
      "Epoch:50/200 AVG Training Loss:0.562 AVG Validation Loss:0.593 AVG Training Acc 73.63 % AVG Validation Acc 72.45 %\n",
      "Epoch:60/200 AVG Training Loss:0.557 AVG Validation Loss:0.609 AVG Training Acc 73.60 % AVG Validation Acc 71.37 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.552 AVG Validation Loss:0.619 AVG Training Acc 74.01 % AVG Validation Acc 70.97 %\n",
      "Epoch:80/200 AVG Training Loss:0.551 AVG Validation Loss:0.618 AVG Training Acc 74.30 % AVG Validation Acc 70.70 %\n",
      "Epoch:90/200 AVG Training Loss:0.550 AVG Validation Loss:0.623 AVG Training Acc 74.27 % AVG Validation Acc 70.83 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.547 AVG Validation Loss:0.623 AVG Training Acc 74.37 % AVG Validation Acc 70.70 %\n",
      "Epoch:110/200 AVG Training Loss:0.548 AVG Validation Loss:0.622 AVG Training Acc 74.16 % AVG Validation Acc 70.97 %\n",
      "Epoch:120/200 AVG Training Loss:0.548 AVG Validation Loss:0.622 AVG Training Acc 74.04 % AVG Validation Acc 70.97 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.548 AVG Validation Loss:0.622 AVG Training Acc 74.34 % AVG Validation Acc 70.83 %\n",
      "Epoch:140/200 AVG Training Loss:0.548 AVG Validation Loss:0.624 AVG Training Acc 74.21 % AVG Validation Acc 70.83 %\n",
      "Epoch:150/200 AVG Training Loss:0.547 AVG Validation Loss:0.622 AVG Training Acc 74.27 % AVG Validation Acc 70.83 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.549 AVG Validation Loss:0.623 AVG Training Acc 73.97 % AVG Validation Acc 70.83 %\n",
      "Epoch:170/200 AVG Training Loss:0.550 AVG Validation Loss:0.623 AVG Training Acc 73.76 % AVG Validation Acc 70.70 %\n",
      "Epoch:180/200 AVG Training Loss:0.548 AVG Validation Loss:0.623 AVG Training Acc 74.33 % AVG Validation Acc 71.10 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.548 AVG Validation Loss:0.624 AVG Training Acc 74.03 % AVG Validation Acc 71.10 %\n",
      "Epoch:200/200 AVG Training Loss:0.549 AVG Validation Loss:0.623 AVG Training Acc 74.22 % AVG Validation Acc 70.83 %\n",
      "Split 46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df7ee27b6d454c54a8a54a8b83e6918c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.587 AVG Validation Loss:0.585 AVG Training Acc 72.30 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.584 AVG Validation Loss:0.580 AVG Training Acc 72.30 % AVG Validation Acc 72.31 %\n",
      "Epoch:30/200 AVG Training Loss:0.582 AVG Validation Loss:0.585 AVG Training Acc 72.36 % AVG Validation Acc 72.31 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.575 AVG Validation Loss:0.582 AVG Training Acc 72.55 % AVG Validation Acc 72.18 %\n",
      "Epoch:50/200 AVG Training Loss:0.571 AVG Validation Loss:0.582 AVG Training Acc 72.85 % AVG Validation Acc 72.58 %\n",
      "Epoch:60/200 AVG Training Loss:0.567 AVG Validation Loss:0.583 AVG Training Acc 73.03 % AVG Validation Acc 72.58 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.562 AVG Validation Loss:0.586 AVG Training Acc 73.73 % AVG Validation Acc 72.85 %\n",
      "Epoch:80/200 AVG Training Loss:0.560 AVG Validation Loss:0.585 AVG Training Acc 73.43 % AVG Validation Acc 72.31 %\n",
      "Epoch:90/200 AVG Training Loss:0.559 AVG Validation Loss:0.584 AVG Training Acc 73.52 % AVG Validation Acc 72.45 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.559 AVG Validation Loss:0.582 AVG Training Acc 73.60 % AVG Validation Acc 72.45 %\n",
      "Epoch:110/200 AVG Training Loss:0.559 AVG Validation Loss:0.587 AVG Training Acc 73.55 % AVG Validation Acc 72.72 %\n",
      "Epoch:120/200 AVG Training Loss:0.559 AVG Validation Loss:0.586 AVG Training Acc 73.43 % AVG Validation Acc 72.58 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.558 AVG Validation Loss:0.581 AVG Training Acc 73.83 % AVG Validation Acc 72.58 %\n",
      "Epoch:140/200 AVG Training Loss:0.559 AVG Validation Loss:0.583 AVG Training Acc 73.43 % AVG Validation Acc 72.58 %\n",
      "Epoch:150/200 AVG Training Loss:0.558 AVG Validation Loss:0.585 AVG Training Acc 73.70 % AVG Validation Acc 72.58 %\n",
      "Epoch:160/200 AVG Training Loss:0.558 AVG Validation Loss:0.586 AVG Training Acc 73.57 % AVG Validation Acc 72.72 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.558 AVG Validation Loss:0.587 AVG Training Acc 73.49 % AVG Validation Acc 72.45 %\n",
      "Epoch:180/200 AVG Training Loss:0.558 AVG Validation Loss:0.587 AVG Training Acc 73.60 % AVG Validation Acc 72.31 %\n",
      "Epoch:190/200 AVG Training Loss:0.558 AVG Validation Loss:0.582 AVG Training Acc 73.68 % AVG Validation Acc 72.31 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.557 AVG Validation Loss:0.586 AVG Training Acc 73.57 % AVG Validation Acc 72.72 %\n",
      "Split 47\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a3f8a80095b4e89ad0a1e0dceb60f4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.587 AVG Validation Loss:0.583 AVG Training Acc 72.30 % AVG Validation Acc 72.41 %\n",
      "Epoch:20/200 AVG Training Loss:0.583 AVG Validation Loss:0.581 AVG Training Acc 72.43 % AVG Validation Acc 72.41 %\n",
      "Epoch:30/200 AVG Training Loss:0.584 AVG Validation Loss:0.582 AVG Training Acc 72.34 % AVG Validation Acc 72.27 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.577 AVG Validation Loss:0.583 AVG Training Acc 72.72 % AVG Validation Acc 71.74 %\n",
      "Epoch:50/200 AVG Training Loss:0.573 AVG Validation Loss:0.583 AVG Training Acc 72.85 % AVG Validation Acc 72.27 %\n",
      "Epoch:60/200 AVG Training Loss:0.570 AVG Validation Loss:0.585 AVG Training Acc 73.15 % AVG Validation Acc 71.87 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.569 AVG Validation Loss:0.583 AVG Training Acc 73.12 % AVG Validation Acc 72.41 %\n",
      "Epoch:80/200 AVG Training Loss:0.567 AVG Validation Loss:0.584 AVG Training Acc 73.24 % AVG Validation Acc 72.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.565 AVG Validation Loss:0.583 AVG Training Acc 73.39 % AVG Validation Acc 72.27 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.566 AVG Validation Loss:0.584 AVG Training Acc 73.27 % AVG Validation Acc 72.27 %\n",
      "Epoch:110/200 AVG Training Loss:0.567 AVG Validation Loss:0.582 AVG Training Acc 73.29 % AVG Validation Acc 72.27 %\n",
      "Epoch:120/200 AVG Training Loss:0.566 AVG Validation Loss:0.583 AVG Training Acc 73.39 % AVG Validation Acc 72.27 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.567 AVG Validation Loss:0.584 AVG Training Acc 73.18 % AVG Validation Acc 72.41 %\n",
      "Epoch:140/200 AVG Training Loss:0.566 AVG Validation Loss:0.583 AVG Training Acc 73.35 % AVG Validation Acc 72.54 %\n",
      "Epoch:150/200 AVG Training Loss:0.567 AVG Validation Loss:0.585 AVG Training Acc 73.38 % AVG Validation Acc 72.27 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.566 AVG Validation Loss:0.584 AVG Training Acc 73.38 % AVG Validation Acc 72.41 %\n",
      "Epoch:170/200 AVG Training Loss:0.566 AVG Validation Loss:0.583 AVG Training Acc 73.33 % AVG Validation Acc 72.27 %\n",
      "Epoch:180/200 AVG Training Loss:0.564 AVG Validation Loss:0.584 AVG Training Acc 73.45 % AVG Validation Acc 72.41 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.565 AVG Validation Loss:0.584 AVG Training Acc 73.52 % AVG Validation Acc 72.27 %\n",
      "Epoch:200/200 AVG Training Loss:0.566 AVG Validation Loss:0.585 AVG Training Acc 73.49 % AVG Validation Acc 72.14 %\n",
      "Split 48\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "876ce3c720ca4493b9ef567c2d4213ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.586 AVG Validation Loss:0.588 AVG Training Acc 72.31 % AVG Validation Acc 72.27 %\n",
      "Epoch:20/200 AVG Training Loss:0.585 AVG Validation Loss:0.583 AVG Training Acc 72.31 % AVG Validation Acc 72.27 %\n",
      "Epoch:30/200 AVG Training Loss:0.585 AVG Validation Loss:0.581 AVG Training Acc 72.28 % AVG Validation Acc 72.27 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.580 AVG Validation Loss:0.584 AVG Training Acc 72.42 % AVG Validation Acc 72.01 %\n",
      "Epoch:50/200 AVG Training Loss:0.578 AVG Validation Loss:0.585 AVG Training Acc 72.43 % AVG Validation Acc 72.01 %\n",
      "Epoch:60/200 AVG Training Loss:0.576 AVG Validation Loss:0.586 AVG Training Acc 72.55 % AVG Validation Acc 72.01 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.574 AVG Validation Loss:0.589 AVG Training Acc 72.67 % AVG Validation Acc 72.01 %\n",
      "Epoch:80/200 AVG Training Loss:0.572 AVG Validation Loss:0.589 AVG Training Acc 72.55 % AVG Validation Acc 72.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.571 AVG Validation Loss:0.590 AVG Training Acc 72.69 % AVG Validation Acc 72.01 %\n",
      "Epoch:100/200 AVG Training Loss:0.571 AVG Validation Loss:0.591 AVG Training Acc 72.69 % AVG Validation Acc 72.14 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.571 AVG Validation Loss:0.591 AVG Training Acc 72.73 % AVG Validation Acc 72.01 %\n",
      "Epoch:120/200 AVG Training Loss:0.572 AVG Validation Loss:0.591 AVG Training Acc 72.64 % AVG Validation Acc 72.01 %\n",
      "Epoch:130/200 AVG Training Loss:0.572 AVG Validation Loss:0.591 AVG Training Acc 72.66 % AVG Validation Acc 72.01 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.571 AVG Validation Loss:0.591 AVG Training Acc 72.67 % AVG Validation Acc 72.01 %\n",
      "Epoch:150/200 AVG Training Loss:0.572 AVG Validation Loss:0.591 AVG Training Acc 72.55 % AVG Validation Acc 72.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.571 AVG Validation Loss:0.591 AVG Training Acc 72.75 % AVG Validation Acc 72.01 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.571 AVG Validation Loss:0.591 AVG Training Acc 72.85 % AVG Validation Acc 72.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.572 AVG Validation Loss:0.591 AVG Training Acc 72.67 % AVG Validation Acc 72.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.570 AVG Validation Loss:0.591 AVG Training Acc 72.73 % AVG Validation Acc 72.14 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.570 AVG Validation Loss:0.591 AVG Training Acc 72.75 % AVG Validation Acc 72.01 %\n",
      "Split 49\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "999a1fc9ab8b4f398b350438f4689ede",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.587 AVG Validation Loss:0.586 AVG Training Acc 72.31 % AVG Validation Acc 72.27 %\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.582 AVG Validation Loss:0.585 AVG Training Acc 72.31 % AVG Validation Acc 72.27 %\n",
      "Epoch:30/200 AVG Training Loss:0.580 AVG Validation Loss:0.586 AVG Training Acc 72.28 % AVG Validation Acc 72.27 %\n",
      "Epoch:40/200 AVG Training Loss:0.580 AVG Validation Loss:0.586 AVG Training Acc 72.34 % AVG Validation Acc 72.27 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.577 AVG Validation Loss:0.585 AVG Training Acc 72.61 % AVG Validation Acc 72.27 %\n",
      "Epoch:60/200 AVG Training Loss:0.577 AVG Validation Loss:0.585 AVG Training Acc 72.69 % AVG Validation Acc 72.27 %\n",
      "Epoch:70/200 AVG Training Loss:0.576 AVG Validation Loss:0.585 AVG Training Acc 72.75 % AVG Validation Acc 72.27 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.575 AVG Validation Loss:0.586 AVG Training Acc 72.58 % AVG Validation Acc 72.41 %\n",
      "Epoch:90/200 AVG Training Loss:0.576 AVG Validation Loss:0.586 AVG Training Acc 72.57 % AVG Validation Acc 72.27 %\n",
      "Epoch:100/200 AVG Training Loss:0.576 AVG Validation Loss:0.586 AVG Training Acc 72.73 % AVG Validation Acc 72.27 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.576 AVG Validation Loss:0.586 AVG Training Acc 72.72 % AVG Validation Acc 72.27 %\n",
      "Epoch:120/200 AVG Training Loss:0.575 AVG Validation Loss:0.586 AVG Training Acc 72.58 % AVG Validation Acc 72.27 %\n",
      "Epoch:130/200 AVG Training Loss:0.576 AVG Validation Loss:0.586 AVG Training Acc 72.66 % AVG Validation Acc 72.27 %\n",
      "Epoch:140/200 AVG Training Loss:0.575 AVG Validation Loss:0.586 AVG Training Acc 72.75 % AVG Validation Acc 72.27 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.576 AVG Validation Loss:0.586 AVG Training Acc 72.49 % AVG Validation Acc 72.27 %\n",
      "Epoch:160/200 AVG Training Loss:0.575 AVG Validation Loss:0.586 AVG Training Acc 72.67 % AVG Validation Acc 72.27 %\n",
      "Epoch:170/200 AVG Training Loss:0.575 AVG Validation Loss:0.586 AVG Training Acc 72.72 % AVG Validation Acc 72.27 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.576 AVG Validation Loss:0.586 AVG Training Acc 72.63 % AVG Validation Acc 72.27 %\n",
      "Epoch:190/200 AVG Training Loss:0.575 AVG Validation Loss:0.586 AVG Training Acc 72.79 % AVG Validation Acc 72.27 %\n",
      "Epoch:200/200 AVG Training Loss:0.575 AVG Validation Loss:0.586 AVG Training Acc 72.70 % AVG Validation Acc 72.27 %\n",
      "Split 50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb0f066627a4381b623c4b576860c71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.586 AVG Validation Loss:0.594 AVG Training Acc 72.33 % AVG Validation Acc 72.27 %\n",
      "Epoch:20/200 AVG Training Loss:0.583 AVG Validation Loss:0.591 AVG Training Acc 72.31 % AVG Validation Acc 72.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.580 AVG Validation Loss:0.589 AVG Training Acc 72.51 % AVG Validation Acc 72.41 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.584 AVG Validation Loss:0.589 AVG Training Acc 72.49 % AVG Validation Acc 72.54 %\n",
      "Epoch:50/200 AVG Training Loss:0.574 AVG Validation Loss:0.598 AVG Training Acc 72.93 % AVG Validation Acc 70.93 %\n",
      "Epoch:60/200 AVG Training Loss:0.570 AVG Validation Loss:0.615 AVG Training Acc 73.15 % AVG Validation Acc 70.93 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.564 AVG Validation Loss:0.629 AVG Training Acc 73.52 % AVG Validation Acc 70.79 %\n",
      "Epoch:80/200 AVG Training Loss:0.564 AVG Validation Loss:0.634 AVG Training Acc 73.61 % AVG Validation Acc 70.66 %\n",
      "Epoch:90/200 AVG Training Loss:0.565 AVG Validation Loss:0.631 AVG Training Acc 73.45 % AVG Validation Acc 70.66 %\n",
      "Epoch:100/200 AVG Training Loss:0.562 AVG Validation Loss:0.633 AVG Training Acc 73.51 % AVG Validation Acc 70.52 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.563 AVG Validation Loss:0.633 AVG Training Acc 73.64 % AVG Validation Acc 70.66 %\n",
      "Epoch:120/200 AVG Training Loss:0.562 AVG Validation Loss:0.634 AVG Training Acc 73.57 % AVG Validation Acc 70.52 %\n",
      "Epoch:130/200 AVG Training Loss:0.563 AVG Validation Loss:0.634 AVG Training Acc 73.43 % AVG Validation Acc 70.66 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.563 AVG Validation Loss:0.633 AVG Training Acc 73.46 % AVG Validation Acc 70.52 %\n",
      "Epoch:150/200 AVG Training Loss:0.561 AVG Validation Loss:0.633 AVG Training Acc 73.73 % AVG Validation Acc 70.66 %\n",
      "Epoch:160/200 AVG Training Loss:0.563 AVG Validation Loss:0.635 AVG Training Acc 73.57 % AVG Validation Acc 70.52 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.563 AVG Validation Loss:0.635 AVG Training Acc 73.48 % AVG Validation Acc 70.52 %\n",
      "Epoch:180/200 AVG Training Loss:0.562 AVG Validation Loss:0.632 AVG Training Acc 73.52 % AVG Validation Acc 70.79 %\n",
      "Epoch:190/200 AVG Training Loss:0.562 AVG Validation Loss:0.634 AVG Training Acc 73.69 % AVG Validation Acc 70.66 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.563 AVG Validation Loss:0.633 AVG Training Acc 73.70 % AVG Validation Acc 70.79 %\n",
      "Date_threshold_33\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c024e09181f42fdb2f91f5b9b25c92a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exam_fail\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df08aba2a69046b1945ed03e2f81ebc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e889c73e8c544c96b6342f725ff3f154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best Accuracy found: 79.84%\n",
      "Epoch: 1\n",
      "Epoch:10/200 AVG Training Loss:0.487 AVG Validation Loss:0.488 AVG Training Acc 79.90 % AVG Validation Acc 79.84 %\n",
      "New Best Accuracy found: 80.38%\n",
      "Epoch: 13\n",
      "Epoch:20/200 AVG Training Loss:0.475 AVG Validation Loss:0.485 AVG Training Acc 79.95 % AVG Validation Acc 79.84 %\n",
      "New Best Accuracy found: 80.78%\n",
      "Epoch: 26\n",
      "Epoch:30/200 AVG Training Loss:0.469 AVG Validation Loss:0.476 AVG Training Acc 79.90 % AVG Validation Acc 80.11 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.440 AVG Validation Loss:0.488 AVG Training Acc 80.92 % AVG Validation Acc 79.70 %\n",
      "Epoch:50/200 AVG Training Loss:0.419 AVG Validation Loss:0.513 AVG Training Acc 82.07 % AVG Validation Acc 78.76 %\n",
      "Epoch:60/200 AVG Training Loss:0.398 AVG Validation Loss:0.522 AVG Training Acc 82.74 % AVG Validation Acc 79.03 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.385 AVG Validation Loss:0.538 AVG Training Acc 83.23 % AVG Validation Acc 78.63 %\n",
      "Epoch:80/200 AVG Training Loss:0.381 AVG Validation Loss:0.546 AVG Training Acc 83.56 % AVG Validation Acc 78.36 %\n",
      "Epoch:90/200 AVG Training Loss:0.377 AVG Validation Loss:0.547 AVG Training Acc 83.71 % AVG Validation Acc 78.36 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.378 AVG Validation Loss:0.545 AVG Training Acc 83.62 % AVG Validation Acc 77.82 %\n",
      "Epoch:110/200 AVG Training Loss:0.375 AVG Validation Loss:0.550 AVG Training Acc 83.49 % AVG Validation Acc 78.09 %\n",
      "Epoch:120/200 AVG Training Loss:0.376 AVG Validation Loss:0.547 AVG Training Acc 83.43 % AVG Validation Acc 78.09 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.377 AVG Validation Loss:0.547 AVG Training Acc 83.56 % AVG Validation Acc 78.09 %\n",
      "Epoch:140/200 AVG Training Loss:0.376 AVG Validation Loss:0.544 AVG Training Acc 83.74 % AVG Validation Acc 77.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.378 AVG Validation Loss:0.553 AVG Training Acc 83.47 % AVG Validation Acc 77.82 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.377 AVG Validation Loss:0.549 AVG Training Acc 83.64 % AVG Validation Acc 77.82 %\n",
      "Epoch:170/200 AVG Training Loss:0.373 AVG Validation Loss:0.548 AVG Training Acc 83.52 % AVG Validation Acc 77.55 %\n",
      "Epoch:180/200 AVG Training Loss:0.377 AVG Validation Loss:0.550 AVG Training Acc 83.40 % AVG Validation Acc 78.09 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.374 AVG Validation Loss:0.549 AVG Training Acc 83.64 % AVG Validation Acc 78.09 %\n",
      "Epoch:200/200 AVG Training Loss:0.378 AVG Validation Loss:0.547 AVG Training Acc 83.53 % AVG Validation Acc 77.82 %\n",
      "Split 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a12bb372d1624b7180fce6a0f6122f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 79.86 % AVG Validation Acc 79.84 %\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.473 AVG Validation Loss:0.483 AVG Training Acc 79.75 % AVG Validation Acc 79.84 %\n",
      "Epoch:30/200 AVG Training Loss:0.471 AVG Validation Loss:0.486 AVG Training Acc 79.87 % AVG Validation Acc 80.24 %\n",
      "Epoch:40/200 AVG Training Loss:0.466 AVG Validation Loss:0.487 AVG Training Acc 79.98 % AVG Validation Acc 79.57 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.462 AVG Validation Loss:0.487 AVG Training Acc 80.08 % AVG Validation Acc 79.84 %\n",
      "Epoch:60/200 AVG Training Loss:0.460 AVG Validation Loss:0.488 AVG Training Acc 80.04 % AVG Validation Acc 79.84 %\n",
      "Epoch:70/200 AVG Training Loss:0.461 AVG Validation Loss:0.487 AVG Training Acc 80.14 % AVG Validation Acc 79.70 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.461 AVG Validation Loss:0.489 AVG Training Acc 80.19 % AVG Validation Acc 79.70 %\n",
      "Epoch:90/200 AVG Training Loss:0.460 AVG Validation Loss:0.488 AVG Training Acc 80.33 % AVG Validation Acc 79.57 %\n",
      "Epoch:100/200 AVG Training Loss:0.459 AVG Validation Loss:0.488 AVG Training Acc 80.05 % AVG Validation Acc 79.30 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.459 AVG Validation Loss:0.487 AVG Training Acc 80.14 % AVG Validation Acc 79.57 %\n",
      "Epoch:120/200 AVG Training Loss:0.461 AVG Validation Loss:0.487 AVG Training Acc 80.14 % AVG Validation Acc 79.70 %\n",
      "Epoch:130/200 AVG Training Loss:0.460 AVG Validation Loss:0.487 AVG Training Acc 80.27 % AVG Validation Acc 79.44 %\n",
      "Epoch:140/200 AVG Training Loss:0.460 AVG Validation Loss:0.488 AVG Training Acc 80.08 % AVG Validation Acc 79.57 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.459 AVG Validation Loss:0.487 AVG Training Acc 80.19 % AVG Validation Acc 79.57 %\n",
      "Epoch:160/200 AVG Training Loss:0.461 AVG Validation Loss:0.487 AVG Training Acc 80.08 % AVG Validation Acc 79.44 %\n",
      "Epoch:170/200 AVG Training Loss:0.460 AVG Validation Loss:0.488 AVG Training Acc 80.22 % AVG Validation Acc 79.57 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.458 AVG Validation Loss:0.488 AVG Training Acc 80.16 % AVG Validation Acc 79.44 %\n",
      "Epoch:190/200 AVG Training Loss:0.460 AVG Validation Loss:0.489 AVG Training Acc 79.92 % AVG Validation Acc 79.84 %\n",
      "Epoch:200/200 AVG Training Loss:0.460 AVG Validation Loss:0.486 AVG Training Acc 80.11 % AVG Validation Acc 79.84 %\n",
      "Split 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83d73098b36a4055b81dd88d819bad40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.488 AVG Validation Loss:0.476 AVG Training Acc 79.92 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.476 AVG Validation Loss:0.472 AVG Training Acc 79.75 % AVG Validation Acc 79.84 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.465 AVG Validation Loss:0.475 AVG Training Acc 80.04 % AVG Validation Acc 79.44 %\n",
      "Epoch:40/200 AVG Training Loss:0.444 AVG Validation Loss:0.484 AVG Training Acc 80.78 % AVG Validation Acc 79.97 %\n",
      "Epoch:50/200 AVG Training Loss:0.434 AVG Validation Loss:0.499 AVG Training Acc 81.20 % AVG Validation Acc 79.57 %\n",
      "Epoch:60/200 AVG Training Loss:0.423 AVG Validation Loss:0.511 AVG Training Acc 82.01 % AVG Validation Acc 79.70 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.415 AVG Validation Loss:0.512 AVG Training Acc 82.35 % AVG Validation Acc 79.70 %\n",
      "Epoch:80/200 AVG Training Loss:0.414 AVG Validation Loss:0.514 AVG Training Acc 82.52 % AVG Validation Acc 79.30 %\n",
      "Epoch:90/200 AVG Training Loss:0.414 AVG Validation Loss:0.517 AVG Training Acc 82.14 % AVG Validation Acc 79.97 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.411 AVG Validation Loss:0.517 AVG Training Acc 82.49 % AVG Validation Acc 79.84 %\n",
      "Epoch:110/200 AVG Training Loss:0.408 AVG Validation Loss:0.518 AVG Training Acc 82.68 % AVG Validation Acc 79.84 %\n",
      "Epoch:120/200 AVG Training Loss:0.411 AVG Validation Loss:0.514 AVG Training Acc 82.16 % AVG Validation Acc 79.97 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.412 AVG Validation Loss:0.519 AVG Training Acc 82.52 % AVG Validation Acc 79.44 %\n",
      "Epoch:140/200 AVG Training Loss:0.409 AVG Validation Loss:0.518 AVG Training Acc 82.88 % AVG Validation Acc 80.11 %\n",
      "Epoch:150/200 AVG Training Loss:0.412 AVG Validation Loss:0.519 AVG Training Acc 82.38 % AVG Validation Acc 80.11 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.411 AVG Validation Loss:0.519 AVG Training Acc 82.37 % AVG Validation Acc 80.11 %\n",
      "Epoch:170/200 AVG Training Loss:0.411 AVG Validation Loss:0.521 AVG Training Acc 82.37 % AVG Validation Acc 79.70 %\n",
      "Epoch:180/200 AVG Training Loss:0.409 AVG Validation Loss:0.516 AVG Training Acc 82.70 % AVG Validation Acc 79.30 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.408 AVG Validation Loss:0.519 AVG Training Acc 82.52 % AVG Validation Acc 80.11 %\n",
      "Epoch:200/200 AVG Training Loss:0.410 AVG Validation Loss:0.515 AVG Training Acc 82.62 % AVG Validation Acc 79.97 %\n",
      "Split 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "21ec629a6a304d798379ad5e32db240c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.487 AVG Validation Loss:0.484 AVG Training Acc 79.63 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.477 AVG Validation Loss:0.483 AVG Training Acc 79.95 % AVG Validation Acc 79.84 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.463 AVG Validation Loss:0.477 AVG Training Acc 80.20 % AVG Validation Acc 80.24 %\n",
      "Epoch:40/200 AVG Training Loss:0.456 AVG Validation Loss:0.480 AVG Training Acc 80.41 % AVG Validation Acc 80.65 %\n",
      "New Best Accuracy found: 80.91%\n",
      "Epoch: 41\n",
      "New Best Accuracy found: 81.05%\n",
      "Epoch: 44\n",
      "Epoch:50/200 AVG Training Loss:0.450 AVG Validation Loss:0.491 AVG Training Acc 80.65 % AVG Validation Acc 81.05 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.443 AVG Validation Loss:0.494 AVG Training Acc 80.80 % AVG Validation Acc 80.11 %\n",
      "Epoch:70/200 AVG Training Loss:0.444 AVG Validation Loss:0.496 AVG Training Acc 80.95 % AVG Validation Acc 79.97 %\n",
      "Epoch:80/200 AVG Training Loss:0.444 AVG Validation Loss:0.498 AVG Training Acc 80.87 % AVG Validation Acc 80.51 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.440 AVG Validation Loss:0.498 AVG Training Acc 80.81 % AVG Validation Acc 80.24 %\n",
      "Epoch:100/200 AVG Training Loss:0.442 AVG Validation Loss:0.498 AVG Training Acc 80.96 % AVG Validation Acc 80.38 %\n",
      "Epoch:110/200 AVG Training Loss:0.439 AVG Validation Loss:0.499 AVG Training Acc 80.96 % AVG Validation Acc 80.38 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.440 AVG Validation Loss:0.498 AVG Training Acc 80.90 % AVG Validation Acc 80.38 %\n",
      "Epoch:130/200 AVG Training Loss:0.442 AVG Validation Loss:0.498 AVG Training Acc 80.69 % AVG Validation Acc 80.24 %\n",
      "Epoch:140/200 AVG Training Loss:0.440 AVG Validation Loss:0.499 AVG Training Acc 81.11 % AVG Validation Acc 80.38 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.439 AVG Validation Loss:0.498 AVG Training Acc 81.02 % AVG Validation Acc 80.24 %\n",
      "Epoch:160/200 AVG Training Loss:0.440 AVG Validation Loss:0.497 AVG Training Acc 80.80 % AVG Validation Acc 80.65 %\n",
      "Epoch:170/200 AVG Training Loss:0.440 AVG Validation Loss:0.498 AVG Training Acc 80.95 % AVG Validation Acc 80.24 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.439 AVG Validation Loss:0.499 AVG Training Acc 81.28 % AVG Validation Acc 80.38 %\n",
      "Epoch:190/200 AVG Training Loss:0.439 AVG Validation Loss:0.500 AVG Training Acc 81.04 % AVG Validation Acc 80.38 %\n",
      "Epoch:200/200 AVG Training Loss:0.440 AVG Validation Loss:0.498 AVG Training Acc 81.20 % AVG Validation Acc 80.38 %\n",
      "Split 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57831302d5144f51b94c3b9d0bcde477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.484 AVG Validation Loss:0.498 AVG Training Acc 79.68 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.469 AVG Validation Loss:0.500 AVG Training Acc 80.25 % AVG Validation Acc 79.17 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.454 AVG Validation Loss:0.506 AVG Training Acc 80.72 % AVG Validation Acc 79.44 %\n",
      "Epoch:40/200 AVG Training Loss:0.446 AVG Validation Loss:0.506 AVG Training Acc 80.77 % AVG Validation Acc 79.30 %\n",
      "Epoch:50/200 AVG Training Loss:0.433 AVG Validation Loss:0.521 AVG Training Acc 81.17 % AVG Validation Acc 78.09 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.422 AVG Validation Loss:0.526 AVG Training Acc 81.74 % AVG Validation Acc 77.69 %\n",
      "Epoch:70/200 AVG Training Loss:0.419 AVG Validation Loss:0.533 AVG Training Acc 82.22 % AVG Validation Acc 77.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.416 AVG Validation Loss:0.529 AVG Training Acc 82.13 % AVG Validation Acc 78.09 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.415 AVG Validation Loss:0.535 AVG Training Acc 82.02 % AVG Validation Acc 78.23 %\n",
      "Epoch:100/200 AVG Training Loss:0.416 AVG Validation Loss:0.539 AVG Training Acc 82.13 % AVG Validation Acc 78.09 %\n",
      "Epoch:110/200 AVG Training Loss:0.413 AVG Validation Loss:0.534 AVG Training Acc 82.22 % AVG Validation Acc 77.82 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.415 AVG Validation Loss:0.537 AVG Training Acc 82.16 % AVG Validation Acc 77.96 %\n",
      "Epoch:130/200 AVG Training Loss:0.414 AVG Validation Loss:0.535 AVG Training Acc 82.31 % AVG Validation Acc 78.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.414 AVG Validation Loss:0.536 AVG Training Acc 82.40 % AVG Validation Acc 78.09 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.415 AVG Validation Loss:0.532 AVG Training Acc 82.11 % AVG Validation Acc 78.36 %\n",
      "Epoch:160/200 AVG Training Loss:0.415 AVG Validation Loss:0.539 AVG Training Acc 82.41 % AVG Validation Acc 77.55 %\n",
      "Epoch:170/200 AVG Training Loss:0.414 AVG Validation Loss:0.534 AVG Training Acc 82.25 % AVG Validation Acc 78.09 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.415 AVG Validation Loss:0.537 AVG Training Acc 81.89 % AVG Validation Acc 78.23 %\n",
      "Epoch:190/200 AVG Training Loss:0.413 AVG Validation Loss:0.534 AVG Training Acc 81.95 % AVG Validation Acc 78.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.415 AVG Validation Loss:0.538 AVG Training Acc 82.28 % AVG Validation Acc 78.09 %\n",
      "Split 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3067218c6fc64047892bf4875404c449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.481 AVG Validation Loss:0.494 AVG Training Acc 79.99 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.470 AVG Validation Loss:0.497 AVG Training Acc 79.80 % AVG Validation Acc 79.70 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.466 AVG Validation Loss:0.487 AVG Training Acc 80.16 % AVG Validation Acc 80.11 %\n",
      "Epoch:40/200 AVG Training Loss:0.452 AVG Validation Loss:0.494 AVG Training Acc 80.90 % AVG Validation Acc 79.57 %\n",
      "Epoch:50/200 AVG Training Loss:0.440 AVG Validation Loss:0.506 AVG Training Acc 81.81 % AVG Validation Acc 79.57 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.426 AVG Validation Loss:0.521 AVG Training Acc 82.26 % AVG Validation Acc 78.90 %\n",
      "Epoch:70/200 AVG Training Loss:0.423 AVG Validation Loss:0.523 AVG Training Acc 82.76 % AVG Validation Acc 79.03 %\n",
      "Epoch:80/200 AVG Training Loss:0.418 AVG Validation Loss:0.528 AVG Training Acc 82.93 % AVG Validation Acc 78.63 %\n",
      "Epoch:90/200 AVG Training Loss:0.417 AVG Validation Loss:0.527 AVG Training Acc 82.86 % AVG Validation Acc 79.03 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.416 AVG Validation Loss:0.526 AVG Training Acc 82.83 % AVG Validation Acc 78.63 %\n",
      "Epoch:110/200 AVG Training Loss:0.415 AVG Validation Loss:0.524 AVG Training Acc 83.11 % AVG Validation Acc 79.17 %\n",
      "Epoch:120/200 AVG Training Loss:0.417 AVG Validation Loss:0.526 AVG Training Acc 82.98 % AVG Validation Acc 78.90 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.418 AVG Validation Loss:0.523 AVG Training Acc 82.79 % AVG Validation Acc 78.90 %\n",
      "Epoch:140/200 AVG Training Loss:0.415 AVG Validation Loss:0.529 AVG Training Acc 82.93 % AVG Validation Acc 79.17 %\n",
      "Epoch:150/200 AVG Training Loss:0.415 AVG Validation Loss:0.527 AVG Training Acc 82.96 % AVG Validation Acc 78.76 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.419 AVG Validation Loss:0.529 AVG Training Acc 82.98 % AVG Validation Acc 78.63 %\n",
      "Epoch:170/200 AVG Training Loss:0.417 AVG Validation Loss:0.529 AVG Training Acc 82.88 % AVG Validation Acc 79.03 %\n",
      "Epoch:180/200 AVG Training Loss:0.417 AVG Validation Loss:0.531 AVG Training Acc 82.99 % AVG Validation Acc 78.90 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.420 AVG Validation Loss:0.527 AVG Training Acc 82.70 % AVG Validation Acc 78.90 %\n",
      "Epoch:200/200 AVG Training Loss:0.415 AVG Validation Loss:0.530 AVG Training Acc 83.20 % AVG Validation Acc 78.90 %\n",
      "Split 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6508eb141b84f8c8399bcf02030c3c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.487 AVG Validation Loss:0.483 AVG Training Acc 79.83 % AVG Validation Acc 79.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.472 AVG Validation Loss:0.477 AVG Training Acc 79.92 % AVG Validation Acc 79.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.465 AVG Validation Loss:0.480 AVG Training Acc 80.10 % AVG Validation Acc 79.81 %\n",
      "Epoch:40/200 AVG Training Loss:0.451 AVG Validation Loss:0.490 AVG Training Acc 80.71 % AVG Validation Acc 79.68 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.415 AVG Validation Loss:0.504 AVG Training Acc 82.07 % AVG Validation Acc 79.00 %\n",
      "Epoch:60/200 AVG Training Loss:0.393 AVG Validation Loss:0.535 AVG Training Acc 83.36 % AVG Validation Acc 78.06 %\n",
      "Epoch:70/200 AVG Training Loss:0.366 AVG Validation Loss:0.566 AVG Training Acc 84.64 % AVG Validation Acc 78.33 %\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.346 AVG Validation Loss:0.590 AVG Training Acc 85.84 % AVG Validation Acc 78.33 %\n",
      "Epoch:90/200 AVG Training Loss:0.344 AVG Validation Loss:0.599 AVG Training Acc 85.87 % AVG Validation Acc 77.93 %\n",
      "Epoch:100/200 AVG Training Loss:0.341 AVG Validation Loss:0.618 AVG Training Acc 85.76 % AVG Validation Acc 77.39 %\n",
      "Epoch   104: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.339 AVG Validation Loss:0.601 AVG Training Acc 86.13 % AVG Validation Acc 77.79 %\n",
      "Epoch:120/200 AVG Training Loss:0.339 AVG Validation Loss:0.614 AVG Training Acc 85.93 % AVG Validation Acc 77.12 %\n",
      "Epoch:130/200 AVG Training Loss:0.340 AVG Validation Loss:0.613 AVG Training Acc 86.16 % AVG Validation Acc 77.39 %\n",
      "Epoch   135: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.338 AVG Validation Loss:0.619 AVG Training Acc 86.10 % AVG Validation Acc 76.99 %\n",
      "Epoch:150/200 AVG Training Loss:0.341 AVG Validation Loss:0.612 AVG Training Acc 85.93 % AVG Validation Acc 77.12 %\n",
      "Epoch:160/200 AVG Training Loss:0.340 AVG Validation Loss:0.624 AVG Training Acc 86.05 % AVG Validation Acc 77.12 %\n",
      "Epoch   166: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.341 AVG Validation Loss:0.617 AVG Training Acc 86.09 % AVG Validation Acc 76.85 %\n",
      "Epoch:180/200 AVG Training Loss:0.344 AVG Validation Loss:0.615 AVG Training Acc 85.37 % AVG Validation Acc 77.25 %\n",
      "Epoch:190/200 AVG Training Loss:0.337 AVG Validation Loss:0.608 AVG Training Acc 86.36 % AVG Validation Acc 77.66 %\n",
      "Epoch   197: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.337 AVG Validation Loss:0.618 AVG Training Acc 86.08 % AVG Validation Acc 76.99 %\n",
      "Split 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e76ec0fe96e444f8f7d2c712423e62a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.486 AVG Validation Loss:0.484 AVG Training Acc 79.61 % AVG Validation Acc 79.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.474 AVG Validation Loss:0.464 AVG Training Acc 79.70 % AVG Validation Acc 79.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.464 AVG Validation Loss:0.468 AVG Training Acc 79.95 % AVG Validation Acc 80.08 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.437 AVG Validation Loss:0.499 AVG Training Acc 80.55 % AVG Validation Acc 81.02 %\n",
      "New Best Accuracy found: 81.16%\n",
      "Epoch: 49\n",
      "Epoch:50/200 AVG Training Loss:0.419 AVG Validation Loss:0.520 AVG Training Acc 81.11 % AVG Validation Acc 81.29 %\n",
      "New Best Accuracy found: 81.29%\n",
      "Epoch: 50\n",
      "Epoch:60/200 AVG Training Loss:0.403 AVG Validation Loss:0.541 AVG Training Acc 81.74 % AVG Validation Acc 79.95 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.382 AVG Validation Loss:0.559 AVG Training Acc 82.59 % AVG Validation Acc 79.41 %\n",
      "Epoch:80/200 AVG Training Loss:0.383 AVG Validation Loss:0.555 AVG Training Acc 82.92 % AVG Validation Acc 79.54 %\n",
      "Epoch:90/200 AVG Training Loss:0.377 AVG Validation Loss:0.565 AVG Training Acc 83.13 % AVG Validation Acc 79.27 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.372 AVG Validation Loss:0.569 AVG Training Acc 83.56 % AVG Validation Acc 79.27 %\n",
      "Epoch:110/200 AVG Training Loss:0.373 AVG Validation Loss:0.574 AVG Training Acc 83.09 % AVG Validation Acc 79.14 %\n",
      "Epoch:120/200 AVG Training Loss:0.371 AVG Validation Loss:0.573 AVG Training Acc 83.00 % AVG Validation Acc 79.14 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.371 AVG Validation Loss:0.574 AVG Training Acc 83.10 % AVG Validation Acc 79.00 %\n",
      "Epoch:140/200 AVG Training Loss:0.373 AVG Validation Loss:0.570 AVG Training Acc 83.28 % AVG Validation Acc 78.73 %\n",
      "Epoch:150/200 AVG Training Loss:0.374 AVG Validation Loss:0.570 AVG Training Acc 83.33 % AVG Validation Acc 79.27 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.371 AVG Validation Loss:0.572 AVG Training Acc 83.04 % AVG Validation Acc 78.73 %\n",
      "Epoch:170/200 AVG Training Loss:0.373 AVG Validation Loss:0.576 AVG Training Acc 83.01 % AVG Validation Acc 79.00 %\n",
      "Epoch:180/200 AVG Training Loss:0.372 AVG Validation Loss:0.579 AVG Training Acc 83.09 % AVG Validation Acc 79.00 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.373 AVG Validation Loss:0.573 AVG Training Acc 83.31 % AVG Validation Acc 78.87 %\n",
      "Epoch:200/200 AVG Training Loss:0.371 AVG Validation Loss:0.570 AVG Training Acc 83.28 % AVG Validation Acc 79.54 %\n",
      "Split 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8368915a91314147adf029b7ead19583",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.482 AVG Validation Loss:0.485 AVG Training Acc 79.71 % AVG Validation Acc 79.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.472 AVG Validation Loss:0.477 AVG Training Acc 80.11 % AVG Validation Acc 80.08 %\n",
      "Epoch:30/200 AVG Training Loss:0.465 AVG Validation Loss:0.477 AVG Training Acc 80.13 % AVG Validation Acc 79.68 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.437 AVG Validation Loss:0.494 AVG Training Acc 80.79 % AVG Validation Acc 79.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.417 AVG Validation Loss:0.516 AVG Training Acc 82.01 % AVG Validation Acc 78.20 %\n",
      "Epoch:60/200 AVG Training Loss:0.396 AVG Validation Loss:0.561 AVG Training Acc 83.42 % AVG Validation Acc 77.39 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.378 AVG Validation Loss:0.566 AVG Training Acc 83.91 % AVG Validation Acc 77.12 %\n",
      "Epoch:80/200 AVG Training Loss:0.375 AVG Validation Loss:0.569 AVG Training Acc 83.94 % AVG Validation Acc 76.99 %\n",
      "Epoch:90/200 AVG Training Loss:0.373 AVG Validation Loss:0.574 AVG Training Acc 84.19 % AVG Validation Acc 76.72 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.373 AVG Validation Loss:0.581 AVG Training Acc 84.49 % AVG Validation Acc 76.58 %\n",
      "Epoch:110/200 AVG Training Loss:0.372 AVG Validation Loss:0.576 AVG Training Acc 84.55 % AVG Validation Acc 76.58 %\n",
      "Epoch:120/200 AVG Training Loss:0.369 AVG Validation Loss:0.585 AVG Training Acc 84.25 % AVG Validation Acc 76.85 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.369 AVG Validation Loss:0.588 AVG Training Acc 84.40 % AVG Validation Acc 75.91 %\n",
      "Epoch:140/200 AVG Training Loss:0.370 AVG Validation Loss:0.578 AVG Training Acc 84.28 % AVG Validation Acc 76.31 %\n",
      "Epoch:150/200 AVG Training Loss:0.370 AVG Validation Loss:0.581 AVG Training Acc 84.48 % AVG Validation Acc 76.58 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.367 AVG Validation Loss:0.577 AVG Training Acc 84.40 % AVG Validation Acc 76.58 %\n",
      "Epoch:170/200 AVG Training Loss:0.373 AVG Validation Loss:0.585 AVG Training Acc 84.19 % AVG Validation Acc 76.99 %\n",
      "Epoch:180/200 AVG Training Loss:0.373 AVG Validation Loss:0.576 AVG Training Acc 84.45 % AVG Validation Acc 76.18 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.369 AVG Validation Loss:0.579 AVG Training Acc 84.57 % AVG Validation Acc 76.18 %\n",
      "Epoch:200/200 AVG Training Loss:0.369 AVG Validation Loss:0.585 AVG Training Acc 84.43 % AVG Validation Acc 76.72 %\n",
      "Split 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "893999ea014c46e09890e28829b414f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.486 AVG Validation Loss:0.489 AVG Training Acc 79.93 % AVG Validation Acc 79.81 %\n",
      "Epoch:20/200 AVG Training Loss:0.475 AVG Validation Loss:0.482 AVG Training Acc 79.78 % AVG Validation Acc 79.81 %\n",
      "Epoch:30/200 AVG Training Loss:0.467 AVG Validation Loss:0.487 AVG Training Acc 80.04 % AVG Validation Acc 79.81 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.465 AVG Validation Loss:0.476 AVG Training Acc 80.23 % AVG Validation Acc 79.81 %\n",
      "Epoch:50/200 AVG Training Loss:0.446 AVG Validation Loss:0.474 AVG Training Acc 80.55 % AVG Validation Acc 79.41 %\n",
      "Epoch:60/200 AVG Training Loss:0.424 AVG Validation Loss:0.489 AVG Training Acc 81.50 % AVG Validation Acc 79.41 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.403 AVG Validation Loss:0.501 AVG Training Acc 82.46 % AVG Validation Acc 78.20 %\n",
      "Epoch:80/200 AVG Training Loss:0.397 AVG Validation Loss:0.503 AVG Training Acc 82.73 % AVG Validation Acc 78.73 %\n",
      "Epoch:90/200 AVG Training Loss:0.397 AVG Validation Loss:0.500 AVG Training Acc 82.55 % AVG Validation Acc 78.73 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.396 AVG Validation Loss:0.499 AVG Training Acc 82.77 % AVG Validation Acc 78.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.394 AVG Validation Loss:0.500 AVG Training Acc 82.70 % AVG Validation Acc 79.00 %\n",
      "Epoch:120/200 AVG Training Loss:0.393 AVG Validation Loss:0.503 AVG Training Acc 82.49 % AVG Validation Acc 78.87 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.392 AVG Validation Loss:0.502 AVG Training Acc 82.76 % AVG Validation Acc 78.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.391 AVG Validation Loss:0.503 AVG Training Acc 82.68 % AVG Validation Acc 78.87 %\n",
      "Epoch:150/200 AVG Training Loss:0.388 AVG Validation Loss:0.501 AVG Training Acc 83.03 % AVG Validation Acc 79.27 %\n",
      "Epoch:160/200 AVG Training Loss:0.394 AVG Validation Loss:0.504 AVG Training Acc 82.61 % AVG Validation Acc 78.47 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.394 AVG Validation Loss:0.500 AVG Training Acc 82.38 % AVG Validation Acc 79.00 %\n",
      "Epoch:180/200 AVG Training Loss:0.392 AVG Validation Loss:0.503 AVG Training Acc 82.76 % AVG Validation Acc 78.87 %\n",
      "Epoch:190/200 AVG Training Loss:0.390 AVG Validation Loss:0.498 AVG Training Acc 82.95 % AVG Validation Acc 78.73 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.391 AVG Validation Loss:0.496 AVG Training Acc 82.68 % AVG Validation Acc 79.14 %\n",
      "Split 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6cc9a20c8d5d4d16bfdf6bf08f971c72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.483 AVG Validation Loss:0.484 AVG Training Acc 80.01 % AVG Validation Acc 79.84 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.471 AVG Validation Loss:0.468 AVG Training Acc 80.11 % AVG Validation Acc 80.38 %\n",
      "Epoch:30/200 AVG Training Loss:0.464 AVG Validation Loss:0.474 AVG Training Acc 80.10 % AVG Validation Acc 80.11 %\n",
      "Epoch:40/200 AVG Training Loss:0.461 AVG Validation Loss:0.475 AVG Training Acc 80.11 % AVG Validation Acc 79.84 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.449 AVG Validation Loss:0.487 AVG Training Acc 80.65 % AVG Validation Acc 79.30 %\n",
      "Epoch:60/200 AVG Training Loss:0.447 AVG Validation Loss:0.490 AVG Training Acc 80.77 % AVG Validation Acc 79.03 %\n",
      "Epoch:70/200 AVG Training Loss:0.446 AVG Validation Loss:0.495 AVG Training Acc 80.74 % AVG Validation Acc 78.63 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.443 AVG Validation Loss:0.497 AVG Training Acc 80.84 % AVG Validation Acc 78.36 %\n",
      "Epoch:90/200 AVG Training Loss:0.445 AVG Validation Loss:0.497 AVG Training Acc 80.90 % AVG Validation Acc 78.63 %\n",
      "Epoch:100/200 AVG Training Loss:0.444 AVG Validation Loss:0.497 AVG Training Acc 81.07 % AVG Validation Acc 78.63 %\n",
      "Epoch:110/200 AVG Training Loss:0.442 AVG Validation Loss:0.498 AVG Training Acc 81.14 % AVG Validation Acc 78.49 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.443 AVG Validation Loss:0.498 AVG Training Acc 80.83 % AVG Validation Acc 78.63 %\n",
      "Epoch:130/200 AVG Training Loss:0.443 AVG Validation Loss:0.496 AVG Training Acc 81.14 % AVG Validation Acc 78.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.444 AVG Validation Loss:0.499 AVG Training Acc 81.19 % AVG Validation Acc 78.63 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.444 AVG Validation Loss:0.497 AVG Training Acc 80.69 % AVG Validation Acc 78.63 %\n",
      "Epoch:160/200 AVG Training Loss:0.441 AVG Validation Loss:0.497 AVG Training Acc 81.19 % AVG Validation Acc 78.23 %\n",
      "Epoch:170/200 AVG Training Loss:0.443 AVG Validation Loss:0.496 AVG Training Acc 80.89 % AVG Validation Acc 78.76 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.445 AVG Validation Loss:0.498 AVG Training Acc 80.45 % AVG Validation Acc 78.49 %\n",
      "Epoch:190/200 AVG Training Loss:0.446 AVG Validation Loss:0.497 AVG Training Acc 81.07 % AVG Validation Acc 78.63 %\n",
      "Epoch:200/200 AVG Training Loss:0.443 AVG Validation Loss:0.497 AVG Training Acc 81.20 % AVG Validation Acc 78.49 %\n",
      "Split 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b65ac01888b048098d186791751bcafe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.483 AVG Validation Loss:0.475 AVG Training Acc 79.77 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.476 AVG Validation Loss:0.474 AVG Training Acc 79.78 % AVG Validation Acc 79.70 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.464 AVG Validation Loss:0.481 AVG Training Acc 80.23 % AVG Validation Acc 79.17 %\n",
      "Epoch:40/200 AVG Training Loss:0.452 AVG Validation Loss:0.494 AVG Training Acc 80.86 % AVG Validation Acc 79.03 %\n",
      "Epoch:50/200 AVG Training Loss:0.443 AVG Validation Loss:0.508 AVG Training Acc 81.59 % AVG Validation Acc 77.82 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.435 AVG Validation Loss:0.523 AVG Training Acc 81.89 % AVG Validation Acc 77.96 %\n",
      "Epoch:70/200 AVG Training Loss:0.432 AVG Validation Loss:0.526 AVG Training Acc 81.65 % AVG Validation Acc 78.09 %\n",
      "Epoch:80/200 AVG Training Loss:0.432 AVG Validation Loss:0.528 AVG Training Acc 81.72 % AVG Validation Acc 77.96 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.429 AVG Validation Loss:0.533 AVG Training Acc 82.05 % AVG Validation Acc 77.82 %\n",
      "Epoch:100/200 AVG Training Loss:0.431 AVG Validation Loss:0.532 AVG Training Acc 82.17 % AVG Validation Acc 77.82 %\n",
      "Epoch:110/200 AVG Training Loss:0.431 AVG Validation Loss:0.534 AVG Training Acc 82.04 % AVG Validation Acc 77.96 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.431 AVG Validation Loss:0.534 AVG Training Acc 81.98 % AVG Validation Acc 77.69 %\n",
      "Epoch:130/200 AVG Training Loss:0.427 AVG Validation Loss:0.533 AVG Training Acc 82.29 % AVG Validation Acc 77.82 %\n",
      "Epoch:140/200 AVG Training Loss:0.428 AVG Validation Loss:0.532 AVG Training Acc 82.11 % AVG Validation Acc 77.82 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.428 AVG Validation Loss:0.534 AVG Training Acc 82.17 % AVG Validation Acc 77.82 %\n",
      "Epoch:160/200 AVG Training Loss:0.428 AVG Validation Loss:0.534 AVG Training Acc 82.41 % AVG Validation Acc 77.82 %\n",
      "Epoch:170/200 AVG Training Loss:0.428 AVG Validation Loss:0.533 AVG Training Acc 82.26 % AVG Validation Acc 77.82 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.429 AVG Validation Loss:0.534 AVG Training Acc 82.08 % AVG Validation Acc 77.82 %\n",
      "Epoch:190/200 AVG Training Loss:0.428 AVG Validation Loss:0.533 AVG Training Acc 82.38 % AVG Validation Acc 77.82 %\n",
      "Epoch:200/200 AVG Training Loss:0.430 AVG Validation Loss:0.535 AVG Training Acc 82.10 % AVG Validation Acc 77.82 %\n",
      "Split 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e44e4ed25404ceb9e4aaa83dc602d84",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.480 AVG Validation Loss:0.483 AVG Training Acc 79.83 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.471 AVG Validation Loss:0.473 AVG Training Acc 80.07 % AVG Validation Acc 80.51 %\n",
      "Epoch:30/200 AVG Training Loss:0.462 AVG Validation Loss:0.473 AVG Training Acc 79.98 % AVG Validation Acc 80.51 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.434 AVG Validation Loss:0.496 AVG Training Acc 81.68 % AVG Validation Acc 80.11 %\n",
      "Epoch:50/200 AVG Training Loss:0.416 AVG Validation Loss:0.518 AVG Training Acc 82.56 % AVG Validation Acc 79.17 %\n",
      "Epoch:60/200 AVG Training Loss:0.405 AVG Validation Loss:0.536 AVG Training Acc 82.80 % AVG Validation Acc 78.76 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.398 AVG Validation Loss:0.543 AVG Training Acc 83.14 % AVG Validation Acc 78.76 %\n",
      "Epoch:80/200 AVG Training Loss:0.397 AVG Validation Loss:0.544 AVG Training Acc 83.44 % AVG Validation Acc 78.90 %\n",
      "Epoch:90/200 AVG Training Loss:0.394 AVG Validation Loss:0.554 AVG Training Acc 83.73 % AVG Validation Acc 78.76 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.392 AVG Validation Loss:0.548 AVG Training Acc 83.67 % AVG Validation Acc 78.76 %\n",
      "Epoch:110/200 AVG Training Loss:0.389 AVG Validation Loss:0.552 AVG Training Acc 84.01 % AVG Validation Acc 79.03 %\n",
      "Epoch:120/200 AVG Training Loss:0.391 AVG Validation Loss:0.553 AVG Training Acc 83.73 % AVG Validation Acc 79.03 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.392 AVG Validation Loss:0.553 AVG Training Acc 83.74 % AVG Validation Acc 79.03 %\n",
      "Epoch:140/200 AVG Training Loss:0.389 AVG Validation Loss:0.555 AVG Training Acc 83.85 % AVG Validation Acc 79.03 %\n",
      "Epoch:150/200 AVG Training Loss:0.391 AVG Validation Loss:0.555 AVG Training Acc 83.95 % AVG Validation Acc 79.03 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.392 AVG Validation Loss:0.553 AVG Training Acc 83.88 % AVG Validation Acc 79.03 %\n",
      "Epoch:170/200 AVG Training Loss:0.390 AVG Validation Loss:0.555 AVG Training Acc 84.07 % AVG Validation Acc 78.90 %\n",
      "Epoch:180/200 AVG Training Loss:0.390 AVG Validation Loss:0.549 AVG Training Acc 83.85 % AVG Validation Acc 79.03 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.388 AVG Validation Loss:0.551 AVG Training Acc 83.94 % AVG Validation Acc 79.03 %\n",
      "Epoch:200/200 AVG Training Loss:0.390 AVG Validation Loss:0.553 AVG Training Acc 83.82 % AVG Validation Acc 79.03 %\n",
      "Split 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e885695948604baf9546c1b4f3d8caca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.485 AVG Validation Loss:0.483 AVG Training Acc 79.87 % AVG Validation Acc 79.97 %\n",
      "Epoch:20/200 AVG Training Loss:0.475 AVG Validation Loss:0.475 AVG Training Acc 79.95 % AVG Validation Acc 79.70 %\n",
      "Epoch:30/200 AVG Training Loss:0.463 AVG Validation Loss:0.481 AVG Training Acc 80.07 % AVG Validation Acc 79.44 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.482 AVG Validation Loss:0.486 AVG Training Acc 79.83 % AVG Validation Acc 80.38 %\n",
      "Epoch:50/200 AVG Training Loss:0.469 AVG Validation Loss:0.485 AVG Training Acc 80.35 % AVG Validation Acc 79.84 %\n",
      "Epoch:60/200 AVG Training Loss:0.460 AVG Validation Loss:0.488 AVG Training Acc 80.66 % AVG Validation Acc 79.84 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.454 AVG Validation Loss:0.486 AVG Training Acc 80.66 % AVG Validation Acc 79.70 %\n",
      "Epoch:80/200 AVG Training Loss:0.457 AVG Validation Loss:0.487 AVG Training Acc 80.30 % AVG Validation Acc 79.30 %\n",
      "Epoch:90/200 AVG Training Loss:0.452 AVG Validation Loss:0.486 AVG Training Acc 80.48 % AVG Validation Acc 79.70 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.451 AVG Validation Loss:0.487 AVG Training Acc 80.84 % AVG Validation Acc 79.70 %\n",
      "Epoch:110/200 AVG Training Loss:0.454 AVG Validation Loss:0.488 AVG Training Acc 80.26 % AVG Validation Acc 79.57 %\n",
      "Epoch:120/200 AVG Training Loss:0.453 AVG Validation Loss:0.489 AVG Training Acc 80.41 % AVG Validation Acc 79.17 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.452 AVG Validation Loss:0.488 AVG Training Acc 80.68 % AVG Validation Acc 79.44 %\n",
      "Epoch:140/200 AVG Training Loss:0.452 AVG Validation Loss:0.487 AVG Training Acc 80.42 % AVG Validation Acc 79.57 %\n",
      "Epoch:150/200 AVG Training Loss:0.450 AVG Validation Loss:0.488 AVG Training Acc 80.66 % AVG Validation Acc 79.57 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.453 AVG Validation Loss:0.490 AVG Training Acc 80.54 % AVG Validation Acc 79.30 %\n",
      "Epoch:170/200 AVG Training Loss:0.452 AVG Validation Loss:0.485 AVG Training Acc 80.69 % AVG Validation Acc 79.70 %\n",
      "Epoch:180/200 AVG Training Loss:0.451 AVG Validation Loss:0.489 AVG Training Acc 80.60 % AVG Validation Acc 79.57 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.451 AVG Validation Loss:0.487 AVG Training Acc 80.35 % AVG Validation Acc 79.57 %\n",
      "Epoch:200/200 AVG Training Loss:0.452 AVG Validation Loss:0.490 AVG Training Acc 80.63 % AVG Validation Acc 79.70 %\n",
      "Split 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff1120487bf42bdb52a1e01290adf6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.483 AVG Validation Loss:0.499 AVG Training Acc 79.98 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.473 AVG Validation Loss:0.492 AVG Training Acc 80.19 % AVG Validation Acc 79.70 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.455 AVG Validation Loss:0.501 AVG Training Acc 80.59 % AVG Validation Acc 78.23 %\n",
      "Epoch:40/200 AVG Training Loss:0.446 AVG Validation Loss:0.505 AVG Training Acc 80.98 % AVG Validation Acc 78.36 %\n",
      "Epoch:50/200 AVG Training Loss:0.434 AVG Validation Loss:0.516 AVG Training Acc 81.92 % AVG Validation Acc 78.49 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.423 AVG Validation Loss:0.528 AVG Training Acc 82.20 % AVG Validation Acc 78.49 %\n",
      "Epoch:70/200 AVG Training Loss:0.417 AVG Validation Loss:0.531 AVG Training Acc 82.58 % AVG Validation Acc 79.03 %\n",
      "Epoch:80/200 AVG Training Loss:0.415 AVG Validation Loss:0.536 AVG Training Acc 82.68 % AVG Validation Acc 78.63 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.412 AVG Validation Loss:0.538 AVG Training Acc 82.95 % AVG Validation Acc 78.63 %\n",
      "Epoch:100/200 AVG Training Loss:0.413 AVG Validation Loss:0.537 AVG Training Acc 82.49 % AVG Validation Acc 78.63 %\n",
      "Epoch:110/200 AVG Training Loss:0.412 AVG Validation Loss:0.537 AVG Training Acc 82.74 % AVG Validation Acc 78.76 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.414 AVG Validation Loss:0.540 AVG Training Acc 82.83 % AVG Validation Acc 78.49 %\n",
      "Epoch:130/200 AVG Training Loss:0.411 AVG Validation Loss:0.539 AVG Training Acc 83.17 % AVG Validation Acc 78.63 %\n",
      "Epoch:140/200 AVG Training Loss:0.414 AVG Validation Loss:0.537 AVG Training Acc 82.82 % AVG Validation Acc 78.23 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.413 AVG Validation Loss:0.541 AVG Training Acc 82.62 % AVG Validation Acc 78.36 %\n",
      "Epoch:160/200 AVG Training Loss:0.412 AVG Validation Loss:0.538 AVG Training Acc 82.61 % AVG Validation Acc 78.76 %\n",
      "Epoch:170/200 AVG Training Loss:0.413 AVG Validation Loss:0.538 AVG Training Acc 82.82 % AVG Validation Acc 78.49 %\n",
      "Epoch:180/200 AVG Training Loss:0.413 AVG Validation Loss:0.540 AVG Training Acc 82.62 % AVG Validation Acc 78.76 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.413 AVG Validation Loss:0.536 AVG Training Acc 82.95 % AVG Validation Acc 78.36 %\n",
      "Epoch:200/200 AVG Training Loss:0.413 AVG Validation Loss:0.538 AVG Training Acc 82.67 % AVG Validation Acc 78.49 %\n",
      "Split 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d161a13bb7fe46e09ce88b512dde52fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.486 AVG Validation Loss:0.485 AVG Training Acc 79.90 % AVG Validation Acc 79.84 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.472 AVG Validation Loss:0.478 AVG Training Acc 79.99 % AVG Validation Acc 80.38 %\n",
      "Epoch:30/200 AVG Training Loss:0.467 AVG Validation Loss:0.476 AVG Training Acc 79.95 % AVG Validation Acc 80.24 %\n",
      "Epoch:40/200 AVG Training Loss:0.463 AVG Validation Loss:0.473 AVG Training Acc 80.41 % AVG Validation Acc 80.38 %\n",
      "Epoch:50/200 AVG Training Loss:0.459 AVG Validation Loss:0.471 AVG Training Acc 80.51 % AVG Validation Acc 80.51 %\n",
      "Epoch:60/200 AVG Training Loss:0.451 AVG Validation Loss:0.472 AVG Training Acc 80.72 % AVG Validation Acc 80.38 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.442 AVG Validation Loss:0.473 AVG Training Acc 80.90 % AVG Validation Acc 79.97 %\n",
      "Epoch:80/200 AVG Training Loss:0.442 AVG Validation Loss:0.474 AVG Training Acc 81.05 % AVG Validation Acc 80.11 %\n",
      "Epoch:90/200 AVG Training Loss:0.437 AVG Validation Loss:0.473 AVG Training Acc 81.13 % AVG Validation Acc 79.97 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.441 AVG Validation Loss:0.475 AVG Training Acc 81.23 % AVG Validation Acc 80.11 %\n",
      "Epoch:110/200 AVG Training Loss:0.438 AVG Validation Loss:0.474 AVG Training Acc 81.32 % AVG Validation Acc 80.11 %\n",
      "Epoch:120/200 AVG Training Loss:0.438 AVG Validation Loss:0.474 AVG Training Acc 81.05 % AVG Validation Acc 79.84 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.440 AVG Validation Loss:0.474 AVG Training Acc 81.25 % AVG Validation Acc 80.11 %\n",
      "Epoch:140/200 AVG Training Loss:0.438 AVG Validation Loss:0.474 AVG Training Acc 80.98 % AVG Validation Acc 80.11 %\n",
      "Epoch:150/200 AVG Training Loss:0.438 AVG Validation Loss:0.475 AVG Training Acc 81.02 % AVG Validation Acc 80.11 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.438 AVG Validation Loss:0.475 AVG Training Acc 81.31 % AVG Validation Acc 79.84 %\n",
      "Epoch:170/200 AVG Training Loss:0.439 AVG Validation Loss:0.474 AVG Training Acc 81.08 % AVG Validation Acc 80.24 %\n",
      "Epoch:180/200 AVG Training Loss:0.437 AVG Validation Loss:0.474 AVG Training Acc 81.32 % AVG Validation Acc 79.97 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.437 AVG Validation Loss:0.475 AVG Training Acc 81.44 % AVG Validation Acc 79.97 %\n",
      "Epoch:200/200 AVG Training Loss:0.438 AVG Validation Loss:0.474 AVG Training Acc 81.28 % AVG Validation Acc 80.11 %\n",
      "Split 17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b6dae628fb849fda798f7daaff26810",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.487 AVG Validation Loss:0.474 AVG Training Acc 79.81 % AVG Validation Acc 80.08 %\n",
      "Epoch:20/200 AVG Training Loss:0.479 AVG Validation Loss:0.474 AVG Training Acc 79.81 % AVG Validation Acc 79.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.468 AVG Validation Loss:0.484 AVG Training Acc 79.92 % AVG Validation Acc 79.95 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.444 AVG Validation Loss:0.474 AVG Training Acc 80.86 % AVG Validation Acc 80.08 %\n",
      "Epoch:50/200 AVG Training Loss:0.430 AVG Validation Loss:0.488 AVG Training Acc 81.26 % AVG Validation Acc 79.54 %\n",
      "Epoch:60/200 AVG Training Loss:0.412 AVG Validation Loss:0.513 AVG Training Acc 82.16 % AVG Validation Acc 78.33 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.401 AVG Validation Loss:0.512 AVG Training Acc 82.50 % AVG Validation Acc 77.39 %\n",
      "Epoch:80/200 AVG Training Loss:0.394 AVG Validation Loss:0.518 AVG Training Acc 83.07 % AVG Validation Acc 76.99 %\n",
      "Epoch:90/200 AVG Training Loss:0.393 AVG Validation Loss:0.522 AVG Training Acc 83.18 % AVG Validation Acc 76.85 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.392 AVG Validation Loss:0.524 AVG Training Acc 83.13 % AVG Validation Acc 76.72 %\n",
      "Epoch:110/200 AVG Training Loss:0.392 AVG Validation Loss:0.522 AVG Training Acc 83.25 % AVG Validation Acc 76.58 %\n",
      "Epoch:120/200 AVG Training Loss:0.391 AVG Validation Loss:0.523 AVG Training Acc 83.22 % AVG Validation Acc 76.58 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.392 AVG Validation Loss:0.523 AVG Training Acc 83.19 % AVG Validation Acc 76.45 %\n",
      "Epoch:140/200 AVG Training Loss:0.391 AVG Validation Loss:0.524 AVG Training Acc 83.51 % AVG Validation Acc 76.58 %\n",
      "Epoch:150/200 AVG Training Loss:0.392 AVG Validation Loss:0.524 AVG Training Acc 83.40 % AVG Validation Acc 76.85 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.390 AVG Validation Loss:0.524 AVG Training Acc 83.07 % AVG Validation Acc 76.31 %\n",
      "Epoch:170/200 AVG Training Loss:0.389 AVG Validation Loss:0.523 AVG Training Acc 83.06 % AVG Validation Acc 76.85 %\n",
      "Epoch:180/200 AVG Training Loss:0.391 AVG Validation Loss:0.524 AVG Training Acc 83.24 % AVG Validation Acc 76.31 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.390 AVG Validation Loss:0.521 AVG Training Acc 83.34 % AVG Validation Acc 76.58 %\n",
      "Epoch:200/200 AVG Training Loss:0.388 AVG Validation Loss:0.524 AVG Training Acc 83.25 % AVG Validation Acc 76.31 %\n",
      "Split 18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8dce38373c2459b9bdba0969524968f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.486 AVG Validation Loss:0.492 AVG Training Acc 79.77 % AVG Validation Acc 79.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.473 AVG Validation Loss:0.485 AVG Training Acc 80.01 % AVG Validation Acc 79.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.473 AVG Validation Loss:0.482 AVG Training Acc 79.98 % AVG Validation Acc 79.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.499 AVG Validation Loss:0.492 AVG Training Acc 79.73 % AVG Validation Acc 79.95 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 79.90 % AVG Validation Acc 79.95 %\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 79.89 % AVG Validation Acc 79.95 %\n",
      "Epoch:70/200 AVG Training Loss:0.484 AVG Validation Loss:0.494 AVG Training Acc 79.93 % AVG Validation Acc 79.95 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.481 AVG Validation Loss:0.495 AVG Training Acc 79.92 % AVG Validation Acc 79.81 %\n",
      "Epoch:90/200 AVG Training Loss:0.478 AVG Validation Loss:0.495 AVG Training Acc 80.01 % AVG Validation Acc 79.95 %\n",
      "Epoch:100/200 AVG Training Loss:0.481 AVG Validation Loss:0.494 AVG Training Acc 79.92 % AVG Validation Acc 79.95 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.478 AVG Validation Loss:0.495 AVG Training Acc 80.11 % AVG Validation Acc 79.95 %\n",
      "Epoch:120/200 AVG Training Loss:0.479 AVG Validation Loss:0.496 AVG Training Acc 79.98 % AVG Validation Acc 79.81 %\n",
      "Epoch:130/200 AVG Training Loss:0.479 AVG Validation Loss:0.494 AVG Training Acc 79.90 % AVG Validation Acc 79.81 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.479 AVG Validation Loss:0.495 AVG Training Acc 80.01 % AVG Validation Acc 79.95 %\n",
      "Epoch:150/200 AVG Training Loss:0.480 AVG Validation Loss:0.496 AVG Training Acc 79.98 % AVG Validation Acc 80.08 %\n",
      "Epoch:160/200 AVG Training Loss:0.478 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 79.81 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.478 AVG Validation Loss:0.494 AVG Training Acc 79.89 % AVG Validation Acc 80.08 %\n",
      "Epoch:180/200 AVG Training Loss:0.478 AVG Validation Loss:0.495 AVG Training Acc 80.07 % AVG Validation Acc 79.81 %\n",
      "Epoch:190/200 AVG Training Loss:0.479 AVG Validation Loss:0.495 AVG Training Acc 79.98 % AVG Validation Acc 79.95 %\n",
      "Epoch:200/200 AVG Training Loss:0.479 AVG Validation Loss:0.495 AVG Training Acc 80.10 % AVG Validation Acc 79.81 %\n",
      "Epoch   200: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Split 19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a168922210854308a838aa854ccad2f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 79.73 % AVG Validation Acc 79.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.479 AVG Validation Loss:0.481 AVG Training Acc 79.83 % AVG Validation Acc 79.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.469 AVG Validation Loss:0.484 AVG Training Acc 79.80 % AVG Validation Acc 80.35 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.455 AVG Validation Loss:0.501 AVG Training Acc 80.68 % AVG Validation Acc 79.81 %\n",
      "Epoch:50/200 AVG Training Loss:0.440 AVG Validation Loss:0.514 AVG Training Acc 81.08 % AVG Validation Acc 79.54 %\n",
      "Epoch:60/200 AVG Training Loss:0.427 AVG Validation Loss:0.535 AVG Training Acc 81.91 % AVG Validation Acc 79.14 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.410 AVG Validation Loss:0.538 AVG Training Acc 82.55 % AVG Validation Acc 79.41 %\n",
      "Epoch:80/200 AVG Training Loss:0.406 AVG Validation Loss:0.548 AVG Training Acc 82.83 % AVG Validation Acc 78.87 %\n",
      "Epoch:90/200 AVG Training Loss:0.405 AVG Validation Loss:0.552 AVG Training Acc 82.88 % AVG Validation Acc 78.87 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.402 AVG Validation Loss:0.558 AVG Training Acc 83.04 % AVG Validation Acc 78.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.401 AVG Validation Loss:0.556 AVG Training Acc 83.07 % AVG Validation Acc 78.73 %\n",
      "Epoch:120/200 AVG Training Loss:0.403 AVG Validation Loss:0.556 AVG Training Acc 83.24 % AVG Validation Acc 78.87 %\n",
      "Epoch:130/200 AVG Training Loss:0.400 AVG Validation Loss:0.557 AVG Training Acc 83.34 % AVG Validation Acc 79.00 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.401 AVG Validation Loss:0.558 AVG Training Acc 83.07 % AVG Validation Acc 79.14 %\n",
      "Epoch:150/200 AVG Training Loss:0.400 AVG Validation Loss:0.556 AVG Training Acc 83.46 % AVG Validation Acc 79.00 %\n",
      "Epoch:160/200 AVG Training Loss:0.402 AVG Validation Loss:0.558 AVG Training Acc 83.12 % AVG Validation Acc 79.00 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.402 AVG Validation Loss:0.558 AVG Training Acc 83.42 % AVG Validation Acc 79.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.401 AVG Validation Loss:0.556 AVG Training Acc 83.18 % AVG Validation Acc 78.87 %\n",
      "Epoch:190/200 AVG Training Loss:0.403 AVG Validation Loss:0.556 AVG Training Acc 83.42 % AVG Validation Acc 79.27 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.402 AVG Validation Loss:0.557 AVG Training Acc 83.21 % AVG Validation Acc 78.87 %\n",
      "Split 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec46499088274ef5a0e5a9a8e072d8a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.483 AVG Validation Loss:0.495 AVG Training Acc 79.99 % AVG Validation Acc 79.81 %\n",
      "Epoch:20/200 AVG Training Loss:0.477 AVG Validation Loss:0.485 AVG Training Acc 79.77 % AVG Validation Acc 79.81 %\n",
      "Epoch:30/200 AVG Training Loss:0.471 AVG Validation Loss:0.478 AVG Training Acc 79.83 % AVG Validation Acc 79.81 %\n",
      "Epoch:40/200 AVG Training Loss:0.451 AVG Validation Loss:0.483 AVG Training Acc 80.56 % AVG Validation Acc 80.08 %\n",
      "Epoch:50/200 AVG Training Loss:0.428 AVG Validation Loss:0.477 AVG Training Acc 81.43 % AVG Validation Acc 79.68 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.356 AVG Validation Loss:0.563 AVG Training Acc 83.79 % AVG Validation Acc 76.85 %\n",
      "Epoch:70/200 AVG Training Loss:0.319 AVG Validation Loss:0.614 AVG Training Acc 85.28 % AVG Validation Acc 76.72 %\n",
      "Epoch:80/200 AVG Training Loss:0.291 AVG Validation Loss:0.662 AVG Training Acc 86.70 % AVG Validation Acc 77.39 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.273 AVG Validation Loss:0.700 AVG Training Acc 87.40 % AVG Validation Acc 76.58 %\n",
      "Epoch:100/200 AVG Training Loss:0.274 AVG Validation Loss:0.706 AVG Training Acc 87.37 % AVG Validation Acc 76.72 %\n",
      "Epoch:110/200 AVG Training Loss:0.268 AVG Validation Loss:0.729 AVG Training Acc 87.78 % AVG Validation Acc 75.64 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.261 AVG Validation Loss:0.703 AVG Training Acc 88.02 % AVG Validation Acc 76.58 %\n",
      "Epoch:130/200 AVG Training Loss:0.264 AVG Validation Loss:0.733 AVG Training Acc 88.14 % AVG Validation Acc 75.91 %\n",
      "Epoch:140/200 AVG Training Loss:0.261 AVG Validation Loss:0.715 AVG Training Acc 87.91 % AVG Validation Acc 76.58 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.262 AVG Validation Loss:0.730 AVG Training Acc 88.29 % AVG Validation Acc 76.18 %\n",
      "Epoch:160/200 AVG Training Loss:0.268 AVG Validation Loss:0.734 AVG Training Acc 88.14 % AVG Validation Acc 76.45 %\n",
      "Epoch:170/200 AVG Training Loss:0.264 AVG Validation Loss:0.739 AVG Training Acc 88.36 % AVG Validation Acc 75.64 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.264 AVG Validation Loss:0.726 AVG Training Acc 88.24 % AVG Validation Acc 76.04 %\n",
      "Epoch:190/200 AVG Training Loss:0.267 AVG Validation Loss:0.725 AVG Training Acc 87.90 % AVG Validation Acc 76.18 %\n",
      "Epoch:200/200 AVG Training Loss:0.266 AVG Validation Loss:0.720 AVG Training Acc 88.09 % AVG Validation Acc 76.18 %\n",
      "Split 21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12d4462fb7864affb1b0e3de58c6e6e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 79.83 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.470 AVG Validation Loss:0.492 AVG Training Acc 80.07 % AVG Validation Acc 79.84 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.459 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 78.63 %\n",
      "Epoch:40/200 AVG Training Loss:0.447 AVG Validation Loss:0.500 AVG Training Acc 80.71 % AVG Validation Acc 78.63 %\n",
      "Epoch:50/200 AVG Training Loss:0.432 AVG Validation Loss:0.519 AVG Training Acc 81.16 % AVG Validation Acc 78.23 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.415 AVG Validation Loss:0.537 AVG Training Acc 81.63 % AVG Validation Acc 77.55 %\n",
      "Epoch:70/200 AVG Training Loss:0.412 AVG Validation Loss:0.545 AVG Training Acc 81.99 % AVG Validation Acc 76.61 %\n",
      "Epoch:80/200 AVG Training Loss:0.410 AVG Validation Loss:0.549 AVG Training Acc 81.90 % AVG Validation Acc 76.61 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.406 AVG Validation Loss:0.550 AVG Training Acc 82.26 % AVG Validation Acc 76.34 %\n",
      "Epoch:100/200 AVG Training Loss:0.410 AVG Validation Loss:0.553 AVG Training Acc 82.19 % AVG Validation Acc 76.08 %\n",
      "Epoch:110/200 AVG Training Loss:0.409 AVG Validation Loss:0.553 AVG Training Acc 81.78 % AVG Validation Acc 76.48 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.406 AVG Validation Loss:0.552 AVG Training Acc 82.16 % AVG Validation Acc 76.34 %\n",
      "Epoch:130/200 AVG Training Loss:0.407 AVG Validation Loss:0.553 AVG Training Acc 82.29 % AVG Validation Acc 76.21 %\n",
      "Epoch:140/200 AVG Training Loss:0.407 AVG Validation Loss:0.555 AVG Training Acc 82.14 % AVG Validation Acc 76.08 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.405 AVG Validation Loss:0.556 AVG Training Acc 82.37 % AVG Validation Acc 76.21 %\n",
      "Epoch:160/200 AVG Training Loss:0.408 AVG Validation Loss:0.554 AVG Training Acc 82.17 % AVG Validation Acc 76.61 %\n",
      "Epoch:170/200 AVG Training Loss:0.407 AVG Validation Loss:0.551 AVG Training Acc 82.14 % AVG Validation Acc 76.34 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.408 AVG Validation Loss:0.552 AVG Training Acc 82.53 % AVG Validation Acc 76.21 %\n",
      "Epoch:190/200 AVG Training Loss:0.408 AVG Validation Loss:0.556 AVG Training Acc 82.23 % AVG Validation Acc 75.94 %\n",
      "Epoch:200/200 AVG Training Loss:0.406 AVG Validation Loss:0.551 AVG Training Acc 82.25 % AVG Validation Acc 76.34 %\n",
      "Split 22\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffe03dae86ab420391dde009ff0c0088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.478 AVG Training Acc 79.84 % AVG Validation Acc 80.11 %\n",
      "Epoch:20/200 AVG Training Loss:0.478 AVG Validation Loss:0.478 AVG Training Acc 79.92 % AVG Validation Acc 79.84 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.466 AVG Validation Loss:0.467 AVG Training Acc 80.17 % AVG Validation Acc 79.97 %\n",
      "Epoch:40/200 AVG Training Loss:0.461 AVG Validation Loss:0.466 AVG Training Acc 80.59 % AVG Validation Acc 80.24 %\n",
      "Epoch:50/200 AVG Training Loss:0.453 AVG Validation Loss:0.475 AVG Training Acc 80.96 % AVG Validation Acc 79.30 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.446 AVG Validation Loss:0.481 AVG Training Acc 81.23 % AVG Validation Acc 79.97 %\n",
      "Epoch:70/200 AVG Training Loss:0.442 AVG Validation Loss:0.475 AVG Training Acc 81.46 % AVG Validation Acc 79.84 %\n",
      "Epoch:80/200 AVG Training Loss:0.444 AVG Validation Loss:0.476 AVG Training Acc 81.40 % AVG Validation Acc 79.84 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.439 AVG Validation Loss:0.479 AVG Training Acc 81.56 % AVG Validation Acc 79.70 %\n",
      "Epoch:100/200 AVG Training Loss:0.441 AVG Validation Loss:0.480 AVG Training Acc 81.53 % AVG Validation Acc 79.44 %\n",
      "Epoch:110/200 AVG Training Loss:0.441 AVG Validation Loss:0.480 AVG Training Acc 81.44 % AVG Validation Acc 79.30 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.441 AVG Validation Loss:0.480 AVG Training Acc 81.56 % AVG Validation Acc 79.44 %\n",
      "Epoch:130/200 AVG Training Loss:0.441 AVG Validation Loss:0.481 AVG Training Acc 81.58 % AVG Validation Acc 79.44 %\n",
      "Epoch:140/200 AVG Training Loss:0.440 AVG Validation Loss:0.479 AVG Training Acc 81.32 % AVG Validation Acc 79.30 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.442 AVG Validation Loss:0.479 AVG Training Acc 81.47 % AVG Validation Acc 79.44 %\n",
      "Epoch:160/200 AVG Training Loss:0.441 AVG Validation Loss:0.480 AVG Training Acc 81.68 % AVG Validation Acc 79.30 %\n",
      "Epoch:170/200 AVG Training Loss:0.440 AVG Validation Loss:0.479 AVG Training Acc 81.52 % AVG Validation Acc 79.30 %\n",
      "Epoch:180/200 AVG Training Loss:0.441 AVG Validation Loss:0.480 AVG Training Acc 81.72 % AVG Validation Acc 79.44 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.438 AVG Validation Loss:0.480 AVG Training Acc 81.83 % AVG Validation Acc 79.44 %\n",
      "Epoch:200/200 AVG Training Loss:0.440 AVG Validation Loss:0.480 AVG Training Acc 81.43 % AVG Validation Acc 79.44 %\n",
      "Split 23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2e82e0ebcb1477d8eb9a5c423f62690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.488 AVG Validation Loss:0.484 AVG Training Acc 79.81 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.480 AVG Validation Loss:0.466 AVG Training Acc 79.90 % AVG Validation Acc 79.84 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.456 AVG Validation Loss:0.464 AVG Training Acc 80.33 % AVG Validation Acc 79.57 %\n",
      "Epoch:40/200 AVG Training Loss:0.445 AVG Validation Loss:0.473 AVG Training Acc 80.63 % AVG Validation Acc 79.97 %\n",
      "Epoch:50/200 AVG Training Loss:0.436 AVG Validation Loss:0.488 AVG Training Acc 81.13 % AVG Validation Acc 80.11 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.423 AVG Validation Loss:0.496 AVG Training Acc 81.14 % AVG Validation Acc 79.57 %\n",
      "Epoch:70/200 AVG Training Loss:0.420 AVG Validation Loss:0.500 AVG Training Acc 81.43 % AVG Validation Acc 79.30 %\n",
      "Epoch:80/200 AVG Training Loss:0.417 AVG Validation Loss:0.504 AVG Training Acc 81.63 % AVG Validation Acc 79.84 %\n",
      "Epoch:90/200 AVG Training Loss:0.418 AVG Validation Loss:0.505 AVG Training Acc 81.60 % AVG Validation Acc 79.30 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.417 AVG Validation Loss:0.505 AVG Training Acc 81.93 % AVG Validation Acc 79.44 %\n",
      "Epoch:110/200 AVG Training Loss:0.414 AVG Validation Loss:0.502 AVG Training Acc 81.93 % AVG Validation Acc 79.44 %\n",
      "Epoch:120/200 AVG Training Loss:0.416 AVG Validation Loss:0.506 AVG Training Acc 81.83 % AVG Validation Acc 79.30 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.415 AVG Validation Loss:0.506 AVG Training Acc 81.87 % AVG Validation Acc 79.44 %\n",
      "Epoch:140/200 AVG Training Loss:0.414 AVG Validation Loss:0.504 AVG Training Acc 81.53 % AVG Validation Acc 79.30 %\n",
      "Epoch:150/200 AVG Training Loss:0.411 AVG Validation Loss:0.506 AVG Training Acc 81.49 % AVG Validation Acc 79.30 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.417 AVG Validation Loss:0.507 AVG Training Acc 81.23 % AVG Validation Acc 79.30 %\n",
      "Epoch:170/200 AVG Training Loss:0.412 AVG Validation Loss:0.507 AVG Training Acc 81.87 % AVG Validation Acc 79.17 %\n",
      "Epoch:180/200 AVG Training Loss:0.416 AVG Validation Loss:0.507 AVG Training Acc 81.93 % AVG Validation Acc 79.44 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.413 AVG Validation Loss:0.506 AVG Training Acc 81.55 % AVG Validation Acc 79.03 %\n",
      "Epoch:200/200 AVG Training Loss:0.417 AVG Validation Loss:0.508 AVG Training Acc 81.63 % AVG Validation Acc 79.03 %\n",
      "Split 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b0ffc6c60584bc3ab07764551f2be70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best Accuracy found: 81.45%\n",
      "Epoch: 3\n",
      "Epoch:10/200 AVG Training Loss:0.486 AVG Validation Loss:0.489 AVG Training Acc 79.74 % AVG Validation Acc 80.11 %\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.475 AVG Validation Loss:0.481 AVG Training Acc 79.60 % AVG Validation Acc 79.84 %\n",
      "Epoch:30/200 AVG Training Loss:0.467 AVG Validation Loss:0.481 AVG Training Acc 80.16 % AVG Validation Acc 79.44 %\n",
      "Epoch:40/200 AVG Training Loss:0.465 AVG Validation Loss:0.484 AVG Training Acc 80.36 % AVG Validation Acc 80.11 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.457 AVG Validation Loss:0.485 AVG Training Acc 80.83 % AVG Validation Acc 80.11 %\n",
      "Epoch:60/200 AVG Training Loss:0.456 AVG Validation Loss:0.486 AVG Training Acc 80.93 % AVG Validation Acc 80.38 %\n",
      "Epoch:70/200 AVG Training Loss:0.453 AVG Validation Loss:0.487 AVG Training Acc 81.16 % AVG Validation Acc 80.24 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.452 AVG Validation Loss:0.487 AVG Training Acc 81.29 % AVG Validation Acc 80.51 %\n",
      "Epoch:90/200 AVG Training Loss:0.451 AVG Validation Loss:0.486 AVG Training Acc 81.16 % AVG Validation Acc 80.51 %\n",
      "Epoch:100/200 AVG Training Loss:0.451 AVG Validation Loss:0.487 AVG Training Acc 81.17 % AVG Validation Acc 80.38 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.452 AVG Validation Loss:0.487 AVG Training Acc 81.07 % AVG Validation Acc 80.38 %\n",
      "Epoch:120/200 AVG Training Loss:0.451 AVG Validation Loss:0.486 AVG Training Acc 81.22 % AVG Validation Acc 80.51 %\n",
      "Epoch:130/200 AVG Training Loss:0.453 AVG Validation Loss:0.486 AVG Training Acc 81.34 % AVG Validation Acc 80.38 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.450 AVG Validation Loss:0.487 AVG Training Acc 81.47 % AVG Validation Acc 80.38 %\n",
      "Epoch:150/200 AVG Training Loss:0.452 AVG Validation Loss:0.488 AVG Training Acc 81.23 % AVG Validation Acc 80.38 %\n",
      "Epoch:160/200 AVG Training Loss:0.450 AVG Validation Loss:0.487 AVG Training Acc 81.10 % AVG Validation Acc 80.38 %\n",
      "Epoch:170/200 AVG Training Loss:0.453 AVG Validation Loss:0.487 AVG Training Acc 80.99 % AVG Validation Acc 80.38 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.453 AVG Validation Loss:0.487 AVG Training Acc 81.08 % AVG Validation Acc 80.51 %\n",
      "Epoch:190/200 AVG Training Loss:0.452 AVG Validation Loss:0.487 AVG Training Acc 81.10 % AVG Validation Acc 80.38 %\n",
      "Epoch:200/200 AVG Training Loss:0.450 AVG Validation Loss:0.486 AVG Training Acc 81.19 % AVG Validation Acc 80.51 %\n",
      "Split 25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b65949e80a743018429a2813ef6774e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.479 AVG Validation Loss:0.498 AVG Training Acc 79.71 % AVG Validation Acc 79.84 %\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.470 AVG Validation Loss:0.498 AVG Training Acc 80.05 % AVG Validation Acc 78.36 %\n",
      "Epoch:30/200 AVG Training Loss:0.466 AVG Validation Loss:0.500 AVG Training Acc 80.45 % AVG Validation Acc 78.36 %\n",
      "Epoch:40/200 AVG Training Loss:0.464 AVG Validation Loss:0.498 AVG Training Acc 80.57 % AVG Validation Acc 78.49 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.460 AVG Validation Loss:0.500 AVG Training Acc 80.36 % AVG Validation Acc 78.09 %\n",
      "Epoch:60/200 AVG Training Loss:0.460 AVG Validation Loss:0.502 AVG Training Acc 80.32 % AVG Validation Acc 77.69 %\n",
      "Epoch:70/200 AVG Training Loss:0.458 AVG Validation Loss:0.502 AVG Training Acc 80.59 % AVG Validation Acc 77.82 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.459 AVG Validation Loss:0.503 AVG Training Acc 80.48 % AVG Validation Acc 77.82 %\n",
      "Epoch:90/200 AVG Training Loss:0.458 AVG Validation Loss:0.503 AVG Training Acc 80.38 % AVG Validation Acc 77.82 %\n",
      "Epoch:100/200 AVG Training Loss:0.459 AVG Validation Loss:0.503 AVG Training Acc 80.69 % AVG Validation Acc 77.69 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.458 AVG Validation Loss:0.503 AVG Training Acc 80.51 % AVG Validation Acc 77.55 %\n",
      "Epoch:120/200 AVG Training Loss:0.458 AVG Validation Loss:0.503 AVG Training Acc 80.80 % AVG Validation Acc 77.82 %\n",
      "Epoch:130/200 AVG Training Loss:0.459 AVG Validation Loss:0.503 AVG Training Acc 80.38 % AVG Validation Acc 77.69 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.458 AVG Validation Loss:0.503 AVG Training Acc 80.57 % AVG Validation Acc 77.69 %\n",
      "Epoch:150/200 AVG Training Loss:0.458 AVG Validation Loss:0.503 AVG Training Acc 80.71 % AVG Validation Acc 77.69 %\n",
      "Epoch:160/200 AVG Training Loss:0.459 AVG Validation Loss:0.503 AVG Training Acc 80.33 % AVG Validation Acc 77.82 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.458 AVG Validation Loss:0.503 AVG Training Acc 80.62 % AVG Validation Acc 77.69 %\n",
      "Epoch:180/200 AVG Training Loss:0.459 AVG Validation Loss:0.504 AVG Training Acc 80.57 % AVG Validation Acc 77.55 %\n",
      "Epoch:190/200 AVG Training Loss:0.459 AVG Validation Loss:0.503 AVG Training Acc 80.47 % AVG Validation Acc 77.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.460 AVG Validation Loss:0.502 AVG Training Acc 80.44 % AVG Validation Acc 77.69 %\n",
      "Split 26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "650d81ab2f824c2a866e85c8a7d29943",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.501 AVG Training Acc 79.80 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.477 AVG Validation Loss:0.492 AVG Training Acc 80.07 % AVG Validation Acc 79.44 %\n",
      "Epoch:30/200 AVG Training Loss:0.466 AVG Validation Loss:0.488 AVG Training Acc 79.90 % AVG Validation Acc 79.97 %\n",
      "Epoch:40/200 AVG Training Loss:0.456 AVG Validation Loss:0.486 AVG Training Acc 80.36 % AVG Validation Acc 79.97 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.425 AVG Validation Loss:0.523 AVG Training Acc 81.78 % AVG Validation Acc 78.36 %\n",
      "Epoch:60/200 AVG Training Loss:0.401 AVG Validation Loss:0.566 AVG Training Acc 82.35 % AVG Validation Acc 77.02 %\n",
      "Epoch:70/200 AVG Training Loss:0.383 AVG Validation Loss:0.595 AVG Training Acc 83.23 % AVG Validation Acc 77.28 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.368 AVG Validation Loss:0.618 AVG Training Acc 83.94 % AVG Validation Acc 76.48 %\n",
      "Epoch:90/200 AVG Training Loss:0.365 AVG Validation Loss:0.617 AVG Training Acc 83.85 % AVG Validation Acc 77.02 %\n",
      "Epoch:100/200 AVG Training Loss:0.365 AVG Validation Loss:0.627 AVG Training Acc 83.79 % AVG Validation Acc 76.75 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.361 AVG Validation Loss:0.630 AVG Training Acc 83.98 % AVG Validation Acc 77.02 %\n",
      "Epoch:120/200 AVG Training Loss:0.365 AVG Validation Loss:0.639 AVG Training Acc 83.86 % AVG Validation Acc 76.75 %\n",
      "Epoch:130/200 AVG Training Loss:0.361 AVG Validation Loss:0.630 AVG Training Acc 84.19 % AVG Validation Acc 77.15 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.362 AVG Validation Loss:0.631 AVG Training Acc 83.94 % AVG Validation Acc 77.15 %\n",
      "Epoch:150/200 AVG Training Loss:0.363 AVG Validation Loss:0.630 AVG Training Acc 84.07 % AVG Validation Acc 76.75 %\n",
      "Epoch:160/200 AVG Training Loss:0.362 AVG Validation Loss:0.632 AVG Training Acc 83.86 % AVG Validation Acc 77.15 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.359 AVG Validation Loss:0.636 AVG Training Acc 84.23 % AVG Validation Acc 77.02 %\n",
      "Epoch:180/200 AVG Training Loss:0.362 AVG Validation Loss:0.638 AVG Training Acc 84.28 % AVG Validation Acc 77.15 %\n",
      "Epoch:190/200 AVG Training Loss:0.364 AVG Validation Loss:0.635 AVG Training Acc 84.13 % AVG Validation Acc 77.15 %\n",
      "Epoch   198: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.359 AVG Validation Loss:0.633 AVG Training Acc 83.94 % AVG Validation Acc 77.02 %\n",
      "Split 27\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e50c0d4126a4aeab8a01e6ad32ff577",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.487 AVG Validation Loss:0.488 AVG Training Acc 79.84 % AVG Validation Acc 79.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.477 AVG Validation Loss:0.479 AVG Training Acc 79.99 % AVG Validation Acc 79.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.469 AVG Validation Loss:0.477 AVG Training Acc 80.02 % AVG Validation Acc 79.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.462 AVG Validation Loss:0.491 AVG Training Acc 79.90 % AVG Validation Acc 80.08 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.426 AVG Validation Loss:0.498 AVG Training Acc 81.13 % AVG Validation Acc 78.06 %\n",
      "Epoch:60/200 AVG Training Loss:0.390 AVG Validation Loss:0.514 AVG Training Acc 82.85 % AVG Validation Acc 77.52 %\n",
      "Epoch:70/200 AVG Training Loss:0.362 AVG Validation Loss:0.549 AVG Training Acc 83.76 % AVG Validation Acc 76.99 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.335 AVG Validation Loss:0.587 AVG Training Acc 85.24 % AVG Validation Acc 75.91 %\n",
      "Epoch:90/200 AVG Training Loss:0.324 AVG Validation Loss:0.592 AVG Training Acc 85.88 % AVG Validation Acc 75.91 %\n",
      "Epoch:100/200 AVG Training Loss:0.325 AVG Validation Loss:0.599 AVG Training Acc 86.05 % AVG Validation Acc 75.91 %\n",
      "Epoch:110/200 AVG Training Loss:0.320 AVG Validation Loss:0.592 AVG Training Acc 86.05 % AVG Validation Acc 76.31 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.320 AVG Validation Loss:0.595 AVG Training Acc 86.25 % AVG Validation Acc 76.04 %\n",
      "Epoch:130/200 AVG Training Loss:0.319 AVG Validation Loss:0.594 AVG Training Acc 86.25 % AVG Validation Acc 75.77 %\n",
      "Epoch:140/200 AVG Training Loss:0.315 AVG Validation Loss:0.595 AVG Training Acc 86.61 % AVG Validation Acc 76.18 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.320 AVG Validation Loss:0.596 AVG Training Acc 86.18 % AVG Validation Acc 75.64 %\n",
      "Epoch:160/200 AVG Training Loss:0.313 AVG Validation Loss:0.602 AVG Training Acc 86.57 % AVG Validation Acc 76.18 %\n",
      "Epoch:170/200 AVG Training Loss:0.319 AVG Validation Loss:0.596 AVG Training Acc 86.09 % AVG Validation Acc 76.18 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.317 AVG Validation Loss:0.599 AVG Training Acc 86.51 % AVG Validation Acc 74.97 %\n",
      "Epoch:190/200 AVG Training Loss:0.316 AVG Validation Loss:0.591 AVG Training Acc 86.36 % AVG Validation Acc 76.18 %\n",
      "Epoch:200/200 AVG Training Loss:0.321 AVG Validation Loss:0.594 AVG Training Acc 85.82 % AVG Validation Acc 75.64 %\n",
      "Split 28\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1397bcee6d3b475ca3c42c1bbbc23571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.484 AVG Validation Loss:0.484 AVG Training Acc 79.59 % AVG Validation Acc 79.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.476 AVG Validation Loss:0.483 AVG Training Acc 79.64 % AVG Validation Acc 79.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.465 AVG Validation Loss:0.488 AVG Training Acc 79.99 % AVG Validation Acc 79.81 %\n",
      "Epoch:40/200 AVG Training Loss:0.446 AVG Validation Loss:0.500 AVG Training Acc 80.73 % AVG Validation Acc 79.41 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.410 AVG Validation Loss:0.526 AVG Training Acc 82.74 % AVG Validation Acc 79.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.380 AVG Validation Loss:0.566 AVG Training Acc 84.06 % AVG Validation Acc 78.33 %\n",
      "Epoch:70/200 AVG Training Loss:0.358 AVG Validation Loss:0.603 AVG Training Acc 84.78 % AVG Validation Acc 77.39 %\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.349 AVG Validation Loss:0.619 AVG Training Acc 85.06 % AVG Validation Acc 77.79 %\n",
      "Epoch:90/200 AVG Training Loss:0.340 AVG Validation Loss:0.638 AVG Training Acc 85.46 % AVG Validation Acc 77.39 %\n",
      "Epoch:100/200 AVG Training Loss:0.338 AVG Validation Loss:0.639 AVG Training Acc 85.72 % AVG Validation Acc 77.52 %\n",
      "Epoch   104: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.334 AVG Validation Loss:0.647 AVG Training Acc 85.69 % AVG Validation Acc 76.99 %\n",
      "Epoch:120/200 AVG Training Loss:0.336 AVG Validation Loss:0.645 AVG Training Acc 85.88 % AVG Validation Acc 77.25 %\n",
      "Epoch:130/200 AVG Training Loss:0.335 AVG Validation Loss:0.635 AVG Training Acc 86.10 % AVG Validation Acc 77.39 %\n",
      "Epoch   135: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.335 AVG Validation Loss:0.648 AVG Training Acc 86.08 % AVG Validation Acc 76.72 %\n",
      "Epoch:150/200 AVG Training Loss:0.337 AVG Validation Loss:0.644 AVG Training Acc 85.81 % AVG Validation Acc 77.25 %\n",
      "Epoch:160/200 AVG Training Loss:0.334 AVG Validation Loss:0.641 AVG Training Acc 86.10 % AVG Validation Acc 76.85 %\n",
      "Epoch   166: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.337 AVG Validation Loss:0.640 AVG Training Acc 85.61 % AVG Validation Acc 77.25 %\n",
      "Epoch:180/200 AVG Training Loss:0.334 AVG Validation Loss:0.641 AVG Training Acc 86.08 % AVG Validation Acc 77.12 %\n",
      "Epoch:190/200 AVG Training Loss:0.335 AVG Validation Loss:0.644 AVG Training Acc 85.94 % AVG Validation Acc 77.25 %\n",
      "Epoch   197: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.337 AVG Validation Loss:0.640 AVG Training Acc 85.55 % AVG Validation Acc 77.12 %\n",
      "Split 29\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "149775fd7ceb4f89bdd573ee6c634383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.492 AVG Validation Loss:0.477 AVG Training Acc 79.99 % AVG Validation Acc 80.62 %\n",
      "Epoch:20/200 AVG Training Loss:0.476 AVG Validation Loss:0.478 AVG Training Acc 80.13 % AVG Validation Acc 79.95 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.467 AVG Validation Loss:0.470 AVG Training Acc 79.77 % AVG Validation Acc 80.62 %\n",
      "Epoch:40/200 AVG Training Loss:0.462 AVG Validation Loss:0.474 AVG Training Acc 79.98 % AVG Validation Acc 80.62 %\n",
      "Epoch:50/200 AVG Training Loss:0.454 AVG Validation Loss:0.479 AVG Training Acc 80.25 % AVG Validation Acc 80.62 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.446 AVG Validation Loss:0.484 AVG Training Acc 80.74 % AVG Validation Acc 80.48 %\n",
      "Epoch:70/200 AVG Training Loss:0.444 AVG Validation Loss:0.489 AVG Training Acc 80.62 % AVG Validation Acc 80.62 %\n",
      "Epoch:80/200 AVG Training Loss:0.441 AVG Validation Loss:0.493 AVG Training Acc 80.73 % AVG Validation Acc 80.75 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.439 AVG Validation Loss:0.493 AVG Training Acc 81.05 % AVG Validation Acc 80.48 %\n",
      "Epoch:100/200 AVG Training Loss:0.438 AVG Validation Loss:0.495 AVG Training Acc 81.07 % AVG Validation Acc 80.75 %\n",
      "Epoch:110/200 AVG Training Loss:0.440 AVG Validation Loss:0.501 AVG Training Acc 80.94 % AVG Validation Acc 80.89 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.439 AVG Validation Loss:0.497 AVG Training Acc 80.91 % AVG Validation Acc 80.89 %\n",
      "Epoch:130/200 AVG Training Loss:0.439 AVG Validation Loss:0.501 AVG Training Acc 80.88 % AVG Validation Acc 80.48 %\n",
      "Epoch:140/200 AVG Training Loss:0.438 AVG Validation Loss:0.504 AVG Training Acc 80.88 % AVG Validation Acc 80.48 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.439 AVG Validation Loss:0.504 AVG Training Acc 80.64 % AVG Validation Acc 80.62 %\n",
      "Epoch:160/200 AVG Training Loss:0.438 AVG Validation Loss:0.503 AVG Training Acc 80.97 % AVG Validation Acc 80.62 %\n",
      "Epoch:170/200 AVG Training Loss:0.440 AVG Validation Loss:0.497 AVG Training Acc 80.77 % AVG Validation Acc 80.35 %\n",
      "Epoch:180/200 AVG Training Loss:0.439 AVG Validation Loss:0.501 AVG Training Acc 80.98 % AVG Validation Acc 80.75 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.440 AVG Validation Loss:0.495 AVG Training Acc 80.76 % AVG Validation Acc 80.75 %\n",
      "Epoch:200/200 AVG Training Loss:0.438 AVG Validation Loss:0.502 AVG Training Acc 80.98 % AVG Validation Acc 80.48 %\n",
      "Split 30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e277214bb8d94ee485b28930c8d02fd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.488 AVG Validation Loss:0.468 AVG Training Acc 79.74 % AVG Validation Acc 80.75 %\n",
      "Epoch:20/200 AVG Training Loss:0.475 AVG Validation Loss:0.468 AVG Training Acc 79.71 % AVG Validation Acc 79.81 %\n",
      "Epoch:30/200 AVG Training Loss:0.470 AVG Validation Loss:0.465 AVG Training Acc 79.90 % AVG Validation Acc 79.81 %\n",
      "Epoch:40/200 AVG Training Loss:0.452 AVG Validation Loss:0.467 AVG Training Acc 80.29 % AVG Validation Acc 79.41 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.432 AVG Validation Loss:0.476 AVG Training Acc 81.00 % AVG Validation Acc 79.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.377 AVG Validation Loss:0.519 AVG Training Acc 83.54 % AVG Validation Acc 79.68 %\n",
      "Epoch:70/200 AVG Training Loss:0.346 AVG Validation Loss:0.555 AVG Training Acc 84.79 % AVG Validation Acc 79.81 %\n",
      "Epoch:80/200 AVG Training Loss:0.323 AVG Validation Loss:0.579 AVG Training Acc 86.15 % AVG Validation Acc 78.47 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.318 AVG Validation Loss:0.586 AVG Training Acc 86.21 % AVG Validation Acc 78.73 %\n",
      "Epoch:100/200 AVG Training Loss:0.312 AVG Validation Loss:0.592 AVG Training Acc 86.45 % AVG Validation Acc 78.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.310 AVG Validation Loss:0.593 AVG Training Acc 86.21 % AVG Validation Acc 79.14 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.311 AVG Validation Loss:0.591 AVG Training Acc 86.54 % AVG Validation Acc 79.00 %\n",
      "Epoch:130/200 AVG Training Loss:0.305 AVG Validation Loss:0.598 AVG Training Acc 86.75 % AVG Validation Acc 78.47 %\n",
      "Epoch:140/200 AVG Training Loss:0.308 AVG Validation Loss:0.599 AVG Training Acc 86.52 % AVG Validation Acc 78.33 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.307 AVG Validation Loss:0.605 AVG Training Acc 86.51 % AVG Validation Acc 78.20 %\n",
      "Epoch:160/200 AVG Training Loss:0.307 AVG Validation Loss:0.590 AVG Training Acc 86.67 % AVG Validation Acc 78.47 %\n",
      "Epoch:170/200 AVG Training Loss:0.306 AVG Validation Loss:0.597 AVG Training Acc 86.90 % AVG Validation Acc 78.73 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.307 AVG Validation Loss:0.589 AVG Training Acc 86.79 % AVG Validation Acc 78.20 %\n",
      "Epoch:190/200 AVG Training Loss:0.311 AVG Validation Loss:0.598 AVG Training Acc 86.30 % AVG Validation Acc 78.60 %\n",
      "Epoch:200/200 AVG Training Loss:0.303 AVG Validation Loss:0.599 AVG Training Acc 86.85 % AVG Validation Acc 78.60 %\n",
      "Split 31\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5a6646e36f14ceda39a6768f3aaefac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.492 AVG Training Acc 79.86 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.476 AVG Validation Loss:0.486 AVG Training Acc 80.01 % AVG Validation Acc 79.84 %\n",
      "Epoch:30/200 AVG Training Loss:0.468 AVG Validation Loss:0.473 AVG Training Acc 80.13 % AVG Validation Acc 79.84 %\n",
      "Epoch:40/200 AVG Training Loss:0.453 AVG Validation Loss:0.489 AVG Training Acc 80.35 % AVG Validation Acc 79.84 %\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.425 AVG Validation Loss:0.497 AVG Training Acc 81.26 % AVG Validation Acc 77.96 %\n",
      "Epoch:60/200 AVG Training Loss:0.408 AVG Validation Loss:0.517 AVG Training Acc 82.20 % AVG Validation Acc 77.96 %\n",
      "Epoch:70/200 AVG Training Loss:0.388 AVG Validation Loss:0.541 AVG Training Acc 83.08 % AVG Validation Acc 78.09 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.377 AVG Validation Loss:0.553 AVG Training Acc 83.77 % AVG Validation Acc 77.69 %\n",
      "Epoch:90/200 AVG Training Loss:0.378 AVG Validation Loss:0.558 AVG Training Acc 83.56 % AVG Validation Acc 77.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.374 AVG Validation Loss:0.555 AVG Training Acc 83.79 % AVG Validation Acc 77.55 %\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.372 AVG Validation Loss:0.555 AVG Training Acc 84.15 % AVG Validation Acc 78.36 %\n",
      "Epoch:120/200 AVG Training Loss:0.374 AVG Validation Loss:0.556 AVG Training Acc 83.79 % AVG Validation Acc 78.09 %\n",
      "Epoch:130/200 AVG Training Loss:0.370 AVG Validation Loss:0.550 AVG Training Acc 84.07 % AVG Validation Acc 78.36 %\n",
      "Epoch   134: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.369 AVG Validation Loss:0.554 AVG Training Acc 84.28 % AVG Validation Acc 77.69 %\n",
      "Epoch:150/200 AVG Training Loss:0.371 AVG Validation Loss:0.561 AVG Training Acc 84.09 % AVG Validation Acc 77.96 %\n",
      "Epoch:160/200 AVG Training Loss:0.371 AVG Validation Loss:0.558 AVG Training Acc 83.89 % AVG Validation Acc 77.82 %\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.373 AVG Validation Loss:0.558 AVG Training Acc 83.89 % AVG Validation Acc 77.82 %\n",
      "Epoch:180/200 AVG Training Loss:0.373 AVG Validation Loss:0.560 AVG Training Acc 84.28 % AVG Validation Acc 77.69 %\n",
      "Epoch:190/200 AVG Training Loss:0.372 AVG Validation Loss:0.555 AVG Training Acc 83.74 % AVG Validation Acc 78.23 %\n",
      "Epoch   196: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.374 AVG Validation Loss:0.562 AVG Training Acc 83.97 % AVG Validation Acc 77.55 %\n",
      "Split 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "128b1c8c2f604b8c91455b0befb0d0a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.488 AVG Validation Loss:0.483 AVG Training Acc 79.86 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.479 AVG Validation Loss:0.476 AVG Training Acc 79.78 % AVG Validation Acc 79.84 %\n",
      "Epoch:30/200 AVG Training Loss:0.470 AVG Validation Loss:0.473 AVG Training Acc 79.92 % AVG Validation Acc 79.84 %\n",
      "Epoch:40/200 AVG Training Loss:0.470 AVG Validation Loss:0.467 AVG Training Acc 80.20 % AVG Validation Acc 80.51 %\n",
      "Epoch:50/200 AVG Training Loss:0.453 AVG Validation Loss:0.504 AVG Training Acc 80.39 % AVG Validation Acc 79.84 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.415 AVG Validation Loss:0.490 AVG Training Acc 82.16 % AVG Validation Acc 78.49 %\n",
      "Epoch:70/200 AVG Training Loss:0.385 AVG Validation Loss:0.519 AVG Training Acc 83.35 % AVG Validation Acc 78.63 %\n",
      "Epoch:80/200 AVG Training Loss:0.364 AVG Validation Loss:0.550 AVG Training Acc 84.68 % AVG Validation Acc 77.28 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.352 AVG Validation Loss:0.546 AVG Training Acc 85.28 % AVG Validation Acc 77.82 %\n",
      "Epoch:100/200 AVG Training Loss:0.350 AVG Validation Loss:0.551 AVG Training Acc 85.06 % AVG Validation Acc 77.15 %\n",
      "Epoch:110/200 AVG Training Loss:0.347 AVG Validation Loss:0.558 AVG Training Acc 85.58 % AVG Validation Acc 77.82 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.345 AVG Validation Loss:0.557 AVG Training Acc 85.49 % AVG Validation Acc 77.42 %\n",
      "Epoch:130/200 AVG Training Loss:0.348 AVG Validation Loss:0.554 AVG Training Acc 85.28 % AVG Validation Acc 77.42 %\n",
      "Epoch:140/200 AVG Training Loss:0.345 AVG Validation Loss:0.562 AVG Training Acc 85.43 % AVG Validation Acc 77.28 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.347 AVG Validation Loss:0.561 AVG Training Acc 85.46 % AVG Validation Acc 76.88 %\n",
      "Epoch:160/200 AVG Training Loss:0.344 AVG Validation Loss:0.560 AVG Training Acc 85.59 % AVG Validation Acc 77.28 %\n",
      "Epoch:170/200 AVG Training Loss:0.345 AVG Validation Loss:0.559 AVG Training Acc 85.77 % AVG Validation Acc 77.42 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.347 AVG Validation Loss:0.557 AVG Training Acc 85.79 % AVG Validation Acc 77.82 %\n",
      "Epoch:190/200 AVG Training Loss:0.342 AVG Validation Loss:0.560 AVG Training Acc 85.76 % AVG Validation Acc 77.15 %\n",
      "Epoch:200/200 AVG Training Loss:0.345 AVG Validation Loss:0.562 AVG Training Acc 85.52 % AVG Validation Acc 77.28 %\n",
      "Split 33\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f49364e3d4f646ee8955a923e8d4e782",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.499 AVG Training Acc 79.80 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.481 AVG Validation Loss:0.481 AVG Training Acc 79.90 % AVG Validation Acc 79.84 %\n",
      "Epoch:30/200 AVG Training Loss:0.472 AVG Validation Loss:0.470 AVG Training Acc 80.08 % AVG Validation Acc 79.97 %\n",
      "Epoch:40/200 AVG Training Loss:0.483 AVG Validation Loss:0.476 AVG Training Acc 79.66 % AVG Validation Acc 79.84 %\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.449 AVG Validation Loss:0.478 AVG Training Acc 80.48 % AVG Validation Acc 79.30 %\n",
      "Epoch:60/200 AVG Training Loss:0.434 AVG Validation Loss:0.497 AVG Training Acc 81.08 % AVG Validation Acc 78.90 %\n",
      "Epoch:70/200 AVG Training Loss:0.425 AVG Validation Loss:0.497 AVG Training Acc 81.43 % AVG Validation Acc 79.17 %\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.410 AVG Validation Loss:0.515 AVG Training Acc 82.19 % AVG Validation Acc 78.76 %\n",
      "Epoch:90/200 AVG Training Loss:0.406 AVG Validation Loss:0.520 AVG Training Acc 82.67 % AVG Validation Acc 78.36 %\n",
      "Epoch:100/200 AVG Training Loss:0.405 AVG Validation Loss:0.523 AVG Training Acc 82.56 % AVG Validation Acc 78.90 %\n",
      "Epoch   106: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.402 AVG Validation Loss:0.521 AVG Training Acc 82.55 % AVG Validation Acc 79.17 %\n",
      "Epoch:120/200 AVG Training Loss:0.402 AVG Validation Loss:0.528 AVG Training Acc 82.46 % AVG Validation Acc 78.90 %\n",
      "Epoch:130/200 AVG Training Loss:0.403 AVG Validation Loss:0.525 AVG Training Acc 82.52 % AVG Validation Acc 78.90 %\n",
      "Epoch   137: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.402 AVG Validation Loss:0.519 AVG Training Acc 82.55 % AVG Validation Acc 78.76 %\n",
      "Epoch:150/200 AVG Training Loss:0.404 AVG Validation Loss:0.524 AVG Training Acc 82.52 % AVG Validation Acc 78.23 %\n",
      "Epoch:160/200 AVG Training Loss:0.403 AVG Validation Loss:0.525 AVG Training Acc 82.50 % AVG Validation Acc 78.63 %\n",
      "Epoch   168: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.402 AVG Validation Loss:0.528 AVG Training Acc 82.50 % AVG Validation Acc 78.63 %\n",
      "Epoch:180/200 AVG Training Loss:0.402 AVG Validation Loss:0.521 AVG Training Acc 82.52 % AVG Validation Acc 79.17 %\n",
      "Epoch:190/200 AVG Training Loss:0.401 AVG Validation Loss:0.526 AVG Training Acc 82.59 % AVG Validation Acc 78.36 %\n",
      "Epoch   199: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.401 AVG Validation Loss:0.527 AVG Training Acc 82.65 % AVG Validation Acc 78.23 %\n",
      "Split 34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c385495557d494d9f87301e66045216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 79.87 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.476 AVG Validation Loss:0.487 AVG Training Acc 79.87 % AVG Validation Acc 79.84 %\n",
      "Epoch:30/200 AVG Training Loss:0.464 AVG Validation Loss:0.492 AVG Training Acc 80.29 % AVG Validation Acc 79.84 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.450 AVG Validation Loss:0.486 AVG Training Acc 80.74 % AVG Validation Acc 80.65 %\n",
      "Epoch:50/200 AVG Training Loss:0.434 AVG Validation Loss:0.501 AVG Training Acc 81.55 % AVG Validation Acc 79.97 %\n",
      "Epoch:60/200 AVG Training Loss:0.419 AVG Validation Loss:0.510 AVG Training Acc 81.83 % AVG Validation Acc 79.57 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.407 AVG Validation Loss:0.512 AVG Training Acc 82.52 % AVG Validation Acc 79.30 %\n",
      "Epoch:80/200 AVG Training Loss:0.404 AVG Validation Loss:0.517 AVG Training Acc 83.05 % AVG Validation Acc 78.36 %\n",
      "Epoch:90/200 AVG Training Loss:0.402 AVG Validation Loss:0.515 AVG Training Acc 82.82 % AVG Validation Acc 78.76 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.401 AVG Validation Loss:0.521 AVG Training Acc 82.92 % AVG Validation Acc 78.49 %\n",
      "Epoch:110/200 AVG Training Loss:0.399 AVG Validation Loss:0.521 AVG Training Acc 83.25 % AVG Validation Acc 78.36 %\n",
      "Epoch:120/200 AVG Training Loss:0.400 AVG Validation Loss:0.515 AVG Training Acc 82.90 % AVG Validation Acc 78.63 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.397 AVG Validation Loss:0.519 AVG Training Acc 83.40 % AVG Validation Acc 78.36 %\n",
      "Epoch:140/200 AVG Training Loss:0.399 AVG Validation Loss:0.516 AVG Training Acc 83.32 % AVG Validation Acc 78.63 %\n",
      "Epoch:150/200 AVG Training Loss:0.400 AVG Validation Loss:0.525 AVG Training Acc 82.80 % AVG Validation Acc 78.36 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.401 AVG Validation Loss:0.526 AVG Training Acc 83.22 % AVG Validation Acc 78.23 %\n",
      "Epoch:170/200 AVG Training Loss:0.403 AVG Validation Loss:0.525 AVG Training Acc 83.04 % AVG Validation Acc 78.63 %\n",
      "Epoch:180/200 AVG Training Loss:0.397 AVG Validation Loss:0.521 AVG Training Acc 83.35 % AVG Validation Acc 78.76 %\n",
      "Epoch:190/200 AVG Training Loss:0.401 AVG Validation Loss:0.519 AVG Training Acc 82.96 % AVG Validation Acc 78.63 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.398 AVG Validation Loss:0.519 AVG Training Acc 83.07 % AVG Validation Acc 78.76 %\n",
      "Split 35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83926e7d38ba451baaff58d25c79a6fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.485 AVG Validation Loss:0.486 AVG Training Acc 79.81 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.476 AVG Validation Loss:0.480 AVG Training Acc 79.80 % AVG Validation Acc 79.84 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.453 AVG Validation Loss:0.482 AVG Training Acc 80.60 % AVG Validation Acc 79.17 %\n",
      "Epoch:40/200 AVG Training Loss:0.435 AVG Validation Loss:0.497 AVG Training Acc 81.14 % AVG Validation Acc 79.30 %\n",
      "Epoch:50/200 AVG Training Loss:0.420 AVG Validation Loss:0.517 AVG Training Acc 81.84 % AVG Validation Acc 78.09 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.402 AVG Validation Loss:0.544 AVG Training Acc 82.85 % AVG Validation Acc 77.55 %\n",
      "Epoch:70/200 AVG Training Loss:0.397 AVG Validation Loss:0.549 AVG Training Acc 83.44 % AVG Validation Acc 77.82 %\n",
      "Epoch:80/200 AVG Training Loss:0.392 AVG Validation Loss:0.550 AVG Training Acc 83.71 % AVG Validation Acc 77.28 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.391 AVG Validation Loss:0.558 AVG Training Acc 83.76 % AVG Validation Acc 77.42 %\n",
      "Epoch:100/200 AVG Training Loss:0.391 AVG Validation Loss:0.557 AVG Training Acc 83.47 % AVG Validation Acc 77.55 %\n",
      "Epoch:110/200 AVG Training Loss:0.390 AVG Validation Loss:0.560 AVG Training Acc 83.71 % AVG Validation Acc 77.28 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.391 AVG Validation Loss:0.557 AVG Training Acc 83.32 % AVG Validation Acc 76.61 %\n",
      "Epoch:130/200 AVG Training Loss:0.390 AVG Validation Loss:0.559 AVG Training Acc 84.01 % AVG Validation Acc 77.28 %\n",
      "Epoch:140/200 AVG Training Loss:0.392 AVG Validation Loss:0.553 AVG Training Acc 83.55 % AVG Validation Acc 77.55 %\n",
      "Epoch:150/200 AVG Training Loss:0.391 AVG Validation Loss:0.556 AVG Training Acc 83.49 % AVG Validation Acc 77.28 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.387 AVG Validation Loss:0.556 AVG Training Acc 83.52 % AVG Validation Acc 77.15 %\n",
      "Epoch:170/200 AVG Training Loss:0.388 AVG Validation Loss:0.554 AVG Training Acc 83.86 % AVG Validation Acc 77.42 %\n",
      "Epoch:180/200 AVG Training Loss:0.389 AVG Validation Loss:0.558 AVG Training Acc 83.40 % AVG Validation Acc 77.42 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.387 AVG Validation Loss:0.557 AVG Training Acc 83.70 % AVG Validation Acc 77.28 %\n",
      "Epoch:200/200 AVG Training Loss:0.391 AVG Validation Loss:0.558 AVG Training Acc 83.43 % AVG Validation Acc 77.28 %\n",
      "Split 36\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9689639b78f0401b8324829037e4154e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.485 AVG Validation Loss:0.483 AVG Training Acc 79.74 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.470 AVG Validation Loss:0.474 AVG Training Acc 79.89 % AVG Validation Acc 79.03 %\n",
      "Epoch:30/200 AVG Training Loss:0.464 AVG Validation Loss:0.479 AVG Training Acc 80.14 % AVG Validation Acc 79.17 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.418 AVG Validation Loss:0.512 AVG Training Acc 81.47 % AVG Validation Acc 78.90 %\n",
      "Epoch:50/200 AVG Training Loss:0.400 AVG Validation Loss:0.543 AVG Training Acc 82.28 % AVG Validation Acc 78.36 %\n",
      "Epoch:60/200 AVG Training Loss:0.387 AVG Validation Loss:0.576 AVG Training Acc 82.47 % AVG Validation Acc 77.15 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.375 AVG Validation Loss:0.556 AVG Training Acc 83.22 % AVG Validation Acc 76.75 %\n",
      "Epoch:80/200 AVG Training Loss:0.372 AVG Validation Loss:0.585 AVG Training Acc 83.14 % AVG Validation Acc 77.02 %\n",
      "Epoch:90/200 AVG Training Loss:0.369 AVG Validation Loss:0.575 AVG Training Acc 83.38 % AVG Validation Acc 77.15 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.369 AVG Validation Loss:0.571 AVG Training Acc 83.22 % AVG Validation Acc 76.88 %\n",
      "Epoch:110/200 AVG Training Loss:0.368 AVG Validation Loss:0.574 AVG Training Acc 83.40 % AVG Validation Acc 76.34 %\n",
      "Epoch:120/200 AVG Training Loss:0.367 AVG Validation Loss:0.566 AVG Training Acc 83.41 % AVG Validation Acc 77.28 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.366 AVG Validation Loss:0.582 AVG Training Acc 83.74 % AVG Validation Acc 76.75 %\n",
      "Epoch:140/200 AVG Training Loss:0.368 AVG Validation Loss:0.573 AVG Training Acc 83.50 % AVG Validation Acc 77.28 %\n",
      "Epoch:150/200 AVG Training Loss:0.368 AVG Validation Loss:0.579 AVG Training Acc 83.23 % AVG Validation Acc 76.88 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.369 AVG Validation Loss:0.566 AVG Training Acc 83.38 % AVG Validation Acc 77.15 %\n",
      "Epoch:170/200 AVG Training Loss:0.370 AVG Validation Loss:0.581 AVG Training Acc 83.40 % AVG Validation Acc 76.75 %\n",
      "Epoch:180/200 AVG Training Loss:0.369 AVG Validation Loss:0.588 AVG Training Acc 83.17 % AVG Validation Acc 76.34 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.369 AVG Validation Loss:0.580 AVG Training Acc 83.19 % AVG Validation Acc 77.28 %\n",
      "Epoch:200/200 AVG Training Loss:0.370 AVG Validation Loss:0.588 AVG Training Acc 83.26 % AVG Validation Acc 76.75 %\n",
      "Split 37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb236c2e174c44f48527d319884434b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.486 AVG Validation Loss:0.484 AVG Training Acc 79.77 % AVG Validation Acc 79.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.473 AVG Validation Loss:0.488 AVG Training Acc 79.84 % AVG Validation Acc 79.95 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.458 AVG Validation Loss:0.501 AVG Training Acc 80.17 % AVG Validation Acc 79.54 %\n",
      "Epoch:40/200 AVG Training Loss:0.451 AVG Validation Loss:0.506 AVG Training Acc 80.08 % AVG Validation Acc 79.68 %\n",
      "Epoch:50/200 AVG Training Loss:0.441 AVG Validation Loss:0.516 AVG Training Acc 80.41 % AVG Validation Acc 79.95 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.433 AVG Validation Loss:0.532 AVG Training Acc 80.52 % AVG Validation Acc 79.68 %\n",
      "Epoch:70/200 AVG Training Loss:0.432 AVG Validation Loss:0.540 AVG Training Acc 80.58 % AVG Validation Acc 79.41 %\n",
      "Epoch:80/200 AVG Training Loss:0.430 AVG Validation Loss:0.544 AVG Training Acc 80.58 % AVG Validation Acc 79.27 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.427 AVG Validation Loss:0.551 AVG Training Acc 80.83 % AVG Validation Acc 79.54 %\n",
      "Epoch:100/200 AVG Training Loss:0.428 AVG Validation Loss:0.543 AVG Training Acc 80.71 % AVG Validation Acc 79.54 %\n",
      "Epoch:110/200 AVG Training Loss:0.428 AVG Validation Loss:0.546 AVG Training Acc 80.98 % AVG Validation Acc 79.68 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.427 AVG Validation Loss:0.549 AVG Training Acc 81.00 % AVG Validation Acc 79.68 %\n",
      "Epoch:130/200 AVG Training Loss:0.428 AVG Validation Loss:0.553 AVG Training Acc 80.62 % AVG Validation Acc 79.54 %\n",
      "Epoch:140/200 AVG Training Loss:0.427 AVG Validation Loss:0.550 AVG Training Acc 80.64 % AVG Validation Acc 79.54 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.426 AVG Validation Loss:0.552 AVG Training Acc 80.53 % AVG Validation Acc 79.54 %\n",
      "Epoch:160/200 AVG Training Loss:0.428 AVG Validation Loss:0.552 AVG Training Acc 80.47 % AVG Validation Acc 79.68 %\n",
      "Epoch:170/200 AVG Training Loss:0.427 AVG Validation Loss:0.552 AVG Training Acc 81.13 % AVG Validation Acc 79.54 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.430 AVG Validation Loss:0.550 AVG Training Acc 80.56 % AVG Validation Acc 79.54 %\n",
      "Epoch:190/200 AVG Training Loss:0.428 AVG Validation Loss:0.551 AVG Training Acc 80.53 % AVG Validation Acc 79.41 %\n",
      "Epoch:200/200 AVG Training Loss:0.428 AVG Validation Loss:0.550 AVG Training Acc 80.79 % AVG Validation Acc 79.54 %\n",
      "Split 38\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aeb607b3ad841859726009725a33f78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.481 AVG Validation Loss:0.489 AVG Training Acc 80.01 % AVG Validation Acc 79.95 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.468 AVG Validation Loss:0.487 AVG Training Acc 79.81 % AVG Validation Acc 79.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.455 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 79.81 %\n",
      "Epoch:40/200 AVG Training Loss:0.445 AVG Validation Loss:0.514 AVG Training Acc 80.58 % AVG Validation Acc 78.87 %\n",
      "Epoch:50/200 AVG Training Loss:0.435 AVG Validation Loss:0.535 AVG Training Acc 80.70 % AVG Validation Acc 78.20 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.426 AVG Validation Loss:0.528 AVG Training Acc 81.37 % AVG Validation Acc 78.06 %\n",
      "Epoch:70/200 AVG Training Loss:0.423 AVG Validation Loss:0.535 AVG Training Acc 81.17 % AVG Validation Acc 77.79 %\n",
      "Epoch:80/200 AVG Training Loss:0.426 AVG Validation Loss:0.538 AVG Training Acc 81.32 % AVG Validation Acc 77.66 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.422 AVG Validation Loss:0.532 AVG Training Acc 81.31 % AVG Validation Acc 77.66 %\n",
      "Epoch:100/200 AVG Training Loss:0.421 AVG Validation Loss:0.534 AVG Training Acc 81.76 % AVG Validation Acc 77.79 %\n",
      "Epoch:110/200 AVG Training Loss:0.418 AVG Validation Loss:0.537 AVG Training Acc 81.76 % AVG Validation Acc 77.93 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.421 AVG Validation Loss:0.536 AVG Training Acc 81.32 % AVG Validation Acc 77.52 %\n",
      "Epoch:130/200 AVG Training Loss:0.422 AVG Validation Loss:0.536 AVG Training Acc 81.56 % AVG Validation Acc 77.66 %\n",
      "Epoch:140/200 AVG Training Loss:0.424 AVG Validation Loss:0.534 AVG Training Acc 81.28 % AVG Validation Acc 77.93 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.420 AVG Validation Loss:0.542 AVG Training Acc 81.58 % AVG Validation Acc 77.66 %\n",
      "Epoch:160/200 AVG Training Loss:0.422 AVG Validation Loss:0.537 AVG Training Acc 81.59 % AVG Validation Acc 77.39 %\n",
      "Epoch:170/200 AVG Training Loss:0.421 AVG Validation Loss:0.537 AVG Training Acc 81.26 % AVG Validation Acc 77.79 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.423 AVG Validation Loss:0.540 AVG Training Acc 81.64 % AVG Validation Acc 77.79 %\n",
      "Epoch:190/200 AVG Training Loss:0.422 AVG Validation Loss:0.536 AVG Training Acc 81.17 % AVG Validation Acc 77.79 %\n",
      "Epoch:200/200 AVG Training Loss:0.422 AVG Validation Loss:0.540 AVG Training Acc 81.32 % AVG Validation Acc 77.52 %\n",
      "Split 39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e3b7e54cab469d8d00b71bc3482aeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.488 AVG Validation Loss:0.484 AVG Training Acc 79.68 % AVG Validation Acc 79.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.475 AVG Validation Loss:0.475 AVG Training Acc 79.98 % AVG Validation Acc 79.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.467 AVG Validation Loss:0.478 AVG Training Acc 79.65 % AVG Validation Acc 79.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.457 AVG Validation Loss:0.496 AVG Training Acc 79.99 % AVG Validation Acc 80.08 %\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.419 AVG Validation Loss:0.521 AVG Training Acc 81.41 % AVG Validation Acc 78.20 %\n",
      "Epoch:60/200 AVG Training Loss:0.396 AVG Validation Loss:0.551 AVG Training Acc 82.29 % AVG Validation Acc 77.79 %\n",
      "Epoch:70/200 AVG Training Loss:0.375 AVG Validation Loss:0.564 AVG Training Acc 83.39 % AVG Validation Acc 77.79 %\n",
      "Epoch    71: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.357 AVG Validation Loss:0.588 AVG Training Acc 84.01 % AVG Validation Acc 77.39 %\n",
      "Epoch:90/200 AVG Training Loss:0.350 AVG Validation Loss:0.594 AVG Training Acc 84.49 % AVG Validation Acc 76.58 %\n",
      "Epoch:100/200 AVG Training Loss:0.350 AVG Validation Loss:0.605 AVG Training Acc 84.22 % AVG Validation Acc 76.04 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.347 AVG Validation Loss:0.608 AVG Training Acc 84.88 % AVG Validation Acc 76.85 %\n",
      "Epoch:120/200 AVG Training Loss:0.349 AVG Validation Loss:0.611 AVG Training Acc 84.49 % AVG Validation Acc 76.04 %\n",
      "Epoch:130/200 AVG Training Loss:0.346 AVG Validation Loss:0.608 AVG Training Acc 84.54 % AVG Validation Acc 76.45 %\n",
      "Epoch   133: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.347 AVG Validation Loss:0.610 AVG Training Acc 84.49 % AVG Validation Acc 76.72 %\n",
      "Epoch:150/200 AVG Training Loss:0.348 AVG Validation Loss:0.606 AVG Training Acc 84.67 % AVG Validation Acc 77.25 %\n",
      "Epoch:160/200 AVG Training Loss:0.345 AVG Validation Loss:0.606 AVG Training Acc 84.79 % AVG Validation Acc 76.85 %\n",
      "Epoch   164: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.348 AVG Validation Loss:0.604 AVG Training Acc 84.30 % AVG Validation Acc 76.99 %\n",
      "Epoch:180/200 AVG Training Loss:0.347 AVG Validation Loss:0.614 AVG Training Acc 84.57 % AVG Validation Acc 76.58 %\n",
      "Epoch:190/200 AVG Training Loss:0.347 AVG Validation Loss:0.609 AVG Training Acc 84.64 % AVG Validation Acc 76.85 %\n",
      "Epoch   195: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.344 AVG Validation Loss:0.611 AVG Training Acc 84.94 % AVG Validation Acc 76.31 %\n",
      "Split 40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01d77ca07755473da07eb55b69810f68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.488 AVG Validation Loss:0.476 AVG Training Acc 79.74 % AVG Validation Acc 79.81 %\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.477 AVG Validation Loss:0.470 AVG Training Acc 79.87 % AVG Validation Acc 80.22 %\n",
      "Epoch:30/200 AVG Training Loss:0.474 AVG Validation Loss:0.470 AVG Training Acc 79.87 % AVG Validation Acc 80.22 %\n",
      "Epoch:40/200 AVG Training Loss:0.471 AVG Validation Loss:0.471 AVG Training Acc 80.23 % AVG Validation Acc 80.08 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.467 AVG Validation Loss:0.473 AVG Training Acc 80.47 % AVG Validation Acc 80.22 %\n",
      "Epoch:60/200 AVG Training Loss:0.466 AVG Validation Loss:0.474 AVG Training Acc 80.44 % AVG Validation Acc 80.35 %\n",
      "Epoch:70/200 AVG Training Loss:0.466 AVG Validation Loss:0.475 AVG Training Acc 80.46 % AVG Validation Acc 80.22 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.465 AVG Validation Loss:0.475 AVG Training Acc 80.61 % AVG Validation Acc 80.08 %\n",
      "Epoch:90/200 AVG Training Loss:0.464 AVG Validation Loss:0.475 AVG Training Acc 80.79 % AVG Validation Acc 80.08 %\n",
      "Epoch:100/200 AVG Training Loss:0.464 AVG Validation Loss:0.476 AVG Training Acc 80.67 % AVG Validation Acc 80.22 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.465 AVG Validation Loss:0.475 AVG Training Acc 80.64 % AVG Validation Acc 80.08 %\n",
      "Epoch:120/200 AVG Training Loss:0.464 AVG Validation Loss:0.476 AVG Training Acc 80.70 % AVG Validation Acc 80.08 %\n",
      "Epoch:130/200 AVG Training Loss:0.463 AVG Validation Loss:0.475 AVG Training Acc 80.79 % AVG Validation Acc 80.08 %\n",
      "Epoch:140/200 AVG Training Loss:0.463 AVG Validation Loss:0.476 AVG Training Acc 80.79 % AVG Validation Acc 80.22 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.463 AVG Validation Loss:0.476 AVG Training Acc 80.65 % AVG Validation Acc 80.08 %\n",
      "Epoch:160/200 AVG Training Loss:0.464 AVG Validation Loss:0.476 AVG Training Acc 80.59 % AVG Validation Acc 80.08 %\n",
      "Epoch:170/200 AVG Training Loss:0.464 AVG Validation Loss:0.475 AVG Training Acc 80.68 % AVG Validation Acc 80.08 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.463 AVG Validation Loss:0.475 AVG Training Acc 80.67 % AVG Validation Acc 80.22 %\n",
      "Epoch:190/200 AVG Training Loss:0.465 AVG Validation Loss:0.476 AVG Training Acc 80.55 % AVG Validation Acc 79.95 %\n",
      "Epoch:200/200 AVG Training Loss:0.465 AVG Validation Loss:0.476 AVG Training Acc 80.52 % AVG Validation Acc 80.08 %\n",
      "Split 41\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec1bc90144e47fea92a47cbef990b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.483 AVG Validation Loss:0.501 AVG Training Acc 79.93 % AVG Validation Acc 79.84 %\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.474 AVG Validation Loss:0.474 AVG Training Acc 79.90 % AVG Validation Acc 80.11 %\n",
      "Epoch:30/200 AVG Training Loss:0.470 AVG Validation Loss:0.473 AVG Training Acc 79.96 % AVG Validation Acc 80.11 %\n",
      "Epoch:40/200 AVG Training Loss:0.465 AVG Validation Loss:0.472 AVG Training Acc 80.10 % AVG Validation Acc 80.38 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.455 AVG Validation Loss:0.474 AVG Training Acc 80.44 % AVG Validation Acc 80.11 %\n",
      "Epoch:60/200 AVG Training Loss:0.452 AVG Validation Loss:0.475 AVG Training Acc 80.62 % AVG Validation Acc 80.24 %\n",
      "Epoch:70/200 AVG Training Loss:0.449 AVG Validation Loss:0.474 AVG Training Acc 80.95 % AVG Validation Acc 80.38 %\n",
      "Epoch:80/200 AVG Training Loss:0.450 AVG Validation Loss:0.475 AVG Training Acc 80.81 % AVG Validation Acc 80.11 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.450 AVG Validation Loss:0.475 AVG Training Acc 80.89 % AVG Validation Acc 79.97 %\n",
      "Epoch:100/200 AVG Training Loss:0.449 AVG Validation Loss:0.474 AVG Training Acc 80.89 % AVG Validation Acc 79.97 %\n",
      "Epoch:110/200 AVG Training Loss:0.449 AVG Validation Loss:0.474 AVG Training Acc 81.07 % AVG Validation Acc 80.11 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.449 AVG Validation Loss:0.475 AVG Training Acc 80.84 % AVG Validation Acc 79.97 %\n",
      "Epoch:130/200 AVG Training Loss:0.450 AVG Validation Loss:0.475 AVG Training Acc 80.63 % AVG Validation Acc 80.11 %\n",
      "Epoch:140/200 AVG Training Loss:0.447 AVG Validation Loss:0.474 AVG Training Acc 80.95 % AVG Validation Acc 79.97 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.449 AVG Validation Loss:0.475 AVG Training Acc 80.75 % AVG Validation Acc 79.97 %\n",
      "Epoch:160/200 AVG Training Loss:0.450 AVG Validation Loss:0.475 AVG Training Acc 80.81 % AVG Validation Acc 79.97 %\n",
      "Epoch:170/200 AVG Training Loss:0.448 AVG Validation Loss:0.475 AVG Training Acc 80.90 % AVG Validation Acc 79.97 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.449 AVG Validation Loss:0.475 AVG Training Acc 80.81 % AVG Validation Acc 79.97 %\n",
      "Epoch:190/200 AVG Training Loss:0.448 AVG Validation Loss:0.475 AVG Training Acc 80.93 % AVG Validation Acc 79.97 %\n",
      "Epoch:200/200 AVG Training Loss:0.450 AVG Validation Loss:0.475 AVG Training Acc 80.78 % AVG Validation Acc 79.97 %\n",
      "Split 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdfaa4eb4e364c6b958940ec3371961d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.483 AVG Validation Loss:0.483 AVG Training Acc 79.83 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.474 AVG Validation Loss:0.478 AVG Training Acc 79.86 % AVG Validation Acc 79.84 %\n",
      "Epoch:30/200 AVG Training Loss:0.465 AVG Validation Loss:0.480 AVG Training Acc 80.19 % AVG Validation Acc 78.63 %\n",
      "Epoch:40/200 AVG Training Loss:0.448 AVG Validation Loss:0.484 AVG Training Acc 80.69 % AVG Validation Acc 79.70 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.408 AVG Validation Loss:0.480 AVG Training Acc 82.17 % AVG Validation Acc 77.96 %\n",
      "Epoch:60/200 AVG Training Loss:0.370 AVG Validation Loss:0.511 AVG Training Acc 83.64 % AVG Validation Acc 76.61 %\n",
      "Epoch:70/200 AVG Training Loss:0.341 AVG Validation Loss:0.570 AVG Training Acc 85.07 % AVG Validation Acc 75.54 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.311 AVG Validation Loss:0.596 AVG Training Acc 86.48 % AVG Validation Acc 75.67 %\n",
      "Epoch:90/200 AVG Training Loss:0.306 AVG Validation Loss:0.624 AVG Training Acc 86.43 % AVG Validation Acc 75.54 %\n",
      "Epoch:100/200 AVG Training Loss:0.302 AVG Validation Loss:0.627 AVG Training Acc 86.85 % AVG Validation Acc 74.87 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.299 AVG Validation Loss:0.639 AVG Training Acc 87.13 % AVG Validation Acc 75.40 %\n",
      "Epoch:120/200 AVG Training Loss:0.297 AVG Validation Loss:0.627 AVG Training Acc 87.09 % AVG Validation Acc 75.13 %\n",
      "Epoch:130/200 AVG Training Loss:0.300 AVG Validation Loss:0.637 AVG Training Acc 86.84 % AVG Validation Acc 74.60 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.298 AVG Validation Loss:0.631 AVG Training Acc 86.88 % AVG Validation Acc 75.27 %\n",
      "Epoch:150/200 AVG Training Loss:0.298 AVG Validation Loss:0.638 AVG Training Acc 87.04 % AVG Validation Acc 75.54 %\n",
      "Epoch:160/200 AVG Training Loss:0.297 AVG Validation Loss:0.642 AVG Training Acc 86.82 % AVG Validation Acc 75.27 %\n",
      "Epoch:170/200 AVG Training Loss:0.301 AVG Validation Loss:0.642 AVG Training Acc 86.75 % AVG Validation Acc 75.13 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.296 AVG Validation Loss:0.644 AVG Training Acc 87.04 % AVG Validation Acc 74.60 %\n",
      "Epoch:190/200 AVG Training Loss:0.294 AVG Validation Loss:0.638 AVG Training Acc 87.27 % AVG Validation Acc 74.87 %\n",
      "Epoch:200/200 AVG Training Loss:0.301 AVG Validation Loss:0.641 AVG Training Acc 86.67 % AVG Validation Acc 74.87 %\n",
      "Split 43\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afae7c9a9dd4448982c9cbdae79c277a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.491 AVG Validation Loss:0.480 AVG Training Acc 79.71 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.478 AVG Validation Loss:0.470 AVG Training Acc 79.71 % AVG Validation Acc 79.70 %\n",
      "Epoch:30/200 AVG Training Loss:0.471 AVG Validation Loss:0.459 AVG Training Acc 80.20 % AVG Validation Acc 79.84 %\n",
      "Epoch:40/200 AVG Training Loss:0.460 AVG Validation Loss:0.470 AVG Training Acc 80.10 % AVG Validation Acc 79.84 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.431 AVG Validation Loss:0.483 AVG Training Acc 81.43 % AVG Validation Acc 79.70 %\n",
      "Epoch:60/200 AVG Training Loss:0.402 AVG Validation Loss:0.518 AVG Training Acc 82.26 % AVG Validation Acc 80.65 %\n",
      "Epoch:70/200 AVG Training Loss:0.382 AVG Validation Loss:0.549 AVG Training Acc 83.13 % AVG Validation Acc 79.84 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.367 AVG Validation Loss:0.570 AVG Training Acc 83.74 % AVG Validation Acc 79.84 %\n",
      "Epoch:90/200 AVG Training Loss:0.362 AVG Validation Loss:0.571 AVG Training Acc 83.74 % AVG Validation Acc 79.17 %\n",
      "Epoch:100/200 AVG Training Loss:0.359 AVG Validation Loss:0.576 AVG Training Acc 84.46 % AVG Validation Acc 79.44 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.357 AVG Validation Loss:0.580 AVG Training Acc 84.47 % AVG Validation Acc 79.70 %\n",
      "Epoch:120/200 AVG Training Loss:0.358 AVG Validation Loss:0.587 AVG Training Acc 84.49 % AVG Validation Acc 79.03 %\n",
      "Epoch:130/200 AVG Training Loss:0.360 AVG Validation Loss:0.584 AVG Training Acc 84.18 % AVG Validation Acc 79.17 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.358 AVG Validation Loss:0.586 AVG Training Acc 84.41 % AVG Validation Acc 78.76 %\n",
      "Epoch:150/200 AVG Training Loss:0.359 AVG Validation Loss:0.580 AVG Training Acc 83.97 % AVG Validation Acc 79.17 %\n",
      "Epoch:160/200 AVG Training Loss:0.359 AVG Validation Loss:0.579 AVG Training Acc 84.22 % AVG Validation Acc 79.17 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.359 AVG Validation Loss:0.583 AVG Training Acc 84.34 % AVG Validation Acc 79.44 %\n",
      "Epoch:180/200 AVG Training Loss:0.357 AVG Validation Loss:0.584 AVG Training Acc 84.53 % AVG Validation Acc 79.44 %\n",
      "Epoch:190/200 AVG Training Loss:0.356 AVG Validation Loss:0.584 AVG Training Acc 84.22 % AVG Validation Acc 79.70 %\n",
      "Epoch:200/200 AVG Training Loss:0.356 AVG Validation Loss:0.584 AVG Training Acc 84.40 % AVG Validation Acc 79.57 %\n",
      "Epoch   200: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Split 44\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a4a4277d63442dfb6ee96225c59b490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.486 AVG Validation Loss:0.493 AVG Training Acc 79.90 % AVG Validation Acc 80.11 %\n",
      "Epoch:20/200 AVG Training Loss:0.474 AVG Validation Loss:0.488 AVG Training Acc 79.53 % AVG Validation Acc 79.84 %\n",
      "Epoch:30/200 AVG Training Loss:0.462 AVG Validation Loss:0.487 AVG Training Acc 80.32 % AVG Validation Acc 79.84 %\n",
      "Epoch:40/200 AVG Training Loss:0.450 AVG Validation Loss:0.504 AVG Training Acc 80.44 % AVG Validation Acc 79.30 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.409 AVG Validation Loss:0.536 AVG Training Acc 82.64 % AVG Validation Acc 77.42 %\n",
      "Epoch:60/200 AVG Training Loss:0.375 AVG Validation Loss:0.569 AVG Training Acc 84.09 % AVG Validation Acc 76.21 %\n",
      "Epoch:70/200 AVG Training Loss:0.351 AVG Validation Loss:0.603 AVG Training Acc 85.00 % AVG Validation Acc 75.54 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.327 AVG Validation Loss:0.641 AVG Training Acc 86.37 % AVG Validation Acc 74.60 %\n",
      "Epoch:90/200 AVG Training Loss:0.317 AVG Validation Loss:0.647 AVG Training Acc 86.92 % AVG Validation Acc 75.13 %\n",
      "Epoch:100/200 AVG Training Loss:0.316 AVG Validation Loss:0.657 AVG Training Acc 87.00 % AVG Validation Acc 75.00 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.313 AVG Validation Loss:0.659 AVG Training Acc 87.21 % AVG Validation Acc 74.46 %\n",
      "Epoch:120/200 AVG Training Loss:0.311 AVG Validation Loss:0.659 AVG Training Acc 86.97 % AVG Validation Acc 75.00 %\n",
      "Epoch:130/200 AVG Training Loss:0.311 AVG Validation Loss:0.671 AVG Training Acc 87.06 % AVG Validation Acc 74.19 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.312 AVG Validation Loss:0.662 AVG Training Acc 87.40 % AVG Validation Acc 75.27 %\n",
      "Epoch:150/200 AVG Training Loss:0.313 AVG Validation Loss:0.668 AVG Training Acc 87.01 % AVG Validation Acc 75.13 %\n",
      "Epoch:160/200 AVG Training Loss:0.308 AVG Validation Loss:0.661 AVG Training Acc 87.37 % AVG Validation Acc 74.46 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.310 AVG Validation Loss:0.662 AVG Training Acc 87.48 % AVG Validation Acc 74.73 %\n",
      "Epoch:180/200 AVG Training Loss:0.308 AVG Validation Loss:0.665 AVG Training Acc 87.49 % AVG Validation Acc 74.87 %\n",
      "Epoch:190/200 AVG Training Loss:0.311 AVG Validation Loss:0.660 AVG Training Acc 87.09 % AVG Validation Acc 74.73 %\n",
      "Epoch   198: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.311 AVG Validation Loss:0.670 AVG Training Acc 86.88 % AVG Validation Acc 74.19 %\n",
      "Split 45\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7802d43d2ca14b649588397c6e23872b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 79.72 % AVG Validation Acc 79.84 %\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.474 AVG Validation Loss:0.480 AVG Training Acc 80.17 % AVG Validation Acc 79.70 %\n",
      "Epoch:30/200 AVG Training Loss:0.468 AVG Validation Loss:0.480 AVG Training Acc 80.32 % AVG Validation Acc 80.24 %\n",
      "Epoch:40/200 AVG Training Loss:0.461 AVG Validation Loss:0.484 AVG Training Acc 80.45 % AVG Validation Acc 80.24 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.452 AVG Validation Loss:0.492 AVG Training Acc 80.62 % AVG Validation Acc 79.97 %\n",
      "Epoch:60/200 AVG Training Loss:0.452 AVG Validation Loss:0.494 AVG Training Acc 80.71 % AVG Validation Acc 79.84 %\n",
      "Epoch:70/200 AVG Training Loss:0.451 AVG Validation Loss:0.499 AVG Training Acc 80.93 % AVG Validation Acc 79.57 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.449 AVG Validation Loss:0.499 AVG Training Acc 80.95 % AVG Validation Acc 80.11 %\n",
      "Epoch:90/200 AVG Training Loss:0.450 AVG Validation Loss:0.499 AVG Training Acc 80.84 % AVG Validation Acc 80.11 %\n",
      "Epoch:100/200 AVG Training Loss:0.448 AVG Validation Loss:0.501 AVG Training Acc 80.99 % AVG Validation Acc 79.97 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.449 AVG Validation Loss:0.499 AVG Training Acc 80.92 % AVG Validation Acc 79.97 %\n",
      "Epoch:120/200 AVG Training Loss:0.449 AVG Validation Loss:0.501 AVG Training Acc 80.83 % AVG Validation Acc 79.84 %\n",
      "Epoch:130/200 AVG Training Loss:0.448 AVG Validation Loss:0.499 AVG Training Acc 81.04 % AVG Validation Acc 80.11 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.446 AVG Validation Loss:0.499 AVG Training Acc 81.10 % AVG Validation Acc 80.11 %\n",
      "Epoch:150/200 AVG Training Loss:0.448 AVG Validation Loss:0.500 AVG Training Acc 80.93 % AVG Validation Acc 79.84 %\n",
      "Epoch:160/200 AVG Training Loss:0.447 AVG Validation Loss:0.500 AVG Training Acc 81.01 % AVG Validation Acc 79.84 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.449 AVG Validation Loss:0.500 AVG Training Acc 80.95 % AVG Validation Acc 80.11 %\n",
      "Epoch:180/200 AVG Training Loss:0.449 AVG Validation Loss:0.499 AVG Training Acc 80.63 % AVG Validation Acc 80.11 %\n",
      "Epoch:190/200 AVG Training Loss:0.449 AVG Validation Loss:0.500 AVG Training Acc 81.01 % AVG Validation Acc 80.11 %\n",
      "Epoch:200/200 AVG Training Loss:0.447 AVG Validation Loss:0.499 AVG Training Acc 80.98 % AVG Validation Acc 79.97 %\n",
      "Split 46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4578b6c41e9438d951a07e333fd9fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.484 AVG Validation Loss:0.490 AVG Training Acc 79.86 % AVG Validation Acc 79.84 %\n",
      "Epoch:20/200 AVG Training Loss:0.475 AVG Validation Loss:0.480 AVG Training Acc 79.93 % AVG Validation Acc 79.84 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.463 AVG Validation Loss:0.473 AVG Training Acc 79.80 % AVG Validation Acc 80.38 %\n",
      "Epoch:40/200 AVG Training Loss:0.455 AVG Validation Loss:0.475 AVG Training Acc 80.51 % AVG Validation Acc 80.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.444 AVG Validation Loss:0.481 AVG Training Acc 80.35 % AVG Validation Acc 79.97 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.432 AVG Validation Loss:0.492 AVG Training Acc 81.02 % AVG Validation Acc 79.70 %\n",
      "Epoch:70/200 AVG Training Loss:0.428 AVG Validation Loss:0.494 AVG Training Acc 81.02 % AVG Validation Acc 80.11 %\n",
      "Epoch:80/200 AVG Training Loss:0.426 AVG Validation Loss:0.498 AVG Training Acc 81.43 % AVG Validation Acc 79.97 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.423 AVG Validation Loss:0.496 AVG Training Acc 81.52 % AVG Validation Acc 79.70 %\n",
      "Epoch:100/200 AVG Training Loss:0.428 AVG Validation Loss:0.498 AVG Training Acc 81.16 % AVG Validation Acc 79.57 %\n",
      "Epoch:110/200 AVG Training Loss:0.423 AVG Validation Loss:0.498 AVG Training Acc 81.55 % AVG Validation Acc 79.44 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.426 AVG Validation Loss:0.499 AVG Training Acc 81.58 % AVG Validation Acc 79.70 %\n",
      "Epoch:130/200 AVG Training Loss:0.426 AVG Validation Loss:0.494 AVG Training Acc 81.31 % AVG Validation Acc 79.70 %\n",
      "Epoch:140/200 AVG Training Loss:0.425 AVG Validation Loss:0.496 AVG Training Acc 81.46 % AVG Validation Acc 79.84 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.426 AVG Validation Loss:0.499 AVG Training Acc 81.11 % AVG Validation Acc 79.97 %\n",
      "Epoch:160/200 AVG Training Loss:0.427 AVG Validation Loss:0.497 AVG Training Acc 81.25 % AVG Validation Acc 79.57 %\n",
      "Epoch:170/200 AVG Training Loss:0.427 AVG Validation Loss:0.499 AVG Training Acc 81.25 % AVG Validation Acc 79.30 %\n",
      "Epoch:180/200 AVG Training Loss:0.423 AVG Validation Loss:0.495 AVG Training Acc 81.37 % AVG Validation Acc 79.97 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.422 AVG Validation Loss:0.495 AVG Training Acc 81.23 % AVG Validation Acc 79.57 %\n",
      "Epoch:200/200 AVG Training Loss:0.423 AVG Validation Loss:0.500 AVG Training Acc 81.26 % AVG Validation Acc 79.70 %\n",
      "Split 47\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecc9977df5d8462a86ebb9dc7eaf5dd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.487 AVG Validation Loss:0.486 AVG Training Acc 79.83 % AVG Validation Acc 79.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.473 AVG Validation Loss:0.476 AVG Training Acc 79.89 % AVG Validation Acc 79.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.465 AVG Validation Loss:0.473 AVG Training Acc 80.16 % AVG Validation Acc 80.22 %\n",
      "Epoch:40/200 AVG Training Loss:0.450 AVG Validation Loss:0.479 AVG Training Acc 80.44 % AVG Validation Acc 80.75 %\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.409 AVG Validation Loss:0.493 AVG Training Acc 82.09 % AVG Validation Acc 79.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.380 AVG Validation Loss:0.528 AVG Training Acc 83.89 % AVG Validation Acc 78.20 %\n",
      "Epoch:70/200 AVG Training Loss:0.357 AVG Validation Loss:0.559 AVG Training Acc 85.06 % AVG Validation Acc 77.93 %\n",
      "Epoch    71: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.343 AVG Validation Loss:0.577 AVG Training Acc 85.82 % AVG Validation Acc 77.25 %\n",
      "Epoch:90/200 AVG Training Loss:0.337 AVG Validation Loss:0.590 AVG Training Acc 86.06 % AVG Validation Acc 76.72 %\n",
      "Epoch:100/200 AVG Training Loss:0.338 AVG Validation Loss:0.581 AVG Training Acc 86.06 % AVG Validation Acc 76.72 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.339 AVG Validation Loss:0.598 AVG Training Acc 86.12 % AVG Validation Acc 76.45 %\n",
      "Epoch:120/200 AVG Training Loss:0.340 AVG Validation Loss:0.601 AVG Training Acc 85.90 % AVG Validation Acc 76.45 %\n",
      "Epoch:130/200 AVG Training Loss:0.340 AVG Validation Loss:0.593 AVG Training Acc 86.02 % AVG Validation Acc 76.99 %\n",
      "Epoch   133: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.337 AVG Validation Loss:0.584 AVG Training Acc 86.24 % AVG Validation Acc 77.66 %\n",
      "Epoch:150/200 AVG Training Loss:0.335 AVG Validation Loss:0.605 AVG Training Acc 86.34 % AVG Validation Acc 76.72 %\n",
      "Epoch:160/200 AVG Training Loss:0.336 AVG Validation Loss:0.588 AVG Training Acc 86.27 % AVG Validation Acc 76.58 %\n",
      "Epoch   164: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.336 AVG Validation Loss:0.592 AVG Training Acc 85.97 % AVG Validation Acc 77.12 %\n",
      "Epoch:180/200 AVG Training Loss:0.337 AVG Validation Loss:0.595 AVG Training Acc 86.06 % AVG Validation Acc 76.85 %\n",
      "Epoch:190/200 AVG Training Loss:0.339 AVG Validation Loss:0.598 AVG Training Acc 85.72 % AVG Validation Acc 76.72 %\n",
      "Epoch   195: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.336 AVG Validation Loss:0.598 AVG Training Acc 86.05 % AVG Validation Acc 76.99 %\n",
      "Split 48\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b64b87fde81b456d8e99093210869359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.486 AVG Validation Loss:0.481 AVG Training Acc 79.70 % AVG Validation Acc 79.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.471 AVG Validation Loss:0.480 AVG Training Acc 79.84 % AVG Validation Acc 79.68 %\n",
      "Epoch:30/200 AVG Training Loss:0.458 AVG Validation Loss:0.469 AVG Training Acc 80.22 % AVG Validation Acc 79.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.435 AVG Validation Loss:0.477 AVG Training Acc 80.83 % AVG Validation Acc 79.27 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.384 AVG Validation Loss:0.501 AVG Training Acc 83.13 % AVG Validation Acc 78.33 %\n",
      "Epoch:60/200 AVG Training Loss:0.345 AVG Validation Loss:0.568 AVG Training Acc 84.78 % AVG Validation Acc 76.58 %\n",
      "Epoch:70/200 AVG Training Loss:0.314 AVG Validation Loss:0.627 AVG Training Acc 86.48 % AVG Validation Acc 75.37 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.283 AVG Validation Loss:0.678 AVG Training Acc 87.58 % AVG Validation Acc 74.16 %\n",
      "Epoch:90/200 AVG Training Loss:0.280 AVG Validation Loss:0.705 AVG Training Acc 87.87 % AVG Validation Acc 74.56 %\n",
      "Epoch:100/200 AVG Training Loss:0.276 AVG Validation Loss:0.707 AVG Training Acc 88.06 % AVG Validation Acc 74.56 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.273 AVG Validation Loss:0.726 AVG Training Acc 88.20 % AVG Validation Acc 73.89 %\n",
      "Epoch:120/200 AVG Training Loss:0.272 AVG Validation Loss:0.727 AVG Training Acc 88.26 % AVG Validation Acc 74.02 %\n",
      "Epoch:130/200 AVG Training Loss:0.271 AVG Validation Loss:0.715 AVG Training Acc 88.44 % AVG Validation Acc 74.16 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.269 AVG Validation Loss:0.717 AVG Training Acc 88.21 % AVG Validation Acc 73.89 %\n",
      "Epoch:150/200 AVG Training Loss:0.268 AVG Validation Loss:0.716 AVG Training Acc 88.73 % AVG Validation Acc 74.16 %\n",
      "Epoch:160/200 AVG Training Loss:0.271 AVG Validation Loss:0.726 AVG Training Acc 88.15 % AVG Validation Acc 73.49 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.272 AVG Validation Loss:0.720 AVG Training Acc 87.97 % AVG Validation Acc 73.62 %\n",
      "Epoch:180/200 AVG Training Loss:0.274 AVG Validation Loss:0.714 AVG Training Acc 88.36 % AVG Validation Acc 73.89 %\n",
      "Epoch:190/200 AVG Training Loss:0.268 AVG Validation Loss:0.723 AVG Training Acc 88.75 % AVG Validation Acc 73.76 %\n",
      "Epoch:200/200 AVG Training Loss:0.272 AVG Validation Loss:0.726 AVG Training Acc 88.35 % AVG Validation Acc 74.29 %\n",
      "Epoch   200: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Split 49\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e805d21b9746d8858d4a011b4a7992",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.485 AVG Validation Loss:0.479 AVG Training Acc 79.55 % AVG Validation Acc 80.08 %\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.472 AVG Validation Loss:0.481 AVG Training Acc 80.07 % AVG Validation Acc 80.08 %\n",
      "Epoch:30/200 AVG Training Loss:0.466 AVG Validation Loss:0.483 AVG Training Acc 80.32 % AVG Validation Acc 80.48 %\n",
      "Epoch:40/200 AVG Training Loss:0.463 AVG Validation Loss:0.484 AVG Training Acc 80.25 % AVG Validation Acc 80.22 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.457 AVG Validation Loss:0.485 AVG Training Acc 80.97 % AVG Validation Acc 80.22 %\n",
      "Epoch:60/200 AVG Training Loss:0.457 AVG Validation Loss:0.487 AVG Training Acc 80.88 % AVG Validation Acc 80.22 %\n",
      "Epoch:70/200 AVG Training Loss:0.454 AVG Validation Loss:0.487 AVG Training Acc 81.16 % AVG Validation Acc 79.95 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.453 AVG Validation Loss:0.486 AVG Training Acc 80.97 % AVG Validation Acc 79.81 %\n",
      "Epoch:90/200 AVG Training Loss:0.453 AVG Validation Loss:0.486 AVG Training Acc 80.92 % AVG Validation Acc 79.81 %\n",
      "Epoch:100/200 AVG Training Loss:0.454 AVG Validation Loss:0.488 AVG Training Acc 80.92 % AVG Validation Acc 79.81 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.454 AVG Validation Loss:0.486 AVG Training Acc 80.77 % AVG Validation Acc 79.95 %\n",
      "Epoch:120/200 AVG Training Loss:0.454 AVG Validation Loss:0.486 AVG Training Acc 80.89 % AVG Validation Acc 79.81 %\n",
      "Epoch:130/200 AVG Training Loss:0.454 AVG Validation Loss:0.486 AVG Training Acc 80.94 % AVG Validation Acc 79.81 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.455 AVG Validation Loss:0.485 AVG Training Acc 80.73 % AVG Validation Acc 79.81 %\n",
      "Epoch:150/200 AVG Training Loss:0.452 AVG Validation Loss:0.486 AVG Training Acc 81.13 % AVG Validation Acc 79.81 %\n",
      "Epoch:160/200 AVG Training Loss:0.454 AVG Validation Loss:0.486 AVG Training Acc 81.05 % AVG Validation Acc 79.81 %\n",
      "Epoch:170/200 AVG Training Loss:0.454 AVG Validation Loss:0.486 AVG Training Acc 80.88 % AVG Validation Acc 79.95 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.453 AVG Validation Loss:0.486 AVG Training Acc 81.28 % AVG Validation Acc 79.81 %\n",
      "Epoch:190/200 AVG Training Loss:0.454 AVG Validation Loss:0.486 AVG Training Acc 80.80 % AVG Validation Acc 79.81 %\n",
      "Epoch:200/200 AVG Training Loss:0.453 AVG Validation Loss:0.486 AVG Training Acc 80.92 % AVG Validation Acc 79.81 %\n",
      "Split 50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c39a92ca78d4f1aa29d4cb1555c4d21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.484 AVG Validation Loss:0.493 AVG Training Acc 79.75 % AVG Validation Acc 79.68 %\n",
      "Epoch:20/200 AVG Training Loss:0.473 AVG Validation Loss:0.485 AVG Training Acc 79.89 % AVG Validation Acc 79.68 %\n",
      "Epoch:30/200 AVG Training Loss:0.460 AVG Validation Loss:0.495 AVG Training Acc 80.37 % AVG Validation Acc 79.41 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.427 AVG Validation Loss:0.515 AVG Training Acc 81.56 % AVG Validation Acc 78.33 %\n",
      "Epoch:50/200 AVG Training Loss:0.400 AVG Validation Loss:0.542 AVG Training Acc 82.59 % AVG Validation Acc 78.60 %\n",
      "Epoch:60/200 AVG Training Loss:0.385 AVG Validation Loss:0.575 AVG Training Acc 83.31 % AVG Validation Acc 77.79 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.362 AVG Validation Loss:0.602 AVG Training Acc 84.43 % AVG Validation Acc 77.52 %\n",
      "Epoch:80/200 AVG Training Loss:0.362 AVG Validation Loss:0.609 AVG Training Acc 84.42 % AVG Validation Acc 77.25 %\n",
      "Epoch:90/200 AVG Training Loss:0.357 AVG Validation Loss:0.613 AVG Training Acc 84.58 % AVG Validation Acc 77.52 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.355 AVG Validation Loss:0.608 AVG Training Acc 84.85 % AVG Validation Acc 77.66 %\n",
      "Epoch:110/200 AVG Training Loss:0.352 AVG Validation Loss:0.614 AVG Training Acc 84.76 % AVG Validation Acc 76.99 %\n",
      "Epoch:120/200 AVG Training Loss:0.355 AVG Validation Loss:0.617 AVG Training Acc 84.75 % AVG Validation Acc 77.12 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.352 AVG Validation Loss:0.616 AVG Training Acc 85.01 % AVG Validation Acc 76.99 %\n",
      "Epoch:140/200 AVG Training Loss:0.354 AVG Validation Loss:0.622 AVG Training Acc 85.06 % AVG Validation Acc 77.52 %\n",
      "Epoch:150/200 AVG Training Loss:0.352 AVG Validation Loss:0.617 AVG Training Acc 84.66 % AVG Validation Acc 77.25 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.355 AVG Validation Loss:0.615 AVG Training Acc 85.06 % AVG Validation Acc 77.66 %\n",
      "Epoch:170/200 AVG Training Loss:0.351 AVG Validation Loss:0.617 AVG Training Acc 84.60 % AVG Validation Acc 77.12 %\n",
      "Epoch:180/200 AVG Training Loss:0.352 AVG Validation Loss:0.620 AVG Training Acc 84.97 % AVG Validation Acc 76.99 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.350 AVG Validation Loss:0.620 AVG Training Acc 85.01 % AVG Validation Acc 76.99 %\n",
      "Epoch:200/200 AVG Training Loss:0.352 AVG Validation Loss:0.614 AVG Training Acc 85.46 % AVG Validation Acc 77.52 %\n",
      "exam_gifted\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7dd0c5acb614bd481544e5ab96bda29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd09c9126d43460aad631b84d24f43c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best Accuracy found: 72.31%\n",
      "Epoch: 1\n",
      "Epoch:10/200 AVG Training Loss:0.584 AVG Validation Loss:0.585 AVG Training Acc 72.31 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.582 AVG Validation Loss:0.582 AVG Training Acc 72.43 % AVG Validation Acc 72.72 %\n",
      "New Best Accuracy found: 72.72%\n",
      "Epoch: 20\n",
      "Epoch:30/200 AVG Training Loss:0.583 AVG Validation Loss:0.582 AVG Training Acc 72.30 % AVG Validation Acc 72.31 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "New Best Accuracy found: 72.85%\n",
      "Epoch: 39\n",
      "Epoch:40/200 AVG Training Loss:0.573 AVG Validation Loss:0.584 AVG Training Acc 72.71 % AVG Validation Acc 72.72 %\n",
      "New Best Accuracy found: 72.98%\n",
      "Epoch: 41\n",
      "Epoch:50/200 AVG Training Loss:0.564 AVG Validation Loss:0.592 AVG Training Acc 73.54 % AVG Validation Acc 72.31 %\n",
      "Epoch:60/200 AVG Training Loss:0.554 AVG Validation Loss:0.609 AVG Training Acc 74.27 % AVG Validation Acc 71.24 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.556 AVG Validation Loss:0.607 AVG Training Acc 73.94 % AVG Validation Acc 71.91 %\n",
      "Epoch:80/200 AVG Training Loss:0.550 AVG Validation Loss:0.613 AVG Training Acc 74.42 % AVG Validation Acc 71.24 %\n",
      "Epoch:90/200 AVG Training Loss:0.547 AVG Validation Loss:0.610 AVG Training Acc 74.67 % AVG Validation Acc 72.04 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.545 AVG Validation Loss:0.607 AVG Training Acc 74.97 % AVG Validation Acc 71.91 %\n",
      "Epoch:110/200 AVG Training Loss:0.544 AVG Validation Loss:0.610 AVG Training Acc 74.93 % AVG Validation Acc 71.91 %\n",
      "Epoch:120/200 AVG Training Loss:0.545 AVG Validation Loss:0.608 AVG Training Acc 74.91 % AVG Validation Acc 72.04 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.543 AVG Validation Loss:0.611 AVG Training Acc 74.82 % AVG Validation Acc 72.04 %\n",
      "Epoch:140/200 AVG Training Loss:0.543 AVG Validation Loss:0.608 AVG Training Acc 74.91 % AVG Validation Acc 72.18 %\n",
      "Epoch:150/200 AVG Training Loss:0.544 AVG Validation Loss:0.612 AVG Training Acc 74.81 % AVG Validation Acc 72.04 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.543 AVG Validation Loss:0.610 AVG Training Acc 74.84 % AVG Validation Acc 72.18 %\n",
      "Epoch:170/200 AVG Training Loss:0.545 AVG Validation Loss:0.613 AVG Training Acc 74.82 % AVG Validation Acc 71.91 %\n",
      "Epoch:180/200 AVG Training Loss:0.542 AVG Validation Loss:0.610 AVG Training Acc 74.70 % AVG Validation Acc 72.18 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.543 AVG Validation Loss:0.611 AVG Training Acc 74.70 % AVG Validation Acc 72.18 %\n",
      "Epoch:200/200 AVG Training Loss:0.542 AVG Validation Loss:0.607 AVG Training Acc 74.76 % AVG Validation Acc 72.04 %\n",
      "Split 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b20c3a4c2ab4ee79349d4d169652eee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.586 AVG Validation Loss:0.585 AVG Training Acc 72.31 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.580 AVG Validation Loss:0.580 AVG Training Acc 72.53 % AVG Validation Acc 72.31 %\n",
      "Epoch:30/200 AVG Training Loss:0.589 AVG Validation Loss:0.582 AVG Training Acc 72.27 % AVG Validation Acc 72.31 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.576 AVG Validation Loss:0.578 AVG Training Acc 72.53 % AVG Validation Acc 72.45 %\n",
      "Epoch:50/200 AVG Training Loss:0.570 AVG Validation Loss:0.581 AVG Training Acc 73.09 % AVG Validation Acc 72.04 %\n",
      "Epoch:60/200 AVG Training Loss:0.561 AVG Validation Loss:0.580 AVG Training Acc 73.68 % AVG Validation Acc 72.45 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.553 AVG Validation Loss:0.591 AVG Training Acc 74.42 % AVG Validation Acc 71.51 %\n",
      "Epoch:80/200 AVG Training Loss:0.549 AVG Validation Loss:0.594 AVG Training Acc 75.09 % AVG Validation Acc 71.37 %\n",
      "Epoch:90/200 AVG Training Loss:0.548 AVG Validation Loss:0.598 AVG Training Acc 74.81 % AVG Validation Acc 71.51 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.548 AVG Validation Loss:0.598 AVG Training Acc 74.87 % AVG Validation Acc 70.97 %\n",
      "Epoch:110/200 AVG Training Loss:0.544 AVG Validation Loss:0.598 AVG Training Acc 75.15 % AVG Validation Acc 71.37 %\n",
      "Epoch:120/200 AVG Training Loss:0.546 AVG Validation Loss:0.600 AVG Training Acc 74.99 % AVG Validation Acc 71.10 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.544 AVG Validation Loss:0.599 AVG Training Acc 75.06 % AVG Validation Acc 71.37 %\n",
      "Epoch:140/200 AVG Training Loss:0.548 AVG Validation Loss:0.598 AVG Training Acc 74.90 % AVG Validation Acc 71.24 %\n",
      "Epoch:150/200 AVG Training Loss:0.546 AVG Validation Loss:0.600 AVG Training Acc 74.87 % AVG Validation Acc 71.37 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.547 AVG Validation Loss:0.598 AVG Training Acc 74.82 % AVG Validation Acc 71.37 %\n",
      "Epoch:170/200 AVG Training Loss:0.546 AVG Validation Loss:0.602 AVG Training Acc 74.97 % AVG Validation Acc 71.37 %\n",
      "Epoch:180/200 AVG Training Loss:0.547 AVG Validation Loss:0.598 AVG Training Acc 74.99 % AVG Validation Acc 70.97 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.546 AVG Validation Loss:0.599 AVG Training Acc 75.19 % AVG Validation Acc 71.37 %\n",
      "Epoch:200/200 AVG Training Loss:0.545 AVG Validation Loss:0.599 AVG Training Acc 75.10 % AVG Validation Acc 71.10 %\n",
      "Split 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e71e0495e59d4b0abc238cfbaa5f2417",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.588 AVG Validation Loss:0.583 AVG Training Acc 72.31 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.582 AVG Validation Loss:0.583 AVG Training Acc 72.30 % AVG Validation Acc 72.31 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.574 AVG Validation Loss:0.583 AVG Training Acc 72.74 % AVG Validation Acc 72.18 %\n",
      "Epoch:40/200 AVG Training Loss:0.569 AVG Validation Loss:0.594 AVG Training Acc 73.16 % AVG Validation Acc 72.04 %\n",
      "Epoch:50/200 AVG Training Loss:0.562 AVG Validation Loss:0.608 AVG Training Acc 73.73 % AVG Validation Acc 70.97 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.553 AVG Validation Loss:0.615 AVG Training Acc 74.24 % AVG Validation Acc 70.56 %\n",
      "Epoch:70/200 AVG Training Loss:0.550 AVG Validation Loss:0.622 AVG Training Acc 74.33 % AVG Validation Acc 69.62 %\n",
      "Epoch:80/200 AVG Training Loss:0.547 AVG Validation Loss:0.625 AVG Training Acc 74.49 % AVG Validation Acc 69.89 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.548 AVG Validation Loss:0.626 AVG Training Acc 74.54 % AVG Validation Acc 69.89 %\n",
      "Epoch:100/200 AVG Training Loss:0.548 AVG Validation Loss:0.623 AVG Training Acc 74.43 % AVG Validation Acc 70.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.548 AVG Validation Loss:0.624 AVG Training Acc 74.25 % AVG Validation Acc 70.03 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.547 AVG Validation Loss:0.626 AVG Training Acc 74.49 % AVG Validation Acc 70.16 %\n",
      "Epoch:130/200 AVG Training Loss:0.545 AVG Validation Loss:0.627 AVG Training Acc 74.49 % AVG Validation Acc 69.89 %\n",
      "Epoch:140/200 AVG Training Loss:0.545 AVG Validation Loss:0.626 AVG Training Acc 74.67 % AVG Validation Acc 69.89 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.547 AVG Validation Loss:0.624 AVG Training Acc 74.55 % AVG Validation Acc 70.03 %\n",
      "Epoch:160/200 AVG Training Loss:0.547 AVG Validation Loss:0.626 AVG Training Acc 74.34 % AVG Validation Acc 69.89 %\n",
      "Epoch:170/200 AVG Training Loss:0.548 AVG Validation Loss:0.625 AVG Training Acc 74.45 % AVG Validation Acc 70.03 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.547 AVG Validation Loss:0.624 AVG Training Acc 74.49 % AVG Validation Acc 70.03 %\n",
      "Epoch:190/200 AVG Training Loss:0.546 AVG Validation Loss:0.626 AVG Training Acc 74.58 % AVG Validation Acc 69.89 %\n",
      "Epoch:200/200 AVG Training Loss:0.547 AVG Validation Loss:0.625 AVG Training Acc 74.31 % AVG Validation Acc 70.03 %\n",
      "Split 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82495043c0f24d59ac71b36113417f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.586 AVG Validation Loss:0.584 AVG Training Acc 72.25 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.581 AVG Validation Loss:0.582 AVG Training Acc 72.61 % AVG Validation Acc 72.45 %\n",
      "Epoch:30/200 AVG Training Loss:0.576 AVG Validation Loss:0.585 AVG Training Acc 72.59 % AVG Validation Acc 72.45 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.553 AVG Validation Loss:0.602 AVG Training Acc 73.98 % AVG Validation Acc 71.37 %\n",
      "Epoch:50/200 AVG Training Loss:0.532 AVG Validation Loss:0.622 AVG Training Acc 75.40 % AVG Validation Acc 70.70 %\n",
      "Epoch:60/200 AVG Training Loss:0.514 AVG Validation Loss:0.637 AVG Training Acc 76.61 % AVG Validation Acc 71.24 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.503 AVG Validation Loss:0.659 AVG Training Acc 77.38 % AVG Validation Acc 69.49 %\n",
      "Epoch:80/200 AVG Training Loss:0.499 AVG Validation Loss:0.666 AVG Training Acc 77.36 % AVG Validation Acc 70.16 %\n",
      "Epoch:90/200 AVG Training Loss:0.493 AVG Validation Loss:0.673 AVG Training Acc 77.50 % AVG Validation Acc 69.89 %\n",
      "Epoch:100/200 AVG Training Loss:0.491 AVG Validation Loss:0.668 AVG Training Acc 77.35 % AVG Validation Acc 70.56 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.492 AVG Validation Loss:0.669 AVG Training Acc 77.59 % AVG Validation Acc 70.70 %\n",
      "Epoch:120/200 AVG Training Loss:0.489 AVG Validation Loss:0.685 AVG Training Acc 77.76 % AVG Validation Acc 70.30 %\n",
      "Epoch:130/200 AVG Training Loss:0.489 AVG Validation Loss:0.675 AVG Training Acc 77.73 % AVG Validation Acc 70.97 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.488 AVG Validation Loss:0.678 AVG Training Acc 77.82 % AVG Validation Acc 69.89 %\n",
      "Epoch:150/200 AVG Training Loss:0.491 AVG Validation Loss:0.680 AVG Training Acc 77.75 % AVG Validation Acc 70.16 %\n",
      "Epoch:160/200 AVG Training Loss:0.490 AVG Validation Loss:0.682 AVG Training Acc 78.09 % AVG Validation Acc 70.03 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.489 AVG Validation Loss:0.676 AVG Training Acc 77.84 % AVG Validation Acc 69.62 %\n",
      "Epoch:180/200 AVG Training Loss:0.491 AVG Validation Loss:0.675 AVG Training Acc 77.84 % AVG Validation Acc 69.76 %\n",
      "Epoch:190/200 AVG Training Loss:0.490 AVG Validation Loss:0.674 AVG Training Acc 77.67 % AVG Validation Acc 70.03 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.490 AVG Validation Loss:0.680 AVG Training Acc 77.97 % AVG Validation Acc 70.16 %\n",
      "Split 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f351750040284717a4b98a51cb5032f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.583 AVG Validation Loss:0.584 AVG Training Acc 72.33 % AVG Validation Acc 72.31 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.573 AVG Validation Loss:0.585 AVG Training Acc 72.80 % AVG Validation Acc 72.45 %\n",
      "Epoch:30/200 AVG Training Loss:0.570 AVG Validation Loss:0.587 AVG Training Acc 72.97 % AVG Validation Acc 72.04 %\n",
      "Epoch:40/200 AVG Training Loss:0.566 AVG Validation Loss:0.593 AVG Training Acc 73.30 % AVG Validation Acc 72.45 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.563 AVG Validation Loss:0.599 AVG Training Acc 73.49 % AVG Validation Acc 71.91 %\n",
      "Epoch:60/200 AVG Training Loss:0.560 AVG Validation Loss:0.602 AVG Training Acc 73.64 % AVG Validation Acc 71.77 %\n",
      "Epoch:70/200 AVG Training Loss:0.559 AVG Validation Loss:0.601 AVG Training Acc 73.77 % AVG Validation Acc 71.77 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.556 AVG Validation Loss:0.601 AVG Training Acc 73.85 % AVG Validation Acc 71.91 %\n",
      "Epoch:90/200 AVG Training Loss:0.557 AVG Validation Loss:0.603 AVG Training Acc 73.85 % AVG Validation Acc 71.64 %\n",
      "Epoch:100/200 AVG Training Loss:0.556 AVG Validation Loss:0.605 AVG Training Acc 73.91 % AVG Validation Acc 71.91 %\n",
      "Epoch:110/200 AVG Training Loss:0.557 AVG Validation Loss:0.602 AVG Training Acc 73.88 % AVG Validation Acc 72.04 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.557 AVG Validation Loss:0.602 AVG Training Acc 73.98 % AVG Validation Acc 72.04 %\n",
      "Epoch:130/200 AVG Training Loss:0.556 AVG Validation Loss:0.602 AVG Training Acc 73.97 % AVG Validation Acc 71.91 %\n",
      "Epoch:140/200 AVG Training Loss:0.557 AVG Validation Loss:0.602 AVG Training Acc 73.74 % AVG Validation Acc 71.77 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.557 AVG Validation Loss:0.605 AVG Training Acc 73.83 % AVG Validation Acc 71.91 %\n",
      "Epoch:160/200 AVG Training Loss:0.557 AVG Validation Loss:0.601 AVG Training Acc 73.86 % AVG Validation Acc 71.91 %\n",
      "Epoch:170/200 AVG Training Loss:0.557 AVG Validation Loss:0.604 AVG Training Acc 73.74 % AVG Validation Acc 72.04 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.558 AVG Validation Loss:0.605 AVG Training Acc 73.91 % AVG Validation Acc 71.51 %\n",
      "Epoch:190/200 AVG Training Loss:0.558 AVG Validation Loss:0.601 AVG Training Acc 73.83 % AVG Validation Acc 71.64 %\n",
      "Epoch:200/200 AVG Training Loss:0.558 AVG Validation Loss:0.602 AVG Training Acc 73.77 % AVG Validation Acc 71.77 %\n",
      "Split 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b975daaf99184130975f24c113dbef54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.582 AVG Validation Loss:0.590 AVG Training Acc 72.33 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.580 AVG Validation Loss:0.590 AVG Training Acc 72.41 % AVG Validation Acc 72.31 %\n",
      "Epoch:30/200 AVG Training Loss:0.574 AVG Validation Loss:0.596 AVG Training Acc 73.15 % AVG Validation Acc 72.31 %\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.557 AVG Validation Loss:0.596 AVG Training Acc 73.85 % AVG Validation Acc 71.64 %\n",
      "Epoch:50/200 AVG Training Loss:0.532 AVG Validation Loss:0.615 AVG Training Acc 75.79 % AVG Validation Acc 70.83 %\n",
      "Epoch:60/200 AVG Training Loss:0.508 AVG Validation Loss:0.639 AVG Training Acc 77.18 % AVG Validation Acc 70.56 %\n",
      "Epoch:70/200 AVG Training Loss:0.496 AVG Validation Loss:0.663 AVG Training Acc 77.69 % AVG Validation Acc 69.09 %\n",
      "Epoch    70: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.489 AVG Validation Loss:0.664 AVG Training Acc 78.60 % AVG Validation Acc 68.68 %\n",
      "Epoch:90/200 AVG Training Loss:0.486 AVG Validation Loss:0.664 AVG Training Acc 78.72 % AVG Validation Acc 69.35 %\n",
      "Epoch:100/200 AVG Training Loss:0.481 AVG Validation Loss:0.675 AVG Training Acc 79.00 % AVG Validation Acc 68.55 %\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.480 AVG Validation Loss:0.672 AVG Training Acc 78.99 % AVG Validation Acc 68.15 %\n",
      "Epoch:120/200 AVG Training Loss:0.481 AVG Validation Loss:0.675 AVG Training Acc 79.35 % AVG Validation Acc 68.41 %\n",
      "Epoch:130/200 AVG Training Loss:0.480 AVG Validation Loss:0.670 AVG Training Acc 78.75 % AVG Validation Acc 68.82 %\n",
      "Epoch   132: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.480 AVG Validation Loss:0.670 AVG Training Acc 78.89 % AVG Validation Acc 68.95 %\n",
      "Epoch:150/200 AVG Training Loss:0.481 AVG Validation Loss:0.669 AVG Training Acc 78.90 % AVG Validation Acc 68.82 %\n",
      "Epoch:160/200 AVG Training Loss:0.479 AVG Validation Loss:0.683 AVG Training Acc 79.02 % AVG Validation Acc 68.55 %\n",
      "Epoch   163: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.484 AVG Validation Loss:0.678 AVG Training Acc 78.78 % AVG Validation Acc 68.68 %\n",
      "Epoch:180/200 AVG Training Loss:0.480 AVG Validation Loss:0.676 AVG Training Acc 79.03 % AVG Validation Acc 68.28 %\n",
      "Epoch:190/200 AVG Training Loss:0.478 AVG Validation Loss:0.671 AVG Training Acc 79.08 % AVG Validation Acc 68.68 %\n",
      "Epoch   194: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.480 AVG Validation Loss:0.674 AVG Training Acc 79.06 % AVG Validation Acc 68.82 %\n",
      "Split 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "012b793116404c37a72fdb1c16348b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.586 AVG Validation Loss:0.588 AVG Training Acc 72.49 % AVG Validation Acc 72.41 %\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.578 AVG Validation Loss:0.586 AVG Training Acc 72.51 % AVG Validation Acc 72.41 %\n",
      "Epoch:30/200 AVG Training Loss:0.574 AVG Validation Loss:0.585 AVG Training Acc 72.81 % AVG Validation Acc 72.41 %\n",
      "Epoch:40/200 AVG Training Loss:0.571 AVG Validation Loss:0.590 AVG Training Acc 72.93 % AVG Validation Acc 72.27 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.568 AVG Validation Loss:0.592 AVG Training Acc 73.29 % AVG Validation Acc 71.87 %\n",
      "Epoch:60/200 AVG Training Loss:0.566 AVG Validation Loss:0.594 AVG Training Acc 73.41 % AVG Validation Acc 72.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.566 AVG Validation Loss:0.591 AVG Training Acc 73.29 % AVG Validation Acc 72.41 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.564 AVG Validation Loss:0.593 AVG Training Acc 73.66 % AVG Validation Acc 72.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.565 AVG Validation Loss:0.593 AVG Training Acc 73.46 % AVG Validation Acc 72.27 %\n",
      "Epoch:100/200 AVG Training Loss:0.564 AVG Validation Loss:0.593 AVG Training Acc 73.45 % AVG Validation Acc 72.27 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.565 AVG Validation Loss:0.595 AVG Training Acc 73.33 % AVG Validation Acc 72.27 %\n",
      "Epoch:120/200 AVG Training Loss:0.565 AVG Validation Loss:0.592 AVG Training Acc 73.32 % AVG Validation Acc 72.41 %\n",
      "Epoch:130/200 AVG Training Loss:0.565 AVG Validation Loss:0.592 AVG Training Acc 73.38 % AVG Validation Acc 72.54 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.565 AVG Validation Loss:0.592 AVG Training Acc 73.30 % AVG Validation Acc 72.41 %\n",
      "Epoch:150/200 AVG Training Loss:0.565 AVG Validation Loss:0.594 AVG Training Acc 73.48 % AVG Validation Acc 72.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.564 AVG Validation Loss:0.594 AVG Training Acc 73.63 % AVG Validation Acc 72.14 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.566 AVG Validation Loss:0.595 AVG Training Acc 73.46 % AVG Validation Acc 72.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.564 AVG Validation Loss:0.595 AVG Training Acc 73.46 % AVG Validation Acc 72.01 %\n",
      "Epoch:190/200 AVG Training Loss:0.565 AVG Validation Loss:0.595 AVG Training Acc 73.49 % AVG Validation Acc 72.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.565 AVG Validation Loss:0.592 AVG Training Acc 73.58 % AVG Validation Acc 72.14 %\n",
      "Split 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35e1a61c55f240d0b59e02e0e0844da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.585 AVG Validation Loss:0.577 AVG Training Acc 72.42 % AVG Validation Acc 72.27 %\n",
      "Epoch:20/200 AVG Training Loss:0.581 AVG Validation Loss:0.576 AVG Training Acc 72.70 % AVG Validation Acc 72.27 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.573 AVG Validation Loss:0.577 AVG Training Acc 72.99 % AVG Validation Acc 72.01 %\n",
      "Epoch:40/200 AVG Training Loss:0.570 AVG Validation Loss:0.577 AVG Training Acc 73.14 % AVG Validation Acc 72.27 %\n",
      "Epoch:50/200 AVG Training Loss:0.565 AVG Validation Loss:0.585 AVG Training Acc 73.39 % AVG Validation Acc 72.01 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.558 AVG Validation Loss:0.588 AVG Training Acc 74.02 % AVG Validation Acc 72.27 %\n",
      "Epoch:70/200 AVG Training Loss:0.557 AVG Validation Loss:0.589 AVG Training Acc 74.15 % AVG Validation Acc 72.01 %\n",
      "Epoch:80/200 AVG Training Loss:0.555 AVG Validation Loss:0.589 AVG Training Acc 74.27 % AVG Validation Acc 72.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.553 AVG Validation Loss:0.591 AVG Training Acc 74.29 % AVG Validation Acc 71.87 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.555 AVG Validation Loss:0.592 AVG Training Acc 74.35 % AVG Validation Acc 72.41 %\n",
      "Epoch:110/200 AVG Training Loss:0.554 AVG Validation Loss:0.592 AVG Training Acc 74.12 % AVG Validation Acc 72.14 %\n",
      "Epoch:120/200 AVG Training Loss:0.555 AVG Validation Loss:0.594 AVG Training Acc 74.09 % AVG Validation Acc 72.01 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.555 AVG Validation Loss:0.591 AVG Training Acc 74.18 % AVG Validation Acc 72.27 %\n",
      "Epoch:140/200 AVG Training Loss:0.554 AVG Validation Loss:0.591 AVG Training Acc 74.17 % AVG Validation Acc 72.27 %\n",
      "Epoch:150/200 AVG Training Loss:0.556 AVG Validation Loss:0.591 AVG Training Acc 74.15 % AVG Validation Acc 72.41 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.555 AVG Validation Loss:0.594 AVG Training Acc 74.21 % AVG Validation Acc 72.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.554 AVG Validation Loss:0.592 AVG Training Acc 74.27 % AVG Validation Acc 72.01 %\n",
      "Epoch:180/200 AVG Training Loss:0.553 AVG Validation Loss:0.591 AVG Training Acc 74.14 % AVG Validation Acc 72.41 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.553 AVG Validation Loss:0.591 AVG Training Acc 74.08 % AVG Validation Acc 72.41 %\n",
      "Epoch:200/200 AVG Training Loss:0.554 AVG Validation Loss:0.592 AVG Training Acc 74.20 % AVG Validation Acc 72.14 %\n",
      "Split 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b6085ce3d6a4d00a0670403e542cd07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.585 AVG Validation Loss:0.580 AVG Training Acc 72.21 % AVG Validation Acc 72.27 %\n",
      "Epoch:20/200 AVG Training Loss:0.582 AVG Validation Loss:0.578 AVG Training Acc 72.48 % AVG Validation Acc 72.27 %\n",
      "Epoch:30/200 AVG Training Loss:0.579 AVG Validation Loss:0.578 AVG Training Acc 72.67 % AVG Validation Acc 72.81 %\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.566 AVG Validation Loss:0.595 AVG Training Acc 73.20 % AVG Validation Acc 71.06 %\n",
      "Epoch:50/200 AVG Training Loss:0.549 AVG Validation Loss:0.616 AVG Training Acc 74.23 % AVG Validation Acc 71.74 %\n",
      "Epoch:60/200 AVG Training Loss:0.539 AVG Validation Loss:0.633 AVG Training Acc 74.75 % AVG Validation Acc 71.33 %\n",
      "Epoch:70/200 AVG Training Loss:0.527 AVG Validation Loss:0.644 AVG Training Acc 75.29 % AVG Validation Acc 72.01 %\n",
      "Epoch    70: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.520 AVG Validation Loss:0.660 AVG Training Acc 75.68 % AVG Validation Acc 71.87 %\n",
      "Epoch:90/200 AVG Training Loss:0.521 AVG Validation Loss:0.661 AVG Training Acc 75.50 % AVG Validation Acc 71.60 %\n",
      "Epoch:100/200 AVG Training Loss:0.517 AVG Validation Loss:0.662 AVG Training Acc 75.97 % AVG Validation Acc 71.60 %\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.517 AVG Validation Loss:0.661 AVG Training Acc 75.80 % AVG Validation Acc 71.74 %\n",
      "Epoch:120/200 AVG Training Loss:0.517 AVG Validation Loss:0.661 AVG Training Acc 75.72 % AVG Validation Acc 71.47 %\n",
      "Epoch:130/200 AVG Training Loss:0.516 AVG Validation Loss:0.661 AVG Training Acc 75.68 % AVG Validation Acc 71.74 %\n",
      "Epoch   132: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.519 AVG Validation Loss:0.662 AVG Training Acc 75.75 % AVG Validation Acc 71.87 %\n",
      "Epoch:150/200 AVG Training Loss:0.516 AVG Validation Loss:0.661 AVG Training Acc 75.86 % AVG Validation Acc 71.87 %\n",
      "Epoch:160/200 AVG Training Loss:0.518 AVG Validation Loss:0.659 AVG Training Acc 75.72 % AVG Validation Acc 72.01 %\n",
      "Epoch   163: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.516 AVG Validation Loss:0.663 AVG Training Acc 75.75 % AVG Validation Acc 71.74 %\n",
      "Epoch:180/200 AVG Training Loss:0.517 AVG Validation Loss:0.662 AVG Training Acc 75.72 % AVG Validation Acc 71.60 %\n",
      "Epoch:190/200 AVG Training Loss:0.518 AVG Validation Loss:0.664 AVG Training Acc 75.80 % AVG Validation Acc 71.47 %\n",
      "Epoch   194: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.517 AVG Validation Loss:0.661 AVG Training Acc 75.71 % AVG Validation Acc 71.60 %\n",
      "Split 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3379b6a5c8d4756834099f1e8afc33f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.587 AVG Validation Loss:0.595 AVG Training Acc 72.31 % AVG Validation Acc 72.27 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.577 AVG Validation Loss:0.594 AVG Training Acc 72.45 % AVG Validation Acc 72.27 %\n",
      "Epoch:30/200 AVG Training Loss:0.571 AVG Validation Loss:0.602 AVG Training Acc 72.93 % AVG Validation Acc 71.06 %\n",
      "Epoch:40/200 AVG Training Loss:0.565 AVG Validation Loss:0.605 AVG Training Acc 73.63 % AVG Validation Acc 70.66 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.558 AVG Validation Loss:0.611 AVG Training Acc 74.18 % AVG Validation Acc 70.26 %\n",
      "Epoch:60/200 AVG Training Loss:0.555 AVG Validation Loss:0.616 AVG Training Acc 74.21 % AVG Validation Acc 70.12 %\n",
      "Epoch:70/200 AVG Training Loss:0.554 AVG Validation Loss:0.618 AVG Training Acc 74.41 % AVG Validation Acc 70.26 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.554 AVG Validation Loss:0.621 AVG Training Acc 74.24 % AVG Validation Acc 70.39 %\n",
      "Epoch:90/200 AVG Training Loss:0.552 AVG Validation Loss:0.620 AVG Training Acc 74.26 % AVG Validation Acc 70.39 %\n",
      "Epoch:100/200 AVG Training Loss:0.552 AVG Validation Loss:0.621 AVG Training Acc 74.42 % AVG Validation Acc 70.26 %\n",
      "Epoch:110/200 AVG Training Loss:0.552 AVG Validation Loss:0.623 AVG Training Acc 74.39 % AVG Validation Acc 69.72 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.553 AVG Validation Loss:0.620 AVG Training Acc 74.42 % AVG Validation Acc 70.66 %\n",
      "Epoch:130/200 AVG Training Loss:0.551 AVG Validation Loss:0.621 AVG Training Acc 74.51 % AVG Validation Acc 70.52 %\n",
      "Epoch:140/200 AVG Training Loss:0.552 AVG Validation Loss:0.620 AVG Training Acc 74.50 % AVG Validation Acc 70.52 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.552 AVG Validation Loss:0.621 AVG Training Acc 74.33 % AVG Validation Acc 70.39 %\n",
      "Epoch:160/200 AVG Training Loss:0.552 AVG Validation Loss:0.621 AVG Training Acc 74.45 % AVG Validation Acc 70.66 %\n",
      "Epoch:170/200 AVG Training Loss:0.552 AVG Validation Loss:0.622 AVG Training Acc 74.45 % AVG Validation Acc 70.39 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.553 AVG Validation Loss:0.622 AVG Training Acc 74.39 % AVG Validation Acc 70.26 %\n",
      "Epoch:190/200 AVG Training Loss:0.553 AVG Validation Loss:0.622 AVG Training Acc 74.32 % AVG Validation Acc 70.52 %\n",
      "Epoch:200/200 AVG Training Loss:0.552 AVG Validation Loss:0.622 AVG Training Acc 74.32 % AVG Validation Acc 70.26 %\n",
      "Split 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8a70cfa1fe14cf6a1314fdfa82c221a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.585 AVG Validation Loss:0.582 AVG Training Acc 72.33 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.580 AVG Validation Loss:0.580 AVG Training Acc 72.62 % AVG Validation Acc 72.31 %\n",
      "Epoch:30/200 AVG Training Loss:0.573 AVG Validation Loss:0.581 AVG Training Acc 73.04 % AVG Validation Acc 72.45 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.554 AVG Validation Loss:0.591 AVG Training Acc 74.36 % AVG Validation Acc 71.37 %\n",
      "Epoch:50/200 AVG Training Loss:0.535 AVG Validation Loss:0.616 AVG Training Acc 75.69 % AVG Validation Acc 70.56 %\n",
      "Epoch:60/200 AVG Training Loss:0.526 AVG Validation Loss:0.631 AVG Training Acc 75.96 % AVG Validation Acc 71.10 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.521 AVG Validation Loss:0.641 AVG Training Acc 76.40 % AVG Validation Acc 69.76 %\n",
      "Epoch:80/200 AVG Training Loss:0.515 AVG Validation Loss:0.647 AVG Training Acc 76.66 % AVG Validation Acc 70.30 %\n",
      "Epoch:90/200 AVG Training Loss:0.512 AVG Validation Loss:0.661 AVG Training Acc 76.75 % AVG Validation Acc 70.03 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.512 AVG Validation Loss:0.653 AVG Training Acc 76.67 % AVG Validation Acc 70.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.509 AVG Validation Loss:0.668 AVG Training Acc 77.11 % AVG Validation Acc 70.30 %\n",
      "Epoch:120/200 AVG Training Loss:0.508 AVG Validation Loss:0.661 AVG Training Acc 77.14 % AVG Validation Acc 70.30 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.508 AVG Validation Loss:0.663 AVG Training Acc 76.99 % AVG Validation Acc 70.30 %\n",
      "Epoch:140/200 AVG Training Loss:0.510 AVG Validation Loss:0.659 AVG Training Acc 76.93 % AVG Validation Acc 69.89 %\n",
      "Epoch:150/200 AVG Training Loss:0.510 AVG Validation Loss:0.664 AVG Training Acc 76.84 % AVG Validation Acc 70.30 %\n",
      "Epoch:160/200 AVG Training Loss:0.510 AVG Validation Loss:0.653 AVG Training Acc 76.61 % AVG Validation Acc 70.43 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.511 AVG Validation Loss:0.662 AVG Training Acc 76.73 % AVG Validation Acc 70.30 %\n",
      "Epoch:180/200 AVG Training Loss:0.509 AVG Validation Loss:0.656 AVG Training Acc 76.97 % AVG Validation Acc 70.70 %\n",
      "Epoch:190/200 AVG Training Loss:0.510 AVG Validation Loss:0.656 AVG Training Acc 76.87 % AVG Validation Acc 70.30 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.509 AVG Validation Loss:0.660 AVG Training Acc 76.78 % AVG Validation Acc 69.89 %\n",
      "Split 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cd992f6209a4dd7b6b1aeda59cf4ea5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.584 AVG Validation Loss:0.582 AVG Training Acc 72.33 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.581 AVG Validation Loss:0.581 AVG Training Acc 72.44 % AVG Validation Acc 72.45 %\n",
      "Epoch:30/200 AVG Training Loss:0.583 AVG Validation Loss:0.583 AVG Training Acc 72.85 % AVG Validation Acc 72.45 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.564 AVG Validation Loss:0.590 AVG Training Acc 73.49 % AVG Validation Acc 71.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.555 AVG Validation Loss:0.588 AVG Training Acc 74.45 % AVG Validation Acc 72.04 %\n",
      "Epoch:60/200 AVG Training Loss:0.546 AVG Validation Loss:0.603 AVG Training Acc 74.93 % AVG Validation Acc 71.91 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.541 AVG Validation Loss:0.608 AVG Training Acc 75.43 % AVG Validation Acc 71.51 %\n",
      "Epoch:80/200 AVG Training Loss:0.537 AVG Validation Loss:0.605 AVG Training Acc 75.36 % AVG Validation Acc 71.77 %\n",
      "Epoch:90/200 AVG Training Loss:0.536 AVG Validation Loss:0.610 AVG Training Acc 75.67 % AVG Validation Acc 72.04 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.535 AVG Validation Loss:0.612 AVG Training Acc 75.75 % AVG Validation Acc 72.31 %\n",
      "Epoch:110/200 AVG Training Loss:0.536 AVG Validation Loss:0.610 AVG Training Acc 75.48 % AVG Validation Acc 72.04 %\n",
      "Epoch:120/200 AVG Training Loss:0.537 AVG Validation Loss:0.610 AVG Training Acc 75.60 % AVG Validation Acc 72.18 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.535 AVG Validation Loss:0.610 AVG Training Acc 75.70 % AVG Validation Acc 72.18 %\n",
      "Epoch:140/200 AVG Training Loss:0.534 AVG Validation Loss:0.610 AVG Training Acc 75.51 % AVG Validation Acc 71.77 %\n",
      "Epoch:150/200 AVG Training Loss:0.535 AVG Validation Loss:0.610 AVG Training Acc 75.61 % AVG Validation Acc 72.45 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.535 AVG Validation Loss:0.609 AVG Training Acc 75.84 % AVG Validation Acc 72.18 %\n",
      "Epoch:170/200 AVG Training Loss:0.536 AVG Validation Loss:0.610 AVG Training Acc 75.42 % AVG Validation Acc 72.18 %\n",
      "Epoch:180/200 AVG Training Loss:0.539 AVG Validation Loss:0.608 AVG Training Acc 75.37 % AVG Validation Acc 71.77 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.536 AVG Validation Loss:0.611 AVG Training Acc 75.63 % AVG Validation Acc 72.18 %\n",
      "Epoch:200/200 AVG Training Loss:0.537 AVG Validation Loss:0.611 AVG Training Acc 75.43 % AVG Validation Acc 72.18 %\n",
      "Split 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14ce072523034965ba3c281b8169fe7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.582 AVG Validation Loss:0.590 AVG Training Acc 72.34 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.578 AVG Validation Loss:0.585 AVG Training Acc 72.41 % AVG Validation Acc 72.45 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.572 AVG Validation Loss:0.589 AVG Training Acc 72.77 % AVG Validation Acc 72.45 %\n",
      "Epoch:40/200 AVG Training Loss:0.564 AVG Validation Loss:0.595 AVG Training Acc 73.16 % AVG Validation Acc 72.04 %\n",
      "Epoch:50/200 AVG Training Loss:0.554 AVG Validation Loss:0.608 AVG Training Acc 74.10 % AVG Validation Acc 70.97 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.535 AVG Validation Loss:0.619 AVG Training Acc 75.70 % AVG Validation Acc 70.30 %\n",
      "Epoch:70/200 AVG Training Loss:0.532 AVG Validation Loss:0.625 AVG Training Acc 75.66 % AVG Validation Acc 70.30 %\n",
      "Epoch:80/200 AVG Training Loss:0.529 AVG Validation Loss:0.632 AVG Training Acc 76.00 % AVG Validation Acc 70.16 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.525 AVG Validation Loss:0.633 AVG Training Acc 76.02 % AVG Validation Acc 69.76 %\n",
      "Epoch:100/200 AVG Training Loss:0.527 AVG Validation Loss:0.636 AVG Training Acc 75.90 % AVG Validation Acc 69.62 %\n",
      "Epoch:110/200 AVG Training Loss:0.527 AVG Validation Loss:0.637 AVG Training Acc 75.97 % AVG Validation Acc 70.03 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.525 AVG Validation Loss:0.632 AVG Training Acc 76.24 % AVG Validation Acc 70.03 %\n",
      "Epoch:130/200 AVG Training Loss:0.526 AVG Validation Loss:0.635 AVG Training Acc 76.00 % AVG Validation Acc 70.16 %\n",
      "Epoch:140/200 AVG Training Loss:0.526 AVG Validation Loss:0.635 AVG Training Acc 76.14 % AVG Validation Acc 69.89 %\n",
      "Epoch:150/200 AVG Training Loss:0.527 AVG Validation Loss:0.637 AVG Training Acc 75.76 % AVG Validation Acc 70.16 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.526 AVG Validation Loss:0.637 AVG Training Acc 76.23 % AVG Validation Acc 70.03 %\n",
      "Epoch:170/200 AVG Training Loss:0.524 AVG Validation Loss:0.634 AVG Training Acc 76.29 % AVG Validation Acc 70.30 %\n",
      "Epoch:180/200 AVG Training Loss:0.525 AVG Validation Loss:0.640 AVG Training Acc 76.23 % AVG Validation Acc 69.62 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.524 AVG Validation Loss:0.635 AVG Training Acc 76.02 % AVG Validation Acc 69.76 %\n",
      "Epoch:200/200 AVG Training Loss:0.525 AVG Validation Loss:0.637 AVG Training Acc 76.21 % AVG Validation Acc 69.62 %\n",
      "Split 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "177e92e80bc04fad92e17a25bc378431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.585 AVG Validation Loss:0.581 AVG Training Acc 72.33 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.580 AVG Validation Loss:0.581 AVG Training Acc 72.43 % AVG Validation Acc 72.45 %\n",
      "Epoch:30/200 AVG Training Loss:0.575 AVG Validation Loss:0.586 AVG Training Acc 72.86 % AVG Validation Acc 72.31 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.552 AVG Validation Loss:0.591 AVG Training Acc 74.01 % AVG Validation Acc 72.04 %\n",
      "Epoch:50/200 AVG Training Loss:0.537 AVG Validation Loss:0.604 AVG Training Acc 75.40 % AVG Validation Acc 71.51 %\n",
      "Epoch:60/200 AVG Training Loss:0.518 AVG Validation Loss:0.618 AVG Training Acc 76.48 % AVG Validation Acc 70.83 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.513 AVG Validation Loss:0.621 AVG Training Acc 77.02 % AVG Validation Acc 70.56 %\n",
      "Epoch:80/200 AVG Training Loss:0.508 AVG Validation Loss:0.625 AVG Training Acc 77.39 % AVG Validation Acc 70.56 %\n",
      "Epoch:90/200 AVG Training Loss:0.507 AVG Validation Loss:0.633 AVG Training Acc 76.82 % AVG Validation Acc 70.70 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.504 AVG Validation Loss:0.634 AVG Training Acc 77.35 % AVG Validation Acc 70.70 %\n",
      "Epoch:110/200 AVG Training Loss:0.506 AVG Validation Loss:0.628 AVG Training Acc 77.23 % AVG Validation Acc 70.30 %\n",
      "Epoch:120/200 AVG Training Loss:0.505 AVG Validation Loss:0.640 AVG Training Acc 77.38 % AVG Validation Acc 69.89 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.502 AVG Validation Loss:0.632 AVG Training Acc 77.29 % AVG Validation Acc 70.03 %\n",
      "Epoch:140/200 AVG Training Loss:0.503 AVG Validation Loss:0.635 AVG Training Acc 77.48 % AVG Validation Acc 70.43 %\n",
      "Epoch:150/200 AVG Training Loss:0.504 AVG Validation Loss:0.626 AVG Training Acc 77.36 % AVG Validation Acc 70.43 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.504 AVG Validation Loss:0.628 AVG Training Acc 77.14 % AVG Validation Acc 70.70 %\n",
      "Epoch:170/200 AVG Training Loss:0.505 AVG Validation Loss:0.637 AVG Training Acc 77.39 % AVG Validation Acc 70.56 %\n",
      "Epoch:180/200 AVG Training Loss:0.505 AVG Validation Loss:0.625 AVG Training Acc 77.14 % AVG Validation Acc 70.97 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.505 AVG Validation Loss:0.621 AVG Training Acc 77.18 % AVG Validation Acc 70.56 %\n",
      "Epoch:200/200 AVG Training Loss:0.504 AVG Validation Loss:0.632 AVG Training Acc 77.45 % AVG Validation Acc 70.43 %\n",
      "Split 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "094f2ab7943f4176a08527e6564d8380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.583 AVG Validation Loss:0.588 AVG Training Acc 72.34 % AVG Validation Acc 72.31 %\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.576 AVG Validation Loss:0.595 AVG Training Acc 72.37 % AVG Validation Acc 71.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.574 AVG Validation Loss:0.598 AVG Training Acc 72.88 % AVG Validation Acc 71.24 %\n",
      "Epoch:40/200 AVG Training Loss:0.570 AVG Validation Loss:0.607 AVG Training Acc 73.09 % AVG Validation Acc 71.51 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.565 AVG Validation Loss:0.615 AVG Training Acc 73.25 % AVG Validation Acc 70.97 %\n",
      "Epoch:60/200 AVG Training Loss:0.564 AVG Validation Loss:0.622 AVG Training Acc 73.36 % AVG Validation Acc 70.97 %\n",
      "Epoch:70/200 AVG Training Loss:0.562 AVG Validation Loss:0.625 AVG Training Acc 73.45 % AVG Validation Acc 71.24 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.560 AVG Validation Loss:0.621 AVG Training Acc 73.76 % AVG Validation Acc 71.24 %\n",
      "Epoch:90/200 AVG Training Loss:0.561 AVG Validation Loss:0.621 AVG Training Acc 73.64 % AVG Validation Acc 71.24 %\n",
      "Epoch:100/200 AVG Training Loss:0.562 AVG Validation Loss:0.626 AVG Training Acc 73.55 % AVG Validation Acc 71.10 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.560 AVG Validation Loss:0.624 AVG Training Acc 73.58 % AVG Validation Acc 71.10 %\n",
      "Epoch:120/200 AVG Training Loss:0.560 AVG Validation Loss:0.624 AVG Training Acc 73.73 % AVG Validation Acc 70.97 %\n",
      "Epoch:130/200 AVG Training Loss:0.561 AVG Validation Loss:0.622 AVG Training Acc 73.74 % AVG Validation Acc 71.37 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.560 AVG Validation Loss:0.627 AVG Training Acc 73.71 % AVG Validation Acc 71.10 %\n",
      "Epoch:150/200 AVG Training Loss:0.561 AVG Validation Loss:0.627 AVG Training Acc 73.73 % AVG Validation Acc 71.10 %\n",
      "Epoch:160/200 AVG Training Loss:0.561 AVG Validation Loss:0.623 AVG Training Acc 73.68 % AVG Validation Acc 71.24 %\n",
      "Epoch:170/200 AVG Training Loss:0.561 AVG Validation Loss:0.623 AVG Training Acc 73.68 % AVG Validation Acc 71.10 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.561 AVG Validation Loss:0.625 AVG Training Acc 73.60 % AVG Validation Acc 71.10 %\n",
      "Epoch:190/200 AVG Training Loss:0.562 AVG Validation Loss:0.622 AVG Training Acc 73.55 % AVG Validation Acc 71.24 %\n",
      "Epoch:200/200 AVG Training Loss:0.562 AVG Validation Loss:0.624 AVG Training Acc 73.51 % AVG Validation Acc 71.24 %\n",
      "Split 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "284fa4619a9448f3887f074859cc82fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.585 AVG Validation Loss:0.588 AVG Training Acc 72.28 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.581 AVG Validation Loss:0.581 AVG Training Acc 72.46 % AVG Validation Acc 72.45 %\n",
      "Epoch:30/200 AVG Training Loss:0.577 AVG Validation Loss:0.581 AVG Training Acc 72.73 % AVG Validation Acc 72.85 %\n",
      "Epoch:40/200 AVG Training Loss:0.580 AVG Validation Loss:0.581 AVG Training Acc 72.68 % AVG Validation Acc 72.58 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "New Best Accuracy found: 73.12%\n",
      "Epoch: 47\n",
      "Epoch:50/200 AVG Training Loss:0.555 AVG Validation Loss:0.597 AVG Training Acc 74.16 % AVG Validation Acc 72.31 %\n",
      "Epoch:60/200 AVG Training Loss:0.540 AVG Validation Loss:0.601 AVG Training Acc 75.16 % AVG Validation Acc 72.31 %\n",
      "Epoch:70/200 AVG Training Loss:0.528 AVG Validation Loss:0.618 AVG Training Acc 75.66 % AVG Validation Acc 70.97 %\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.519 AVG Validation Loss:0.631 AVG Training Acc 76.09 % AVG Validation Acc 70.83 %\n",
      "Epoch:90/200 AVG Training Loss:0.518 AVG Validation Loss:0.630 AVG Training Acc 76.61 % AVG Validation Acc 71.10 %\n",
      "Epoch:100/200 AVG Training Loss:0.517 AVG Validation Loss:0.636 AVG Training Acc 76.79 % AVG Validation Acc 70.70 %\n",
      "Epoch   104: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.514 AVG Validation Loss:0.633 AVG Training Acc 76.66 % AVG Validation Acc 70.43 %\n",
      "Epoch:120/200 AVG Training Loss:0.516 AVG Validation Loss:0.639 AVG Training Acc 76.69 % AVG Validation Acc 70.16 %\n",
      "Epoch:130/200 AVG Training Loss:0.513 AVG Validation Loss:0.640 AVG Training Acc 76.88 % AVG Validation Acc 69.89 %\n",
      "Epoch   135: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.515 AVG Validation Loss:0.636 AVG Training Acc 76.76 % AVG Validation Acc 70.03 %\n",
      "Epoch:150/200 AVG Training Loss:0.515 AVG Validation Loss:0.629 AVG Training Acc 76.84 % AVG Validation Acc 70.83 %\n",
      "Epoch:160/200 AVG Training Loss:0.517 AVG Validation Loss:0.634 AVG Training Acc 76.60 % AVG Validation Acc 70.97 %\n",
      "Epoch   166: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.516 AVG Validation Loss:0.638 AVG Training Acc 76.63 % AVG Validation Acc 69.76 %\n",
      "Epoch:180/200 AVG Training Loss:0.514 AVG Validation Loss:0.632 AVG Training Acc 76.72 % AVG Validation Acc 70.83 %\n",
      "Epoch:190/200 AVG Training Loss:0.515 AVG Validation Loss:0.641 AVG Training Acc 76.70 % AVG Validation Acc 70.30 %\n",
      "Epoch   197: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.518 AVG Validation Loss:0.638 AVG Training Acc 76.45 % AVG Validation Acc 70.70 %\n",
      "Split 17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "052c3efc09ff4f02b95991ec026d4585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.585 AVG Validation Loss:0.582 AVG Training Acc 72.36 % AVG Validation Acc 72.41 %\n",
      "Epoch:20/200 AVG Training Loss:0.580 AVG Validation Loss:0.580 AVG Training Acc 72.61 % AVG Validation Acc 72.54 %\n",
      "Epoch:30/200 AVG Training Loss:0.577 AVG Validation Loss:0.582 AVG Training Acc 72.70 % AVG Validation Acc 72.14 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.560 AVG Validation Loss:0.593 AVG Training Acc 73.78 % AVG Validation Acc 70.93 %\n",
      "Epoch:50/200 AVG Training Loss:0.537 AVG Validation Loss:0.622 AVG Training Acc 75.59 % AVG Validation Acc 70.93 %\n",
      "Epoch:60/200 AVG Training Loss:0.524 AVG Validation Loss:0.662 AVG Training Acc 76.24 % AVG Validation Acc 71.06 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.505 AVG Validation Loss:0.680 AVG Training Acc 77.63 % AVG Validation Acc 70.12 %\n",
      "Epoch:80/200 AVG Training Loss:0.502 AVG Validation Loss:0.686 AVG Training Acc 77.77 % AVG Validation Acc 69.31 %\n",
      "Epoch:90/200 AVG Training Loss:0.501 AVG Validation Loss:0.695 AVG Training Acc 77.80 % AVG Validation Acc 69.72 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.497 AVG Validation Loss:0.688 AVG Training Acc 78.25 % AVG Validation Acc 70.39 %\n",
      "Epoch:110/200 AVG Training Loss:0.498 AVG Validation Loss:0.698 AVG Training Acc 78.20 % AVG Validation Acc 69.58 %\n",
      "Epoch:120/200 AVG Training Loss:0.500 AVG Validation Loss:0.701 AVG Training Acc 78.20 % AVG Validation Acc 69.85 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.497 AVG Validation Loss:0.701 AVG Training Acc 77.93 % AVG Validation Acc 69.85 %\n",
      "Epoch:140/200 AVG Training Loss:0.498 AVG Validation Loss:0.695 AVG Training Acc 77.98 % AVG Validation Acc 69.72 %\n",
      "Epoch:150/200 AVG Training Loss:0.498 AVG Validation Loss:0.688 AVG Training Acc 77.93 % AVG Validation Acc 69.72 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.497 AVG Validation Loss:0.701 AVG Training Acc 78.07 % AVG Validation Acc 69.58 %\n",
      "Epoch:170/200 AVG Training Loss:0.496 AVG Validation Loss:0.702 AVG Training Acc 78.22 % AVG Validation Acc 69.72 %\n",
      "Epoch:180/200 AVG Training Loss:0.497 AVG Validation Loss:0.690 AVG Training Acc 77.87 % AVG Validation Acc 69.99 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.496 AVG Validation Loss:0.699 AVG Training Acc 78.41 % AVG Validation Acc 69.85 %\n",
      "Epoch:200/200 AVG Training Loss:0.498 AVG Validation Loss:0.699 AVG Training Acc 78.08 % AVG Validation Acc 69.72 %\n",
      "Split 18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7873860d04ff456eba10c7051108b260",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.583 AVG Validation Loss:0.590 AVG Training Acc 72.31 % AVG Validation Acc 72.27 %\n",
      "Epoch:20/200 AVG Training Loss:0.577 AVG Validation Loss:0.592 AVG Training Acc 72.60 % AVG Validation Acc 72.01 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.565 AVG Validation Loss:0.596 AVG Training Acc 73.46 % AVG Validation Acc 72.01 %\n",
      "Epoch:40/200 AVG Training Loss:0.560 AVG Validation Loss:0.605 AVG Training Acc 73.81 % AVG Validation Acc 72.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.551 AVG Validation Loss:0.615 AVG Training Acc 74.18 % AVG Validation Acc 71.20 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.546 AVG Validation Loss:0.626 AVG Training Acc 74.65 % AVG Validation Acc 70.39 %\n",
      "Epoch:70/200 AVG Training Loss:0.543 AVG Validation Loss:0.630 AVG Training Acc 74.76 % AVG Validation Acc 70.39 %\n",
      "Epoch:80/200 AVG Training Loss:0.541 AVG Validation Loss:0.633 AVG Training Acc 75.06 % AVG Validation Acc 70.12 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.544 AVG Validation Loss:0.634 AVG Training Acc 74.88 % AVG Validation Acc 70.26 %\n",
      "Epoch:100/200 AVG Training Loss:0.540 AVG Validation Loss:0.638 AVG Training Acc 75.14 % AVG Validation Acc 70.26 %\n",
      "Epoch:110/200 AVG Training Loss:0.539 AVG Validation Loss:0.635 AVG Training Acc 75.06 % AVG Validation Acc 70.39 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.539 AVG Validation Loss:0.633 AVG Training Acc 75.08 % AVG Validation Acc 70.26 %\n",
      "Epoch:130/200 AVG Training Loss:0.540 AVG Validation Loss:0.636 AVG Training Acc 75.05 % AVG Validation Acc 70.12 %\n",
      "Epoch:140/200 AVG Training Loss:0.540 AVG Validation Loss:0.635 AVG Training Acc 74.81 % AVG Validation Acc 70.52 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.539 AVG Validation Loss:0.639 AVG Training Acc 75.15 % AVG Validation Acc 70.39 %\n",
      "Epoch:160/200 AVG Training Loss:0.540 AVG Validation Loss:0.640 AVG Training Acc 75.09 % AVG Validation Acc 70.26 %\n",
      "Epoch:170/200 AVG Training Loss:0.540 AVG Validation Loss:0.635 AVG Training Acc 75.02 % AVG Validation Acc 70.39 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.540 AVG Validation Loss:0.635 AVG Training Acc 75.09 % AVG Validation Acc 70.39 %\n",
      "Epoch:190/200 AVG Training Loss:0.540 AVG Validation Loss:0.636 AVG Training Acc 74.90 % AVG Validation Acc 70.39 %\n",
      "Epoch:200/200 AVG Training Loss:0.540 AVG Validation Loss:0.637 AVG Training Acc 74.99 % AVG Validation Acc 70.52 %\n",
      "Split 19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49c900d7e98a4a4fa79c64df91637bf3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.584 AVG Validation Loss:0.582 AVG Training Acc 72.31 % AVG Validation Acc 72.27 %\n",
      "Epoch:20/200 AVG Training Loss:0.599 AVG Validation Loss:0.596 AVG Training Acc 72.12 % AVG Validation Acc 72.27 %\n",
      "Epoch:30/200 AVG Training Loss:0.580 AVG Validation Loss:0.577 AVG Training Acc 72.48 % AVG Validation Acc 72.01 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.567 AVG Validation Loss:0.578 AVG Training Acc 73.18 % AVG Validation Acc 73.35 %\n",
      "New Best Accuracy found: 73.35%\n",
      "Epoch: 40\n",
      "Epoch:50/200 AVG Training Loss:0.555 AVG Validation Loss:0.586 AVG Training Acc 74.36 % AVG Validation Acc 72.54 %\n",
      "Epoch:60/200 AVG Training Loss:0.541 AVG Validation Loss:0.619 AVG Training Acc 75.56 % AVG Validation Acc 71.74 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.530 AVG Validation Loss:0.624 AVG Training Acc 76.14 % AVG Validation Acc 71.74 %\n",
      "Epoch:80/200 AVG Training Loss:0.523 AVG Validation Loss:0.622 AVG Training Acc 76.38 % AVG Validation Acc 72.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.521 AVG Validation Loss:0.629 AVG Training Acc 76.48 % AVG Validation Acc 72.01 %\n",
      "Epoch:100/200 AVG Training Loss:0.520 AVG Validation Loss:0.626 AVG Training Acc 76.89 % AVG Validation Acc 72.14 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.519 AVG Validation Loss:0.634 AVG Training Acc 76.71 % AVG Validation Acc 71.87 %\n",
      "Epoch:120/200 AVG Training Loss:0.521 AVG Validation Loss:0.628 AVG Training Acc 76.50 % AVG Validation Acc 72.27 %\n",
      "Epoch:130/200 AVG Training Loss:0.517 AVG Validation Loss:0.632 AVG Training Acc 76.93 % AVG Validation Acc 72.41 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.517 AVG Validation Loss:0.625 AVG Training Acc 76.90 % AVG Validation Acc 72.27 %\n",
      "Epoch:150/200 AVG Training Loss:0.518 AVG Validation Loss:0.631 AVG Training Acc 76.86 % AVG Validation Acc 72.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.521 AVG Validation Loss:0.631 AVG Training Acc 76.78 % AVG Validation Acc 71.60 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.516 AVG Validation Loss:0.626 AVG Training Acc 76.87 % AVG Validation Acc 72.27 %\n",
      "Epoch:180/200 AVG Training Loss:0.518 AVG Validation Loss:0.633 AVG Training Acc 76.59 % AVG Validation Acc 72.01 %\n",
      "Epoch:190/200 AVG Training Loss:0.520 AVG Validation Loss:0.628 AVG Training Acc 76.86 % AVG Validation Acc 72.14 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.518 AVG Validation Loss:0.631 AVG Training Acc 76.87 % AVG Validation Acc 72.01 %\n",
      "Split 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8e82668434d4f2990a91b4a8ae0d62a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.586 AVG Validation Loss:0.583 AVG Training Acc 72.30 % AVG Validation Acc 72.27 %\n",
      "Epoch:20/200 AVG Training Loss:0.581 AVG Validation Loss:0.579 AVG Training Acc 72.30 % AVG Validation Acc 72.27 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.576 AVG Validation Loss:0.581 AVG Training Acc 72.63 % AVG Validation Acc 72.68 %\n",
      "Epoch:40/200 AVG Training Loss:0.563 AVG Validation Loss:0.591 AVG Training Acc 73.72 % AVG Validation Acc 72.27 %\n",
      "Epoch:50/200 AVG Training Loss:0.552 AVG Validation Loss:0.609 AVG Training Acc 74.38 % AVG Validation Acc 71.06 %\n",
      "Epoch:60/200 AVG Training Loss:0.536 AVG Validation Loss:0.619 AVG Training Acc 75.48 % AVG Validation Acc 71.33 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.526 AVG Validation Loss:0.631 AVG Training Acc 75.92 % AVG Validation Acc 71.06 %\n",
      "Epoch:80/200 AVG Training Loss:0.526 AVG Validation Loss:0.639 AVG Training Acc 75.97 % AVG Validation Acc 70.66 %\n",
      "Epoch:90/200 AVG Training Loss:0.523 AVG Validation Loss:0.646 AVG Training Acc 76.24 % AVG Validation Acc 71.06 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.523 AVG Validation Loss:0.649 AVG Training Acc 76.42 % AVG Validation Acc 70.39 %\n",
      "Epoch:110/200 AVG Training Loss:0.520 AVG Validation Loss:0.642 AVG Training Acc 76.57 % AVG Validation Acc 70.52 %\n",
      "Epoch:120/200 AVG Training Loss:0.521 AVG Validation Loss:0.645 AVG Training Acc 76.23 % AVG Validation Acc 70.39 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.521 AVG Validation Loss:0.640 AVG Training Acc 76.18 % AVG Validation Acc 71.06 %\n",
      "Epoch:140/200 AVG Training Loss:0.520 AVG Validation Loss:0.642 AVG Training Acc 76.27 % AVG Validation Acc 71.06 %\n",
      "Epoch:150/200 AVG Training Loss:0.521 AVG Validation Loss:0.643 AVG Training Acc 76.32 % AVG Validation Acc 70.79 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.520 AVG Validation Loss:0.647 AVG Training Acc 76.63 % AVG Validation Acc 70.79 %\n",
      "Epoch:170/200 AVG Training Loss:0.522 AVG Validation Loss:0.650 AVG Training Acc 76.24 % AVG Validation Acc 70.79 %\n",
      "Epoch:180/200 AVG Training Loss:0.518 AVG Validation Loss:0.648 AVG Training Acc 76.51 % AVG Validation Acc 70.39 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.520 AVG Validation Loss:0.643 AVG Training Acc 76.29 % AVG Validation Acc 71.06 %\n",
      "Epoch:200/200 AVG Training Loss:0.521 AVG Validation Loss:0.645 AVG Training Acc 76.38 % AVG Validation Acc 70.93 %\n",
      "Split 21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed4cdff6b9c44161a7c581e895218765",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.586 AVG Validation Loss:0.584 AVG Training Acc 72.34 % AVG Validation Acc 72.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.582 AVG Validation Loss:0.578 AVG Training Acc 72.43 % AVG Validation Acc 72.58 %\n",
      "Epoch:30/200 AVG Training Loss:0.577 AVG Validation Loss:0.579 AVG Training Acc 72.59 % AVG Validation Acc 72.85 %\n",
      "Epoch:40/200 AVG Training Loss:0.576 AVG Validation Loss:0.585 AVG Training Acc 72.62 % AVG Validation Acc 72.45 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.562 AVG Validation Loss:0.583 AVG Training Acc 73.22 % AVG Validation Acc 72.85 %\n",
      "New Best Accuracy found: 73.39%\n",
      "Epoch: 54\n",
      "Epoch:60/200 AVG Training Loss:0.543 AVG Validation Loss:0.597 AVG Training Acc 74.31 % AVG Validation Acc 72.45 %\n",
      "Epoch:70/200 AVG Training Loss:0.528 AVG Validation Loss:0.609 AVG Training Acc 75.55 % AVG Validation Acc 71.77 %\n",
      "Epoch:80/200 AVG Training Loss:0.518 AVG Validation Loss:0.635 AVG Training Acc 76.32 % AVG Validation Acc 70.83 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.513 AVG Validation Loss:0.635 AVG Training Acc 76.79 % AVG Validation Acc 70.70 %\n",
      "Epoch:100/200 AVG Training Loss:0.512 AVG Validation Loss:0.627 AVG Training Acc 76.81 % AVG Validation Acc 71.64 %\n",
      "Epoch:110/200 AVG Training Loss:0.506 AVG Validation Loss:0.634 AVG Training Acc 77.08 % AVG Validation Acc 70.43 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.506 AVG Validation Loss:0.642 AVG Training Acc 76.94 % AVG Validation Acc 70.70 %\n",
      "Epoch:130/200 AVG Training Loss:0.510 AVG Validation Loss:0.637 AVG Training Acc 76.76 % AVG Validation Acc 70.97 %\n",
      "Epoch:140/200 AVG Training Loss:0.508 AVG Validation Loss:0.639 AVG Training Acc 76.93 % AVG Validation Acc 70.83 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.507 AVG Validation Loss:0.633 AVG Training Acc 77.17 % AVG Validation Acc 70.97 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11452/706929218.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     77\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m                 \u001b[0mtrain_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_correct\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m                 \u001b[0mval_loss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_correct\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauroc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalid_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mval_loader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_11452/4176354458.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[1;34m(model, dataloader, loss_fn, optimizer)\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0mscores\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Conda\\anaconda3\\envs\\deep_torch\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m                     \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Conda\\anaconda3\\envs\\deep_torch\\lib\\site-packages\\torch\\autograd\\grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mF\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Conda\\anaconda3\\envs\\deep_torch\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    105\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'step'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 107\u001b[1;33m             F.adam(params_with_grad,\n\u001b[0m\u001b[0;32m    108\u001b[0m                    \u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m                    \u001b[0mexp_avgs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Conda\\anaconda3\\envs\\deep_torch\\lib\\site-packages\\torch\\optim\\_functional.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, amsgrad, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[0;32m     85\u001b[0m         \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mamsgrad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[1;31m# Maintains the maximum of all 2nd moment running avg. till now\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in tqdm(list(course_programs.keys())[1:]):\n",
    "    \n",
    "    print(i)\n",
    "    threshold_dict = {} #dict to store information in for each threshold\n",
    "    data = deepcopy(course_programs[i])\n",
    "    \n",
    "    data.set_index(['course_encoding', 'userid'], drop = True, inplace = True)\n",
    "    data.fillna(0, inplace = True)\n",
    "    \n",
    "    #set X and Y columns\n",
    "    X = data[data.columns[:25]] #different timesteps\n",
    "    y = data[data.columns[-4:]] #the 4 different putative targets\n",
    "    \n",
    "    for k in tqdm(targets):\n",
    "        print(k)\n",
    "        \n",
    "        #Start with train test split\n",
    "        X_train_val, X_test, y_train_val, y_test, = train_test_split(\n",
    "                                    X,\n",
    "                                   y[k], #replace when going for multi-target \n",
    "                                   test_size = 0.20,\n",
    "                                   random_state = 15,\n",
    "                                   shuffle=True,\n",
    "                                   stratify = y[k] #replace when going for multi-target\n",
    "                                    )\n",
    "        \n",
    "        #create dict to store fold performance\n",
    "        foldperf={}\n",
    "        \n",
    "        #reset \"best accuracy for treshold i and target k\"\n",
    "        best_accuracy = 0\n",
    "\n",
    "        #make train_val split\n",
    "        for fold, (train_idx,val_idx) in tqdm(enumerate(splits.split(X_train_val, y_train_val))):\n",
    "\n",
    "            print('Split {}'.format(fold + 1))\n",
    "            \n",
    "            #make split between train and Val\n",
    "            X_train, y_train = X_train_val.iloc[train_idx], y_train_val.iloc[train_idx]\n",
    "            X_val, y_val = X_train_val.iloc[val_idx], y_train_val.iloc[val_idx]\n",
    "            \n",
    "            #apply scaling after \n",
    "            X_train, X_val = normalize(X_train, X_val, 'Standard')\n",
    "            \n",
    "            #second, convert everything to pytorch tensor - we will convert to tensor dataset and \n",
    "            X_train_tensors = Variable(torch.Tensor(X_train.values))\n",
    "            X_val_tensors = Variable(torch.Tensor(X_val.values))\n",
    "\n",
    "            y_train_tensors = Variable(torch.Tensor(y_train.values))\n",
    "            y_val_tensors = Variable(torch.Tensor(y_val.values)) \n",
    "\n",
    "            #reshaping to rows, timestamps, features \n",
    "            X_train_tensors = torch.reshape(X_train_tensors,   (X_train_tensors.shape[0], X_train_tensors.shape[1], 1))\n",
    "            X_val_tensors = torch.reshape(X_val_tensors,  (X_val_tensors.shape[0], X_val_tensors.shape[1], 1))\n",
    "        \n",
    "            #convert y tensors to format longtensor\n",
    "            y_train_tensors = y_train_tensors.type(torch.cuda.LongTensor)\n",
    "            y_val_tensors = y_val_tensors.type(torch.cuda.LongTensor)\n",
    "            \n",
    "            #create Tensor Datasets and dataloaders for both Train and Val\n",
    "            train_dataset = TensorDataset(X_train_tensors, y_train_tensors)\n",
    "            val_dataset = TensorDataset(X_val_tensors, y_val_tensors)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "            #creates new model for each \n",
    "            model = LSTM_Uni(num_classes, input_size, hidden_size, num_layers, X_train_tensors.shape[1]).to('cuda') #our lstm class\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "            scheduler = ReduceLROnPlateau(optimizer, \n",
    "                                  'min', \n",
    "                                  patience = 10,\n",
    "                                  cooldown = 20,\n",
    "                                 verbose = True)\n",
    "    \n",
    "            history = {'train_loss': [], 'val_loss': [],'train_acc':[],'val_acc':[], 'precision': [],\n",
    "                      'recall' : [], 'auroc': []}\n",
    "\n",
    "            for epoch in tqdm(range(num_epochs)):\n",
    "                train_loss, train_correct=train_epoch(model,train_loader,criterion,optimizer)\n",
    "                val_loss, val_correct, precision, recall, auroc = valid_epoch(model,val_loader,criterion)\n",
    "\n",
    "                train_loss = train_loss / len(train_loader.sampler)\n",
    "                train_acc = train_correct / len(train_loader.sampler) * 100\n",
    "                val_loss = val_loss / len(val_loader.sampler)\n",
    "                val_acc = val_correct / len(val_loader.sampler) * 100\n",
    "        \n",
    "        \n",
    "                if (epoch+1) % 10 == 0: \n",
    "                    print(\"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Validation Loss:{:.3f} AVG Training Acc {:.2f} % AVG Validation Acc {:.2f} %\".format(epoch + 1,\n",
    "                                                                                                             num_epochs,\n",
    "                                                                                                             train_loss,\n",
    "                                                                                                             val_loss,\n",
    "                                                                                                             train_acc,\n",
    "                                                                                                             val_acc))\n",
    "                history['train_loss'].append(train_loss)\n",
    "                history['val_loss'].append(val_loss)\n",
    "                history['train_acc'].append(train_acc)\n",
    "                history['val_acc'].append(val_acc)\n",
    "                history['precision'].append(precision)\n",
    "                history['recall'].append(recall)\n",
    "                history['auroc'].append(auroc)\n",
    "                scheduler.step(val_loss)\n",
    "    \n",
    "                if val_acc > best_accuracy:\n",
    "            \n",
    "                #replace best accuracy and save best model\n",
    "                    print(f'New Best Accuracy found: {val_acc:.2f}%\\nEpoch: {epoch + 1}')\n",
    "                    best_accuracy = val_acc\n",
    "                    best = deepcopy(model)\n",
    "                    curr_epoch = epoch + 1\n",
    "                    \n",
    "            #store fold performance\n",
    "            foldperf['fold{}'.format(fold+1)] = history\n",
    "        \n",
    "        #saves fold performance for target \n",
    "        threshold_dict[k] = pd.DataFrame.from_dict(foldperf, orient='index') # convert dict to dataframe\n",
    "        \n",
    "        #explode to get eacxh epoch as a row\n",
    "        threshold_dict[k] = threshold_dict[k].explode(list(threshold_dict[k].columns))\n",
    "        torch.save(best,f\"../Models/{i}/Nova_IMS_best_{k}_{curr_epoch}_epochs.h\")\n",
    "        \n",
    "    # from pandas.io.parsers import ExcelWriter\n",
    "    with pd.ExcelWriter(f\"../Data/Modeling Stage/Results/IMS/Clicks per % duration/25_splits_{i}_{replicas}_replicas.xlsx\") as writer:  \n",
    "        for sheet in targets:\n",
    "                threshold_dict[sheet].to_excel(writer, sheet_name=str(sheet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9702df3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
