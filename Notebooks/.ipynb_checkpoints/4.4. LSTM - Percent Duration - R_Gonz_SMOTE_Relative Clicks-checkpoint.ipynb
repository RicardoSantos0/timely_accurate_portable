{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84eda90e",
   "metadata": {},
   "source": [
    "### Thesis notebook 4.4. - R_Gonz\n",
    "\n",
    "#### LSTM - Temporal data representation\n",
    "\n",
    "In this notebook, we will finally start our application of temporal representation using LSTMs and bi-directional LSTMs.\n",
    "The argument for the usage of Deep Learning stems from the fact that sequences themselves encode information that can be extracted using Recurrent Neural Networks and, more specifically, Long Short Term Memory Units.\n",
    "\n",
    "#### First Step: Setup a PyTorch environment that enables the use of GPU for training. \n",
    "\n",
    "The following cell wll confirm that the GPU will be the default device to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f27844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pycuda.driver as cuda\n",
    "\n",
    "cuda.init()\n",
    "## Get Id of default device\n",
    "torch.cuda.current_device()\n",
    "# 0\n",
    "cuda.Device(0).name() # '0' is the id of your GPU\n",
    "\n",
    "#set all tensors to gpu\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d95429e",
   "metadata": {},
   "source": [
    "#### Second Step: Import the relevant packages and declare global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6c2d97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary modules/libraries\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "#tqdm to monitor progress\n",
    "from tqdm.notebook import tqdm, trange\n",
    "tqdm.pandas(desc=\"Progress\")\n",
    "\n",
    "#time related features\n",
    "from datetime import timedelta\n",
    "from copy import copy, deepcopy\n",
    "\n",
    "#vizualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#imblearn, scalers, kfold and metrics\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, QuantileTransformer,PowerTransformer\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold, RepeatedStratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, recall_score, classification_report, average_precision_score, precision_recall_curve\n",
    "\n",
    "#import torch related\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable \n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "\n",
    "#and optimizer of learning rate\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "#import pytorch modules\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6c3f1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variables that may come in handy\n",
    "#course threshold sets the % duration that will be considered (1 = 100%)\n",
    "duration_threshold = [0.1, 0.25, 0.33, 0.5, 1]\n",
    "\n",
    "#colors for vizualizations\n",
    "nova_ims_colors = ['#BFD72F', '#5C666C']\n",
    "\n",
    "#standard color for student aggregates\n",
    "student_color = '#474838'\n",
    "\n",
    "#standard color for course aggragates\n",
    "course_color = '#1B3D2F'\n",
    "\n",
    "#standard continuous colormap\n",
    "standard_cmap = 'viridis_r'\n",
    "\n",
    "#Function designed to deal with multiindex and flatten it\n",
    "def flattenHierarchicalCol(col,sep = '_'):\n",
    "    '''converts multiindex columns into single index columns while retaining the hierarchical components'''\n",
    "    if not type(col) is tuple:\n",
    "        return col\n",
    "    else:\n",
    "        new_col = ''\n",
    "        for leveli,level in enumerate(col):\n",
    "            if not level == '':\n",
    "                if not leveli == 0:\n",
    "                    new_col += sep\n",
    "                new_col += level\n",
    "        return new_col\n",
    "    \n",
    "#number of replicas - number of repeats of stratified k fold - in this case 10\n",
    "replicas = 30\n",
    "\n",
    "#names to display on result figures\n",
    "date_names = {\n",
    "             'Date_threshold_10': '10% of Course Duration',   \n",
    "             'Date_threshold_25': '25% of Course Duration', \n",
    "             'Date_threshold_33': '33% of Course Duration', \n",
    "             'Date_threshold_50': '50% of Course Duration', \n",
    "             'Date_threshold_100':'100% of Course Duration', \n",
    "            }\n",
    "\n",
    "target_names = {\n",
    "                'exam_fail' : 'At risk - Exam Grade',\n",
    "                'final_fail' : 'At risk - Final Grade', \n",
    "                'exam_gifted' : 'High performer - Exam Grade', \n",
    "                'final_gifted': 'High performer - Final Grade'\n",
    "                }\n",
    "\n",
    "#targets\n",
    "targets = ['final_fail' ,'final_gifted']\n",
    "temporal_columns = ['0 to 4%', '4 to 8%', '8 to 12%', '12 to 16%', '16 to 20%', '20 to 24%',\n",
    "       '24 to 28%', '28 to 32%', '32 to 36%', '36 to 40%', '40 to 44%',\n",
    "       '44 to 48%', '48 to 52%', '52 to 56%', '56 to 60%', '60 to 64%',\n",
    "       '64 to 68%', '68 to 72%', '72 to 76%', '76 to 80%', '80 to 84%',\n",
    "       '84 to 88%', '88 to 92%', '92 to 96%', '96 to 100%']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c5ddb6",
   "metadata": {},
   "source": [
    "#### Step 3: Import data and take a preliminary look at it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8a23ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports dataframes\n",
    "course_programs = pd.read_excel(\"../Data/Modeling Stage/R_Gonz_Temporal_Datasets_25_splits.xlsx\", \n",
    "                                dtype = {\n",
    "                                    'course_encoding' : int,\n",
    "                                    'userid' : int},\n",
    "                               sheet_name = None)\n",
    "\n",
    "#save tables \n",
    "student_list = pd.read_csv('../Data/Modeling Stage/R_Gonz_Filtered_targets.csv', \n",
    "                         dtype = {\n",
    "                                   'course_encoding': int,\n",
    "                                   'userid' : int,\n",
    "                                   })\n",
    "\n",
    "#drop unnamed 0 column\n",
    "for i in course_programs:\n",
    "        \n",
    "    #merge with the targets we calculated on the other \n",
    "    course_programs[i] = course_programs[i].merge(student_list, on = ['course', 'userid'], how = 'inner')\n",
    "    course_programs[i].drop(['Unnamed: 0', 'final_mark'], axis = 1, inplace = True)\n",
    "    \n",
    "    #convert results to object\n",
    "    course_programs[i]['course'], course_programs[i]['userid'] = course_programs[i]['course'].astype(object), course_programs[i]['userid'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bc3c84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13857 entries, 0 to 13856\n",
      "Data columns (total 29 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   course        13857 non-null  object\n",
      " 1   userid        13857 non-null  object\n",
      " 2   1             13857 non-null  int64 \n",
      " 3   2             13857 non-null  int64 \n",
      " 4   3             13857 non-null  int64 \n",
      " 5   4             13857 non-null  int64 \n",
      " 6   5             13857 non-null  int64 \n",
      " 7   6             13857 non-null  int64 \n",
      " 8   7             13857 non-null  int64 \n",
      " 9   8             13857 non-null  int64 \n",
      " 10  9             13857 non-null  int64 \n",
      " 11  10            13857 non-null  int64 \n",
      " 12  11            13857 non-null  int64 \n",
      " 13  12            13857 non-null  int64 \n",
      " 14  13            13857 non-null  int64 \n",
      " 15  14            13857 non-null  int64 \n",
      " 16  15            13857 non-null  int64 \n",
      " 17  16            13857 non-null  int64 \n",
      " 18  17            13857 non-null  int64 \n",
      " 19  18            13857 non-null  int64 \n",
      " 20  19            13857 non-null  int64 \n",
      " 21  20            13857 non-null  int64 \n",
      " 22  21            13857 non-null  int64 \n",
      " 23  22            13857 non-null  int64 \n",
      " 24  23            13857 non-null  int64 \n",
      " 25  24            13857 non-null  int64 \n",
      " 26  25            13857 non-null  int64 \n",
      " 27  final_fail    13857 non-null  int64 \n",
      " 28  final_gifted  13857 non-null  int64 \n",
      "dtypes: int64(27), object(2)\n",
      "memory usage: 3.2+ MB\n"
     ]
    }
   ],
   "source": [
    "course_programs['Date_threshold_100'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4a751ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course</th>\n",
       "      <th>userid</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>final_fail</th>\n",
       "      <th>final_gifted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13857.0</td>\n",
       "      <td>13857.0</td>\n",
       "      <td>13857.000000</td>\n",
       "      <td>13857.000000</td>\n",
       "      <td>13857.000000</td>\n",
       "      <td>13857.000000</td>\n",
       "      <td>13857.000000</td>\n",
       "      <td>13857.000000</td>\n",
       "      <td>13857.000000</td>\n",
       "      <td>13857.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>13857.000000</td>\n",
       "      <td>13857.000000</td>\n",
       "      <td>13857.000000</td>\n",
       "      <td>13857.000000</td>\n",
       "      <td>13857.000000</td>\n",
       "      <td>13857.000000</td>\n",
       "      <td>13857.000000</td>\n",
       "      <td>13857.000000</td>\n",
       "      <td>13857.000000</td>\n",
       "      <td>13857.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>174.0</td>\n",
       "      <td>8544.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2059.0</td>\n",
       "      <td>68888.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>507.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.601140</td>\n",
       "      <td>4.616584</td>\n",
       "      <td>7.876092</td>\n",
       "      <td>8.510067</td>\n",
       "      <td>9.804792</td>\n",
       "      <td>10.839431</td>\n",
       "      <td>11.184167</td>\n",
       "      <td>12.273147</td>\n",
       "      <td>...</td>\n",
       "      <td>11.521036</td>\n",
       "      <td>11.677997</td>\n",
       "      <td>8.524067</td>\n",
       "      <td>10.015155</td>\n",
       "      <td>8.560583</td>\n",
       "      <td>7.720935</td>\n",
       "      <td>3.454355</td>\n",
       "      <td>0.082413</td>\n",
       "      <td>0.381035</td>\n",
       "      <td>0.198528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.581259</td>\n",
       "      <td>12.238187</td>\n",
       "      <td>15.785656</td>\n",
       "      <td>14.600375</td>\n",
       "      <td>16.021089</td>\n",
       "      <td>16.473371</td>\n",
       "      <td>20.043011</td>\n",
       "      <td>20.126765</td>\n",
       "      <td>...</td>\n",
       "      <td>22.043869</td>\n",
       "      <td>27.925613</td>\n",
       "      <td>18.816024</td>\n",
       "      <td>29.534244</td>\n",
       "      <td>20.248598</td>\n",
       "      <td>20.105366</td>\n",
       "      <td>14.589819</td>\n",
       "      <td>1.264520</td>\n",
       "      <td>0.485659</td>\n",
       "      <td>0.398906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>880.000000</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>557.000000</td>\n",
       "      <td>729.000000</td>\n",
       "      <td>678.000000</td>\n",
       "      <td>1316.000000</td>\n",
       "      <td>407.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>523.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows Ã— 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         course   userid             1             2             3  \\\n",
       "count   13857.0  13857.0  13857.000000  13857.000000  13857.000000   \n",
       "unique    174.0   8544.0           NaN           NaN           NaN   \n",
       "top      2059.0  68888.0           NaN           NaN           NaN   \n",
       "freq      507.0      7.0           NaN           NaN           NaN   \n",
       "mean        NaN      NaN      1.601140      4.616584      7.876092   \n",
       "std         NaN      NaN      6.581259     12.238187     15.785656   \n",
       "min         NaN      NaN      0.000000      0.000000      0.000000   \n",
       "25%         NaN      NaN      0.000000      0.000000      0.000000   \n",
       "50%         NaN      NaN      0.000000      0.000000      1.000000   \n",
       "75%         NaN      NaN      0.000000      4.000000     10.000000   \n",
       "max         NaN      NaN    178.000000    236.000000    292.000000   \n",
       "\n",
       "                   4             5             6             7             8  \\\n",
       "count   13857.000000  13857.000000  13857.000000  13857.000000  13857.000000   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean        8.510067      9.804792     10.839431     11.184167     12.273147   \n",
       "std        14.600375     16.021089     16.473371     20.043011     20.126765   \n",
       "min         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%         3.000000      4.000000      4.000000      5.000000      5.000000   \n",
       "75%        11.000000     13.000000     15.000000     15.000000     17.000000   \n",
       "max       239.000000    255.000000    219.000000    880.000000    602.000000   \n",
       "\n",
       "        ...            18            19            20            21  \\\n",
       "count   ...  13857.000000  13857.000000  13857.000000  13857.000000   \n",
       "unique  ...           NaN           NaN           NaN           NaN   \n",
       "top     ...           NaN           NaN           NaN           NaN   \n",
       "freq    ...           NaN           NaN           NaN           NaN   \n",
       "mean    ...     11.521036     11.677997      8.524067     10.015155   \n",
       "std     ...     22.043869     27.925613     18.816024     29.534244   \n",
       "min     ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%     ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%     ...      4.000000      3.000000      1.000000      1.000000   \n",
       "75%     ...     15.000000     13.000000     10.000000     11.000000   \n",
       "max     ...    557.000000    729.000000    678.000000   1316.000000   \n",
       "\n",
       "                  22            23            24            25    final_fail  \\\n",
       "count   13857.000000  13857.000000  13857.000000  13857.000000  13857.000000   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean        8.560583      7.720935      3.454355      0.082413      0.381035   \n",
       "std        20.248598     20.105366     14.589819      1.264520      0.485659   \n",
       "min         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%         1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%         9.000000      7.000000      1.000000      0.000000      1.000000   \n",
       "max       407.000000    422.000000    523.000000     74.000000      1.000000   \n",
       "\n",
       "        final_gifted  \n",
       "count   13857.000000  \n",
       "unique           NaN  \n",
       "top              NaN  \n",
       "freq             NaN  \n",
       "mean        0.198528  \n",
       "std         0.398906  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[11 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "course_programs['Date_threshold_100'].describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3291817",
   "metadata": {},
   "source": [
    "In our second attempt, we are looking to obtain a different result. Instead of using the absolute number of clicks used in each instance, we are instead looking to use the percent number of clicks made by each student relative to the the total number of clicks performed in the curricular unit.\n",
    "\n",
    "For that we will use transform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1ca4caab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7fdbabf7ce04ded97d01b19a5831244",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77b2a2d37fdb42dfabdf1cb8a4763d49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6de50013db1f467a883917343bc30324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "966e3e4920e548fc92568814bbd30480",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7d299d08f23406289b91ab2dfd3617e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe38cb45293c4c08aa874530cf46cf1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm(course_programs.keys()):\n",
    "    \n",
    "    for j in tqdm(range(1,25)):\n",
    "            course_programs[i][j] = np.where(course_programs[i].fillna(0).groupby('course')[j].transform('sum') != 0, #where valid operations occur\n",
    "                                             course_programs[i][j].fillna(0) / course_programs[i].fillna(0).groupby('course')[j].transform('sum') * 100, #calculate percentage\n",
    "                                             0) #otherwise, its 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be722ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(train, test, scaler):\n",
    "    \n",
    "    if scaler == 'MinMax':\n",
    "        pt = MinMaxScaler()\n",
    "    elif scaler == 'Standard':\n",
    "        pt = StandardScaler()\n",
    "    elif scaler == 'Robust':\n",
    "        pt = RobustScaler()\n",
    "    elif scaler == 'Quantile':\n",
    "        pt = QuantileTransformer()\n",
    "    else:\n",
    "        pt = PowerTransformer(method='yeo-johnson')\n",
    "    \n",
    "    data_train = pt.fit_transform(train)\n",
    "    data_test = pt.transform(test)\n",
    "    # convert the array back to a dataframe\n",
    "    normalized_train = pd.DataFrame(data_train,columns=train.columns)\n",
    "    normalized_test = pd.DataFrame(data_test,columns=test.columns)\n",
    "        \n",
    "    return normalized_train, normalized_test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4d5475",
   "metadata": {},
   "source": [
    "#### Implementing Cross-Validation with Deep Learning Model\n",
    "\n",
    "**1. Create the Deep Learning Model**\n",
    "\n",
    "In this instance, we will follow-up with on the approach used in Chen & Cui - CrossEntropyLoss with applied over a softmax layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a16bd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Uni(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(LSTM_Uni, self).__init__()\n",
    "        self.num_classes = num_classes #number of classes\n",
    "        self.num_layers = num_layers #number of layers\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size = hidden_size #hidden state\n",
    "        self.seq_length = seq_length #sequence length\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first = True) #lstm\n",
    "        \n",
    "        self.dropout = nn.Dropout(p = 0.5)\n",
    "    \n",
    "        self.fc = nn.Linear(self.hidden_size, num_classes) #fully connected last layer\n",
    "\n",
    "    def forward(self,x):\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) #hidden state\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) #internal state\n",
    "        \n",
    "        #Xavier_init for both H_0 and C_0\n",
    "        torch.nn.init.xavier_normal_(h_0)\n",
    "        torch.nn.init.xavier_normal_(c_0)\n",
    "        \n",
    "        # Propagate input through LSTM\n",
    "        lstm_out, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
    "        last_output = hn.view(-1, self.hidden_size) #reshaping the data for Dense layer next\n",
    "        \n",
    "        #we are interested in only keeping the last output\n",
    "        drop_out = self.dropout(last_output)\n",
    "        pre_softmax = self.fc(drop_out) #Final Output - dense\n",
    "        return pre_softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c356bd",
   "metadata": {},
   "source": [
    "**2. Define the train and validation Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25b29a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model,dataloader,loss_fn,optimizer):\n",
    "    \n",
    "    train_loss,train_correct=0.0,0 \n",
    "    model.train()\n",
    "    for X, labels in dataloader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)\n",
    "        loss = loss_fn(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * X.size(0)\n",
    "        scores, predictions = torch.max(F.log_softmax(output.data), 1)\n",
    "        train_correct += (predictions == labels).sum().item()\n",
    "        \n",
    "    return train_loss,train_correct\n",
    "  \n",
    "def valid_epoch(model,dataloader,loss_fn):\n",
    "    valid_loss, val_correct = 0.0, 0\n",
    "    targets = []\n",
    "    y_pred = []\n",
    "    probability_1 = []\n",
    "    \n",
    "    model.eval()\n",
    "    for X, labels in dataloader:\n",
    "\n",
    "        output = model(X)\n",
    "        loss=loss_fn(output,labels)\n",
    "        valid_loss+=loss.item()*X.size(0)\n",
    "        probability_1.append(F.softmax(output.data)[:,1])\n",
    "        predictions = torch.argmax(output, dim=1)\n",
    "        val_correct+=(predictions == labels).sum().item()\n",
    "        targets.append(labels)\n",
    "        y_pred.append(predictions)\n",
    "    \n",
    "    #concat all results\n",
    "    targets = torch.cat(targets).data.cpu().numpy()\n",
    "    y_pred = torch.cat(y_pred).data.cpu().numpy()\n",
    "    probability_1 = torch.cat(probability_1).data.cpu().numpy()\n",
    "    \n",
    "    #calculate precision, recall and AUC score\n",
    "    \n",
    "    precision = precision_score(targets, y_pred)\n",
    "    recall = recall_score(targets, y_pred)\n",
    "    auroc = roc_auc_score(targets, probability_1)\n",
    "    \n",
    "    #return all\n",
    "    return valid_loss,val_correct, precision, recall, auroc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4543fb3",
   "metadata": {},
   "source": [
    "**3. Define main hyperparameters of the model, including splits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcbbef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "num_epochs = 200 #50 epochs\n",
    "learning_rate = 0.01 #0.001 lr\n",
    "input_size = 1 #number of features\n",
    "hidden_size = 40 #number of features in hidden state\n",
    "num_layers = 1 #number of stacked lstm layers\n",
    "\n",
    "#Shape of Output as required for SoftMax Classifier\n",
    "num_classes = 2 #output shape\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "k=10\n",
    "splits= RepeatedStratifiedKFold(n_splits=k, n_repeats=replicas, random_state=15) #kfold of 10 with 30 replicas\n",
    "criterion = nn.CrossEntropyLoss()    # cross-entropy for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20713d9",
   "metadata": {},
   "source": [
    "**4. Make the splits and Start Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e831a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "875c69a297a44e69adfdf3867b32f0d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date_threshold_33\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01d1f5b2dfc0419dab1b856a8b7f3054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_fail\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf689c5a9e194152991df30dd5feee39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b6f39d3d7044a6b922a49c526839f7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best Accuracy found: 38.05%\n",
      "Epoch: 1\n",
      "Epoch:10/200 AVG Training Loss:0.649 AVG Validation Loss:5.676 AVG Training Acc 64.84 % AVG Validation Acc 38.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.616 AVG Validation Loss:3.937 AVG Training Acc 64.84 % AVG Validation Acc 38.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.711 AVG Validation Loss:2.466 AVG Training Acc 64.12 % AVG Validation Acc 38.05 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "New Best Accuracy found: 38.23%\n",
      "Epoch: 37\n",
      "New Best Accuracy found: 38.77%\n",
      "Epoch: 38\n",
      "New Best Accuracy found: 38.86%\n",
      "Epoch: 39\n",
      "Epoch:40/200 AVG Training Loss:0.696 AVG Validation Loss:0.718 AVG Training Acc 49.97 % AVG Validation Acc 39.04 %\n",
      "New Best Accuracy found: 39.04%\n",
      "Epoch: 40\n",
      "New Best Accuracy found: 39.13%\n",
      "Epoch: 43\n",
      "New Best Accuracy found: 40.04%\n",
      "Epoch: 44\n",
      "New Best Accuracy found: 40.22%\n",
      "Epoch: 46\n",
      "New Best Accuracy found: 40.40%\n",
      "Epoch: 47\n",
      "New Best Accuracy found: 40.67%\n",
      "Epoch: 48\n",
      "New Best Accuracy found: 41.30%\n",
      "Epoch: 49\n",
      "Epoch:50/200 AVG Training Loss:0.692 AVG Validation Loss:0.719 AVG Training Acc 52.14 % AVG Validation Acc 41.57 %\n",
      "New Best Accuracy found: 41.57%\n",
      "Epoch: 50\n",
      "New Best Accuracy found: 42.47%\n",
      "Epoch: 51\n",
      "New Best Accuracy found: 42.83%\n",
      "Epoch: 54\n",
      "New Best Accuracy found: 43.01%\n",
      "Epoch: 55\n",
      "New Best Accuracy found: 44.00%\n",
      "Epoch: 56\n",
      "New Best Accuracy found: 44.45%\n",
      "Epoch: 57\n",
      "New Best Accuracy found: 44.54%\n",
      "Epoch: 58\n",
      "New Best Accuracy found: 45.09%\n",
      "Epoch: 59\n",
      "Epoch:60/200 AVG Training Loss:0.689 AVG Validation Loss:0.718 AVG Training Acc 53.31 % AVG Validation Acc 44.72 %\n",
      "New Best Accuracy found: 45.18%\n",
      "Epoch: 63\n",
      "New Best Accuracy found: 45.54%\n",
      "Epoch: 65\n",
      "New Best Accuracy found: 45.63%\n",
      "Epoch: 66\n",
      "New Best Accuracy found: 46.08%\n",
      "Epoch: 67\n",
      "Epoch:70/200 AVG Training Loss:0.687 AVG Validation Loss:0.718 AVG Training Acc 53.90 % AVG Validation Acc 45.00 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.686 AVG Validation Loss:0.710 AVG Training Acc 54.55 % AVG Validation Acc 46.98 %\n",
      "New Best Accuracy found: 46.98%\n",
      "Epoch: 80\n",
      "New Best Accuracy found: 47.16%\n",
      "Epoch: 82\n",
      "New Best Accuracy found: 47.43%\n",
      "Epoch: 84\n",
      "Epoch:90/200 AVG Training Loss:0.684 AVG Validation Loss:0.699 AVG Training Acc 55.25 % AVG Validation Acc 47.61 %\n",
      "New Best Accuracy found: 47.61%\n",
      "Epoch: 90\n",
      "New Best Accuracy found: 47.97%\n",
      "Epoch: 93\n",
      "New Best Accuracy found: 48.24%\n",
      "Epoch: 97\n",
      "Epoch:100/200 AVG Training Loss:0.681 AVG Validation Loss:0.697 AVG Training Acc 55.37 % AVG Validation Acc 48.24 %\n",
      "New Best Accuracy found: 48.33%\n",
      "Epoch: 101\n",
      "New Best Accuracy found: 48.42%\n",
      "Epoch: 105\n",
      "New Best Accuracy found: 48.51%\n",
      "Epoch: 106\n",
      "Epoch:110/200 AVG Training Loss:0.681 AVG Validation Loss:0.696 AVG Training Acc 55.26 % AVG Validation Acc 48.24 %\n",
      "Epoch:120/200 AVG Training Loss:0.681 AVG Validation Loss:0.696 AVG Training Acc 55.86 % AVG Validation Acc 48.42 %\n",
      "Epoch:130/200 AVG Training Loss:0.681 AVG Validation Loss:0.696 AVG Training Acc 55.73 % AVG Validation Acc 48.15 %\n",
      "Epoch:140/200 AVG Training Loss:0.680 AVG Validation Loss:0.696 AVG Training Acc 55.20 % AVG Validation Acc 48.24 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.680 AVG Validation Loss:0.696 AVG Training Acc 55.44 % AVG Validation Acc 48.15 %\n",
      "Epoch:160/200 AVG Training Loss:0.679 AVG Validation Loss:0.696 AVG Training Acc 55.77 % AVG Validation Acc 48.33 %\n",
      "New Best Accuracy found: 48.60%\n",
      "Epoch: 161\n",
      "Epoch:170/200 AVG Training Loss:0.679 AVG Validation Loss:0.695 AVG Training Acc 55.64 % AVG Validation Acc 48.60 %\n",
      "New Best Accuracy found: 48.69%\n",
      "Epoch: 177\n",
      "Epoch:180/200 AVG Training Loss:0.679 AVG Validation Loss:0.695 AVG Training Acc 55.84 % AVG Validation Acc 48.42 %\n",
      "Epoch:190/200 AVG Training Loss:0.679 AVG Validation Loss:0.695 AVG Training Acc 55.82 % AVG Validation Acc 48.60 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:200/200 AVG Training Loss:0.679 AVG Validation Loss:0.695 AVG Training Acc 55.68 % AVG Validation Acc 48.60 %\n",
      "Split 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c92ceebb2da466c8a6901d0b6d6a81e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.673 AVG Validation Loss:1.706 AVG Training Acc 63.04 % AVG Validation Acc 38.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.675 AVG Validation Loss:1.257 AVG Training Acc 60.58 % AVG Validation Acc 38.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.702 AVG Validation Loss:3.378 AVG Training Acc 62.56 % AVG Validation Acc 38.14 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.691 AVG Validation Loss:0.716 AVG Training Acc 53.01 % AVG Validation Acc 42.83 %\n",
      "Epoch:50/200 AVG Training Loss:0.689 AVG Validation Loss:0.718 AVG Training Acc 52.99 % AVG Validation Acc 43.82 %\n",
      "Epoch:60/200 AVG Training Loss:0.689 AVG Validation Loss:0.717 AVG Training Acc 53.77 % AVG Validation Acc 43.73 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.686 AVG Validation Loss:0.700 AVG Training Acc 54.88 % AVG Validation Acc 48.78 %\n",
      "New Best Accuracy found: 48.78%\n",
      "Epoch: 70\n",
      "New Best Accuracy found: 49.32%\n",
      "Epoch: 73\n",
      "New Best Accuracy found: 49.41%\n",
      "Epoch: 74\n",
      "New Best Accuracy found: 49.68%\n",
      "Epoch: 75\n",
      "New Best Accuracy found: 50.05%\n",
      "Epoch: 76\n",
      "New Best Accuracy found: 50.41%\n",
      "Epoch: 79\n",
      "Epoch:80/200 AVG Training Loss:0.683 AVG Validation Loss:0.692 AVG Training Acc 55.35 % AVG Validation Acc 50.41 %\n",
      "New Best Accuracy found: 50.50%\n",
      "Epoch: 82\n",
      "New Best Accuracy found: 50.59%\n",
      "Epoch: 84\n",
      "New Best Accuracy found: 50.68%\n",
      "Epoch: 85\n",
      "Epoch:90/200 AVG Training Loss:0.683 AVG Validation Loss:0.691 AVG Training Acc 55.22 % AVG Validation Acc 50.59 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.682 AVG Validation Loss:0.691 AVG Training Acc 55.51 % AVG Validation Acc 50.68 %\n",
      "Epoch:110/200 AVG Training Loss:0.681 AVG Validation Loss:0.690 AVG Training Acc 55.75 % AVG Validation Acc 50.68 %\n",
      "New Best Accuracy found: 50.77%\n",
      "Epoch: 111\n",
      "Epoch:120/200 AVG Training Loss:0.681 AVG Validation Loss:0.690 AVG Training Acc 55.77 % AVG Validation Acc 50.86 %\n",
      "New Best Accuracy found: 50.86%\n",
      "Epoch: 120\n",
      "Epoch:130/200 AVG Training Loss:0.682 AVG Validation Loss:0.690 AVG Training Acc 55.60 % AVG Validation Acc 50.77 %\n",
      "Epoch:140/200 AVG Training Loss:0.682 AVG Validation Loss:0.690 AVG Training Acc 55.64 % AVG Validation Acc 50.86 %\n",
      "Epoch:150/200 AVG Training Loss:0.682 AVG Validation Loss:0.690 AVG Training Acc 55.55 % AVG Validation Acc 50.77 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-06.\n",
      "New Best Accuracy found: 50.95%\n",
      "Epoch: 153\n",
      "Epoch:160/200 AVG Training Loss:0.681 AVG Validation Loss:0.690 AVG Training Acc 55.92 % AVG Validation Acc 50.86 %\n",
      "Epoch:170/200 AVG Training Loss:0.682 AVG Validation Loss:0.690 AVG Training Acc 55.60 % AVG Validation Acc 50.86 %\n",
      "Epoch:180/200 AVG Training Loss:0.683 AVG Validation Loss:0.690 AVG Training Acc 55.75 % AVG Validation Acc 50.77 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.682 AVG Validation Loss:0.690 AVG Training Acc 55.58 % AVG Validation Acc 50.77 %\n",
      "Epoch:200/200 AVG Training Loss:0.682 AVG Validation Loss:0.690 AVG Training Acc 55.70 % AVG Validation Acc 50.77 %\n",
      "Split 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a82035646504e199da06ddefb8ac57b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:2.954 AVG Training Acc 64.96 % AVG Validation Acc 38.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.687 AVG Validation Loss:4.764 AVG Training Acc 64.91 % AVG Validation Acc 38.14 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.701 AVG Validation Loss:0.767 AVG Training Acc 51.47 % AVG Validation Acc 38.41 %\n",
      "Epoch:40/200 AVG Training Loss:0.694 AVG Validation Loss:0.745 AVG Training Acc 52.23 % AVG Validation Acc 38.86 %\n",
      "Epoch:50/200 AVG Training Loss:0.693 AVG Validation Loss:0.735 AVG Training Acc 52.49 % AVG Validation Acc 39.13 %\n",
      "Epoch:60/200 AVG Training Loss:0.692 AVG Validation Loss:0.727 AVG Training Acc 52.79 % AVG Validation Acc 42.02 %\n",
      "Epoch:70/200 AVG Training Loss:0.691 AVG Validation Loss:0.723 AVG Training Acc 52.79 % AVG Validation Acc 43.55 %\n",
      "Epoch:80/200 AVG Training Loss:0.689 AVG Validation Loss:0.720 AVG Training Acc 53.56 % AVG Validation Acc 45.09 %\n",
      "Epoch:90/200 AVG Training Loss:0.686 AVG Validation Loss:0.720 AVG Training Acc 54.17 % AVG Validation Acc 45.36 %\n",
      "Epoch:100/200 AVG Training Loss:0.685 AVG Validation Loss:0.719 AVG Training Acc 54.57 % AVG Validation Acc 45.09 %\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:110/200 AVG Training Loss:0.683 AVG Validation Loss:0.697 AVG Training Acc 55.35 % AVG Validation Acc 48.51 %\n",
      "Epoch:120/200 AVG Training Loss:0.681 AVG Validation Loss:0.690 AVG Training Acc 55.68 % AVG Validation Acc 50.32 %\n",
      "New Best Accuracy found: 51.04%\n",
      "Epoch: 128\n",
      "New Best Accuracy found: 51.22%\n",
      "Epoch: 129\n",
      "Epoch:130/200 AVG Training Loss:0.681 AVG Validation Loss:0.688 AVG Training Acc 55.50 % AVG Validation Acc 51.31 %\n",
      "New Best Accuracy found: 51.31%\n",
      "Epoch: 130\n",
      "Epoch:140/200 AVG Training Loss:0.681 AVG Validation Loss:0.687 AVG Training Acc 55.65 % AVG Validation Acc 51.13 %\n",
      "Epoch:150/200 AVG Training Loss:0.682 AVG Validation Loss:0.687 AVG Training Acc 55.51 % AVG Validation Acc 50.95 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:160/200 AVG Training Loss:0.680 AVG Validation Loss:0.687 AVG Training Acc 55.69 % AVG Validation Acc 50.95 %\n",
      "Epoch:170/200 AVG Training Loss:0.680 AVG Validation Loss:0.687 AVG Training Acc 55.84 % AVG Validation Acc 50.68 %\n",
      "Epoch:180/200 AVG Training Loss:0.680 AVG Validation Loss:0.687 AVG Training Acc 55.80 % AVG Validation Acc 50.68 %\n",
      "Epoch:190/200 AVG Training Loss:0.680 AVG Validation Loss:0.686 AVG Training Acc 55.80 % AVG Validation Acc 51.13 %\n",
      "Epoch:200/200 AVG Training Loss:0.680 AVG Validation Loss:0.686 AVG Training Acc 55.73 % AVG Validation Acc 51.04 %\n",
      "Split 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f191fa53a3b0466690b9575898515ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:3.851 AVG Training Acc 64.29 % AVG Validation Acc 38.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:3.640 AVG Training Acc 62.89 % AVG Validation Acc 38.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.712 AVG Validation Loss:2.675 AVG Training Acc 63.47 % AVG Validation Acc 38.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.674 AVG Validation Loss:1.265 AVG Training Acc 60.58 % AVG Validation Acc 38.14 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.715 AVG Validation Loss:0.737 AVG Training Acc 48.53 % AVG Validation Acc 38.23 %\n",
      "Epoch:60/200 AVG Training Loss:0.691 AVG Validation Loss:0.715 AVG Training Acc 52.70 % AVG Validation Acc 43.46 %\n",
      "Epoch:70/200 AVG Training Loss:0.690 AVG Validation Loss:0.714 AVG Training Acc 53.21 % AVG Validation Acc 44.72 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.689 AVG Validation Loss:0.708 AVG Training Acc 54.49 % AVG Validation Acc 46.80 %\n",
      "Epoch:90/200 AVG Training Loss:0.685 AVG Validation Loss:0.696 AVG Training Acc 55.33 % AVG Validation Acc 49.41 %\n",
      "Epoch:100/200 AVG Training Loss:0.685 AVG Validation Loss:0.693 AVG Training Acc 55.23 % AVG Validation Acc 50.50 %\n",
      "Epoch:110/200 AVG Training Loss:0.684 AVG Validation Loss:0.692 AVG Training Acc 55.21 % AVG Validation Acc 50.23 %\n",
      "Epoch:120/200 AVG Training Loss:0.684 AVG Validation Loss:0.692 AVG Training Acc 55.67 % AVG Validation Acc 50.23 %\n",
      "Epoch:130/200 AVG Training Loss:0.685 AVG Validation Loss:0.692 AVG Training Acc 55.10 % AVG Validation Acc 50.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.684 AVG Validation Loss:0.692 AVG Training Acc 55.43 % AVG Validation Acc 50.32 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.683 AVG Validation Loss:0.691 AVG Training Acc 55.42 % AVG Validation Acc 50.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.684 AVG Validation Loss:0.691 AVG Training Acc 55.64 % AVG Validation Acc 50.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.683 AVG Validation Loss:0.691 AVG Training Acc 55.75 % AVG Validation Acc 50.41 %\n",
      "Epoch:180/200 AVG Training Loss:0.684 AVG Validation Loss:0.691 AVG Training Acc 55.85 % AVG Validation Acc 50.32 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:190/200 AVG Training Loss:0.684 AVG Validation Loss:0.691 AVG Training Acc 55.97 % AVG Validation Acc 50.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.683 AVG Validation Loss:0.691 AVG Training Acc 55.69 % AVG Validation Acc 50.32 %\n",
      "Split 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b9530eaacf34499ba044bdb6fc3b53f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:3.708 AVG Training Acc 64.69 % AVG Validation Acc 38.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.676 AVG Validation Loss:1.248 AVG Training Acc 60.20 % AVG Validation Acc 38.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.675 AVG Validation Loss:3.366 AVG Training Acc 64.37 % AVG Validation Acc 38.14 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.702 AVG Validation Loss:0.723 AVG Training Acc 49.14 % AVG Validation Acc 40.58 %\n",
      "Epoch:50/200 AVG Training Loss:0.695 AVG Validation Loss:0.713 AVG Training Acc 50.49 % AVG Validation Acc 41.12 %\n",
      "Epoch:60/200 AVG Training Loss:0.692 AVG Validation Loss:0.711 AVG Training Acc 51.78 % AVG Validation Acc 43.28 %\n",
      "Epoch:70/200 AVG Training Loss:0.691 AVG Validation Loss:0.711 AVG Training Acc 52.63 % AVG Validation Acc 43.55 %\n",
      "Epoch:80/200 AVG Training Loss:0.690 AVG Validation Loss:0.711 AVG Training Acc 52.89 % AVG Validation Acc 44.82 %\n",
      "Epoch:90/200 AVG Training Loss:0.690 AVG Validation Loss:0.711 AVG Training Acc 53.11 % AVG Validation Acc 46.08 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.687 AVG Validation Loss:0.700 AVG Training Acc 54.56 % AVG Validation Acc 48.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.687 AVG Validation Loss:0.693 AVG Training Acc 54.15 % AVG Validation Acc 49.23 %\n",
      "Epoch:120/200 AVG Training Loss:0.686 AVG Validation Loss:0.691 AVG Training Acc 54.91 % AVG Validation Acc 49.59 %\n",
      "Epoch:130/200 AVG Training Loss:0.685 AVG Validation Loss:0.690 AVG Training Acc 54.82 % AVG Validation Acc 49.32 %\n",
      "Epoch:140/200 AVG Training Loss:0.686 AVG Validation Loss:0.690 AVG Training Acc 54.03 % AVG Validation Acc 49.32 %\n",
      "Epoch:150/200 AVG Training Loss:0.686 AVG Validation Loss:0.690 AVG Training Acc 54.18 % AVG Validation Acc 49.32 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:160/200 AVG Training Loss:0.686 AVG Validation Loss:0.690 AVG Training Acc 55.01 % AVG Validation Acc 49.50 %\n",
      "Epoch:170/200 AVG Training Loss:0.686 AVG Validation Loss:0.690 AVG Training Acc 54.63 % AVG Validation Acc 49.77 %\n",
      "Epoch:180/200 AVG Training Loss:0.685 AVG Validation Loss:0.690 AVG Training Acc 54.79 % AVG Validation Acc 49.41 %\n",
      "Epoch:190/200 AVG Training Loss:0.684 AVG Validation Loss:0.690 AVG Training Acc 54.95 % AVG Validation Acc 49.86 %\n",
      "Epoch:200/200 AVG Training Loss:0.684 AVG Validation Loss:0.690 AVG Training Acc 55.09 % AVG Validation Acc 49.59 %\n",
      "Split 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d17ac31bc06460c861d6eee76d39901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.655 AVG Validation Loss:3.964 AVG Training Acc 64.98 % AVG Validation Acc 38.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.665 AVG Validation Loss:2.223 AVG Training Acc 63.32 % AVG Validation Acc 38.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.675 AVG Validation Loss:1.288 AVG Training Acc 60.27 % AVG Validation Acc 38.09 %\n",
      "Epoch:40/200 AVG Training Loss:0.676 AVG Validation Loss:1.219 AVG Training Acc 60.09 % AVG Validation Acc 38.09 %\n",
      "Epoch:50/200 AVG Training Loss:0.674 AVG Validation Loss:1.191 AVG Training Acc 60.14 % AVG Validation Acc 38.09 %\n",
      "Epoch:60/200 AVG Training Loss:0.672 AVG Validation Loss:1.205 AVG Training Acc 60.30 % AVG Validation Acc 38.09 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:70/200 AVG Training Loss:0.690 AVG Validation Loss:0.706 AVG Training Acc 52.52 % AVG Validation Acc 45.49 %\n",
      "Epoch:80/200 AVG Training Loss:0.689 AVG Validation Loss:0.704 AVG Training Acc 52.96 % AVG Validation Acc 46.39 %\n",
      "Epoch:90/200 AVG Training Loss:0.688 AVG Validation Loss:0.705 AVG Training Acc 53.39 % AVG Validation Acc 47.56 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.686 AVG Validation Loss:0.696 AVG Training Acc 54.76 % AVG Validation Acc 50.45 %\n",
      "New Best Accuracy found: 51.35%\n",
      "Epoch: 106\n",
      "New Best Accuracy found: 51.44%\n",
      "Epoch: 108\n",
      "Epoch:110/200 AVG Training Loss:0.685 AVG Validation Loss:0.690 AVG Training Acc 54.93 % AVG Validation Acc 50.90 %\n",
      "New Best Accuracy found: 51.53%\n",
      "Epoch: 114\n",
      "New Best Accuracy found: 51.71%\n",
      "Epoch: 115\n",
      "Epoch:120/200 AVG Training Loss:0.685 AVG Validation Loss:0.688 AVG Training Acc 55.09 % AVG Validation Acc 51.99 %\n",
      "New Best Accuracy found: 51.99%\n",
      "Epoch: 120\n",
      "Epoch:130/200 AVG Training Loss:0.684 AVG Validation Loss:0.687 AVG Training Acc 55.43 % AVG Validation Acc 51.62 %\n",
      "New Best Accuracy found: 52.44%\n",
      "Epoch: 134\n",
      "Epoch:140/200 AVG Training Loss:0.685 AVG Validation Loss:0.687 AVG Training Acc 55.16 % AVG Validation Acc 51.99 %\n",
      "Epoch:150/200 AVG Training Loss:0.683 AVG Validation Loss:0.687 AVG Training Acc 55.35 % AVG Validation Acc 52.35 %\n",
      "New Best Accuracy found: 52.62%\n",
      "Epoch: 157\n",
      "Epoch:160/200 AVG Training Loss:0.684 AVG Validation Loss:0.687 AVG Training Acc 55.21 % AVG Validation Acc 52.08 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:170/200 AVG Training Loss:0.682 AVG Validation Loss:0.687 AVG Training Acc 55.84 % AVG Validation Acc 52.44 %\n",
      "Epoch:180/200 AVG Training Loss:0.682 AVG Validation Loss:0.686 AVG Training Acc 55.50 % AVG Validation Acc 52.53 %\n",
      "Epoch:190/200 AVG Training Loss:0.683 AVG Validation Loss:0.686 AVG Training Acc 55.54 % AVG Validation Acc 52.53 %\n",
      "Epoch   195: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:200/200 AVG Training Loss:0.683 AVG Validation Loss:0.686 AVG Training Acc 55.26 % AVG Validation Acc 52.62 %\n",
      "Split 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f2144d690724b95a0328daadb901287",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.656 AVG Validation Loss:4.750 AVG Training Acc 64.60 % AVG Validation Acc 38.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.678 AVG Validation Loss:5.017 AVG Training Acc 64.96 % AVG Validation Acc 38.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.676 AVG Validation Loss:1.829 AVG Training Acc 63.40 % AVG Validation Acc 38.09 %\n",
      "Epoch:40/200 AVG Training Loss:0.680 AVG Validation Loss:1.241 AVG Training Acc 60.39 % AVG Validation Acc 38.18 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.752 AVG Validation Loss:0.779 AVG Training Acc 50.17 % AVG Validation Acc 38.09 %\n",
      "Epoch:60/200 AVG Training Loss:0.692 AVG Validation Loss:0.708 AVG Training Acc 51.89 % AVG Validation Acc 43.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.689 AVG Validation Loss:0.711 AVG Training Acc 52.88 % AVG Validation Acc 45.67 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.688 AVG Validation Loss:0.709 AVG Training Acc 54.23 % AVG Validation Acc 46.48 %\n",
      "Epoch:90/200 AVG Training Loss:0.684 AVG Validation Loss:0.696 AVG Training Acc 55.25 % AVG Validation Acc 49.28 %\n",
      "Epoch:100/200 AVG Training Loss:0.684 AVG Validation Loss:0.692 AVG Training Acc 54.92 % AVG Validation Acc 49.91 %\n",
      "Epoch:110/200 AVG Training Loss:0.683 AVG Validation Loss:0.691 AVG Training Acc 55.34 % AVG Validation Acc 49.91 %\n",
      "Epoch:120/200 AVG Training Loss:0.682 AVG Validation Loss:0.691 AVG Training Acc 55.47 % AVG Validation Acc 49.64 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.681 AVG Validation Loss:0.691 AVG Training Acc 55.67 % AVG Validation Acc 49.73 %\n",
      "Epoch:140/200 AVG Training Loss:0.682 AVG Validation Loss:0.691 AVG Training Acc 55.15 % AVG Validation Acc 50.09 %\n",
      "Epoch:150/200 AVG Training Loss:0.682 AVG Validation Loss:0.691 AVG Training Acc 55.48 % AVG Validation Acc 50.00 %\n",
      "Epoch:160/200 AVG Training Loss:0.681 AVG Validation Loss:0.691 AVG Training Acc 55.14 % AVG Validation Acc 49.91 %\n",
      "Epoch:170/200 AVG Training Loss:0.682 AVG Validation Loss:0.691 AVG Training Acc 55.44 % AVG Validation Acc 50.27 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:180/200 AVG Training Loss:0.683 AVG Validation Loss:0.690 AVG Training Acc 55.36 % AVG Validation Acc 50.54 %\n",
      "Epoch:190/200 AVG Training Loss:0.681 AVG Validation Loss:0.690 AVG Training Acc 55.32 % AVG Validation Acc 50.27 %\n",
      "Epoch:200/200 AVG Training Loss:0.682 AVG Validation Loss:0.690 AVG Training Acc 55.50 % AVG Validation Acc 50.27 %\n",
      "Split 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d1a37cb02b4bafb752dd8deee93c0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.647 AVG Validation Loss:7.153 AVG Training Acc 63.56 % AVG Validation Acc 38.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.671 AVG Validation Loss:1.448 AVG Training Acc 62.12 % AVG Validation Acc 38.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.676 AVG Validation Loss:1.201 AVG Training Acc 59.69 % AVG Validation Acc 38.09 %\n",
      "Epoch:40/200 AVG Training Loss:0.674 AVG Validation Loss:1.204 AVG Training Acc 60.05 % AVG Validation Acc 38.09 %\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.692 AVG Validation Loss:0.713 AVG Training Acc 51.00 % AVG Validation Acc 45.49 %\n",
      "Epoch:60/200 AVG Training Loss:0.690 AVG Validation Loss:0.713 AVG Training Acc 52.22 % AVG Validation Acc 47.29 %\n",
      "Epoch:70/200 AVG Training Loss:0.689 AVG Validation Loss:0.713 AVG Training Acc 52.80 % AVG Validation Acc 48.47 %\n",
      "Epoch:80/200 AVG Training Loss:0.688 AVG Validation Loss:0.711 AVG Training Acc 54.05 % AVG Validation Acc 49.64 %\n",
      "Epoch:90/200 AVG Training Loss:0.687 AVG Validation Loss:0.707 AVG Training Acc 53.68 % AVG Validation Acc 50.18 %\n",
      "Epoch:100/200 AVG Training Loss:0.687 AVG Validation Loss:0.707 AVG Training Acc 53.52 % AVG Validation Acc 50.27 %\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:110/200 AVG Training Loss:0.684 AVG Validation Loss:0.697 AVG Training Acc 54.98 % AVG Validation Acc 51.17 %\n",
      "Epoch:120/200 AVG Training Loss:0.684 AVG Validation Loss:0.691 AVG Training Acc 55.30 % AVG Validation Acc 52.44 %\n",
      "New Best Accuracy found: 52.71%\n",
      "Epoch: 122\n",
      "New Best Accuracy found: 52.89%\n",
      "Epoch: 127\n",
      "New Best Accuracy found: 52.98%\n",
      "Epoch: 128\n",
      "New Best Accuracy found: 53.07%\n",
      "Epoch: 129\n",
      "Epoch:130/200 AVG Training Loss:0.683 AVG Validation Loss:0.689 AVG Training Acc 55.36 % AVG Validation Acc 52.98 %\n",
      "New Best Accuracy found: 53.16%\n",
      "Epoch: 133\n",
      "Epoch:140/200 AVG Training Loss:0.682 AVG Validation Loss:0.688 AVG Training Acc 55.35 % AVG Validation Acc 53.34 %\n",
      "New Best Accuracy found: 53.34%\n",
      "Epoch: 140\n",
      "New Best Accuracy found: 53.43%\n",
      "Epoch: 144\n",
      "New Best Accuracy found: 53.52%\n",
      "Epoch: 147\n",
      "Epoch:150/200 AVG Training Loss:0.684 AVG Validation Loss:0.688 AVG Training Acc 54.83 % AVG Validation Acc 53.43 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:160/200 AVG Training Loss:0.682 AVG Validation Loss:0.688 AVG Training Acc 55.73 % AVG Validation Acc 52.98 %\n",
      "Epoch:170/200 AVG Training Loss:0.683 AVG Validation Loss:0.688 AVG Training Acc 55.04 % AVG Validation Acc 53.52 %\n",
      "Epoch:180/200 AVG Training Loss:0.683 AVG Validation Loss:0.688 AVG Training Acc 55.58 % AVG Validation Acc 53.52 %\n",
      "New Best Accuracy found: 53.61%\n",
      "Epoch: 183\n",
      "Epoch:190/200 AVG Training Loss:0.684 AVG Validation Loss:0.688 AVG Training Acc 55.27 % AVG Validation Acc 53.16 %\n",
      "New Best Accuracy found: 53.70%\n",
      "Epoch: 194\n",
      "Epoch:200/200 AVG Training Loss:0.683 AVG Validation Loss:0.688 AVG Training Acc 55.44 % AVG Validation Acc 53.34 %\n",
      "Split 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b8599dbabaf451daa46265cab0fd93c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.678 AVG Validation Loss:4.128 AVG Training Acc 66.09 % AVG Validation Acc 38.09 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.725 AVG Validation Loss:0.840 AVG Training Acc 52.91 % AVG Validation Acc 38.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.695 AVG Validation Loss:0.759 AVG Training Acc 53.04 % AVG Validation Acc 38.54 %\n",
      "Epoch:40/200 AVG Training Loss:0.691 AVG Validation Loss:0.752 AVG Training Acc 53.66 % AVG Validation Acc 38.54 %\n",
      "Epoch:50/200 AVG Training Loss:0.688 AVG Validation Loss:0.752 AVG Training Acc 53.72 % AVG Validation Acc 39.98 %\n",
      "Epoch:60/200 AVG Training Loss:0.687 AVG Validation Loss:0.748 AVG Training Acc 54.43 % AVG Validation Acc 40.88 %\n",
      "Epoch:70/200 AVG Training Loss:0.684 AVG Validation Loss:0.744 AVG Training Acc 54.71 % AVG Validation Acc 41.97 %\n",
      "Epoch:80/200 AVG Training Loss:0.684 AVG Validation Loss:0.739 AVG Training Acc 54.81 % AVG Validation Acc 42.69 %\n",
      "Epoch:90/200 AVG Training Loss:0.681 AVG Validation Loss:0.738 AVG Training Acc 55.42 % AVG Validation Acc 42.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.679 AVG Validation Loss:0.745 AVG Training Acc 55.56 % AVG Validation Acc 43.59 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:110/200 AVG Training Loss:0.682 AVG Validation Loss:0.730 AVG Training Acc 55.71 % AVG Validation Acc 45.04 %\n",
      "Epoch:120/200 AVG Training Loss:0.674 AVG Validation Loss:0.717 AVG Training Acc 57.10 % AVG Validation Acc 47.83 %\n",
      "Epoch:130/200 AVG Training Loss:0.673 AVG Validation Loss:0.715 AVG Training Acc 56.76 % AVG Validation Acc 48.38 %\n",
      "Epoch:140/200 AVG Training Loss:0.673 AVG Validation Loss:0.715 AVG Training Acc 56.75 % AVG Validation Acc 48.19 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.671 AVG Validation Loss:0.715 AVG Training Acc 57.25 % AVG Validation Acc 48.47 %\n",
      "Epoch:160/200 AVG Training Loss:0.673 AVG Validation Loss:0.716 AVG Training Acc 56.81 % AVG Validation Acc 48.47 %\n",
      "Epoch:170/200 AVG Training Loss:0.671 AVG Validation Loss:0.717 AVG Training Acc 57.06 % AVG Validation Acc 48.29 %\n",
      "Epoch:180/200 AVG Training Loss:0.671 AVG Validation Loss:0.715 AVG Training Acc 57.04 % AVG Validation Acc 48.47 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:190/200 AVG Training Loss:0.671 AVG Validation Loss:0.714 AVG Training Acc 57.42 % AVG Validation Acc 48.38 %\n",
      "Epoch:200/200 AVG Training Loss:0.671 AVG Validation Loss:0.715 AVG Training Acc 56.87 % AVG Validation Acc 48.56 %\n",
      "Split 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "599732b1a64e441cbf4b52f524b0f1e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.655 AVG Validation Loss:4.050 AVG Training Acc 65.13 % AVG Validation Acc 38.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.631 AVG Validation Loss:4.828 AVG Training Acc 64.04 % AVG Validation Acc 38.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.675 AVG Validation Loss:1.267 AVG Training Acc 60.40 % AVG Validation Acc 38.09 %\n",
      "Epoch:40/200 AVG Training Loss:0.666 AVG Validation Loss:1.739 AVG Training Acc 60.14 % AVG Validation Acc 38.09 %\n",
      "Epoch:50/200 AVG Training Loss:0.673 AVG Validation Loss:1.204 AVG Training Acc 60.10 % AVG Validation Acc 38.09 %\n",
      "Epoch:60/200 AVG Training Loss:0.722 AVG Validation Loss:1.263 AVG Training Acc 61.90 % AVG Validation Acc 38.09 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:70/200 AVG Training Loss:0.688 AVG Validation Loss:0.708 AVG Training Acc 53.64 % AVG Validation Acc 46.39 %\n",
      "Epoch:80/200 AVG Training Loss:0.688 AVG Validation Loss:0.710 AVG Training Acc 53.68 % AVG Validation Acc 47.02 %\n",
      "Epoch:90/200 AVG Training Loss:0.687 AVG Validation Loss:0.712 AVG Training Acc 54.24 % AVG Validation Acc 48.10 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.684 AVG Validation Loss:0.700 AVG Training Acc 55.25 % AVG Validation Acc 51.53 %\n",
      "Epoch:110/200 AVG Training Loss:0.684 AVG Validation Loss:0.695 AVG Training Acc 55.20 % AVG Validation Acc 51.90 %\n",
      "Epoch:120/200 AVG Training Loss:0.683 AVG Validation Loss:0.694 AVG Training Acc 55.09 % AVG Validation Acc 52.08 %\n",
      "Epoch:130/200 AVG Training Loss:0.683 AVG Validation Loss:0.694 AVG Training Acc 55.62 % AVG Validation Acc 52.17 %\n",
      "Epoch:140/200 AVG Training Loss:0.684 AVG Validation Loss:0.694 AVG Training Acc 55.25 % AVG Validation Acc 52.53 %\n",
      "Epoch:150/200 AVG Training Loss:0.683 AVG Validation Loss:0.694 AVG Training Acc 55.19 % AVG Validation Acc 52.26 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:160/200 AVG Training Loss:0.683 AVG Validation Loss:0.693 AVG Training Acc 55.35 % AVG Validation Acc 52.35 %\n",
      "Epoch:170/200 AVG Training Loss:0.682 AVG Validation Loss:0.693 AVG Training Acc 55.69 % AVG Validation Acc 51.99 %\n",
      "Epoch:180/200 AVG Training Loss:0.682 AVG Validation Loss:0.693 AVG Training Acc 55.72 % AVG Validation Acc 52.35 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:190/200 AVG Training Loss:0.682 AVG Validation Loss:0.693 AVG Training Acc 55.98 % AVG Validation Acc 52.17 %\n",
      "Epoch:200/200 AVG Training Loss:0.683 AVG Validation Loss:0.693 AVG Training Acc 55.76 % AVG Validation Acc 52.35 %\n",
      "Split 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93c52df7d78b4c15ac9620627d30a65e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.652 AVG Validation Loss:4.176 AVG Training Acc 66.14 % AVG Validation Acc 38.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:3.174 AVG Training Acc 63.29 % AVG Validation Acc 38.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.677 AVG Validation Loss:1.264 AVG Training Acc 60.37 % AVG Validation Acc 38.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.673 AVG Validation Loss:1.288 AVG Training Acc 59.99 % AVG Validation Acc 38.05 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.904 AVG Validation Loss:0.890 AVG Training Acc 50.13 % AVG Validation Acc 38.32 %\n",
      "Epoch:60/200 AVG Training Loss:0.687 AVG Validation Loss:0.710 AVG Training Acc 54.28 % AVG Validation Acc 48.33 %\n",
      "Epoch:70/200 AVG Training Loss:0.686 AVG Validation Loss:0.710 AVG Training Acc 54.34 % AVG Validation Acc 48.33 %\n",
      "Epoch:80/200 AVG Training Loss:0.685 AVG Validation Loss:0.710 AVG Training Acc 54.66 % AVG Validation Acc 48.24 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.684 AVG Validation Loss:0.698 AVG Training Acc 55.85 % AVG Validation Acc 48.87 %\n",
      "Epoch:100/200 AVG Training Loss:0.683 AVG Validation Loss:0.694 AVG Training Acc 55.79 % AVG Validation Acc 49.32 %\n",
      "Epoch:110/200 AVG Training Loss:0.683 AVG Validation Loss:0.692 AVG Training Acc 55.87 % AVG Validation Acc 49.68 %\n",
      "Epoch:120/200 AVG Training Loss:0.683 AVG Validation Loss:0.692 AVG Training Acc 56.00 % AVG Validation Acc 50.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.682 AVG Validation Loss:0.692 AVG Training Acc 55.94 % AVG Validation Acc 49.77 %\n",
      "Epoch:140/200 AVG Training Loss:0.682 AVG Validation Loss:0.692 AVG Training Acc 55.99 % AVG Validation Acc 49.86 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.681 AVG Validation Loss:0.691 AVG Training Acc 56.37 % AVG Validation Acc 49.95 %\n",
      "Epoch:160/200 AVG Training Loss:0.683 AVG Validation Loss:0.691 AVG Training Acc 55.94 % AVG Validation Acc 49.86 %\n",
      "Epoch:170/200 AVG Training Loss:0.683 AVG Validation Loss:0.691 AVG Training Acc 56.15 % AVG Validation Acc 49.86 %\n",
      "Epoch:180/200 AVG Training Loss:0.682 AVG Validation Loss:0.691 AVG Training Acc 56.12 % AVG Validation Acc 49.86 %\n",
      "Epoch:190/200 AVG Training Loss:0.681 AVG Validation Loss:0.691 AVG Training Acc 56.50 % AVG Validation Acc 49.86 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:200/200 AVG Training Loss:0.682 AVG Validation Loss:0.691 AVG Training Acc 56.18 % AVG Validation Acc 49.86 %\n",
      "Split 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5395d8afd2d04c54b4adc3e5abc3875e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.653 AVG Validation Loss:5.564 AVG Training Acc 65.39 % AVG Validation Acc 38.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.692 AVG Validation Loss:5.420 AVG Training Acc 63.47 % AVG Validation Acc 38.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.693 AVG Validation Loss:2.995 AVG Training Acc 62.90 % AVG Validation Acc 38.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.675 AVG Validation Loss:1.232 AVG Training Acc 60.29 % AVG Validation Acc 38.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.674 AVG Validation Loss:1.190 AVG Training Acc 59.89 % AVG Validation Acc 38.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.659 AVG Validation Loss:5.480 AVG Training Acc 60.28 % AVG Validation Acc 38.14 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:70/200 AVG Training Loss:0.695 AVG Validation Loss:0.711 AVG Training Acc 50.27 % AVG Validation Acc 39.77 %\n",
      "Epoch:80/200 AVG Training Loss:0.690 AVG Validation Loss:0.715 AVG Training Acc 52.66 % AVG Validation Acc 41.30 %\n",
      "Epoch:90/200 AVG Training Loss:0.687 AVG Validation Loss:0.715 AVG Training Acc 53.07 % AVG Validation Acc 42.20 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.686 AVG Validation Loss:0.695 AVG Training Acc 54.32 % AVG Validation Acc 49.50 %\n",
      "Epoch:110/200 AVG Training Loss:0.685 AVG Validation Loss:0.690 AVG Training Acc 54.48 % AVG Validation Acc 51.31 %\n",
      "Epoch:120/200 AVG Training Loss:0.684 AVG Validation Loss:0.688 AVG Training Acc 54.84 % AVG Validation Acc 51.40 %\n",
      "Epoch:130/200 AVG Training Loss:0.685 AVG Validation Loss:0.688 AVG Training Acc 54.34 % AVG Validation Acc 51.94 %\n",
      "Epoch:140/200 AVG Training Loss:0.685 AVG Validation Loss:0.688 AVG Training Acc 54.52 % AVG Validation Acc 51.76 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.684 AVG Validation Loss:0.687 AVG Training Acc 54.70 % AVG Validation Acc 51.49 %\n",
      "Epoch:160/200 AVG Training Loss:0.685 AVG Validation Loss:0.687 AVG Training Acc 53.81 % AVG Validation Acc 51.94 %\n",
      "Epoch:170/200 AVG Training Loss:0.685 AVG Validation Loss:0.687 AVG Training Acc 54.58 % AVG Validation Acc 51.94 %\n",
      "Epoch:180/200 AVG Training Loss:0.684 AVG Validation Loss:0.687 AVG Training Acc 54.75 % AVG Validation Acc 51.85 %\n",
      "Epoch:190/200 AVG Training Loss:0.683 AVG Validation Loss:0.687 AVG Training Acc 54.88 % AVG Validation Acc 51.49 %\n",
      "Epoch:200/200 AVG Training Loss:0.683 AVG Validation Loss:0.686 AVG Training Acc 54.68 % AVG Validation Acc 51.58 %\n",
      "Split 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43f5d66e87554143a2684993b7429a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.649 AVG Validation Loss:3.880 AVG Training Acc 65.58 % AVG Validation Acc 38.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.645 AVG Validation Loss:8.484 AVG Training Acc 62.31 % AVG Validation Acc 38.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.669 AVG Validation Loss:3.474 AVG Training Acc 62.28 % AVG Validation Acc 38.14 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.697 AVG Validation Loss:0.734 AVG Training Acc 51.25 % AVG Validation Acc 38.59 %\n",
      "Epoch:50/200 AVG Training Loss:0.694 AVG Validation Loss:0.729 AVG Training Acc 51.33 % AVG Validation Acc 38.95 %\n",
      "Epoch:60/200 AVG Training Loss:0.694 AVG Validation Loss:0.724 AVG Training Acc 51.29 % AVG Validation Acc 39.40 %\n",
      "Epoch:70/200 AVG Training Loss:0.693 AVG Validation Loss:0.722 AVG Training Acc 51.06 % AVG Validation Acc 40.49 %\n",
      "Epoch:80/200 AVG Training Loss:0.690 AVG Validation Loss:0.724 AVG Training Acc 53.04 % AVG Validation Acc 41.48 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.686 AVG Validation Loss:0.706 AVG Training Acc 53.76 % AVG Validation Acc 47.70 %\n",
      "Epoch:100/200 AVG Training Loss:0.687 AVG Validation Loss:0.700 AVG Training Acc 54.10 % AVG Validation Acc 48.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.686 AVG Validation Loss:0.699 AVG Training Acc 54.42 % AVG Validation Acc 49.14 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.686 AVG Validation Loss:0.699 AVG Training Acc 54.39 % AVG Validation Acc 48.96 %\n",
      "Epoch:130/200 AVG Training Loss:0.685 AVG Validation Loss:0.698 AVG Training Acc 54.44 % AVG Validation Acc 48.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.685 AVG Validation Loss:0.698 AVG Training Acc 54.88 % AVG Validation Acc 48.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.685 AVG Validation Loss:0.698 AVG Training Acc 54.54 % AVG Validation Acc 48.96 %\n",
      "Epoch:160/200 AVG Training Loss:0.685 AVG Validation Loss:0.698 AVG Training Acc 54.79 % AVG Validation Acc 49.32 %\n",
      "Epoch:170/200 AVG Training Loss:0.685 AVG Validation Loss:0.698 AVG Training Acc 54.91 % AVG Validation Acc 49.59 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:180/200 AVG Training Loss:0.685 AVG Validation Loss:0.698 AVG Training Acc 54.99 % AVG Validation Acc 49.59 %\n",
      "Epoch:190/200 AVG Training Loss:0.685 AVG Validation Loss:0.698 AVG Training Acc 55.08 % AVG Validation Acc 49.59 %\n",
      "Epoch:200/200 AVG Training Loss:0.686 AVG Validation Loss:0.698 AVG Training Acc 54.62 % AVG Validation Acc 49.59 %\n",
      "Split 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c478b79eb0141f3a06c541b5f80da65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.681 AVG Validation Loss:2.186 AVG Training Acc 64.69 % AVG Validation Acc 38.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.632 AVG Validation Loss:2.285 AVG Training Acc 64.26 % AVG Validation Acc 38.14 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.697 AVG Validation Loss:1.068 AVG Training Acc 58.25 % AVG Validation Acc 38.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.680 AVG Validation Loss:1.074 AVG Training Acc 58.89 % AVG Validation Acc 38.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.679 AVG Validation Loss:1.033 AVG Training Acc 59.49 % AVG Validation Acc 38.32 %\n",
      "Epoch:60/200 AVG Training Loss:0.665 AVG Validation Loss:1.477 AVG Training Acc 59.81 % AVG Validation Acc 38.23 %\n",
      "Epoch:70/200 AVG Training Loss:0.673 AVG Validation Loss:1.376 AVG Training Acc 58.16 % AVG Validation Acc 38.59 %\n",
      "Epoch:80/200 AVG Training Loss:0.684 AVG Validation Loss:0.847 AVG Training Acc 57.05 % AVG Validation Acc 39.68 %\n",
      "Epoch:90/200 AVG Training Loss:0.679 AVG Validation Loss:0.833 AVG Training Acc 56.57 % AVG Validation Acc 39.22 %\n",
      "Epoch:100/200 AVG Training Loss:0.682 AVG Validation Loss:0.789 AVG Training Acc 55.31 % AVG Validation Acc 40.13 %\n",
      "Epoch:110/200 AVG Training Loss:0.683 AVG Validation Loss:0.781 AVG Training Acc 55.25 % AVG Validation Acc 39.68 %\n",
      "Epoch:120/200 AVG Training Loss:0.680 AVG Validation Loss:0.778 AVG Training Acc 55.45 % AVG Validation Acc 39.77 %\n",
      "Epoch:130/200 AVG Training Loss:0.679 AVG Validation Loss:0.780 AVG Training Acc 55.21 % AVG Validation Acc 39.86 %\n",
      "Epoch:140/200 AVG Training Loss:0.681 AVG Validation Loss:0.774 AVG Training Acc 54.63 % AVG Validation Acc 40.40 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:150/200 AVG Training Loss:0.677 AVG Validation Loss:0.716 AVG Training Acc 55.46 % AVG Validation Acc 46.44 %\n",
      "Epoch:160/200 AVG Training Loss:0.674 AVG Validation Loss:0.710 AVG Training Acc 55.93 % AVG Validation Acc 48.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.673 AVG Validation Loss:0.705 AVG Training Acc 56.19 % AVG Validation Acc 49.32 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:180/200 AVG Training Loss:0.673 AVG Validation Loss:0.712 AVG Training Acc 56.04 % AVG Validation Acc 49.23 %\n",
      "Epoch:190/200 AVG Training Loss:0.671 AVG Validation Loss:0.709 AVG Training Acc 56.62 % AVG Validation Acc 50.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.672 AVG Validation Loss:0.706 AVG Training Acc 56.13 % AVG Validation Acc 50.32 %\n",
      "Split 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d192f44b59749b5a36f5935f5981e2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.614 AVG Validation Loss:3.659 AVG Training Acc 64.33 % AVG Validation Acc 38.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.598 AVG Validation Loss:3.953 AVG Training Acc 65.85 % AVG Validation Acc 38.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.659 AVG Validation Loss:1.698 AVG Training Acc 63.15 % AVG Validation Acc 38.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:2.701 AVG Training Acc 63.89 % AVG Validation Acc 38.14 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.693 AVG Validation Loss:0.748 AVG Training Acc 52.79 % AVG Validation Acc 41.39 %\n",
      "Epoch:60/200 AVG Training Loss:0.690 AVG Validation Loss:0.749 AVG Training Acc 53.38 % AVG Validation Acc 41.21 %\n",
      "Epoch:70/200 AVG Training Loss:0.688 AVG Validation Loss:0.743 AVG Training Acc 53.42 % AVG Validation Acc 41.21 %\n",
      "Epoch:80/200 AVG Training Loss:0.685 AVG Validation Loss:0.750 AVG Training Acc 54.98 % AVG Validation Acc 40.67 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.685 AVG Validation Loss:0.705 AVG Training Acc 54.79 % AVG Validation Acc 46.26 %\n",
      "Epoch:100/200 AVG Training Loss:0.683 AVG Validation Loss:0.699 AVG Training Acc 55.17 % AVG Validation Acc 47.52 %\n",
      "Epoch:110/200 AVG Training Loss:0.682 AVG Validation Loss:0.698 AVG Training Acc 55.71 % AVG Validation Acc 47.97 %\n",
      "Epoch:120/200 AVG Training Loss:0.682 AVG Validation Loss:0.697 AVG Training Acc 55.47 % AVG Validation Acc 47.97 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.681 AVG Validation Loss:0.697 AVG Training Acc 55.15 % AVG Validation Acc 48.15 %\n",
      "Epoch:140/200 AVG Training Loss:0.681 AVG Validation Loss:0.696 AVG Training Acc 55.55 % AVG Validation Acc 48.33 %\n",
      "Epoch:150/200 AVG Training Loss:0.681 AVG Validation Loss:0.696 AVG Training Acc 55.43 % AVG Validation Acc 48.15 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.681 AVG Validation Loss:0.696 AVG Training Acc 55.68 % AVG Validation Acc 48.51 %\n",
      "Epoch:170/200 AVG Training Loss:0.681 AVG Validation Loss:0.695 AVG Training Acc 55.43 % AVG Validation Acc 48.42 %\n",
      "Epoch:180/200 AVG Training Loss:0.681 AVG Validation Loss:0.696 AVG Training Acc 55.78 % AVG Validation Acc 48.33 %\n",
      "Epoch:190/200 AVG Training Loss:0.680 AVG Validation Loss:0.695 AVG Training Acc 55.72 % AVG Validation Acc 48.78 %\n",
      "Epoch:200/200 AVG Training Loss:0.682 AVG Validation Loss:0.695 AVG Training Acc 55.17 % AVG Validation Acc 48.69 %\n",
      "Epoch   200: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Split 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "220f5bc38cd5400794d8c9c61439edd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.636 AVG Validation Loss:2.508 AVG Training Acc 64.06 % AVG Validation Acc 38.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.685 AVG Validation Loss:2.456 AVG Training Acc 62.71 % AVG Validation Acc 38.09 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.692 AVG Validation Loss:0.944 AVG Training Acc 56.21 % AVG Validation Acc 38.36 %\n",
      "Epoch:40/200 AVG Training Loss:0.693 AVG Validation Loss:0.821 AVG Training Acc 55.10 % AVG Validation Acc 38.36 %\n",
      "Epoch:50/200 AVG Training Loss:0.690 AVG Validation Loss:0.772 AVG Training Acc 54.18 % AVG Validation Acc 38.63 %\n",
      "Epoch:60/200 AVG Training Loss:0.688 AVG Validation Loss:0.749 AVG Training Acc 54.45 % AVG Validation Acc 39.17 %\n",
      "Epoch:70/200 AVG Training Loss:0.686 AVG Validation Loss:0.744 AVG Training Acc 54.23 % AVG Validation Acc 40.16 %\n",
      "Epoch:80/200 AVG Training Loss:0.682 AVG Validation Loss:0.735 AVG Training Acc 54.29 % AVG Validation Acc 40.25 %\n",
      "Epoch:90/200 AVG Training Loss:0.680 AVG Validation Loss:0.736 AVG Training Acc 53.99 % AVG Validation Acc 40.97 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.682 AVG Validation Loss:0.718 AVG Training Acc 54.06 % AVG Validation Acc 43.95 %\n",
      "Epoch:110/200 AVG Training Loss:0.676 AVG Validation Loss:0.703 AVG Training Acc 55.41 % AVG Validation Acc 47.38 %\n",
      "Epoch:120/200 AVG Training Loss:0.675 AVG Validation Loss:0.702 AVG Training Acc 55.45 % AVG Validation Acc 48.47 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.674 AVG Validation Loss:0.701 AVG Training Acc 55.62 % AVG Validation Acc 48.65 %\n",
      "Epoch:140/200 AVG Training Loss:0.674 AVG Validation Loss:0.701 AVG Training Acc 55.69 % AVG Validation Acc 48.56 %\n",
      "Epoch:150/200 AVG Training Loss:0.674 AVG Validation Loss:0.700 AVG Training Acc 55.90 % AVG Validation Acc 48.56 %\n",
      "Epoch:160/200 AVG Training Loss:0.672 AVG Validation Loss:0.701 AVG Training Acc 55.79 % AVG Validation Acc 48.83 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:170/200 AVG Training Loss:0.673 AVG Validation Loss:0.700 AVG Training Acc 55.97 % AVG Validation Acc 49.19 %\n",
      "Epoch:180/200 AVG Training Loss:0.673 AVG Validation Loss:0.700 AVG Training Acc 55.75 % AVG Validation Acc 49.19 %\n",
      "Epoch:190/200 AVG Training Loss:0.674 AVG Validation Loss:0.700 AVG Training Acc 55.89 % AVG Validation Acc 49.01 %\n",
      "Epoch:200/200 AVG Training Loss:0.673 AVG Validation Loss:0.700 AVG Training Acc 55.84 % AVG Validation Acc 48.92 %\n",
      "Epoch   200: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Split 17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4db65428d89402189bce1d45568a7d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.653 AVG Validation Loss:4.422 AVG Training Acc 65.30 % AVG Validation Acc 38.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.661 AVG Validation Loss:2.214 AVG Training Acc 63.73 % AVG Validation Acc 38.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.697 AVG Validation Loss:5.803 AVG Training Acc 64.81 % AVG Validation Acc 38.09 %\n",
      "Epoch:40/200 AVG Training Loss:0.672 AVG Validation Loss:1.796 AVG Training Acc 63.48 % AVG Validation Acc 38.09 %\n",
      "Epoch:50/200 AVG Training Loss:0.674 AVG Validation Loss:1.246 AVG Training Acc 60.07 % AVG Validation Acc 38.09 %\n",
      "Epoch:60/200 AVG Training Loss:0.665 AVG Validation Loss:4.534 AVG Training Acc 60.35 % AVG Validation Acc 38.18 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:70/200 AVG Training Loss:0.693 AVG Validation Loss:0.720 AVG Training Acc 52.27 % AVG Validation Acc 44.86 %\n",
      "Epoch:80/200 AVG Training Loss:0.689 AVG Validation Loss:0.714 AVG Training Acc 53.68 % AVG Validation Acc 48.01 %\n",
      "Epoch:90/200 AVG Training Loss:0.686 AVG Validation Loss:0.713 AVG Training Acc 54.36 % AVG Validation Acc 48.47 %\n",
      "Epoch:100/200 AVG Training Loss:0.687 AVG Validation Loss:0.710 AVG Training Acc 53.77 % AVG Validation Acc 48.65 %\n",
      "Epoch:110/200 AVG Training Loss:0.683 AVG Validation Loss:0.714 AVG Training Acc 54.09 % AVG Validation Acc 48.29 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:120/200 AVG Training Loss:0.681 AVG Validation Loss:0.697 AVG Training Acc 55.47 % AVG Validation Acc 49.28 %\n",
      "Epoch:130/200 AVG Training Loss:0.680 AVG Validation Loss:0.695 AVG Training Acc 55.51 % AVG Validation Acc 49.37 %\n",
      "Epoch:140/200 AVG Training Loss:0.679 AVG Validation Loss:0.693 AVG Training Acc 55.75 % AVG Validation Acc 49.82 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.679 AVG Validation Loss:0.695 AVG Training Acc 55.71 % AVG Validation Acc 50.09 %\n",
      "Epoch:160/200 AVG Training Loss:0.680 AVG Validation Loss:0.695 AVG Training Acc 56.02 % AVG Validation Acc 50.18 %\n",
      "Epoch:170/200 AVG Training Loss:0.679 AVG Validation Loss:0.697 AVG Training Acc 55.63 % AVG Validation Acc 50.27 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:180/200 AVG Training Loss:0.679 AVG Validation Loss:0.697 AVG Training Acc 56.11 % AVG Validation Acc 50.18 %\n",
      "Epoch:190/200 AVG Training Loss:0.679 AVG Validation Loss:0.698 AVG Training Acc 56.01 % AVG Validation Acc 49.91 %\n",
      "Epoch:200/200 AVG Training Loss:0.678 AVG Validation Loss:0.699 AVG Training Acc 55.94 % AVG Validation Acc 50.27 %\n",
      "Split 18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a54db85d11f0464cb10868ff2dd36056",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.656 AVG Validation Loss:4.558 AVG Training Acc 64.36 % AVG Validation Acc 38.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.665 AVG Validation Loss:4.558 AVG Training Acc 64.23 % AVG Validation Acc 38.00 %\n",
      "Epoch:30/200 AVG Training Loss:0.678 AVG Validation Loss:1.224 AVG Training Acc 60.06 % AVG Validation Acc 38.09 %\n",
      "Epoch:40/200 AVG Training Loss:0.675 AVG Validation Loss:1.207 AVG Training Acc 59.90 % AVG Validation Acc 38.09 %\n",
      "Epoch:50/200 AVG Training Loss:0.674 AVG Validation Loss:1.250 AVG Training Acc 60.01 % AVG Validation Acc 38.09 %\n",
      "Epoch:60/200 AVG Training Loss:0.672 AVG Validation Loss:1.627 AVG Training Acc 60.37 % AVG Validation Acc 38.09 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:70/200 AVG Training Loss:0.689 AVG Validation Loss:0.716 AVG Training Acc 53.86 % AVG Validation Acc 44.40 %\n",
      "Epoch:80/200 AVG Training Loss:0.687 AVG Validation Loss:0.721 AVG Training Acc 54.23 % AVG Validation Acc 45.31 %\n",
      "Epoch:90/200 AVG Training Loss:0.687 AVG Validation Loss:0.721 AVG Training Acc 54.45 % AVG Validation Acc 45.49 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.684 AVG Validation Loss:0.712 AVG Training Acc 54.63 % AVG Validation Acc 48.29 %\n",
      "Epoch:110/200 AVG Training Loss:0.683 AVG Validation Loss:0.707 AVG Training Acc 54.93 % AVG Validation Acc 49.19 %\n",
      "Epoch:120/200 AVG Training Loss:0.683 AVG Validation Loss:0.706 AVG Training Acc 54.99 % AVG Validation Acc 48.92 %\n",
      "Epoch:130/200 AVG Training Loss:0.682 AVG Validation Loss:0.706 AVG Training Acc 54.91 % AVG Validation Acc 49.46 %\n",
      "Epoch   133: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:140/200 AVG Training Loss:0.682 AVG Validation Loss:0.706 AVG Training Acc 55.30 % AVG Validation Acc 49.37 %\n",
      "Epoch:150/200 AVG Training Loss:0.682 AVG Validation Loss:0.705 AVG Training Acc 55.29 % AVG Validation Acc 49.46 %\n",
      "Epoch:160/200 AVG Training Loss:0.683 AVG Validation Loss:0.705 AVG Training Acc 55.17 % AVG Validation Acc 49.46 %\n",
      "Epoch:170/200 AVG Training Loss:0.682 AVG Validation Loss:0.705 AVG Training Acc 55.40 % AVG Validation Acc 49.55 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:180/200 AVG Training Loss:0.682 AVG Validation Loss:0.705 AVG Training Acc 55.39 % AVG Validation Acc 49.82 %\n",
      "Epoch:190/200 AVG Training Loss:0.682 AVG Validation Loss:0.705 AVG Training Acc 55.30 % AVG Validation Acc 49.64 %\n",
      "Epoch:200/200 AVG Training Loss:0.681 AVG Validation Loss:0.705 AVG Training Acc 55.55 % AVG Validation Acc 49.64 %\n",
      "Split 19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b5d3665ff040fe85c02371336e6f5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.653 AVG Validation Loss:5.213 AVG Training Acc 65.88 % AVG Validation Acc 38.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.639 AVG Validation Loss:2.734 AVG Training Acc 63.88 % AVG Validation Acc 38.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:2.022 AVG Training Acc 64.03 % AVG Validation Acc 37.91 %\n",
      "Epoch:40/200 AVG Training Loss:0.654 AVG Validation Loss:2.016 AVG Training Acc 61.86 % AVG Validation Acc 38.09 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.758 AVG Validation Loss:0.856 AVG Training Acc 52.16 % AVG Validation Acc 38.18 %\n",
      "Epoch:60/200 AVG Training Loss:0.694 AVG Validation Loss:0.769 AVG Training Acc 52.81 % AVG Validation Acc 38.09 %\n",
      "Epoch:70/200 AVG Training Loss:0.694 AVG Validation Loss:0.738 AVG Training Acc 53.54 % AVG Validation Acc 39.08 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.704 AVG Validation Loss:0.728 AVG Training Acc 52.62 % AVG Validation Acc 43.86 %\n",
      "Epoch:90/200 AVG Training Loss:0.688 AVG Validation Loss:0.693 AVG Training Acc 54.71 % AVG Validation Acc 49.73 %\n",
      "Epoch:100/200 AVG Training Loss:0.687 AVG Validation Loss:0.690 AVG Training Acc 54.70 % AVG Validation Acc 49.19 %\n",
      "Epoch:110/200 AVG Training Loss:0.685 AVG Validation Loss:0.689 AVG Training Acc 55.19 % AVG Validation Acc 49.37 %\n",
      "Epoch:120/200 AVG Training Loss:0.687 AVG Validation Loss:0.690 AVG Training Acc 54.81 % AVG Validation Acc 50.36 %\n",
      "Epoch:130/200 AVG Training Loss:0.686 AVG Validation Loss:0.689 AVG Training Acc 55.15 % AVG Validation Acc 50.18 %\n",
      "Epoch   132: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:140/200 AVG Training Loss:0.686 AVG Validation Loss:0.688 AVG Training Acc 55.43 % AVG Validation Acc 50.63 %\n",
      "Epoch:150/200 AVG Training Loss:0.686 AVG Validation Loss:0.686 AVG Training Acc 55.17 % AVG Validation Acc 50.27 %\n",
      "Epoch:160/200 AVG Training Loss:0.686 AVG Validation Loss:0.686 AVG Training Acc 55.47 % AVG Validation Acc 50.45 %\n",
      "Epoch:170/200 AVG Training Loss:0.686 AVG Validation Loss:0.686 AVG Training Acc 55.10 % AVG Validation Acc 51.17 %\n",
      "Epoch:180/200 AVG Training Loss:0.685 AVG Validation Loss:0.684 AVG Training Acc 55.56 % AVG Validation Acc 51.35 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:190/200 AVG Training Loss:0.686 AVG Validation Loss:0.684 AVG Training Acc 55.15 % AVG Validation Acc 51.44 %\n",
      "Epoch:200/200 AVG Training Loss:0.685 AVG Validation Loss:0.685 AVG Training Acc 55.37 % AVG Validation Acc 51.08 %\n",
      "Split 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79e9918ef3df449398193bf712d4409b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.616 AVG Validation Loss:3.982 AVG Training Acc 64.19 % AVG Validation Acc 38.63 %\n",
      "Epoch:20/200 AVG Training Loss:0.619 AVG Validation Loss:3.438 AVG Training Acc 64.96 % AVG Validation Acc 38.09 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.694 AVG Validation Loss:0.832 AVG Training Acc 55.50 % AVG Validation Acc 38.09 %\n",
      "Epoch:40/200 AVG Training Loss:0.693 AVG Validation Loss:0.762 AVG Training Acc 54.32 % AVG Validation Acc 41.97 %\n",
      "Epoch:50/200 AVG Training Loss:0.692 AVG Validation Loss:0.738 AVG Training Acc 52.68 % AVG Validation Acc 42.78 %\n",
      "Epoch:60/200 AVG Training Loss:0.706 AVG Validation Loss:0.736 AVG Training Acc 52.92 % AVG Validation Acc 44.40 %\n",
      "Epoch:70/200 AVG Training Loss:0.689 AVG Validation Loss:0.737 AVG Training Acc 54.60 % AVG Validation Acc 42.87 %\n",
      "Epoch:80/200 AVG Training Loss:0.689 AVG Validation Loss:0.725 AVG Training Acc 53.21 % AVG Validation Acc 44.86 %\n",
      "Epoch:90/200 AVG Training Loss:0.688 AVG Validation Loss:0.724 AVG Training Acc 53.90 % AVG Validation Acc 43.59 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.684 AVG Validation Loss:0.694 AVG Training Acc 54.85 % AVG Validation Acc 49.82 %\n",
      "Epoch:110/200 AVG Training Loss:0.683 AVG Validation Loss:0.688 AVG Training Acc 55.03 % AVG Validation Acc 50.45 %\n",
      "Epoch:120/200 AVG Training Loss:0.684 AVG Validation Loss:0.687 AVG Training Acc 54.93 % AVG Validation Acc 51.35 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.682 AVG Validation Loss:0.687 AVG Training Acc 55.05 % AVG Validation Acc 50.81 %\n",
      "Epoch:140/200 AVG Training Loss:0.680 AVG Validation Loss:0.685 AVG Training Acc 55.32 % AVG Validation Acc 51.08 %\n",
      "Epoch:150/200 AVG Training Loss:0.681 AVG Validation Loss:0.688 AVG Training Acc 55.53 % AVG Validation Acc 51.08 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.680 AVG Validation Loss:0.685 AVG Training Acc 55.72 % AVG Validation Acc 51.08 %\n",
      "Epoch:170/200 AVG Training Loss:0.681 AVG Validation Loss:0.686 AVG Training Acc 55.49 % AVG Validation Acc 51.26 %\n",
      "Epoch:180/200 AVG Training Loss:0.680 AVG Validation Loss:0.686 AVG Training Acc 55.38 % AVG Validation Acc 51.53 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.681 AVG Validation Loss:0.686 AVG Training Acc 55.22 % AVG Validation Acc 51.26 %\n",
      "Epoch:200/200 AVG Training Loss:0.679 AVG Validation Loss:0.687 AVG Training Acc 55.57 % AVG Validation Acc 50.36 %\n",
      "Split 21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ed948461b724ba4afaa7a3af6ecef0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.616 AVG Validation Loss:4.225 AVG Training Acc 66.17 % AVG Validation Acc 38.05 %\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.690 AVG Validation Loss:0.937 AVG Training Acc 55.90 % AVG Validation Acc 37.96 %\n",
      "Epoch:30/200 AVG Training Loss:0.676 AVG Validation Loss:0.964 AVG Training Acc 56.41 % AVG Validation Acc 39.31 %\n",
      "Epoch:40/200 AVG Training Loss:0.694 AVG Validation Loss:0.756 AVG Training Acc 53.69 % AVG Validation Acc 38.68 %\n",
      "Epoch:50/200 AVG Training Loss:0.689 AVG Validation Loss:0.740 AVG Training Acc 54.28 % AVG Validation Acc 41.66 %\n",
      "Epoch:60/200 AVG Training Loss:0.688 AVG Validation Loss:0.733 AVG Training Acc 53.66 % AVG Validation Acc 42.74 %\n",
      "Epoch:70/200 AVG Training Loss:0.687 AVG Validation Loss:0.729 AVG Training Acc 54.37 % AVG Validation Acc 42.65 %\n",
      "Epoch:80/200 AVG Training Loss:0.684 AVG Validation Loss:0.731 AVG Training Acc 54.75 % AVG Validation Acc 42.74 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.681 AVG Validation Loss:0.698 AVG Training Acc 55.98 % AVG Validation Acc 47.25 %\n",
      "Epoch:100/200 AVG Training Loss:0.679 AVG Validation Loss:0.693 AVG Training Acc 56.18 % AVG Validation Acc 48.24 %\n",
      "Epoch:110/200 AVG Training Loss:0.679 AVG Validation Loss:0.692 AVG Training Acc 55.81 % AVG Validation Acc 48.15 %\n",
      "Epoch:120/200 AVG Training Loss:0.679 AVG Validation Loss:0.693 AVG Training Acc 56.26 % AVG Validation Acc 48.15 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.677 AVG Validation Loss:0.693 AVG Training Acc 56.17 % AVG Validation Acc 47.70 %\n",
      "Epoch:140/200 AVG Training Loss:0.677 AVG Validation Loss:0.692 AVG Training Acc 56.39 % AVG Validation Acc 47.97 %\n",
      "Epoch:150/200 AVG Training Loss:0.677 AVG Validation Loss:0.691 AVG Training Acc 56.52 % AVG Validation Acc 48.24 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.677 AVG Validation Loss:0.692 AVG Training Acc 56.54 % AVG Validation Acc 47.61 %\n",
      "Epoch:170/200 AVG Training Loss:0.678 AVG Validation Loss:0.691 AVG Training Acc 56.44 % AVG Validation Acc 48.06 %\n",
      "Epoch:180/200 AVG Training Loss:0.677 AVG Validation Loss:0.690 AVG Training Acc 56.58 % AVG Validation Acc 48.24 %\n",
      "Epoch:190/200 AVG Training Loss:0.676 AVG Validation Loss:0.691 AVG Training Acc 56.20 % AVG Validation Acc 48.33 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:200/200 AVG Training Loss:0.677 AVG Validation Loss:0.692 AVG Training Acc 56.08 % AVG Validation Acc 47.88 %\n",
      "Split 22\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e565b4e3fec4be0b2d032294bd1987d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.652 AVG Validation Loss:4.636 AVG Training Acc 65.06 % AVG Validation Acc 38.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.679 AVG Validation Loss:6.245 AVG Training Acc 63.35 % AVG Validation Acc 38.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.676 AVG Validation Loss:1.224 AVG Training Acc 60.05 % AVG Validation Acc 38.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.755 AVG Validation Loss:4.680 AVG Training Acc 61.81 % AVG Validation Acc 38.14 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.691 AVG Validation Loss:0.712 AVG Training Acc 52.72 % AVG Validation Acc 44.18 %\n",
      "Epoch:60/200 AVG Training Loss:0.689 AVG Validation Loss:0.711 AVG Training Acc 52.91 % AVG Validation Acc 45.09 %\n",
      "Epoch:70/200 AVG Training Loss:0.687 AVG Validation Loss:0.711 AVG Training Acc 54.14 % AVG Validation Acc 45.00 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.687 AVG Validation Loss:0.704 AVG Training Acc 54.14 % AVG Validation Acc 47.07 %\n",
      "Epoch:90/200 AVG Training Loss:0.685 AVG Validation Loss:0.693 AVG Training Acc 55.16 % AVG Validation Acc 50.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.684 AVG Validation Loss:0.691 AVG Training Acc 54.91 % AVG Validation Acc 50.32 %\n",
      "Epoch:110/200 AVG Training Loss:0.684 AVG Validation Loss:0.690 AVG Training Acc 55.04 % AVG Validation Acc 50.86 %\n",
      "Epoch:120/200 AVG Training Loss:0.684 AVG Validation Loss:0.690 AVG Training Acc 55.21 % AVG Validation Acc 51.04 %\n",
      "Epoch:130/200 AVG Training Loss:0.683 AVG Validation Loss:0.689 AVG Training Acc 55.45 % AVG Validation Acc 51.13 %\n",
      "Epoch:140/200 AVG Training Loss:0.683 AVG Validation Loss:0.690 AVG Training Acc 55.32 % AVG Validation Acc 51.13 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.682 AVG Validation Loss:0.689 AVG Training Acc 55.23 % AVG Validation Acc 51.22 %\n",
      "Epoch:160/200 AVG Training Loss:0.682 AVG Validation Loss:0.689 AVG Training Acc 55.47 % AVG Validation Acc 51.49 %\n",
      "Epoch:170/200 AVG Training Loss:0.683 AVG Validation Loss:0.689 AVG Training Acc 55.38 % AVG Validation Acc 51.58 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:180/200 AVG Training Loss:0.683 AVG Validation Loss:0.689 AVG Training Acc 55.08 % AVG Validation Acc 51.58 %\n",
      "Epoch:190/200 AVG Training Loss:0.683 AVG Validation Loss:0.689 AVG Training Acc 55.04 % AVG Validation Acc 51.49 %\n",
      "Epoch:200/200 AVG Training Loss:0.682 AVG Validation Loss:0.689 AVG Training Acc 55.31 % AVG Validation Acc 51.40 %\n",
      "Split 23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c073e61743e448aa29a665bacdf3cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.655 AVG Validation Loss:2.728 AVG Training Acc 65.04 % AVG Validation Acc 38.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.674 AVG Validation Loss:1.293 AVG Training Acc 60.71 % AVG Validation Acc 38.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.691 AVG Validation Loss:1.298 AVG Training Acc 61.32 % AVG Validation Acc 38.14 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.697 AVG Validation Loss:0.791 AVG Training Acc 52.85 % AVG Validation Acc 38.50 %\n",
      "Epoch:50/200 AVG Training Loss:0.692 AVG Validation Loss:0.723 AVG Training Acc 52.71 % AVG Validation Acc 42.74 %\n",
      "Epoch:60/200 AVG Training Loss:0.691 AVG Validation Loss:0.715 AVG Training Acc 52.82 % AVG Validation Acc 43.37 %\n",
      "Epoch:70/200 AVG Training Loss:0.691 AVG Validation Loss:0.712 AVG Training Acc 52.55 % AVG Validation Acc 43.73 %\n",
      "Epoch:80/200 AVG Training Loss:0.686 AVG Validation Loss:0.712 AVG Training Acc 53.59 % AVG Validation Acc 45.09 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.688 AVG Validation Loss:0.714 AVG Training Acc 54.03 % AVG Validation Acc 45.99 %\n",
      "Epoch:100/200 AVG Training Loss:0.682 AVG Validation Loss:0.701 AVG Training Acc 55.41 % AVG Validation Acc 49.41 %\n",
      "Epoch:110/200 AVG Training Loss:0.682 AVG Validation Loss:0.698 AVG Training Acc 55.49 % AVG Validation Acc 49.86 %\n",
      "Epoch:120/200 AVG Training Loss:0.680 AVG Validation Loss:0.698 AVG Training Acc 55.56 % AVG Validation Acc 50.14 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.681 AVG Validation Loss:0.699 AVG Training Acc 56.08 % AVG Validation Acc 50.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.680 AVG Validation Loss:0.699 AVG Training Acc 55.84 % AVG Validation Acc 50.32 %\n",
      "Epoch:150/200 AVG Training Loss:0.680 AVG Validation Loss:0.699 AVG Training Acc 56.22 % AVG Validation Acc 50.23 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.680 AVG Validation Loss:0.699 AVG Training Acc 55.85 % AVG Validation Acc 50.23 %\n",
      "Epoch:170/200 AVG Training Loss:0.680 AVG Validation Loss:0.699 AVG Training Acc 55.97 % AVG Validation Acc 50.59 %\n",
      "Epoch:180/200 AVG Training Loss:0.681 AVG Validation Loss:0.699 AVG Training Acc 55.51 % AVG Validation Acc 50.50 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.679 AVG Validation Loss:0.699 AVG Training Acc 55.97 % AVG Validation Acc 50.32 %\n",
      "Epoch:200/200 AVG Training Loss:0.680 AVG Validation Loss:0.699 AVG Training Acc 55.97 % AVG Validation Acc 50.23 %\n",
      "Split 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a65468816f0e486d99ca653d6e931264",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.665 AVG Validation Loss:3.026 AVG Training Acc 63.85 % AVG Validation Acc 38.14 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:1.057 AVG Validation Loss:0.860 AVG Training Acc 49.74 % AVG Validation Acc 38.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.696 AVG Validation Loss:0.756 AVG Training Acc 52.08 % AVG Validation Acc 38.68 %\n",
      "Epoch:40/200 AVG Training Loss:0.694 AVG Validation Loss:0.737 AVG Training Acc 51.60 % AVG Validation Acc 39.13 %\n",
      "Epoch:50/200 AVG Training Loss:0.691 AVG Validation Loss:0.738 AVG Training Acc 52.57 % AVG Validation Acc 39.50 %\n",
      "Epoch:60/200 AVG Training Loss:0.686 AVG Validation Loss:0.739 AVG Training Acc 54.24 % AVG Validation Acc 39.40 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.683 AVG Validation Loss:0.708 AVG Training Acc 55.23 % AVG Validation Acc 47.88 %\n",
      "Epoch:80/200 AVG Training Loss:0.681 AVG Validation Loss:0.703 AVG Training Acc 55.68 % AVG Validation Acc 49.05 %\n",
      "Epoch:90/200 AVG Training Loss:0.681 AVG Validation Loss:0.702 AVG Training Acc 55.51 % AVG Validation Acc 49.32 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.680 AVG Validation Loss:0.703 AVG Training Acc 55.60 % AVG Validation Acc 49.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.680 AVG Validation Loss:0.702 AVG Training Acc 55.58 % AVG Validation Acc 49.23 %\n",
      "Epoch:120/200 AVG Training Loss:0.680 AVG Validation Loss:0.702 AVG Training Acc 55.99 % AVG Validation Acc 49.41 %\n",
      "Epoch:130/200 AVG Training Loss:0.679 AVG Validation Loss:0.702 AVG Training Acc 55.54 % AVG Validation Acc 49.41 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.679 AVG Validation Loss:0.702 AVG Training Acc 55.67 % AVG Validation Acc 49.41 %\n",
      "Epoch:150/200 AVG Training Loss:0.679 AVG Validation Loss:0.702 AVG Training Acc 55.71 % AVG Validation Acc 49.59 %\n",
      "Epoch:160/200 AVG Training Loss:0.679 AVG Validation Loss:0.702 AVG Training Acc 55.72 % AVG Validation Acc 49.59 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.679 AVG Validation Loss:0.702 AVG Training Acc 55.58 % AVG Validation Acc 49.32 %\n",
      "Epoch:180/200 AVG Training Loss:0.680 AVG Validation Loss:0.702 AVG Training Acc 55.65 % AVG Validation Acc 49.41 %\n",
      "Epoch:190/200 AVG Training Loss:0.679 AVG Validation Loss:0.702 AVG Training Acc 55.68 % AVG Validation Acc 49.68 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.680 AVG Validation Loss:0.702 AVG Training Acc 55.56 % AVG Validation Acc 49.50 %\n",
      "Split 25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42b1e797b20749999625a63d59144ad9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.654 AVG Validation Loss:4.409 AVG Training Acc 64.99 % AVG Validation Acc 38.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.688 AVG Validation Loss:7.016 AVG Training Acc 64.53 % AVG Validation Acc 38.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.662 AVG Validation Loss:1.649 AVG Training Acc 62.66 % AVG Validation Acc 38.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.659 AVG Validation Loss:2.171 AVG Training Acc 64.68 % AVG Validation Acc 38.14 %\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.695 AVG Validation Loss:0.729 AVG Training Acc 50.91 % AVG Validation Acc 39.68 %\n",
      "Epoch:60/200 AVG Training Loss:0.694 AVG Validation Loss:0.728 AVG Training Acc 51.68 % AVG Validation Acc 41.30 %\n",
      "Epoch:70/200 AVG Training Loss:0.694 AVG Validation Loss:0.728 AVG Training Acc 52.16 % AVG Validation Acc 41.93 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.693 AVG Validation Loss:0.710 AVG Training Acc 52.80 % AVG Validation Acc 44.63 %\n",
      "Epoch:90/200 AVG Training Loss:0.688 AVG Validation Loss:0.692 AVG Training Acc 54.15 % AVG Validation Acc 49.68 %\n",
      "Epoch:100/200 AVG Training Loss:0.688 AVG Validation Loss:0.689 AVG Training Acc 54.21 % AVG Validation Acc 51.40 %\n",
      "Epoch:110/200 AVG Training Loss:0.688 AVG Validation Loss:0.688 AVG Training Acc 54.18 % AVG Validation Acc 51.04 %\n",
      "Epoch:120/200 AVG Training Loss:0.687 AVG Validation Loss:0.688 AVG Training Acc 54.19 % AVG Validation Acc 51.13 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.687 AVG Validation Loss:0.687 AVG Training Acc 54.69 % AVG Validation Acc 51.04 %\n",
      "Epoch:140/200 AVG Training Loss:0.686 AVG Validation Loss:0.687 AVG Training Acc 54.79 % AVG Validation Acc 51.22 %\n",
      "Epoch:150/200 AVG Training Loss:0.685 AVG Validation Loss:0.687 AVG Training Acc 54.49 % AVG Validation Acc 51.58 %\n",
      "Epoch:160/200 AVG Training Loss:0.686 AVG Validation Loss:0.686 AVG Training Acc 54.74 % AVG Validation Acc 51.67 %\n",
      "Epoch:170/200 AVG Training Loss:0.686 AVG Validation Loss:0.686 AVG Training Acc 54.37 % AVG Validation Acc 51.94 %\n",
      "Epoch:180/200 AVG Training Loss:0.686 AVG Validation Loss:0.686 AVG Training Acc 55.09 % AVG Validation Acc 51.94 %\n",
      "Epoch:190/200 AVG Training Loss:0.687 AVG Validation Loss:0.686 AVG Training Acc 54.76 % AVG Validation Acc 52.39 %\n",
      "Epoch:200/200 AVG Training Loss:0.686 AVG Validation Loss:0.685 AVG Training Acc 54.11 % AVG Validation Acc 52.21 %\n",
      "Split 26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5c1f9302bf046a2ac5299f8d926a9d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.646 AVG Validation Loss:3.829 AVG Training Acc 64.80 % AVG Validation Acc 38.09 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.677 AVG Validation Loss:1.109 AVG Training Acc 59.43 % AVG Validation Acc 38.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.679 AVG Validation Loss:0.976 AVG Training Acc 58.28 % AVG Validation Acc 38.09 %\n",
      "Epoch:40/200 AVG Training Loss:0.669 AVG Validation Loss:1.019 AVG Training Acc 60.55 % AVG Validation Acc 38.00 %\n",
      "Epoch:50/200 AVG Training Loss:0.668 AVG Validation Loss:0.914 AVG Training Acc 60.31 % AVG Validation Acc 38.00 %\n",
      "Epoch:60/200 AVG Training Loss:0.675 AVG Validation Loss:0.860 AVG Training Acc 58.28 % AVG Validation Acc 37.91 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.720 AVG Validation Loss:0.756 AVG Training Acc 51.25 % AVG Validation Acc 39.26 %\n",
      "Epoch:80/200 AVG Training Loss:0.683 AVG Validation Loss:0.699 AVG Training Acc 54.99 % AVG Validation Acc 44.95 %\n",
      "Epoch:90/200 AVG Training Loss:0.682 AVG Validation Loss:0.699 AVG Training Acc 55.40 % AVG Validation Acc 44.77 %\n",
      "Epoch:100/200 AVG Training Loss:0.683 AVG Validation Loss:0.698 AVG Training Acc 55.38 % AVG Validation Acc 45.04 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.681 AVG Validation Loss:0.697 AVG Training Acc 55.85 % AVG Validation Acc 45.58 %\n",
      "Epoch:120/200 AVG Training Loss:0.680 AVG Validation Loss:0.694 AVG Training Acc 55.68 % AVG Validation Acc 46.93 %\n",
      "Epoch:130/200 AVG Training Loss:0.680 AVG Validation Loss:0.691 AVG Training Acc 55.66 % AVG Validation Acc 48.10 %\n",
      "Epoch:140/200 AVG Training Loss:0.681 AVG Validation Loss:0.691 AVG Training Acc 55.89 % AVG Validation Acc 48.10 %\n",
      "Epoch:150/200 AVG Training Loss:0.680 AVG Validation Loss:0.690 AVG Training Acc 55.87 % AVG Validation Acc 48.65 %\n",
      "Epoch:160/200 AVG Training Loss:0.681 AVG Validation Loss:0.691 AVG Training Acc 55.85 % AVG Validation Acc 48.56 %\n",
      "Epoch   168: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:170/200 AVG Training Loss:0.681 AVG Validation Loss:0.691 AVG Training Acc 56.04 % AVG Validation Acc 48.47 %\n",
      "Epoch:180/200 AVG Training Loss:0.681 AVG Validation Loss:0.690 AVG Training Acc 55.89 % AVG Validation Acc 48.56 %\n",
      "Epoch:190/200 AVG Training Loss:0.680 AVG Validation Loss:0.692 AVG Training Acc 56.09 % AVG Validation Acc 48.83 %\n",
      "Epoch   199: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:200/200 AVG Training Loss:0.679 AVG Validation Loss:0.691 AVG Training Acc 56.09 % AVG Validation Acc 48.38 %\n",
      "Split 27\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b6818b22532457e9b5ee80103d88e10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:3.765 AVG Training Acc 63.28 % AVG Validation Acc 38.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.674 AVG Validation Loss:1.305 AVG Training Acc 60.87 % AVG Validation Acc 38.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.677 AVG Validation Loss:1.279 AVG Training Acc 60.83 % AVG Validation Acc 38.09 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.711 AVG Validation Loss:0.745 AVG Training Acc 49.26 % AVG Validation Acc 38.63 %\n",
      "Epoch:50/200 AVG Training Loss:0.696 AVG Validation Loss:0.724 AVG Training Acc 50.85 % AVG Validation Acc 39.53 %\n",
      "Epoch:60/200 AVG Training Loss:0.691 AVG Validation Loss:0.724 AVG Training Acc 53.29 % AVG Validation Acc 42.51 %\n",
      "Epoch:70/200 AVG Training Loss:0.691 AVG Validation Loss:0.721 AVG Training Acc 52.90 % AVG Validation Acc 43.95 %\n",
      "Epoch:80/200 AVG Training Loss:0.690 AVG Validation Loss:0.721 AVG Training Acc 53.46 % AVG Validation Acc 45.22 %\n",
      "Epoch:90/200 AVG Training Loss:0.689 AVG Validation Loss:0.719 AVG Training Acc 53.10 % AVG Validation Acc 45.67 %\n",
      "Epoch:100/200 AVG Training Loss:0.687 AVG Validation Loss:0.721 AVG Training Acc 54.69 % AVG Validation Acc 46.12 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:110/200 AVG Training Loss:0.684 AVG Validation Loss:0.701 AVG Training Acc 55.21 % AVG Validation Acc 48.92 %\n",
      "Epoch:120/200 AVG Training Loss:0.683 AVG Validation Loss:0.695 AVG Training Acc 55.71 % AVG Validation Acc 49.91 %\n",
      "Epoch:130/200 AVG Training Loss:0.682 AVG Validation Loss:0.694 AVG Training Acc 55.51 % AVG Validation Acc 50.45 %\n",
      "Epoch:140/200 AVG Training Loss:0.683 AVG Validation Loss:0.694 AVG Training Acc 55.38 % AVG Validation Acc 50.27 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.681 AVG Validation Loss:0.693 AVG Training Acc 55.78 % AVG Validation Acc 49.91 %\n",
      "Epoch:160/200 AVG Training Loss:0.681 AVG Validation Loss:0.693 AVG Training Acc 55.74 % AVG Validation Acc 50.09 %\n",
      "Epoch:170/200 AVG Training Loss:0.682 AVG Validation Loss:0.693 AVG Training Acc 55.48 % AVG Validation Acc 50.18 %\n",
      "Epoch:180/200 AVG Training Loss:0.682 AVG Validation Loss:0.693 AVG Training Acc 55.61 % AVG Validation Acc 50.09 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:190/200 AVG Training Loss:0.682 AVG Validation Loss:0.693 AVG Training Acc 55.43 % AVG Validation Acc 50.18 %\n",
      "Epoch:200/200 AVG Training Loss:0.683 AVG Validation Loss:0.693 AVG Training Acc 55.64 % AVG Validation Acc 50.09 %\n",
      "Split 28\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed7342afc9d746d5ab5efa963e3d6ed8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.652 AVG Validation Loss:3.258 AVG Training Acc 65.77 % AVG Validation Acc 38.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.677 AVG Validation Loss:1.843 AVG Training Acc 62.94 % AVG Validation Acc 38.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.687 AVG Validation Loss:1.391 AVG Training Acc 62.67 % AVG Validation Acc 38.09 %\n",
      "Epoch:40/200 AVG Training Loss:0.830 AVG Validation Loss:5.858 AVG Training Acc 63.57 % AVG Validation Acc 38.09 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.748 AVG Validation Loss:0.770 AVG Training Acc 50.18 % AVG Validation Acc 38.09 %\n",
      "Epoch:60/200 AVG Training Loss:0.691 AVG Validation Loss:0.705 AVG Training Acc 52.17 % AVG Validation Acc 46.21 %\n",
      "Epoch:70/200 AVG Training Loss:0.690 AVG Validation Loss:0.705 AVG Training Acc 52.79 % AVG Validation Acc 47.11 %\n",
      "Epoch:80/200 AVG Training Loss:0.689 AVG Validation Loss:0.705 AVG Training Acc 52.71 % AVG Validation Acc 47.11 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.687 AVG Validation Loss:0.696 AVG Training Acc 53.88 % AVG Validation Acc 48.74 %\n",
      "Epoch:100/200 AVG Training Loss:0.686 AVG Validation Loss:0.690 AVG Training Acc 54.25 % AVG Validation Acc 51.44 %\n",
      "Epoch:110/200 AVG Training Loss:0.685 AVG Validation Loss:0.688 AVG Training Acc 54.62 % AVG Validation Acc 52.71 %\n",
      "Epoch:120/200 AVG Training Loss:0.685 AVG Validation Loss:0.688 AVG Training Acc 54.36 % AVG Validation Acc 52.80 %\n",
      "Epoch:130/200 AVG Training Loss:0.684 AVG Validation Loss:0.687 AVG Training Acc 55.13 % AVG Validation Acc 53.07 %\n",
      "Epoch:140/200 AVG Training Loss:0.684 AVG Validation Loss:0.687 AVG Training Acc 54.60 % AVG Validation Acc 53.25 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.683 AVG Validation Loss:0.687 AVG Training Acc 55.35 % AVG Validation Acc 53.34 %\n",
      "Epoch:160/200 AVG Training Loss:0.684 AVG Validation Loss:0.687 AVG Training Acc 54.96 % AVG Validation Acc 53.43 %\n",
      "New Best Accuracy found: 53.79%\n",
      "Epoch: 164\n",
      "Epoch:170/200 AVG Training Loss:0.684 AVG Validation Loss:0.686 AVG Training Acc 54.63 % AVG Validation Acc 53.70 %\n",
      "Epoch:180/200 AVG Training Loss:0.684 AVG Validation Loss:0.686 AVG Training Acc 54.89 % AVG Validation Acc 53.43 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:190/200 AVG Training Loss:0.685 AVG Validation Loss:0.686 AVG Training Acc 54.90 % AVG Validation Acc 53.25 %\n",
      "Epoch:200/200 AVG Training Loss:0.684 AVG Validation Loss:0.686 AVG Training Acc 55.08 % AVG Validation Acc 53.61 %\n",
      "Split 29\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1837f3b1dbe64df88f7434d30bea73ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.634 AVG Validation Loss:6.420 AVG Training Acc 66.11 % AVG Validation Acc 38.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:2.040 AVG Training Acc 64.32 % AVG Validation Acc 38.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:3.047 AVG Training Acc 65.77 % AVG Validation Acc 38.09 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.693 AVG Validation Loss:0.758 AVG Training Acc 52.35 % AVG Validation Acc 39.17 %\n",
      "Epoch:50/200 AVG Training Loss:0.690 AVG Validation Loss:0.764 AVG Training Acc 53.94 % AVG Validation Acc 40.07 %\n",
      "Epoch:60/200 AVG Training Loss:0.686 AVG Validation Loss:0.766 AVG Training Acc 54.91 % AVG Validation Acc 40.25 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.685 AVG Validation Loss:0.708 AVG Training Acc 54.66 % AVG Validation Acc 45.94 %\n",
      "Epoch:80/200 AVG Training Loss:0.682 AVG Validation Loss:0.700 AVG Training Acc 55.54 % AVG Validation Acc 47.56 %\n",
      "Epoch:90/200 AVG Training Loss:0.680 AVG Validation Loss:0.700 AVG Training Acc 55.47 % AVG Validation Acc 47.74 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.679 AVG Validation Loss:0.700 AVG Training Acc 55.78 % AVG Validation Acc 48.01 %\n",
      "Epoch:110/200 AVG Training Loss:0.681 AVG Validation Loss:0.700 AVG Training Acc 55.41 % AVG Validation Acc 47.83 %\n",
      "Epoch:120/200 AVG Training Loss:0.680 AVG Validation Loss:0.699 AVG Training Acc 56.19 % AVG Validation Acc 47.56 %\n",
      "Epoch:130/200 AVG Training Loss:0.679 AVG Validation Loss:0.700 AVG Training Acc 55.94 % AVG Validation Acc 47.92 %\n",
      "Epoch   137: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.680 AVG Validation Loss:0.699 AVG Training Acc 55.45 % AVG Validation Acc 47.74 %\n",
      "Epoch:150/200 AVG Training Loss:0.680 AVG Validation Loss:0.700 AVG Training Acc 56.01 % AVG Validation Acc 48.10 %\n",
      "Epoch:160/200 AVG Training Loss:0.679 AVG Validation Loss:0.699 AVG Training Acc 55.74 % AVG Validation Acc 48.10 %\n",
      "Epoch   168: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.680 AVG Validation Loss:0.699 AVG Training Acc 55.69 % AVG Validation Acc 47.92 %\n",
      "Epoch:180/200 AVG Training Loss:0.680 AVG Validation Loss:0.699 AVG Training Acc 55.73 % AVG Validation Acc 48.01 %\n",
      "Epoch:190/200 AVG Training Loss:0.678 AVG Validation Loss:0.700 AVG Training Acc 56.10 % AVG Validation Acc 47.74 %\n",
      "Epoch   199: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.679 AVG Validation Loss:0.699 AVG Training Acc 55.64 % AVG Validation Acc 47.74 %\n",
      "Split 30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37167a8b7d3a433aaa9659a80cbd2355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.611 AVG Validation Loss:5.254 AVG Training Acc 64.87 % AVG Validation Acc 38.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:1.936 AVG Training Acc 63.88 % AVG Validation Acc 38.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.733 AVG Validation Loss:2.852 AVG Training Acc 62.97 % AVG Validation Acc 38.09 %\n",
      "Epoch:40/200 AVG Training Loss:0.650 AVG Validation Loss:2.283 AVG Training Acc 64.49 % AVG Validation Acc 38.09 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.684 AVG Validation Loss:0.860 AVG Training Acc 55.20 % AVG Validation Acc 38.18 %\n",
      "Epoch:60/200 AVG Training Loss:0.695 AVG Validation Loss:0.747 AVG Training Acc 52.73 % AVG Validation Acc 38.63 %\n",
      "Epoch:70/200 AVG Training Loss:0.684 AVG Validation Loss:0.768 AVG Training Acc 55.82 % AVG Validation Acc 38.99 %\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.686 AVG Validation Loss:0.700 AVG Training Acc 54.19 % AVG Validation Acc 47.65 %\n",
      "Epoch:90/200 AVG Training Loss:0.685 AVG Validation Loss:0.692 AVG Training Acc 54.62 % AVG Validation Acc 51.26 %\n",
      "Epoch:100/200 AVG Training Loss:0.684 AVG Validation Loss:0.692 AVG Training Acc 54.98 % AVG Validation Acc 50.63 %\n",
      "Epoch:110/200 AVG Training Loss:0.684 AVG Validation Loss:0.692 AVG Training Acc 54.94 % AVG Validation Acc 50.63 %\n",
      "Epoch:120/200 AVG Training Loss:0.683 AVG Validation Loss:0.691 AVG Training Acc 55.04 % AVG Validation Acc 50.54 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.681 AVG Validation Loss:0.690 AVG Training Acc 55.35 % AVG Validation Acc 50.99 %\n",
      "Epoch:140/200 AVG Training Loss:0.683 AVG Validation Loss:0.689 AVG Training Acc 55.29 % AVG Validation Acc 51.26 %\n",
      "Epoch:150/200 AVG Training Loss:0.682 AVG Validation Loss:0.688 AVG Training Acc 54.70 % AVG Validation Acc 51.53 %\n",
      "Epoch:160/200 AVG Training Loss:0.683 AVG Validation Loss:0.688 AVG Training Acc 55.10 % AVG Validation Acc 51.08 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:170/200 AVG Training Loss:0.682 AVG Validation Loss:0.688 AVG Training Acc 54.84 % AVG Validation Acc 51.17 %\n",
      "Epoch:180/200 AVG Training Loss:0.682 AVG Validation Loss:0.688 AVG Training Acc 55.42 % AVG Validation Acc 51.44 %\n",
      "Epoch:190/200 AVG Training Loss:0.681 AVG Validation Loss:0.687 AVG Training Acc 55.64 % AVG Validation Acc 50.90 %\n",
      "Epoch:200/200 AVG Training Loss:0.682 AVG Validation Loss:0.688 AVG Training Acc 54.92 % AVG Validation Acc 50.90 %\n",
      "Split 31\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "673772b2bcca410e8d1f772f996fe373",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.644 AVG Validation Loss:5.249 AVG Training Acc 66.27 % AVG Validation Acc 38.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.669 AVG Validation Loss:3.293 AVG Training Acc 65.44 % AVG Validation Acc 38.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.673 AVG Validation Loss:1.295 AVG Training Acc 60.82 % AVG Validation Acc 38.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.665 AVG Validation Loss:2.977 AVG Training Acc 63.59 % AVG Validation Acc 38.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.675 AVG Validation Loss:1.274 AVG Training Acc 60.03 % AVG Validation Acc 38.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.673 AVG Validation Loss:1.217 AVG Training Acc 60.37 % AVG Validation Acc 38.05 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:70/200 AVG Training Loss:0.707 AVG Validation Loss:0.732 AVG Training Acc 51.51 % AVG Validation Acc 40.94 %\n",
      "Epoch:80/200 AVG Training Loss:0.689 AVG Validation Loss:0.707 AVG Training Acc 53.42 % AVG Validation Acc 46.98 %\n",
      "Epoch:90/200 AVG Training Loss:0.689 AVG Validation Loss:0.707 AVG Training Acc 53.62 % AVG Validation Acc 47.16 %\n",
      "Epoch:100/200 AVG Training Loss:0.687 AVG Validation Loss:0.706 AVG Training Acc 53.75 % AVG Validation Acc 47.07 %\n",
      "Epoch:110/200 AVG Training Loss:0.686 AVG Validation Loss:0.706 AVG Training Acc 54.58 % AVG Validation Acc 46.17 %\n",
      "Epoch:120/200 AVG Training Loss:0.685 AVG Validation Loss:0.707 AVG Training Acc 54.54 % AVG Validation Acc 46.08 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:130/200 AVG Training Loss:0.682 AVG Validation Loss:0.698 AVG Training Acc 55.39 % AVG Validation Acc 48.60 %\n",
      "Epoch:140/200 AVG Training Loss:0.681 AVG Validation Loss:0.693 AVG Training Acc 55.79 % AVG Validation Acc 49.95 %\n",
      "Epoch:150/200 AVG Training Loss:0.681 AVG Validation Loss:0.691 AVG Training Acc 55.43 % AVG Validation Acc 50.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.680 AVG Validation Loss:0.691 AVG Training Acc 55.63 % AVG Validation Acc 50.95 %\n",
      "Epoch:170/200 AVG Training Loss:0.681 AVG Validation Loss:0.691 AVG Training Acc 55.81 % AVG Validation Acc 51.04 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:180/200 AVG Training Loss:0.680 AVG Validation Loss:0.691 AVG Training Acc 55.81 % AVG Validation Acc 50.50 %\n",
      "Epoch:190/200 AVG Training Loss:0.680 AVG Validation Loss:0.691 AVG Training Acc 56.20 % AVG Validation Acc 50.86 %\n",
      "Epoch:200/200 AVG Training Loss:0.681 AVG Validation Loss:0.691 AVG Training Acc 56.03 % AVG Validation Acc 50.86 %\n",
      "Split 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fcbf46bd5f74be8a99ef641a5271476",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.653 AVG Validation Loss:6.100 AVG Training Acc 65.61 % AVG Validation Acc 38.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:4.225 AVG Training Acc 63.43 % AVG Validation Acc 38.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.665 AVG Validation Loss:1.794 AVG Training Acc 63.59 % AVG Validation Acc 38.14 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.699 AVG Validation Loss:0.734 AVG Training Acc 50.92 % AVG Validation Acc 38.59 %\n",
      "Epoch:50/200 AVG Training Loss:0.696 AVG Validation Loss:0.726 AVG Training Acc 51.10 % AVG Validation Acc 38.50 %\n",
      "Epoch:60/200 AVG Training Loss:0.694 AVG Validation Loss:0.720 AVG Training Acc 51.59 % AVG Validation Acc 38.95 %\n",
      "Epoch:70/200 AVG Training Loss:0.691 AVG Validation Loss:0.718 AVG Training Acc 52.10 % AVG Validation Acc 44.18 %\n",
      "Epoch:80/200 AVG Training Loss:0.689 AVG Validation Loss:0.717 AVG Training Acc 53.47 % AVG Validation Acc 45.90 %\n",
      "Epoch:90/200 AVG Training Loss:0.688 AVG Validation Loss:0.714 AVG Training Acc 53.34 % AVG Validation Acc 47.16 %\n",
      "Epoch:100/200 AVG Training Loss:0.687 AVG Validation Loss:0.714 AVG Training Acc 54.44 % AVG Validation Acc 47.07 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:110/200 AVG Training Loss:0.684 AVG Validation Loss:0.702 AVG Training Acc 55.23 % AVG Validation Acc 51.49 %\n",
      "Epoch:120/200 AVG Training Loss:0.682 AVG Validation Loss:0.695 AVG Training Acc 55.81 % AVG Validation Acc 52.84 %\n",
      "Epoch:130/200 AVG Training Loss:0.683 AVG Validation Loss:0.694 AVG Training Acc 54.94 % AVG Validation Acc 53.29 %\n",
      "Epoch:140/200 AVG Training Loss:0.681 AVG Validation Loss:0.693 AVG Training Acc 55.27 % AVG Validation Acc 53.65 %\n",
      "Epoch:150/200 AVG Training Loss:0.681 AVG Validation Loss:0.693 AVG Training Acc 55.71 % AVG Validation Acc 53.65 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:160/200 AVG Training Loss:0.680 AVG Validation Loss:0.693 AVG Training Acc 55.96 % AVG Validation Acc 53.47 %\n",
      "Epoch:170/200 AVG Training Loss:0.680 AVG Validation Loss:0.692 AVG Training Acc 55.25 % AVG Validation Acc 53.47 %\n",
      "Epoch:180/200 AVG Training Loss:0.680 AVG Validation Loss:0.693 AVG Training Acc 55.65 % AVG Validation Acc 53.38 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:190/200 AVG Training Loss:0.681 AVG Validation Loss:0.692 AVG Training Acc 55.63 % AVG Validation Acc 53.47 %\n",
      "New Best Accuracy found: 53.92%\n",
      "Epoch: 196\n",
      "Epoch:200/200 AVG Training Loss:0.679 AVG Validation Loss:0.692 AVG Training Acc 55.69 % AVG Validation Acc 53.29 %\n",
      "Split 33\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57cfec3b2e1f461ebcba7c45da07c329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.648 AVG Validation Loss:4.482 AVG Training Acc 66.11 % AVG Validation Acc 38.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.664 AVG Validation Loss:1.984 AVG Training Acc 63.09 % AVG Validation Acc 38.14 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.733 AVG Validation Loss:0.759 AVG Training Acc 48.94 % AVG Validation Acc 38.23 %\n",
      "Epoch:40/200 AVG Training Loss:0.695 AVG Validation Loss:0.730 AVG Training Acc 51.52 % AVG Validation Acc 38.77 %\n",
      "Epoch:50/200 AVG Training Loss:0.692 AVG Validation Loss:0.728 AVG Training Acc 52.30 % AVG Validation Acc 39.68 %\n",
      "Epoch:60/200 AVG Training Loss:0.691 AVG Validation Loss:0.725 AVG Training Acc 52.72 % AVG Validation Acc 41.66 %\n",
      "Epoch:70/200 AVG Training Loss:0.690 AVG Validation Loss:0.723 AVG Training Acc 53.32 % AVG Validation Acc 42.92 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.687 AVG Validation Loss:0.711 AVG Training Acc 54.53 % AVG Validation Acc 46.08 %\n",
      "Epoch:90/200 AVG Training Loss:0.684 AVG Validation Loss:0.699 AVG Training Acc 55.23 % AVG Validation Acc 48.33 %\n",
      "Epoch:100/200 AVG Training Loss:0.683 AVG Validation Loss:0.698 AVG Training Acc 55.48 % AVG Validation Acc 48.24 %\n",
      "Epoch:110/200 AVG Training Loss:0.683 AVG Validation Loss:0.698 AVG Training Acc 55.33 % AVG Validation Acc 48.42 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.682 AVG Validation Loss:0.698 AVG Training Acc 55.37 % AVG Validation Acc 48.51 %\n",
      "Epoch:130/200 AVG Training Loss:0.682 AVG Validation Loss:0.698 AVG Training Acc 55.60 % AVG Validation Acc 48.69 %\n",
      "Epoch:140/200 AVG Training Loss:0.683 AVG Validation Loss:0.698 AVG Training Acc 55.41 % AVG Validation Acc 48.60 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.682 AVG Validation Loss:0.698 AVG Training Acc 55.51 % AVG Validation Acc 48.51 %\n",
      "Epoch:160/200 AVG Training Loss:0.683 AVG Validation Loss:0.698 AVG Training Acc 55.64 % AVG Validation Acc 48.69 %\n",
      "Epoch:170/200 AVG Training Loss:0.682 AVG Validation Loss:0.698 AVG Training Acc 55.61 % AVG Validation Acc 48.60 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.683 AVG Validation Loss:0.698 AVG Training Acc 55.21 % AVG Validation Acc 48.60 %\n",
      "Epoch:190/200 AVG Training Loss:0.683 AVG Validation Loss:0.698 AVG Training Acc 55.32 % AVG Validation Acc 48.60 %\n",
      "Epoch:200/200 AVG Training Loss:0.683 AVG Validation Loss:0.698 AVG Training Acc 55.34 % AVG Validation Acc 48.51 %\n",
      "Split 34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "796cddee748c4114b168169f90463e20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:5.281 AVG Training Acc 64.68 % AVG Validation Acc 38.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.682 AVG Validation Loss:4.078 AVG Training Acc 64.27 % AVG Validation Acc 38.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.676 AVG Validation Loss:1.244 AVG Training Acc 59.77 % AVG Validation Acc 38.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:2.899 AVG Training Acc 63.26 % AVG Validation Acc 38.14 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.752 AVG Validation Loss:0.778 AVG Training Acc 50.03 % AVG Validation Acc 38.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.692 AVG Validation Loss:0.708 AVG Training Acc 51.91 % AVG Validation Acc 45.18 %\n",
      "Epoch:70/200 AVG Training Loss:0.690 AVG Validation Loss:0.711 AVG Training Acc 52.95 % AVG Validation Acc 46.35 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.688 AVG Validation Loss:0.718 AVG Training Acc 54.41 % AVG Validation Acc 47.52 %\n",
      "Epoch:90/200 AVG Training Loss:0.685 AVG Validation Loss:0.706 AVG Training Acc 55.00 % AVG Validation Acc 49.86 %\n",
      "Epoch:100/200 AVG Training Loss:0.686 AVG Validation Loss:0.702 AVG Training Acc 54.96 % AVG Validation Acc 50.50 %\n",
      "Epoch:110/200 AVG Training Loss:0.685 AVG Validation Loss:0.702 AVG Training Acc 55.19 % AVG Validation Acc 50.50 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.685 AVG Validation Loss:0.702 AVG Training Acc 55.47 % AVG Validation Acc 50.95 %\n",
      "Epoch:130/200 AVG Training Loss:0.684 AVG Validation Loss:0.702 AVG Training Acc 55.10 % AVG Validation Acc 50.77 %\n",
      "Epoch:140/200 AVG Training Loss:0.684 AVG Validation Loss:0.702 AVG Training Acc 55.57 % AVG Validation Acc 50.95 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.685 AVG Validation Loss:0.702 AVG Training Acc 55.51 % AVG Validation Acc 50.86 %\n",
      "Epoch:160/200 AVG Training Loss:0.685 AVG Validation Loss:0.702 AVG Training Acc 55.72 % AVG Validation Acc 50.95 %\n",
      "Epoch:170/200 AVG Training Loss:0.683 AVG Validation Loss:0.702 AVG Training Acc 55.68 % AVG Validation Acc 51.04 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.684 AVG Validation Loss:0.702 AVG Training Acc 55.37 % AVG Validation Acc 50.77 %\n",
      "Epoch:190/200 AVG Training Loss:0.684 AVG Validation Loss:0.702 AVG Training Acc 55.36 % AVG Validation Acc 50.95 %\n",
      "Epoch:200/200 AVG Training Loss:0.685 AVG Validation Loss:0.702 AVG Training Acc 55.25 % AVG Validation Acc 51.49 %\n",
      "Split 35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce294d2ed65c489d9117ba8fbced0af0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.638 AVG Validation Loss:4.694 AVG Training Acc 65.08 % AVG Validation Acc 38.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.645 AVG Validation Loss:4.205 AVG Training Acc 65.43 % AVG Validation Acc 38.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.676 AVG Validation Loss:1.226 AVG Training Acc 60.06 % AVG Validation Acc 38.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.677 AVG Validation Loss:1.278 AVG Training Acc 61.25 % AVG Validation Acc 38.14 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.697 AVG Validation Loss:0.819 AVG Training Acc 53.72 % AVG Validation Acc 38.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.693 AVG Validation Loss:0.767 AVG Training Acc 53.68 % AVG Validation Acc 38.77 %\n",
      "Epoch:70/200 AVG Training Loss:0.691 AVG Validation Loss:0.742 AVG Training Acc 53.25 % AVG Validation Acc 38.95 %\n",
      "Epoch:80/200 AVG Training Loss:0.688 AVG Validation Loss:0.732 AVG Training Acc 53.78 % AVG Validation Acc 39.77 %\n",
      "Epoch:90/200 AVG Training Loss:0.685 AVG Validation Loss:0.726 AVG Training Acc 53.88 % AVG Validation Acc 40.22 %\n",
      "Epoch:100/200 AVG Training Loss:0.683 AVG Validation Loss:0.726 AVG Training Acc 54.06 % AVG Validation Acc 40.13 %\n",
      "Epoch:110/200 AVG Training Loss:0.683 AVG Validation Loss:0.724 AVG Training Acc 54.32 % AVG Validation Acc 40.76 %\n",
      "Epoch:120/200 AVG Training Loss:0.682 AVG Validation Loss:0.724 AVG Training Acc 54.45 % AVG Validation Acc 40.94 %\n",
      "Epoch:130/200 AVG Training Loss:0.680 AVG Validation Loss:0.723 AVG Training Acc 54.86 % AVG Validation Acc 41.84 %\n",
      "Epoch   135: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:140/200 AVG Training Loss:0.679 AVG Validation Loss:0.704 AVG Training Acc 55.52 % AVG Validation Acc 47.61 %\n",
      "Epoch:150/200 AVG Training Loss:0.677 AVG Validation Loss:0.695 AVG Training Acc 55.92 % AVG Validation Acc 49.41 %\n",
      "Epoch:160/200 AVG Training Loss:0.676 AVG Validation Loss:0.693 AVG Training Acc 56.23 % AVG Validation Acc 49.59 %\n",
      "Epoch:170/200 AVG Training Loss:0.675 AVG Validation Loss:0.694 AVG Training Acc 56.30 % AVG Validation Acc 49.77 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:180/200 AVG Training Loss:0.676 AVG Validation Loss:0.693 AVG Training Acc 55.94 % AVG Validation Acc 49.77 %\n",
      "Epoch:190/200 AVG Training Loss:0.675 AVG Validation Loss:0.692 AVG Training Acc 55.89 % AVG Validation Acc 49.95 %\n",
      "Epoch:200/200 AVG Training Loss:0.675 AVG Validation Loss:0.692 AVG Training Acc 56.02 % AVG Validation Acc 50.05 %\n",
      "Split 36\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17c1a5dd12694ed2b7f49456735a7d1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:3.506 AVG Training Acc 65.73 % AVG Validation Acc 38.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:4.013 AVG Training Acc 63.13 % AVG Validation Acc 38.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.669 AVG Validation Loss:2.212 AVG Training Acc 64.81 % AVG Validation Acc 38.09 %\n",
      "Epoch:40/200 AVG Training Loss:0.764 AVG Validation Loss:4.106 AVG Training Acc 64.28 % AVG Validation Acc 38.09 %\n",
      "Epoch:50/200 AVG Training Loss:0.676 AVG Validation Loss:1.203 AVG Training Acc 60.02 % AVG Validation Acc 38.09 %\n",
      "Epoch:60/200 AVG Training Loss:0.674 AVG Validation Loss:1.218 AVG Training Acc 60.24 % AVG Validation Acc 38.09 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:70/200 AVG Training Loss:0.690 AVG Validation Loss:0.706 AVG Training Acc 53.32 % AVG Validation Acc 47.74 %\n",
      "Epoch:80/200 AVG Training Loss:0.689 AVG Validation Loss:0.706 AVG Training Acc 53.34 % AVG Validation Acc 47.56 %\n",
      "Epoch:90/200 AVG Training Loss:0.688 AVG Validation Loss:0.706 AVG Training Acc 54.01 % AVG Validation Acc 46.93 %\n",
      "Epoch:100/200 AVG Training Loss:0.688 AVG Validation Loss:0.706 AVG Training Acc 53.89 % AVG Validation Acc 47.02 %\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:110/200 AVG Training Loss:0.685 AVG Validation Loss:0.696 AVG Training Acc 54.87 % AVG Validation Acc 49.73 %\n",
      "Epoch:120/200 AVG Training Loss:0.685 AVG Validation Loss:0.691 AVG Training Acc 54.68 % AVG Validation Acc 52.08 %\n",
      "Epoch:130/200 AVG Training Loss:0.683 AVG Validation Loss:0.689 AVG Training Acc 55.00 % AVG Validation Acc 52.53 %\n",
      "Epoch:140/200 AVG Training Loss:0.684 AVG Validation Loss:0.688 AVG Training Acc 55.08 % AVG Validation Acc 52.98 %\n",
      "Epoch:150/200 AVG Training Loss:0.684 AVG Validation Loss:0.688 AVG Training Acc 54.91 % AVG Validation Acc 52.71 %\n",
      "Epoch:160/200 AVG Training Loss:0.685 AVG Validation Loss:0.688 AVG Training Acc 54.91 % AVG Validation Acc 52.89 %\n",
      "Epoch   164: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:170/200 AVG Training Loss:0.684 AVG Validation Loss:0.688 AVG Training Acc 54.85 % AVG Validation Acc 52.80 %\n",
      "Epoch:180/200 AVG Training Loss:0.683 AVG Validation Loss:0.688 AVG Training Acc 55.26 % AVG Validation Acc 52.71 %\n",
      "Epoch:190/200 AVG Training Loss:0.682 AVG Validation Loss:0.688 AVG Training Acc 55.40 % AVG Validation Acc 52.80 %\n",
      "Epoch   195: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:200/200 AVG Training Loss:0.683 AVG Validation Loss:0.688 AVG Training Acc 55.37 % AVG Validation Acc 52.89 %\n",
      "Split 37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21148374366455099d9a76ad30ed174",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:2.584 AVG Training Acc 64.02 % AVG Validation Acc 38.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:5.494 AVG Training Acc 62.34 % AVG Validation Acc 38.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.676 AVG Validation Loss:1.213 AVG Training Acc 59.88 % AVG Validation Acc 38.09 %\n",
      "Epoch:40/200 AVG Training Loss:0.672 AVG Validation Loss:2.132 AVG Training Acc 60.15 % AVG Validation Acc 38.09 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.692 AVG Validation Loss:0.712 AVG Training Acc 52.23 % AVG Validation Acc 43.32 %\n",
      "Epoch:60/200 AVG Training Loss:0.691 AVG Validation Loss:0.711 AVG Training Acc 52.53 % AVG Validation Acc 43.50 %\n",
      "Epoch:70/200 AVG Training Loss:0.689 AVG Validation Loss:0.711 AVG Training Acc 53.30 % AVG Validation Acc 44.95 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.687 AVG Validation Loss:0.700 AVG Training Acc 54.53 % AVG Validation Acc 47.83 %\n",
      "Epoch:90/200 AVG Training Loss:0.686 AVG Validation Loss:0.693 AVG Training Acc 54.89 % AVG Validation Acc 50.27 %\n",
      "Epoch:100/200 AVG Training Loss:0.685 AVG Validation Loss:0.691 AVG Training Acc 54.95 % AVG Validation Acc 50.81 %\n",
      "Epoch:110/200 AVG Training Loss:0.685 AVG Validation Loss:0.691 AVG Training Acc 54.51 % AVG Validation Acc 50.81 %\n",
      "Epoch:120/200 AVG Training Loss:0.685 AVG Validation Loss:0.691 AVG Training Acc 54.59 % AVG Validation Acc 50.72 %\n",
      "Epoch:130/200 AVG Training Loss:0.686 AVG Validation Loss:0.690 AVG Training Acc 54.88 % AVG Validation Acc 50.90 %\n",
      "Epoch:140/200 AVG Training Loss:0.685 AVG Validation Loss:0.690 AVG Training Acc 54.90 % AVG Validation Acc 50.72 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.684 AVG Validation Loss:0.690 AVG Training Acc 55.00 % AVG Validation Acc 50.54 %\n",
      "Epoch:160/200 AVG Training Loss:0.685 AVG Validation Loss:0.690 AVG Training Acc 54.94 % AVG Validation Acc 50.81 %\n",
      "Epoch:170/200 AVG Training Loss:0.685 AVG Validation Loss:0.690 AVG Training Acc 54.78 % AVG Validation Acc 50.81 %\n",
      "Epoch:180/200 AVG Training Loss:0.684 AVG Validation Loss:0.690 AVG Training Acc 55.18 % AVG Validation Acc 50.54 %\n",
      "Epoch:190/200 AVG Training Loss:0.685 AVG Validation Loss:0.690 AVG Training Acc 55.05 % AVG Validation Acc 50.81 %\n",
      "Epoch   196: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:200/200 AVG Training Loss:0.684 AVG Validation Loss:0.690 AVG Training Acc 55.13 % AVG Validation Acc 50.72 %\n",
      "Split 38\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc874c85133e455d9d87437080183029",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.654 AVG Validation Loss:3.566 AVG Training Acc 63.76 % AVG Validation Acc 38.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:6.942 AVG Training Acc 62.49 % AVG Validation Acc 38.09 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.763 AVG Validation Loss:0.787 AVG Training Acc 49.92 % AVG Validation Acc 38.18 %\n",
      "Epoch:40/200 AVG Training Loss:0.693 AVG Validation Loss:0.717 AVG Training Acc 51.30 % AVG Validation Acc 39.80 %\n",
      "Epoch:50/200 AVG Training Loss:0.693 AVG Validation Loss:0.718 AVG Training Acc 51.69 % AVG Validation Acc 39.98 %\n",
      "Epoch:60/200 AVG Training Loss:0.691 AVG Validation Loss:0.717 AVG Training Acc 52.55 % AVG Validation Acc 41.06 %\n",
      "Epoch:70/200 AVG Training Loss:0.689 AVG Validation Loss:0.718 AVG Training Acc 53.16 % AVG Validation Acc 42.96 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.688 AVG Validation Loss:0.708 AVG Training Acc 53.90 % AVG Validation Acc 45.76 %\n",
      "Epoch:90/200 AVG Training Loss:0.686 AVG Validation Loss:0.699 AVG Training Acc 54.35 % AVG Validation Acc 48.74 %\n",
      "Epoch:100/200 AVG Training Loss:0.685 AVG Validation Loss:0.697 AVG Training Acc 54.74 % AVG Validation Acc 48.56 %\n",
      "Epoch:110/200 AVG Training Loss:0.685 AVG Validation Loss:0.696 AVG Training Acc 54.73 % AVG Validation Acc 48.65 %\n",
      "Epoch:120/200 AVG Training Loss:0.684 AVG Validation Loss:0.696 AVG Training Acc 54.90 % AVG Validation Acc 48.56 %\n",
      "Epoch:130/200 AVG Training Loss:0.685 AVG Validation Loss:0.696 AVG Training Acc 54.53 % AVG Validation Acc 48.83 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:140/200 AVG Training Loss:0.683 AVG Validation Loss:0.696 AVG Training Acc 54.96 % AVG Validation Acc 48.65 %\n",
      "Epoch:150/200 AVG Training Loss:0.685 AVG Validation Loss:0.696 AVG Training Acc 54.67 % AVG Validation Acc 48.92 %\n",
      "Epoch:160/200 AVG Training Loss:0.683 AVG Validation Loss:0.696 AVG Training Acc 54.83 % AVG Validation Acc 48.92 %\n",
      "Epoch:170/200 AVG Training Loss:0.684 AVG Validation Loss:0.695 AVG Training Acc 54.64 % AVG Validation Acc 49.19 %\n",
      "Epoch:180/200 AVG Training Loss:0.683 AVG Validation Loss:0.695 AVG Training Acc 55.09 % AVG Validation Acc 48.74 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:190/200 AVG Training Loss:0.684 AVG Validation Loss:0.695 AVG Training Acc 54.81 % AVG Validation Acc 48.74 %\n",
      "Epoch:200/200 AVG Training Loss:0.684 AVG Validation Loss:0.695 AVG Training Acc 54.65 % AVG Validation Acc 49.01 %\n",
      "Split 39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3c6a06e1faa4455aaf6878baaf477a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.653 AVG Validation Loss:2.847 AVG Training Acc 66.10 % AVG Validation Acc 38.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.661 AVG Validation Loss:3.072 AVG Training Acc 65.29 % AVG Validation Acc 38.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.664 AVG Validation Loss:1.635 AVG Training Acc 62.79 % AVG Validation Acc 38.09 %\n",
      "Epoch:40/200 AVG Training Loss:0.676 AVG Validation Loss:1.337 AVG Training Acc 62.51 % AVG Validation Acc 38.09 %\n",
      "Epoch:50/200 AVG Training Loss:0.667 AVG Validation Loss:1.513 AVG Training Acc 62.19 % AVG Validation Acc 38.09 %\n",
      "Epoch:60/200 AVG Training Loss:0.673 AVG Validation Loss:1.202 AVG Training Acc 60.27 % AVG Validation Acc 38.09 %\n",
      "Epoch:70/200 AVG Training Loss:0.671 AVG Validation Loss:1.246 AVG Training Acc 60.31 % AVG Validation Acc 38.00 %\n",
      "Epoch    70: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:80/200 AVG Training Loss:0.689 AVG Validation Loss:0.717 AVG Training Acc 53.34 % AVG Validation Acc 46.57 %\n",
      "Epoch:90/200 AVG Training Loss:0.688 AVG Validation Loss:0.721 AVG Training Acc 53.09 % AVG Validation Acc 47.11 %\n",
      "Epoch:100/200 AVG Training Loss:0.689 AVG Validation Loss:0.723 AVG Training Acc 52.66 % AVG Validation Acc 47.02 %\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:110/200 AVG Training Loss:0.684 AVG Validation Loss:0.714 AVG Training Acc 54.91 % AVG Validation Acc 49.73 %\n",
      "Epoch:120/200 AVG Training Loss:0.684 AVG Validation Loss:0.710 AVG Training Acc 54.89 % AVG Validation Acc 49.82 %\n",
      "Epoch:130/200 AVG Training Loss:0.685 AVG Validation Loss:0.710 AVG Training Acc 55.47 % AVG Validation Acc 49.91 %\n",
      "Epoch:140/200 AVG Training Loss:0.685 AVG Validation Loss:0.709 AVG Training Acc 55.04 % AVG Validation Acc 50.09 %\n",
      "Epoch:150/200 AVG Training Loss:0.684 AVG Validation Loss:0.709 AVG Training Acc 55.23 % AVG Validation Acc 50.00 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:160/200 AVG Training Loss:0.685 AVG Validation Loss:0.709 AVG Training Acc 54.84 % AVG Validation Acc 50.27 %\n",
      "Epoch:170/200 AVG Training Loss:0.684 AVG Validation Loss:0.709 AVG Training Acc 55.13 % AVG Validation Acc 49.91 %\n",
      "Epoch:180/200 AVG Training Loss:0.684 AVG Validation Loss:0.709 AVG Training Acc 55.06 % AVG Validation Acc 50.00 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:190/200 AVG Training Loss:0.685 AVG Validation Loss:0.709 AVG Training Acc 55.26 % AVG Validation Acc 50.45 %\n",
      "Epoch:200/200 AVG Training Loss:0.684 AVG Validation Loss:0.709 AVG Training Acc 55.17 % AVG Validation Acc 50.27 %\n",
      "Split 40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1eb59a31d52416bb5b07dbba4445b3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.657 AVG Validation Loss:2.269 AVG Training Acc 63.76 % AVG Validation Acc 38.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.661 AVG Validation Loss:1.666 AVG Training Acc 62.88 % AVG Validation Acc 38.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.711 AVG Validation Loss:1.911 AVG Training Acc 63.78 % AVG Validation Acc 38.09 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.697 AVG Validation Loss:1.419 AVG Training Acc 56.74 % AVG Validation Acc 38.09 %\n",
      "Epoch:50/200 AVG Training Loss:0.687 AVG Validation Loss:1.161 AVG Training Acc 59.27 % AVG Validation Acc 38.09 %\n",
      "Epoch:60/200 AVG Training Loss:0.706 AVG Validation Loss:0.771 AVG Training Acc 52.08 % AVG Validation Acc 38.27 %\n",
      "Epoch:70/200 AVG Training Loss:0.695 AVG Validation Loss:0.745 AVG Training Acc 52.18 % AVG Validation Acc 37.91 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.694 AVG Validation Loss:0.711 AVG Training Acc 52.15 % AVG Validation Acc 42.06 %\n",
      "Epoch:90/200 AVG Training Loss:0.688 AVG Validation Loss:0.693 AVG Training Acc 53.84 % AVG Validation Acc 49.10 %\n",
      "Epoch:100/200 AVG Training Loss:0.688 AVG Validation Loss:0.693 AVG Training Acc 54.11 % AVG Validation Acc 48.65 %\n",
      "Epoch:110/200 AVG Training Loss:0.687 AVG Validation Loss:0.692 AVG Training Acc 54.12 % AVG Validation Acc 48.92 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.687 AVG Validation Loss:0.691 AVG Training Acc 54.06 % AVG Validation Acc 49.82 %\n",
      "Epoch:130/200 AVG Training Loss:0.686 AVG Validation Loss:0.691 AVG Training Acc 53.86 % AVG Validation Acc 49.28 %\n",
      "Epoch:140/200 AVG Training Loss:0.687 AVG Validation Loss:0.690 AVG Training Acc 54.49 % AVG Validation Acc 49.46 %\n",
      "Epoch:150/200 AVG Training Loss:0.688 AVG Validation Loss:0.690 AVG Training Acc 54.26 % AVG Validation Acc 49.73 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.686 AVG Validation Loss:0.688 AVG Training Acc 54.68 % AVG Validation Acc 50.18 %\n",
      "Epoch:170/200 AVG Training Loss:0.687 AVG Validation Loss:0.689 AVG Training Acc 54.45 % AVG Validation Acc 49.73 %\n",
      "Epoch:180/200 AVG Training Loss:0.687 AVG Validation Loss:0.689 AVG Training Acc 54.06 % AVG Validation Acc 49.82 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.687 AVG Validation Loss:0.689 AVG Training Acc 54.61 % AVG Validation Acc 49.73 %\n",
      "Epoch:200/200 AVG Training Loss:0.687 AVG Validation Loss:0.689 AVG Training Acc 54.29 % AVG Validation Acc 49.73 %\n",
      "Split 41\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df1e519d9cf64b32990fe7307b0121c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.656 AVG Validation Loss:2.646 AVG Training Acc 65.44 % AVG Validation Acc 38.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.661 AVG Validation Loss:4.860 AVG Training Acc 65.12 % AVG Validation Acc 38.14 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.694 AVG Validation Loss:0.765 AVG Training Acc 53.58 % AVG Validation Acc 38.32 %\n",
      "Epoch:40/200 AVG Training Loss:0.692 AVG Validation Loss:0.753 AVG Training Acc 53.19 % AVG Validation Acc 38.86 %\n",
      "Epoch:50/200 AVG Training Loss:0.690 AVG Validation Loss:0.747 AVG Training Acc 53.89 % AVG Validation Acc 38.95 %\n",
      "Epoch:60/200 AVG Training Loss:0.688 AVG Validation Loss:0.747 AVG Training Acc 53.97 % AVG Validation Acc 39.95 %\n",
      "Epoch:70/200 AVG Training Loss:0.686 AVG Validation Loss:0.745 AVG Training Acc 54.62 % AVG Validation Acc 40.22 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.682 AVG Validation Loss:0.710 AVG Training Acc 55.36 % AVG Validation Acc 45.81 %\n",
      "Epoch:90/200 AVG Training Loss:0.681 AVG Validation Loss:0.702 AVG Training Acc 56.11 % AVG Validation Acc 47.34 %\n",
      "Epoch:100/200 AVG Training Loss:0.680 AVG Validation Loss:0.701 AVG Training Acc 55.58 % AVG Validation Acc 47.34 %\n",
      "Epoch:110/200 AVG Training Loss:0.679 AVG Validation Loss:0.701 AVG Training Acc 55.90 % AVG Validation Acc 47.16 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.679 AVG Validation Loss:0.701 AVG Training Acc 56.21 % AVG Validation Acc 46.89 %\n",
      "Epoch:130/200 AVG Training Loss:0.678 AVG Validation Loss:0.700 AVG Training Acc 55.94 % AVG Validation Acc 47.61 %\n",
      "Epoch:140/200 AVG Training Loss:0.678 AVG Validation Loss:0.700 AVG Training Acc 56.25 % AVG Validation Acc 47.43 %\n",
      "Epoch:150/200 AVG Training Loss:0.678 AVG Validation Loss:0.700 AVG Training Acc 55.98 % AVG Validation Acc 47.79 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.679 AVG Validation Loss:0.700 AVG Training Acc 56.22 % AVG Validation Acc 47.61 %\n",
      "Epoch:170/200 AVG Training Loss:0.679 AVG Validation Loss:0.700 AVG Training Acc 56.20 % AVG Validation Acc 47.70 %\n",
      "Epoch:180/200 AVG Training Loss:0.678 AVG Validation Loss:0.701 AVG Training Acc 56.32 % AVG Validation Acc 47.97 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.678 AVG Validation Loss:0.700 AVG Training Acc 56.20 % AVG Validation Acc 47.34 %\n",
      "Epoch:200/200 AVG Training Loss:0.677 AVG Validation Loss:0.700 AVG Training Acc 56.27 % AVG Validation Acc 47.52 %\n",
      "Split 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c17086ad214475897d246773d3746fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.636 AVG Validation Loss:4.423 AVG Training Acc 65.19 % AVG Validation Acc 38.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.639 AVG Validation Loss:6.881 AVG Training Acc 62.94 % AVG Validation Acc 38.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.674 AVG Validation Loss:1.288 AVG Training Acc 60.70 % AVG Validation Acc 38.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.676 AVG Validation Loss:1.203 AVG Training Acc 59.99 % AVG Validation Acc 38.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.675 AVG Validation Loss:1.227 AVG Training Acc 60.32 % AVG Validation Acc 38.14 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.692 AVG Validation Loss:0.708 AVG Training Acc 51.59 % AVG Validation Acc 43.10 %\n",
      "Epoch:70/200 AVG Training Loss:0.691 AVG Validation Loss:0.709 AVG Training Acc 52.86 % AVG Validation Acc 44.18 %\n",
      "Epoch:80/200 AVG Training Loss:0.688 AVG Validation Loss:0.709 AVG Training Acc 53.43 % AVG Validation Acc 45.18 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.686 AVG Validation Loss:0.695 AVG Training Acc 54.66 % AVG Validation Acc 49.32 %\n",
      "Epoch:100/200 AVG Training Loss:0.685 AVG Validation Loss:0.690 AVG Training Acc 55.14 % AVG Validation Acc 50.50 %\n",
      "Epoch:110/200 AVG Training Loss:0.685 AVG Validation Loss:0.689 AVG Training Acc 54.98 % AVG Validation Acc 50.50 %\n",
      "Epoch:120/200 AVG Training Loss:0.685 AVG Validation Loss:0.688 AVG Training Acc 55.04 % AVG Validation Acc 50.05 %\n",
      "Epoch:130/200 AVG Training Loss:0.684 AVG Validation Loss:0.688 AVG Training Acc 54.91 % AVG Validation Acc 50.32 %\n",
      "Epoch:140/200 AVG Training Loss:0.683 AVG Validation Loss:0.688 AVG Training Acc 55.24 % AVG Validation Acc 50.32 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.683 AVG Validation Loss:0.688 AVG Training Acc 55.31 % AVG Validation Acc 50.59 %\n",
      "Epoch:160/200 AVG Training Loss:0.684 AVG Validation Loss:0.687 AVG Training Acc 55.23 % AVG Validation Acc 50.59 %\n",
      "Epoch:170/200 AVG Training Loss:0.683 AVG Validation Loss:0.687 AVG Training Acc 54.98 % AVG Validation Acc 50.05 %\n",
      "Epoch:180/200 AVG Training Loss:0.684 AVG Validation Loss:0.687 AVG Training Acc 55.11 % AVG Validation Acc 50.23 %\n",
      "Epoch:190/200 AVG Training Loss:0.684 AVG Validation Loss:0.687 AVG Training Acc 55.00 % AVG Validation Acc 50.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.683 AVG Validation Loss:0.687 AVG Training Acc 55.07 % AVG Validation Acc 50.50 %\n",
      "Split 43\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa5c92a3d7143e8b8e6b02781fbd7a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.647 AVG Validation Loss:4.697 AVG Training Acc 64.31 % AVG Validation Acc 38.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.662 AVG Validation Loss:2.327 AVG Training Acc 64.62 % AVG Validation Acc 38.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.742 AVG Validation Loss:3.414 AVG Training Acc 62.12 % AVG Validation Acc 38.23 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.694 AVG Validation Loss:0.942 AVG Training Acc 57.39 % AVG Validation Acc 38.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.682 AVG Validation Loss:0.905 AVG Training Acc 57.09 % AVG Validation Acc 38.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.688 AVG Validation Loss:0.809 AVG Training Acc 55.47 % AVG Validation Acc 38.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.687 AVG Validation Loss:0.770 AVG Training Acc 54.68 % AVG Validation Acc 38.50 %\n",
      "Epoch:80/200 AVG Training Loss:0.687 AVG Validation Loss:0.753 AVG Training Acc 54.19 % AVG Validation Acc 38.32 %\n",
      "Epoch:90/200 AVG Training Loss:0.685 AVG Validation Loss:0.752 AVG Training Acc 53.54 % AVG Validation Acc 38.41 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.683 AVG Validation Loss:0.713 AVG Training Acc 54.77 % AVG Validation Acc 46.98 %\n",
      "Epoch:110/200 AVG Training Loss:0.681 AVG Validation Loss:0.707 AVG Training Acc 55.10 % AVG Validation Acc 48.06 %\n",
      "Epoch:120/200 AVG Training Loss:0.681 AVG Validation Loss:0.704 AVG Training Acc 55.42 % AVG Validation Acc 48.78 %\n",
      "Epoch:130/200 AVG Training Loss:0.681 AVG Validation Loss:0.704 AVG Training Acc 55.43 % AVG Validation Acc 48.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.679 AVG Validation Loss:0.703 AVG Training Acc 55.24 % AVG Validation Acc 48.51 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.678 AVG Validation Loss:0.703 AVG Training Acc 55.58 % AVG Validation Acc 49.23 %\n",
      "Epoch:160/200 AVG Training Loss:0.679 AVG Validation Loss:0.702 AVG Training Acc 55.43 % AVG Validation Acc 49.68 %\n",
      "Epoch:170/200 AVG Training Loss:0.678 AVG Validation Loss:0.702 AVG Training Acc 55.80 % AVG Validation Acc 49.50 %\n",
      "Epoch:180/200 AVG Training Loss:0.679 AVG Validation Loss:0.702 AVG Training Acc 55.60 % AVG Validation Acc 49.50 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:190/200 AVG Training Loss:0.678 AVG Validation Loss:0.701 AVG Training Acc 55.82 % AVG Validation Acc 49.32 %\n",
      "Epoch:200/200 AVG Training Loss:0.679 AVG Validation Loss:0.701 AVG Training Acc 55.73 % AVG Validation Acc 49.50 %\n",
      "Split 44\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ece6b6fbdb04f2d8ed3aab0796ca828",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.662 AVG Validation Loss:2.062 AVG Training Acc 63.55 % AVG Validation Acc 38.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:1.542 AVG Training Acc 62.53 % AVG Validation Acc 38.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.667 AVG Validation Loss:5.509 AVG Training Acc 60.20 % AVG Validation Acc 38.14 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.755 AVG Validation Loss:0.782 AVG Training Acc 49.98 % AVG Validation Acc 38.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.694 AVG Validation Loss:0.713 AVG Training Acc 50.12 % AVG Validation Acc 40.31 %\n",
      "Epoch:60/200 AVG Training Loss:0.693 AVG Validation Loss:0.712 AVG Training Acc 50.92 % AVG Validation Acc 42.20 %\n",
      "Epoch:70/200 AVG Training Loss:0.691 AVG Validation Loss:0.712 AVG Training Acc 52.53 % AVG Validation Acc 44.72 %\n",
      "Epoch:80/200 AVG Training Loss:0.691 AVG Validation Loss:0.708 AVG Training Acc 52.97 % AVG Validation Acc 48.06 %\n",
      "Epoch:90/200 AVG Training Loss:0.690 AVG Validation Loss:0.709 AVG Training Acc 52.98 % AVG Validation Acc 47.70 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.686 AVG Validation Loss:0.695 AVG Training Acc 54.59 % AVG Validation Acc 50.59 %\n",
      "Epoch:110/200 AVG Training Loss:0.687 AVG Validation Loss:0.690 AVG Training Acc 55.06 % AVG Validation Acc 51.22 %\n",
      "Epoch:120/200 AVG Training Loss:0.685 AVG Validation Loss:0.688 AVG Training Acc 54.86 % AVG Validation Acc 51.58 %\n",
      "Epoch:130/200 AVG Training Loss:0.685 AVG Validation Loss:0.688 AVG Training Acc 55.13 % AVG Validation Acc 51.85 %\n",
      "Epoch:140/200 AVG Training Loss:0.685 AVG Validation Loss:0.688 AVG Training Acc 54.98 % AVG Validation Acc 52.03 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.685 AVG Validation Loss:0.687 AVG Training Acc 55.34 % AVG Validation Acc 52.12 %\n",
      "Epoch:160/200 AVG Training Loss:0.685 AVG Validation Loss:0.687 AVG Training Acc 55.27 % AVG Validation Acc 52.21 %\n",
      "Epoch:170/200 AVG Training Loss:0.684 AVG Validation Loss:0.687 AVG Training Acc 55.30 % AVG Validation Acc 52.21 %\n",
      "Epoch:180/200 AVG Training Loss:0.685 AVG Validation Loss:0.687 AVG Training Acc 55.25 % AVG Validation Acc 52.21 %\n",
      "Epoch:190/200 AVG Training Loss:0.685 AVG Validation Loss:0.687 AVG Training Acc 54.89 % AVG Validation Acc 52.21 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:200/200 AVG Training Loss:0.685 AVG Validation Loss:0.687 AVG Training Acc 55.05 % AVG Validation Acc 52.30 %\n",
      "Split 45\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81eaf728b7c34ff2a2e9771020170931",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:2.178 AVG Training Acc 64.15 % AVG Validation Acc 38.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.675 AVG Validation Loss:1.357 AVG Training Acc 61.50 % AVG Validation Acc 38.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.676 AVG Validation Loss:1.242 AVG Training Acc 59.86 % AVG Validation Acc 38.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.715 AVG Validation Loss:1.274 AVG Training Acc 61.89 % AVG Validation Acc 38.14 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.690 AVG Validation Loss:0.706 AVG Training Acc 53.00 % AVG Validation Acc 46.98 %\n",
      "Epoch:60/200 AVG Training Loss:0.688 AVG Validation Loss:0.707 AVG Training Acc 53.42 % AVG Validation Acc 47.88 %\n",
      "Epoch:70/200 AVG Training Loss:0.688 AVG Validation Loss:0.709 AVG Training Acc 53.72 % AVG Validation Acc 47.88 %\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.686 AVG Validation Loss:0.699 AVG Training Acc 54.62 % AVG Validation Acc 49.68 %\n",
      "Epoch:90/200 AVG Training Loss:0.685 AVG Validation Loss:0.693 AVG Training Acc 54.82 % AVG Validation Acc 50.86 %\n",
      "Epoch:100/200 AVG Training Loss:0.684 AVG Validation Loss:0.691 AVG Training Acc 55.25 % AVG Validation Acc 50.77 %\n",
      "Epoch:110/200 AVG Training Loss:0.685 AVG Validation Loss:0.691 AVG Training Acc 54.74 % AVG Validation Acc 50.95 %\n",
      "Epoch:120/200 AVG Training Loss:0.685 AVG Validation Loss:0.690 AVG Training Acc 55.51 % AVG Validation Acc 50.86 %\n",
      "Epoch:130/200 AVG Training Loss:0.685 AVG Validation Loss:0.690 AVG Training Acc 55.00 % AVG Validation Acc 50.77 %\n",
      "Epoch   135: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:140/200 AVG Training Loss:0.683 AVG Validation Loss:0.690 AVG Training Acc 55.45 % AVG Validation Acc 50.41 %\n",
      "Epoch:150/200 AVG Training Loss:0.684 AVG Validation Loss:0.690 AVG Training Acc 55.47 % AVG Validation Acc 50.59 %\n",
      "Epoch:160/200 AVG Training Loss:0.683 AVG Validation Loss:0.690 AVG Training Acc 55.18 % AVG Validation Acc 50.86 %\n",
      "Epoch:170/200 AVG Training Loss:0.684 AVG Validation Loss:0.690 AVG Training Acc 55.24 % AVG Validation Acc 50.68 %\n",
      "Epoch:180/200 AVG Training Loss:0.683 AVG Validation Loss:0.689 AVG Training Acc 55.47 % AVG Validation Acc 50.95 %\n",
      "Epoch:190/200 AVG Training Loss:0.684 AVG Validation Loss:0.690 AVG Training Acc 55.26 % AVG Validation Acc 50.95 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:200/200 AVG Training Loss:0.683 AVG Validation Loss:0.689 AVG Training Acc 55.31 % AVG Validation Acc 51.22 %\n",
      "Split 46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983b6bea0b1945f2a3517472769f67be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:2.074 AVG Training Acc 64.13 % AVG Validation Acc 38.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.662 AVG Validation Loss:1.656 AVG Training Acc 62.92 % AVG Validation Acc 38.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.649 AVG Validation Loss:5.569 AVG Training Acc 62.25 % AVG Validation Acc 38.09 %\n",
      "Epoch:40/200 AVG Training Loss:0.689 AVG Validation Loss:3.703 AVG Training Acc 63.89 % AVG Validation Acc 38.09 %\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.696 AVG Validation Loss:0.730 AVG Training Acc 50.58 % AVG Validation Acc 39.08 %\n",
      "Epoch:60/200 AVG Training Loss:0.692 AVG Validation Loss:0.732 AVG Training Acc 51.98 % AVG Validation Acc 41.43 %\n",
      "Epoch:70/200 AVG Training Loss:0.689 AVG Validation Loss:0.734 AVG Training Acc 53.51 % AVG Validation Acc 42.87 %\n",
      "Epoch    71: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.684 AVG Validation Loss:0.707 AVG Training Acc 54.87 % AVG Validation Acc 47.38 %\n",
      "Epoch:90/200 AVG Training Loss:0.683 AVG Validation Loss:0.702 AVG Training Acc 54.62 % AVG Validation Acc 48.29 %\n",
      "Epoch:100/200 AVG Training Loss:0.683 AVG Validation Loss:0.701 AVG Training Acc 55.22 % AVG Validation Acc 47.92 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.682 AVG Validation Loss:0.701 AVG Training Acc 55.60 % AVG Validation Acc 48.38 %\n",
      "Epoch:120/200 AVG Training Loss:0.682 AVG Validation Loss:0.701 AVG Training Acc 55.28 % AVG Validation Acc 48.01 %\n",
      "Epoch:130/200 AVG Training Loss:0.682 AVG Validation Loss:0.700 AVG Training Acc 55.95 % AVG Validation Acc 48.29 %\n",
      "Epoch:140/200 AVG Training Loss:0.682 AVG Validation Loss:0.700 AVG Training Acc 55.77 % AVG Validation Acc 48.38 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.682 AVG Validation Loss:0.700 AVG Training Acc 55.36 % AVG Validation Acc 48.56 %\n",
      "Epoch:160/200 AVG Training Loss:0.682 AVG Validation Loss:0.700 AVG Training Acc 55.57 % AVG Validation Acc 48.19 %\n",
      "Epoch:170/200 AVG Training Loss:0.682 AVG Validation Loss:0.700 AVG Training Acc 55.64 % AVG Validation Acc 48.56 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.682 AVG Validation Loss:0.700 AVG Training Acc 55.34 % AVG Validation Acc 48.56 %\n",
      "Epoch:190/200 AVG Training Loss:0.682 AVG Validation Loss:0.700 AVG Training Acc 55.03 % AVG Validation Acc 48.47 %\n",
      "Epoch:200/200 AVG Training Loss:0.682 AVG Validation Loss:0.700 AVG Training Acc 55.25 % AVG Validation Acc 48.10 %\n",
      "Split 47\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1358c605a37341db9608ab41456aef6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.662 AVG Validation Loss:2.630 AVG Training Acc 63.83 % AVG Validation Acc 38.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.674 AVG Validation Loss:1.325 AVG Training Acc 61.12 % AVG Validation Acc 38.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.674 AVG Validation Loss:1.715 AVG Training Acc 59.96 % AVG Validation Acc 38.09 %\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.888 AVG Validation Loss:0.895 AVG Training Acc 50.01 % AVG Validation Acc 38.09 %\n",
      "Epoch:50/200 AVG Training Loss:0.692 AVG Validation Loss:0.711 AVG Training Acc 51.66 % AVG Validation Acc 43.32 %\n",
      "Epoch:60/200 AVG Training Loss:0.691 AVG Validation Loss:0.711 AVG Training Acc 53.21 % AVG Validation Acc 44.58 %\n",
      "Epoch:70/200 AVG Training Loss:0.689 AVG Validation Loss:0.712 AVG Training Acc 53.30 % AVG Validation Acc 46.48 %\n",
      "Epoch    70: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.686 AVG Validation Loss:0.696 AVG Training Acc 54.83 % AVG Validation Acc 50.27 %\n",
      "Epoch:90/200 AVG Training Loss:0.685 AVG Validation Loss:0.692 AVG Training Acc 55.34 % AVG Validation Acc 50.99 %\n",
      "Epoch:100/200 AVG Training Loss:0.686 AVG Validation Loss:0.690 AVG Training Acc 55.10 % AVG Validation Acc 50.90 %\n",
      "Epoch:110/200 AVG Training Loss:0.685 AVG Validation Loss:0.690 AVG Training Acc 55.14 % AVG Validation Acc 51.08 %\n",
      "Epoch:120/200 AVG Training Loss:0.685 AVG Validation Loss:0.690 AVG Training Acc 55.15 % AVG Validation Acc 51.17 %\n",
      "Epoch:130/200 AVG Training Loss:0.685 AVG Validation Loss:0.690 AVG Training Acc 55.02 % AVG Validation Acc 50.99 %\n",
      "Epoch:140/200 AVG Training Loss:0.685 AVG Validation Loss:0.689 AVG Training Acc 55.10 % AVG Validation Acc 51.26 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.684 AVG Validation Loss:0.689 AVG Training Acc 55.32 % AVG Validation Acc 51.17 %\n",
      "Epoch:160/200 AVG Training Loss:0.684 AVG Validation Loss:0.689 AVG Training Acc 55.38 % AVG Validation Acc 50.90 %\n",
      "Epoch:170/200 AVG Training Loss:0.683 AVG Validation Loss:0.689 AVG Training Acc 55.55 % AVG Validation Acc 51.26 %\n",
      "Epoch:180/200 AVG Training Loss:0.683 AVG Validation Loss:0.689 AVG Training Acc 55.54 % AVG Validation Acc 51.08 %\n",
      "Epoch:190/200 AVG Training Loss:0.685 AVG Validation Loss:0.689 AVG Training Acc 55.43 % AVG Validation Acc 51.08 %\n",
      "Epoch:200/200 AVG Training Loss:0.685 AVG Validation Loss:0.688 AVG Training Acc 55.25 % AVG Validation Acc 51.17 %\n",
      "Split 48\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c48731c830d14962844c092edc51f895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.637 AVG Validation Loss:3.263 AVG Training Acc 65.93 % AVG Validation Acc 38.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:2.867 AVG Training Acc 63.04 % AVG Validation Acc 38.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.671 AVG Validation Loss:1.545 AVG Training Acc 60.97 % AVG Validation Acc 38.09 %\n",
      "Epoch:40/200 AVG Training Loss:0.655 AVG Validation Loss:2.736 AVG Training Acc 65.72 % AVG Validation Acc 38.09 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.703 AVG Validation Loss:0.747 AVG Training Acc 51.21 % AVG Validation Acc 38.99 %\n",
      "Epoch:60/200 AVG Training Loss:0.695 AVG Validation Loss:0.721 AVG Training Acc 50.45 % AVG Validation Acc 38.81 %\n",
      "Epoch:70/200 AVG Training Loss:0.691 AVG Validation Loss:0.719 AVG Training Acc 52.60 % AVG Validation Acc 41.52 %\n",
      "Epoch:80/200 AVG Training Loss:0.689 AVG Validation Loss:0.717 AVG Training Acc 53.00 % AVG Validation Acc 42.60 %\n",
      "Epoch:90/200 AVG Training Loss:0.687 AVG Validation Loss:0.717 AVG Training Acc 53.71 % AVG Validation Acc 44.31 %\n",
      "Epoch:100/200 AVG Training Loss:0.685 AVG Validation Loss:0.718 AVG Training Acc 53.77 % AVG Validation Acc 44.86 %\n",
      "Epoch   106: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:110/200 AVG Training Loss:0.683 AVG Validation Loss:0.724 AVG Training Acc 54.88 % AVG Validation Acc 45.58 %\n",
      "Epoch:120/200 AVG Training Loss:0.682 AVG Validation Loss:0.707 AVG Training Acc 55.03 % AVG Validation Acc 47.83 %\n",
      "Epoch:130/200 AVG Training Loss:0.681 AVG Validation Loss:0.707 AVG Training Acc 55.47 % AVG Validation Acc 48.38 %\n",
      "Epoch:140/200 AVG Training Loss:0.682 AVG Validation Loss:0.709 AVG Training Acc 55.41 % AVG Validation Acc 48.10 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.680 AVG Validation Loss:0.707 AVG Training Acc 55.49 % AVG Validation Acc 48.29 %\n",
      "Epoch:160/200 AVG Training Loss:0.680 AVG Validation Loss:0.705 AVG Training Acc 55.67 % AVG Validation Acc 48.47 %\n",
      "Epoch:170/200 AVG Training Loss:0.680 AVG Validation Loss:0.705 AVG Training Acc 55.68 % AVG Validation Acc 48.65 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:180/200 AVG Training Loss:0.681 AVG Validation Loss:0.710 AVG Training Acc 55.80 % AVG Validation Acc 48.29 %\n",
      "Epoch:190/200 AVG Training Loss:0.682 AVG Validation Loss:0.708 AVG Training Acc 55.18 % AVG Validation Acc 48.01 %\n",
      "Epoch:200/200 AVG Training Loss:0.680 AVG Validation Loss:0.706 AVG Training Acc 55.64 % AVG Validation Acc 48.19 %\n",
      "Split 49\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54cc0c878a7d4e6f9e9571e1adab8777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.646 AVG Validation Loss:3.510 AVG Training Acc 65.60 % AVG Validation Acc 38.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.679 AVG Validation Loss:6.057 AVG Training Acc 63.75 % AVG Validation Acc 38.09 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.824 AVG Validation Loss:1.780 AVG Training Acc 52.18 % AVG Validation Acc 38.18 %\n",
      "Epoch:40/200 AVG Training Loss:0.694 AVG Validation Loss:0.762 AVG Training Acc 52.82 % AVG Validation Acc 38.81 %\n",
      "Epoch:50/200 AVG Training Loss:0.693 AVG Validation Loss:0.757 AVG Training Acc 53.81 % AVG Validation Acc 39.17 %\n",
      "Epoch:60/200 AVG Training Loss:0.687 AVG Validation Loss:0.756 AVG Training Acc 54.58 % AVG Validation Acc 39.08 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.708 AVG Validation Loss:0.744 AVG Training Acc 51.32 % AVG Validation Acc 39.71 %\n",
      "Epoch:80/200 AVG Training Loss:0.688 AVG Validation Loss:0.700 AVG Training Acc 54.40 % AVG Validation Acc 46.03 %\n",
      "Epoch:90/200 AVG Training Loss:0.687 AVG Validation Loss:0.699 AVG Training Acc 54.45 % AVG Validation Acc 46.30 %\n",
      "Epoch:100/200 AVG Training Loss:0.687 AVG Validation Loss:0.699 AVG Training Acc 54.40 % AVG Validation Acc 46.57 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.686 AVG Validation Loss:0.699 AVG Training Acc 54.30 % AVG Validation Acc 46.48 %\n",
      "Epoch:120/200 AVG Training Loss:0.685 AVG Validation Loss:0.698 AVG Training Acc 54.66 % AVG Validation Acc 46.93 %\n",
      "Epoch:130/200 AVG Training Loss:0.685 AVG Validation Loss:0.697 AVG Training Acc 54.87 % AVG Validation Acc 47.29 %\n",
      "Epoch:140/200 AVG Training Loss:0.685 AVG Validation Loss:0.696 AVG Training Acc 54.72 % AVG Validation Acc 47.65 %\n",
      "Epoch:150/200 AVG Training Loss:0.684 AVG Validation Loss:0.696 AVG Training Acc 54.81 % AVG Validation Acc 47.74 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.685 AVG Validation Loss:0.697 AVG Training Acc 55.25 % AVG Validation Acc 48.01 %\n",
      "Epoch:170/200 AVG Training Loss:0.685 AVG Validation Loss:0.696 AVG Training Acc 54.92 % AVG Validation Acc 47.83 %\n",
      "Epoch:180/200 AVG Training Loss:0.685 AVG Validation Loss:0.697 AVG Training Acc 54.91 % AVG Validation Acc 47.65 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.685 AVG Validation Loss:0.696 AVG Training Acc 54.80 % AVG Validation Acc 48.38 %\n",
      "Epoch:200/200 AVG Training Loss:0.685 AVG Validation Loss:0.696 AVG Training Acc 54.88 % AVG Validation Acc 48.38 %\n",
      "Split 50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "faa7312dbf73404baabc92d4b3ff48a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.657 AVG Validation Loss:2.086 AVG Training Acc 64.26 % AVG Validation Acc 38.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.669 AVG Validation Loss:3.755 AVG Training Acc 62.62 % AVG Validation Acc 38.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:3.946 AVG Training Acc 62.42 % AVG Validation Acc 38.09 %\n",
      "Epoch:40/200 AVG Training Loss:0.678 AVG Validation Loss:1.193 AVG Training Acc 59.69 % AVG Validation Acc 38.09 %\n",
      "Epoch:50/200 AVG Training Loss:0.675 AVG Validation Loss:1.230 AVG Training Acc 60.31 % AVG Validation Acc 38.09 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.690 AVG Validation Loss:0.899 AVG Training Acc 56.67 % AVG Validation Acc 38.09 %\n",
      "Epoch:70/200 AVG Training Loss:0.696 AVG Validation Loss:0.795 AVG Training Acc 53.68 % AVG Validation Acc 38.00 %\n",
      "Epoch:80/200 AVG Training Loss:0.695 AVG Validation Loss:0.747 AVG Training Acc 52.17 % AVG Validation Acc 38.36 %\n",
      "Epoch:90/200 AVG Training Loss:0.693 AVG Validation Loss:0.736 AVG Training Acc 52.61 % AVG Validation Acc 38.27 %\n",
      "Epoch:100/200 AVG Training Loss:0.692 AVG Validation Loss:0.735 AVG Training Acc 52.57 % AVG Validation Acc 39.53 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:110/200 AVG Training Loss:0.689 AVG Validation Loss:0.695 AVG Training Acc 53.74 % AVG Validation Acc 50.18 %\n",
      "Epoch:120/200 AVG Training Loss:0.687 AVG Validation Loss:0.688 AVG Training Acc 53.94 % AVG Validation Acc 51.81 %\n",
      "Epoch:130/200 AVG Training Loss:0.687 AVG Validation Loss:0.688 AVG Training Acc 54.31 % AVG Validation Acc 52.26 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:140/200 AVG Training Loss:0.686 AVG Validation Loss:0.687 AVG Training Acc 54.32 % AVG Validation Acc 52.35 %\n",
      "Epoch:150/200 AVG Training Loss:0.686 AVG Validation Loss:0.687 AVG Training Acc 54.09 % AVG Validation Acc 52.53 %\n",
      "Epoch:160/200 AVG Training Loss:0.686 AVG Validation Loss:0.686 AVG Training Acc 54.18 % AVG Validation Acc 52.53 %\n",
      "Epoch:170/200 AVG Training Loss:0.685 AVG Validation Loss:0.686 AVG Training Acc 54.59 % AVG Validation Acc 53.16 %\n",
      "Epoch:180/200 AVG Training Loss:0.687 AVG Validation Loss:0.686 AVG Training Acc 54.23 % AVG Validation Acc 52.98 %\n",
      "Epoch:190/200 AVG Training Loss:0.686 AVG Validation Loss:0.685 AVG Training Acc 54.34 % AVG Validation Acc 53.43 %\n",
      "Epoch:200/200 AVG Training Loss:0.686 AVG Validation Loss:0.685 AVG Training Acc 54.38 % AVG Validation Acc 53.34 %\n",
      "Split 51\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e9fe54fde342a28b75ebaab79c0316",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.669 AVG Validation Loss:1.981 AVG Training Acc 63.19 % AVG Validation Acc 38.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.661 AVG Validation Loss:5.482 AVG Training Acc 63.02 % AVG Validation Acc 38.05 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.703 AVG Validation Loss:0.739 AVG Training Acc 50.11 % AVG Validation Acc 38.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.695 AVG Validation Loss:0.725 AVG Training Acc 50.94 % AVG Validation Acc 38.41 %\n",
      "Epoch:50/200 AVG Training Loss:0.694 AVG Validation Loss:0.721 AVG Training Acc 51.34 % AVG Validation Acc 38.68 %\n",
      "Epoch:60/200 AVG Training Loss:0.693 AVG Validation Loss:0.721 AVG Training Acc 51.34 % AVG Validation Acc 39.22 %\n",
      "Epoch:70/200 AVG Training Loss:0.691 AVG Validation Loss:0.721 AVG Training Acc 52.62 % AVG Validation Acc 41.30 %\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.689 AVG Validation Loss:0.718 AVG Training Acc 53.44 % AVG Validation Acc 48.24 %\n",
      "Epoch:90/200 AVG Training Loss:0.687 AVG Validation Loss:0.708 AVG Training Acc 54.32 % AVG Validation Acc 50.59 %\n",
      "Epoch:100/200 AVG Training Loss:0.686 AVG Validation Loss:0.707 AVG Training Acc 54.75 % AVG Validation Acc 50.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.686 AVG Validation Loss:0.707 AVG Training Acc 54.06 % AVG Validation Acc 50.14 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.685 AVG Validation Loss:0.708 AVG Training Acc 54.50 % AVG Validation Acc 50.41 %\n",
      "Epoch:130/200 AVG Training Loss:0.685 AVG Validation Loss:0.708 AVG Training Acc 54.59 % AVG Validation Acc 50.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.685 AVG Validation Loss:0.708 AVG Training Acc 54.66 % AVG Validation Acc 50.32 %\n",
      "Epoch:150/200 AVG Training Loss:0.684 AVG Validation Loss:0.707 AVG Training Acc 54.66 % AVG Validation Acc 50.32 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.685 AVG Validation Loss:0.707 AVG Training Acc 54.83 % AVG Validation Acc 50.32 %\n",
      "Epoch:170/200 AVG Training Loss:0.685 AVG Validation Loss:0.707 AVG Training Acc 54.51 % AVG Validation Acc 50.32 %\n",
      "Epoch:180/200 AVG Training Loss:0.684 AVG Validation Loss:0.707 AVG Training Acc 54.87 % AVG Validation Acc 50.32 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.685 AVG Validation Loss:0.708 AVG Training Acc 54.62 % AVG Validation Acc 50.32 %\n",
      "Epoch:200/200 AVG Training Loss:0.685 AVG Validation Loss:0.707 AVG Training Acc 54.47 % AVG Validation Acc 50.32 %\n",
      "Split 52\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39b10cc5e1d54bf692e0f7fc95c197d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.651 AVG Validation Loss:4.280 AVG Training Acc 64.65 % AVG Validation Acc 38.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.677 AVG Validation Loss:2.927 AVG Training Acc 64.18 % AVG Validation Acc 38.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.675 AVG Validation Loss:1.288 AVG Training Acc 60.67 % AVG Validation Acc 38.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.671 AVG Validation Loss:1.292 AVG Training Acc 60.66 % AVG Validation Acc 38.14 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.691 AVG Validation Loss:0.719 AVG Training Acc 53.13 % AVG Validation Acc 45.90 %\n",
      "Epoch:60/200 AVG Training Loss:0.689 AVG Validation Loss:0.715 AVG Training Acc 54.66 % AVG Validation Acc 47.79 %\n",
      "Epoch:70/200 AVG Training Loss:0.687 AVG Validation Loss:0.714 AVG Training Acc 54.81 % AVG Validation Acc 48.33 %\n",
      "Epoch:80/200 AVG Training Loss:0.686 AVG Validation Loss:0.714 AVG Training Acc 55.17 % AVG Validation Acc 47.88 %\n",
      "Epoch:90/200 AVG Training Loss:0.686 AVG Validation Loss:0.714 AVG Training Acc 54.99 % AVG Validation Acc 48.06 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.681 AVG Validation Loss:0.703 AVG Training Acc 56.21 % AVG Validation Acc 48.15 %\n",
      "Epoch:110/200 AVG Training Loss:0.680 AVG Validation Loss:0.697 AVG Training Acc 55.96 % AVG Validation Acc 49.50 %\n",
      "Epoch:120/200 AVG Training Loss:0.679 AVG Validation Loss:0.695 AVG Training Acc 56.46 % AVG Validation Acc 49.86 %\n",
      "Epoch:130/200 AVG Training Loss:0.679 AVG Validation Loss:0.695 AVG Training Acc 56.39 % AVG Validation Acc 50.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.679 AVG Validation Loss:0.694 AVG Training Acc 56.11 % AVG Validation Acc 50.14 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.680 AVG Validation Loss:0.694 AVG Training Acc 56.06 % AVG Validation Acc 50.23 %\n",
      "Epoch:160/200 AVG Training Loss:0.679 AVG Validation Loss:0.694 AVG Training Acc 56.14 % AVG Validation Acc 50.41 %\n",
      "Epoch:170/200 AVG Training Loss:0.679 AVG Validation Loss:0.694 AVG Training Acc 56.25 % AVG Validation Acc 50.23 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:180/200 AVG Training Loss:0.679 AVG Validation Loss:0.694 AVG Training Acc 56.18 % AVG Validation Acc 50.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.679 AVG Validation Loss:0.694 AVG Training Acc 56.30 % AVG Validation Acc 50.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.679 AVG Validation Loss:0.694 AVG Training Acc 56.32 % AVG Validation Acc 50.23 %\n",
      "Split 53\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fc323661c4149bdac50a027472e8bc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.656 AVG Validation Loss:2.785 AVG Training Acc 63.64 % AVG Validation Acc 38.14 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.665 AVG Validation Loss:1.314 AVG Training Acc 58.77 % AVG Validation Acc 38.23 %\n",
      "Epoch:30/200 AVG Training Loss:0.667 AVG Validation Loss:1.390 AVG Training Acc 62.92 % AVG Validation Acc 38.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.664 AVG Validation Loss:0.994 AVG Training Acc 61.23 % AVG Validation Acc 38.41 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.721 AVG Validation Loss:0.756 AVG Training Acc 50.75 % AVG Validation Acc 39.68 %\n",
      "Epoch:60/200 AVG Training Loss:0.688 AVG Validation Loss:0.695 AVG Training Acc 54.09 % AVG Validation Acc 46.89 %\n",
      "Epoch:70/200 AVG Training Loss:0.687 AVG Validation Loss:0.695 AVG Training Acc 54.03 % AVG Validation Acc 47.52 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.686 AVG Validation Loss:0.695 AVG Training Acc 54.38 % AVG Validation Acc 47.07 %\n",
      "Epoch:90/200 AVG Training Loss:0.685 AVG Validation Loss:0.690 AVG Training Acc 54.87 % AVG Validation Acc 48.87 %\n",
      "Epoch:100/200 AVG Training Loss:0.686 AVG Validation Loss:0.688 AVG Training Acc 54.58 % AVG Validation Acc 50.68 %\n",
      "Epoch:110/200 AVG Training Loss:0.684 AVG Validation Loss:0.687 AVG Training Acc 55.05 % AVG Validation Acc 50.59 %\n",
      "Epoch:120/200 AVG Training Loss:0.684 AVG Validation Loss:0.687 AVG Training Acc 55.19 % AVG Validation Acc 50.59 %\n",
      "Epoch:130/200 AVG Training Loss:0.686 AVG Validation Loss:0.686 AVG Training Acc 54.88 % AVG Validation Acc 51.04 %\n",
      "Epoch:140/200 AVG Training Loss:0.685 AVG Validation Loss:0.686 AVG Training Acc 54.88 % AVG Validation Acc 51.22 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.684 AVG Validation Loss:0.686 AVG Training Acc 55.26 % AVG Validation Acc 50.77 %\n",
      "Epoch:160/200 AVG Training Loss:0.685 AVG Validation Loss:0.686 AVG Training Acc 54.91 % AVG Validation Acc 50.95 %\n",
      "Epoch:170/200 AVG Training Loss:0.685 AVG Validation Loss:0.686 AVG Training Acc 55.07 % AVG Validation Acc 51.13 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.685 AVG Validation Loss:0.686 AVG Training Acc 55.05 % AVG Validation Acc 51.31 %\n",
      "Epoch:190/200 AVG Training Loss:0.685 AVG Validation Loss:0.686 AVG Training Acc 54.72 % AVG Validation Acc 50.50 %\n",
      "Epoch:200/200 AVG Training Loss:0.685 AVG Validation Loss:0.686 AVG Training Acc 54.97 % AVG Validation Acc 51.13 %\n",
      "Split 54\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ebc026d15034e4998eb99d4d886c9b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.654 AVG Validation Loss:2.395 AVG Training Acc 65.21 % AVG Validation Acc 38.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.668 AVG Validation Loss:2.794 AVG Training Acc 63.48 % AVG Validation Acc 38.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.665 AVG Validation Loss:2.186 AVG Training Acc 64.43 % AVG Validation Acc 38.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.675 AVG Validation Loss:1.206 AVG Training Acc 59.96 % AVG Validation Acc 38.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.680 AVG Validation Loss:1.238 AVG Training Acc 60.40 % AVG Validation Acc 38.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.673 AVG Validation Loss:1.229 AVG Training Acc 59.95 % AVG Validation Acc 38.05 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:70/200 AVG Training Loss:0.695 AVG Validation Loss:0.729 AVG Training Acc 52.21 % AVG Validation Acc 43.37 %\n",
      "Epoch:80/200 AVG Training Loss:0.688 AVG Validation Loss:0.720 AVG Training Acc 53.34 % AVG Validation Acc 45.99 %\n",
      "Epoch:90/200 AVG Training Loss:0.686 AVG Validation Loss:0.721 AVG Training Acc 53.47 % AVG Validation Acc 46.89 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.684 AVG Validation Loss:0.717 AVG Training Acc 54.71 % AVG Validation Acc 48.51 %\n",
      "Epoch:110/200 AVG Training Loss:0.682 AVG Validation Loss:0.710 AVG Training Acc 55.37 % AVG Validation Acc 50.59 %\n",
      "Epoch:120/200 AVG Training Loss:0.681 AVG Validation Loss:0.708 AVG Training Acc 55.19 % AVG Validation Acc 50.95 %\n",
      "Epoch:130/200 AVG Training Loss:0.682 AVG Validation Loss:0.708 AVG Training Acc 55.30 % AVG Validation Acc 51.31 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:140/200 AVG Training Loss:0.681 AVG Validation Loss:0.708 AVG Training Acc 55.38 % AVG Validation Acc 51.49 %\n",
      "Epoch:150/200 AVG Training Loss:0.680 AVG Validation Loss:0.708 AVG Training Acc 55.50 % AVG Validation Acc 51.49 %\n",
      "Epoch:160/200 AVG Training Loss:0.681 AVG Validation Loss:0.708 AVG Training Acc 54.97 % AVG Validation Acc 51.58 %\n",
      "Epoch:170/200 AVG Training Loss:0.680 AVG Validation Loss:0.708 AVG Training Acc 55.55 % AVG Validation Acc 51.40 %\n",
      "Epoch:180/200 AVG Training Loss:0.681 AVG Validation Loss:0.707 AVG Training Acc 55.34 % AVG Validation Acc 51.94 %\n",
      "Epoch:190/200 AVG Training Loss:0.681 AVG Validation Loss:0.707 AVG Training Acc 55.42 % AVG Validation Acc 51.67 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:200/200 AVG Training Loss:0.680 AVG Validation Loss:0.708 AVG Training Acc 55.34 % AVG Validation Acc 51.40 %\n",
      "Split 55\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35d76fa818a3475380284fa80cadeac5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:2.843 AVG Training Acc 65.50 % AVG Validation Acc 38.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.665 AVG Validation Loss:1.654 AVG Training Acc 62.36 % AVG Validation Acc 38.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.683 AVG Validation Loss:3.745 AVG Training Acc 66.37 % AVG Validation Acc 38.14 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.692 AVG Validation Loss:0.887 AVG Training Acc 56.45 % AVG Validation Acc 38.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.693 AVG Validation Loss:0.808 AVG Training Acc 54.44 % AVG Validation Acc 38.32 %\n",
      "Epoch:60/200 AVG Training Loss:0.689 AVG Validation Loss:0.761 AVG Training Acc 54.35 % AVG Validation Acc 38.59 %\n",
      "Epoch:70/200 AVG Training Loss:0.687 AVG Validation Loss:0.754 AVG Training Acc 54.36 % AVG Validation Acc 39.22 %\n",
      "Epoch:80/200 AVG Training Loss:0.686 AVG Validation Loss:0.747 AVG Training Acc 54.58 % AVG Validation Acc 40.49 %\n",
      "Epoch:90/200 AVG Training Loss:0.684 AVG Validation Loss:0.741 AVG Training Acc 54.49 % AVG Validation Acc 40.13 %\n",
      "Epoch:100/200 AVG Training Loss:0.680 AVG Validation Loss:0.740 AVG Training Acc 55.04 % AVG Validation Acc 40.58 %\n",
      "Epoch:110/200 AVG Training Loss:0.680 AVG Validation Loss:0.740 AVG Training Acc 55.30 % AVG Validation Acc 40.40 %\n",
      "Epoch:120/200 AVG Training Loss:0.677 AVG Validation Loss:0.740 AVG Training Acc 55.09 % AVG Validation Acc 40.94 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:130/200 AVG Training Loss:0.675 AVG Validation Loss:0.714 AVG Training Acc 55.76 % AVG Validation Acc 46.53 %\n",
      "Epoch:140/200 AVG Training Loss:0.673 AVG Validation Loss:0.709 AVG Training Acc 55.94 % AVG Validation Acc 46.80 %\n",
      "Epoch:150/200 AVG Training Loss:0.673 AVG Validation Loss:0.709 AVG Training Acc 55.93 % AVG Validation Acc 46.89 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:160/200 AVG Training Loss:0.672 AVG Validation Loss:0.710 AVG Training Acc 56.24 % AVG Validation Acc 46.98 %\n",
      "Epoch:170/200 AVG Training Loss:0.671 AVG Validation Loss:0.710 AVG Training Acc 56.62 % AVG Validation Acc 47.07 %\n",
      "Epoch:180/200 AVG Training Loss:0.672 AVG Validation Loss:0.709 AVG Training Acc 56.15 % AVG Validation Acc 47.16 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:190/200 AVG Training Loss:0.669 AVG Validation Loss:0.709 AVG Training Acc 56.33 % AVG Validation Acc 47.34 %\n",
      "Epoch:200/200 AVG Training Loss:0.672 AVG Validation Loss:0.709 AVG Training Acc 55.83 % AVG Validation Acc 46.98 %\n",
      "Split 56\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b71413cc86da43cebb41de1001b77f3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:3.490 AVG Training Acc 65.41 % AVG Validation Acc 38.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.665 AVG Validation Loss:1.828 AVG Training Acc 62.66 % AVG Validation Acc 38.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.768 AVG Validation Loss:7.802 AVG Training Acc 62.31 % AVG Validation Acc 38.09 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.756 AVG Validation Loss:0.783 AVG Training Acc 50.05 % AVG Validation Acc 37.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.691 AVG Validation Loss:0.712 AVG Training Acc 52.71 % AVG Validation Acc 43.68 %\n",
      "Epoch:60/200 AVG Training Loss:0.692 AVG Validation Loss:0.711 AVG Training Acc 52.54 % AVG Validation Acc 44.77 %\n",
      "Epoch:70/200 AVG Training Loss:0.690 AVG Validation Loss:0.710 AVG Training Acc 53.02 % AVG Validation Acc 46.03 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.689 AVG Validation Loss:0.703 AVG Training Acc 53.85 % AVG Validation Acc 48.47 %\n",
      "Epoch:90/200 AVG Training Loss:0.687 AVG Validation Loss:0.693 AVG Training Acc 54.62 % AVG Validation Acc 51.90 %\n",
      "Epoch:100/200 AVG Training Loss:0.686 AVG Validation Loss:0.691 AVG Training Acc 54.68 % AVG Validation Acc 51.26 %\n",
      "Epoch:110/200 AVG Training Loss:0.686 AVG Validation Loss:0.690 AVG Training Acc 54.78 % AVG Validation Acc 51.17 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.685 AVG Validation Loss:0.690 AVG Training Acc 55.23 % AVG Validation Acc 51.17 %\n",
      "Epoch:130/200 AVG Training Loss:0.685 AVG Validation Loss:0.690 AVG Training Acc 54.97 % AVG Validation Acc 51.17 %\n",
      "Epoch:140/200 AVG Training Loss:0.685 AVG Validation Loss:0.690 AVG Training Acc 55.09 % AVG Validation Acc 50.99 %\n",
      "Epoch:150/200 AVG Training Loss:0.684 AVG Validation Loss:0.690 AVG Training Acc 54.92 % AVG Validation Acc 51.08 %\n",
      "Epoch:160/200 AVG Training Loss:0.685 AVG Validation Loss:0.690 AVG Training Acc 55.04 % AVG Validation Acc 51.08 %\n",
      "Epoch   166: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:170/200 AVG Training Loss:0.685 AVG Validation Loss:0.690 AVG Training Acc 55.07 % AVG Validation Acc 51.08 %\n",
      "Epoch:180/200 AVG Training Loss:0.685 AVG Validation Loss:0.690 AVG Training Acc 55.26 % AVG Validation Acc 50.99 %\n",
      "Epoch:190/200 AVG Training Loss:0.684 AVG Validation Loss:0.690 AVG Training Acc 55.39 % AVG Validation Acc 51.26 %\n",
      "Epoch:200/200 AVG Training Loss:0.686 AVG Validation Loss:0.690 AVG Training Acc 55.23 % AVG Validation Acc 51.08 %\n",
      "Split 57\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb76aecad471464a8aa5feb12d8524df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.645 AVG Validation Loss:2.965 AVG Training Acc 64.26 % AVG Validation Acc 38.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:5.174 AVG Training Acc 65.16 % AVG Validation Acc 38.09 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.697 AVG Validation Loss:0.735 AVG Training Acc 51.25 % AVG Validation Acc 38.45 %\n",
      "Epoch:40/200 AVG Training Loss:0.694 AVG Validation Loss:0.730 AVG Training Acc 51.53 % AVG Validation Acc 38.81 %\n",
      "Epoch:50/200 AVG Training Loss:0.692 AVG Validation Loss:0.725 AVG Training Acc 52.57 % AVG Validation Acc 38.99 %\n",
      "Epoch:60/200 AVG Training Loss:0.693 AVG Validation Loss:0.721 AVG Training Acc 51.99 % AVG Validation Acc 40.52 %\n",
      "Epoch:70/200 AVG Training Loss:0.692 AVG Validation Loss:0.717 AVG Training Acc 52.05 % AVG Validation Acc 41.97 %\n",
      "Epoch:80/200 AVG Training Loss:0.691 AVG Validation Loss:0.717 AVG Training Acc 52.25 % AVG Validation Acc 43.05 %\n",
      "Epoch:90/200 AVG Training Loss:0.689 AVG Validation Loss:0.712 AVG Training Acc 53.23 % AVG Validation Acc 44.68 %\n",
      "Epoch:100/200 AVG Training Loss:0.687 AVG Validation Loss:0.714 AVG Training Acc 53.73 % AVG Validation Acc 42.78 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:110/200 AVG Training Loss:0.683 AVG Validation Loss:0.696 AVG Training Acc 55.33 % AVG Validation Acc 50.63 %\n",
      "Epoch:120/200 AVG Training Loss:0.683 AVG Validation Loss:0.692 AVG Training Acc 55.41 % AVG Validation Acc 50.99 %\n",
      "Epoch:130/200 AVG Training Loss:0.682 AVG Validation Loss:0.691 AVG Training Acc 55.63 % AVG Validation Acc 51.35 %\n",
      "Epoch:140/200 AVG Training Loss:0.681 AVG Validation Loss:0.690 AVG Training Acc 55.43 % AVG Validation Acc 51.44 %\n",
      "Epoch:150/200 AVG Training Loss:0.681 AVG Validation Loss:0.691 AVG Training Acc 55.68 % AVG Validation Acc 51.08 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:160/200 AVG Training Loss:0.680 AVG Validation Loss:0.690 AVG Training Acc 55.74 % AVG Validation Acc 51.26 %\n",
      "Epoch:170/200 AVG Training Loss:0.680 AVG Validation Loss:0.690 AVG Training Acc 55.94 % AVG Validation Acc 51.26 %\n",
      "Epoch:180/200 AVG Training Loss:0.680 AVG Validation Loss:0.690 AVG Training Acc 55.66 % AVG Validation Acc 51.53 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:190/200 AVG Training Loss:0.680 AVG Validation Loss:0.690 AVG Training Acc 55.72 % AVG Validation Acc 51.44 %\n",
      "Epoch:200/200 AVG Training Loss:0.680 AVG Validation Loss:0.690 AVG Training Acc 55.57 % AVG Validation Acc 51.90 %\n",
      "Split 58\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dc3a52cfae44d7e9967a64478dc0b2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.623 AVG Validation Loss:4.864 AVG Training Acc 66.13 % AVG Validation Acc 38.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.663 AVG Validation Loss:2.030 AVG Training Acc 63.58 % AVG Validation Acc 38.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.674 AVG Validation Loss:1.477 AVG Training Acc 60.74 % AVG Validation Acc 38.09 %\n",
      "Epoch:40/200 AVG Training Loss:0.672 AVG Validation Loss:1.401 AVG Training Acc 60.82 % AVG Validation Acc 38.09 %\n",
      "Epoch:50/200 AVG Training Loss:0.690 AVG Validation Loss:1.298 AVG Training Acc 61.33 % AVG Validation Acc 38.09 %\n",
      "Epoch:60/200 AVG Training Loss:0.677 AVG Validation Loss:1.182 AVG Training Acc 59.71 % AVG Validation Acc 38.09 %\n",
      "Epoch:70/200 AVG Training Loss:0.676 AVG Validation Loss:1.208 AVG Training Acc 59.88 % AVG Validation Acc 38.09 %\n",
      "Epoch    71: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:80/200 AVG Training Loss:0.693 AVG Validation Loss:0.709 AVG Training Acc 50.03 % AVG Validation Acc 39.71 %\n",
      "Epoch:90/200 AVG Training Loss:0.691 AVG Validation Loss:0.708 AVG Training Acc 51.67 % AVG Validation Acc 43.95 %\n",
      "Epoch:100/200 AVG Training Loss:0.690 AVG Validation Loss:0.706 AVG Training Acc 52.60 % AVG Validation Acc 47.02 %\n",
      "Epoch:110/200 AVG Training Loss:0.689 AVG Validation Loss:0.708 AVG Training Acc 52.83 % AVG Validation Acc 48.47 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:120/200 AVG Training Loss:0.688 AVG Validation Loss:0.696 AVG Training Acc 53.28 % AVG Validation Acc 50.18 %\n",
      "Epoch:130/200 AVG Training Loss:0.686 AVG Validation Loss:0.692 AVG Training Acc 54.01 % AVG Validation Acc 52.08 %\n",
      "Epoch:140/200 AVG Training Loss:0.686 AVG Validation Loss:0.692 AVG Training Acc 54.09 % AVG Validation Acc 52.71 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.686 AVG Validation Loss:0.691 AVG Training Acc 54.11 % AVG Validation Acc 52.71 %\n",
      "Epoch:160/200 AVG Training Loss:0.686 AVG Validation Loss:0.691 AVG Training Acc 53.89 % AVG Validation Acc 52.80 %\n",
      "Epoch:170/200 AVG Training Loss:0.687 AVG Validation Loss:0.690 AVG Training Acc 53.72 % AVG Validation Acc 52.62 %\n",
      "Epoch:180/200 AVG Training Loss:0.685 AVG Validation Loss:0.691 AVG Training Acc 54.37 % AVG Validation Acc 52.44 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:190/200 AVG Training Loss:0.686 AVG Validation Loss:0.690 AVG Training Acc 54.10 % AVG Validation Acc 52.80 %\n",
      "Epoch:200/200 AVG Training Loss:0.687 AVG Validation Loss:0.690 AVG Training Acc 53.66 % AVG Validation Acc 52.44 %\n",
      "Split 59\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac009570304d45d297bfc72a5db23c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.664 AVG Validation Loss:1.871 AVG Training Acc 63.24 % AVG Validation Acc 38.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.675 AVG Validation Loss:1.281 AVG Training Acc 60.76 % AVG Validation Acc 38.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.676 AVG Validation Loss:1.259 AVG Training Acc 60.36 % AVG Validation Acc 38.09 %\n",
      "Epoch:40/200 AVG Training Loss:0.670 AVG Validation Loss:1.934 AVG Training Acc 60.40 % AVG Validation Acc 38.18 %\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.689 AVG Validation Loss:0.715 AVG Training Acc 54.09 % AVG Validation Acc 44.40 %\n",
      "Epoch:60/200 AVG Training Loss:0.689 AVG Validation Loss:0.712 AVG Training Acc 53.97 % AVG Validation Acc 45.31 %\n",
      "Epoch:70/200 AVG Training Loss:0.686 AVG Validation Loss:0.714 AVG Training Acc 54.45 % AVG Validation Acc 46.12 %\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.684 AVG Validation Loss:0.705 AVG Training Acc 55.17 % AVG Validation Acc 47.11 %\n",
      "Epoch:90/200 AVG Training Loss:0.683 AVG Validation Loss:0.697 AVG Training Acc 55.38 % AVG Validation Acc 48.01 %\n",
      "Epoch:100/200 AVG Training Loss:0.682 AVG Validation Loss:0.695 AVG Training Acc 55.38 % AVG Validation Acc 48.01 %\n",
      "Epoch:110/200 AVG Training Loss:0.682 AVG Validation Loss:0.695 AVG Training Acc 55.51 % AVG Validation Acc 48.83 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.682 AVG Validation Loss:0.695 AVG Training Acc 55.79 % AVG Validation Acc 48.29 %\n",
      "Epoch:130/200 AVG Training Loss:0.681 AVG Validation Loss:0.695 AVG Training Acc 56.08 % AVG Validation Acc 48.47 %\n",
      "Epoch:140/200 AVG Training Loss:0.682 AVG Validation Loss:0.695 AVG Training Acc 55.55 % AVG Validation Acc 48.83 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.682 AVG Validation Loss:0.695 AVG Training Acc 55.58 % AVG Validation Acc 48.74 %\n",
      "Epoch:160/200 AVG Training Loss:0.682 AVG Validation Loss:0.695 AVG Training Acc 55.57 % AVG Validation Acc 48.92 %\n",
      "Epoch:170/200 AVG Training Loss:0.682 AVG Validation Loss:0.694 AVG Training Acc 55.36 % AVG Validation Acc 48.74 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.682 AVG Validation Loss:0.695 AVG Training Acc 55.90 % AVG Validation Acc 49.19 %\n",
      "Epoch:190/200 AVG Training Loss:0.683 AVG Validation Loss:0.695 AVG Training Acc 55.49 % AVG Validation Acc 48.92 %\n",
      "Epoch:200/200 AVG Training Loss:0.682 AVG Validation Loss:0.695 AVG Training Acc 55.29 % AVG Validation Acc 49.01 %\n",
      "Split 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "146fb978fb054bc6a836b931155ae170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.665 AVG Validation Loss:3.597 AVG Training Acc 64.42 % AVG Validation Acc 38.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.656 AVG Validation Loss:2.564 AVG Training Acc 64.91 % AVG Validation Acc 38.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.699 AVG Validation Loss:1.589 AVG Training Acc 62.15 % AVG Validation Acc 38.09 %\n",
      "Epoch:40/200 AVG Training Loss:0.666 AVG Validation Loss:6.142 AVG Training Acc 61.12 % AVG Validation Acc 38.09 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.884 AVG Validation Loss:0.893 AVG Training Acc 50.01 % AVG Validation Acc 38.18 %\n",
      "Epoch:60/200 AVG Training Loss:0.692 AVG Validation Loss:0.710 AVG Training Acc 51.45 % AVG Validation Acc 41.52 %\n",
      "Epoch:70/200 AVG Training Loss:0.691 AVG Validation Loss:0.712 AVG Training Acc 52.84 % AVG Validation Acc 43.86 %\n",
      "Epoch:80/200 AVG Training Loss:0.691 AVG Validation Loss:0.714 AVG Training Acc 53.23 % AVG Validation Acc 43.59 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.688 AVG Validation Loss:0.700 AVG Training Acc 54.12 % AVG Validation Acc 46.93 %\n",
      "Epoch:100/200 AVG Training Loss:0.687 AVG Validation Loss:0.695 AVG Training Acc 54.04 % AVG Validation Acc 48.83 %\n",
      "Epoch:110/200 AVG Training Loss:0.687 AVG Validation Loss:0.694 AVG Training Acc 54.40 % AVG Validation Acc 49.55 %\n",
      "Epoch:120/200 AVG Training Loss:0.686 AVG Validation Loss:0.694 AVG Training Acc 54.53 % AVG Validation Acc 49.64 %\n",
      "Epoch:130/200 AVG Training Loss:0.686 AVG Validation Loss:0.693 AVG Training Acc 54.48 % AVG Validation Acc 50.09 %\n",
      "Epoch:140/200 AVG Training Loss:0.686 AVG Validation Loss:0.693 AVG Training Acc 54.45 % AVG Validation Acc 50.00 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.686 AVG Validation Loss:0.693 AVG Training Acc 54.80 % AVG Validation Acc 50.27 %\n",
      "Epoch:160/200 AVG Training Loss:0.685 AVG Validation Loss:0.693 AVG Training Acc 54.86 % AVG Validation Acc 50.18 %\n",
      "Epoch:170/200 AVG Training Loss:0.685 AVG Validation Loss:0.693 AVG Training Acc 54.94 % AVG Validation Acc 50.18 %\n",
      "Epoch:180/200 AVG Training Loss:0.685 AVG Validation Loss:0.693 AVG Training Acc 55.02 % AVG Validation Acc 50.18 %\n",
      "Epoch:190/200 AVG Training Loss:0.686 AVG Validation Loss:0.693 AVG Training Acc 54.51 % AVG Validation Acc 50.09 %\n",
      "Epoch:200/200 AVG Training Loss:0.686 AVG Validation Loss:0.693 AVG Training Acc 54.28 % AVG Validation Acc 50.00 %\n",
      "Split 61\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b9adf8bedd84774b5b348d599770168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.642 AVG Validation Loss:4.378 AVG Training Acc 65.86 % AVG Validation Acc 38.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.676 AVG Validation Loss:1.315 AVG Training Acc 60.97 % AVG Validation Acc 38.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.673 AVG Validation Loss:2.903 AVG Training Acc 65.26 % AVG Validation Acc 38.05 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.698 AVG Validation Loss:0.716 AVG Training Acc 48.96 % AVG Validation Acc 39.31 %\n",
      "Epoch:50/200 AVG Training Loss:0.693 AVG Validation Loss:0.712 AVG Training Acc 51.09 % AVG Validation Acc 40.22 %\n",
      "Epoch:60/200 AVG Training Loss:0.691 AVG Validation Loss:0.715 AVG Training Acc 53.08 % AVG Validation Acc 43.55 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.688 AVG Validation Loss:0.706 AVG Training Acc 54.51 % AVG Validation Acc 46.89 %\n",
      "Epoch:80/200 AVG Training Loss:0.687 AVG Validation Loss:0.696 AVG Training Acc 54.84 % AVG Validation Acc 48.15 %\n",
      "Epoch:90/200 AVG Training Loss:0.685 AVG Validation Loss:0.693 AVG Training Acc 55.25 % AVG Validation Acc 49.32 %\n",
      "Epoch:100/200 AVG Training Loss:0.686 AVG Validation Loss:0.693 AVG Training Acc 55.30 % AVG Validation Acc 49.59 %\n",
      "Epoch:110/200 AVG Training Loss:0.685 AVG Validation Loss:0.692 AVG Training Acc 55.17 % AVG Validation Acc 49.95 %\n",
      "Epoch:120/200 AVG Training Loss:0.685 AVG Validation Loss:0.692 AVG Training Acc 55.36 % AVG Validation Acc 50.23 %\n",
      "Epoch:130/200 AVG Training Loss:0.685 AVG Validation Loss:0.692 AVG Training Acc 55.44 % AVG Validation Acc 50.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.686 AVG Validation Loss:0.692 AVG Training Acc 55.16 % AVG Validation Acc 50.23 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.684 AVG Validation Loss:0.692 AVG Training Acc 55.65 % AVG Validation Acc 50.23 %\n",
      "Epoch:160/200 AVG Training Loss:0.685 AVG Validation Loss:0.692 AVG Training Acc 55.62 % AVG Validation Acc 50.59 %\n",
      "Epoch:170/200 AVG Training Loss:0.685 AVG Validation Loss:0.692 AVG Training Acc 55.21 % AVG Validation Acc 50.59 %\n",
      "Epoch:180/200 AVG Training Loss:0.685 AVG Validation Loss:0.691 AVG Training Acc 55.77 % AVG Validation Acc 50.41 %\n",
      "Epoch:190/200 AVG Training Loss:0.685 AVG Validation Loss:0.691 AVG Training Acc 55.45 % AVG Validation Acc 50.50 %\n",
      "Epoch:200/200 AVG Training Loss:0.684 AVG Validation Loss:0.691 AVG Training Acc 55.42 % AVG Validation Acc 50.59 %\n",
      "Split 62\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0ae55d9aca742ae820301ef78ed76b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.653 AVG Validation Loss:3.830 AVG Training Acc 64.45 % AVG Validation Acc 38.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:3.340 AVG Training Acc 64.48 % AVG Validation Acc 38.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.651 AVG Validation Loss:6.656 AVG Training Acc 60.86 % AVG Validation Acc 38.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.647 AVG Validation Loss:2.738 AVG Training Acc 65.32 % AVG Validation Acc 38.14 %\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.692 AVG Validation Loss:0.767 AVG Training Acc 54.37 % AVG Validation Acc 38.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.690 AVG Validation Loss:0.753 AVG Training Acc 54.12 % AVG Validation Acc 38.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.678 AVG Validation Loss:0.782 AVG Training Acc 58.35 % AVG Validation Acc 38.14 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.687 AVG Validation Loss:0.702 AVG Training Acc 54.78 % AVG Validation Acc 48.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.685 AVG Validation Loss:0.694 AVG Training Acc 55.22 % AVG Validation Acc 49.41 %\n",
      "Epoch:100/200 AVG Training Loss:0.685 AVG Validation Loss:0.693 AVG Training Acc 55.39 % AVG Validation Acc 48.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.684 AVG Validation Loss:0.693 AVG Training Acc 55.35 % AVG Validation Acc 49.14 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.683 AVG Validation Loss:0.692 AVG Training Acc 55.57 % AVG Validation Acc 49.77 %\n",
      "Epoch:130/200 AVG Training Loss:0.683 AVG Validation Loss:0.691 AVG Training Acc 55.51 % AVG Validation Acc 49.68 %\n",
      "Epoch:140/200 AVG Training Loss:0.684 AVG Validation Loss:0.691 AVG Training Acc 55.50 % AVG Validation Acc 49.86 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.683 AVG Validation Loss:0.691 AVG Training Acc 55.77 % AVG Validation Acc 49.59 %\n",
      "Epoch:160/200 AVG Training Loss:0.683 AVG Validation Loss:0.690 AVG Training Acc 55.57 % AVG Validation Acc 49.77 %\n",
      "Epoch:170/200 AVG Training Loss:0.683 AVG Validation Loss:0.690 AVG Training Acc 55.56 % AVG Validation Acc 49.59 %\n",
      "Epoch:180/200 AVG Training Loss:0.682 AVG Validation Loss:0.691 AVG Training Acc 55.50 % AVG Validation Acc 49.50 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.683 AVG Validation Loss:0.691 AVG Training Acc 55.69 % AVG Validation Acc 49.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.682 AVG Validation Loss:0.690 AVG Training Acc 55.55 % AVG Validation Acc 49.86 %\n",
      "Split 63\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d78579362e9d4161bc6779a1f21c54a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:2.319 AVG Training Acc 63.81 % AVG Validation Acc 38.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.675 AVG Validation Loss:1.290 AVG Training Acc 60.83 % AVG Validation Acc 38.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.674 AVG Validation Loss:1.225 AVG Training Acc 60.22 % AVG Validation Acc 38.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.676 AVG Validation Loss:1.381 AVG Training Acc 59.85 % AVG Validation Acc 38.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.732 AVG Validation Loss:1.217 AVG Training Acc 60.44 % AVG Validation Acc 38.14 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.691 AVG Validation Loss:0.707 AVG Training Acc 52.93 % AVG Validation Acc 46.44 %\n",
      "Epoch:70/200 AVG Training Loss:0.689 AVG Validation Loss:0.707 AVG Training Acc 53.35 % AVG Validation Acc 48.51 %\n",
      "Epoch:80/200 AVG Training Loss:0.688 AVG Validation Loss:0.708 AVG Training Acc 54.34 % AVG Validation Acc 48.78 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.685 AVG Validation Loss:0.697 AVG Training Acc 55.02 % AVG Validation Acc 50.41 %\n",
      "Epoch:100/200 AVG Training Loss:0.686 AVG Validation Loss:0.691 AVG Training Acc 55.30 % AVG Validation Acc 51.31 %\n",
      "Epoch:110/200 AVG Training Loss:0.686 AVG Validation Loss:0.689 AVG Training Acc 54.96 % AVG Validation Acc 52.03 %\n",
      "Epoch:120/200 AVG Training Loss:0.685 AVG Validation Loss:0.688 AVG Training Acc 55.49 % AVG Validation Acc 51.94 %\n",
      "Epoch:130/200 AVG Training Loss:0.685 AVG Validation Loss:0.688 AVG Training Acc 55.72 % AVG Validation Acc 51.85 %\n",
      "Epoch:140/200 AVG Training Loss:0.685 AVG Validation Loss:0.688 AVG Training Acc 55.23 % AVG Validation Acc 52.03 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.684 AVG Validation Loss:0.688 AVG Training Acc 55.41 % AVG Validation Acc 52.03 %\n",
      "Epoch:160/200 AVG Training Loss:0.684 AVG Validation Loss:0.687 AVG Training Acc 55.40 % AVG Validation Acc 52.21 %\n",
      "Epoch:170/200 AVG Training Loss:0.684 AVG Validation Loss:0.687 AVG Training Acc 55.43 % AVG Validation Acc 51.94 %\n",
      "Epoch:180/200 AVG Training Loss:0.685 AVG Validation Loss:0.687 AVG Training Acc 55.77 % AVG Validation Acc 51.85 %\n",
      "Epoch:190/200 AVG Training Loss:0.684 AVG Validation Loss:0.687 AVG Training Acc 55.47 % AVG Validation Acc 51.94 %\n",
      "Epoch   196: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:200/200 AVG Training Loss:0.684 AVG Validation Loss:0.687 AVG Training Acc 55.63 % AVG Validation Acc 52.12 %\n",
      "Split 64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03249e215614183be7e1122ff12a7bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:2.350 AVG Training Acc 65.19 % AVG Validation Acc 38.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.678 AVG Validation Loss:2.334 AVG Training Acc 63.23 % AVG Validation Acc 38.14 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.694 AVG Validation Loss:0.941 AVG Training Acc 54.42 % AVG Validation Acc 38.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.701 AVG Validation Loss:1.254 AVG Training Acc 60.43 % AVG Validation Acc 38.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.696 AVG Validation Loss:0.766 AVG Training Acc 53.59 % AVG Validation Acc 39.13 %\n",
      "Epoch:60/200 AVG Training Loss:0.691 AVG Validation Loss:0.726 AVG Training Acc 53.30 % AVG Validation Acc 43.55 %\n",
      "Epoch:70/200 AVG Training Loss:0.690 AVG Validation Loss:0.718 AVG Training Acc 53.34 % AVG Validation Acc 45.81 %\n",
      "Epoch:80/200 AVG Training Loss:0.690 AVG Validation Loss:0.714 AVG Training Acc 53.26 % AVG Validation Acc 47.07 %\n",
      "Epoch:90/200 AVG Training Loss:0.687 AVG Validation Loss:0.712 AVG Training Acc 54.03 % AVG Validation Acc 46.17 %\n",
      "Epoch:100/200 AVG Training Loss:0.686 AVG Validation Loss:0.712 AVG Training Acc 54.55 % AVG Validation Acc 46.53 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:110/200 AVG Training Loss:0.686 AVG Validation Loss:0.699 AVG Training Acc 55.25 % AVG Validation Acc 50.50 %\n",
      "Epoch:120/200 AVG Training Loss:0.682 AVG Validation Loss:0.685 AVG Training Acc 55.67 % AVG Validation Acc 52.21 %\n",
      "Epoch:130/200 AVG Training Loss:0.681 AVG Validation Loss:0.682 AVG Training Acc 56.23 % AVG Validation Acc 52.48 %\n",
      "Epoch:140/200 AVG Training Loss:0.682 AVG Validation Loss:0.682 AVG Training Acc 56.02 % AVG Validation Acc 52.75 %\n",
      "Epoch:150/200 AVG Training Loss:0.681 AVG Validation Loss:0.682 AVG Training Acc 56.19 % AVG Validation Acc 53.02 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:160/200 AVG Training Loss:0.681 AVG Validation Loss:0.682 AVG Training Acc 56.49 % AVG Validation Acc 52.84 %\n",
      "Epoch:170/200 AVG Training Loss:0.680 AVG Validation Loss:0.681 AVG Training Acc 56.43 % AVG Validation Acc 52.84 %\n",
      "Epoch:180/200 AVG Training Loss:0.681 AVG Validation Loss:0.681 AVG Training Acc 56.11 % AVG Validation Acc 52.66 %\n",
      "Epoch:190/200 AVG Training Loss:0.682 AVG Validation Loss:0.681 AVG Training Acc 56.05 % AVG Validation Acc 52.84 %\n",
      "Epoch   197: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:200/200 AVG Training Loss:0.679 AVG Validation Loss:0.681 AVG Training Acc 56.28 % AVG Validation Acc 52.93 %\n",
      "Split 65\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e096203e2eb54f699f451d7985f9284b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:3.198 AVG Training Acc 64.72 % AVG Validation Acc 38.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:3.585 AVG Training Acc 64.75 % AVG Validation Acc 38.14 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.694 AVG Validation Loss:0.815 AVG Training Acc 54.25 % AVG Validation Acc 38.32 %\n",
      "Epoch:40/200 AVG Training Loss:0.695 AVG Validation Loss:0.754 AVG Training Acc 52.86 % AVG Validation Acc 38.50 %\n",
      "Epoch:50/200 AVG Training Loss:0.689 AVG Validation Loss:0.757 AVG Training Acc 54.04 % AVG Validation Acc 39.50 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.693 AVG Validation Loss:0.719 AVG Training Acc 53.05 % AVG Validation Acc 43.55 %\n",
      "Epoch:70/200 AVG Training Loss:0.686 AVG Validation Loss:0.697 AVG Training Acc 54.63 % AVG Validation Acc 47.34 %\n",
      "Epoch:80/200 AVG Training Loss:0.684 AVG Validation Loss:0.696 AVG Training Acc 55.12 % AVG Validation Acc 47.25 %\n",
      "Epoch:90/200 AVG Training Loss:0.683 AVG Validation Loss:0.694 AVG Training Acc 54.98 % AVG Validation Acc 48.15 %\n",
      "Epoch:100/200 AVG Training Loss:0.683 AVG Validation Loss:0.695 AVG Training Acc 55.18 % AVG Validation Acc 47.61 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.682 AVG Validation Loss:0.694 AVG Training Acc 55.34 % AVG Validation Acc 48.06 %\n",
      "Epoch:120/200 AVG Training Loss:0.682 AVG Validation Loss:0.694 AVG Training Acc 55.36 % AVG Validation Acc 48.24 %\n",
      "Epoch:130/200 AVG Training Loss:0.682 AVG Validation Loss:0.694 AVG Training Acc 55.55 % AVG Validation Acc 48.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.683 AVG Validation Loss:0.693 AVG Training Acc 55.30 % AVG Validation Acc 49.32 %\n",
      "Epoch:150/200 AVG Training Loss:0.682 AVG Validation Loss:0.692 AVG Training Acc 55.09 % AVG Validation Acc 49.41 %\n",
      "Epoch:160/200 AVG Training Loss:0.682 AVG Validation Loss:0.693 AVG Training Acc 55.42 % AVG Validation Acc 49.23 %\n",
      "Epoch   164: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:170/200 AVG Training Loss:0.682 AVG Validation Loss:0.692 AVG Training Acc 55.60 % AVG Validation Acc 49.77 %\n",
      "Epoch:180/200 AVG Training Loss:0.682 AVG Validation Loss:0.693 AVG Training Acc 55.54 % AVG Validation Acc 49.05 %\n",
      "Epoch:190/200 AVG Training Loss:0.682 AVG Validation Loss:0.692 AVG Training Acc 55.58 % AVG Validation Acc 49.68 %\n",
      "Epoch   195: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:200/200 AVG Training Loss:0.684 AVG Validation Loss:0.693 AVG Training Acc 54.81 % AVG Validation Acc 49.32 %\n",
      "Split 66\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7df8d974d97a4656a391d431d0d9393e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.671 AVG Validation Loss:1.593 AVG Training Acc 61.59 % AVG Validation Acc 38.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.672 AVG Validation Loss:3.665 AVG Training Acc 65.94 % AVG Validation Acc 38.09 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.699 AVG Validation Loss:0.742 AVG Training Acc 51.08 % AVG Validation Acc 38.18 %\n",
      "Epoch:40/200 AVG Training Loss:0.694 AVG Validation Loss:0.730 AVG Training Acc 51.37 % AVG Validation Acc 38.09 %\n",
      "Epoch:50/200 AVG Training Loss:0.692 AVG Validation Loss:0.726 AVG Training Acc 51.68 % AVG Validation Acc 39.08 %\n",
      "Epoch:60/200 AVG Training Loss:0.693 AVG Validation Loss:0.722 AVG Training Acc 51.30 % AVG Validation Acc 40.25 %\n",
      "Epoch:70/200 AVG Training Loss:0.691 AVG Validation Loss:0.720 AVG Training Acc 52.40 % AVG Validation Acc 41.79 %\n",
      "Epoch:80/200 AVG Training Loss:0.690 AVG Validation Loss:0.719 AVG Training Acc 52.95 % AVG Validation Acc 43.23 %\n",
      "Epoch:90/200 AVG Training Loss:0.690 AVG Validation Loss:0.718 AVG Training Acc 53.12 % AVG Validation Acc 43.59 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.687 AVG Validation Loss:0.713 AVG Training Acc 53.94 % AVG Validation Acc 45.49 %\n",
      "Epoch:110/200 AVG Training Loss:0.684 AVG Validation Loss:0.701 AVG Training Acc 55.15 % AVG Validation Acc 49.46 %\n",
      "Epoch:120/200 AVG Training Loss:0.683 AVG Validation Loss:0.698 AVG Training Acc 55.37 % AVG Validation Acc 50.18 %\n",
      "Epoch:130/200 AVG Training Loss:0.683 AVG Validation Loss:0.697 AVG Training Acc 55.24 % AVG Validation Acc 50.54 %\n",
      "Epoch:140/200 AVG Training Loss:0.682 AVG Validation Loss:0.697 AVG Training Acc 55.17 % AVG Validation Acc 50.99 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.682 AVG Validation Loss:0.697 AVG Training Acc 55.22 % AVG Validation Acc 51.35 %\n",
      "Epoch:160/200 AVG Training Loss:0.682 AVG Validation Loss:0.697 AVG Training Acc 55.55 % AVG Validation Acc 51.26 %\n",
      "Epoch:170/200 AVG Training Loss:0.682 AVG Validation Loss:0.697 AVG Training Acc 55.51 % AVG Validation Acc 51.44 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:180/200 AVG Training Loss:0.682 AVG Validation Loss:0.697 AVG Training Acc 55.34 % AVG Validation Acc 51.26 %\n",
      "Epoch:190/200 AVG Training Loss:0.682 AVG Validation Loss:0.697 AVG Training Acc 55.40 % AVG Validation Acc 51.62 %\n",
      "Epoch:200/200 AVG Training Loss:0.682 AVG Validation Loss:0.697 AVG Training Acc 55.49 % AVG Validation Acc 51.44 %\n",
      "Split 67\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fac3a7acb01402cbc13a3a9bae97909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.654 AVG Validation Loss:3.139 AVG Training Acc 65.03 % AVG Validation Acc 38.00 %\n",
      "Epoch:20/200 AVG Training Loss:0.673 AVG Validation Loss:1.305 AVG Training Acc 60.94 % AVG Validation Acc 38.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.712 AVG Validation Loss:1.428 AVG Training Acc 62.07 % AVG Validation Acc 38.09 %\n",
      "Epoch:40/200 AVG Training Loss:0.673 AVG Validation Loss:1.940 AVG Training Acc 63.79 % AVG Validation Acc 38.09 %\n",
      "Epoch:50/200 AVG Training Loss:0.674 AVG Validation Loss:1.198 AVG Training Acc 59.96 % AVG Validation Acc 38.09 %\n",
      "Epoch:60/200 AVG Training Loss:0.674 AVG Validation Loss:1.525 AVG Training Acc 59.85 % AVG Validation Acc 38.09 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:70/200 AVG Training Loss:0.693 AVG Validation Loss:0.708 AVG Training Acc 50.83 % AVG Validation Acc 41.88 %\n",
      "Epoch:80/200 AVG Training Loss:0.689 AVG Validation Loss:0.709 AVG Training Acc 53.16 % AVG Validation Acc 47.74 %\n",
      "Epoch:90/200 AVG Training Loss:0.688 AVG Validation Loss:0.721 AVG Training Acc 53.78 % AVG Validation Acc 49.19 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.685 AVG Validation Loss:0.713 AVG Training Acc 55.09 % AVG Validation Acc 50.36 %\n",
      "Epoch:110/200 AVG Training Loss:0.683 AVG Validation Loss:0.707 AVG Training Acc 55.52 % AVG Validation Acc 51.81 %\n",
      "Epoch:120/200 AVG Training Loss:0.683 AVG Validation Loss:0.705 AVG Training Acc 55.34 % AVG Validation Acc 51.81 %\n",
      "Epoch:130/200 AVG Training Loss:0.683 AVG Validation Loss:0.704 AVG Training Acc 55.26 % AVG Validation Acc 51.90 %\n",
      "Epoch:140/200 AVG Training Loss:0.682 AVG Validation Loss:0.703 AVG Training Acc 55.34 % AVG Validation Acc 51.81 %\n",
      "Epoch:150/200 AVG Training Loss:0.683 AVG Validation Loss:0.704 AVG Training Acc 55.32 % AVG Validation Acc 51.71 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:160/200 AVG Training Loss:0.683 AVG Validation Loss:0.705 AVG Training Acc 55.62 % AVG Validation Acc 51.90 %\n",
      "Epoch:170/200 AVG Training Loss:0.682 AVG Validation Loss:0.704 AVG Training Acc 55.47 % AVG Validation Acc 51.81 %\n",
      "Epoch:180/200 AVG Training Loss:0.682 AVG Validation Loss:0.704 AVG Training Acc 55.60 % AVG Validation Acc 51.62 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:190/200 AVG Training Loss:0.683 AVG Validation Loss:0.704 AVG Training Acc 55.39 % AVG Validation Acc 51.53 %\n",
      "Epoch:200/200 AVG Training Loss:0.683 AVG Validation Loss:0.703 AVG Training Acc 55.76 % AVG Validation Acc 51.90 %\n",
      "Split 68\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c531879af4544689913cb4376577ad6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.652 AVG Validation Loss:3.002 AVG Training Acc 65.21 % AVG Validation Acc 38.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.647 AVG Validation Loss:6.877 AVG Training Acc 63.40 % AVG Validation Acc 38.18 %\n",
      "Epoch:30/200 AVG Training Loss:0.708 AVG Validation Loss:1.640 AVG Training Acc 63.56 % AVG Validation Acc 38.09 %\n",
      "Epoch:40/200 AVG Training Loss:0.827 AVG Validation Loss:3.701 AVG Training Acc 64.04 % AVG Validation Acc 38.09 %\n",
      "Epoch:50/200 AVG Training Loss:0.671 AVG Validation Loss:1.272 AVG Training Acc 61.32 % AVG Validation Acc 38.09 %\n",
      "Epoch:60/200 AVG Training Loss:0.674 AVG Validation Loss:1.206 AVG Training Acc 60.19 % AVG Validation Acc 38.18 %\n",
      "Epoch:70/200 AVG Training Loss:0.665 AVG Validation Loss:2.210 AVG Training Acc 60.42 % AVG Validation Acc 38.45 %\n",
      "Epoch:80/200 AVG Training Loss:0.669 AVG Validation Loss:1.223 AVG Training Acc 60.51 % AVG Validation Acc 38.27 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:90/200 AVG Training Loss:0.689 AVG Validation Loss:0.707 AVG Training Acc 53.32 % AVG Validation Acc 46.39 %\n",
      "Epoch:100/200 AVG Training Loss:0.687 AVG Validation Loss:0.709 AVG Training Acc 54.20 % AVG Validation Acc 46.84 %\n",
      "Epoch:110/200 AVG Training Loss:0.687 AVG Validation Loss:0.711 AVG Training Acc 54.06 % AVG Validation Acc 47.38 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:120/200 AVG Training Loss:0.685 AVG Validation Loss:0.704 AVG Training Acc 55.64 % AVG Validation Acc 49.46 %\n",
      "Epoch:130/200 AVG Training Loss:0.683 AVG Validation Loss:0.700 AVG Training Acc 55.64 % AVG Validation Acc 50.63 %\n",
      "Epoch:140/200 AVG Training Loss:0.682 AVG Validation Loss:0.701 AVG Training Acc 55.98 % AVG Validation Acc 50.63 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.683 AVG Validation Loss:0.701 AVG Training Acc 55.67 % AVG Validation Acc 51.08 %\n",
      "Epoch:160/200 AVG Training Loss:0.683 AVG Validation Loss:0.700 AVG Training Acc 55.93 % AVG Validation Acc 50.81 %\n",
      "Epoch:170/200 AVG Training Loss:0.683 AVG Validation Loss:0.701 AVG Training Acc 55.81 % AVG Validation Acc 51.26 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:180/200 AVG Training Loss:0.683 AVG Validation Loss:0.701 AVG Training Acc 55.88 % AVG Validation Acc 50.90 %\n",
      "Epoch:190/200 AVG Training Loss:0.683 AVG Validation Loss:0.701 AVG Training Acc 55.82 % AVG Validation Acc 50.90 %\n",
      "Epoch:200/200 AVG Training Loss:0.683 AVG Validation Loss:0.701 AVG Training Acc 55.43 % AVG Validation Acc 51.44 %\n",
      "Split 69\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb713498b25b4f96811dc03089150c15",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:2.402 AVG Training Acc 65.18 % AVG Validation Acc 38.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.656 AVG Validation Loss:3.580 AVG Training Acc 61.64 % AVG Validation Acc 38.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.678 AVG Validation Loss:1.284 AVG Training Acc 61.49 % AVG Validation Acc 38.09 %\n",
      "Epoch:40/200 AVG Training Loss:0.752 AVG Validation Loss:3.763 AVG Training Acc 62.23 % AVG Validation Acc 38.09 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.691 AVG Validation Loss:0.713 AVG Training Acc 52.91 % AVG Validation Acc 43.23 %\n",
      "Epoch:60/200 AVG Training Loss:0.689 AVG Validation Loss:0.715 AVG Training Acc 53.97 % AVG Validation Acc 44.77 %\n",
      "Epoch:70/200 AVG Training Loss:0.688 AVG Validation Loss:0.717 AVG Training Acc 54.30 % AVG Validation Acc 44.49 %\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.685 AVG Validation Loss:0.706 AVG Training Acc 54.63 % AVG Validation Acc 47.38 %\n",
      "Epoch:90/200 AVG Training Loss:0.685 AVG Validation Loss:0.700 AVG Training Acc 55.58 % AVG Validation Acc 48.38 %\n",
      "Epoch:100/200 AVG Training Loss:0.684 AVG Validation Loss:0.699 AVG Training Acc 55.03 % AVG Validation Acc 48.83 %\n",
      "Epoch:110/200 AVG Training Loss:0.685 AVG Validation Loss:0.698 AVG Training Acc 55.04 % AVG Validation Acc 48.92 %\n",
      "Epoch:120/200 AVG Training Loss:0.684 AVG Validation Loss:0.698 AVG Training Acc 55.17 % AVG Validation Acc 49.01 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.683 AVG Validation Loss:0.698 AVG Training Acc 55.47 % AVG Validation Acc 49.46 %\n",
      "Epoch:140/200 AVG Training Loss:0.684 AVG Validation Loss:0.698 AVG Training Acc 54.96 % AVG Validation Acc 49.55 %\n",
      "Epoch:150/200 AVG Training Loss:0.684 AVG Validation Loss:0.698 AVG Training Acc 55.52 % AVG Validation Acc 49.55 %\n",
      "Epoch:160/200 AVG Training Loss:0.683 AVG Validation Loss:0.697 AVG Training Acc 55.38 % AVG Validation Acc 49.82 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:170/200 AVG Training Loss:0.683 AVG Validation Loss:0.697 AVG Training Acc 55.26 % AVG Validation Acc 49.55 %\n",
      "Epoch:180/200 AVG Training Loss:0.683 AVG Validation Loss:0.698 AVG Training Acc 55.60 % AVG Validation Acc 49.37 %\n",
      "Epoch:190/200 AVG Training Loss:0.683 AVG Validation Loss:0.697 AVG Training Acc 55.48 % AVG Validation Acc 49.64 %\n",
      "Epoch   198: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:200/200 AVG Training Loss:0.684 AVG Validation Loss:0.698 AVG Training Acc 55.29 % AVG Validation Acc 49.73 %\n",
      "Split 70\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6753a0c9b76c442f90d93eef591f978f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:2.749 AVG Training Acc 64.87 % AVG Validation Acc 38.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:2.766 AVG Training Acc 63.88 % AVG Validation Acc 38.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.675 AVG Validation Loss:1.304 AVG Training Acc 61.29 % AVG Validation Acc 38.09 %\n",
      "Epoch:40/200 AVG Training Loss:0.784 AVG Validation Loss:5.435 AVG Training Acc 62.34 % AVG Validation Acc 38.09 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.732 AVG Validation Loss:0.757 AVG Training Acc 48.79 % AVG Validation Acc 38.18 %\n",
      "Epoch:60/200 AVG Training Loss:0.692 AVG Validation Loss:0.730 AVG Training Acc 52.28 % AVG Validation Acc 39.08 %\n",
      "Epoch:70/200 AVG Training Loss:0.691 AVG Validation Loss:0.728 AVG Training Acc 53.21 % AVG Validation Acc 40.70 %\n",
      "Epoch:80/200 AVG Training Loss:0.690 AVG Validation Loss:0.725 AVG Training Acc 52.41 % AVG Validation Acc 41.88 %\n",
      "Epoch:90/200 AVG Training Loss:0.687 AVG Validation Loss:0.723 AVG Training Acc 53.50 % AVG Validation Acc 42.42 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.684 AVG Validation Loss:0.711 AVG Training Acc 54.68 % AVG Validation Acc 51.08 %\n",
      "Epoch:110/200 AVG Training Loss:0.683 AVG Validation Loss:0.704 AVG Training Acc 54.86 % AVG Validation Acc 51.44 %\n",
      "Epoch:120/200 AVG Training Loss:0.683 AVG Validation Loss:0.698 AVG Training Acc 55.04 % AVG Validation Acc 51.62 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.681 AVG Validation Loss:0.698 AVG Training Acc 55.02 % AVG Validation Acc 51.53 %\n",
      "Epoch:140/200 AVG Training Loss:0.682 AVG Validation Loss:0.702 AVG Training Acc 55.09 % AVG Validation Acc 52.17 %\n",
      "Epoch:150/200 AVG Training Loss:0.681 AVG Validation Loss:0.698 AVG Training Acc 55.32 % AVG Validation Acc 52.44 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.681 AVG Validation Loss:0.697 AVG Training Acc 55.09 % AVG Validation Acc 52.62 %\n",
      "Epoch:170/200 AVG Training Loss:0.682 AVG Validation Loss:0.702 AVG Training Acc 55.35 % AVG Validation Acc 52.44 %\n",
      "Epoch:180/200 AVG Training Loss:0.681 AVG Validation Loss:0.697 AVG Training Acc 55.52 % AVG Validation Acc 52.44 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.682 AVG Validation Loss:0.697 AVG Training Acc 55.28 % AVG Validation Acc 52.44 %\n",
      "Epoch:200/200 AVG Training Loss:0.681 AVG Validation Loss:0.698 AVG Training Acc 55.33 % AVG Validation Acc 52.44 %\n",
      "Split 71\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba9909c095d44a78945460f08c31a32d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:5.555 AVG Training Acc 64.80 % AVG Validation Acc 38.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:3.257 AVG Training Acc 64.25 % AVG Validation Acc 38.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.660 AVG Validation Loss:7.097 AVG Training Acc 60.45 % AVG Validation Acc 38.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.719 AVG Validation Loss:1.312 AVG Training Acc 62.17 % AVG Validation Acc 38.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.675 AVG Validation Loss:1.241 AVG Training Acc 59.97 % AVG Validation Acc 38.05 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.710 AVG Validation Loss:0.733 AVG Training Acc 50.77 % AVG Validation Acc 38.59 %\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(list(course_programs.keys())[2:]):\n",
    "    \n",
    "    print(i)\n",
    "    threshold_dict = {} #dict to store information in for each threshold\n",
    "    data = deepcopy(course_programs[i])\n",
    "    \n",
    "    data.set_index(['course', 'userid'], drop = True, inplace = True)\n",
    "    data.fillna(0, inplace = True)\n",
    "    \n",
    "    #set X and Y columns\n",
    "    X = data[data.columns[:25]] #different timesteps\n",
    "    y = data[data.columns[-4:]] #the 4 different putative targets\n",
    "    \n",
    "    for k in tqdm(targets):\n",
    "        print(k)\n",
    "        \n",
    "        #Start with train test split\n",
    "        X_train_val, X_test, y_train_val, y_test, = train_test_split(\n",
    "                                    X,\n",
    "                                   y[k], #replace when going for multi-target \n",
    "                                   test_size = 0.20,\n",
    "                                   random_state = 15,\n",
    "                                   shuffle=True,\n",
    "                                   stratify = y[k] #replace when going for multi-target\n",
    "                                    )\n",
    "        \n",
    "        #create dict to store fold performance\n",
    "        foldperf={}\n",
    "        \n",
    "        #reset \"best accuracy for treshold i and target k\"\n",
    "        best_accuracy = 0\n",
    "\n",
    "        #make train_val split\n",
    "        for fold, (train_idx,val_idx) in tqdm(enumerate(splits.split(X_train_val, y_train_val))):\n",
    "\n",
    "            print('Split {}'.format(fold + 1))\n",
    "            \n",
    "            #make split between train and Val\n",
    "            X_train, y_train = X_train_val.iloc[train_idx], y_train_val.iloc[train_idx]\n",
    "            X_val, y_val = X_train_val.iloc[val_idx], y_train_val.iloc[val_idx]\n",
    "            \n",
    "            #apply SMOTE to training split\n",
    "            over = SMOTE()\n",
    "            X_train, y_train = over.fit_resample(X_train, y_train)\n",
    "            \n",
    "            #apply scaling after \n",
    "            X_train, X_val = normalize(X_train, X_val, 'Standard')\n",
    "            \n",
    "            #second, convert everything to pytorch tensor - we will convert to tensor dataset and \n",
    "            X_train_tensors = Variable(torch.Tensor(X_train.values))\n",
    "            X_val_tensors = Variable(torch.Tensor(X_val.values))\n",
    "\n",
    "            y_train_tensors = Variable(torch.Tensor(y_train.values))\n",
    "            y_val_tensors = Variable(torch.Tensor(y_val.values)) \n",
    "\n",
    "            #reshaping to rows, timestamps, features \n",
    "            X_train_tensors = torch.reshape(X_train_tensors,   (X_train_tensors.shape[0], X_train_tensors.shape[1], 1))\n",
    "            X_val_tensors = torch.reshape(X_val_tensors,  (X_val_tensors.shape[0], X_val_tensors.shape[1], 1))\n",
    "        \n",
    "            #convert y tensors to format longtensor\n",
    "            y_train_tensors = y_train_tensors.type(torch.cuda.LongTensor)\n",
    "            y_val_tensors = y_val_tensors.type(torch.cuda.LongTensor)\n",
    "            \n",
    "            #create Tensor Datasets and dataloaders for both Train and Val\n",
    "            train_dataset = TensorDataset(X_train_tensors, y_train_tensors)\n",
    "            val_dataset = TensorDataset(X_val_tensors, y_val_tensors)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "            #creates new model for each \n",
    "            model = LSTM_Uni(num_classes, input_size, hidden_size, num_layers, X_train_tensors.shape[1]).to('cuda') #our lstm class\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "            scheduler = ReduceLROnPlateau(optimizer, \n",
    "                                  'min', \n",
    "                                  patience = 10,\n",
    "                                  cooldown = 20,\n",
    "                                 verbose = True)\n",
    "    \n",
    "            history = {'train_loss': [], 'val_loss': [],'train_acc':[],'val_acc':[], 'precision': [],\n",
    "                      'recall' : [], 'auroc': []}\n",
    "\n",
    "            for epoch in tqdm(range(num_epochs)):\n",
    "                train_loss, train_correct=train_epoch(model,train_loader,criterion,optimizer)\n",
    "                val_loss, val_correct, precision, recall, auroc = valid_epoch(model,val_loader,criterion)\n",
    "\n",
    "                train_loss = train_loss / len(train_loader.sampler)\n",
    "                train_acc = train_correct / len(train_loader.sampler) * 100\n",
    "                val_loss = val_loss / len(val_loader.sampler)\n",
    "                val_acc = val_correct / len(val_loader.sampler) * 100\n",
    "        \n",
    "        \n",
    "                if (epoch+1) % 10 == 0: \n",
    "                    print(\"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Validation Loss:{:.3f} AVG Training Acc {:.2f} % AVG Validation Acc {:.2f} %\".format(epoch + 1,\n",
    "                                                                                                             num_epochs,\n",
    "                                                                                                             train_loss,\n",
    "                                                                                                             val_loss,\n",
    "                                                                                                             train_acc,\n",
    "                                                                                                             val_acc))\n",
    "                history['train_loss'].append(train_loss)\n",
    "                history['val_loss'].append(val_loss)\n",
    "                history['train_acc'].append(train_acc)\n",
    "                history['val_acc'].append(val_acc)\n",
    "                history['precision'].append(precision)\n",
    "                history['recall'].append(recall)\n",
    "                history['auroc'].append(auroc)\n",
    "                scheduler.step(val_loss)\n",
    "    \n",
    "                if val_acc > best_accuracy:\n",
    "            \n",
    "                #replace best accuracy and save best model\n",
    "                    print(f'New Best Accuracy found: {val_acc:.2f}%\\nEpoch: {epoch + 1}')\n",
    "                    best_accuracy = val_acc\n",
    "                    best = deepcopy(model)\n",
    "                    curr_epoch = epoch + 1\n",
    "                    \n",
    "            #store fold performance\n",
    "            foldperf['fold{}'.format(fold+1)] = history\n",
    "        \n",
    "        #saves fold performance for target \n",
    "        threshold_dict[k] = pd.DataFrame.from_dict(foldperf, orient='index') # convert dict to dataframe\n",
    "        \n",
    "        #explode to get eacxh epoch as a row\n",
    "        threshold_dict[k] = threshold_dict[k].explode(list(threshold_dict[k].columns))\n",
    "        torch.save(best,f\"../Models/{i}/R_Gonz_best_{k}_{curr_epoch}_epochs_SMOTE_relative_clicks.h\")\n",
    "        \n",
    "    # from pandas.io.parsers import ExcelWriter\n",
    "    with pd.ExcelWriter(f\"../Data/Modeling Stage/Results/R_Gonz/Clicks per % duration/25_splits_{i}_{replicas}_replicas_SMOTE_relative_clicks.xlsx\") as writer:  \n",
    "        for sheet in targets:\n",
    "                threshold_dict[sheet].to_excel(writer, sheet_name=str(sheet))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
