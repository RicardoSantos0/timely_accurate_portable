{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84eda90e",
   "metadata": {},
   "source": [
    "### Thesis notebook 4.3. - R_Gonz\n",
    "\n",
    "#### LSTM - Temporal data representation\n",
    "\n",
    "In this notebook, we will finally start our application of temporal representation using LSTMs and bi-directional LSTMs.\n",
    "The argument for the usage of Deep Learning stems from the fact that sequences themselves encode information that can be extracted using Recurrent Neural Networks and, more specifically, Long Short Term Memory Units.\n",
    "\n",
    "#### First Step: Setup a PyTorch environment that enables the use of GPU for training. \n",
    "\n",
    "The following cell wll confirm that the GPU will be the default device to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f27844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pycuda.driver as cuda\n",
    "\n",
    "cuda.init()\n",
    "## Get Id of default device\n",
    "torch.cuda.current_device()\n",
    "# 0\n",
    "cuda.Device(0).name() # '0' is the id of your GPU\n",
    "\n",
    "#set all tensors to gpu\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d95429e",
   "metadata": {},
   "source": [
    "#### Second Step: Import the relevant packages and declare global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6c2d97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary modules/libraries\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "#tqdm to monitor progress\n",
    "from tqdm.notebook import tqdm, trange\n",
    "tqdm.pandas(desc=\"Progress\")\n",
    "\n",
    "#time related features\n",
    "from datetime import timedelta\n",
    "from copy import copy, deepcopy\n",
    "\n",
    "#vizualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#imblearn, scalers, kfold and metrics\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, QuantileTransformer,PowerTransformer\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold, RepeatedStratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, recall_score, classification_report, average_precision_score, precision_recall_curve\n",
    "\n",
    "#import torch related\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable \n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "\n",
    "#and optimizer of learning rate\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "#import pytorch modules\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6c3f1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variables that may come in handy\n",
    "#course threshold sets the % duration that will be considered (1 = 100%)\n",
    "duration_threshold = [0.1, 0.25, 0.33, 0.5, 1]\n",
    "\n",
    "#colors for vizualizations\n",
    "nova_ims_colors = ['#BFD72F', '#5C666C']\n",
    "\n",
    "#standard color for student aggregates\n",
    "student_color = '#474838'\n",
    "\n",
    "#standard color for course aggragates\n",
    "course_color = '#1B3D2F'\n",
    "\n",
    "#standard continuous colormap\n",
    "standard_cmap = 'viridis_r'\n",
    "\n",
    "#Function designed to deal with multiindex and flatten it\n",
    "def flattenHierarchicalCol(col,sep = '_'):\n",
    "    '''converts multiindex columns into single index columns while retaining the hierarchical components'''\n",
    "    if not type(col) is tuple:\n",
    "        return col\n",
    "    else:\n",
    "        new_col = ''\n",
    "        for leveli,level in enumerate(col):\n",
    "            if not level == '':\n",
    "                if not leveli == 0:\n",
    "                    new_col += sep\n",
    "                new_col += level\n",
    "        return new_col\n",
    "    \n",
    "#number of replicas - number of repeats of stratified k fold - in this case 10\n",
    "replicas = 30\n",
    "\n",
    "#names to display on result figures\n",
    "date_names = {\n",
    "             'Date_threshold_10': '10% of Course Duration',   \n",
    "             'Date_threshold_25': '25% of Course Duration', \n",
    "             'Date_threshold_33': '33% of Course Duration', \n",
    "             'Date_threshold_50': '50% of Course Duration', \n",
    "             'Date_threshold_100':'100% of Course Duration', \n",
    "            }\n",
    "\n",
    "target_names = {\n",
    "                'exam_fail' : 'At risk - Exam Grade',\n",
    "                'final_fail' : 'At risk - Final Grade', \n",
    "                'exam_gifted' : 'High performer - Exam Grade', \n",
    "                'final_gifted': 'High performer - Final Grade'\n",
    "                }\n",
    "\n",
    "#targets\n",
    "targets = ['final_fail' ,'final_gifted']\n",
    "temporal_columns = ['0 to 4%', '4 to 8%', '8 to 12%', '12 to 16%', '16 to 20%', '20 to 24%',\n",
    "       '24 to 28%', '28 to 32%', '32 to 36%', '36 to 40%', '40 to 44%',\n",
    "       '44 to 48%', '48 to 52%', '52 to 56%', '56 to 60%', '60 to 64%',\n",
    "       '64 to 68%', '68 to 72%', '72 to 76%', '76 to 80%', '80 to 84%',\n",
    "       '84 to 88%', '88 to 92%', '92 to 96%', '96 to 100%']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c5ddb6",
   "metadata": {},
   "source": [
    "#### Step 3: Import data and take a preliminary look at it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8a23ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports dataframes\n",
    "course_programs = pd.read_excel(\"../Data/Modeling Stage/R_Gonz_Temporal_Datasets_25_splits.xlsx\", \n",
    "                                dtype = {\n",
    "                                    'course_encoding' : int,\n",
    "                                    'userid' : int},\n",
    "                               sheet_name = None)\n",
    "\n",
    "#save tables \n",
    "student_list = pd.read_csv('../Data/Modeling Stage/R_Gonz_Filtered_targets.csv', \n",
    "                         dtype = {\n",
    "                                   'course_encoding': int,\n",
    "                                   'userid' : int,\n",
    "                                   })\n",
    "\n",
    "#drop unnamed 0 column\n",
    "for i in course_programs:\n",
    "        \n",
    "    #merge with the targets we calculated on the other \n",
    "    course_programs[i] = course_programs[i].merge(student_list, on = ['course', 'userid'], how = 'inner')\n",
    "    course_programs[i].drop(['Unnamed: 0', 'final_mark'], axis = 1, inplace = True)\n",
    "    \n",
    "    #convert results to object\n",
    "    course_programs[i]['course'], course_programs[i]['userid'] = course_programs[i]['course'].astype(object), course_programs[i]['userid'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bc3c84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 13857 entries, 0 to 13856\n",
      "Data columns (total 29 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   course        13857 non-null  object\n",
      " 1   userid        13857 non-null  object\n",
      " 2   1             13857 non-null  int64 \n",
      " 3   2             13857 non-null  int64 \n",
      " 4   3             13857 non-null  int64 \n",
      " 5   4             13857 non-null  int64 \n",
      " 6   5             13857 non-null  int64 \n",
      " 7   6             13857 non-null  int64 \n",
      " 8   7             13857 non-null  int64 \n",
      " 9   8             13857 non-null  int64 \n",
      " 10  9             13857 non-null  int64 \n",
      " 11  10            13857 non-null  int64 \n",
      " 12  11            13857 non-null  int64 \n",
      " 13  12            13857 non-null  int64 \n",
      " 14  13            13857 non-null  int64 \n",
      " 15  14            13857 non-null  int64 \n",
      " 16  15            13857 non-null  int64 \n",
      " 17  16            13857 non-null  int64 \n",
      " 18  17            13857 non-null  int64 \n",
      " 19  18            13857 non-null  int64 \n",
      " 20  19            13857 non-null  int64 \n",
      " 21  20            13857 non-null  int64 \n",
      " 22  21            13857 non-null  int64 \n",
      " 23  22            13857 non-null  int64 \n",
      " 24  23            13857 non-null  int64 \n",
      " 25  24            13857 non-null  int64 \n",
      " 26  25            13857 non-null  int64 \n",
      " 27  final_fail    13857 non-null  int64 \n",
      " 28  final_gifted  13857 non-null  int64 \n",
      "dtypes: int64(27), object(2)\n",
      "memory usage: 3.2+ MB\n"
     ]
    }
   ],
   "source": [
    "course_programs['Date_threshold_100'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4a751ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course</th>\n",
       "      <th>userid</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>final_fail</th>\n",
       "      <th>final_gifted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13857.0</td>\n",
       "      <td>13857.0</td>\n",
       "      <td>13857.000000</td>\n",
       "      <td>13857.000000</td>\n",
       "      <td>13857.000000</td>\n",
       "      <td>13857.000000</td>\n",
       "      <td>13857.000000</td>\n",
       "      <td>13857.000000</td>\n",
       "      <td>13857.000000</td>\n",
       "      <td>13857.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>13857.000000</td>\n",
       "      <td>13857.000000</td>\n",
       "      <td>13857.000000</td>\n",
       "      <td>13857.000000</td>\n",
       "      <td>13857.000000</td>\n",
       "      <td>13857.000000</td>\n",
       "      <td>13857.000000</td>\n",
       "      <td>13857.000000</td>\n",
       "      <td>13857.000000</td>\n",
       "      <td>13857.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>174.0</td>\n",
       "      <td>8544.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>2059.0</td>\n",
       "      <td>68888.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>507.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.601140</td>\n",
       "      <td>4.616584</td>\n",
       "      <td>7.876092</td>\n",
       "      <td>8.510067</td>\n",
       "      <td>9.804792</td>\n",
       "      <td>10.839431</td>\n",
       "      <td>11.184167</td>\n",
       "      <td>12.273147</td>\n",
       "      <td>...</td>\n",
       "      <td>11.521036</td>\n",
       "      <td>11.677997</td>\n",
       "      <td>8.524067</td>\n",
       "      <td>10.015155</td>\n",
       "      <td>8.560583</td>\n",
       "      <td>7.720935</td>\n",
       "      <td>3.454355</td>\n",
       "      <td>0.082413</td>\n",
       "      <td>0.381035</td>\n",
       "      <td>0.198528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.581259</td>\n",
       "      <td>12.238187</td>\n",
       "      <td>15.785656</td>\n",
       "      <td>14.600375</td>\n",
       "      <td>16.021089</td>\n",
       "      <td>16.473371</td>\n",
       "      <td>20.043011</td>\n",
       "      <td>20.126765</td>\n",
       "      <td>...</td>\n",
       "      <td>22.043869</td>\n",
       "      <td>27.925613</td>\n",
       "      <td>18.816024</td>\n",
       "      <td>29.534244</td>\n",
       "      <td>20.248598</td>\n",
       "      <td>20.105366</td>\n",
       "      <td>14.589819</td>\n",
       "      <td>1.264520</td>\n",
       "      <td>0.485659</td>\n",
       "      <td>0.398906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>178.000000</td>\n",
       "      <td>236.000000</td>\n",
       "      <td>292.000000</td>\n",
       "      <td>239.000000</td>\n",
       "      <td>255.000000</td>\n",
       "      <td>219.000000</td>\n",
       "      <td>880.000000</td>\n",
       "      <td>602.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>557.000000</td>\n",
       "      <td>729.000000</td>\n",
       "      <td>678.000000</td>\n",
       "      <td>1316.000000</td>\n",
       "      <td>407.000000</td>\n",
       "      <td>422.000000</td>\n",
       "      <td>523.000000</td>\n",
       "      <td>74.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         course   userid             1             2             3  \\\n",
       "count   13857.0  13857.0  13857.000000  13857.000000  13857.000000   \n",
       "unique    174.0   8544.0           NaN           NaN           NaN   \n",
       "top      2059.0  68888.0           NaN           NaN           NaN   \n",
       "freq      507.0      7.0           NaN           NaN           NaN   \n",
       "mean        NaN      NaN      1.601140      4.616584      7.876092   \n",
       "std         NaN      NaN      6.581259     12.238187     15.785656   \n",
       "min         NaN      NaN      0.000000      0.000000      0.000000   \n",
       "25%         NaN      NaN      0.000000      0.000000      0.000000   \n",
       "50%         NaN      NaN      0.000000      0.000000      1.000000   \n",
       "75%         NaN      NaN      0.000000      4.000000     10.000000   \n",
       "max         NaN      NaN    178.000000    236.000000    292.000000   \n",
       "\n",
       "                   4             5             6             7             8  \\\n",
       "count   13857.000000  13857.000000  13857.000000  13857.000000  13857.000000   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean        8.510067      9.804792     10.839431     11.184167     12.273147   \n",
       "std        14.600375     16.021089     16.473371     20.043011     20.126765   \n",
       "min         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%         3.000000      4.000000      4.000000      5.000000      5.000000   \n",
       "75%        11.000000     13.000000     15.000000     15.000000     17.000000   \n",
       "max       239.000000    255.000000    219.000000    880.000000    602.000000   \n",
       "\n",
       "        ...            18            19            20            21  \\\n",
       "count   ...  13857.000000  13857.000000  13857.000000  13857.000000   \n",
       "unique  ...           NaN           NaN           NaN           NaN   \n",
       "top     ...           NaN           NaN           NaN           NaN   \n",
       "freq    ...           NaN           NaN           NaN           NaN   \n",
       "mean    ...     11.521036     11.677997      8.524067     10.015155   \n",
       "std     ...     22.043869     27.925613     18.816024     29.534244   \n",
       "min     ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%     ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%     ...      4.000000      3.000000      1.000000      1.000000   \n",
       "75%     ...     15.000000     13.000000     10.000000     11.000000   \n",
       "max     ...    557.000000    729.000000    678.000000   1316.000000   \n",
       "\n",
       "                  22            23            24            25    final_fail  \\\n",
       "count   13857.000000  13857.000000  13857.000000  13857.000000  13857.000000   \n",
       "unique           NaN           NaN           NaN           NaN           NaN   \n",
       "top              NaN           NaN           NaN           NaN           NaN   \n",
       "freq             NaN           NaN           NaN           NaN           NaN   \n",
       "mean        8.560583      7.720935      3.454355      0.082413      0.381035   \n",
       "std        20.248598     20.105366     14.589819      1.264520      0.485659   \n",
       "min         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%         0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%         1.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%         9.000000      7.000000      1.000000      0.000000      1.000000   \n",
       "max       407.000000    422.000000    523.000000     74.000000      1.000000   \n",
       "\n",
       "        final_gifted  \n",
       "count   13857.000000  \n",
       "unique           NaN  \n",
       "top              NaN  \n",
       "freq             NaN  \n",
       "mean        0.198528  \n",
       "std         0.398906  \n",
       "min         0.000000  \n",
       "25%         0.000000  \n",
       "50%         0.000000  \n",
       "75%         0.000000  \n",
       "max         1.000000  \n",
       "\n",
       "[11 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "course_programs['Date_threshold_100'].describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a150610b",
   "metadata": {},
   "source": [
    "In our second attempt, we are looking to obtain a different result. Instead of using the absolute number of clicks used in each instance, we are instead looking to use the percent number of clicks made by each student relative to the the total number of clicks performed in the curricular unit.\n",
    "\n",
    "For that we will use transform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa5e45f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5675db120c734d1dbb3975c5033fffac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c2dff4d247a4e829d360a81450c832c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52a810bf5f8d43d0ac76d8ce9ffca763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6f443eda9d944ec83cc59da5e25fcb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b54fab63d31e4f70b5c8ad899bd30cd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d448ea61c9634f32bd656896bcc85ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm(course_programs.keys()):\n",
    "    \n",
    "    for j in tqdm(range(1,25)):\n",
    "            course_programs[i][j] = np.where(course_programs[i].fillna(0).groupby('course')[j].transform('sum') != 0, #where valid operations occur\n",
    "                                             course_programs[i][j].fillna(0) / course_programs[i].fillna(0).groupby('course')[j].transform('sum') * 100, #calculate percentage\n",
    "                                             0) #otherwise, its 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3291817",
   "metadata": {},
   "source": [
    "In our first attempt, we will use the absolute number of clicks made by each student - scaled using standard scaler. \n",
    "Therefore, we can start by immediately placing our course encoding/userid pairings into the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be722ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(train, test, scaler):\n",
    "    \n",
    "    if scaler == 'MinMax':\n",
    "        pt = MinMaxScaler()\n",
    "    elif scaler == 'Standard':\n",
    "        pt = StandardScaler()\n",
    "    elif scaler == 'Robust':\n",
    "        pt = RobustScaler()\n",
    "    elif scaler == 'Quantile':\n",
    "        pt = QuantileTransformer()\n",
    "    else:\n",
    "        pt = PowerTransformer(method='yeo-johnson')\n",
    "    \n",
    "    data_train = pt.fit_transform(train)\n",
    "    data_test = pt.transform(test)\n",
    "    # convert the array back to a dataframe\n",
    "    normalized_train = pd.DataFrame(data_train,columns=train.columns)\n",
    "    normalized_test = pd.DataFrame(data_test,columns=test.columns)\n",
    "        \n",
    "    return normalized_train, normalized_test "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4d5475",
   "metadata": {},
   "source": [
    "#### Implementing Cross-Validation with Deep Learning Model\n",
    "\n",
    "**1. Create the Deep Learning Model**\n",
    "\n",
    "In this instance, we will follow-up with on the approach used in Chen & Cui - CrossEntropyLoss with applied over a softmax layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a16bd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Uni(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(LSTM_Uni, self).__init__()\n",
    "        self.num_classes = num_classes #number of classes\n",
    "        self.num_layers = num_layers #number of layers\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size = hidden_size #hidden state\n",
    "        self.seq_length = seq_length #sequence length\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first = True) #lstm\n",
    "        \n",
    "        self.dropout = nn.Dropout(p = 0.5)\n",
    "    \n",
    "        self.fc = nn.Linear(self.hidden_size, num_classes) #fully connected last layer\n",
    "\n",
    "    def forward(self,x):\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) #hidden state\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) #internal state\n",
    "        \n",
    "        #Xavier_init for both H_0 and C_0\n",
    "        torch.nn.init.xavier_normal_(h_0)\n",
    "        torch.nn.init.xavier_normal_(c_0)\n",
    "        \n",
    "        # Propagate input through LSTM\n",
    "        lstm_out, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
    "        last_output = hn.view(-1, self.hidden_size) #reshaping the data for Dense layer next\n",
    "        \n",
    "        #we are interested in only keeping the last output\n",
    "        drop_out = self.dropout(last_output)\n",
    "        pre_softmax = self.fc(drop_out) #Final Output - dense\n",
    "        return pre_softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c356bd",
   "metadata": {},
   "source": [
    "**2. Define the train and validation Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "25b29a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model,dataloader,loss_fn,optimizer):\n",
    "    \n",
    "    train_loss,train_correct=0.0,0 \n",
    "    model.train()\n",
    "    for X, labels in dataloader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)\n",
    "        loss = loss_fn(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * X.size(0)\n",
    "        scores, predictions = torch.max(F.log_softmax(output.data), 1)\n",
    "        train_correct += (predictions == labels).sum().item()\n",
    "        \n",
    "    return train_loss,train_correct\n",
    "  \n",
    "def valid_epoch(model,dataloader,loss_fn):\n",
    "    valid_loss, val_correct = 0.0, 0\n",
    "    targets = []\n",
    "    y_pred = []\n",
    "    probability_1 = []\n",
    "    \n",
    "    model.eval()\n",
    "    for X, labels in dataloader:\n",
    "\n",
    "        output = model(X)\n",
    "        loss=loss_fn(output,labels)\n",
    "        valid_loss+=loss.item()*X.size(0)\n",
    "        probability_1.append(F.softmax(output.data)[:,1])\n",
    "        predictions = torch.argmax(output, dim=1)\n",
    "        val_correct+=(predictions == labels).sum().item()\n",
    "        targets.append(labels)\n",
    "        y_pred.append(predictions)\n",
    "    \n",
    "    #concat all results\n",
    "    targets = torch.cat(targets).data.cpu().numpy()\n",
    "    y_pred = torch.cat(y_pred).data.cpu().numpy()\n",
    "    probability_1 = torch.cat(probability_1).data.cpu().numpy()\n",
    "    \n",
    "    #calculate precision, recall and AUC score\n",
    "    \n",
    "    precision = precision_score(targets, y_pred)\n",
    "    recall = recall_score(targets, y_pred)\n",
    "    auroc = roc_auc_score(targets, probability_1)\n",
    "    \n",
    "    #return all\n",
    "    return valid_loss,val_correct, precision, recall, auroc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4543fb3",
   "metadata": {},
   "source": [
    "**3. Define main hyperparameters of the model, including splits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcbbef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "num_epochs = 200 #50 epochs\n",
    "learning_rate = 0.01 #0.001 lr\n",
    "input_size = 1 #number of features\n",
    "hidden_size = 40 #number of features in hidden state\n",
    "num_layers = 1 #number of stacked lstm layers\n",
    "\n",
    "#Shape of Output as required for SoftMax Classifier\n",
    "num_classes = 2 #output shape\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "k=10\n",
    "splits= RepeatedStratifiedKFold(n_splits=k, n_repeats=replicas, random_state=15) #kfold of 10 with 30 replicas\n",
    "criterion = nn.CrossEntropyLoss()    # cross-entropy for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20713d9",
   "metadata": {},
   "source": [
    "**4. Make the splits and Start Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1d9af744",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5705d01119b4424a8d0615b2984a28b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date_threshold_50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8d4ffeb919b4df6b895506d2632cc31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_fail\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "593b3f91b3744f65a7cae2b659d71c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc438f1b1c50482c917d30b1569b88a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best Accuracy found: 61.95%\n",
      "Epoch: 1\n",
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.661 AVG Training Acc 61.81 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.659 AVG Training Acc 61.93 % AVG Validation Acc 61.95 %\n",
      "New Best Accuracy found: 62.04%\n",
      "Epoch: 21\n",
      "Epoch:30/200 AVG Training Loss:0.658 AVG Validation Loss:0.660 AVG Training Acc 61.93 % AVG Validation Acc 61.95 %\n",
      "New Best Accuracy found: 62.13%\n",
      "Epoch: 35\n",
      "Epoch:40/200 AVG Training Loss:0.656 AVG Validation Loss:0.661 AVG Training Acc 61.93 % AVG Validation Acc 62.13 %\n",
      "Epoch:50/200 AVG Training Loss:0.654 AVG Validation Loss:0.660 AVG Training Acc 61.79 % AVG Validation Acc 61.95 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.642 AVG Validation Loss:0.662 AVG Training Acc 62.52 % AVG Validation Acc 62.49 %\n",
      "New Best Accuracy found: 62.49%\n",
      "Epoch: 60\n",
      "New Best Accuracy found: 62.58%\n",
      "Epoch: 62\n",
      "New Best Accuracy found: 62.85%\n",
      "Epoch: 67\n",
      "Epoch:70/200 AVG Training Loss:0.638 AVG Validation Loss:0.669 AVG Training Acc 62.30 % AVG Validation Acc 62.04 %\n",
      "Epoch:80/200 AVG Training Loss:0.635 AVG Validation Loss:0.677 AVG Training Acc 62.61 % AVG Validation Acc 61.14 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.633 AVG Validation Loss:0.678 AVG Training Acc 62.92 % AVG Validation Acc 61.50 %\n",
      "Epoch:100/200 AVG Training Loss:0.631 AVG Validation Loss:0.677 AVG Training Acc 63.18 % AVG Validation Acc 61.50 %\n",
      "Epoch:110/200 AVG Training Loss:0.630 AVG Validation Loss:0.680 AVG Training Acc 63.32 % AVG Validation Acc 60.87 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.630 AVG Validation Loss:0.679 AVG Training Acc 62.78 % AVG Validation Acc 61.41 %\n",
      "Epoch:130/200 AVG Training Loss:0.629 AVG Validation Loss:0.680 AVG Training Acc 62.82 % AVG Validation Acc 61.41 %\n",
      "Epoch:140/200 AVG Training Loss:0.630 AVG Validation Loss:0.678 AVG Training Acc 63.44 % AVG Validation Acc 61.50 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.629 AVG Validation Loss:0.678 AVG Training Acc 63.04 % AVG Validation Acc 61.23 %\n",
      "Epoch:160/200 AVG Training Loss:0.631 AVG Validation Loss:0.680 AVG Training Acc 62.94 % AVG Validation Acc 61.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.631 AVG Validation Loss:0.681 AVG Training Acc 63.01 % AVG Validation Acc 60.69 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.630 AVG Validation Loss:0.679 AVG Training Acc 62.79 % AVG Validation Acc 61.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.630 AVG Validation Loss:0.680 AVG Training Acc 62.81 % AVG Validation Acc 61.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.630 AVG Validation Loss:0.679 AVG Training Acc 62.89 % AVG Validation Acc 61.05 %\n",
      "Split 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9028be4b358241a09088b4a218ce31b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.664 AVG Training Acc 61.77 % AVG Validation Acc 61.86 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.656 AVG Validation Loss:0.663 AVG Training Acc 61.83 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.662 AVG Training Acc 61.93 % AVG Validation Acc 62.22 %\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.664 AVG Training Acc 61.97 % AVG Validation Acc 62.40 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.649 AVG Validation Loss:0.665 AVG Training Acc 62.06 % AVG Validation Acc 62.40 %\n",
      "Epoch:60/200 AVG Training Loss:0.647 AVG Validation Loss:0.666 AVG Training Acc 62.01 % AVG Validation Acc 62.40 %\n",
      "Epoch:70/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 62.41 % AVG Validation Acc 62.22 %\n",
      "Epoch:80/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 62.03 % AVG Validation Acc 62.22 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 61.84 % AVG Validation Acc 62.22 %\n",
      "Epoch:100/200 AVG Training Loss:0.648 AVG Validation Loss:0.667 AVG Training Acc 62.11 % AVG Validation Acc 62.31 %\n",
      "Epoch:110/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 62.13 % AVG Validation Acc 62.13 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.645 AVG Validation Loss:0.667 AVG Training Acc 62.41 % AVG Validation Acc 62.22 %\n",
      "Epoch:130/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 61.83 % AVG Validation Acc 62.22 %\n",
      "Epoch:140/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 62.07 % AVG Validation Acc 62.13 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.646 AVG Validation Loss:0.668 AVG Training Acc 62.26 % AVG Validation Acc 62.22 %\n",
      "Epoch:160/200 AVG Training Loss:0.647 AVG Validation Loss:0.668 AVG Training Acc 61.95 % AVG Validation Acc 62.22 %\n",
      "Epoch:170/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 62.25 % AVG Validation Acc 62.22 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.646 AVG Validation Loss:0.667 AVG Training Acc 62.32 % AVG Validation Acc 62.31 %\n",
      "Epoch:190/200 AVG Training Loss:0.645 AVG Validation Loss:0.667 AVG Training Acc 62.34 % AVG Validation Acc 62.22 %\n",
      "Epoch:200/200 AVG Training Loss:0.648 AVG Validation Loss:0.667 AVG Training Acc 62.23 % AVG Validation Acc 62.13 %\n",
      "Split 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d657745401b40859aa8e8d19f7551b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.658 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.657 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 61.98 % AVG Validation Acc 61.59 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.655 AVG Validation Loss:0.657 AVG Training Acc 61.99 % AVG Validation Acc 61.77 %\n",
      "Epoch:50/200 AVG Training Loss:0.651 AVG Validation Loss:0.655 AVG Training Acc 62.08 % AVG Validation Acc 61.77 %\n",
      "Epoch:60/200 AVG Training Loss:0.648 AVG Validation Loss:0.658 AVG Training Acc 62.07 % AVG Validation Acc 61.68 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.644 AVG Validation Loss:0.660 AVG Training Acc 62.25 % AVG Validation Acc 61.50 %\n",
      "Epoch:80/200 AVG Training Loss:0.642 AVG Validation Loss:0.662 AVG Training Acc 62.34 % AVG Validation Acc 61.32 %\n",
      "Epoch:90/200 AVG Training Loss:0.642 AVG Validation Loss:0.662 AVG Training Acc 62.24 % AVG Validation Acc 61.32 %\n",
      "Epoch:100/200 AVG Training Loss:0.642 AVG Validation Loss:0.664 AVG Training Acc 62.27 % AVG Validation Acc 61.32 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.641 AVG Validation Loss:0.664 AVG Training Acc 62.34 % AVG Validation Acc 61.23 %\n",
      "Epoch:120/200 AVG Training Loss:0.642 AVG Validation Loss:0.664 AVG Training Acc 62.19 % AVG Validation Acc 61.23 %\n",
      "Epoch:130/200 AVG Training Loss:0.641 AVG Validation Loss:0.664 AVG Training Acc 62.43 % AVG Validation Acc 61.23 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.641 AVG Validation Loss:0.664 AVG Training Acc 62.36 % AVG Validation Acc 61.23 %\n",
      "Epoch:150/200 AVG Training Loss:0.642 AVG Validation Loss:0.664 AVG Training Acc 62.23 % AVG Validation Acc 61.23 %\n",
      "Epoch:160/200 AVG Training Loss:0.642 AVG Validation Loss:0.665 AVG Training Acc 62.22 % AVG Validation Acc 61.14 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.641 AVG Validation Loss:0.663 AVG Training Acc 62.36 % AVG Validation Acc 61.23 %\n",
      "Epoch:180/200 AVG Training Loss:0.640 AVG Validation Loss:0.663 AVG Training Acc 62.30 % AVG Validation Acc 61.23 %\n",
      "Epoch:190/200 AVG Training Loss:0.641 AVG Validation Loss:0.663 AVG Training Acc 62.27 % AVG Validation Acc 61.23 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.642 AVG Validation Loss:0.664 AVG Training Acc 62.28 % AVG Validation Acc 61.23 %\n",
      "Split 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f1cfe243f4485bb73057052ccfac8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.661 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.661 AVG Training Acc 61.79 % AVG Validation Acc 61.86 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.664 AVG Training Acc 62.04 % AVG Validation Acc 61.59 %\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.666 AVG Training Acc 62.14 % AVG Validation Acc 61.32 %\n",
      "Epoch:50/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 62.05 % AVG Validation Acc 61.32 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.648 AVG Validation Loss:0.671 AVG Training Acc 62.25 % AVG Validation Acc 61.41 %\n",
      "Epoch:70/200 AVG Training Loss:0.649 AVG Validation Loss:0.672 AVG Training Acc 62.34 % AVG Validation Acc 61.59 %\n",
      "Epoch:80/200 AVG Training Loss:0.648 AVG Validation Loss:0.672 AVG Training Acc 62.43 % AVG Validation Acc 61.32 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.649 AVG Validation Loss:0.672 AVG Training Acc 61.88 % AVG Validation Acc 61.32 %\n",
      "Epoch:100/200 AVG Training Loss:0.649 AVG Validation Loss:0.672 AVG Training Acc 62.20 % AVG Validation Acc 61.32 %\n",
      "Epoch:110/200 AVG Training Loss:0.647 AVG Validation Loss:0.672 AVG Training Acc 62.22 % AVG Validation Acc 61.41 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.647 AVG Validation Loss:0.672 AVG Training Acc 62.38 % AVG Validation Acc 61.59 %\n",
      "Epoch:130/200 AVG Training Loss:0.647 AVG Validation Loss:0.672 AVG Training Acc 62.24 % AVG Validation Acc 61.68 %\n",
      "Epoch:140/200 AVG Training Loss:0.648 AVG Validation Loss:0.672 AVG Training Acc 62.17 % AVG Validation Acc 61.59 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.647 AVG Validation Loss:0.672 AVG Training Acc 62.43 % AVG Validation Acc 61.50 %\n",
      "Epoch:160/200 AVG Training Loss:0.647 AVG Validation Loss:0.672 AVG Training Acc 62.50 % AVG Validation Acc 61.50 %\n",
      "Epoch:170/200 AVG Training Loss:0.649 AVG Validation Loss:0.672 AVG Training Acc 62.13 % AVG Validation Acc 61.59 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.647 AVG Validation Loss:0.672 AVG Training Acc 62.45 % AVG Validation Acc 61.50 %\n",
      "Epoch:190/200 AVG Training Loss:0.648 AVG Validation Loss:0.672 AVG Training Acc 62.43 % AVG Validation Acc 61.68 %\n",
      "Epoch:200/200 AVG Training Loss:0.648 AVG Validation Loss:0.672 AVG Training Acc 62.20 % AVG Validation Acc 61.59 %\n",
      "Split 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1343d684b76a467f811cc3ec623bb53b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.661 AVG Training Acc 61.81 % AVG Validation Acc 61.86 %\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.660 AVG Training Acc 61.95 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.659 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.660 AVG Training Acc 61.94 % AVG Validation Acc 61.95 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.648 AVG Validation Loss:0.663 AVG Training Acc 62.12 % AVG Validation Acc 62.13 %\n",
      "Epoch:60/200 AVG Training Loss:0.647 AVG Validation Loss:0.664 AVG Training Acc 62.06 % AVG Validation Acc 62.13 %\n",
      "Epoch:70/200 AVG Training Loss:0.646 AVG Validation Loss:0.665 AVG Training Acc 61.96 % AVG Validation Acc 62.13 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.645 AVG Validation Loss:0.665 AVG Training Acc 61.98 % AVG Validation Acc 62.13 %\n",
      "Epoch:90/200 AVG Training Loss:0.646 AVG Validation Loss:0.665 AVG Training Acc 62.04 % AVG Validation Acc 62.13 %\n",
      "Epoch:100/200 AVG Training Loss:0.646 AVG Validation Loss:0.664 AVG Training Acc 61.70 % AVG Validation Acc 62.13 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.646 AVG Validation Loss:0.665 AVG Training Acc 62.17 % AVG Validation Acc 62.13 %\n",
      "Epoch:120/200 AVG Training Loss:0.645 AVG Validation Loss:0.664 AVG Training Acc 62.25 % AVG Validation Acc 62.13 %\n",
      "Epoch:130/200 AVG Training Loss:0.645 AVG Validation Loss:0.665 AVG Training Acc 62.16 % AVG Validation Acc 62.13 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.646 AVG Validation Loss:0.665 AVG Training Acc 62.04 % AVG Validation Acc 62.13 %\n",
      "Epoch:150/200 AVG Training Loss:0.645 AVG Validation Loss:0.664 AVG Training Acc 61.99 % AVG Validation Acc 62.13 %\n",
      "Epoch:160/200 AVG Training Loss:0.645 AVG Validation Loss:0.665 AVG Training Acc 62.08 % AVG Validation Acc 62.13 %\n",
      "Epoch:170/200 AVG Training Loss:0.646 AVG Validation Loss:0.665 AVG Training Acc 61.98 % AVG Validation Acc 62.13 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.646 AVG Validation Loss:0.666 AVG Training Acc 61.90 % AVG Validation Acc 62.13 %\n",
      "Epoch:190/200 AVG Training Loss:0.646 AVG Validation Loss:0.665 AVG Training Acc 61.99 % AVG Validation Acc 62.13 %\n",
      "Epoch:200/200 AVG Training Loss:0.646 AVG Validation Loss:0.666 AVG Training Acc 62.05 % AVG Validation Acc 62.13 %\n",
      "Split 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "157860cb882545a797de5ab8abddac7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.660 AVG Training Acc 61.89 % AVG Validation Acc 62.00 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.656 AVG Validation Loss:0.659 AVG Training Acc 61.99 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.659 AVG Training Acc 62.00 % AVG Validation Acc 61.82 %\n",
      "Epoch:40/200 AVG Training Loss:0.654 AVG Validation Loss:0.658 AVG Training Acc 62.00 % AVG Validation Acc 61.64 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.651 AVG Validation Loss:0.660 AVG Training Acc 62.15 % AVG Validation Acc 61.73 %\n",
      "Epoch:60/200 AVG Training Loss:0.650 AVG Validation Loss:0.662 AVG Training Acc 62.16 % AVG Validation Acc 61.73 %\n",
      "Epoch:70/200 AVG Training Loss:0.649 AVG Validation Loss:0.663 AVG Training Acc 62.31 % AVG Validation Acc 61.73 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.650 AVG Validation Loss:0.663 AVG Training Acc 62.17 % AVG Validation Acc 61.46 %\n",
      "Epoch:90/200 AVG Training Loss:0.650 AVG Validation Loss:0.663 AVG Training Acc 62.10 % AVG Validation Acc 61.37 %\n",
      "Epoch:100/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.21 % AVG Validation Acc 61.46 %\n",
      "Epoch:110/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.15 % AVG Validation Acc 61.55 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.647 AVG Validation Loss:0.664 AVG Training Acc 62.19 % AVG Validation Acc 61.37 %\n",
      "Epoch:130/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.25 % AVG Validation Acc 61.64 %\n",
      "Epoch:140/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.23 % AVG Validation Acc 61.46 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.21 % AVG Validation Acc 61.46 %\n",
      "Epoch:160/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.15 % AVG Validation Acc 61.46 %\n",
      "Epoch:170/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.18 % AVG Validation Acc 61.37 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.649 AVG Validation Loss:0.663 AVG Training Acc 62.12 % AVG Validation Acc 61.46 %\n",
      "Epoch:190/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 62.28 % AVG Validation Acc 61.55 %\n",
      "Epoch:200/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.12 % AVG Validation Acc 61.55 %\n",
      "Split 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64fadccf63c644de9190180c452ad7e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.657 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.664 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.665 AVG Training Acc 61.92 % AVG Validation Acc 62.09 %\n",
      "Epoch:50/200 AVG Training Loss:0.651 AVG Validation Loss:0.667 AVG Training Acc 62.00 % AVG Validation Acc 62.00 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 62.11 % AVG Validation Acc 62.09 %\n",
      "Epoch:70/200 AVG Training Loss:0.649 AVG Validation Loss:0.667 AVG Training Acc 62.25 % AVG Validation Acc 62.09 %\n",
      "Epoch:80/200 AVG Training Loss:0.648 AVG Validation Loss:0.667 AVG Training Acc 62.18 % AVG Validation Acc 62.09 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.648 AVG Validation Loss:0.668 AVG Training Acc 62.17 % AVG Validation Acc 62.00 %\n",
      "Epoch:100/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 62.19 % AVG Validation Acc 62.09 %\n",
      "Epoch:110/200 AVG Training Loss:0.647 AVG Validation Loss:0.668 AVG Training Acc 62.25 % AVG Validation Acc 62.00 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.648 AVG Validation Loss:0.667 AVG Training Acc 62.15 % AVG Validation Acc 62.09 %\n",
      "Epoch:130/200 AVG Training Loss:0.648 AVG Validation Loss:0.668 AVG Training Acc 62.13 % AVG Validation Acc 62.09 %\n",
      "Epoch:140/200 AVG Training Loss:0.648 AVG Validation Loss:0.668 AVG Training Acc 62.01 % AVG Validation Acc 62.09 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 62.27 % AVG Validation Acc 62.09 %\n",
      "Epoch:160/200 AVG Training Loss:0.648 AVG Validation Loss:0.667 AVG Training Acc 62.05 % AVG Validation Acc 62.18 %\n",
      "Epoch:170/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 62.17 % AVG Validation Acc 62.18 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 62.15 % AVG Validation Acc 62.09 %\n",
      "Epoch:190/200 AVG Training Loss:0.648 AVG Validation Loss:0.667 AVG Training Acc 62.16 % AVG Validation Acc 62.18 %\n",
      "Epoch:200/200 AVG Training Loss:0.648 AVG Validation Loss:0.668 AVG Training Acc 62.21 % AVG Validation Acc 62.18 %\n",
      "Split 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a056e1e4861421e98768b1da766a934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.659 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.660 AVG Training Acc 61.93 % AVG Validation Acc 61.91 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.658 AVG Training Acc 61.75 % AVG Validation Acc 62.09 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.660 AVG Training Acc 61.84 % AVG Validation Acc 62.27 %\n",
      "Epoch:50/200 AVG Training Loss:0.650 AVG Validation Loss:0.662 AVG Training Acc 62.33 % AVG Validation Acc 62.00 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.647 AVG Validation Loss:0.662 AVG Training Acc 62.58 % AVG Validation Acc 61.73 %\n",
      "Epoch:70/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 62.31 % AVG Validation Acc 61.82 %\n",
      "Epoch:80/200 AVG Training Loss:0.648 AVG Validation Loss:0.663 AVG Training Acc 62.25 % AVG Validation Acc 61.64 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.647 AVG Validation Loss:0.664 AVG Training Acc 62.23 % AVG Validation Acc 61.82 %\n",
      "Epoch:100/200 AVG Training Loss:0.646 AVG Validation Loss:0.664 AVG Training Acc 62.35 % AVG Validation Acc 61.82 %\n",
      "Epoch:110/200 AVG Training Loss:0.646 AVG Validation Loss:0.663 AVG Training Acc 62.50 % AVG Validation Acc 61.82 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.647 AVG Validation Loss:0.664 AVG Training Acc 62.39 % AVG Validation Acc 61.73 %\n",
      "Epoch:130/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 62.32 % AVG Validation Acc 62.09 %\n",
      "Epoch:140/200 AVG Training Loss:0.645 AVG Validation Loss:0.663 AVG Training Acc 62.51 % AVG Validation Acc 62.00 %\n",
      "Epoch:150/200 AVG Training Loss:0.646 AVG Validation Loss:0.664 AVG Training Acc 62.39 % AVG Validation Acc 61.82 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.645 AVG Validation Loss:0.664 AVG Training Acc 62.56 % AVG Validation Acc 61.91 %\n",
      "Epoch:170/200 AVG Training Loss:0.647 AVG Validation Loss:0.664 AVG Training Acc 62.45 % AVG Validation Acc 61.82 %\n",
      "Epoch:180/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 62.09 % AVG Validation Acc 61.91 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.646 AVG Validation Loss:0.664 AVG Training Acc 62.51 % AVG Validation Acc 61.64 %\n",
      "Epoch:200/200 AVG Training Loss:0.646 AVG Validation Loss:0.663 AVG Training Acc 62.51 % AVG Validation Acc 61.91 %\n",
      "Split 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa5b16d4c2074fd6b3dcdcd68c3e5894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 61.92 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.664 AVG Training Acc 61.96 % AVG Validation Acc 61.82 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.667 AVG Training Acc 61.77 % AVG Validation Acc 61.73 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.651 AVG Validation Loss:0.667 AVG Training Acc 62.07 % AVG Validation Acc 61.73 %\n",
      "Epoch:60/200 AVG Training Loss:0.651 AVG Validation Loss:0.668 AVG Training Acc 61.80 % AVG Validation Acc 61.64 %\n",
      "Epoch:70/200 AVG Training Loss:0.650 AVG Validation Loss:0.668 AVG Training Acc 62.07 % AVG Validation Acc 61.64 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.650 AVG Validation Loss:0.668 AVG Training Acc 61.82 % AVG Validation Acc 61.64 %\n",
      "Epoch:90/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 62.25 % AVG Validation Acc 61.64 %\n",
      "Epoch:100/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 61.98 % AVG Validation Acc 61.64 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 61.82 % AVG Validation Acc 61.64 %\n",
      "Epoch:120/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 62.02 % AVG Validation Acc 61.64 %\n",
      "Epoch:130/200 AVG Training Loss:0.650 AVG Validation Loss:0.668 AVG Training Acc 61.71 % AVG Validation Acc 61.64 %\n",
      "Epoch:140/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 61.97 % AVG Validation Acc 61.64 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.650 AVG Validation Loss:0.668 AVG Training Acc 61.85 % AVG Validation Acc 61.55 %\n",
      "Epoch:160/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 62.02 % AVG Validation Acc 61.64 %\n",
      "Epoch:170/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 61.80 % AVG Validation Acc 61.64 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.650 AVG Validation Loss:0.668 AVG Training Acc 61.83 % AVG Validation Acc 61.64 %\n",
      "Epoch:190/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 61.87 % AVG Validation Acc 61.64 %\n",
      "Epoch:200/200 AVG Training Loss:0.650 AVG Validation Loss:0.668 AVG Training Acc 62.01 % AVG Validation Acc 61.64 %\n",
      "Split 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb6969a7566049ddad1080d15587be63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.654 AVG Training Acc 61.92 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.651 AVG Training Acc 61.85 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.660 AVG Validation Loss:0.653 AVG Training Acc 61.88 % AVG Validation Acc 61.82 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.652 AVG Training Acc 62.27 % AVG Validation Acc 61.46 %\n",
      "Epoch:50/200 AVG Training Loss:0.649 AVG Validation Loss:0.656 AVG Training Acc 62.11 % AVG Validation Acc 61.73 %\n",
      "Epoch:60/200 AVG Training Loss:0.645 AVG Validation Loss:0.660 AVG Training Acc 62.66 % AVG Validation Acc 61.37 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.642 AVG Validation Loss:0.662 AVG Training Acc 62.62 % AVG Validation Acc 61.01 %\n",
      "Epoch:80/200 AVG Training Loss:0.642 AVG Validation Loss:0.665 AVG Training Acc 63.00 % AVG Validation Acc 61.37 %\n",
      "Epoch:90/200 AVG Training Loss:0.641 AVG Validation Loss:0.666 AVG Training Acc 62.91 % AVG Validation Acc 61.10 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.639 AVG Validation Loss:0.666 AVG Training Acc 62.81 % AVG Validation Acc 61.19 %\n",
      "Epoch:110/200 AVG Training Loss:0.640 AVG Validation Loss:0.667 AVG Training Acc 62.83 % AVG Validation Acc 60.92 %\n",
      "Epoch:120/200 AVG Training Loss:0.640 AVG Validation Loss:0.667 AVG Training Acc 62.78 % AVG Validation Acc 61.10 %\n",
      "Epoch:130/200 AVG Training Loss:0.640 AVG Validation Loss:0.666 AVG Training Acc 62.77 % AVG Validation Acc 61.28 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.639 AVG Validation Loss:0.666 AVG Training Acc 62.96 % AVG Validation Acc 61.10 %\n",
      "Epoch:150/200 AVG Training Loss:0.641 AVG Validation Loss:0.666 AVG Training Acc 62.69 % AVG Validation Acc 61.01 %\n",
      "Epoch:160/200 AVG Training Loss:0.638 AVG Validation Loss:0.666 AVG Training Acc 63.19 % AVG Validation Acc 61.19 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.639 AVG Validation Loss:0.666 AVG Training Acc 63.27 % AVG Validation Acc 61.19 %\n",
      "Epoch:180/200 AVG Training Loss:0.640 AVG Validation Loss:0.666 AVG Training Acc 62.89 % AVG Validation Acc 61.37 %\n",
      "Epoch:190/200 AVG Training Loss:0.640 AVG Validation Loss:0.666 AVG Training Acc 62.92 % AVG Validation Acc 61.64 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.639 AVG Validation Loss:0.666 AVG Training Acc 62.88 % AVG Validation Acc 61.46 %\n",
      "Split 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b71806a67bee4cb6bd5eaabd7091897c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.665 AVG Training Acc 61.83 % AVG Validation Acc 62.04 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.666 AVG Training Acc 61.97 % AVG Validation Acc 61.77 %\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.665 AVG Training Acc 61.97 % AVG Validation Acc 61.77 %\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.664 AVG Training Acc 62.07 % AVG Validation Acc 61.77 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.649 AVG Validation Loss:0.665 AVG Training Acc 62.13 % AVG Validation Acc 61.77 %\n",
      "Epoch:60/200 AVG Training Loss:0.647 AVG Validation Loss:0.666 AVG Training Acc 62.16 % AVG Validation Acc 61.86 %\n",
      "Epoch:70/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 62.27 % AVG Validation Acc 61.77 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.646 AVG Validation Loss:0.666 AVG Training Acc 62.26 % AVG Validation Acc 61.86 %\n",
      "Epoch:90/200 AVG Training Loss:0.646 AVG Validation Loss:0.666 AVG Training Acc 62.26 % AVG Validation Acc 61.86 %\n",
      "Epoch:100/200 AVG Training Loss:0.646 AVG Validation Loss:0.666 AVG Training Acc 62.19 % AVG Validation Acc 61.86 %\n",
      "Epoch:110/200 AVG Training Loss:0.647 AVG Validation Loss:0.666 AVG Training Acc 62.06 % AVG Validation Acc 61.86 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 62.32 % AVG Validation Acc 61.86 %\n",
      "Epoch:130/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 62.09 % AVG Validation Acc 61.86 %\n",
      "Epoch:140/200 AVG Training Loss:0.646 AVG Validation Loss:0.667 AVG Training Acc 62.17 % AVG Validation Acc 61.86 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 62.04 % AVG Validation Acc 61.86 %\n",
      "Epoch:160/200 AVG Training Loss:0.646 AVG Validation Loss:0.666 AVG Training Acc 62.17 % AVG Validation Acc 61.86 %\n",
      "Epoch:170/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 62.12 % AVG Validation Acc 61.77 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.646 AVG Validation Loss:0.666 AVG Training Acc 62.22 % AVG Validation Acc 61.77 %\n",
      "Epoch:190/200 AVG Training Loss:0.646 AVG Validation Loss:0.667 AVG Training Acc 62.26 % AVG Validation Acc 61.86 %\n",
      "Epoch:200/200 AVG Training Loss:0.646 AVG Validation Loss:0.667 AVG Training Acc 62.21 % AVG Validation Acc 61.86 %\n",
      "Split 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd9a08b9489d48ae9ab93a4f97b27285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.659 AVG Training Acc 61.87 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.657 AVG Training Acc 62.04 % AVG Validation Acc 61.77 %\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.659 AVG Training Acc 61.81 % AVG Validation Acc 61.77 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.660 AVG Training Acc 61.84 % AVG Validation Acc 61.95 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.640 AVG Validation Loss:0.674 AVG Training Acc 62.70 % AVG Validation Acc 61.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.633 AVG Validation Loss:0.687 AVG Training Acc 62.99 % AVG Validation Acc 60.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.627 AVG Validation Loss:0.697 AVG Training Acc 63.33 % AVG Validation Acc 60.32 %\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.622 AVG Validation Loss:0.700 AVG Training Acc 63.54 % AVG Validation Acc 60.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.623 AVG Validation Loss:0.701 AVG Training Acc 63.95 % AVG Validation Acc 60.23 %\n",
      "Epoch:100/200 AVG Training Loss:0.623 AVG Validation Loss:0.707 AVG Training Acc 63.80 % AVG Validation Acc 59.96 %\n",
      "Epoch   104: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.622 AVG Validation Loss:0.705 AVG Training Acc 63.54 % AVG Validation Acc 60.05 %\n",
      "Epoch:120/200 AVG Training Loss:0.620 AVG Validation Loss:0.705 AVG Training Acc 63.66 % AVG Validation Acc 60.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.623 AVG Validation Loss:0.706 AVG Training Acc 63.49 % AVG Validation Acc 59.96 %\n",
      "Epoch   135: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.622 AVG Validation Loss:0.706 AVG Training Acc 64.15 % AVG Validation Acc 60.23 %\n",
      "Epoch:150/200 AVG Training Loss:0.619 AVG Validation Loss:0.706 AVG Training Acc 64.36 % AVG Validation Acc 59.96 %\n",
      "Epoch:160/200 AVG Training Loss:0.621 AVG Validation Loss:0.708 AVG Training Acc 63.74 % AVG Validation Acc 59.87 %\n",
      "Epoch   166: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.621 AVG Validation Loss:0.705 AVG Training Acc 64.00 % AVG Validation Acc 59.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.620 AVG Validation Loss:0.706 AVG Training Acc 64.00 % AVG Validation Acc 59.96 %\n",
      "Epoch:190/200 AVG Training Loss:0.623 AVG Validation Loss:0.705 AVG Training Acc 63.90 % AVG Validation Acc 60.41 %\n",
      "Epoch   197: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.621 AVG Validation Loss:0.703 AVG Training Acc 63.98 % AVG Validation Acc 60.32 %\n",
      "Split 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0215bdbc63b843a8a70f185b6d664bdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.657 AVG Training Acc 61.93 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.657 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.657 AVG Training Acc 62.02 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.657 AVG Training Acc 62.14 % AVG Validation Acc 61.86 %\n",
      "Epoch:50/200 AVG Training Loss:0.648 AVG Validation Loss:0.658 AVG Training Acc 62.40 % AVG Validation Acc 61.68 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.648 AVG Validation Loss:0.657 AVG Training Acc 62.22 % AVG Validation Acc 61.77 %\n",
      "Epoch:70/200 AVG Training Loss:0.646 AVG Validation Loss:0.657 AVG Training Acc 62.37 % AVG Validation Acc 61.77 %\n",
      "Epoch:80/200 AVG Training Loss:0.646 AVG Validation Loss:0.658 AVG Training Acc 62.45 % AVG Validation Acc 61.77 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.646 AVG Validation Loss:0.658 AVG Training Acc 62.38 % AVG Validation Acc 61.77 %\n",
      "Epoch:100/200 AVG Training Loss:0.646 AVG Validation Loss:0.658 AVG Training Acc 62.40 % AVG Validation Acc 61.59 %\n",
      "Epoch:110/200 AVG Training Loss:0.646 AVG Validation Loss:0.658 AVG Training Acc 62.38 % AVG Validation Acc 61.77 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.646 AVG Validation Loss:0.658 AVG Training Acc 62.50 % AVG Validation Acc 61.77 %\n",
      "Epoch:130/200 AVG Training Loss:0.645 AVG Validation Loss:0.658 AVG Training Acc 62.44 % AVG Validation Acc 61.68 %\n",
      "Epoch:140/200 AVG Training Loss:0.646 AVG Validation Loss:0.658 AVG Training Acc 62.44 % AVG Validation Acc 61.77 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.645 AVG Validation Loss:0.658 AVG Training Acc 62.55 % AVG Validation Acc 61.68 %\n",
      "Epoch:160/200 AVG Training Loss:0.645 AVG Validation Loss:0.658 AVG Training Acc 62.45 % AVG Validation Acc 61.59 %\n",
      "Epoch:170/200 AVG Training Loss:0.646 AVG Validation Loss:0.657 AVG Training Acc 62.44 % AVG Validation Acc 61.77 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.644 AVG Validation Loss:0.658 AVG Training Acc 62.56 % AVG Validation Acc 61.68 %\n",
      "Epoch:190/200 AVG Training Loss:0.645 AVG Validation Loss:0.658 AVG Training Acc 62.45 % AVG Validation Acc 61.59 %\n",
      "Epoch:200/200 AVG Training Loss:0.646 AVG Validation Loss:0.658 AVG Training Acc 62.43 % AVG Validation Acc 61.59 %\n",
      "Split 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46741a725f264bf4b31c473075bd6b86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.655 AVG Training Acc 61.93 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.657 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.656 AVG Training Acc 61.84 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.654 AVG Training Acc 62.09 % AVG Validation Acc 62.31 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.643 AVG Validation Loss:0.656 AVG Training Acc 62.26 % AVG Validation Acc 62.04 %\n",
      "Epoch:60/200 AVG Training Loss:0.637 AVG Validation Loss:0.660 AVG Training Acc 62.63 % AVG Validation Acc 61.77 %\n",
      "Epoch:70/200 AVG Training Loss:0.633 AVG Validation Loss:0.660 AVG Training Acc 63.00 % AVG Validation Acc 61.23 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.626 AVG Validation Loss:0.660 AVG Training Acc 63.44 % AVG Validation Acc 61.68 %\n",
      "Epoch:90/200 AVG Training Loss:0.626 AVG Validation Loss:0.662 AVG Training Acc 63.48 % AVG Validation Acc 61.68 %\n",
      "Epoch:100/200 AVG Training Loss:0.626 AVG Validation Loss:0.662 AVG Training Acc 63.24 % AVG Validation Acc 62.04 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.625 AVG Validation Loss:0.664 AVG Training Acc 63.77 % AVG Validation Acc 61.77 %\n",
      "Epoch:120/200 AVG Training Loss:0.624 AVG Validation Loss:0.664 AVG Training Acc 63.71 % AVG Validation Acc 61.77 %\n",
      "Epoch:130/200 AVG Training Loss:0.625 AVG Validation Loss:0.663 AVG Training Acc 63.75 % AVG Validation Acc 61.86 %\n",
      "Epoch:140/200 AVG Training Loss:0.624 AVG Validation Loss:0.665 AVG Training Acc 63.63 % AVG Validation Acc 61.50 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.623 AVG Validation Loss:0.664 AVG Training Acc 63.67 % AVG Validation Acc 61.77 %\n",
      "Epoch:160/200 AVG Training Loss:0.623 AVG Validation Loss:0.662 AVG Training Acc 63.68 % AVG Validation Acc 61.68 %\n",
      "Epoch:170/200 AVG Training Loss:0.625 AVG Validation Loss:0.665 AVG Training Acc 63.67 % AVG Validation Acc 61.41 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.624 AVG Validation Loss:0.663 AVG Training Acc 63.44 % AVG Validation Acc 61.68 %\n",
      "Epoch:190/200 AVG Training Loss:0.623 AVG Validation Loss:0.663 AVG Training Acc 63.25 % AVG Validation Acc 61.59 %\n",
      "Epoch:200/200 AVG Training Loss:0.625 AVG Validation Loss:0.660 AVG Training Acc 63.95 % AVG Validation Acc 61.86 %\n",
      "Split 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81e47fb7883d44c38ed71697c09a63b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.666 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.667 AVG Training Acc 62.02 % AVG Validation Acc 61.86 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.664 AVG Training Acc 62.16 % AVG Validation Acc 61.59 %\n",
      "Epoch:40/200 AVG Training Loss:0.650 AVG Validation Loss:0.665 AVG Training Acc 61.96 % AVG Validation Acc 61.68 %\n",
      "Epoch:50/200 AVG Training Loss:0.648 AVG Validation Loss:0.669 AVG Training Acc 62.12 % AVG Validation Acc 61.86 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.644 AVG Validation Loss:0.673 AVG Training Acc 62.16 % AVG Validation Acc 61.32 %\n",
      "Epoch:70/200 AVG Training Loss:0.644 AVG Validation Loss:0.674 AVG Training Acc 62.10 % AVG Validation Acc 61.23 %\n",
      "Epoch:80/200 AVG Training Loss:0.644 AVG Validation Loss:0.674 AVG Training Acc 62.27 % AVG Validation Acc 61.32 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.642 AVG Validation Loss:0.676 AVG Training Acc 62.24 % AVG Validation Acc 61.05 %\n",
      "Epoch:100/200 AVG Training Loss:0.642 AVG Validation Loss:0.676 AVG Training Acc 62.21 % AVG Validation Acc 61.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.643 AVG Validation Loss:0.676 AVG Training Acc 62.26 % AVG Validation Acc 61.32 %\n",
      "Epoch:120/200 AVG Training Loss:0.643 AVG Validation Loss:0.676 AVG Training Acc 62.01 % AVG Validation Acc 61.23 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.642 AVG Validation Loss:0.675 AVG Training Acc 62.14 % AVG Validation Acc 61.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.643 AVG Validation Loss:0.677 AVG Training Acc 62.25 % AVG Validation Acc 61.14 %\n",
      "Epoch:150/200 AVG Training Loss:0.643 AVG Validation Loss:0.676 AVG Training Acc 62.28 % AVG Validation Acc 61.23 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.643 AVG Validation Loss:0.677 AVG Training Acc 62.07 % AVG Validation Acc 61.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.642 AVG Validation Loss:0.676 AVG Training Acc 62.38 % AVG Validation Acc 61.23 %\n",
      "Epoch:180/200 AVG Training Loss:0.643 AVG Validation Loss:0.677 AVG Training Acc 62.22 % AVG Validation Acc 61.23 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.643 AVG Validation Loss:0.676 AVG Training Acc 61.97 % AVG Validation Acc 61.32 %\n",
      "Epoch:200/200 AVG Training Loss:0.643 AVG Validation Loss:0.676 AVG Training Acc 62.39 % AVG Validation Acc 61.32 %\n",
      "Split 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "207f07d35dab4263810f7d58900ba5ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.662 AVG Validation Loss:0.658 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.661 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.665 AVG Training Acc 61.86 % AVG Validation Acc 61.91 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.668 AVG Training Acc 61.96 % AVG Validation Acc 61.64 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.650 AVG Validation Loss:0.672 AVG Training Acc 62.01 % AVG Validation Acc 61.46 %\n",
      "Epoch:60/200 AVG Training Loss:0.649 AVG Validation Loss:0.672 AVG Training Acc 62.03 % AVG Validation Acc 61.46 %\n",
      "Epoch:70/200 AVG Training Loss:0.649 AVG Validation Loss:0.675 AVG Training Acc 62.06 % AVG Validation Acc 61.46 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.649 AVG Validation Loss:0.675 AVG Training Acc 62.09 % AVG Validation Acc 61.55 %\n",
      "Epoch:90/200 AVG Training Loss:0.649 AVG Validation Loss:0.675 AVG Training Acc 62.11 % AVG Validation Acc 61.55 %\n",
      "Epoch:100/200 AVG Training Loss:0.649 AVG Validation Loss:0.675 AVG Training Acc 62.13 % AVG Validation Acc 61.55 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.648 AVG Validation Loss:0.675 AVG Training Acc 62.06 % AVG Validation Acc 61.55 %\n",
      "Epoch:120/200 AVG Training Loss:0.649 AVG Validation Loss:0.675 AVG Training Acc 62.06 % AVG Validation Acc 61.55 %\n",
      "Epoch:130/200 AVG Training Loss:0.647 AVG Validation Loss:0.675 AVG Training Acc 62.05 % AVG Validation Acc 61.55 %\n",
      "Epoch:140/200 AVG Training Loss:0.648 AVG Validation Loss:0.675 AVG Training Acc 62.10 % AVG Validation Acc 61.55 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.649 AVG Validation Loss:0.675 AVG Training Acc 62.14 % AVG Validation Acc 61.55 %\n",
      "Epoch:160/200 AVG Training Loss:0.649 AVG Validation Loss:0.675 AVG Training Acc 62.01 % AVG Validation Acc 61.55 %\n",
      "Epoch:170/200 AVG Training Loss:0.648 AVG Validation Loss:0.675 AVG Training Acc 62.18 % AVG Validation Acc 61.55 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.649 AVG Validation Loss:0.675 AVG Training Acc 61.99 % AVG Validation Acc 61.55 %\n",
      "Epoch:190/200 AVG Training Loss:0.649 AVG Validation Loss:0.675 AVG Training Acc 62.08 % AVG Validation Acc 61.55 %\n",
      "Epoch:200/200 AVG Training Loss:0.650 AVG Validation Loss:0.676 AVG Training Acc 61.99 % AVG Validation Acc 61.55 %\n",
      "Split 17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b1c39ca02d54ae18059e750ede4c3dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.663 AVG Training Acc 61.80 % AVG Validation Acc 62.00 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.649 AVG Validation Loss:0.665 AVG Training Acc 62.19 % AVG Validation Acc 61.64 %\n",
      "Epoch:40/200 AVG Training Loss:0.645 AVG Validation Loss:0.668 AVG Training Acc 61.90 % AVG Validation Acc 60.92 %\n",
      "Epoch:50/200 AVG Training Loss:0.640 AVG Validation Loss:0.670 AVG Training Acc 62.05 % AVG Validation Acc 60.92 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.636 AVG Validation Loss:0.672 AVG Training Acc 62.62 % AVG Validation Acc 60.56 %\n",
      "Epoch:70/200 AVG Training Loss:0.633 AVG Validation Loss:0.673 AVG Training Acc 62.89 % AVG Validation Acc 60.92 %\n",
      "Epoch:80/200 AVG Training Loss:0.632 AVG Validation Loss:0.674 AVG Training Acc 62.66 % AVG Validation Acc 60.83 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.632 AVG Validation Loss:0.674 AVG Training Acc 62.82 % AVG Validation Acc 61.10 %\n",
      "Epoch:100/200 AVG Training Loss:0.631 AVG Validation Loss:0.675 AVG Training Acc 62.65 % AVG Validation Acc 60.83 %\n",
      "Epoch:110/200 AVG Training Loss:0.629 AVG Validation Loss:0.675 AVG Training Acc 62.90 % AVG Validation Acc 60.92 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.633 AVG Validation Loss:0.674 AVG Training Acc 62.65 % AVG Validation Acc 61.01 %\n",
      "Epoch:130/200 AVG Training Loss:0.630 AVG Validation Loss:0.675 AVG Training Acc 62.80 % AVG Validation Acc 61.10 %\n",
      "Epoch:140/200 AVG Training Loss:0.631 AVG Validation Loss:0.675 AVG Training Acc 62.77 % AVG Validation Acc 60.83 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.631 AVG Validation Loss:0.674 AVG Training Acc 63.05 % AVG Validation Acc 61.10 %\n",
      "Epoch:160/200 AVG Training Loss:0.631 AVG Validation Loss:0.675 AVG Training Acc 62.65 % AVG Validation Acc 61.01 %\n",
      "Epoch:170/200 AVG Training Loss:0.630 AVG Validation Loss:0.675 AVG Training Acc 62.74 % AVG Validation Acc 61.01 %\n",
      "Epoch:180/200 AVG Training Loss:0.631 AVG Validation Loss:0.676 AVG Training Acc 62.75 % AVG Validation Acc 61.10 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.632 AVG Validation Loss:0.675 AVG Training Acc 62.61 % AVG Validation Acc 61.10 %\n",
      "Epoch:200/200 AVG Training Loss:0.633 AVG Validation Loss:0.675 AVG Training Acc 62.66 % AVG Validation Acc 60.83 %\n",
      "Split 18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc635eeb88c047038a9e91752aa966e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.661 AVG Training Acc 61.85 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.660 AVG Training Acc 61.92 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.660 AVG Training Acc 61.51 % AVG Validation Acc 62.00 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.662 AVG Training Acc 62.31 % AVG Validation Acc 61.64 %\n",
      "Epoch:50/200 AVG Training Loss:0.650 AVG Validation Loss:0.663 AVG Training Acc 62.19 % AVG Validation Acc 61.19 %\n",
      "Epoch:60/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.26 % AVG Validation Acc 61.19 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.646 AVG Validation Loss:0.665 AVG Training Acc 62.48 % AVG Validation Acc 61.19 %\n",
      "Epoch:80/200 AVG Training Loss:0.644 AVG Validation Loss:0.665 AVG Training Acc 62.78 % AVG Validation Acc 61.19 %\n",
      "Epoch:90/200 AVG Training Loss:0.644 AVG Validation Loss:0.666 AVG Training Acc 62.74 % AVG Validation Acc 60.65 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.644 AVG Validation Loss:0.666 AVG Training Acc 62.35 % AVG Validation Acc 61.19 %\n",
      "Epoch:110/200 AVG Training Loss:0.644 AVG Validation Loss:0.665 AVG Training Acc 62.71 % AVG Validation Acc 60.83 %\n",
      "Epoch:120/200 AVG Training Loss:0.644 AVG Validation Loss:0.665 AVG Training Acc 62.96 % AVG Validation Acc 61.28 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.644 AVG Validation Loss:0.666 AVG Training Acc 62.58 % AVG Validation Acc 61.10 %\n",
      "Epoch:140/200 AVG Training Loss:0.644 AVG Validation Loss:0.666 AVG Training Acc 62.55 % AVG Validation Acc 61.10 %\n",
      "Epoch:150/200 AVG Training Loss:0.645 AVG Validation Loss:0.666 AVG Training Acc 62.41 % AVG Validation Acc 61.01 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.644 AVG Validation Loss:0.666 AVG Training Acc 62.52 % AVG Validation Acc 61.37 %\n",
      "Epoch:170/200 AVG Training Loss:0.645 AVG Validation Loss:0.666 AVG Training Acc 62.71 % AVG Validation Acc 61.01 %\n",
      "Epoch:180/200 AVG Training Loss:0.644 AVG Validation Loss:0.666 AVG Training Acc 62.87 % AVG Validation Acc 61.10 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.645 AVG Validation Loss:0.666 AVG Training Acc 62.57 % AVG Validation Acc 60.92 %\n",
      "Epoch:200/200 AVG Training Loss:0.643 AVG Validation Loss:0.666 AVG Training Acc 62.75 % AVG Validation Acc 61.28 %\n",
      "Split 19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10d86725083942d08339ae5fbbb1eabe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.657 AVG Training Acc 61.86 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.659 AVG Training Acc 61.75 % AVG Validation Acc 62.09 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.662 AVG Training Acc 61.98 % AVG Validation Acc 61.82 %\n",
      "Epoch:40/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 62.03 % AVG Validation Acc 61.73 %\n",
      "Epoch:50/200 AVG Training Loss:0.645 AVG Validation Loss:0.675 AVG Training Acc 62.13 % AVG Validation Acc 61.37 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.638 AVG Validation Loss:0.677 AVG Training Acc 62.76 % AVG Validation Acc 61.37 %\n",
      "Epoch:70/200 AVG Training Loss:0.636 AVG Validation Loss:0.680 AVG Training Acc 62.51 % AVG Validation Acc 61.28 %\n",
      "Epoch:80/200 AVG Training Loss:0.637 AVG Validation Loss:0.680 AVG Training Acc 62.48 % AVG Validation Acc 61.28 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.635 AVG Validation Loss:0.682 AVG Training Acc 62.76 % AVG Validation Acc 61.28 %\n",
      "Epoch:100/200 AVG Training Loss:0.635 AVG Validation Loss:0.681 AVG Training Acc 62.69 % AVG Validation Acc 61.28 %\n",
      "Epoch:110/200 AVG Training Loss:0.635 AVG Validation Loss:0.682 AVG Training Acc 62.55 % AVG Validation Acc 61.28 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.635 AVG Validation Loss:0.682 AVG Training Acc 62.75 % AVG Validation Acc 61.28 %\n",
      "Epoch:130/200 AVG Training Loss:0.635 AVG Validation Loss:0.682 AVG Training Acc 62.74 % AVG Validation Acc 61.28 %\n",
      "Epoch:140/200 AVG Training Loss:0.636 AVG Validation Loss:0.682 AVG Training Acc 62.65 % AVG Validation Acc 61.28 %\n",
      "Epoch:150/200 AVG Training Loss:0.635 AVG Validation Loss:0.682 AVG Training Acc 62.63 % AVG Validation Acc 61.28 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.635 AVG Validation Loss:0.682 AVG Training Acc 62.56 % AVG Validation Acc 61.28 %\n",
      "Epoch:170/200 AVG Training Loss:0.635 AVG Validation Loss:0.682 AVG Training Acc 62.60 % AVG Validation Acc 61.28 %\n",
      "Epoch:180/200 AVG Training Loss:0.634 AVG Validation Loss:0.682 AVG Training Acc 62.81 % AVG Validation Acc 61.19 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.634 AVG Validation Loss:0.682 AVG Training Acc 62.68 % AVG Validation Acc 61.28 %\n",
      "Epoch:200/200 AVG Training Loss:0.637 AVG Validation Loss:0.682 AVG Training Acc 62.38 % AVG Validation Acc 61.28 %\n",
      "Split 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb3cbed6f7946a7955e60c6e1786aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.660 AVG Training Acc 61.92 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.659 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.661 AVG Training Acc 61.87 % AVG Validation Acc 61.91 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.663 AVG Training Acc 61.73 % AVG Validation Acc 61.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 61.84 % AVG Validation Acc 61.55 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.645 AVG Validation Loss:0.670 AVG Training Acc 62.10 % AVG Validation Acc 61.64 %\n",
      "Epoch:70/200 AVG Training Loss:0.646 AVG Validation Loss:0.671 AVG Training Acc 61.94 % AVG Validation Acc 61.46 %\n",
      "Epoch:80/200 AVG Training Loss:0.645 AVG Validation Loss:0.670 AVG Training Acc 62.11 % AVG Validation Acc 61.73 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.645 AVG Validation Loss:0.670 AVG Training Acc 62.05 % AVG Validation Acc 61.37 %\n",
      "Epoch:100/200 AVG Training Loss:0.644 AVG Validation Loss:0.671 AVG Training Acc 62.05 % AVG Validation Acc 61.28 %\n",
      "Epoch:110/200 AVG Training Loss:0.645 AVG Validation Loss:0.670 AVG Training Acc 61.94 % AVG Validation Acc 61.01 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.645 AVG Validation Loss:0.671 AVG Training Acc 62.17 % AVG Validation Acc 61.19 %\n",
      "Epoch:130/200 AVG Training Loss:0.644 AVG Validation Loss:0.671 AVG Training Acc 62.03 % AVG Validation Acc 61.28 %\n",
      "Epoch:140/200 AVG Training Loss:0.645 AVG Validation Loss:0.670 AVG Training Acc 62.03 % AVG Validation Acc 60.92 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.645 AVG Validation Loss:0.671 AVG Training Acc 62.00 % AVG Validation Acc 61.10 %\n",
      "Epoch:160/200 AVG Training Loss:0.645 AVG Validation Loss:0.671 AVG Training Acc 62.03 % AVG Validation Acc 61.19 %\n",
      "Epoch:170/200 AVG Training Loss:0.645 AVG Validation Loss:0.671 AVG Training Acc 62.02 % AVG Validation Acc 61.46 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.645 AVG Validation Loss:0.671 AVG Training Acc 62.09 % AVG Validation Acc 61.28 %\n",
      "Epoch:190/200 AVG Training Loss:0.644 AVG Validation Loss:0.671 AVG Training Acc 61.86 % AVG Validation Acc 61.37 %\n",
      "Epoch:200/200 AVG Training Loss:0.645 AVG Validation Loss:0.671 AVG Training Acc 61.81 % AVG Validation Acc 61.19 %\n",
      "Split 21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8387e77d686f4a2d8504a58d76351f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.665 AVG Training Acc 61.88 % AVG Validation Acc 61.95 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.666 AVG Training Acc 61.87 % AVG Validation Acc 61.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.665 AVG Training Acc 61.90 % AVG Validation Acc 61.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.665 AVG Training Acc 61.96 % AVG Validation Acc 62.04 %\n",
      "Epoch:50/200 AVG Training Loss:0.650 AVG Validation Loss:0.670 AVG Training Acc 61.98 % AVG Validation Acc 61.68 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.648 AVG Validation Loss:0.670 AVG Training Acc 62.05 % AVG Validation Acc 61.77 %\n",
      "Epoch:70/200 AVG Training Loss:0.649 AVG Validation Loss:0.669 AVG Training Acc 62.00 % AVG Validation Acc 61.77 %\n",
      "Epoch:80/200 AVG Training Loss:0.649 AVG Validation Loss:0.670 AVG Training Acc 62.09 % AVG Validation Acc 61.68 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.648 AVG Validation Loss:0.670 AVG Training Acc 62.04 % AVG Validation Acc 61.68 %\n",
      "Epoch:100/200 AVG Training Loss:0.648 AVG Validation Loss:0.670 AVG Training Acc 62.02 % AVG Validation Acc 61.68 %\n",
      "Epoch:110/200 AVG Training Loss:0.648 AVG Validation Loss:0.670 AVG Training Acc 62.12 % AVG Validation Acc 61.68 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.648 AVG Validation Loss:0.671 AVG Training Acc 61.97 % AVG Validation Acc 61.68 %\n",
      "Epoch:130/200 AVG Training Loss:0.648 AVG Validation Loss:0.670 AVG Training Acc 62.07 % AVG Validation Acc 61.68 %\n",
      "Epoch:140/200 AVG Training Loss:0.647 AVG Validation Loss:0.671 AVG Training Acc 62.03 % AVG Validation Acc 61.68 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.647 AVG Validation Loss:0.670 AVG Training Acc 62.07 % AVG Validation Acc 61.68 %\n",
      "Epoch:160/200 AVG Training Loss:0.648 AVG Validation Loss:0.671 AVG Training Acc 62.15 % AVG Validation Acc 61.68 %\n",
      "Epoch:170/200 AVG Training Loss:0.648 AVG Validation Loss:0.670 AVG Training Acc 62.09 % AVG Validation Acc 61.68 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.647 AVG Validation Loss:0.671 AVG Training Acc 62.08 % AVG Validation Acc 61.68 %\n",
      "Epoch:190/200 AVG Training Loss:0.647 AVG Validation Loss:0.671 AVG Training Acc 62.06 % AVG Validation Acc 61.68 %\n",
      "Epoch:200/200 AVG Training Loss:0.647 AVG Validation Loss:0.670 AVG Training Acc 62.11 % AVG Validation Acc 61.68 %\n",
      "Split 22\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bebf4cacfc544ce8e6937f8e08df49c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.660 AVG Training Acc 61.92 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.658 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.658 AVG Validation Loss:0.655 AVG Training Acc 61.84 % AVG Validation Acc 61.77 %\n",
      "Epoch:40/200 AVG Training Loss:0.655 AVG Validation Loss:0.656 AVG Training Acc 61.85 % AVG Validation Acc 61.95 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.648 AVG Validation Loss:0.658 AVG Training Acc 62.15 % AVG Validation Acc 61.68 %\n",
      "Epoch:60/200 AVG Training Loss:0.641 AVG Validation Loss:0.658 AVG Training Acc 62.44 % AVG Validation Acc 61.50 %\n",
      "Epoch:70/200 AVG Training Loss:0.636 AVG Validation Loss:0.658 AVG Training Acc 62.73 % AVG Validation Acc 61.32 %\n",
      "Epoch:80/200 AVG Training Loss:0.633 AVG Validation Loss:0.666 AVG Training Acc 63.08 % AVG Validation Acc 61.68 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.632 AVG Validation Loss:0.665 AVG Training Acc 63.10 % AVG Validation Acc 61.77 %\n",
      "Epoch:100/200 AVG Training Loss:0.631 AVG Validation Loss:0.665 AVG Training Acc 63.10 % AVG Validation Acc 62.04 %\n",
      "Epoch:110/200 AVG Training Loss:0.631 AVG Validation Loss:0.662 AVG Training Acc 63.10 % AVG Validation Acc 61.77 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.631 AVG Validation Loss:0.662 AVG Training Acc 62.79 % AVG Validation Acc 62.13 %\n",
      "Epoch:130/200 AVG Training Loss:0.631 AVG Validation Loss:0.665 AVG Training Acc 62.83 % AVG Validation Acc 62.04 %\n",
      "Epoch:140/200 AVG Training Loss:0.630 AVG Validation Loss:0.666 AVG Training Acc 62.46 % AVG Validation Acc 61.59 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.631 AVG Validation Loss:0.665 AVG Training Acc 63.11 % AVG Validation Acc 61.77 %\n",
      "Epoch:160/200 AVG Training Loss:0.630 AVG Validation Loss:0.668 AVG Training Acc 63.04 % AVG Validation Acc 61.77 %\n",
      "Epoch:170/200 AVG Training Loss:0.630 AVG Validation Loss:0.666 AVG Training Acc 62.98 % AVG Validation Acc 61.95 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.630 AVG Validation Loss:0.667 AVG Training Acc 62.89 % AVG Validation Acc 61.95 %\n",
      "Epoch:190/200 AVG Training Loss:0.632 AVG Validation Loss:0.665 AVG Training Acc 62.83 % AVG Validation Acc 61.86 %\n",
      "Epoch:200/200 AVG Training Loss:0.631 AVG Validation Loss:0.668 AVG Training Acc 62.56 % AVG Validation Acc 61.50 %\n",
      "Split 23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92105dfa9fca4c3b888cbeb834266bb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.656 AVG Training Acc 61.84 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.655 AVG Training Acc 61.84 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.664 AVG Training Acc 62.03 % AVG Validation Acc 62.04 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.648 AVG Validation Loss:0.659 AVG Training Acc 62.01 % AVG Validation Acc 61.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.644 AVG Validation Loss:0.667 AVG Training Acc 61.94 % AVG Validation Acc 60.78 %\n",
      "Epoch:60/200 AVG Training Loss:0.640 AVG Validation Loss:0.670 AVG Training Acc 62.58 % AVG Validation Acc 60.60 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.636 AVG Validation Loss:0.670 AVG Training Acc 63.19 % AVG Validation Acc 60.50 %\n",
      "Epoch:80/200 AVG Training Loss:0.637 AVG Validation Loss:0.670 AVG Training Acc 62.91 % AVG Validation Acc 60.50 %\n",
      "Epoch:90/200 AVG Training Loss:0.635 AVG Validation Loss:0.671 AVG Training Acc 63.38 % AVG Validation Acc 60.05 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.637 AVG Validation Loss:0.669 AVG Training Acc 63.08 % AVG Validation Acc 60.32 %\n",
      "Epoch:110/200 AVG Training Loss:0.637 AVG Validation Loss:0.671 AVG Training Acc 63.14 % AVG Validation Acc 59.96 %\n",
      "Epoch:120/200 AVG Training Loss:0.636 AVG Validation Loss:0.670 AVG Training Acc 63.09 % AVG Validation Acc 60.14 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.636 AVG Validation Loss:0.671 AVG Training Acc 62.97 % AVG Validation Acc 60.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.634 AVG Validation Loss:0.671 AVG Training Acc 63.43 % AVG Validation Acc 59.60 %\n",
      "Epoch:150/200 AVG Training Loss:0.636 AVG Validation Loss:0.671 AVG Training Acc 63.28 % AVG Validation Acc 60.05 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.636 AVG Validation Loss:0.670 AVG Training Acc 63.20 % AVG Validation Acc 59.96 %\n",
      "Epoch:170/200 AVG Training Loss:0.636 AVG Validation Loss:0.670 AVG Training Acc 63.40 % AVG Validation Acc 59.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.634 AVG Validation Loss:0.671 AVG Training Acc 63.57 % AVG Validation Acc 59.96 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.635 AVG Validation Loss:0.669 AVG Training Acc 63.14 % AVG Validation Acc 59.96 %\n",
      "Epoch:200/200 AVG Training Loss:0.637 AVG Validation Loss:0.672 AVG Training Acc 63.21 % AVG Validation Acc 59.87 %\n",
      "Split 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73369978615e47c9b3a8c1f21dd67541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.664 AVG Training Acc 61.85 % AVG Validation Acc 61.86 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.669 AVG Training Acc 61.94 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.652 AVG Validation Loss:0.672 AVG Training Acc 61.94 % AVG Validation Acc 62.04 %\n",
      "Epoch:40/200 AVG Training Loss:0.650 AVG Validation Loss:0.674 AVG Training Acc 62.08 % AVG Validation Acc 62.22 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.647 AVG Validation Loss:0.678 AVG Training Acc 62.03 % AVG Validation Acc 62.13 %\n",
      "Epoch:60/200 AVG Training Loss:0.647 AVG Validation Loss:0.678 AVG Training Acc 62.18 % AVG Validation Acc 62.22 %\n",
      "Epoch:70/200 AVG Training Loss:0.647 AVG Validation Loss:0.679 AVG Training Acc 62.26 % AVG Validation Acc 62.13 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.647 AVG Validation Loss:0.679 AVG Training Acc 62.10 % AVG Validation Acc 62.22 %\n",
      "Epoch:90/200 AVG Training Loss:0.646 AVG Validation Loss:0.679 AVG Training Acc 62.21 % AVG Validation Acc 62.22 %\n",
      "Epoch:100/200 AVG Training Loss:0.646 AVG Validation Loss:0.679 AVG Training Acc 62.21 % AVG Validation Acc 62.22 %\n",
      "Epoch:110/200 AVG Training Loss:0.646 AVG Validation Loss:0.680 AVG Training Acc 62.13 % AVG Validation Acc 62.22 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.647 AVG Validation Loss:0.680 AVG Training Acc 61.96 % AVG Validation Acc 62.13 %\n",
      "Epoch:130/200 AVG Training Loss:0.647 AVG Validation Loss:0.680 AVG Training Acc 62.38 % AVG Validation Acc 62.13 %\n",
      "Epoch:140/200 AVG Training Loss:0.647 AVG Validation Loss:0.680 AVG Training Acc 62.27 % AVG Validation Acc 62.22 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.647 AVG Validation Loss:0.680 AVG Training Acc 62.04 % AVG Validation Acc 62.31 %\n",
      "Epoch:160/200 AVG Training Loss:0.647 AVG Validation Loss:0.680 AVG Training Acc 62.36 % AVG Validation Acc 62.22 %\n",
      "Epoch:170/200 AVG Training Loss:0.647 AVG Validation Loss:0.680 AVG Training Acc 62.19 % AVG Validation Acc 62.22 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.647 AVG Validation Loss:0.680 AVG Training Acc 62.08 % AVG Validation Acc 62.22 %\n",
      "Epoch:190/200 AVG Training Loss:0.646 AVG Validation Loss:0.680 AVG Training Acc 62.31 % AVG Validation Acc 62.22 %\n",
      "Epoch:200/200 AVG Training Loss:0.646 AVG Validation Loss:0.680 AVG Training Acc 62.28 % AVG Validation Acc 62.22 %\n",
      "Split 25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d5c7223dbb478499b43f8a6639ea86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.662 AVG Validation Loss:0.656 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.656 AVG Training Acc 61.86 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.657 AVG Training Acc 61.82 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.661 AVG Validation Loss:0.656 AVG Training Acc 61.63 % AVG Validation Acc 61.86 %\n",
      "Epoch:50/200 AVG Training Loss:0.653 AVG Validation Loss:0.654 AVG Training Acc 62.02 % AVG Validation Acc 61.86 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.648 AVG Validation Loss:0.658 AVG Training Acc 62.23 % AVG Validation Acc 61.59 %\n",
      "Epoch:70/200 AVG Training Loss:0.640 AVG Validation Loss:0.661 AVG Training Acc 62.31 % AVG Validation Acc 61.41 %\n",
      "Epoch:80/200 AVG Training Loss:0.633 AVG Validation Loss:0.661 AVG Training Acc 62.16 % AVG Validation Acc 61.59 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.628 AVG Validation Loss:0.665 AVG Training Acc 62.95 % AVG Validation Acc 61.50 %\n",
      "Epoch:100/200 AVG Training Loss:0.626 AVG Validation Loss:0.667 AVG Training Acc 62.92 % AVG Validation Acc 61.32 %\n",
      "Epoch:110/200 AVG Training Loss:0.628 AVG Validation Loss:0.664 AVG Training Acc 62.60 % AVG Validation Acc 61.59 %\n",
      "Epoch:120/200 AVG Training Loss:0.627 AVG Validation Loss:0.666 AVG Training Acc 63.21 % AVG Validation Acc 61.77 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.625 AVG Validation Loss:0.665 AVG Training Acc 63.33 % AVG Validation Acc 61.32 %\n",
      "Epoch:140/200 AVG Training Loss:0.625 AVG Validation Loss:0.665 AVG Training Acc 63.25 % AVG Validation Acc 61.32 %\n",
      "Epoch:150/200 AVG Training Loss:0.625 AVG Validation Loss:0.670 AVG Training Acc 63.12 % AVG Validation Acc 61.23 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.626 AVG Validation Loss:0.666 AVG Training Acc 62.77 % AVG Validation Acc 61.68 %\n",
      "Epoch:170/200 AVG Training Loss:0.626 AVG Validation Loss:0.666 AVG Training Acc 62.98 % AVG Validation Acc 61.95 %\n",
      "Epoch:180/200 AVG Training Loss:0.625 AVG Validation Loss:0.667 AVG Training Acc 63.28 % AVG Validation Acc 61.59 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.627 AVG Validation Loss:0.664 AVG Training Acc 62.98 % AVG Validation Acc 61.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.625 AVG Validation Loss:0.666 AVG Training Acc 63.46 % AVG Validation Acc 61.14 %\n",
      "Split 26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4614bb9b64a2482497d2804b83f3e17a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.658 AVG Training Acc 61.85 % AVG Validation Acc 61.91 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.656 AVG Training Acc 61.93 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.658 AVG Training Acc 62.08 % AVG Validation Acc 61.37 %\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.660 AVG Training Acc 61.98 % AVG Validation Acc 61.64 %\n",
      "Epoch:50/200 AVG Training Loss:0.650 AVG Validation Loss:0.661 AVG Training Acc 62.00 % AVG Validation Acc 61.64 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.649 AVG Validation Loss:0.663 AVG Training Acc 62.42 % AVG Validation Acc 61.55 %\n",
      "Epoch:70/200 AVG Training Loss:0.648 AVG Validation Loss:0.666 AVG Training Acc 62.15 % AVG Validation Acc 61.64 %\n",
      "Epoch:80/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 62.10 % AVG Validation Acc 61.64 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 62.14 % AVG Validation Acc 61.64 %\n",
      "Epoch:100/200 AVG Training Loss:0.648 AVG Validation Loss:0.667 AVG Training Acc 61.85 % AVG Validation Acc 61.91 %\n",
      "Epoch:110/200 AVG Training Loss:0.647 AVG Validation Loss:0.668 AVG Training Acc 62.20 % AVG Validation Acc 61.73 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.647 AVG Validation Loss:0.668 AVG Training Acc 62.28 % AVG Validation Acc 61.82 %\n",
      "Epoch:130/200 AVG Training Loss:0.648 AVG Validation Loss:0.668 AVG Training Acc 62.28 % AVG Validation Acc 61.73 %\n",
      "Epoch:140/200 AVG Training Loss:0.646 AVG Validation Loss:0.668 AVG Training Acc 62.39 % AVG Validation Acc 61.64 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.647 AVG Validation Loss:0.668 AVG Training Acc 62.17 % AVG Validation Acc 61.73 %\n",
      "Epoch:160/200 AVG Training Loss:0.647 AVG Validation Loss:0.668 AVG Training Acc 62.25 % AVG Validation Acc 61.64 %\n",
      "Epoch:170/200 AVG Training Loss:0.646 AVG Validation Loss:0.668 AVG Training Acc 62.32 % AVG Validation Acc 61.55 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.647 AVG Validation Loss:0.668 AVG Training Acc 62.13 % AVG Validation Acc 61.64 %\n",
      "Epoch:190/200 AVG Training Loss:0.647 AVG Validation Loss:0.668 AVG Training Acc 62.32 % AVG Validation Acc 61.64 %\n",
      "Epoch:200/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 61.98 % AVG Validation Acc 61.82 %\n",
      "Split 27\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8571c8ee3b241fb9d48353c2bf6fb05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.659 AVG Training Acc 61.93 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.659 AVG Training Acc 62.03 % AVG Validation Acc 61.82 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.658 AVG Training Acc 61.85 % AVG Validation Acc 61.73 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.657 AVG Training Acc 62.01 % AVG Validation Acc 61.82 %\n",
      "Epoch:50/200 AVG Training Loss:0.649 AVG Validation Loss:0.655 AVG Training Acc 62.41 % AVG Validation Acc 62.09 %\n",
      "Epoch:60/200 AVG Training Loss:0.645 AVG Validation Loss:0.659 AVG Training Acc 62.56 % AVG Validation Acc 61.64 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.642 AVG Validation Loss:0.659 AVG Training Acc 62.97 % AVG Validation Acc 62.27 %\n",
      "Epoch:80/200 AVG Training Loss:0.641 AVG Validation Loss:0.660 AVG Training Acc 62.70 % AVG Validation Acc 61.37 %\n",
      "Epoch:90/200 AVG Training Loss:0.641 AVG Validation Loss:0.662 AVG Training Acc 62.97 % AVG Validation Acc 61.19 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.639 AVG Validation Loss:0.662 AVG Training Acc 63.14 % AVG Validation Acc 61.91 %\n",
      "Epoch:110/200 AVG Training Loss:0.639 AVG Validation Loss:0.662 AVG Training Acc 62.65 % AVG Validation Acc 61.73 %\n",
      "Epoch:120/200 AVG Training Loss:0.640 AVG Validation Loss:0.661 AVG Training Acc 63.23 % AVG Validation Acc 62.09 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.641 AVG Validation Loss:0.661 AVG Training Acc 62.62 % AVG Validation Acc 61.91 %\n",
      "New Best Accuracy found: 63.00%\n",
      "Epoch: 138\n",
      "Epoch:140/200 AVG Training Loss:0.640 AVG Validation Loss:0.662 AVG Training Acc 63.34 % AVG Validation Acc 62.09 %\n",
      "Epoch:150/200 AVG Training Loss:0.639 AVG Validation Loss:0.660 AVG Training Acc 63.28 % AVG Validation Acc 62.18 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.639 AVG Validation Loss:0.662 AVG Training Acc 62.91 % AVG Validation Acc 62.55 %\n",
      "Epoch:170/200 AVG Training Loss:0.639 AVG Validation Loss:0.660 AVG Training Acc 63.15 % AVG Validation Acc 62.36 %\n",
      "New Best Accuracy found: 63.09%\n",
      "Epoch: 178\n",
      "Epoch:180/200 AVG Training Loss:0.640 AVG Validation Loss:0.658 AVG Training Acc 63.24 % AVG Validation Acc 62.55 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.640 AVG Validation Loss:0.661 AVG Training Acc 63.01 % AVG Validation Acc 62.00 %\n",
      "Epoch:200/200 AVG Training Loss:0.642 AVG Validation Loss:0.661 AVG Training Acc 62.90 % AVG Validation Acc 62.36 %\n",
      "Split 28\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99d5916b6a7b479aa1102e587c8f33c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.655 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.654 AVG Training Acc 61.90 % AVG Validation Acc 61.82 %\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.660 AVG Training Acc 61.81 % AVG Validation Acc 61.64 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.665 AVG Training Acc 61.89 % AVG Validation Acc 61.73 %\n",
      "Epoch:50/200 AVG Training Loss:0.646 AVG Validation Loss:0.671 AVG Training Acc 62.16 % AVG Validation Acc 61.55 %\n",
      "Epoch:60/200 AVG Training Loss:0.643 AVG Validation Loss:0.681 AVG Training Acc 62.11 % AVG Validation Acc 61.01 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.639 AVG Validation Loss:0.692 AVG Training Acc 62.46 % AVG Validation Acc 61.10 %\n",
      "Epoch:80/200 AVG Training Loss:0.637 AVG Validation Loss:0.695 AVG Training Acc 62.43 % AVG Validation Acc 61.10 %\n",
      "Epoch:90/200 AVG Training Loss:0.638 AVG Validation Loss:0.698 AVG Training Acc 62.40 % AVG Validation Acc 61.19 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.636 AVG Validation Loss:0.697 AVG Training Acc 62.59 % AVG Validation Acc 61.10 %\n",
      "Epoch:110/200 AVG Training Loss:0.637 AVG Validation Loss:0.698 AVG Training Acc 62.67 % AVG Validation Acc 61.10 %\n",
      "Epoch:120/200 AVG Training Loss:0.637 AVG Validation Loss:0.700 AVG Training Acc 62.62 % AVG Validation Acc 61.19 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.638 AVG Validation Loss:0.697 AVG Training Acc 62.44 % AVG Validation Acc 61.01 %\n",
      "Epoch:140/200 AVG Training Loss:0.637 AVG Validation Loss:0.696 AVG Training Acc 62.33 % AVG Validation Acc 61.10 %\n",
      "Epoch:150/200 AVG Training Loss:0.635 AVG Validation Loss:0.699 AVG Training Acc 62.83 % AVG Validation Acc 60.92 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.637 AVG Validation Loss:0.696 AVG Training Acc 62.56 % AVG Validation Acc 61.28 %\n",
      "Epoch:170/200 AVG Training Loss:0.638 AVG Validation Loss:0.696 AVG Training Acc 62.62 % AVG Validation Acc 61.10 %\n",
      "Epoch:180/200 AVG Training Loss:0.636 AVG Validation Loss:0.699 AVG Training Acc 62.56 % AVG Validation Acc 61.01 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.636 AVG Validation Loss:0.697 AVG Training Acc 62.80 % AVG Validation Acc 61.10 %\n",
      "Epoch:200/200 AVG Training Loss:0.636 AVG Validation Loss:0.698 AVG Training Acc 62.54 % AVG Validation Acc 61.10 %\n",
      "Split 29\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28904bad901d414db85571a2fe8b106f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.659 AVG Training Acc 61.86 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.656 AVG Training Acc 61.94 % AVG Validation Acc 62.00 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.655 AVG Training Acc 61.95 % AVG Validation Acc 61.91 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.665 AVG Training Acc 61.91 % AVG Validation Acc 61.46 %\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.647 AVG Validation Loss:0.665 AVG Training Acc 62.27 % AVG Validation Acc 61.55 %\n",
      "Epoch:60/200 AVG Training Loss:0.645 AVG Validation Loss:0.673 AVG Training Acc 62.19 % AVG Validation Acc 62.09 %\n",
      "Epoch:70/200 AVG Training Loss:0.641 AVG Validation Loss:0.680 AVG Training Acc 62.40 % AVG Validation Acc 61.37 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.639 AVG Validation Loss:0.684 AVG Training Acc 62.58 % AVG Validation Acc 61.64 %\n",
      "Epoch:90/200 AVG Training Loss:0.641 AVG Validation Loss:0.687 AVG Training Acc 62.53 % AVG Validation Acc 61.55 %\n",
      "Epoch:100/200 AVG Training Loss:0.640 AVG Validation Loss:0.690 AVG Training Acc 62.68 % AVG Validation Acc 61.64 %\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.640 AVG Validation Loss:0.697 AVG Training Acc 62.63 % AVG Validation Acc 61.55 %\n",
      "Epoch:120/200 AVG Training Loss:0.638 AVG Validation Loss:0.696 AVG Training Acc 62.70 % AVG Validation Acc 61.82 %\n",
      "Epoch:130/200 AVG Training Loss:0.639 AVG Validation Loss:0.692 AVG Training Acc 62.48 % AVG Validation Acc 61.91 %\n",
      "Epoch   134: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.639 AVG Validation Loss:0.686 AVG Training Acc 62.57 % AVG Validation Acc 61.91 %\n",
      "Epoch:150/200 AVG Training Loss:0.638 AVG Validation Loss:0.690 AVG Training Acc 62.97 % AVG Validation Acc 61.64 %\n",
      "Epoch:160/200 AVG Training Loss:0.638 AVG Validation Loss:0.700 AVG Training Acc 62.64 % AVG Validation Acc 61.91 %\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.639 AVG Validation Loss:0.690 AVG Training Acc 62.59 % AVG Validation Acc 61.82 %\n",
      "Epoch:180/200 AVG Training Loss:0.637 AVG Validation Loss:0.684 AVG Training Acc 62.95 % AVG Validation Acc 61.91 %\n",
      "Epoch:190/200 AVG Training Loss:0.639 AVG Validation Loss:0.692 AVG Training Acc 62.85 % AVG Validation Acc 61.64 %\n",
      "Epoch   196: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.638 AVG Validation Loss:0.686 AVG Training Acc 62.77 % AVG Validation Acc 61.64 %\n",
      "Split 30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdd053e2ca7a4af2a31318f727e9dd70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.665 AVG Training Acc 61.85 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.666 AVG Training Acc 61.62 % AVG Validation Acc 61.82 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.650 AVG Validation Loss:0.672 AVG Training Acc 62.03 % AVG Validation Acc 61.82 %\n",
      "Epoch:40/200 AVG Training Loss:0.643 AVG Validation Loss:0.679 AVG Training Acc 62.23 % AVG Validation Acc 62.18 %\n",
      "Epoch:50/200 AVG Training Loss:0.639 AVG Validation Loss:0.683 AVG Training Acc 62.38 % AVG Validation Acc 61.64 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.632 AVG Validation Loss:0.688 AVG Training Acc 62.82 % AVG Validation Acc 61.73 %\n",
      "Epoch:70/200 AVG Training Loss:0.632 AVG Validation Loss:0.690 AVG Training Acc 63.39 % AVG Validation Acc 61.55 %\n",
      "Epoch:80/200 AVG Training Loss:0.632 AVG Validation Loss:0.692 AVG Training Acc 63.02 % AVG Validation Acc 61.64 %\n",
      "Epoch:90/200 AVG Training Loss:0.631 AVG Validation Loss:0.695 AVG Training Acc 62.84 % AVG Validation Acc 61.55 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.631 AVG Validation Loss:0.692 AVG Training Acc 63.00 % AVG Validation Acc 61.73 %\n",
      "Epoch:110/200 AVG Training Loss:0.631 AVG Validation Loss:0.693 AVG Training Acc 62.99 % AVG Validation Acc 61.82 %\n",
      "Epoch:120/200 AVG Training Loss:0.630 AVG Validation Loss:0.696 AVG Training Acc 63.36 % AVG Validation Acc 61.73 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.630 AVG Validation Loss:0.694 AVG Training Acc 62.82 % AVG Validation Acc 61.73 %\n",
      "Epoch:140/200 AVG Training Loss:0.630 AVG Validation Loss:0.692 AVG Training Acc 62.87 % AVG Validation Acc 61.73 %\n",
      "Epoch:150/200 AVG Training Loss:0.630 AVG Validation Loss:0.694 AVG Training Acc 63.30 % AVG Validation Acc 61.55 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.629 AVG Validation Loss:0.695 AVG Training Acc 63.40 % AVG Validation Acc 61.82 %\n",
      "Epoch:170/200 AVG Training Loss:0.629 AVG Validation Loss:0.693 AVG Training Acc 63.26 % AVG Validation Acc 61.46 %\n",
      "Epoch:180/200 AVG Training Loss:0.630 AVG Validation Loss:0.695 AVG Training Acc 63.28 % AVG Validation Acc 61.46 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.629 AVG Validation Loss:0.695 AVG Training Acc 63.12 % AVG Validation Acc 61.73 %\n",
      "Epoch:200/200 AVG Training Loss:0.628 AVG Validation Loss:0.695 AVG Training Acc 63.37 % AVG Validation Acc 61.55 %\n",
      "Split 31\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f376c38b23d943fa8598a0d38e4e87d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.663 AVG Training Acc 61.88 % AVG Validation Acc 61.95 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.656 AVG Validation Loss:0.663 AVG Training Acc 61.92 % AVG Validation Acc 61.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.663 AVG Training Acc 61.93 % AVG Validation Acc 61.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.655 AVG Validation Loss:0.662 AVG Training Acc 61.96 % AVG Validation Acc 62.04 %\n",
      "Epoch:50/200 AVG Training Loss:0.654 AVG Validation Loss:0.662 AVG Training Acc 61.96 % AVG Validation Acc 61.86 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.651 AVG Validation Loss:0.662 AVG Training Acc 62.03 % AVG Validation Acc 61.86 %\n",
      "Epoch:70/200 AVG Training Loss:0.650 AVG Validation Loss:0.662 AVG Training Acc 62.18 % AVG Validation Acc 61.86 %\n",
      "Epoch:80/200 AVG Training Loss:0.650 AVG Validation Loss:0.663 AVG Training Acc 62.03 % AVG Validation Acc 61.86 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.651 AVG Validation Loss:0.663 AVG Training Acc 62.23 % AVG Validation Acc 61.86 %\n",
      "Epoch:100/200 AVG Training Loss:0.649 AVG Validation Loss:0.663 AVG Training Acc 62.26 % AVG Validation Acc 61.86 %\n",
      "Epoch:110/200 AVG Training Loss:0.650 AVG Validation Loss:0.663 AVG Training Acc 62.19 % AVG Validation Acc 61.86 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.650 AVG Validation Loss:0.663 AVG Training Acc 62.10 % AVG Validation Acc 61.86 %\n",
      "Epoch:130/200 AVG Training Loss:0.650 AVG Validation Loss:0.663 AVG Training Acc 62.17 % AVG Validation Acc 61.77 %\n",
      "Epoch:140/200 AVG Training Loss:0.650 AVG Validation Loss:0.662 AVG Training Acc 62.04 % AVG Validation Acc 61.77 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.650 AVG Validation Loss:0.662 AVG Training Acc 61.96 % AVG Validation Acc 61.86 %\n",
      "Epoch:160/200 AVG Training Loss:0.650 AVG Validation Loss:0.662 AVG Training Acc 62.10 % AVG Validation Acc 61.86 %\n",
      "Epoch:170/200 AVG Training Loss:0.650 AVG Validation Loss:0.663 AVG Training Acc 62.07 % AVG Validation Acc 61.86 %\n",
      "Epoch:180/200 AVG Training Loss:0.651 AVG Validation Loss:0.663 AVG Training Acc 62.01 % AVG Validation Acc 61.86 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.650 AVG Validation Loss:0.663 AVG Training Acc 62.20 % AVG Validation Acc 61.86 %\n",
      "Epoch:200/200 AVG Training Loss:0.651 AVG Validation Loss:0.663 AVG Training Acc 61.93 % AVG Validation Acc 61.86 %\n",
      "Split 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1079b9adad9452a98f38beb3975bcb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.656 AVG Training Acc 61.88 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.654 AVG Training Acc 61.70 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.654 AVG Training Acc 61.84 % AVG Validation Acc 61.86 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.649 AVG Validation Loss:0.656 AVG Training Acc 62.08 % AVG Validation Acc 61.41 %\n",
      "Epoch:50/200 AVG Training Loss:0.646 AVG Validation Loss:0.663 AVG Training Acc 62.50 % AVG Validation Acc 61.41 %\n",
      "Epoch:60/200 AVG Training Loss:0.641 AVG Validation Loss:0.673 AVG Training Acc 62.72 % AVG Validation Acc 60.05 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.638 AVG Validation Loss:0.676 AVG Training Acc 62.90 % AVG Validation Acc 59.69 %\n",
      "Epoch:80/200 AVG Training Loss:0.639 AVG Validation Loss:0.679 AVG Training Acc 62.82 % AVG Validation Acc 59.69 %\n",
      "Epoch:90/200 AVG Training Loss:0.638 AVG Validation Loss:0.680 AVG Training Acc 62.82 % AVG Validation Acc 60.05 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.636 AVG Validation Loss:0.680 AVG Training Acc 62.82 % AVG Validation Acc 59.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.636 AVG Validation Loss:0.676 AVG Training Acc 62.85 % AVG Validation Acc 60.14 %\n",
      "Epoch:120/200 AVG Training Loss:0.637 AVG Validation Loss:0.680 AVG Training Acc 62.61 % AVG Validation Acc 59.69 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.637 AVG Validation Loss:0.683 AVG Training Acc 63.18 % AVG Validation Acc 59.69 %\n",
      "Epoch:140/200 AVG Training Loss:0.636 AVG Validation Loss:0.678 AVG Training Acc 62.99 % AVG Validation Acc 59.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.637 AVG Validation Loss:0.681 AVG Training Acc 62.80 % AVG Validation Acc 59.69 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.637 AVG Validation Loss:0.680 AVG Training Acc 62.84 % AVG Validation Acc 59.96 %\n",
      "Epoch:170/200 AVG Training Loss:0.636 AVG Validation Loss:0.676 AVG Training Acc 62.64 % AVG Validation Acc 59.87 %\n",
      "Epoch:180/200 AVG Training Loss:0.636 AVG Validation Loss:0.680 AVG Training Acc 62.85 % AVG Validation Acc 60.05 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.638 AVG Validation Loss:0.678 AVG Training Acc 62.85 % AVG Validation Acc 59.96 %\n",
      "Epoch:200/200 AVG Training Loss:0.636 AVG Validation Loss:0.681 AVG Training Acc 62.96 % AVG Validation Acc 59.87 %\n",
      "Split 33\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63fcf259d9b244839bce39926461e497",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.662 AVG Training Acc 61.86 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.662 AVG Training Acc 61.93 % AVG Validation Acc 61.86 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.662 AVG Training Acc 62.00 % AVG Validation Acc 61.77 %\n",
      "Epoch:40/200 AVG Training Loss:0.655 AVG Validation Loss:0.662 AVG Training Acc 61.96 % AVG Validation Acc 61.77 %\n",
      "Epoch:50/200 AVG Training Loss:0.653 AVG Validation Loss:0.663 AVG Training Acc 62.10 % AVG Validation Acc 61.77 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.653 AVG Validation Loss:0.663 AVG Training Acc 62.08 % AVG Validation Acc 61.77 %\n",
      "Epoch:70/200 AVG Training Loss:0.652 AVG Validation Loss:0.663 AVG Training Acc 62.03 % AVG Validation Acc 61.86 %\n",
      "Epoch:80/200 AVG Training Loss:0.651 AVG Validation Loss:0.663 AVG Training Acc 62.12 % AVG Validation Acc 61.95 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.651 AVG Validation Loss:0.664 AVG Training Acc 62.08 % AVG Validation Acc 61.95 %\n",
      "Epoch:100/200 AVG Training Loss:0.651 AVG Validation Loss:0.664 AVG Training Acc 62.06 % AVG Validation Acc 61.95 %\n",
      "Epoch:110/200 AVG Training Loss:0.651 AVG Validation Loss:0.663 AVG Training Acc 62.10 % AVG Validation Acc 61.95 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.651 AVG Validation Loss:0.664 AVG Training Acc 62.06 % AVG Validation Acc 61.95 %\n",
      "Epoch:130/200 AVG Training Loss:0.650 AVG Validation Loss:0.664 AVG Training Acc 62.11 % AVG Validation Acc 61.95 %\n",
      "Epoch:140/200 AVG Training Loss:0.651 AVG Validation Loss:0.663 AVG Training Acc 62.06 % AVG Validation Acc 61.95 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.651 AVG Validation Loss:0.663 AVG Training Acc 62.13 % AVG Validation Acc 61.95 %\n",
      "Epoch:160/200 AVG Training Loss:0.651 AVG Validation Loss:0.664 AVG Training Acc 62.00 % AVG Validation Acc 61.95 %\n",
      "Epoch:170/200 AVG Training Loss:0.651 AVG Validation Loss:0.664 AVG Training Acc 62.03 % AVG Validation Acc 61.95 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.651 AVG Validation Loss:0.664 AVG Training Acc 62.01 % AVG Validation Acc 61.95 %\n",
      "Epoch:190/200 AVG Training Loss:0.651 AVG Validation Loss:0.664 AVG Training Acc 62.04 % AVG Validation Acc 61.95 %\n",
      "Epoch:200/200 AVG Training Loss:0.651 AVG Validation Loss:0.663 AVG Training Acc 62.01 % AVG Validation Acc 61.95 %\n",
      "Split 34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18392c57675044119013b04d9a0a9035",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.659 AVG Training Acc 61.87 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.662 AVG Training Acc 61.94 % AVG Validation Acc 61.86 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.666 AVG Training Acc 61.96 % AVG Validation Acc 61.59 %\n",
      "Epoch:40/200 AVG Training Loss:0.648 AVG Validation Loss:0.675 AVG Training Acc 62.09 % AVG Validation Acc 61.59 %\n",
      "Epoch:50/200 AVG Training Loss:0.642 AVG Validation Loss:0.685 AVG Training Acc 62.31 % AVG Validation Acc 61.32 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.638 AVG Validation Loss:0.690 AVG Training Acc 62.33 % AVG Validation Acc 61.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.638 AVG Validation Loss:0.692 AVG Training Acc 62.38 % AVG Validation Acc 60.78 %\n",
      "Epoch:80/200 AVG Training Loss:0.638 AVG Validation Loss:0.694 AVG Training Acc 62.37 % AVG Validation Acc 60.87 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.636 AVG Validation Loss:0.693 AVG Training Acc 62.46 % AVG Validation Acc 60.69 %\n",
      "Epoch:100/200 AVG Training Loss:0.638 AVG Validation Loss:0.696 AVG Training Acc 62.39 % AVG Validation Acc 60.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.634 AVG Validation Loss:0.694 AVG Training Acc 62.69 % AVG Validation Acc 60.78 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.635 AVG Validation Loss:0.696 AVG Training Acc 62.70 % AVG Validation Acc 60.60 %\n",
      "Epoch:130/200 AVG Training Loss:0.637 AVG Validation Loss:0.694 AVG Training Acc 62.42 % AVG Validation Acc 60.50 %\n",
      "Epoch:140/200 AVG Training Loss:0.637 AVG Validation Loss:0.695 AVG Training Acc 62.70 % AVG Validation Acc 60.50 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.635 AVG Validation Loss:0.697 AVG Training Acc 62.71 % AVG Validation Acc 60.60 %\n",
      "Epoch:160/200 AVG Training Loss:0.637 AVG Validation Loss:0.695 AVG Training Acc 62.64 % AVG Validation Acc 60.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.636 AVG Validation Loss:0.694 AVG Training Acc 62.63 % AVG Validation Acc 60.60 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.636 AVG Validation Loss:0.697 AVG Training Acc 62.50 % AVG Validation Acc 60.60 %\n",
      "Epoch:190/200 AVG Training Loss:0.637 AVG Validation Loss:0.694 AVG Training Acc 62.58 % AVG Validation Acc 60.78 %\n",
      "Epoch:200/200 AVG Training Loss:0.635 AVG Validation Loss:0.696 AVG Training Acc 62.59 % AVG Validation Acc 60.50 %\n",
      "Split 35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104d99ecb114422991ce4befacee349e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.663 AVG Training Acc 61.78 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.661 AVG Training Acc 61.88 % AVG Validation Acc 61.77 %\n",
      "Epoch:30/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.661 AVG Training Acc 61.95 % AVG Validation Acc 61.77 %\n",
      "Epoch:50/200 AVG Training Loss:0.652 AVG Validation Loss:0.663 AVG Training Acc 62.21 % AVG Validation Acc 61.68 %\n",
      "Epoch:60/200 AVG Training Loss:0.651 AVG Validation Loss:0.667 AVG Training Acc 62.08 % AVG Validation Acc 61.68 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.650 AVG Validation Loss:0.667 AVG Training Acc 62.13 % AVG Validation Acc 61.41 %\n",
      "Epoch:80/200 AVG Training Loss:0.650 AVG Validation Loss:0.667 AVG Training Acc 62.28 % AVG Validation Acc 61.68 %\n",
      "Epoch:90/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 62.19 % AVG Validation Acc 61.32 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.648 AVG Validation Loss:0.668 AVG Training Acc 62.20 % AVG Validation Acc 61.59 %\n",
      "Epoch:110/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 62.15 % AVG Validation Acc 61.32 %\n",
      "Epoch:120/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 62.29 % AVG Validation Acc 61.59 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 62.13 % AVG Validation Acc 61.41 %\n",
      "Epoch:140/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 62.20 % AVG Validation Acc 61.59 %\n",
      "Epoch:150/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 62.26 % AVG Validation Acc 61.50 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 62.16 % AVG Validation Acc 61.68 %\n",
      "Epoch:170/200 AVG Training Loss:0.650 AVG Validation Loss:0.668 AVG Training Acc 62.18 % AVG Validation Acc 61.59 %\n",
      "Epoch:180/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 62.33 % AVG Validation Acc 61.59 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 62.19 % AVG Validation Acc 61.68 %\n",
      "Epoch:200/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 62.23 % AVG Validation Acc 61.68 %\n",
      "Split 36\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f58769cdda91493c85eef73452aeeec5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.652 AVG Training Acc 61.87 % AVG Validation Acc 61.91 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.652 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.652 AVG Training Acc 61.98 % AVG Validation Acc 61.82 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.654 AVG Training Acc 62.03 % AVG Validation Acc 61.64 %\n",
      "Epoch:50/200 AVG Training Loss:0.650 AVG Validation Loss:0.655 AVG Training Acc 61.91 % AVG Validation Acc 61.64 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.649 AVG Validation Loss:0.655 AVG Training Acc 62.19 % AVG Validation Acc 61.64 %\n",
      "Epoch:70/200 AVG Training Loss:0.648 AVG Validation Loss:0.655 AVG Training Acc 62.04 % AVG Validation Acc 61.55 %\n",
      "Epoch:80/200 AVG Training Loss:0.649 AVG Validation Loss:0.654 AVG Training Acc 62.17 % AVG Validation Acc 61.64 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.648 AVG Validation Loss:0.654 AVG Training Acc 62.14 % AVG Validation Acc 61.64 %\n",
      "Epoch:100/200 AVG Training Loss:0.648 AVG Validation Loss:0.654 AVG Training Acc 62.12 % AVG Validation Acc 61.64 %\n",
      "Epoch:110/200 AVG Training Loss:0.647 AVG Validation Loss:0.655 AVG Training Acc 62.23 % AVG Validation Acc 61.64 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.648 AVG Validation Loss:0.655 AVG Training Acc 62.08 % AVG Validation Acc 61.64 %\n",
      "Epoch:130/200 AVG Training Loss:0.647 AVG Validation Loss:0.655 AVG Training Acc 62.17 % AVG Validation Acc 61.64 %\n",
      "Epoch:140/200 AVG Training Loss:0.647 AVG Validation Loss:0.655 AVG Training Acc 62.18 % AVG Validation Acc 61.64 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.647 AVG Validation Loss:0.655 AVG Training Acc 62.09 % AVG Validation Acc 61.64 %\n",
      "Epoch:160/200 AVG Training Loss:0.648 AVG Validation Loss:0.655 AVG Training Acc 62.14 % AVG Validation Acc 61.64 %\n",
      "Epoch:170/200 AVG Training Loss:0.648 AVG Validation Loss:0.654 AVG Training Acc 62.14 % AVG Validation Acc 61.64 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.647 AVG Validation Loss:0.655 AVG Training Acc 62.19 % AVG Validation Acc 61.64 %\n",
      "Epoch:190/200 AVG Training Loss:0.648 AVG Validation Loss:0.655 AVG Training Acc 62.18 % AVG Validation Acc 61.64 %\n",
      "Epoch:200/200 AVG Training Loss:0.647 AVG Validation Loss:0.654 AVG Training Acc 62.14 % AVG Validation Acc 61.64 %\n",
      "Split 37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d750c02203fb4cc4b3e3b752ef48762d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.668 AVG Training Acc 61.84 % AVG Validation Acc 61.91 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.656 AVG Validation Loss:0.665 AVG Training Acc 61.76 % AVG Validation Acc 62.00 %\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.666 AVG Training Acc 61.78 % AVG Validation Acc 62.09 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.668 AVG Training Acc 61.71 % AVG Validation Acc 62.09 %\n",
      "Epoch:50/200 AVG Training Loss:0.652 AVG Validation Loss:0.669 AVG Training Acc 61.72 % AVG Validation Acc 62.18 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.650 AVG Validation Loss:0.671 AVG Training Acc 62.03 % AVG Validation Acc 62.27 %\n",
      "Epoch:70/200 AVG Training Loss:0.651 AVG Validation Loss:0.671 AVG Training Acc 61.85 % AVG Validation Acc 62.18 %\n",
      "Epoch:80/200 AVG Training Loss:0.649 AVG Validation Loss:0.671 AVG Training Acc 62.19 % AVG Validation Acc 62.09 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.650 AVG Validation Loss:0.671 AVG Training Acc 61.96 % AVG Validation Acc 62.09 %\n",
      "Epoch:100/200 AVG Training Loss:0.649 AVG Validation Loss:0.672 AVG Training Acc 62.05 % AVG Validation Acc 62.00 %\n",
      "Epoch:110/200 AVG Training Loss:0.649 AVG Validation Loss:0.672 AVG Training Acc 62.05 % AVG Validation Acc 62.00 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.650 AVG Validation Loss:0.672 AVG Training Acc 61.92 % AVG Validation Acc 62.00 %\n",
      "Epoch:130/200 AVG Training Loss:0.650 AVG Validation Loss:0.672 AVG Training Acc 61.95 % AVG Validation Acc 61.91 %\n",
      "Epoch:140/200 AVG Training Loss:0.649 AVG Validation Loss:0.672 AVG Training Acc 62.13 % AVG Validation Acc 62.00 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.650 AVG Validation Loss:0.671 AVG Training Acc 61.84 % AVG Validation Acc 62.00 %\n",
      "Epoch:160/200 AVG Training Loss:0.649 AVG Validation Loss:0.672 AVG Training Acc 61.97 % AVG Validation Acc 62.00 %\n",
      "Epoch:170/200 AVG Training Loss:0.650 AVG Validation Loss:0.672 AVG Training Acc 62.06 % AVG Validation Acc 62.00 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.650 AVG Validation Loss:0.671 AVG Training Acc 61.90 % AVG Validation Acc 62.00 %\n",
      "Epoch:190/200 AVG Training Loss:0.650 AVG Validation Loss:0.671 AVG Training Acc 61.98 % AVG Validation Acc 62.09 %\n",
      "Epoch:200/200 AVG Training Loss:0.650 AVG Validation Loss:0.671 AVG Training Acc 61.93 % AVG Validation Acc 62.00 %\n",
      "Split 38\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ee0daf6771c4c99992e3f9d6a0ea118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.659 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.661 AVG Training Acc 61.84 % AVG Validation Acc 61.91 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.661 AVG Training Acc 62.00 % AVG Validation Acc 62.00 %\n",
      "Epoch:40/200 AVG Training Loss:0.650 AVG Validation Loss:0.666 AVG Training Acc 62.09 % AVG Validation Acc 62.09 %\n",
      "Epoch:50/200 AVG Training Loss:0.644 AVG Validation Loss:0.668 AVG Training Acc 62.35 % AVG Validation Acc 61.73 %\n",
      "Epoch:60/200 AVG Training Loss:0.642 AVG Validation Loss:0.666 AVG Training Acc 62.39 % AVG Validation Acc 61.73 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.640 AVG Validation Loss:0.668 AVG Training Acc 62.60 % AVG Validation Acc 61.19 %\n",
      "Epoch:80/200 AVG Training Loss:0.638 AVG Validation Loss:0.665 AVG Training Acc 62.74 % AVG Validation Acc 61.28 %\n",
      "Epoch:90/200 AVG Training Loss:0.639 AVG Validation Loss:0.665 AVG Training Acc 62.80 % AVG Validation Acc 61.19 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.638 AVG Validation Loss:0.665 AVG Training Acc 62.94 % AVG Validation Acc 61.37 %\n",
      "Epoch:110/200 AVG Training Loss:0.638 AVG Validation Loss:0.665 AVG Training Acc 63.00 % AVG Validation Acc 61.37 %\n",
      "Epoch:120/200 AVG Training Loss:0.639 AVG Validation Loss:0.667 AVG Training Acc 62.78 % AVG Validation Acc 61.10 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.639 AVG Validation Loss:0.665 AVG Training Acc 62.79 % AVG Validation Acc 61.46 %\n",
      "Epoch:140/200 AVG Training Loss:0.638 AVG Validation Loss:0.666 AVG Training Acc 62.50 % AVG Validation Acc 61.37 %\n",
      "Epoch:150/200 AVG Training Loss:0.638 AVG Validation Loss:0.667 AVG Training Acc 62.46 % AVG Validation Acc 61.37 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.638 AVG Validation Loss:0.665 AVG Training Acc 62.47 % AVG Validation Acc 61.28 %\n",
      "Epoch:170/200 AVG Training Loss:0.638 AVG Validation Loss:0.666 AVG Training Acc 62.71 % AVG Validation Acc 61.10 %\n",
      "Epoch:180/200 AVG Training Loss:0.639 AVG Validation Loss:0.666 AVG Training Acc 62.90 % AVG Validation Acc 61.37 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.638 AVG Validation Loss:0.665 AVG Training Acc 62.81 % AVG Validation Acc 61.55 %\n",
      "Epoch:200/200 AVG Training Loss:0.638 AVG Validation Loss:0.667 AVG Training Acc 62.59 % AVG Validation Acc 61.37 %\n",
      "Split 39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b44c331663d4c06b6a5d65637f405e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.657 AVG Training Acc 61.77 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.663 AVG Training Acc 61.79 % AVG Validation Acc 61.91 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.659 AVG Training Acc 61.96 % AVG Validation Acc 61.73 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.659 AVG Training Acc 62.10 % AVG Validation Acc 61.64 %\n",
      "Epoch:50/200 AVG Training Loss:0.650 AVG Validation Loss:0.668 AVG Training Acc 62.04 % AVG Validation Acc 61.46 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.647 AVG Validation Loss:0.668 AVG Training Acc 62.23 % AVG Validation Acc 61.55 %\n",
      "Epoch:70/200 AVG Training Loss:0.647 AVG Validation Loss:0.670 AVG Training Acc 62.11 % AVG Validation Acc 61.46 %\n",
      "Epoch:80/200 AVG Training Loss:0.647 AVG Validation Loss:0.672 AVG Training Acc 62.18 % AVG Validation Acc 61.55 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.647 AVG Validation Loss:0.672 AVG Training Acc 62.13 % AVG Validation Acc 61.55 %\n",
      "Epoch:100/200 AVG Training Loss:0.645 AVG Validation Loss:0.672 AVG Training Acc 62.20 % AVG Validation Acc 61.55 %\n",
      "Epoch:110/200 AVG Training Loss:0.646 AVG Validation Loss:0.672 AVG Training Acc 62.21 % AVG Validation Acc 61.46 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.647 AVG Validation Loss:0.672 AVG Training Acc 62.00 % AVG Validation Acc 61.46 %\n",
      "Epoch:130/200 AVG Training Loss:0.646 AVG Validation Loss:0.672 AVG Training Acc 62.18 % AVG Validation Acc 61.55 %\n",
      "Epoch:140/200 AVG Training Loss:0.647 AVG Validation Loss:0.673 AVG Training Acc 62.25 % AVG Validation Acc 61.55 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.646 AVG Validation Loss:0.672 AVG Training Acc 62.23 % AVG Validation Acc 61.55 %\n",
      "Epoch:160/200 AVG Training Loss:0.646 AVG Validation Loss:0.672 AVG Training Acc 62.29 % AVG Validation Acc 61.55 %\n",
      "Epoch:170/200 AVG Training Loss:0.646 AVG Validation Loss:0.672 AVG Training Acc 62.15 % AVG Validation Acc 61.55 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.646 AVG Validation Loss:0.672 AVG Training Acc 62.25 % AVG Validation Acc 61.37 %\n",
      "Epoch:190/200 AVG Training Loss:0.645 AVG Validation Loss:0.672 AVG Training Acc 62.15 % AVG Validation Acc 61.55 %\n",
      "Epoch:200/200 AVG Training Loss:0.647 AVG Validation Loss:0.672 AVG Training Acc 62.14 % AVG Validation Acc 61.55 %\n",
      "Split 40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8630f36cf79d45418dca96806a817d24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.662 AVG Training Acc 61.81 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.661 AVG Training Acc 61.93 % AVG Validation Acc 61.82 %\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.660 AVG Training Acc 61.85 % AVG Validation Acc 62.00 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.658 AVG Training Acc 61.95 % AVG Validation Acc 61.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.647 AVG Validation Loss:0.662 AVG Training Acc 62.05 % AVG Validation Acc 61.91 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.637 AVG Validation Loss:0.666 AVG Training Acc 62.87 % AVG Validation Acc 62.27 %\n",
      "Epoch:70/200 AVG Training Loss:0.631 AVG Validation Loss:0.672 AVG Training Acc 63.22 % AVG Validation Acc 61.91 %\n",
      "Epoch:80/200 AVG Training Loss:0.629 AVG Validation Loss:0.676 AVG Training Acc 63.06 % AVG Validation Acc 62.00 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.626 AVG Validation Loss:0.677 AVG Training Acc 63.63 % AVG Validation Acc 62.64 %\n",
      "Epoch:100/200 AVG Training Loss:0.625 AVG Validation Loss:0.681 AVG Training Acc 63.79 % AVG Validation Acc 62.36 %\n",
      "Epoch:110/200 AVG Training Loss:0.624 AVG Validation Loss:0.681 AVG Training Acc 63.82 % AVG Validation Acc 62.64 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.625 AVG Validation Loss:0.680 AVG Training Acc 63.42 % AVG Validation Acc 62.55 %\n",
      "Epoch:130/200 AVG Training Loss:0.623 AVG Validation Loss:0.680 AVG Training Acc 63.66 % AVG Validation Acc 62.91 %\n",
      "Epoch:140/200 AVG Training Loss:0.623 AVG Validation Loss:0.680 AVG Training Acc 63.37 % AVG Validation Acc 62.82 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.624 AVG Validation Loss:0.682 AVG Training Acc 63.34 % AVG Validation Acc 62.64 %\n",
      "Epoch:160/200 AVG Training Loss:0.623 AVG Validation Loss:0.682 AVG Training Acc 63.83 % AVG Validation Acc 62.55 %\n",
      "Epoch:170/200 AVG Training Loss:0.623 AVG Validation Loss:0.683 AVG Training Acc 63.85 % AVG Validation Acc 62.64 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.623 AVG Validation Loss:0.683 AVG Training Acc 63.52 % AVG Validation Acc 62.64 %\n",
      "Epoch:190/200 AVG Training Loss:0.622 AVG Validation Loss:0.682 AVG Training Acc 63.58 % AVG Validation Acc 62.64 %\n",
      "Epoch:200/200 AVG Training Loss:0.626 AVG Validation Loss:0.682 AVG Training Acc 63.46 % AVG Validation Acc 62.64 %\n",
      "Split 41\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cbb58b6b09b4cce8888985283e2f624",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.664 AVG Training Acc 61.74 % AVG Validation Acc 61.95 %\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.656 AVG Validation Loss:0.663 AVG Training Acc 61.92 % AVG Validation Acc 62.04 %\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.662 AVG Training Acc 61.87 % AVG Validation Acc 62.13 %\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.665 AVG Training Acc 61.91 % AVG Validation Acc 62.04 %\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.05 % AVG Validation Acc 62.04 %\n",
      "Epoch:60/200 AVG Training Loss:0.649 AVG Validation Loss:0.665 AVG Training Acc 61.92 % AVG Validation Acc 62.04 %\n",
      "Epoch:70/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.01 % AVG Validation Acc 61.95 %\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.648 AVG Validation Loss:0.665 AVG Training Acc 61.94 % AVG Validation Acc 61.95 %\n",
      "Epoch:90/200 AVG Training Loss:0.648 AVG Validation Loss:0.665 AVG Training Acc 61.91 % AVG Validation Acc 61.95 %\n",
      "Epoch:100/200 AVG Training Loss:0.649 AVG Validation Loss:0.665 AVG Training Acc 62.04 % AVG Validation Acc 61.95 %\n",
      "Epoch   106: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.04 % AVG Validation Acc 61.95 %\n",
      "Epoch:120/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 61.91 % AVG Validation Acc 61.95 %\n",
      "Epoch:130/200 AVG Training Loss:0.649 AVG Validation Loss:0.665 AVG Training Acc 62.12 % AVG Validation Acc 61.95 %\n",
      "Epoch   137: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.648 AVG Validation Loss:0.665 AVG Training Acc 62.03 % AVG Validation Acc 61.95 %\n",
      "Epoch:150/200 AVG Training Loss:0.650 AVG Validation Loss:0.665 AVG Training Acc 61.94 % AVG Validation Acc 61.95 %\n",
      "Epoch:160/200 AVG Training Loss:0.649 AVG Validation Loss:0.665 AVG Training Acc 61.92 % AVG Validation Acc 61.95 %\n",
      "Epoch   168: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.650 AVG Validation Loss:0.664 AVG Training Acc 62.04 % AVG Validation Acc 61.95 %\n",
      "Epoch:180/200 AVG Training Loss:0.649 AVG Validation Loss:0.665 AVG Training Acc 62.02 % AVG Validation Acc 61.95 %\n",
      "Epoch:190/200 AVG Training Loss:0.647 AVG Validation Loss:0.665 AVG Training Acc 61.91 % AVG Validation Acc 61.95 %\n",
      "Epoch:200/200 AVG Training Loss:0.649 AVG Validation Loss:0.665 AVG Training Acc 62.20 % AVG Validation Acc 61.95 %\n",
      "Split 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36ec57a2ca8140ed9df1a8a104a06ff3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.658 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.658 AVG Training Acc 61.88 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.660 AVG Validation Loss:0.659 AVG Training Acc 61.95 % AVG Validation Acc 62.13 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.650 AVG Validation Loss:0.661 AVG Training Acc 62.08 % AVG Validation Acc 61.86 %\n",
      "Epoch:50/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 62.08 % AVG Validation Acc 61.59 %\n",
      "Epoch:60/200 AVG Training Loss:0.645 AVG Validation Loss:0.664 AVG Training Acc 62.25 % AVG Validation Acc 61.50 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.639 AVG Validation Loss:0.665 AVG Training Acc 62.63 % AVG Validation Acc 61.32 %\n",
      "Epoch:80/200 AVG Training Loss:0.638 AVG Validation Loss:0.665 AVG Training Acc 62.66 % AVG Validation Acc 61.77 %\n",
      "Epoch:90/200 AVG Training Loss:0.638 AVG Validation Loss:0.665 AVG Training Acc 62.91 % AVG Validation Acc 61.95 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.637 AVG Validation Loss:0.665 AVG Training Acc 62.99 % AVG Validation Acc 62.31 %\n",
      "Epoch:110/200 AVG Training Loss:0.636 AVG Validation Loss:0.665 AVG Training Acc 62.61 % AVG Validation Acc 61.95 %\n",
      "Epoch:120/200 AVG Training Loss:0.637 AVG Validation Loss:0.665 AVG Training Acc 62.84 % AVG Validation Acc 62.22 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.637 AVG Validation Loss:0.666 AVG Training Acc 62.96 % AVG Validation Acc 62.13 %\n",
      "Epoch:140/200 AVG Training Loss:0.638 AVG Validation Loss:0.666 AVG Training Acc 62.75 % AVG Validation Acc 62.13 %\n",
      "Epoch:150/200 AVG Training Loss:0.638 AVG Validation Loss:0.665 AVG Training Acc 62.98 % AVG Validation Acc 62.22 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.637 AVG Validation Loss:0.665 AVG Training Acc 62.94 % AVG Validation Acc 61.95 %\n",
      "Epoch:170/200 AVG Training Loss:0.636 AVG Validation Loss:0.665 AVG Training Acc 62.84 % AVG Validation Acc 62.31 %\n",
      "Epoch:180/200 AVG Training Loss:0.637 AVG Validation Loss:0.665 AVG Training Acc 62.78 % AVG Validation Acc 62.40 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.638 AVG Validation Loss:0.665 AVG Training Acc 62.52 % AVG Validation Acc 62.04 %\n",
      "Epoch:200/200 AVG Training Loss:0.638 AVG Validation Loss:0.666 AVG Training Acc 62.51 % AVG Validation Acc 61.86 %\n",
      "Split 43\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f70f8f3c0288428b8221f849a6c50739",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.661 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.665 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.650 AVG Validation Loss:0.668 AVG Training Acc 62.02 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.644 AVG Validation Loss:0.673 AVG Training Acc 62.00 % AVG Validation Acc 61.59 %\n",
      "Epoch:50/200 AVG Training Loss:0.640 AVG Validation Loss:0.678 AVG Training Acc 62.17 % AVG Validation Acc 61.50 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.634 AVG Validation Loss:0.683 AVG Training Acc 62.70 % AVG Validation Acc 60.41 %\n",
      "Epoch:70/200 AVG Training Loss:0.633 AVG Validation Loss:0.685 AVG Training Acc 62.48 % AVG Validation Acc 59.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.633 AVG Validation Loss:0.686 AVG Training Acc 62.68 % AVG Validation Acc 59.87 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.633 AVG Validation Loss:0.687 AVG Training Acc 62.49 % AVG Validation Acc 59.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.632 AVG Validation Loss:0.686 AVG Training Acc 62.70 % AVG Validation Acc 60.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.633 AVG Validation Loss:0.687 AVG Training Acc 62.85 % AVG Validation Acc 59.69 %\n",
      "Epoch:120/200 AVG Training Loss:0.630 AVG Validation Loss:0.688 AVG Training Acc 62.97 % AVG Validation Acc 59.87 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.633 AVG Validation Loss:0.689 AVG Training Acc 62.66 % AVG Validation Acc 59.51 %\n",
      "Epoch:140/200 AVG Training Loss:0.633 AVG Validation Loss:0.688 AVG Training Acc 62.94 % AVG Validation Acc 59.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.633 AVG Validation Loss:0.687 AVG Training Acc 62.38 % AVG Validation Acc 59.96 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.632 AVG Validation Loss:0.688 AVG Training Acc 62.58 % AVG Validation Acc 60.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.632 AVG Validation Loss:0.687 AVG Training Acc 62.88 % AVG Validation Acc 59.78 %\n",
      "Epoch:180/200 AVG Training Loss:0.632 AVG Validation Loss:0.687 AVG Training Acc 62.60 % AVG Validation Acc 60.05 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.631 AVG Validation Loss:0.687 AVG Training Acc 62.52 % AVG Validation Acc 59.78 %\n",
      "Epoch:200/200 AVG Training Loss:0.632 AVG Validation Loss:0.688 AVG Training Acc 62.51 % AVG Validation Acc 60.14 %\n",
      "Split 44\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d2f2e7f6a9244a6ae25b836946fb5a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.655 AVG Training Acc 61.83 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.654 AVG Training Acc 62.05 % AVG Validation Acc 61.77 %\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.653 AVG Training Acc 61.89 % AVG Validation Acc 61.68 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.658 AVG Training Acc 61.95 % AVG Validation Acc 61.86 %\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.639 AVG Validation Loss:0.657 AVG Training Acc 62.90 % AVG Validation Acc 62.22 %\n",
      "Epoch:60/200 AVG Training Loss:0.636 AVG Validation Loss:0.661 AVG Training Acc 62.99 % AVG Validation Acc 62.49 %\n",
      "Epoch:70/200 AVG Training Loss:0.630 AVG Validation Loss:0.661 AVG Training Acc 63.21 % AVG Validation Acc 62.85 %\n",
      "Epoch    71: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.628 AVG Validation Loss:0.662 AVG Training Acc 63.14 % AVG Validation Acc 62.31 %\n",
      "Epoch:90/200 AVG Training Loss:0.628 AVG Validation Loss:0.664 AVG Training Acc 63.30 % AVG Validation Acc 61.95 %\n",
      "Epoch:100/200 AVG Training Loss:0.628 AVG Validation Loss:0.665 AVG Training Acc 63.13 % AVG Validation Acc 62.13 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.629 AVG Validation Loss:0.664 AVG Training Acc 63.21 % AVG Validation Acc 61.95 %\n",
      "Epoch:120/200 AVG Training Loss:0.628 AVG Validation Loss:0.665 AVG Training Acc 63.39 % AVG Validation Acc 61.95 %\n",
      "Epoch:130/200 AVG Training Loss:0.627 AVG Validation Loss:0.662 AVG Training Acc 63.47 % AVG Validation Acc 62.04 %\n",
      "Epoch   133: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.627 AVG Validation Loss:0.663 AVG Training Acc 63.36 % AVG Validation Acc 62.13 %\n",
      "Epoch:150/200 AVG Training Loss:0.627 AVG Validation Loss:0.665 AVG Training Acc 63.58 % AVG Validation Acc 62.04 %\n",
      "Epoch:160/200 AVG Training Loss:0.627 AVG Validation Loss:0.664 AVG Training Acc 63.51 % AVG Validation Acc 62.04 %\n",
      "Epoch   164: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.626 AVG Validation Loss:0.664 AVG Training Acc 63.26 % AVG Validation Acc 61.95 %\n",
      "Epoch:180/200 AVG Training Loss:0.627 AVG Validation Loss:0.665 AVG Training Acc 63.46 % AVG Validation Acc 62.31 %\n",
      "Epoch:190/200 AVG Training Loss:0.626 AVG Validation Loss:0.664 AVG Training Acc 63.45 % AVG Validation Acc 62.13 %\n",
      "Epoch   195: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.628 AVG Validation Loss:0.661 AVG Training Acc 63.28 % AVG Validation Acc 62.31 %\n",
      "Split 45\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "916a655c0e194588a85ec9c99223948a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.658 AVG Training Acc 61.85 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.659 AVG Training Acc 61.78 % AVG Validation Acc 61.50 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.667 AVG Training Acc 61.81 % AVG Validation Acc 61.50 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.650 AVG Validation Loss:0.661 AVG Training Acc 62.06 % AVG Validation Acc 61.95 %\n",
      "Epoch:50/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 61.95 % AVG Validation Acc 61.86 %\n",
      "Epoch:60/200 AVG Training Loss:0.645 AVG Validation Loss:0.666 AVG Training Acc 62.14 % AVG Validation Acc 61.77 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.643 AVG Validation Loss:0.667 AVG Training Acc 62.20 % AVG Validation Acc 61.41 %\n",
      "Epoch:80/200 AVG Training Loss:0.641 AVG Validation Loss:0.668 AVG Training Acc 62.46 % AVG Validation Acc 61.50 %\n",
      "Epoch:90/200 AVG Training Loss:0.643 AVG Validation Loss:0.668 AVG Training Acc 62.12 % AVG Validation Acc 61.50 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.642 AVG Validation Loss:0.668 AVG Training Acc 62.35 % AVG Validation Acc 61.50 %\n",
      "Epoch:110/200 AVG Training Loss:0.643 AVG Validation Loss:0.668 AVG Training Acc 62.33 % AVG Validation Acc 61.59 %\n",
      "Epoch:120/200 AVG Training Loss:0.642 AVG Validation Loss:0.668 AVG Training Acc 62.47 % AVG Validation Acc 61.32 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.641 AVG Validation Loss:0.670 AVG Training Acc 62.18 % AVG Validation Acc 61.59 %\n",
      "Epoch:140/200 AVG Training Loss:0.641 AVG Validation Loss:0.668 AVG Training Acc 62.41 % AVG Validation Acc 61.41 %\n",
      "Epoch:150/200 AVG Training Loss:0.641 AVG Validation Loss:0.668 AVG Training Acc 62.43 % AVG Validation Acc 61.59 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.641 AVG Validation Loss:0.669 AVG Training Acc 62.61 % AVG Validation Acc 61.50 %\n",
      "Epoch:170/200 AVG Training Loss:0.641 AVG Validation Loss:0.668 AVG Training Acc 62.31 % AVG Validation Acc 61.41 %\n",
      "Epoch:180/200 AVG Training Loss:0.641 AVG Validation Loss:0.668 AVG Training Acc 62.27 % AVG Validation Acc 61.41 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.641 AVG Validation Loss:0.669 AVG Training Acc 62.25 % AVG Validation Acc 61.41 %\n",
      "Epoch:200/200 AVG Training Loss:0.641 AVG Validation Loss:0.668 AVG Training Acc 62.58 % AVG Validation Acc 61.23 %\n",
      "Split 46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "501adcee73e64a36b6c66a25616fe766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.663 AVG Training Acc 61.84 % AVG Validation Acc 61.91 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:0.665 AVG Training Acc 61.86 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.667 AVG Training Acc 61.99 % AVG Validation Acc 61.91 %\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.670 AVG Training Acc 61.84 % AVG Validation Acc 61.73 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.646 AVG Validation Loss:0.675 AVG Training Acc 61.83 % AVG Validation Acc 61.64 %\n",
      "Epoch:60/200 AVG Training Loss:0.643 AVG Validation Loss:0.677 AVG Training Acc 62.24 % AVG Validation Acc 61.46 %\n",
      "Epoch:70/200 AVG Training Loss:0.644 AVG Validation Loss:0.678 AVG Training Acc 62.04 % AVG Validation Acc 61.10 %\n",
      "Epoch:80/200 AVG Training Loss:0.642 AVG Validation Loss:0.679 AVG Training Acc 62.23 % AVG Validation Acc 61.19 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.642 AVG Validation Loss:0.679 AVG Training Acc 61.98 % AVG Validation Acc 61.19 %\n",
      "Epoch:100/200 AVG Training Loss:0.642 AVG Validation Loss:0.679 AVG Training Acc 62.43 % AVG Validation Acc 61.28 %\n",
      "Epoch:110/200 AVG Training Loss:0.642 AVG Validation Loss:0.679 AVG Training Acc 62.30 % AVG Validation Acc 61.19 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.642 AVG Validation Loss:0.680 AVG Training Acc 62.20 % AVG Validation Acc 61.19 %\n",
      "Epoch:130/200 AVG Training Loss:0.643 AVG Validation Loss:0.679 AVG Training Acc 62.12 % AVG Validation Acc 61.19 %\n",
      "Epoch:140/200 AVG Training Loss:0.642 AVG Validation Loss:0.679 AVG Training Acc 62.25 % AVG Validation Acc 61.28 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.642 AVG Validation Loss:0.679 AVG Training Acc 62.28 % AVG Validation Acc 61.28 %\n",
      "Epoch:160/200 AVG Training Loss:0.643 AVG Validation Loss:0.679 AVG Training Acc 62.03 % AVG Validation Acc 61.19 %\n",
      "Epoch:170/200 AVG Training Loss:0.641 AVG Validation Loss:0.680 AVG Training Acc 62.31 % AVG Validation Acc 61.28 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.641 AVG Validation Loss:0.679 AVG Training Acc 62.47 % AVG Validation Acc 61.28 %\n",
      "Epoch:190/200 AVG Training Loss:0.641 AVG Validation Loss:0.679 AVG Training Acc 62.13 % AVG Validation Acc 61.19 %\n",
      "Epoch:200/200 AVG Training Loss:0.641 AVG Validation Loss:0.680 AVG Training Acc 62.41 % AVG Validation Acc 61.19 %\n",
      "Split 47\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a87855bbd0ed44a18c33a4402bfe494c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.660 AVG Training Acc 61.92 % AVG Validation Acc 61.82 %\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.660 AVG Training Acc 61.95 % AVG Validation Acc 61.55 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.660 AVG Training Acc 62.13 % AVG Validation Acc 61.55 %\n",
      "Epoch:50/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 62.19 % AVG Validation Acc 61.46 %\n",
      "Epoch:60/200 AVG Training Loss:0.642 AVG Validation Loss:0.670 AVG Training Acc 62.23 % AVG Validation Acc 61.37 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.640 AVG Validation Loss:0.672 AVG Training Acc 62.40 % AVG Validation Acc 61.28 %\n",
      "Epoch:80/200 AVG Training Loss:0.638 AVG Validation Loss:0.676 AVG Training Acc 62.37 % AVG Validation Acc 61.28 %\n",
      "Epoch:90/200 AVG Training Loss:0.637 AVG Validation Loss:0.673 AVG Training Acc 62.54 % AVG Validation Acc 61.37 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.636 AVG Validation Loss:0.675 AVG Training Acc 62.45 % AVG Validation Acc 61.37 %\n",
      "Epoch:110/200 AVG Training Loss:0.639 AVG Validation Loss:0.677 AVG Training Acc 62.40 % AVG Validation Acc 61.28 %\n",
      "Epoch:120/200 AVG Training Loss:0.638 AVG Validation Loss:0.678 AVG Training Acc 62.39 % AVG Validation Acc 61.28 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.637 AVG Validation Loss:0.677 AVG Training Acc 62.39 % AVG Validation Acc 61.28 %\n",
      "Epoch:140/200 AVG Training Loss:0.638 AVG Validation Loss:0.677 AVG Training Acc 62.28 % AVG Validation Acc 61.37 %\n",
      "Epoch:150/200 AVG Training Loss:0.637 AVG Validation Loss:0.676 AVG Training Acc 62.44 % AVG Validation Acc 61.37 %\n",
      "Epoch:160/200 AVG Training Loss:0.637 AVG Validation Loss:0.679 AVG Training Acc 62.48 % AVG Validation Acc 61.28 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.637 AVG Validation Loss:0.675 AVG Training Acc 62.40 % AVG Validation Acc 61.37 %\n",
      "Epoch:180/200 AVG Training Loss:0.637 AVG Validation Loss:0.675 AVG Training Acc 62.52 % AVG Validation Acc 61.37 %\n",
      "Epoch:190/200 AVG Training Loss:0.637 AVG Validation Loss:0.679 AVG Training Acc 62.42 % AVG Validation Acc 61.28 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.637 AVG Validation Loss:0.676 AVG Training Acc 62.54 % AVG Validation Acc 61.28 %\n",
      "Split 48\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0da719820f448a1b45e6d9c9b94a9c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.660 AVG Training Acc 61.86 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.662 AVG Training Acc 61.88 % AVG Validation Acc 62.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.667 AVG Training Acc 61.74 % AVG Validation Acc 61.91 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.663 AVG Training Acc 61.88 % AVG Validation Acc 61.73 %\n",
      "Epoch:50/200 AVG Training Loss:0.646 AVG Validation Loss:0.663 AVG Training Acc 62.42 % AVG Validation Acc 61.28 %\n",
      "Epoch:60/200 AVG Training Loss:0.643 AVG Validation Loss:0.665 AVG Training Acc 62.89 % AVG Validation Acc 60.65 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.640 AVG Validation Loss:0.668 AVG Training Acc 62.96 % AVG Validation Acc 60.56 %\n",
      "Epoch:80/200 AVG Training Loss:0.640 AVG Validation Loss:0.669 AVG Training Acc 62.51 % AVG Validation Acc 60.20 %\n",
      "Epoch:90/200 AVG Training Loss:0.637 AVG Validation Loss:0.670 AVG Training Acc 62.83 % AVG Validation Acc 60.74 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.639 AVG Validation Loss:0.672 AVG Training Acc 62.65 % AVG Validation Acc 60.92 %\n",
      "Epoch:110/200 AVG Training Loss:0.637 AVG Validation Loss:0.672 AVG Training Acc 62.91 % AVG Validation Acc 60.56 %\n",
      "Epoch:120/200 AVG Training Loss:0.637 AVG Validation Loss:0.672 AVG Training Acc 63.33 % AVG Validation Acc 60.65 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.637 AVG Validation Loss:0.672 AVG Training Acc 62.74 % AVG Validation Acc 60.56 %\n",
      "Epoch:140/200 AVG Training Loss:0.638 AVG Validation Loss:0.672 AVG Training Acc 62.95 % AVG Validation Acc 60.02 %\n",
      "Epoch:150/200 AVG Training Loss:0.638 AVG Validation Loss:0.672 AVG Training Acc 62.67 % AVG Validation Acc 60.92 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.638 AVG Validation Loss:0.671 AVG Training Acc 62.73 % AVG Validation Acc 60.92 %\n",
      "Epoch:170/200 AVG Training Loss:0.638 AVG Validation Loss:0.672 AVG Training Acc 62.78 % AVG Validation Acc 60.83 %\n",
      "Epoch:180/200 AVG Training Loss:0.637 AVG Validation Loss:0.672 AVG Training Acc 63.01 % AVG Validation Acc 60.56 %\n",
      "Epoch:190/200 AVG Training Loss:0.638 AVG Validation Loss:0.672 AVG Training Acc 62.99 % AVG Validation Acc 60.29 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.637 AVG Validation Loss:0.672 AVG Training Acc 63.03 % AVG Validation Acc 60.92 %\n",
      "Split 49\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4875145bafd4d8290fdd0fa39d49b30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.665 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:0.665 AVG Training Acc 61.73 % AVG Validation Acc 62.00 %\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.666 AVG Training Acc 61.73 % AVG Validation Acc 61.91 %\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.669 AVG Training Acc 61.86 % AVG Validation Acc 61.82 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.648 AVG Validation Loss:0.667 AVG Training Acc 62.05 % AVG Validation Acc 61.91 %\n",
      "Epoch:60/200 AVG Training Loss:0.645 AVG Validation Loss:0.669 AVG Training Acc 61.98 % AVG Validation Acc 61.64 %\n",
      "Epoch:70/200 AVG Training Loss:0.646 AVG Validation Loss:0.670 AVG Training Acc 61.83 % AVG Validation Acc 61.73 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.644 AVG Validation Loss:0.669 AVG Training Acc 62.12 % AVG Validation Acc 61.91 %\n",
      "Epoch:90/200 AVG Training Loss:0.644 AVG Validation Loss:0.669 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch:100/200 AVG Training Loss:0.644 AVG Validation Loss:0.670 AVG Training Acc 62.24 % AVG Validation Acc 61.91 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.645 AVG Validation Loss:0.669 AVG Training Acc 62.01 % AVG Validation Acc 61.82 %\n",
      "Epoch:120/200 AVG Training Loss:0.646 AVG Validation Loss:0.670 AVG Training Acc 61.97 % AVG Validation Acc 62.09 %\n",
      "Epoch:130/200 AVG Training Loss:0.644 AVG Validation Loss:0.669 AVG Training Acc 61.94 % AVG Validation Acc 62.09 %\n",
      "Epoch:140/200 AVG Training Loss:0.644 AVG Validation Loss:0.670 AVG Training Acc 62.00 % AVG Validation Acc 61.91 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.644 AVG Validation Loss:0.669 AVG Training Acc 62.27 % AVG Validation Acc 61.91 %\n",
      "Epoch:160/200 AVG Training Loss:0.645 AVG Validation Loss:0.669 AVG Training Acc 61.99 % AVG Validation Acc 62.00 %\n",
      "Epoch:170/200 AVG Training Loss:0.644 AVG Validation Loss:0.670 AVG Training Acc 62.23 % AVG Validation Acc 61.82 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.643 AVG Validation Loss:0.670 AVG Training Acc 62.17 % AVG Validation Acc 61.82 %\n",
      "Epoch:190/200 AVG Training Loss:0.645 AVG Validation Loss:0.670 AVG Training Acc 62.02 % AVG Validation Acc 61.73 %\n",
      "Epoch:200/200 AVG Training Loss:0.645 AVG Validation Loss:0.670 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Split 50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb4fb28372a4efaaab9a3230d039dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.655 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.655 AVG Training Acc 61.92 % AVG Validation Acc 61.73 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.654 AVG Training Acc 62.03 % AVG Validation Acc 61.55 %\n",
      "Epoch:40/200 AVG Training Loss:0.654 AVG Validation Loss:0.655 AVG Training Acc 61.88 % AVG Validation Acc 61.55 %\n",
      "Epoch:50/200 AVG Training Loss:0.652 AVG Validation Loss:0.658 AVG Training Acc 61.92 % AVG Validation Acc 61.55 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.650 AVG Validation Loss:0.659 AVG Training Acc 62.03 % AVG Validation Acc 61.55 %\n",
      "Epoch:70/200 AVG Training Loss:0.649 AVG Validation Loss:0.659 AVG Training Acc 61.92 % AVG Validation Acc 61.55 %\n",
      "Epoch:80/200 AVG Training Loss:0.650 AVG Validation Loss:0.659 AVG Training Acc 62.05 % AVG Validation Acc 61.64 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.649 AVG Validation Loss:0.659 AVG Training Acc 61.99 % AVG Validation Acc 61.55 %\n",
      "Epoch:100/200 AVG Training Loss:0.648 AVG Validation Loss:0.659 AVG Training Acc 62.11 % AVG Validation Acc 61.64 %\n",
      "Epoch:110/200 AVG Training Loss:0.648 AVG Validation Loss:0.659 AVG Training Acc 62.09 % AVG Validation Acc 61.55 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.649 AVG Validation Loss:0.659 AVG Training Acc 62.18 % AVG Validation Acc 61.64 %\n",
      "Epoch:130/200 AVG Training Loss:0.649 AVG Validation Loss:0.660 AVG Training Acc 62.24 % AVG Validation Acc 61.64 %\n",
      "Epoch:140/200 AVG Training Loss:0.647 AVG Validation Loss:0.659 AVG Training Acc 62.13 % AVG Validation Acc 61.64 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.648 AVG Validation Loss:0.659 AVG Training Acc 62.13 % AVG Validation Acc 61.73 %\n",
      "Epoch:160/200 AVG Training Loss:0.648 AVG Validation Loss:0.659 AVG Training Acc 62.18 % AVG Validation Acc 61.64 %\n",
      "Epoch:170/200 AVG Training Loss:0.647 AVG Validation Loss:0.659 AVG Training Acc 62.31 % AVG Validation Acc 61.64 %\n",
      "Epoch:180/200 AVG Training Loss:0.648 AVG Validation Loss:0.659 AVG Training Acc 62.31 % AVG Validation Acc 61.64 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.648 AVG Validation Loss:0.659 AVG Training Acc 62.29 % AVG Validation Acc 61.64 %\n",
      "Epoch:200/200 AVG Training Loss:0.648 AVG Validation Loss:0.659 AVG Training Acc 62.03 % AVG Validation Acc 61.55 %\n",
      "Split 51\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0024a7060d7846da82386289dd6e0ed7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.659 AVG Training Acc 61.88 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.659 AVG Training Acc 61.92 % AVG Validation Acc 61.77 %\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.665 AVG Training Acc 61.82 % AVG Validation Acc 61.59 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.646 AVG Validation Loss:0.665 AVG Training Acc 62.46 % AVG Validation Acc 61.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.644 AVG Validation Loss:0.667 AVG Training Acc 62.77 % AVG Validation Acc 61.23 %\n",
      "Epoch:60/200 AVG Training Loss:0.641 AVG Validation Loss:0.676 AVG Training Acc 62.73 % AVG Validation Acc 60.87 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.637 AVG Validation Loss:0.676 AVG Training Acc 63.15 % AVG Validation Acc 60.69 %\n",
      "Epoch:80/200 AVG Training Loss:0.637 AVG Validation Loss:0.674 AVG Training Acc 63.04 % AVG Validation Acc 60.78 %\n",
      "Epoch:90/200 AVG Training Loss:0.636 AVG Validation Loss:0.675 AVG Training Acc 63.17 % AVG Validation Acc 60.96 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.637 AVG Validation Loss:0.677 AVG Training Acc 63.20 % AVG Validation Acc 60.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.637 AVG Validation Loss:0.677 AVG Training Acc 62.99 % AVG Validation Acc 60.69 %\n",
      "Epoch:120/200 AVG Training Loss:0.637 AVG Validation Loss:0.674 AVG Training Acc 63.03 % AVG Validation Acc 60.87 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.636 AVG Validation Loss:0.676 AVG Training Acc 62.75 % AVG Validation Acc 60.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.635 AVG Validation Loss:0.676 AVG Training Acc 62.92 % AVG Validation Acc 60.69 %\n",
      "Epoch:150/200 AVG Training Loss:0.636 AVG Validation Loss:0.676 AVG Training Acc 63.24 % AVG Validation Acc 60.87 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.636 AVG Validation Loss:0.675 AVG Training Acc 62.82 % AVG Validation Acc 60.69 %\n",
      "Epoch:170/200 AVG Training Loss:0.635 AVG Validation Loss:0.676 AVG Training Acc 63.60 % AVG Validation Acc 60.50 %\n",
      "Epoch:180/200 AVG Training Loss:0.637 AVG Validation Loss:0.677 AVG Training Acc 63.13 % AVG Validation Acc 60.69 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.635 AVG Validation Loss:0.676 AVG Training Acc 63.07 % AVG Validation Acc 60.78 %\n",
      "Epoch:200/200 AVG Training Loss:0.636 AVG Validation Loss:0.676 AVG Training Acc 63.14 % AVG Validation Acc 60.78 %\n",
      "Split 52\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f89569a442a42a487e36c7c3992f5c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.664 AVG Training Acc 61.85 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.665 AVG Training Acc 61.67 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.672 AVG Training Acc 61.74 % AVG Validation Acc 61.68 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.650 AVG Validation Loss:0.670 AVG Training Acc 61.96 % AVG Validation Acc 61.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.647 AVG Validation Loss:0.675 AVG Training Acc 62.37 % AVG Validation Acc 61.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.644 AVG Validation Loss:0.682 AVG Training Acc 62.48 % AVG Validation Acc 60.78 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.642 AVG Validation Loss:0.685 AVG Training Acc 62.27 % AVG Validation Acc 60.69 %\n",
      "Epoch:80/200 AVG Training Loss:0.642 AVG Validation Loss:0.686 AVG Training Acc 62.41 % AVG Validation Acc 60.69 %\n",
      "Epoch:90/200 AVG Training Loss:0.641 AVG Validation Loss:0.685 AVG Training Acc 62.60 % AVG Validation Acc 60.96 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.641 AVG Validation Loss:0.685 AVG Training Acc 62.31 % AVG Validation Acc 60.50 %\n",
      "Epoch:110/200 AVG Training Loss:0.641 AVG Validation Loss:0.685 AVG Training Acc 62.59 % AVG Validation Acc 60.87 %\n",
      "Epoch:120/200 AVG Training Loss:0.640 AVG Validation Loss:0.685 AVG Training Acc 62.56 % AVG Validation Acc 60.69 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.641 AVG Validation Loss:0.685 AVG Training Acc 62.19 % AVG Validation Acc 60.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.641 AVG Validation Loss:0.686 AVG Training Acc 62.24 % AVG Validation Acc 60.87 %\n",
      "Epoch:150/200 AVG Training Loss:0.640 AVG Validation Loss:0.686 AVG Training Acc 62.54 % AVG Validation Acc 60.69 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.641 AVG Validation Loss:0.686 AVG Training Acc 62.46 % AVG Validation Acc 60.69 %\n",
      "Epoch:170/200 AVG Training Loss:0.641 AVG Validation Loss:0.686 AVG Training Acc 62.45 % AVG Validation Acc 60.50 %\n",
      "Epoch:180/200 AVG Training Loss:0.641 AVG Validation Loss:0.685 AVG Training Acc 62.48 % AVG Validation Acc 60.96 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.640 AVG Validation Loss:0.686 AVG Training Acc 62.27 % AVG Validation Acc 60.60 %\n",
      "Epoch:200/200 AVG Training Loss:0.641 AVG Validation Loss:0.685 AVG Training Acc 62.24 % AVG Validation Acc 60.69 %\n",
      "Split 53\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ddd18ac1d1d4d9c8704b6e0729e3404",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.658 AVG Training Acc 61.92 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 61.82 % AVG Validation Acc 61.86 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.659 AVG Training Acc 61.89 % AVG Validation Acc 61.59 %\n",
      "Epoch:40/200 AVG Training Loss:0.650 AVG Validation Loss:0.661 AVG Training Acc 62.02 % AVG Validation Acc 61.41 %\n",
      "Epoch:50/200 AVG Training Loss:0.646 AVG Validation Loss:0.662 AVG Training Acc 62.17 % AVG Validation Acc 61.32 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.641 AVG Validation Loss:0.667 AVG Training Acc 62.28 % AVG Validation Acc 60.87 %\n",
      "Epoch:70/200 AVG Training Loss:0.640 AVG Validation Loss:0.668 AVG Training Acc 62.32 % AVG Validation Acc 60.78 %\n",
      "Epoch:80/200 AVG Training Loss:0.641 AVG Validation Loss:0.669 AVG Training Acc 62.27 % AVG Validation Acc 60.87 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.639 AVG Validation Loss:0.672 AVG Training Acc 62.62 % AVG Validation Acc 60.78 %\n",
      "Epoch:100/200 AVG Training Loss:0.640 AVG Validation Loss:0.671 AVG Training Acc 62.28 % AVG Validation Acc 60.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.638 AVG Validation Loss:0.671 AVG Training Acc 62.43 % AVG Validation Acc 60.78 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.638 AVG Validation Loss:0.673 AVG Training Acc 62.72 % AVG Validation Acc 60.78 %\n",
      "Epoch:130/200 AVG Training Loss:0.638 AVG Validation Loss:0.671 AVG Training Acc 62.43 % AVG Validation Acc 60.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.638 AVG Validation Loss:0.671 AVG Training Acc 62.38 % AVG Validation Acc 60.78 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.639 AVG Validation Loss:0.673 AVG Training Acc 62.20 % AVG Validation Acc 60.69 %\n",
      "Epoch:160/200 AVG Training Loss:0.638 AVG Validation Loss:0.673 AVG Training Acc 62.48 % AVG Validation Acc 60.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.639 AVG Validation Loss:0.671 AVG Training Acc 62.57 % AVG Validation Acc 60.78 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.639 AVG Validation Loss:0.671 AVG Training Acc 62.20 % AVG Validation Acc 60.87 %\n",
      "Epoch:190/200 AVG Training Loss:0.638 AVG Validation Loss:0.672 AVG Training Acc 62.60 % AVG Validation Acc 60.78 %\n",
      "Epoch:200/200 AVG Training Loss:0.639 AVG Validation Loss:0.672 AVG Training Acc 62.50 % AVG Validation Acc 60.78 %\n",
      "Split 54\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6abf527625574f868b5b6b28b324cc1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.665 AVG Training Acc 61.72 % AVG Validation Acc 61.86 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:0.659 AVG Training Acc 61.82 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.659 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.660 AVG Training Acc 61.77 % AVG Validation Acc 61.86 %\n",
      "Epoch:50/200 AVG Training Loss:0.650 AVG Validation Loss:0.660 AVG Training Acc 62.02 % AVG Validation Acc 61.77 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.648 AVG Validation Loss:0.661 AVG Training Acc 62.39 % AVG Validation Acc 61.86 %\n",
      "Epoch:70/200 AVG Training Loss:0.648 AVG Validation Loss:0.661 AVG Training Acc 62.39 % AVG Validation Acc 61.86 %\n",
      "Epoch:80/200 AVG Training Loss:0.647 AVG Validation Loss:0.662 AVG Training Acc 62.35 % AVG Validation Acc 61.68 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.646 AVG Validation Loss:0.663 AVG Training Acc 62.60 % AVG Validation Acc 61.77 %\n",
      "Epoch:100/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 62.22 % AVG Validation Acc 61.86 %\n",
      "Epoch:110/200 AVG Training Loss:0.647 AVG Validation Loss:0.662 AVG Training Acc 61.91 % AVG Validation Acc 61.68 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.646 AVG Validation Loss:0.662 AVG Training Acc 62.48 % AVG Validation Acc 61.86 %\n",
      "Epoch:130/200 AVG Training Loss:0.646 AVG Validation Loss:0.662 AVG Training Acc 62.22 % AVG Validation Acc 61.77 %\n",
      "Epoch:140/200 AVG Training Loss:0.645 AVG Validation Loss:0.663 AVG Training Acc 62.53 % AVG Validation Acc 61.86 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 62.68 % AVG Validation Acc 62.13 %\n",
      "Epoch:160/200 AVG Training Loss:0.647 AVG Validation Loss:0.662 AVG Training Acc 62.48 % AVG Validation Acc 61.95 %\n",
      "Epoch:170/200 AVG Training Loss:0.647 AVG Validation Loss:0.662 AVG Training Acc 62.17 % AVG Validation Acc 61.68 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.647 AVG Validation Loss:0.662 AVG Training Acc 62.13 % AVG Validation Acc 61.68 %\n",
      "Epoch:190/200 AVG Training Loss:0.647 AVG Validation Loss:0.662 AVG Training Acc 62.43 % AVG Validation Acc 62.22 %\n",
      "Epoch:200/200 AVG Training Loss:0.646 AVG Validation Loss:0.663 AVG Training Acc 62.61 % AVG Validation Acc 62.04 %\n",
      "Split 55\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29087db9cf544478ba6075b10b34c387",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.662 AVG Training Acc 61.84 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.665 AVG Training Acc 61.91 % AVG Validation Acc 61.77 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.650 AVG Validation Loss:0.671 AVG Training Acc 62.10 % AVG Validation Acc 61.77 %\n",
      "Epoch:40/200 AVG Training Loss:0.646 AVG Validation Loss:0.674 AVG Training Acc 62.19 % AVG Validation Acc 61.68 %\n",
      "Epoch:50/200 AVG Training Loss:0.643 AVG Validation Loss:0.676 AVG Training Acc 62.12 % AVG Validation Acc 61.68 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.639 AVG Validation Loss:0.682 AVG Training Acc 62.37 % AVG Validation Acc 61.86 %\n",
      "Epoch:70/200 AVG Training Loss:0.639 AVG Validation Loss:0.685 AVG Training Acc 62.43 % AVG Validation Acc 61.77 %\n",
      "Epoch:80/200 AVG Training Loss:0.638 AVG Validation Loss:0.686 AVG Training Acc 62.38 % AVG Validation Acc 61.77 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.636 AVG Validation Loss:0.688 AVG Training Acc 62.57 % AVG Validation Acc 61.77 %\n",
      "Epoch:100/200 AVG Training Loss:0.637 AVG Validation Loss:0.687 AVG Training Acc 62.59 % AVG Validation Acc 61.77 %\n",
      "Epoch:110/200 AVG Training Loss:0.636 AVG Validation Loss:0.688 AVG Training Acc 62.29 % AVG Validation Acc 61.77 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.636 AVG Validation Loss:0.688 AVG Training Acc 62.40 % AVG Validation Acc 61.77 %\n",
      "Epoch:130/200 AVG Training Loss:0.637 AVG Validation Loss:0.688 AVG Training Acc 62.52 % AVG Validation Acc 61.68 %\n",
      "Epoch:140/200 AVG Training Loss:0.636 AVG Validation Loss:0.688 AVG Training Acc 62.62 % AVG Validation Acc 61.68 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.637 AVG Validation Loss:0.688 AVG Training Acc 62.67 % AVG Validation Acc 61.68 %\n",
      "Epoch:160/200 AVG Training Loss:0.636 AVG Validation Loss:0.689 AVG Training Acc 62.54 % AVG Validation Acc 61.77 %\n",
      "Epoch:170/200 AVG Training Loss:0.637 AVG Validation Loss:0.688 AVG Training Acc 62.44 % AVG Validation Acc 61.77 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.637 AVG Validation Loss:0.688 AVG Training Acc 62.18 % AVG Validation Acc 61.77 %\n",
      "Epoch:190/200 AVG Training Loss:0.637 AVG Validation Loss:0.688 AVG Training Acc 62.34 % AVG Validation Acc 61.68 %\n",
      "Epoch:200/200 AVG Training Loss:0.636 AVG Validation Loss:0.686 AVG Training Acc 62.32 % AVG Validation Acc 61.77 %\n",
      "Split 56\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e459d2fe1c24aafb13c97b8c57a10ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.660 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.660 AVG Training Acc 61.64 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.659 AVG Training Acc 61.77 % AVG Validation Acc 62.00 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.662 AVG Training Acc 62.15 % AVG Validation Acc 61.73 %\n",
      "Epoch:50/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 62.24 % AVG Validation Acc 62.27 %\n",
      "Epoch:60/200 AVG Training Loss:0.646 AVG Validation Loss:0.673 AVG Training Acc 62.17 % AVG Validation Acc 62.18 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.643 AVG Validation Loss:0.675 AVG Training Acc 62.07 % AVG Validation Acc 62.36 %\n",
      "Epoch:80/200 AVG Training Loss:0.643 AVG Validation Loss:0.678 AVG Training Acc 62.35 % AVG Validation Acc 62.27 %\n",
      "Epoch:90/200 AVG Training Loss:0.641 AVG Validation Loss:0.678 AVG Training Acc 62.52 % AVG Validation Acc 62.64 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.641 AVG Validation Loss:0.677 AVG Training Acc 62.79 % AVG Validation Acc 62.45 %\n",
      "Epoch:110/200 AVG Training Loss:0.641 AVG Validation Loss:0.678 AVG Training Acc 62.34 % AVG Validation Acc 62.18 %\n",
      "Epoch:120/200 AVG Training Loss:0.640 AVG Validation Loss:0.679 AVG Training Acc 62.93 % AVG Validation Acc 62.18 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.642 AVG Validation Loss:0.678 AVG Training Acc 62.48 % AVG Validation Acc 62.45 %\n",
      "Epoch:140/200 AVG Training Loss:0.641 AVG Validation Loss:0.678 AVG Training Acc 62.52 % AVG Validation Acc 62.27 %\n",
      "Epoch:150/200 AVG Training Loss:0.642 AVG Validation Loss:0.679 AVG Training Acc 62.21 % AVG Validation Acc 62.18 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.642 AVG Validation Loss:0.679 AVG Training Acc 62.49 % AVG Validation Acc 62.18 %\n",
      "Epoch:170/200 AVG Training Loss:0.641 AVG Validation Loss:0.678 AVG Training Acc 62.25 % AVG Validation Acc 62.64 %\n",
      "Epoch:180/200 AVG Training Loss:0.641 AVG Validation Loss:0.680 AVG Training Acc 62.70 % AVG Validation Acc 62.27 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.643 AVG Validation Loss:0.678 AVG Training Acc 62.25 % AVG Validation Acc 62.45 %\n",
      "Epoch:200/200 AVG Training Loss:0.641 AVG Validation Loss:0.678 AVG Training Acc 62.50 % AVG Validation Acc 62.18 %\n",
      "Split 57\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d1c1f96a9eb4addb5982270077084f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.658 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.654 AVG Training Acc 61.87 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.659 AVG Validation Loss:0.655 AVG Training Acc 61.94 % AVG Validation Acc 61.91 %\n",
      "Epoch:40/200 AVG Training Loss:0.657 AVG Validation Loss:0.657 AVG Training Acc 61.94 % AVG Validation Acc 62.00 %\n",
      "Epoch:50/200 AVG Training Loss:0.656 AVG Validation Loss:0.653 AVG Training Acc 61.92 % AVG Validation Acc 62.00 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.651 AVG Validation Loss:0.653 AVG Training Acc 61.98 % AVG Validation Acc 61.91 %\n",
      "Epoch:70/200 AVG Training Loss:0.646 AVG Validation Loss:0.651 AVG Training Acc 61.98 % AVG Validation Acc 62.09 %\n",
      "Epoch:80/200 AVG Training Loss:0.643 AVG Validation Loss:0.651 AVG Training Acc 62.34 % AVG Validation Acc 62.09 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.641 AVG Validation Loss:0.656 AVG Training Acc 62.32 % AVG Validation Acc 62.00 %\n",
      "Epoch:100/200 AVG Training Loss:0.639 AVG Validation Loss:0.656 AVG Training Acc 62.25 % AVG Validation Acc 61.37 %\n",
      "Epoch:110/200 AVG Training Loss:0.640 AVG Validation Loss:0.655 AVG Training Acc 62.50 % AVG Validation Acc 61.64 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.638 AVG Validation Loss:0.653 AVG Training Acc 62.54 % AVG Validation Acc 62.00 %\n",
      "Epoch:130/200 AVG Training Loss:0.639 AVG Validation Loss:0.654 AVG Training Acc 62.45 % AVG Validation Acc 62.18 %\n",
      "Epoch:140/200 AVG Training Loss:0.639 AVG Validation Loss:0.653 AVG Training Acc 62.53 % AVG Validation Acc 62.09 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.638 AVG Validation Loss:0.654 AVG Training Acc 62.56 % AVG Validation Acc 61.55 %\n",
      "Epoch:160/200 AVG Training Loss:0.639 AVG Validation Loss:0.655 AVG Training Acc 62.39 % AVG Validation Acc 61.73 %\n",
      "Epoch:170/200 AVG Training Loss:0.638 AVG Validation Loss:0.654 AVG Training Acc 62.69 % AVG Validation Acc 61.64 %\n",
      "Epoch:180/200 AVG Training Loss:0.639 AVG Validation Loss:0.656 AVG Training Acc 62.55 % AVG Validation Acc 61.91 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.639 AVG Validation Loss:0.654 AVG Training Acc 62.35 % AVG Validation Acc 61.73 %\n",
      "Epoch:200/200 AVG Training Loss:0.638 AVG Validation Loss:0.656 AVG Training Acc 62.41 % AVG Validation Acc 62.00 %\n",
      "Split 58\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "315c06a6eb494fedaca2b6bc5bc9fcab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.657 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.657 AVG Training Acc 61.90 % AVG Validation Acc 62.00 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.662 AVG Training Acc 62.03 % AVG Validation Acc 61.91 %\n",
      "Epoch:40/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.15 % AVG Validation Acc 61.82 %\n",
      "Epoch:50/200 AVG Training Loss:0.644 AVG Validation Loss:0.668 AVG Training Acc 62.46 % AVG Validation Acc 61.55 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.641 AVG Validation Loss:0.672 AVG Training Acc 62.57 % AVG Validation Acc 61.10 %\n",
      "Epoch:70/200 AVG Training Loss:0.639 AVG Validation Loss:0.672 AVG Training Acc 62.41 % AVG Validation Acc 61.10 %\n",
      "Epoch:80/200 AVG Training Loss:0.640 AVG Validation Loss:0.674 AVG Training Acc 62.48 % AVG Validation Acc 60.83 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.638 AVG Validation Loss:0.673 AVG Training Acc 62.69 % AVG Validation Acc 60.92 %\n",
      "Epoch:100/200 AVG Training Loss:0.637 AVG Validation Loss:0.674 AVG Training Acc 62.84 % AVG Validation Acc 60.92 %\n",
      "Epoch:110/200 AVG Training Loss:0.640 AVG Validation Loss:0.674 AVG Training Acc 62.23 % AVG Validation Acc 60.92 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.638 AVG Validation Loss:0.676 AVG Training Acc 62.62 % AVG Validation Acc 60.83 %\n",
      "Epoch:130/200 AVG Training Loss:0.639 AVG Validation Loss:0.674 AVG Training Acc 62.49 % AVG Validation Acc 60.92 %\n",
      "Epoch:140/200 AVG Training Loss:0.639 AVG Validation Loss:0.675 AVG Training Acc 62.50 % AVG Validation Acc 60.92 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.640 AVG Validation Loss:0.673 AVG Training Acc 62.58 % AVG Validation Acc 60.74 %\n",
      "Epoch:160/200 AVG Training Loss:0.639 AVG Validation Loss:0.674 AVG Training Acc 62.58 % AVG Validation Acc 61.01 %\n",
      "Epoch:170/200 AVG Training Loss:0.638 AVG Validation Loss:0.674 AVG Training Acc 62.54 % AVG Validation Acc 60.83 %\n",
      "Epoch:180/200 AVG Training Loss:0.638 AVG Validation Loss:0.675 AVG Training Acc 62.75 % AVG Validation Acc 60.83 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.638 AVG Validation Loss:0.674 AVG Training Acc 62.30 % AVG Validation Acc 60.74 %\n",
      "Epoch:200/200 AVG Training Loss:0.638 AVG Validation Loss:0.675 AVG Training Acc 62.72 % AVG Validation Acc 60.92 %\n",
      "Split 59\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc2b3387aa1744e081b83b9f1cc30347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.662 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.663 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.663 AVG Training Acc 61.89 % AVG Validation Acc 62.00 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.666 AVG Training Acc 62.00 % AVG Validation Acc 61.82 %\n",
      "Epoch:50/200 AVG Training Loss:0.648 AVG Validation Loss:0.673 AVG Training Acc 61.82 % AVG Validation Acc 61.82 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.645 AVG Validation Loss:0.675 AVG Training Acc 61.99 % AVG Validation Acc 61.82 %\n",
      "Epoch:70/200 AVG Training Loss:0.643 AVG Validation Loss:0.679 AVG Training Acc 62.25 % AVG Validation Acc 61.82 %\n",
      "Epoch:80/200 AVG Training Loss:0.644 AVG Validation Loss:0.681 AVG Training Acc 62.07 % AVG Validation Acc 61.82 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.643 AVG Validation Loss:0.682 AVG Training Acc 62.00 % AVG Validation Acc 61.82 %\n",
      "Epoch:100/200 AVG Training Loss:0.642 AVG Validation Loss:0.682 AVG Training Acc 62.37 % AVG Validation Acc 61.82 %\n",
      "Epoch:110/200 AVG Training Loss:0.643 AVG Validation Loss:0.682 AVG Training Acc 62.34 % AVG Validation Acc 61.82 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.642 AVG Validation Loss:0.682 AVG Training Acc 62.18 % AVG Validation Acc 61.82 %\n",
      "Epoch:130/200 AVG Training Loss:0.641 AVG Validation Loss:0.681 AVG Training Acc 62.14 % AVG Validation Acc 61.82 %\n",
      "Epoch:140/200 AVG Training Loss:0.643 AVG Validation Loss:0.682 AVG Training Acc 62.27 % AVG Validation Acc 61.82 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.643 AVG Validation Loss:0.681 AVG Training Acc 62.09 % AVG Validation Acc 61.82 %\n",
      "Epoch:160/200 AVG Training Loss:0.642 AVG Validation Loss:0.682 AVG Training Acc 62.40 % AVG Validation Acc 61.82 %\n",
      "Epoch:170/200 AVG Training Loss:0.642 AVG Validation Loss:0.682 AVG Training Acc 62.27 % AVG Validation Acc 61.82 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.642 AVG Validation Loss:0.681 AVG Training Acc 62.36 % AVG Validation Acc 61.82 %\n",
      "Epoch:190/200 AVG Training Loss:0.643 AVG Validation Loss:0.683 AVG Training Acc 62.08 % AVG Validation Acc 61.82 %\n",
      "Epoch:200/200 AVG Training Loss:0.641 AVG Validation Loss:0.682 AVG Training Acc 62.41 % AVG Validation Acc 61.82 %\n",
      "Split 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95d94fdb9807474a80999f33d3a08062",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.657 AVG Training Acc 61.93 % AVG Validation Acc 61.91 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.659 AVG Training Acc 62.01 % AVG Validation Acc 61.73 %\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.660 AVG Training Acc 62.00 % AVG Validation Acc 61.73 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.662 AVG Training Acc 62.18 % AVG Validation Acc 61.64 %\n",
      "Epoch:50/200 AVG Training Loss:0.650 AVG Validation Loss:0.663 AVG Training Acc 62.22 % AVG Validation Acc 61.64 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.20 % AVG Validation Acc 61.64 %\n",
      "Epoch:70/200 AVG Training Loss:0.648 AVG Validation Loss:0.665 AVG Training Acc 62.11 % AVG Validation Acc 61.73 %\n",
      "Epoch:80/200 AVG Training Loss:0.646 AVG Validation Loss:0.666 AVG Training Acc 62.41 % AVG Validation Acc 61.73 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.647 AVG Validation Loss:0.666 AVG Training Acc 62.43 % AVG Validation Acc 61.73 %\n",
      "Epoch:100/200 AVG Training Loss:0.648 AVG Validation Loss:0.666 AVG Training Acc 62.17 % AVG Validation Acc 61.73 %\n",
      "Epoch:110/200 AVG Training Loss:0.646 AVG Validation Loss:0.666 AVG Training Acc 62.27 % AVG Validation Acc 61.73 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.648 AVG Validation Loss:0.667 AVG Training Acc 62.05 % AVG Validation Acc 61.73 %\n",
      "Epoch:130/200 AVG Training Loss:0.646 AVG Validation Loss:0.667 AVG Training Acc 62.23 % AVG Validation Acc 61.64 %\n",
      "Epoch:140/200 AVG Training Loss:0.647 AVG Validation Loss:0.666 AVG Training Acc 62.24 % AVG Validation Acc 61.64 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.646 AVG Validation Loss:0.666 AVG Training Acc 62.40 % AVG Validation Acc 61.73 %\n",
      "Epoch:160/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 62.28 % AVG Validation Acc 61.73 %\n",
      "Epoch:170/200 AVG Training Loss:0.647 AVG Validation Loss:0.666 AVG Training Acc 62.19 % AVG Validation Acc 61.64 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.647 AVG Validation Loss:0.666 AVG Training Acc 62.20 % AVG Validation Acc 61.73 %\n",
      "Epoch:190/200 AVG Training Loss:0.647 AVG Validation Loss:0.666 AVG Training Acc 61.97 % AVG Validation Acc 61.64 %\n",
      "Epoch:200/200 AVG Training Loss:0.645 AVG Validation Loss:0.666 AVG Training Acc 62.33 % AVG Validation Acc 61.64 %\n",
      "Split 61\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91112427619b4f709ee27900a2807281",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.659 AVG Training Acc 61.86 % AVG Validation Acc 61.95 %\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:0.660 AVG Training Acc 61.83 % AVG Validation Acc 62.13 %\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.663 AVG Training Acc 61.65 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.648 AVG Validation Loss:0.670 AVG Training Acc 62.33 % AVG Validation Acc 61.68 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.644 AVG Validation Loss:0.674 AVG Training Acc 62.48 % AVG Validation Acc 61.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.643 AVG Validation Loss:0.675 AVG Training Acc 62.35 % AVG Validation Acc 61.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.642 AVG Validation Loss:0.676 AVG Training Acc 62.26 % AVG Validation Acc 61.32 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.641 AVG Validation Loss:0.676 AVG Training Acc 62.64 % AVG Validation Acc 61.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.642 AVG Validation Loss:0.676 AVG Training Acc 62.35 % AVG Validation Acc 61.23 %\n",
      "Epoch:100/200 AVG Training Loss:0.641 AVG Validation Loss:0.676 AVG Training Acc 62.44 % AVG Validation Acc 61.14 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.643 AVG Validation Loss:0.676 AVG Training Acc 62.39 % AVG Validation Acc 61.23 %\n",
      "Epoch:120/200 AVG Training Loss:0.642 AVG Validation Loss:0.677 AVG Training Acc 62.40 % AVG Validation Acc 61.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.642 AVG Validation Loss:0.678 AVG Training Acc 62.83 % AVG Validation Acc 60.96 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.641 AVG Validation Loss:0.677 AVG Training Acc 62.68 % AVG Validation Acc 61.32 %\n",
      "Epoch:150/200 AVG Training Loss:0.641 AVG Validation Loss:0.677 AVG Training Acc 62.38 % AVG Validation Acc 61.23 %\n",
      "Epoch:160/200 AVG Training Loss:0.641 AVG Validation Loss:0.677 AVG Training Acc 62.63 % AVG Validation Acc 60.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.643 AVG Validation Loss:0.677 AVG Training Acc 62.63 % AVG Validation Acc 61.05 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.642 AVG Validation Loss:0.677 AVG Training Acc 62.41 % AVG Validation Acc 60.87 %\n",
      "Epoch:190/200 AVG Training Loss:0.641 AVG Validation Loss:0.678 AVG Training Acc 62.59 % AVG Validation Acc 61.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.641 AVG Validation Loss:0.676 AVG Training Acc 62.97 % AVG Validation Acc 61.14 %\n",
      "Split 62\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72a972d70a224bdfb5bf4df71d9c0e63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.663 AVG Training Acc 61.88 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 61.88 % AVG Validation Acc 61.86 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.664 AVG Training Acc 61.95 % AVG Validation Acc 61.77 %\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.666 AVG Training Acc 61.97 % AVG Validation Acc 61.50 %\n",
      "Epoch:50/200 AVG Training Loss:0.648 AVG Validation Loss:0.668 AVG Training Acc 62.00 % AVG Validation Acc 61.50 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.644 AVG Validation Loss:0.670 AVG Training Acc 62.38 % AVG Validation Acc 61.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.644 AVG Validation Loss:0.670 AVG Training Acc 62.29 % AVG Validation Acc 61.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.643 AVG Validation Loss:0.670 AVG Training Acc 62.14 % AVG Validation Acc 61.23 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.642 AVG Validation Loss:0.670 AVG Training Acc 62.52 % AVG Validation Acc 61.05 %\n",
      "Epoch:100/200 AVG Training Loss:0.643 AVG Validation Loss:0.670 AVG Training Acc 62.37 % AVG Validation Acc 61.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.642 AVG Validation Loss:0.670 AVG Training Acc 62.32 % AVG Validation Acc 61.14 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.642 AVG Validation Loss:0.670 AVG Training Acc 62.16 % AVG Validation Acc 61.32 %\n",
      "Epoch:130/200 AVG Training Loss:0.641 AVG Validation Loss:0.670 AVG Training Acc 62.43 % AVG Validation Acc 61.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.642 AVG Validation Loss:0.670 AVG Training Acc 62.36 % AVG Validation Acc 61.32 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.641 AVG Validation Loss:0.670 AVG Training Acc 62.58 % AVG Validation Acc 61.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.642 AVG Validation Loss:0.670 AVG Training Acc 62.47 % AVG Validation Acc 61.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.642 AVG Validation Loss:0.670 AVG Training Acc 62.51 % AVG Validation Acc 61.23 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.642 AVG Validation Loss:0.670 AVG Training Acc 62.44 % AVG Validation Acc 61.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.643 AVG Validation Loss:0.670 AVG Training Acc 62.29 % AVG Validation Acc 61.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.643 AVG Validation Loss:0.670 AVG Training Acc 62.40 % AVG Validation Acc 61.32 %\n",
      "Split 63\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3dcc82e6d23f4b2c9f3fd5cdf5483f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.660 AVG Training Acc 61.88 % AVG Validation Acc 61.86 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.656 AVG Validation Loss:0.659 AVG Training Acc 61.94 % AVG Validation Acc 61.77 %\n",
      "Epoch:30/200 AVG Training Loss:0.652 AVG Validation Loss:0.661 AVG Training Acc 61.91 % AVG Validation Acc 61.68 %\n",
      "Epoch:40/200 AVG Training Loss:0.648 AVG Validation Loss:0.663 AVG Training Acc 62.03 % AVG Validation Acc 61.59 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.642 AVG Validation Loss:0.662 AVG Training Acc 62.43 % AVG Validation Acc 61.68 %\n",
      "Epoch:60/200 AVG Training Loss:0.642 AVG Validation Loss:0.663 AVG Training Acc 62.49 % AVG Validation Acc 61.77 %\n",
      "Epoch:70/200 AVG Training Loss:0.641 AVG Validation Loss:0.664 AVG Training Acc 62.44 % AVG Validation Acc 61.68 %\n",
      "Epoch:80/200 AVG Training Loss:0.641 AVG Validation Loss:0.664 AVG Training Acc 62.36 % AVG Validation Acc 61.86 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.640 AVG Validation Loss:0.665 AVG Training Acc 62.37 % AVG Validation Acc 61.77 %\n",
      "Epoch:100/200 AVG Training Loss:0.640 AVG Validation Loss:0.665 AVG Training Acc 62.58 % AVG Validation Acc 61.77 %\n",
      "Epoch:110/200 AVG Training Loss:0.640 AVG Validation Loss:0.664 AVG Training Acc 62.29 % AVG Validation Acc 61.77 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.640 AVG Validation Loss:0.664 AVG Training Acc 62.61 % AVG Validation Acc 61.68 %\n",
      "Epoch:130/200 AVG Training Loss:0.639 AVG Validation Loss:0.664 AVG Training Acc 62.42 % AVG Validation Acc 61.77 %\n",
      "Epoch:140/200 AVG Training Loss:0.640 AVG Validation Loss:0.664 AVG Training Acc 62.45 % AVG Validation Acc 61.68 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.641 AVG Validation Loss:0.664 AVG Training Acc 62.27 % AVG Validation Acc 61.77 %\n",
      "Epoch:160/200 AVG Training Loss:0.639 AVG Validation Loss:0.664 AVG Training Acc 62.48 % AVG Validation Acc 61.77 %\n",
      "Epoch:170/200 AVG Training Loss:0.640 AVG Validation Loss:0.664 AVG Training Acc 62.34 % AVG Validation Acc 61.77 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.641 AVG Validation Loss:0.664 AVG Training Acc 62.35 % AVG Validation Acc 61.77 %\n",
      "Epoch:190/200 AVG Training Loss:0.639 AVG Validation Loss:0.664 AVG Training Acc 62.49 % AVG Validation Acc 61.68 %\n",
      "Epoch:200/200 AVG Training Loss:0.640 AVG Validation Loss:0.665 AVG Training Acc 62.37 % AVG Validation Acc 61.68 %\n",
      "Split 64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab257d37147449af9a4dcdc7ab3c3ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.655 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.654 AVG Training Acc 61.95 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.658 AVG Validation Loss:0.651 AVG Training Acc 61.88 % AVG Validation Acc 61.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.659 AVG Validation Loss:0.654 AVG Training Acc 61.84 % AVG Validation Acc 61.77 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.646 AVG Validation Loss:0.662 AVG Training Acc 62.18 % AVG Validation Acc 60.96 %\n",
      "Epoch:60/200 AVG Training Loss:0.642 AVG Validation Loss:0.662 AVG Training Acc 62.46 % AVG Validation Acc 60.41 %\n",
      "Epoch:70/200 AVG Training Loss:0.641 AVG Validation Loss:0.674 AVG Training Acc 62.41 % AVG Validation Acc 60.32 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.638 AVG Validation Loss:0.681 AVG Training Acc 62.52 % AVG Validation Acc 60.50 %\n",
      "Epoch:90/200 AVG Training Loss:0.635 AVG Validation Loss:0.681 AVG Training Acc 62.98 % AVG Validation Acc 60.50 %\n",
      "Epoch:100/200 AVG Training Loss:0.634 AVG Validation Loss:0.682 AVG Training Acc 62.61 % AVG Validation Acc 60.50 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.636 AVG Validation Loss:0.683 AVG Training Acc 62.48 % AVG Validation Acc 60.69 %\n",
      "Epoch:120/200 AVG Training Loss:0.634 AVG Validation Loss:0.682 AVG Training Acc 62.54 % AVG Validation Acc 60.60 %\n",
      "Epoch:130/200 AVG Training Loss:0.634 AVG Validation Loss:0.682 AVG Training Acc 62.59 % AVG Validation Acc 60.41 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.634 AVG Validation Loss:0.682 AVG Training Acc 62.74 % AVG Validation Acc 60.41 %\n",
      "Epoch:150/200 AVG Training Loss:0.634 AVG Validation Loss:0.683 AVG Training Acc 62.85 % AVG Validation Acc 60.23 %\n",
      "Epoch:160/200 AVG Training Loss:0.635 AVG Validation Loss:0.684 AVG Training Acc 62.71 % AVG Validation Acc 60.50 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.635 AVG Validation Loss:0.682 AVG Training Acc 62.71 % AVG Validation Acc 60.50 %\n",
      "Epoch:180/200 AVG Training Loss:0.635 AVG Validation Loss:0.685 AVG Training Acc 62.62 % AVG Validation Acc 60.41 %\n",
      "Epoch:190/200 AVG Training Loss:0.634 AVG Validation Loss:0.683 AVG Training Acc 62.97 % AVG Validation Acc 60.50 %\n",
      "Epoch:200/200 AVG Training Loss:0.635 AVG Validation Loss:0.683 AVG Training Acc 62.72 % AVG Validation Acc 60.60 %\n",
      "Epoch   200: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Split 65\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7de643ab132d441c8189b690216cdd6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.664 AVG Training Acc 61.94 % AVG Validation Acc 61.86 %\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.661 AVG Training Acc 61.92 % AVG Validation Acc 61.77 %\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.661 AVG Training Acc 62.01 % AVG Validation Acc 61.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.662 AVG Training Acc 62.05 % AVG Validation Acc 61.95 %\n",
      "Epoch:50/200 AVG Training Loss:0.649 AVG Validation Loss:0.660 AVG Training Acc 62.07 % AVG Validation Acc 62.04 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.645 AVG Validation Loss:0.663 AVG Training Acc 62.28 % AVG Validation Acc 61.95 %\n",
      "Epoch:70/200 AVG Training Loss:0.645 AVG Validation Loss:0.664 AVG Training Acc 62.13 % AVG Validation Acc 62.13 %\n",
      "Epoch:80/200 AVG Training Loss:0.646 AVG Validation Loss:0.664 AVG Training Acc 62.29 % AVG Validation Acc 62.04 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.643 AVG Validation Loss:0.665 AVG Training Acc 62.15 % AVG Validation Acc 62.04 %\n",
      "Epoch:100/200 AVG Training Loss:0.645 AVG Validation Loss:0.665 AVG Training Acc 62.33 % AVG Validation Acc 62.04 %\n",
      "Epoch:110/200 AVG Training Loss:0.642 AVG Validation Loss:0.665 AVG Training Acc 62.67 % AVG Validation Acc 62.04 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.644 AVG Validation Loss:0.665 AVG Training Acc 62.29 % AVG Validation Acc 62.13 %\n",
      "Epoch:130/200 AVG Training Loss:0.644 AVG Validation Loss:0.665 AVG Training Acc 62.37 % AVG Validation Acc 62.04 %\n",
      "Epoch:140/200 AVG Training Loss:0.644 AVG Validation Loss:0.665 AVG Training Acc 62.53 % AVG Validation Acc 62.13 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.644 AVG Validation Loss:0.665 AVG Training Acc 62.48 % AVG Validation Acc 62.13 %\n",
      "Epoch:160/200 AVG Training Loss:0.645 AVG Validation Loss:0.665 AVG Training Acc 62.23 % AVG Validation Acc 62.13 %\n",
      "Epoch:170/200 AVG Training Loss:0.642 AVG Validation Loss:0.665 AVG Training Acc 62.60 % AVG Validation Acc 62.04 %\n",
      "Epoch:180/200 AVG Training Loss:0.645 AVG Validation Loss:0.665 AVG Training Acc 62.15 % AVG Validation Acc 61.95 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.644 AVG Validation Loss:0.665 AVG Training Acc 62.46 % AVG Validation Acc 62.04 %\n",
      "Epoch:200/200 AVG Training Loss:0.644 AVG Validation Loss:0.665 AVG Training Acc 62.39 % AVG Validation Acc 62.04 %\n",
      "Split 66\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96433a620a434557bf6d871fd1769c60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.662 AVG Training Acc 61.77 % AVG Validation Acc 61.91 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.660 AVG Training Acc 61.91 % AVG Validation Acc 62.00 %\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.661 AVG Training Acc 61.94 % AVG Validation Acc 62.00 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.663 AVG Training Acc 61.97 % AVG Validation Acc 62.09 %\n",
      "Epoch:50/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 61.90 % AVG Validation Acc 62.09 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.646 AVG Validation Loss:0.669 AVG Training Acc 61.89 % AVG Validation Acc 62.09 %\n",
      "Epoch:70/200 AVG Training Loss:0.645 AVG Validation Loss:0.670 AVG Training Acc 61.94 % AVG Validation Acc 62.00 %\n",
      "Epoch:80/200 AVG Training Loss:0.644 AVG Validation Loss:0.671 AVG Training Acc 61.92 % AVG Validation Acc 62.00 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.645 AVG Validation Loss:0.671 AVG Training Acc 61.89 % AVG Validation Acc 62.00 %\n",
      "Epoch:100/200 AVG Training Loss:0.643 AVG Validation Loss:0.671 AVG Training Acc 62.04 % AVG Validation Acc 62.00 %\n",
      "Epoch:110/200 AVG Training Loss:0.643 AVG Validation Loss:0.671 AVG Training Acc 62.02 % AVG Validation Acc 62.00 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.643 AVG Validation Loss:0.671 AVG Training Acc 61.88 % AVG Validation Acc 62.00 %\n",
      "Epoch:130/200 AVG Training Loss:0.644 AVG Validation Loss:0.671 AVG Training Acc 61.73 % AVG Validation Acc 62.00 %\n",
      "Epoch:140/200 AVG Training Loss:0.644 AVG Validation Loss:0.671 AVG Training Acc 61.84 % AVG Validation Acc 62.00 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.643 AVG Validation Loss:0.671 AVG Training Acc 61.94 % AVG Validation Acc 62.00 %\n",
      "Epoch:160/200 AVG Training Loss:0.643 AVG Validation Loss:0.671 AVG Training Acc 62.06 % AVG Validation Acc 62.00 %\n",
      "Epoch:170/200 AVG Training Loss:0.644 AVG Validation Loss:0.672 AVG Training Acc 61.82 % AVG Validation Acc 62.00 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.645 AVG Validation Loss:0.671 AVG Training Acc 61.70 % AVG Validation Acc 62.00 %\n",
      "Epoch:190/200 AVG Training Loss:0.643 AVG Validation Loss:0.671 AVG Training Acc 61.86 % AVG Validation Acc 62.00 %\n",
      "Epoch:200/200 AVG Training Loss:0.644 AVG Validation Loss:0.671 AVG Training Acc 61.80 % AVG Validation Acc 62.00 %\n",
      "Split 67\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73b8355c1a1c45d89371182391d41097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.660 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.661 AVG Training Acc 61.86 % AVG Validation Acc 61.82 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.652 AVG Validation Loss:0.660 AVG Training Acc 61.97 % AVG Validation Acc 61.91 %\n",
      "Epoch:40/200 AVG Training Loss:0.646 AVG Validation Loss:0.672 AVG Training Acc 62.33 % AVG Validation Acc 61.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.641 AVG Validation Loss:0.674 AVG Training Acc 62.48 % AVG Validation Acc 61.37 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.637 AVG Validation Loss:0.680 AVG Training Acc 62.98 % AVG Validation Acc 60.74 %\n",
      "Epoch:70/200 AVG Training Loss:0.637 AVG Validation Loss:0.683 AVG Training Acc 62.50 % AVG Validation Acc 60.65 %\n",
      "Epoch:80/200 AVG Training Loss:0.635 AVG Validation Loss:0.684 AVG Training Acc 63.05 % AVG Validation Acc 60.29 %\n",
      "Epoch:90/200 AVG Training Loss:0.636 AVG Validation Loss:0.687 AVG Training Acc 63.00 % AVG Validation Acc 60.38 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.634 AVG Validation Loss:0.683 AVG Training Acc 62.67 % AVG Validation Acc 61.01 %\n",
      "Epoch:110/200 AVG Training Loss:0.635 AVG Validation Loss:0.686 AVG Training Acc 62.78 % AVG Validation Acc 60.47 %\n",
      "Epoch:120/200 AVG Training Loss:0.634 AVG Validation Loss:0.685 AVG Training Acc 62.91 % AVG Validation Acc 60.47 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.634 AVG Validation Loss:0.685 AVG Training Acc 62.83 % AVG Validation Acc 60.83 %\n",
      "Epoch:140/200 AVG Training Loss:0.634 AVG Validation Loss:0.684 AVG Training Acc 62.78 % AVG Validation Acc 60.92 %\n",
      "Epoch:150/200 AVG Training Loss:0.634 AVG Validation Loss:0.685 AVG Training Acc 62.87 % AVG Validation Acc 60.65 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.633 AVG Validation Loss:0.685 AVG Training Acc 63.09 % AVG Validation Acc 60.56 %\n",
      "Epoch:170/200 AVG Training Loss:0.635 AVG Validation Loss:0.685 AVG Training Acc 63.12 % AVG Validation Acc 60.74 %\n",
      "Epoch:180/200 AVG Training Loss:0.635 AVG Validation Loss:0.685 AVG Training Acc 62.74 % AVG Validation Acc 60.47 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.633 AVG Validation Loss:0.685 AVG Training Acc 63.06 % AVG Validation Acc 60.47 %\n",
      "Epoch:200/200 AVG Training Loss:0.634 AVG Validation Loss:0.685 AVG Training Acc 63.00 % AVG Validation Acc 61.01 %\n",
      "Split 68\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c0612cebd4436e8c3a0bbafc109515",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.667 AVG Training Acc 61.83 % AVG Validation Acc 61.82 %\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.666 AVG Training Acc 62.14 % AVG Validation Acc 61.73 %\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.666 AVG Training Acc 61.93 % AVG Validation Acc 61.73 %\n",
      "Epoch:40/200 AVG Training Loss:0.648 AVG Validation Loss:0.669 AVG Training Acc 61.95 % AVG Validation Acc 61.82 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.645 AVG Validation Loss:0.674 AVG Training Acc 62.12 % AVG Validation Acc 62.09 %\n",
      "Epoch:60/200 AVG Training Loss:0.644 AVG Validation Loss:0.675 AVG Training Acc 62.20 % AVG Validation Acc 61.91 %\n",
      "Epoch:70/200 AVG Training Loss:0.643 AVG Validation Loss:0.675 AVG Training Acc 62.45 % AVG Validation Acc 61.91 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.643 AVG Validation Loss:0.677 AVG Training Acc 62.11 % AVG Validation Acc 61.91 %\n",
      "Epoch:90/200 AVG Training Loss:0.643 AVG Validation Loss:0.678 AVG Training Acc 62.38 % AVG Validation Acc 61.91 %\n",
      "Epoch:100/200 AVG Training Loss:0.642 AVG Validation Loss:0.678 AVG Training Acc 62.23 % AVG Validation Acc 62.00 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.642 AVG Validation Loss:0.677 AVG Training Acc 62.52 % AVG Validation Acc 61.91 %\n",
      "Epoch:120/200 AVG Training Loss:0.643 AVG Validation Loss:0.677 AVG Training Acc 62.11 % AVG Validation Acc 61.82 %\n",
      "Epoch:130/200 AVG Training Loss:0.643 AVG Validation Loss:0.677 AVG Training Acc 61.95 % AVG Validation Acc 61.82 %\n",
      "Epoch:140/200 AVG Training Loss:0.644 AVG Validation Loss:0.677 AVG Training Acc 62.34 % AVG Validation Acc 61.82 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.643 AVG Validation Loss:0.677 AVG Training Acc 62.25 % AVG Validation Acc 62.00 %\n",
      "Epoch:160/200 AVG Training Loss:0.642 AVG Validation Loss:0.677 AVG Training Acc 62.23 % AVG Validation Acc 61.91 %\n",
      "Epoch:170/200 AVG Training Loss:0.642 AVG Validation Loss:0.677 AVG Training Acc 62.20 % AVG Validation Acc 61.82 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.643 AVG Validation Loss:0.678 AVG Training Acc 62.27 % AVG Validation Acc 61.82 %\n",
      "Epoch:190/200 AVG Training Loss:0.642 AVG Validation Loss:0.677 AVG Training Acc 62.16 % AVG Validation Acc 61.91 %\n",
      "Epoch:200/200 AVG Training Loss:0.642 AVG Validation Loss:0.677 AVG Training Acc 62.54 % AVG Validation Acc 61.73 %\n",
      "Split 69\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41070081c2544b42beafb163ee675964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.657 AVG Training Acc 61.82 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.655 AVG Training Acc 61.78 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.660 AVG Validation Loss:0.657 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.656 AVG Validation Loss:0.658 AVG Training Acc 61.97 % AVG Validation Acc 62.18 %\n",
      "Epoch:50/200 AVG Training Loss:0.652 AVG Validation Loss:0.660 AVG Training Acc 62.11 % AVG Validation Acc 62.09 %\n",
      "Epoch:60/200 AVG Training Loss:0.648 AVG Validation Loss:0.662 AVG Training Acc 62.01 % AVG Validation Acc 62.00 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.644 AVG Validation Loss:0.664 AVG Training Acc 62.14 % AVG Validation Acc 61.91 %\n",
      "Epoch:80/200 AVG Training Loss:0.644 AVG Validation Loss:0.665 AVG Training Acc 62.40 % AVG Validation Acc 61.73 %\n",
      "Epoch:90/200 AVG Training Loss:0.642 AVG Validation Loss:0.667 AVG Training Acc 62.42 % AVG Validation Acc 61.73 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.641 AVG Validation Loss:0.667 AVG Training Acc 62.48 % AVG Validation Acc 61.73 %\n",
      "Epoch:110/200 AVG Training Loss:0.642 AVG Validation Loss:0.666 AVG Training Acc 62.35 % AVG Validation Acc 61.73 %\n",
      "Epoch:120/200 AVG Training Loss:0.642 AVG Validation Loss:0.666 AVG Training Acc 62.41 % AVG Validation Acc 61.64 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.643 AVG Validation Loss:0.666 AVG Training Acc 62.15 % AVG Validation Acc 61.82 %\n",
      "Epoch:140/200 AVG Training Loss:0.641 AVG Validation Loss:0.666 AVG Training Acc 62.26 % AVG Validation Acc 61.91 %\n",
      "Epoch:150/200 AVG Training Loss:0.644 AVG Validation Loss:0.666 AVG Training Acc 62.12 % AVG Validation Acc 62.00 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.643 AVG Validation Loss:0.666 AVG Training Acc 62.25 % AVG Validation Acc 61.91 %\n",
      "Epoch:170/200 AVG Training Loss:0.643 AVG Validation Loss:0.667 AVG Training Acc 62.21 % AVG Validation Acc 61.91 %\n",
      "Epoch:180/200 AVG Training Loss:0.641 AVG Validation Loss:0.665 AVG Training Acc 62.36 % AVG Validation Acc 62.00 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.642 AVG Validation Loss:0.667 AVG Training Acc 62.53 % AVG Validation Acc 61.82 %\n",
      "Epoch:200/200 AVG Training Loss:0.643 AVG Validation Loss:0.666 AVG Training Acc 62.13 % AVG Validation Acc 61.82 %\n",
      "Split 70\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac1edd2c0be249efb3c0819fed61bd1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.663 AVG Training Acc 61.98 % AVG Validation Acc 61.91 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.656 AVG Validation Loss:0.660 AVG Training Acc 61.94 % AVG Validation Acc 61.82 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.661 AVG Training Acc 61.97 % AVG Validation Acc 61.82 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.659 AVG Training Acc 62.01 % AVG Validation Acc 61.64 %\n",
      "Epoch:50/200 AVG Training Loss:0.653 AVG Validation Loss:0.658 AVG Training Acc 62.22 % AVG Validation Acc 61.64 %\n",
      "Epoch:60/200 AVG Training Loss:0.651 AVG Validation Loss:0.660 AVG Training Acc 62.10 % AVG Validation Acc 61.73 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.650 AVG Validation Loss:0.663 AVG Training Acc 62.11 % AVG Validation Acc 61.64 %\n",
      "Epoch:80/200 AVG Training Loss:0.649 AVG Validation Loss:0.665 AVG Training Acc 62.01 % AVG Validation Acc 61.46 %\n",
      "Epoch:90/200 AVG Training Loss:0.648 AVG Validation Loss:0.665 AVG Training Acc 62.17 % AVG Validation Acc 61.46 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.648 AVG Validation Loss:0.665 AVG Training Acc 62.46 % AVG Validation Acc 61.55 %\n",
      "Epoch:110/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.12 % AVG Validation Acc 61.46 %\n",
      "Epoch:120/200 AVG Training Loss:0.647 AVG Validation Loss:0.664 AVG Training Acc 62.34 % AVG Validation Acc 61.46 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.648 AVG Validation Loss:0.665 AVG Training Acc 62.22 % AVG Validation Acc 61.46 %\n",
      "Epoch:140/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.08 % AVG Validation Acc 61.37 %\n",
      "Epoch:150/200 AVG Training Loss:0.648 AVG Validation Loss:0.665 AVG Training Acc 62.30 % AVG Validation Acc 61.46 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.648 AVG Validation Loss:0.665 AVG Training Acc 62.33 % AVG Validation Acc 61.46 %\n",
      "Epoch:170/200 AVG Training Loss:0.647 AVG Validation Loss:0.665 AVG Training Acc 62.29 % AVG Validation Acc 61.46 %\n",
      "Epoch:180/200 AVG Training Loss:0.649 AVG Validation Loss:0.665 AVG Training Acc 61.93 % AVG Validation Acc 61.55 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.647 AVG Validation Loss:0.665 AVG Training Acc 62.17 % AVG Validation Acc 61.37 %\n",
      "Epoch:200/200 AVG Training Loss:0.647 AVG Validation Loss:0.664 AVG Training Acc 62.49 % AVG Validation Acc 61.64 %\n",
      "Split 71\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba790b5f84c4b91a4b4263b1418a561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.656 AVG Training Acc 61.88 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.656 AVG Training Acc 61.93 % AVG Validation Acc 61.95 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.655 AVG Training Acc 61.98 % AVG Validation Acc 61.77 %\n",
      "Epoch:40/200 AVG Training Loss:0.655 AVG Validation Loss:0.655 AVG Training Acc 62.06 % AVG Validation Acc 61.77 %\n",
      "Epoch:50/200 AVG Training Loss:0.653 AVG Validation Loss:0.653 AVG Training Acc 62.03 % AVG Validation Acc 61.95 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.651 AVG Validation Loss:0.654 AVG Training Acc 62.17 % AVG Validation Acc 62.04 %\n",
      "Epoch:70/200 AVG Training Loss:0.650 AVG Validation Loss:0.654 AVG Training Acc 61.87 % AVG Validation Acc 62.04 %\n",
      "Epoch:80/200 AVG Training Loss:0.648 AVG Validation Loss:0.655 AVG Training Acc 62.24 % AVG Validation Acc 61.95 %\n",
      "Epoch:90/200 AVG Training Loss:0.648 AVG Validation Loss:0.656 AVG Training Acc 62.17 % AVG Validation Acc 61.86 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.647 AVG Validation Loss:0.655 AVG Training Acc 62.25 % AVG Validation Acc 61.86 %\n",
      "Epoch:110/200 AVG Training Loss:0.649 AVG Validation Loss:0.655 AVG Training Acc 62.02 % AVG Validation Acc 61.77 %\n",
      "Epoch:120/200 AVG Training Loss:0.648 AVG Validation Loss:0.656 AVG Training Acc 61.92 % AVG Validation Acc 61.77 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.647 AVG Validation Loss:0.656 AVG Training Acc 62.01 % AVG Validation Acc 61.77 %\n",
      "Epoch:140/200 AVG Training Loss:0.649 AVG Validation Loss:0.656 AVG Training Acc 61.93 % AVG Validation Acc 61.77 %\n",
      "Epoch:150/200 AVG Training Loss:0.648 AVG Validation Loss:0.655 AVG Training Acc 62.17 % AVG Validation Acc 61.77 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.648 AVG Validation Loss:0.656 AVG Training Acc 62.10 % AVG Validation Acc 61.77 %\n",
      "Epoch:170/200 AVG Training Loss:0.647 AVG Validation Loss:0.656 AVG Training Acc 62.09 % AVG Validation Acc 61.77 %\n",
      "Epoch:180/200 AVG Training Loss:0.648 AVG Validation Loss:0.655 AVG Training Acc 62.26 % AVG Validation Acc 61.77 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.647 AVG Validation Loss:0.656 AVG Training Acc 62.25 % AVG Validation Acc 61.77 %\n",
      "Epoch:200/200 AVG Training Loss:0.647 AVG Validation Loss:0.655 AVG Training Acc 62.13 % AVG Validation Acc 61.86 %\n",
      "Split 72\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98f9559c05b74eb4bc57787cd8b930a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.661 AVG Training Acc 61.88 % AVG Validation Acc 61.86 %\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.656 AVG Validation Loss:0.659 AVG Training Acc 61.92 % AVG Validation Acc 61.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.659 AVG Training Acc 61.96 % AVG Validation Acc 62.04 %\n",
      "Epoch:40/200 AVG Training Loss:0.654 AVG Validation Loss:0.659 AVG Training Acc 61.98 % AVG Validation Acc 61.86 %\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.652 AVG Validation Loss:0.661 AVG Training Acc 62.04 % AVG Validation Acc 61.77 %\n",
      "Epoch:60/200 AVG Training Loss:0.651 AVG Validation Loss:0.661 AVG Training Acc 62.21 % AVG Validation Acc 61.77 %\n",
      "Epoch:70/200 AVG Training Loss:0.650 AVG Validation Loss:0.662 AVG Training Acc 61.98 % AVG Validation Acc 61.86 %\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.651 AVG Validation Loss:0.663 AVG Training Acc 62.10 % AVG Validation Acc 61.77 %\n",
      "Epoch:90/200 AVG Training Loss:0.650 AVG Validation Loss:0.663 AVG Training Acc 62.19 % AVG Validation Acc 61.77 %\n",
      "Epoch:100/200 AVG Training Loss:0.650 AVG Validation Loss:0.663 AVG Training Acc 62.03 % AVG Validation Acc 61.77 %\n",
      "Epoch   106: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.650 AVG Validation Loss:0.663 AVG Training Acc 61.96 % AVG Validation Acc 61.77 %\n",
      "Epoch:120/200 AVG Training Loss:0.649 AVG Validation Loss:0.663 AVG Training Acc 62.10 % AVG Validation Acc 61.77 %\n",
      "Epoch:130/200 AVG Training Loss:0.650 AVG Validation Loss:0.663 AVG Training Acc 62.10 % AVG Validation Acc 61.77 %\n",
      "Epoch   137: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.650 AVG Validation Loss:0.663 AVG Training Acc 62.20 % AVG Validation Acc 61.77 %\n",
      "Epoch:150/200 AVG Training Loss:0.649 AVG Validation Loss:0.663 AVG Training Acc 62.23 % AVG Validation Acc 61.77 %\n",
      "Epoch:160/200 AVG Training Loss:0.650 AVG Validation Loss:0.663 AVG Training Acc 62.09 % AVG Validation Acc 61.77 %\n",
      "Epoch   168: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.649 AVG Validation Loss:0.663 AVG Training Acc 61.98 % AVG Validation Acc 61.77 %\n",
      "Epoch:180/200 AVG Training Loss:0.651 AVG Validation Loss:0.663 AVG Training Acc 62.06 % AVG Validation Acc 61.77 %\n",
      "Epoch:190/200 AVG Training Loss:0.650 AVG Validation Loss:0.663 AVG Training Acc 62.21 % AVG Validation Acc 61.77 %\n",
      "Epoch:200/200 AVG Training Loss:0.649 AVG Validation Loss:0.663 AVG Training Acc 62.09 % AVG Validation Acc 61.77 %\n",
      "Split 73\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6374749742684423bf87ab91ca5bba30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.662 AVG Training Acc 61.92 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.661 AVG Training Acc 61.87 % AVG Validation Acc 61.68 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.660 AVG Training Acc 61.99 % AVG Validation Acc 61.68 %\n",
      "Epoch:40/200 AVG Training Loss:0.650 AVG Validation Loss:0.661 AVG Training Acc 61.99 % AVG Validation Acc 61.59 %\n",
      "Epoch:50/200 AVG Training Loss:0.647 AVG Validation Loss:0.662 AVG Training Acc 62.18 % AVG Validation Acc 61.59 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.643 AVG Validation Loss:0.661 AVG Training Acc 62.35 % AVG Validation Acc 61.59 %\n",
      "Epoch:70/200 AVG Training Loss:0.643 AVG Validation Loss:0.661 AVG Training Acc 62.38 % AVG Validation Acc 61.50 %\n",
      "Epoch:80/200 AVG Training Loss:0.641 AVG Validation Loss:0.661 AVG Training Acc 62.33 % AVG Validation Acc 61.59 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.640 AVG Validation Loss:0.662 AVG Training Acc 62.41 % AVG Validation Acc 61.59 %\n",
      "Epoch:100/200 AVG Training Loss:0.641 AVG Validation Loss:0.662 AVG Training Acc 62.44 % AVG Validation Acc 61.68 %\n",
      "Epoch:110/200 AVG Training Loss:0.640 AVG Validation Loss:0.662 AVG Training Acc 62.45 % AVG Validation Acc 61.59 %\n",
      "Epoch:120/200 AVG Training Loss:0.640 AVG Validation Loss:0.662 AVG Training Acc 62.65 % AVG Validation Acc 61.41 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.639 AVG Validation Loss:0.662 AVG Training Acc 62.43 % AVG Validation Acc 61.68 %\n",
      "Epoch:140/200 AVG Training Loss:0.639 AVG Validation Loss:0.662 AVG Training Acc 62.49 % AVG Validation Acc 61.68 %\n",
      "Epoch:150/200 AVG Training Loss:0.639 AVG Validation Loss:0.661 AVG Training Acc 62.37 % AVG Validation Acc 61.59 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.640 AVG Validation Loss:0.661 AVG Training Acc 62.61 % AVG Validation Acc 61.59 %\n",
      "Epoch:170/200 AVG Training Loss:0.640 AVG Validation Loss:0.662 AVG Training Acc 62.47 % AVG Validation Acc 61.77 %\n",
      "Epoch:180/200 AVG Training Loss:0.640 AVG Validation Loss:0.662 AVG Training Acc 62.39 % AVG Validation Acc 61.77 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.640 AVG Validation Loss:0.662 AVG Training Acc 62.39 % AVG Validation Acc 61.77 %\n",
      "Epoch:200/200 AVG Training Loss:0.640 AVG Validation Loss:0.661 AVG Training Acc 62.53 % AVG Validation Acc 61.77 %\n",
      "Split 74\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ab3d6764fdb4b24be47f41ea32f7c6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.659 AVG Training Acc 61.85 % AVG Validation Acc 61.86 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.660 AVG Training Acc 61.81 % AVG Validation Acc 61.77 %\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.663 AVG Training Acc 61.87 % AVG Validation Acc 61.68 %\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.668 AVG Training Acc 62.05 % AVG Validation Acc 61.41 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 61.94 % AVG Validation Acc 61.68 %\n",
      "Epoch:60/200 AVG Training Loss:0.649 AVG Validation Loss:0.669 AVG Training Acc 61.81 % AVG Validation Acc 61.50 %\n",
      "Epoch:70/200 AVG Training Loss:0.648 AVG Validation Loss:0.669 AVG Training Acc 61.96 % AVG Validation Acc 61.23 %\n",
      "Epoch:80/200 AVG Training Loss:0.647 AVG Validation Loss:0.670 AVG Training Acc 62.12 % AVG Validation Acc 61.41 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.645 AVG Validation Loss:0.670 AVG Training Acc 62.52 % AVG Validation Acc 61.32 %\n",
      "Epoch:100/200 AVG Training Loss:0.646 AVG Validation Loss:0.671 AVG Training Acc 62.35 % AVG Validation Acc 61.32 %\n",
      "Epoch:110/200 AVG Training Loss:0.648 AVG Validation Loss:0.671 AVG Training Acc 62.07 % AVG Validation Acc 61.32 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.646 AVG Validation Loss:0.671 AVG Training Acc 62.26 % AVG Validation Acc 61.32 %\n",
      "Epoch:130/200 AVG Training Loss:0.647 AVG Validation Loss:0.670 AVG Training Acc 62.06 % AVG Validation Acc 61.41 %\n",
      "Epoch:140/200 AVG Training Loss:0.647 AVG Validation Loss:0.671 AVG Training Acc 62.25 % AVG Validation Acc 61.41 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.647 AVG Validation Loss:0.671 AVG Training Acc 62.31 % AVG Validation Acc 61.32 %\n",
      "Epoch:160/200 AVG Training Loss:0.647 AVG Validation Loss:0.671 AVG Training Acc 62.06 % AVG Validation Acc 61.32 %\n",
      "Epoch:170/200 AVG Training Loss:0.649 AVG Validation Loss:0.671 AVG Training Acc 61.82 % AVG Validation Acc 61.32 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.647 AVG Validation Loss:0.670 AVG Training Acc 62.25 % AVG Validation Acc 61.41 %\n",
      "Epoch:190/200 AVG Training Loss:0.647 AVG Validation Loss:0.671 AVG Training Acc 62.19 % AVG Validation Acc 61.32 %\n",
      "Epoch:200/200 AVG Training Loss:0.648 AVG Validation Loss:0.671 AVG Training Acc 62.32 % AVG Validation Acc 61.32 %\n",
      "Split 75\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ac002809d984cc0b441aacb41608d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.654 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.654 AVG Training Acc 61.63 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.658 AVG Validation Loss:0.657 AVG Training Acc 61.70 % AVG Validation Acc 61.77 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.647 AVG Validation Loss:0.666 AVG Training Acc 62.06 % AVG Validation Acc 60.96 %\n",
      "Epoch:50/200 AVG Training Loss:0.644 AVG Validation Loss:0.673 AVG Training Acc 62.45 % AVG Validation Acc 60.69 %\n",
      "Epoch:60/200 AVG Training Loss:0.639 AVG Validation Loss:0.683 AVG Training Acc 62.64 % AVG Validation Acc 60.87 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.637 AVG Validation Loss:0.685 AVG Training Acc 62.97 % AVG Validation Acc 61.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.636 AVG Validation Loss:0.686 AVG Training Acc 62.93 % AVG Validation Acc 61.23 %\n",
      "Epoch:90/200 AVG Training Loss:0.634 AVG Validation Loss:0.688 AVG Training Acc 62.90 % AVG Validation Acc 60.96 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.636 AVG Validation Loss:0.688 AVG Training Acc 62.97 % AVG Validation Acc 60.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.636 AVG Validation Loss:0.687 AVG Training Acc 62.92 % AVG Validation Acc 60.96 %\n",
      "Epoch:120/200 AVG Training Loss:0.635 AVG Validation Loss:0.687 AVG Training Acc 62.87 % AVG Validation Acc 61.14 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.634 AVG Validation Loss:0.687 AVG Training Acc 62.91 % AVG Validation Acc 61.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.635 AVG Validation Loss:0.688 AVG Training Acc 62.88 % AVG Validation Acc 60.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.636 AVG Validation Loss:0.687 AVG Training Acc 62.84 % AVG Validation Acc 61.05 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.635 AVG Validation Loss:0.689 AVG Training Acc 62.70 % AVG Validation Acc 61.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.635 AVG Validation Loss:0.688 AVG Training Acc 62.41 % AVG Validation Acc 60.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.634 AVG Validation Loss:0.689 AVG Training Acc 62.75 % AVG Validation Acc 61.32 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.634 AVG Validation Loss:0.688 AVG Training Acc 62.79 % AVG Validation Acc 61.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.636 AVG Validation Loss:0.688 AVG Training Acc 62.93 % AVG Validation Acc 61.14 %\n",
      "Split 76\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d773aae162f45fdad66421f23d227d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.662 AVG Training Acc 61.87 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 61.79 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.664 AVG Training Acc 61.84 % AVG Validation Acc 61.91 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.31 % AVG Validation Acc 61.82 %\n",
      "Epoch:50/200 AVG Training Loss:0.644 AVG Validation Loss:0.667 AVG Training Acc 62.07 % AVG Validation Acc 61.82 %\n",
      "Epoch:60/200 AVG Training Loss:0.638 AVG Validation Loss:0.671 AVG Training Acc 61.97 % AVG Validation Acc 61.64 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.632 AVG Validation Loss:0.681 AVG Training Acc 62.77 % AVG Validation Acc 60.47 %\n",
      "Epoch:80/200 AVG Training Loss:0.632 AVG Validation Loss:0.681 AVG Training Acc 62.56 % AVG Validation Acc 60.11 %\n",
      "Epoch:90/200 AVG Training Loss:0.631 AVG Validation Loss:0.685 AVG Training Acc 62.70 % AVG Validation Acc 59.75 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.631 AVG Validation Loss:0.686 AVG Training Acc 62.80 % AVG Validation Acc 59.84 %\n",
      "Epoch:110/200 AVG Training Loss:0.630 AVG Validation Loss:0.687 AVG Training Acc 62.60 % AVG Validation Acc 60.38 %\n",
      "Epoch:120/200 AVG Training Loss:0.629 AVG Validation Loss:0.685 AVG Training Acc 62.96 % AVG Validation Acc 60.02 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.629 AVG Validation Loss:0.687 AVG Training Acc 62.85 % AVG Validation Acc 59.93 %\n",
      "Epoch:140/200 AVG Training Loss:0.630 AVG Validation Loss:0.687 AVG Training Acc 63.07 % AVG Validation Acc 60.02 %\n",
      "Epoch:150/200 AVG Training Loss:0.629 AVG Validation Loss:0.687 AVG Training Acc 63.10 % AVG Validation Acc 59.84 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.631 AVG Validation Loss:0.685 AVG Training Acc 62.77 % AVG Validation Acc 60.11 %\n",
      "Epoch:170/200 AVG Training Loss:0.631 AVG Validation Loss:0.685 AVG Training Acc 63.15 % AVG Validation Acc 60.20 %\n",
      "Epoch:180/200 AVG Training Loss:0.629 AVG Validation Loss:0.687 AVG Training Acc 63.19 % AVG Validation Acc 60.11 %\n",
      "Epoch:190/200 AVG Training Loss:0.628 AVG Validation Loss:0.687 AVG Training Acc 62.81 % AVG Validation Acc 59.66 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.630 AVG Validation Loss:0.686 AVG Training Acc 62.71 % AVG Validation Acc 60.11 %\n",
      "Split 77\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b8e58ff05cf4a42857a583a950a0344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 61.87 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.661 AVG Training Acc 61.87 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.659 AVG Training Acc 61.70 % AVG Validation Acc 61.91 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.657 AVG Training Acc 61.96 % AVG Validation Acc 62.00 %\n",
      "Epoch:50/200 AVG Training Loss:0.652 AVG Validation Loss:0.659 AVG Training Acc 61.83 % AVG Validation Acc 61.91 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.637 AVG Validation Loss:0.659 AVG Training Acc 62.41 % AVG Validation Acc 61.55 %\n",
      "Epoch:70/200 AVG Training Loss:0.633 AVG Validation Loss:0.665 AVG Training Acc 62.72 % AVG Validation Acc 62.82 %\n",
      "New Best Accuracy found: 63.27%\n",
      "Epoch: 77\n",
      "New Best Accuracy found: 63.72%\n",
      "Epoch: 78\n",
      "Epoch:80/200 AVG Training Loss:0.628 AVG Validation Loss:0.671 AVG Training Acc 63.14 % AVG Validation Acc 62.45 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.626 AVG Validation Loss:0.674 AVG Training Acc 63.02 % AVG Validation Acc 62.27 %\n",
      "Epoch:100/200 AVG Training Loss:0.625 AVG Validation Loss:0.675 AVG Training Acc 63.19 % AVG Validation Acc 62.27 %\n",
      "Epoch:110/200 AVG Training Loss:0.623 AVG Validation Loss:0.673 AVG Training Acc 63.32 % AVG Validation Acc 62.00 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.621 AVG Validation Loss:0.670 AVG Training Acc 63.40 % AVG Validation Acc 62.36 %\n",
      "Epoch:130/200 AVG Training Loss:0.622 AVG Validation Loss:0.675 AVG Training Acc 63.60 % AVG Validation Acc 62.73 %\n",
      "Epoch:140/200 AVG Training Loss:0.622 AVG Validation Loss:0.678 AVG Training Acc 63.61 % AVG Validation Acc 62.45 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.622 AVG Validation Loss:0.677 AVG Training Acc 63.54 % AVG Validation Acc 62.18 %\n",
      "Epoch:160/200 AVG Training Loss:0.623 AVG Validation Loss:0.680 AVG Training Acc 63.25 % AVG Validation Acc 62.27 %\n",
      "Epoch:170/200 AVG Training Loss:0.623 AVG Validation Loss:0.677 AVG Training Acc 63.47 % AVG Validation Acc 62.82 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.622 AVG Validation Loss:0.674 AVG Training Acc 63.50 % AVG Validation Acc 62.18 %\n",
      "Epoch:190/200 AVG Training Loss:0.622 AVG Validation Loss:0.674 AVG Training Acc 63.78 % AVG Validation Acc 62.00 %\n",
      "Epoch:200/200 AVG Training Loss:0.621 AVG Validation Loss:0.669 AVG Training Acc 63.06 % AVG Validation Acc 62.91 %\n",
      "Split 78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47d139c0ff0e4cb1889a965a2fbf6a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.659 AVG Training Acc 61.95 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.658 AVG Training Acc 61.97 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.658 AVG Training Acc 61.87 % AVG Validation Acc 62.09 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.658 AVG Training Acc 62.02 % AVG Validation Acc 62.09 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.645 AVG Validation Loss:0.665 AVG Training Acc 62.54 % AVG Validation Acc 61.73 %\n",
      "Epoch:60/200 AVG Training Loss:0.640 AVG Validation Loss:0.667 AVG Training Acc 62.58 % AVG Validation Acc 61.46 %\n",
      "Epoch:70/200 AVG Training Loss:0.637 AVG Validation Loss:0.673 AVG Training Acc 62.84 % AVG Validation Acc 61.55 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.635 AVG Validation Loss:0.671 AVG Training Acc 62.77 % AVG Validation Acc 62.00 %\n",
      "Epoch:90/200 AVG Training Loss:0.635 AVG Validation Loss:0.674 AVG Training Acc 62.98 % AVG Validation Acc 61.46 %\n",
      "Epoch:100/200 AVG Training Loss:0.633 AVG Validation Loss:0.674 AVG Training Acc 63.28 % AVG Validation Acc 61.73 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.634 AVG Validation Loss:0.674 AVG Training Acc 63.17 % AVG Validation Acc 61.55 %\n",
      "Epoch:120/200 AVG Training Loss:0.633 AVG Validation Loss:0.673 AVG Training Acc 63.34 % AVG Validation Acc 61.64 %\n",
      "Epoch:130/200 AVG Training Loss:0.635 AVG Validation Loss:0.675 AVG Training Acc 62.96 % AVG Validation Acc 61.28 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.634 AVG Validation Loss:0.675 AVG Training Acc 63.32 % AVG Validation Acc 61.55 %\n",
      "Epoch:150/200 AVG Training Loss:0.632 AVG Validation Loss:0.674 AVG Training Acc 63.42 % AVG Validation Acc 61.82 %\n",
      "Epoch:160/200 AVG Training Loss:0.633 AVG Validation Loss:0.676 AVG Training Acc 62.91 % AVG Validation Acc 61.19 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.633 AVG Validation Loss:0.679 AVG Training Acc 63.22 % AVG Validation Acc 61.64 %\n",
      "Epoch:180/200 AVG Training Loss:0.632 AVG Validation Loss:0.674 AVG Training Acc 63.51 % AVG Validation Acc 62.00 %\n",
      "Epoch:190/200 AVG Training Loss:0.634 AVG Validation Loss:0.674 AVG Training Acc 63.35 % AVG Validation Acc 61.82 %\n",
      "Epoch   198: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.634 AVG Validation Loss:0.674 AVG Training Acc 63.19 % AVG Validation Acc 61.55 %\n",
      "Split 79\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d20149dcb940d7ac680c51f4c5b61a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.661 AVG Training Acc 61.85 % AVG Validation Acc 62.00 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.658 AVG Training Acc 61.80 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.664 AVG Training Acc 61.81 % AVG Validation Acc 61.82 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.647 AVG Validation Loss:0.665 AVG Training Acc 62.18 % AVG Validation Acc 61.37 %\n",
      "Epoch:50/200 AVG Training Loss:0.643 AVG Validation Loss:0.670 AVG Training Acc 62.10 % AVG Validation Acc 61.46 %\n",
      "Epoch:60/200 AVG Training Loss:0.639 AVG Validation Loss:0.674 AVG Training Acc 62.18 % AVG Validation Acc 61.28 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.636 AVG Validation Loss:0.677 AVG Training Acc 62.38 % AVG Validation Acc 61.19 %\n",
      "Epoch:80/200 AVG Training Loss:0.636 AVG Validation Loss:0.676 AVG Training Acc 62.29 % AVG Validation Acc 61.19 %\n",
      "Epoch:90/200 AVG Training Loss:0.634 AVG Validation Loss:0.676 AVG Training Acc 62.69 % AVG Validation Acc 61.28 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.634 AVG Validation Loss:0.675 AVG Training Acc 62.43 % AVG Validation Acc 61.19 %\n",
      "Epoch:110/200 AVG Training Loss:0.634 AVG Validation Loss:0.676 AVG Training Acc 62.42 % AVG Validation Acc 61.10 %\n",
      "Epoch:120/200 AVG Training Loss:0.633 AVG Validation Loss:0.675 AVG Training Acc 62.49 % AVG Validation Acc 61.37 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.633 AVG Validation Loss:0.677 AVG Training Acc 62.39 % AVG Validation Acc 61.28 %\n",
      "Epoch:140/200 AVG Training Loss:0.634 AVG Validation Loss:0.676 AVG Training Acc 62.60 % AVG Validation Acc 61.01 %\n",
      "Epoch:150/200 AVG Training Loss:0.634 AVG Validation Loss:0.677 AVG Training Acc 62.47 % AVG Validation Acc 61.10 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.633 AVG Validation Loss:0.676 AVG Training Acc 62.82 % AVG Validation Acc 61.19 %\n",
      "Epoch:170/200 AVG Training Loss:0.633 AVG Validation Loss:0.676 AVG Training Acc 62.52 % AVG Validation Acc 61.19 %\n",
      "Epoch:180/200 AVG Training Loss:0.633 AVG Validation Loss:0.676 AVG Training Acc 62.75 % AVG Validation Acc 61.10 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.634 AVG Validation Loss:0.676 AVG Training Acc 62.42 % AVG Validation Acc 61.19 %\n",
      "Epoch:200/200 AVG Training Loss:0.633 AVG Validation Loss:0.677 AVG Training Acc 62.58 % AVG Validation Acc 61.10 %\n",
      "Split 80\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1958d3cc0b6d452ba69d870133f43977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.665 AVG Training Acc 61.87 % AVG Validation Acc 62.00 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.661 AVG Training Acc 61.71 % AVG Validation Acc 62.00 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.660 AVG Training Acc 61.94 % AVG Validation Acc 61.91 %\n",
      "Epoch:40/200 AVG Training Loss:0.655 AVG Validation Loss:0.660 AVG Training Acc 62.00 % AVG Validation Acc 62.00 %\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.649 AVG Validation Loss:0.660 AVG Training Acc 62.17 % AVG Validation Acc 61.55 %\n",
      "Epoch:60/200 AVG Training Loss:0.644 AVG Validation Loss:0.661 AVG Training Acc 62.70 % AVG Validation Acc 61.82 %\n",
      "Epoch:70/200 AVG Training Loss:0.641 AVG Validation Loss:0.668 AVG Training Acc 62.50 % AVG Validation Acc 61.73 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.636 AVG Validation Loss:0.669 AVG Training Acc 62.79 % AVG Validation Acc 61.28 %\n",
      "Epoch:90/200 AVG Training Loss:0.638 AVG Validation Loss:0.670 AVG Training Acc 62.72 % AVG Validation Acc 61.37 %\n",
      "Epoch:100/200 AVG Training Loss:0.636 AVG Validation Loss:0.672 AVG Training Acc 63.17 % AVG Validation Acc 61.55 %\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.638 AVG Validation Loss:0.673 AVG Training Acc 62.82 % AVG Validation Acc 61.46 %\n",
      "Epoch:120/200 AVG Training Loss:0.636 AVG Validation Loss:0.672 AVG Training Acc 63.03 % AVG Validation Acc 61.46 %\n",
      "Epoch:130/200 AVG Training Loss:0.637 AVG Validation Loss:0.672 AVG Training Acc 62.83 % AVG Validation Acc 61.46 %\n",
      "Epoch   134: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.636 AVG Validation Loss:0.673 AVG Training Acc 62.55 % AVG Validation Acc 61.37 %\n",
      "Epoch:150/200 AVG Training Loss:0.636 AVG Validation Loss:0.672 AVG Training Acc 62.99 % AVG Validation Acc 61.55 %\n",
      "Epoch:160/200 AVG Training Loss:0.635 AVG Validation Loss:0.673 AVG Training Acc 63.54 % AVG Validation Acc 61.37 %\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.637 AVG Validation Loss:0.673 AVG Training Acc 62.86 % AVG Validation Acc 61.28 %\n",
      "Epoch:180/200 AVG Training Loss:0.636 AVG Validation Loss:0.673 AVG Training Acc 62.86 % AVG Validation Acc 61.82 %\n",
      "Epoch:190/200 AVG Training Loss:0.634 AVG Validation Loss:0.674 AVG Training Acc 63.15 % AVG Validation Acc 62.00 %\n",
      "Epoch   196: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.636 AVG Validation Loss:0.674 AVG Training Acc 63.29 % AVG Validation Acc 61.19 %\n",
      "Split 81\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa0a135c9a7416f9bd30399a790c30c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.654 AVG Training Acc 61.85 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.670 AVG Validation Loss:0.664 AVG Training Acc 61.41 % AVG Validation Acc 61.95 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.665 AVG Validation Loss:0.663 AVG Training Acc 61.91 % AVG Validation Acc 61.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.664 AVG Validation Loss:0.663 AVG Training Acc 61.88 % AVG Validation Acc 61.95 %\n",
      "Epoch:50/200 AVG Training Loss:0.663 AVG Validation Loss:0.662 AVG Training Acc 61.94 % AVG Validation Acc 61.95 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.663 AVG Validation Loss:0.664 AVG Training Acc 61.91 % AVG Validation Acc 61.95 %\n",
      "Epoch:70/200 AVG Training Loss:0.663 AVG Validation Loss:0.663 AVG Training Acc 61.88 % AVG Validation Acc 61.95 %\n",
      "Epoch:80/200 AVG Training Loss:0.662 AVG Validation Loss:0.663 AVG Training Acc 61.89 % AVG Validation Acc 61.95 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.662 AVG Validation Loss:0.663 AVG Training Acc 61.93 % AVG Validation Acc 61.95 %\n",
      "Epoch:100/200 AVG Training Loss:0.662 AVG Validation Loss:0.663 AVG Training Acc 61.92 % AVG Validation Acc 61.95 %\n",
      "Epoch:110/200 AVG Training Loss:0.661 AVG Validation Loss:0.664 AVG Training Acc 61.89 % AVG Validation Acc 61.95 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.662 AVG Validation Loss:0.664 AVG Training Acc 61.92 % AVG Validation Acc 61.95 %\n",
      "Epoch:130/200 AVG Training Loss:0.663 AVG Validation Loss:0.662 AVG Training Acc 61.87 % AVG Validation Acc 61.95 %\n",
      "Epoch:140/200 AVG Training Loss:0.662 AVG Validation Loss:0.663 AVG Training Acc 61.88 % AVG Validation Acc 61.95 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.663 AVG Validation Loss:0.663 AVG Training Acc 61.92 % AVG Validation Acc 61.95 %\n",
      "Epoch:160/200 AVG Training Loss:0.662 AVG Validation Loss:0.663 AVG Training Acc 61.90 % AVG Validation Acc 61.95 %\n",
      "Epoch:170/200 AVG Training Loss:0.663 AVG Validation Loss:0.663 AVG Training Acc 61.90 % AVG Validation Acc 61.95 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.662 AVG Validation Loss:0.664 AVG Training Acc 61.90 % AVG Validation Acc 61.95 %\n",
      "Epoch:190/200 AVG Training Loss:0.661 AVG Validation Loss:0.663 AVG Training Acc 61.91 % AVG Validation Acc 61.95 %\n",
      "Epoch:200/200 AVG Training Loss:0.662 AVG Validation Loss:0.662 AVG Training Acc 61.88 % AVG Validation Acc 61.95 %\n",
      "Split 82\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a89cb115ea489ea73aaec8cf8b1ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.658 AVG Training Acc 61.92 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.658 AVG Training Acc 61.84 % AVG Validation Acc 61.86 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.657 AVG Training Acc 61.79 % AVG Validation Acc 61.68 %\n",
      "Epoch:40/200 AVG Training Loss:0.655 AVG Validation Loss:0.657 AVG Training Acc 61.64 % AVG Validation Acc 61.77 %\n",
      "Epoch:50/200 AVG Training Loss:0.652 AVG Validation Loss:0.658 AVG Training Acc 61.94 % AVG Validation Acc 61.68 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.648 AVG Validation Loss:0.661 AVG Training Acc 62.23 % AVG Validation Acc 60.78 %\n",
      "Epoch:70/200 AVG Training Loss:0.646 AVG Validation Loss:0.660 AVG Training Acc 61.93 % AVG Validation Acc 60.78 %\n",
      "Epoch:80/200 AVG Training Loss:0.645 AVG Validation Loss:0.661 AVG Training Acc 62.01 % AVG Validation Acc 60.69 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.645 AVG Validation Loss:0.662 AVG Training Acc 62.01 % AVG Validation Acc 60.69 %\n",
      "Epoch:100/200 AVG Training Loss:0.646 AVG Validation Loss:0.661 AVG Training Acc 62.05 % AVG Validation Acc 60.69 %\n",
      "Epoch:110/200 AVG Training Loss:0.645 AVG Validation Loss:0.662 AVG Training Acc 61.84 % AVG Validation Acc 60.60 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.646 AVG Validation Loss:0.662 AVG Training Acc 61.88 % AVG Validation Acc 60.69 %\n",
      "Epoch:130/200 AVG Training Loss:0.646 AVG Validation Loss:0.662 AVG Training Acc 61.81 % AVG Validation Acc 60.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.647 AVG Validation Loss:0.661 AVG Training Acc 61.80 % AVG Validation Acc 60.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.646 AVG Validation Loss:0.661 AVG Training Acc 62.22 % AVG Validation Acc 60.78 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.646 AVG Validation Loss:0.661 AVG Training Acc 62.09 % AVG Validation Acc 60.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.647 AVG Validation Loss:0.662 AVG Training Acc 61.81 % AVG Validation Acc 60.78 %\n",
      "Epoch:180/200 AVG Training Loss:0.646 AVG Validation Loss:0.661 AVG Training Acc 62.18 % AVG Validation Acc 60.69 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.647 AVG Validation Loss:0.661 AVG Training Acc 62.01 % AVG Validation Acc 60.78 %\n",
      "Epoch:200/200 AVG Training Loss:0.646 AVG Validation Loss:0.661 AVG Training Acc 62.22 % AVG Validation Acc 60.78 %\n",
      "Split 83\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c98fab05c7cd41848baa8671f3c848b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.667 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.667 AVG Training Acc 61.96 % AVG Validation Acc 61.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.665 AVG Training Acc 61.83 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.668 AVG Training Acc 62.09 % AVG Validation Acc 61.86 %\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.645 AVG Validation Loss:0.675 AVG Training Acc 62.02 % AVG Validation Acc 61.68 %\n",
      "Epoch:60/200 AVG Training Loss:0.641 AVG Validation Loss:0.684 AVG Training Acc 62.37 % AVG Validation Acc 61.68 %\n",
      "Epoch:70/200 AVG Training Loss:0.638 AVG Validation Loss:0.693 AVG Training Acc 62.40 % AVG Validation Acc 61.59 %\n",
      "Epoch    71: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.636 AVG Validation Loss:0.693 AVG Training Acc 62.50 % AVG Validation Acc 61.68 %\n",
      "Epoch:90/200 AVG Training Loss:0.634 AVG Validation Loss:0.694 AVG Training Acc 62.62 % AVG Validation Acc 61.68 %\n",
      "Epoch:100/200 AVG Training Loss:0.633 AVG Validation Loss:0.693 AVG Training Acc 62.60 % AVG Validation Acc 61.77 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.634 AVG Validation Loss:0.692 AVG Training Acc 62.59 % AVG Validation Acc 61.68 %\n",
      "Epoch:120/200 AVG Training Loss:0.634 AVG Validation Loss:0.693 AVG Training Acc 62.57 % AVG Validation Acc 61.68 %\n",
      "Epoch:130/200 AVG Training Loss:0.634 AVG Validation Loss:0.695 AVG Training Acc 62.60 % AVG Validation Acc 61.68 %\n",
      "Epoch   133: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.634 AVG Validation Loss:0.694 AVG Training Acc 62.64 % AVG Validation Acc 61.59 %\n",
      "Epoch:150/200 AVG Training Loss:0.633 AVG Validation Loss:0.694 AVG Training Acc 62.54 % AVG Validation Acc 61.68 %\n",
      "Epoch:160/200 AVG Training Loss:0.634 AVG Validation Loss:0.694 AVG Training Acc 62.55 % AVG Validation Acc 61.77 %\n",
      "Epoch   164: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.633 AVG Validation Loss:0.695 AVG Training Acc 62.52 % AVG Validation Acc 61.68 %\n",
      "Epoch:180/200 AVG Training Loss:0.635 AVG Validation Loss:0.694 AVG Training Acc 62.61 % AVG Validation Acc 61.77 %\n",
      "Epoch:190/200 AVG Training Loss:0.635 AVG Validation Loss:0.692 AVG Training Acc 62.50 % AVG Validation Acc 61.68 %\n",
      "Epoch   195: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.633 AVG Validation Loss:0.694 AVG Training Acc 62.65 % AVG Validation Acc 61.59 %\n",
      "Split 84\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f43854a9498e4c6ca395089452b6767a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.660 AVG Training Acc 61.82 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.657 AVG Training Acc 61.92 % AVG Validation Acc 62.04 %\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.660 AVG Training Acc 61.89 % AVG Validation Acc 62.04 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.647 AVG Validation Loss:0.664 AVG Training Acc 62.04 % AVG Validation Acc 61.59 %\n",
      "Epoch:50/200 AVG Training Loss:0.642 AVG Validation Loss:0.668 AVG Training Acc 62.37 % AVG Validation Acc 60.96 %\n",
      "Epoch:60/200 AVG Training Loss:0.638 AVG Validation Loss:0.673 AVG Training Acc 62.59 % AVG Validation Acc 61.05 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.634 AVG Validation Loss:0.677 AVG Training Acc 62.66 % AVG Validation Acc 60.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.635 AVG Validation Loss:0.678 AVG Training Acc 62.92 % AVG Validation Acc 60.78 %\n",
      "Epoch:90/200 AVG Training Loss:0.633 AVG Validation Loss:0.679 AVG Training Acc 62.84 % AVG Validation Acc 60.87 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.632 AVG Validation Loss:0.679 AVG Training Acc 62.83 % AVG Validation Acc 61.32 %\n",
      "Epoch:110/200 AVG Training Loss:0.633 AVG Validation Loss:0.679 AVG Training Acc 62.87 % AVG Validation Acc 61.05 %\n",
      "Epoch:120/200 AVG Training Loss:0.633 AVG Validation Loss:0.679 AVG Training Acc 62.73 % AVG Validation Acc 60.87 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.633 AVG Validation Loss:0.681 AVG Training Acc 63.11 % AVG Validation Acc 61.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.632 AVG Validation Loss:0.680 AVG Training Acc 62.77 % AVG Validation Acc 61.05 %\n",
      "Epoch:150/200 AVG Training Loss:0.631 AVG Validation Loss:0.682 AVG Training Acc 63.22 % AVG Validation Acc 60.50 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.634 AVG Validation Loss:0.679 AVG Training Acc 62.99 % AVG Validation Acc 60.69 %\n",
      "Epoch:170/200 AVG Training Loss:0.633 AVG Validation Loss:0.678 AVG Training Acc 62.96 % AVG Validation Acc 60.87 %\n",
      "Epoch:180/200 AVG Training Loss:0.633 AVG Validation Loss:0.680 AVG Training Acc 62.88 % AVG Validation Acc 61.05 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.635 AVG Validation Loss:0.679 AVG Training Acc 62.84 % AVG Validation Acc 61.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.632 AVG Validation Loss:0.678 AVG Training Acc 63.08 % AVG Validation Acc 61.14 %\n",
      "Split 85\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd175d1fd0ad4ff3af5f42056deb3c4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 61.83 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.661 AVG Training Acc 61.83 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.662 AVG Training Acc 61.74 % AVG Validation Acc 62.04 %\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.649 AVG Validation Loss:0.659 AVG Training Acc 62.12 % AVG Validation Acc 61.95 %\n",
      "Epoch:50/200 AVG Training Loss:0.643 AVG Validation Loss:0.662 AVG Training Acc 62.32 % AVG Validation Acc 62.85 %\n",
      "Epoch:60/200 AVG Training Loss:0.639 AVG Validation Loss:0.659 AVG Training Acc 62.61 % AVG Validation Acc 62.85 %\n",
      "Epoch:70/200 AVG Training Loss:0.636 AVG Validation Loss:0.668 AVG Training Acc 62.24 % AVG Validation Acc 62.31 %\n",
      "Epoch    70: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.633 AVG Validation Loss:0.665 AVG Training Acc 62.13 % AVG Validation Acc 61.95 %\n",
      "Epoch:90/200 AVG Training Loss:0.632 AVG Validation Loss:0.664 AVG Training Acc 62.84 % AVG Validation Acc 61.77 %\n",
      "Epoch:100/200 AVG Training Loss:0.631 AVG Validation Loss:0.665 AVG Training Acc 62.67 % AVG Validation Acc 61.77 %\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.631 AVG Validation Loss:0.664 AVG Training Acc 62.75 % AVG Validation Acc 61.59 %\n",
      "Epoch:120/200 AVG Training Loss:0.632 AVG Validation Loss:0.665 AVG Training Acc 62.61 % AVG Validation Acc 61.95 %\n",
      "Epoch:130/200 AVG Training Loss:0.632 AVG Validation Loss:0.664 AVG Training Acc 62.57 % AVG Validation Acc 61.77 %\n",
      "Epoch   132: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.631 AVG Validation Loss:0.665 AVG Training Acc 63.16 % AVG Validation Acc 61.59 %\n",
      "Epoch:150/200 AVG Training Loss:0.631 AVG Validation Loss:0.667 AVG Training Acc 62.56 % AVG Validation Acc 61.50 %\n",
      "Epoch:160/200 AVG Training Loss:0.631 AVG Validation Loss:0.665 AVG Training Acc 62.90 % AVG Validation Acc 61.41 %\n",
      "Epoch   163: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.629 AVG Validation Loss:0.663 AVG Training Acc 63.02 % AVG Validation Acc 61.86 %\n",
      "Epoch:180/200 AVG Training Loss:0.629 AVG Validation Loss:0.666 AVG Training Acc 62.72 % AVG Validation Acc 61.32 %\n",
      "Epoch:190/200 AVG Training Loss:0.631 AVG Validation Loss:0.663 AVG Training Acc 62.54 % AVG Validation Acc 61.86 %\n",
      "Epoch   194: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.631 AVG Validation Loss:0.667 AVG Training Acc 62.57 % AVG Validation Acc 61.68 %\n",
      "Split 86\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c487324710334572adc53526e880abb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.659 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.659 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.656 AVG Training Acc 61.90 % AVG Validation Acc 61.73 %\n",
      "Epoch:40/200 AVG Training Loss:0.655 AVG Validation Loss:0.656 AVG Training Acc 61.93 % AVG Validation Acc 61.73 %\n",
      "Epoch:50/200 AVG Training Loss:0.654 AVG Validation Loss:0.657 AVG Training Acc 62.05 % AVG Validation Acc 61.82 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.652 AVG Validation Loss:0.657 AVG Training Acc 62.05 % AVG Validation Acc 61.55 %\n",
      "Epoch:70/200 AVG Training Loss:0.653 AVG Validation Loss:0.657 AVG Training Acc 62.10 % AVG Validation Acc 61.46 %\n",
      "Epoch:80/200 AVG Training Loss:0.653 AVG Validation Loss:0.657 AVG Training Acc 62.05 % AVG Validation Acc 61.46 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.652 AVG Validation Loss:0.657 AVG Training Acc 62.19 % AVG Validation Acc 61.37 %\n",
      "Epoch:100/200 AVG Training Loss:0.652 AVG Validation Loss:0.657 AVG Training Acc 62.17 % AVG Validation Acc 61.37 %\n",
      "Epoch:110/200 AVG Training Loss:0.653 AVG Validation Loss:0.657 AVG Training Acc 62.15 % AVG Validation Acc 61.46 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.653 AVG Validation Loss:0.657 AVG Training Acc 62.13 % AVG Validation Acc 61.37 %\n",
      "Epoch:130/200 AVG Training Loss:0.653 AVG Validation Loss:0.657 AVG Training Acc 62.12 % AVG Validation Acc 61.55 %\n",
      "Epoch:140/200 AVG Training Loss:0.653 AVG Validation Loss:0.657 AVG Training Acc 62.09 % AVG Validation Acc 61.55 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.653 AVG Validation Loss:0.657 AVG Training Acc 62.25 % AVG Validation Acc 61.55 %\n",
      "Epoch:160/200 AVG Training Loss:0.654 AVG Validation Loss:0.657 AVG Training Acc 62.20 % AVG Validation Acc 61.64 %\n",
      "Epoch:170/200 AVG Training Loss:0.653 AVG Validation Loss:0.657 AVG Training Acc 62.16 % AVG Validation Acc 61.46 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.653 AVG Validation Loss:0.657 AVG Training Acc 62.22 % AVG Validation Acc 61.46 %\n",
      "Epoch:190/200 AVG Training Loss:0.653 AVG Validation Loss:0.657 AVG Training Acc 62.12 % AVG Validation Acc 61.46 %\n",
      "Epoch:200/200 AVG Training Loss:0.653 AVG Validation Loss:0.657 AVG Training Acc 62.07 % AVG Validation Acc 61.37 %\n",
      "Split 87\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e0f70aaa034f12a3e4b6dc1d315735",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.663 AVG Training Acc 61.91 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.658 AVG Training Acc 61.79 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.660 AVG Training Acc 61.64 % AVG Validation Acc 62.36 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.644 AVG Validation Loss:0.664 AVG Training Acc 62.24 % AVG Validation Acc 62.00 %\n",
      "Epoch:50/200 AVG Training Loss:0.639 AVG Validation Loss:0.668 AVG Training Acc 62.59 % AVG Validation Acc 61.19 %\n",
      "Epoch:60/200 AVG Training Loss:0.637 AVG Validation Loss:0.670 AVG Training Acc 62.45 % AVG Validation Acc 61.37 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.634 AVG Validation Loss:0.673 AVG Training Acc 62.61 % AVG Validation Acc 61.19 %\n",
      "Epoch:80/200 AVG Training Loss:0.633 AVG Validation Loss:0.675 AVG Training Acc 62.88 % AVG Validation Acc 61.10 %\n",
      "Epoch:90/200 AVG Training Loss:0.632 AVG Validation Loss:0.675 AVG Training Acc 62.83 % AVG Validation Acc 61.28 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.632 AVG Validation Loss:0.677 AVG Training Acc 63.09 % AVG Validation Acc 60.92 %\n",
      "Epoch:110/200 AVG Training Loss:0.631 AVG Validation Loss:0.673 AVG Training Acc 63.13 % AVG Validation Acc 61.10 %\n",
      "Epoch:120/200 AVG Training Loss:0.632 AVG Validation Loss:0.675 AVG Training Acc 62.83 % AVG Validation Acc 61.01 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.632 AVG Validation Loss:0.677 AVG Training Acc 62.72 % AVG Validation Acc 60.83 %\n",
      "Epoch:140/200 AVG Training Loss:0.632 AVG Validation Loss:0.675 AVG Training Acc 62.92 % AVG Validation Acc 61.01 %\n",
      "Epoch:150/200 AVG Training Loss:0.632 AVG Validation Loss:0.679 AVG Training Acc 62.74 % AVG Validation Acc 60.92 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.630 AVG Validation Loss:0.674 AVG Training Acc 62.76 % AVG Validation Acc 61.37 %\n",
      "Epoch:170/200 AVG Training Loss:0.631 AVG Validation Loss:0.675 AVG Training Acc 63.18 % AVG Validation Acc 61.28 %\n",
      "Epoch:180/200 AVG Training Loss:0.630 AVG Validation Loss:0.674 AVG Training Acc 63.31 % AVG Validation Acc 61.19 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.633 AVG Validation Loss:0.676 AVG Training Acc 62.83 % AVG Validation Acc 61.10 %\n",
      "Epoch:200/200 AVG Training Loss:0.632 AVG Validation Loss:0.676 AVG Training Acc 62.81 % AVG Validation Acc 60.92 %\n",
      "Split 88\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "302a6c7c22884b4ba2aa55989ca31343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.659 AVG Training Acc 61.85 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.659 AVG Training Acc 61.95 % AVG Validation Acc 61.82 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.661 AVG Training Acc 61.77 % AVG Validation Acc 61.55 %\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.662 AVG Training Acc 62.04 % AVG Validation Acc 61.37 %\n",
      "Epoch:50/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 62.08 % AVG Validation Acc 61.28 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.645 AVG Validation Loss:0.669 AVG Training Acc 62.48 % AVG Validation Acc 61.28 %\n",
      "Epoch:70/200 AVG Training Loss:0.645 AVG Validation Loss:0.670 AVG Training Acc 62.45 % AVG Validation Acc 61.28 %\n",
      "Epoch:80/200 AVG Training Loss:0.645 AVG Validation Loss:0.671 AVG Training Acc 62.18 % AVG Validation Acc 61.10 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.645 AVG Validation Loss:0.669 AVG Training Acc 62.23 % AVG Validation Acc 61.37 %\n",
      "Epoch:100/200 AVG Training Loss:0.644 AVG Validation Loss:0.671 AVG Training Acc 62.24 % AVG Validation Acc 61.10 %\n",
      "Epoch:110/200 AVG Training Loss:0.644 AVG Validation Loss:0.670 AVG Training Acc 62.42 % AVG Validation Acc 61.28 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.643 AVG Validation Loss:0.671 AVG Training Acc 62.47 % AVG Validation Acc 61.01 %\n",
      "Epoch:130/200 AVG Training Loss:0.644 AVG Validation Loss:0.671 AVG Training Acc 62.37 % AVG Validation Acc 61.28 %\n",
      "Epoch:140/200 AVG Training Loss:0.644 AVG Validation Loss:0.671 AVG Training Acc 62.63 % AVG Validation Acc 61.19 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.644 AVG Validation Loss:0.670 AVG Training Acc 62.71 % AVG Validation Acc 61.01 %\n",
      "Epoch:160/200 AVG Training Loss:0.644 AVG Validation Loss:0.671 AVG Training Acc 62.28 % AVG Validation Acc 61.28 %\n",
      "Epoch:170/200 AVG Training Loss:0.645 AVG Validation Loss:0.672 AVG Training Acc 62.42 % AVG Validation Acc 61.19 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.645 AVG Validation Loss:0.671 AVG Training Acc 62.25 % AVG Validation Acc 61.19 %\n",
      "Epoch:190/200 AVG Training Loss:0.645 AVG Validation Loss:0.673 AVG Training Acc 62.28 % AVG Validation Acc 61.01 %\n",
      "Epoch:200/200 AVG Training Loss:0.645 AVG Validation Loss:0.673 AVG Training Acc 62.77 % AVG Validation Acc 61.01 %\n",
      "Split 89\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6d6c0d50494a31bd35ca63d9d66443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.663 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.664 AVG Training Acc 61.87 % AVG Validation Acc 61.91 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.666 AVG Training Acc 61.79 % AVG Validation Acc 62.09 %\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.675 AVG Training Acc 61.99 % AVG Validation Acc 62.00 %\n",
      "Epoch:50/200 AVG Training Loss:0.649 AVG Validation Loss:0.686 AVG Training Acc 61.95 % AVG Validation Acc 62.18 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.645 AVG Validation Loss:0.697 AVG Training Acc 62.03 % AVG Validation Acc 62.18 %\n",
      "Epoch:70/200 AVG Training Loss:0.645 AVG Validation Loss:0.696 AVG Training Acc 61.83 % AVG Validation Acc 62.00 %\n",
      "Epoch:80/200 AVG Training Loss:0.643 AVG Validation Loss:0.696 AVG Training Acc 62.02 % AVG Validation Acc 62.27 %\n",
      "Epoch:90/200 AVG Training Loss:0.643 AVG Validation Loss:0.699 AVG Training Acc 62.17 % AVG Validation Acc 62.09 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.644 AVG Validation Loss:0.698 AVG Training Acc 62.06 % AVG Validation Acc 62.27 %\n",
      "Epoch:110/200 AVG Training Loss:0.643 AVG Validation Loss:0.698 AVG Training Acc 62.01 % AVG Validation Acc 62.18 %\n",
      "Epoch:120/200 AVG Training Loss:0.643 AVG Validation Loss:0.699 AVG Training Acc 62.19 % AVG Validation Acc 62.09 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.643 AVG Validation Loss:0.698 AVG Training Acc 62.14 % AVG Validation Acc 62.09 %\n",
      "Epoch:140/200 AVG Training Loss:0.643 AVG Validation Loss:0.699 AVG Training Acc 61.98 % AVG Validation Acc 62.27 %\n",
      "Epoch:150/200 AVG Training Loss:0.644 AVG Validation Loss:0.699 AVG Training Acc 62.15 % AVG Validation Acc 62.27 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.643 AVG Validation Loss:0.699 AVG Training Acc 61.97 % AVG Validation Acc 62.36 %\n",
      "Epoch:170/200 AVG Training Loss:0.644 AVG Validation Loss:0.699 AVG Training Acc 62.06 % AVG Validation Acc 62.27 %\n",
      "Epoch:180/200 AVG Training Loss:0.644 AVG Validation Loss:0.698 AVG Training Acc 61.94 % AVG Validation Acc 62.18 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.643 AVG Validation Loss:0.698 AVG Training Acc 62.11 % AVG Validation Acc 62.36 %\n",
      "Epoch:200/200 AVG Training Loss:0.644 AVG Validation Loss:0.700 AVG Training Acc 61.73 % AVG Validation Acc 62.09 %\n",
      "Split 90\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13d2f18e50714a40bf6abab9ab273d7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.654 AVG Training Acc 61.83 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.654 AVG Training Acc 61.83 % AVG Validation Acc 61.91 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.653 AVG Training Acc 61.92 % AVG Validation Acc 62.00 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.654 AVG Training Acc 62.00 % AVG Validation Acc 61.55 %\n",
      "Epoch:50/200 AVG Training Loss:0.648 AVG Validation Loss:0.660 AVG Training Acc 62.13 % AVG Validation Acc 61.19 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.646 AVG Validation Loss:0.662 AVG Training Acc 62.10 % AVG Validation Acc 60.83 %\n",
      "Epoch:70/200 AVG Training Loss:0.645 AVG Validation Loss:0.663 AVG Training Acc 62.10 % AVG Validation Acc 60.83 %\n",
      "Epoch:80/200 AVG Training Loss:0.645 AVG Validation Loss:0.665 AVG Training Acc 62.38 % AVG Validation Acc 60.83 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.643 AVG Validation Loss:0.666 AVG Training Acc 62.52 % AVG Validation Acc 60.56 %\n",
      "Epoch:100/200 AVG Training Loss:0.643 AVG Validation Loss:0.666 AVG Training Acc 62.44 % AVG Validation Acc 60.65 %\n",
      "Epoch:110/200 AVG Training Loss:0.645 AVG Validation Loss:0.666 AVG Training Acc 62.33 % AVG Validation Acc 60.56 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.643 AVG Validation Loss:0.666 AVG Training Acc 62.23 % AVG Validation Acc 60.56 %\n",
      "Epoch:130/200 AVG Training Loss:0.644 AVG Validation Loss:0.666 AVG Training Acc 62.40 % AVG Validation Acc 60.56 %\n",
      "Epoch:140/200 AVG Training Loss:0.644 AVG Validation Loss:0.666 AVG Training Acc 62.37 % AVG Validation Acc 60.65 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.643 AVG Validation Loss:0.667 AVG Training Acc 62.39 % AVG Validation Acc 60.74 %\n",
      "Epoch:160/200 AVG Training Loss:0.644 AVG Validation Loss:0.667 AVG Training Acc 62.31 % AVG Validation Acc 60.56 %\n",
      "Epoch:170/200 AVG Training Loss:0.643 AVG Validation Loss:0.667 AVG Training Acc 62.49 % AVG Validation Acc 60.65 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.644 AVG Validation Loss:0.666 AVG Training Acc 62.21 % AVG Validation Acc 60.56 %\n",
      "Epoch:190/200 AVG Training Loss:0.643 AVG Validation Loss:0.666 AVG Training Acc 62.38 % AVG Validation Acc 60.65 %\n",
      "Epoch:200/200 AVG Training Loss:0.643 AVG Validation Loss:0.666 AVG Training Acc 62.28 % AVG Validation Acc 60.65 %\n",
      "Split 91\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3efcb1de3a4e2bb32770c30db18894",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.660 AVG Training Acc 61.85 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.662 AVG Validation Loss:0.659 AVG Training Acc 61.76 % AVG Validation Acc 62.04 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.659 AVG Training Acc 62.00 % AVG Validation Acc 62.04 %\n",
      "Epoch:40/200 AVG Training Loss:0.657 AVG Validation Loss:0.660 AVG Training Acc 62.01 % AVG Validation Acc 62.04 %\n",
      "Epoch:50/200 AVG Training Loss:0.655 AVG Validation Loss:0.660 AVG Training Acc 62.00 % AVG Validation Acc 61.86 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.654 AVG Validation Loss:0.659 AVG Training Acc 62.02 % AVG Validation Acc 61.77 %\n",
      "Epoch:70/200 AVG Training Loss:0.652 AVG Validation Loss:0.660 AVG Training Acc 62.07 % AVG Validation Acc 61.77 %\n",
      "Epoch:80/200 AVG Training Loss:0.653 AVG Validation Loss:0.661 AVG Training Acc 61.97 % AVG Validation Acc 61.86 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.653 AVG Validation Loss:0.660 AVG Training Acc 62.07 % AVG Validation Acc 61.77 %\n",
      "Epoch:100/200 AVG Training Loss:0.654 AVG Validation Loss:0.659 AVG Training Acc 61.95 % AVG Validation Acc 61.77 %\n",
      "Epoch:110/200 AVG Training Loss:0.652 AVG Validation Loss:0.661 AVG Training Acc 62.04 % AVG Validation Acc 61.77 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.653 AVG Validation Loss:0.659 AVG Training Acc 61.92 % AVG Validation Acc 61.77 %\n",
      "Epoch:130/200 AVG Training Loss:0.653 AVG Validation Loss:0.661 AVG Training Acc 62.23 % AVG Validation Acc 61.86 %\n",
      "Epoch:140/200 AVG Training Loss:0.652 AVG Validation Loss:0.659 AVG Training Acc 61.96 % AVG Validation Acc 61.77 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.652 AVG Validation Loss:0.660 AVG Training Acc 62.15 % AVG Validation Acc 61.68 %\n",
      "Epoch:160/200 AVG Training Loss:0.653 AVG Validation Loss:0.661 AVG Training Acc 61.96 % AVG Validation Acc 61.86 %\n",
      "Epoch:170/200 AVG Training Loss:0.652 AVG Validation Loss:0.660 AVG Training Acc 62.05 % AVG Validation Acc 61.86 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.653 AVG Validation Loss:0.660 AVG Training Acc 62.03 % AVG Validation Acc 61.86 %\n",
      "Epoch:190/200 AVG Training Loss:0.653 AVG Validation Loss:0.659 AVG Training Acc 62.17 % AVG Validation Acc 61.86 %\n",
      "Epoch:200/200 AVG Training Loss:0.653 AVG Validation Loss:0.660 AVG Training Acc 62.13 % AVG Validation Acc 61.68 %\n",
      "Split 92\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf8f4d7a71eb4ef4bc74596e776b980a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.659 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.660 AVG Training Acc 61.96 % AVG Validation Acc 61.95 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.658 AVG Training Acc 61.97 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.661 AVG Training Acc 62.02 % AVG Validation Acc 61.77 %\n",
      "Epoch:50/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 62.26 % AVG Validation Acc 61.68 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.644 AVG Validation Loss:0.667 AVG Training Acc 62.39 % AVG Validation Acc 61.77 %\n",
      "Epoch:70/200 AVG Training Loss:0.645 AVG Validation Loss:0.666 AVG Training Acc 62.15 % AVG Validation Acc 61.86 %\n",
      "Epoch:80/200 AVG Training Loss:0.644 AVG Validation Loss:0.668 AVG Training Acc 62.16 % AVG Validation Acc 61.77 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.643 AVG Validation Loss:0.668 AVG Training Acc 62.49 % AVG Validation Acc 61.68 %\n",
      "Epoch:100/200 AVG Training Loss:0.643 AVG Validation Loss:0.667 AVG Training Acc 62.12 % AVG Validation Acc 61.86 %\n",
      "Epoch:110/200 AVG Training Loss:0.642 AVG Validation Loss:0.667 AVG Training Acc 62.19 % AVG Validation Acc 61.95 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.642 AVG Validation Loss:0.668 AVG Training Acc 61.98 % AVG Validation Acc 61.68 %\n",
      "Epoch:130/200 AVG Training Loss:0.644 AVG Validation Loss:0.667 AVG Training Acc 62.29 % AVG Validation Acc 61.86 %\n",
      "Epoch:140/200 AVG Training Loss:0.643 AVG Validation Loss:0.668 AVG Training Acc 62.35 % AVG Validation Acc 61.68 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.643 AVG Validation Loss:0.668 AVG Training Acc 62.37 % AVG Validation Acc 61.68 %\n",
      "Epoch:160/200 AVG Training Loss:0.642 AVG Validation Loss:0.668 AVG Training Acc 62.40 % AVG Validation Acc 61.95 %\n",
      "Epoch:170/200 AVG Training Loss:0.643 AVG Validation Loss:0.668 AVG Training Acc 62.16 % AVG Validation Acc 61.86 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.645 AVG Validation Loss:0.668 AVG Training Acc 62.08 % AVG Validation Acc 61.95 %\n",
      "Epoch:190/200 AVG Training Loss:0.642 AVG Validation Loss:0.668 AVG Training Acc 62.36 % AVG Validation Acc 61.68 %\n",
      "Epoch:200/200 AVG Training Loss:0.643 AVG Validation Loss:0.667 AVG Training Acc 62.15 % AVG Validation Acc 61.86 %\n",
      "Split 93\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6f655e0cdcb4ffb84fd27f6d31033c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.660 AVG Training Acc 61.88 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.658 AVG Training Acc 61.89 % AVG Validation Acc 61.77 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.659 AVG Training Acc 62.00 % AVG Validation Acc 61.86 %\n",
      "Epoch:50/200 AVG Training Loss:0.648 AVG Validation Loss:0.658 AVG Training Acc 62.14 % AVG Validation Acc 61.68 %\n",
      "Epoch:60/200 AVG Training Loss:0.646 AVG Validation Loss:0.661 AVG Training Acc 62.22 % AVG Validation Acc 61.50 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.642 AVG Validation Loss:0.671 AVG Training Acc 62.69 % AVG Validation Acc 61.77 %\n",
      "Epoch:80/200 AVG Training Loss:0.640 AVG Validation Loss:0.671 AVG Training Acc 62.52 % AVG Validation Acc 61.77 %\n",
      "Epoch:90/200 AVG Training Loss:0.641 AVG Validation Loss:0.673 AVG Training Acc 62.57 % AVG Validation Acc 61.77 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.638 AVG Validation Loss:0.675 AVG Training Acc 62.78 % AVG Validation Acc 61.68 %\n",
      "Epoch:110/200 AVG Training Loss:0.640 AVG Validation Loss:0.674 AVG Training Acc 62.57 % AVG Validation Acc 61.68 %\n",
      "Epoch:120/200 AVG Training Loss:0.638 AVG Validation Loss:0.670 AVG Training Acc 62.72 % AVG Validation Acc 61.77 %\n",
      "Epoch:130/200 AVG Training Loss:0.638 AVG Validation Loss:0.674 AVG Training Acc 62.63 % AVG Validation Acc 61.68 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.639 AVG Validation Loss:0.673 AVG Training Acc 62.82 % AVG Validation Acc 61.59 %\n",
      "Epoch:150/200 AVG Training Loss:0.638 AVG Validation Loss:0.675 AVG Training Acc 62.72 % AVG Validation Acc 61.59 %\n",
      "Epoch:160/200 AVG Training Loss:0.638 AVG Validation Loss:0.675 AVG Training Acc 62.75 % AVG Validation Acc 61.59 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.637 AVG Validation Loss:0.676 AVG Training Acc 62.92 % AVG Validation Acc 61.59 %\n",
      "Epoch:180/200 AVG Training Loss:0.638 AVG Validation Loss:0.676 AVG Training Acc 62.86 % AVG Validation Acc 61.59 %\n",
      "Epoch:190/200 AVG Training Loss:0.638 AVG Validation Loss:0.674 AVG Training Acc 62.97 % AVG Validation Acc 61.59 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.639 AVG Validation Loss:0.674 AVG Training Acc 62.69 % AVG Validation Acc 61.68 %\n",
      "Split 94\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d2a8ac9392046f2aebcd9c35b609277",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.668 AVG Training Acc 61.87 % AVG Validation Acc 61.86 %\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:0.669 AVG Training Acc 61.93 % AVG Validation Acc 61.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.668 AVG Training Acc 62.04 % AVG Validation Acc 61.77 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.668 AVG Training Acc 61.99 % AVG Validation Acc 61.77 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.650 AVG Validation Loss:0.669 AVG Training Acc 62.20 % AVG Validation Acc 61.77 %\n",
      "Epoch:60/200 AVG Training Loss:0.649 AVG Validation Loss:0.670 AVG Training Acc 62.16 % AVG Validation Acc 61.41 %\n",
      "Epoch:70/200 AVG Training Loss:0.649 AVG Validation Loss:0.671 AVG Training Acc 62.44 % AVG Validation Acc 61.59 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.647 AVG Validation Loss:0.671 AVG Training Acc 62.14 % AVG Validation Acc 61.59 %\n",
      "Epoch:90/200 AVG Training Loss:0.647 AVG Validation Loss:0.671 AVG Training Acc 62.27 % AVG Validation Acc 61.50 %\n",
      "Epoch:100/200 AVG Training Loss:0.649 AVG Validation Loss:0.671 AVG Training Acc 62.28 % AVG Validation Acc 61.50 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.648 AVG Validation Loss:0.671 AVG Training Acc 62.39 % AVG Validation Acc 61.59 %\n",
      "Epoch:120/200 AVG Training Loss:0.647 AVG Validation Loss:0.672 AVG Training Acc 62.21 % AVG Validation Acc 61.59 %\n",
      "Epoch:130/200 AVG Training Loss:0.647 AVG Validation Loss:0.672 AVG Training Acc 62.27 % AVG Validation Acc 61.50 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.648 AVG Validation Loss:0.672 AVG Training Acc 62.22 % AVG Validation Acc 61.50 %\n",
      "Epoch:150/200 AVG Training Loss:0.647 AVG Validation Loss:0.672 AVG Training Acc 62.00 % AVG Validation Acc 61.68 %\n",
      "Epoch:160/200 AVG Training Loss:0.648 AVG Validation Loss:0.672 AVG Training Acc 62.14 % AVG Validation Acc 61.50 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.647 AVG Validation Loss:0.672 AVG Training Acc 62.16 % AVG Validation Acc 61.59 %\n",
      "Epoch:180/200 AVG Training Loss:0.647 AVG Validation Loss:0.671 AVG Training Acc 62.13 % AVG Validation Acc 61.50 %\n",
      "Epoch:190/200 AVG Training Loss:0.648 AVG Validation Loss:0.672 AVG Training Acc 62.19 % AVG Validation Acc 61.50 %\n",
      "Epoch:200/200 AVG Training Loss:0.647 AVG Validation Loss:0.671 AVG Training Acc 62.16 % AVG Validation Acc 61.50 %\n",
      "Split 95\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63e85786ec0e4923858b24e6eb9ec4f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.658 AVG Training Acc 61.79 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 61.83 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.659 AVG Training Acc 61.81 % AVG Validation Acc 61.77 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.649 AVG Validation Loss:0.660 AVG Training Acc 62.16 % AVG Validation Acc 61.77 %\n",
      "Epoch:50/200 AVG Training Loss:0.646 AVG Validation Loss:0.662 AVG Training Acc 62.46 % AVG Validation Acc 61.77 %\n",
      "Epoch:60/200 AVG Training Loss:0.642 AVG Validation Loss:0.665 AVG Training Acc 62.47 % AVG Validation Acc 61.68 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.640 AVG Validation Loss:0.663 AVG Training Acc 62.53 % AVG Validation Acc 61.77 %\n",
      "Epoch:80/200 AVG Training Loss:0.640 AVG Validation Loss:0.665 AVG Training Acc 62.63 % AVG Validation Acc 61.68 %\n",
      "Epoch:90/200 AVG Training Loss:0.640 AVG Validation Loss:0.666 AVG Training Acc 62.61 % AVG Validation Acc 61.59 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.639 AVG Validation Loss:0.666 AVG Training Acc 62.47 % AVG Validation Acc 61.23 %\n",
      "Epoch:110/200 AVG Training Loss:0.640 AVG Validation Loss:0.665 AVG Training Acc 62.58 % AVG Validation Acc 61.50 %\n",
      "Epoch:120/200 AVG Training Loss:0.639 AVG Validation Loss:0.666 AVG Training Acc 62.83 % AVG Validation Acc 61.32 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.640 AVG Validation Loss:0.667 AVG Training Acc 62.61 % AVG Validation Acc 61.50 %\n",
      "Epoch:140/200 AVG Training Loss:0.640 AVG Validation Loss:0.666 AVG Training Acc 62.75 % AVG Validation Acc 61.59 %\n",
      "Epoch:150/200 AVG Training Loss:0.639 AVG Validation Loss:0.666 AVG Training Acc 62.74 % AVG Validation Acc 61.23 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.640 AVG Validation Loss:0.666 AVG Training Acc 62.72 % AVG Validation Acc 61.50 %\n",
      "Epoch:170/200 AVG Training Loss:0.640 AVG Validation Loss:0.665 AVG Training Acc 62.84 % AVG Validation Acc 61.59 %\n",
      "Epoch:180/200 AVG Training Loss:0.640 AVG Validation Loss:0.665 AVG Training Acc 62.47 % AVG Validation Acc 61.68 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.640 AVG Validation Loss:0.665 AVG Training Acc 62.54 % AVG Validation Acc 61.50 %\n",
      "Epoch:200/200 AVG Training Loss:0.638 AVG Validation Loss:0.666 AVG Training Acc 62.72 % AVG Validation Acc 61.41 %\n",
      "Split 96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2544e1414ec149818e3dbf94dbe2a1d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.660 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 61.96 % AVG Validation Acc 62.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.661 AVG Training Acc 62.08 % AVG Validation Acc 61.91 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.647 AVG Validation Loss:0.666 AVG Training Acc 62.18 % AVG Validation Acc 62.18 %\n",
      "Epoch:50/200 AVG Training Loss:0.644 AVG Validation Loss:0.672 AVG Training Acc 62.22 % AVG Validation Acc 62.00 %\n",
      "Epoch:60/200 AVG Training Loss:0.641 AVG Validation Loss:0.676 AVG Training Acc 62.45 % AVG Validation Acc 62.00 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.637 AVG Validation Loss:0.678 AVG Training Acc 62.64 % AVG Validation Acc 62.09 %\n",
      "Epoch:80/200 AVG Training Loss:0.637 AVG Validation Loss:0.680 AVG Training Acc 62.30 % AVG Validation Acc 62.09 %\n",
      "Epoch:90/200 AVG Training Loss:0.636 AVG Validation Loss:0.680 AVG Training Acc 62.69 % AVG Validation Acc 61.91 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.637 AVG Validation Loss:0.681 AVG Training Acc 62.49 % AVG Validation Acc 61.82 %\n",
      "Epoch:110/200 AVG Training Loss:0.637 AVG Validation Loss:0.680 AVG Training Acc 62.53 % AVG Validation Acc 62.00 %\n",
      "Epoch:120/200 AVG Training Loss:0.637 AVG Validation Loss:0.681 AVG Training Acc 62.44 % AVG Validation Acc 62.09 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.635 AVG Validation Loss:0.680 AVG Training Acc 62.58 % AVG Validation Acc 62.00 %\n",
      "Epoch:140/200 AVG Training Loss:0.637 AVG Validation Loss:0.678 AVG Training Acc 62.48 % AVG Validation Acc 61.91 %\n",
      "Epoch:150/200 AVG Training Loss:0.636 AVG Validation Loss:0.679 AVG Training Acc 62.71 % AVG Validation Acc 61.91 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.637 AVG Validation Loss:0.681 AVG Training Acc 62.70 % AVG Validation Acc 61.82 %\n",
      "Epoch:170/200 AVG Training Loss:0.637 AVG Validation Loss:0.681 AVG Training Acc 62.44 % AVG Validation Acc 61.91 %\n",
      "Epoch:180/200 AVG Training Loss:0.637 AVG Validation Loss:0.682 AVG Training Acc 62.66 % AVG Validation Acc 61.91 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.637 AVG Validation Loss:0.680 AVG Training Acc 62.62 % AVG Validation Acc 62.00 %\n",
      "Epoch:200/200 AVG Training Loss:0.635 AVG Validation Loss:0.682 AVG Training Acc 62.72 % AVG Validation Acc 61.91 %\n",
      "Split 97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b59c415ef2e748439103565535bd0cd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.656 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.656 AVG Training Acc 61.94 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.657 AVG Training Acc 61.83 % AVG Validation Acc 61.82 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.654 AVG Training Acc 61.99 % AVG Validation Acc 61.64 %\n",
      "Epoch:50/200 AVG Training Loss:0.647 AVG Validation Loss:0.657 AVG Training Acc 62.30 % AVG Validation Acc 62.00 %\n",
      "Epoch:60/200 AVG Training Loss:0.644 AVG Validation Loss:0.661 AVG Training Acc 62.55 % AVG Validation Acc 61.73 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.642 AVG Validation Loss:0.662 AVG Training Acc 62.62 % AVG Validation Acc 60.92 %\n",
      "Epoch:80/200 AVG Training Loss:0.640 AVG Validation Loss:0.664 AVG Training Acc 62.69 % AVG Validation Acc 61.01 %\n",
      "Epoch:90/200 AVG Training Loss:0.641 AVG Validation Loss:0.663 AVG Training Acc 62.79 % AVG Validation Acc 60.74 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.640 AVG Validation Loss:0.664 AVG Training Acc 62.81 % AVG Validation Acc 61.10 %\n",
      "Epoch:110/200 AVG Training Loss:0.641 AVG Validation Loss:0.664 AVG Training Acc 62.84 % AVG Validation Acc 60.92 %\n",
      "Epoch:120/200 AVG Training Loss:0.640 AVG Validation Loss:0.664 AVG Training Acc 62.67 % AVG Validation Acc 61.10 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.640 AVG Validation Loss:0.664 AVG Training Acc 62.53 % AVG Validation Acc 61.10 %\n",
      "Epoch:140/200 AVG Training Loss:0.641 AVG Validation Loss:0.665 AVG Training Acc 62.42 % AVG Validation Acc 60.83 %\n",
      "Epoch:150/200 AVG Training Loss:0.641 AVG Validation Loss:0.664 AVG Training Acc 62.68 % AVG Validation Acc 61.28 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.641 AVG Validation Loss:0.665 AVG Training Acc 62.94 % AVG Validation Acc 60.92 %\n",
      "Epoch:170/200 AVG Training Loss:0.640 AVG Validation Loss:0.665 AVG Training Acc 62.60 % AVG Validation Acc 61.01 %\n",
      "Epoch:180/200 AVG Training Loss:0.641 AVG Validation Loss:0.664 AVG Training Acc 62.76 % AVG Validation Acc 61.19 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.639 AVG Validation Loss:0.665 AVG Training Acc 62.93 % AVG Validation Acc 61.28 %\n",
      "Epoch:200/200 AVG Training Loss:0.641 AVG Validation Loss:0.665 AVG Training Acc 62.67 % AVG Validation Acc 61.01 %\n",
      "Split 98\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "152f416fee3a4f86af6dfbbed35ad363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.661 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.660 AVG Training Acc 61.84 % AVG Validation Acc 62.18 %\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.659 AVG Training Acc 61.91 % AVG Validation Acc 62.00 %\n",
      "Epoch:40/200 AVG Training Loss:0.654 AVG Validation Loss:0.659 AVG Training Acc 62.01 % AVG Validation Acc 62.27 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.642 AVG Validation Loss:0.667 AVG Training Acc 62.33 % AVG Validation Acc 61.91 %\n",
      "Epoch:60/200 AVG Training Loss:0.639 AVG Validation Loss:0.672 AVG Training Acc 62.60 % AVG Validation Acc 61.64 %\n",
      "Epoch:70/200 AVG Training Loss:0.633 AVG Validation Loss:0.676 AVG Training Acc 62.87 % AVG Validation Acc 61.73 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.631 AVG Validation Loss:0.678 AVG Training Acc 63.12 % AVG Validation Acc 61.64 %\n",
      "Epoch:90/200 AVG Training Loss:0.629 AVG Validation Loss:0.680 AVG Training Acc 63.14 % AVG Validation Acc 61.73 %\n",
      "Epoch:100/200 AVG Training Loss:0.630 AVG Validation Loss:0.680 AVG Training Acc 63.16 % AVG Validation Acc 61.73 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.628 AVG Validation Loss:0.681 AVG Training Acc 63.16 % AVG Validation Acc 61.55 %\n",
      "Epoch:120/200 AVG Training Loss:0.628 AVG Validation Loss:0.680 AVG Training Acc 63.42 % AVG Validation Acc 61.64 %\n",
      "Epoch:130/200 AVG Training Loss:0.630 AVG Validation Loss:0.681 AVG Training Acc 63.21 % AVG Validation Acc 61.73 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.627 AVG Validation Loss:0.679 AVG Training Acc 63.34 % AVG Validation Acc 61.73 %\n",
      "Epoch:150/200 AVG Training Loss:0.628 AVG Validation Loss:0.679 AVG Training Acc 63.19 % AVG Validation Acc 61.73 %\n",
      "Epoch:160/200 AVG Training Loss:0.626 AVG Validation Loss:0.679 AVG Training Acc 63.57 % AVG Validation Acc 61.82 %\n",
      "Epoch:170/200 AVG Training Loss:0.627 AVG Validation Loss:0.681 AVG Training Acc 63.00 % AVG Validation Acc 61.73 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.627 AVG Validation Loss:0.681 AVG Training Acc 63.32 % AVG Validation Acc 61.55 %\n",
      "Epoch:190/200 AVG Training Loss:0.628 AVG Validation Loss:0.680 AVG Training Acc 63.31 % AVG Validation Acc 61.64 %\n",
      "Epoch:200/200 AVG Training Loss:0.627 AVG Validation Loss:0.680 AVG Training Acc 63.20 % AVG Validation Acc 61.73 %\n",
      "Split 99\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "063a1cea0b54404d9f6e50b5b8af063d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.662 AVG Validation Loss:0.656 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.660 AVG Training Acc 61.83 % AVG Validation Acc 61.82 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.652 AVG Validation Loss:0.656 AVG Training Acc 62.08 % AVG Validation Acc 61.82 %\n",
      "Epoch:40/200 AVG Training Loss:0.649 AVG Validation Loss:0.658 AVG Training Acc 62.06 % AVG Validation Acc 61.82 %\n",
      "Epoch:50/200 AVG Training Loss:0.648 AVG Validation Loss:0.658 AVG Training Acc 62.17 % AVG Validation Acc 61.73 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.646 AVG Validation Loss:0.659 AVG Training Acc 62.16 % AVG Validation Acc 61.73 %\n",
      "Epoch:70/200 AVG Training Loss:0.646 AVG Validation Loss:0.659 AVG Training Acc 62.18 % AVG Validation Acc 61.64 %\n",
      "Epoch:80/200 AVG Training Loss:0.646 AVG Validation Loss:0.660 AVG Training Acc 62.14 % AVG Validation Acc 61.64 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.645 AVG Validation Loss:0.660 AVG Training Acc 62.06 % AVG Validation Acc 61.64 %\n",
      "Epoch:100/200 AVG Training Loss:0.644 AVG Validation Loss:0.660 AVG Training Acc 62.22 % AVG Validation Acc 61.64 %\n",
      "Epoch:110/200 AVG Training Loss:0.646 AVG Validation Loss:0.660 AVG Training Acc 62.17 % AVG Validation Acc 61.64 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.644 AVG Validation Loss:0.659 AVG Training Acc 62.07 % AVG Validation Acc 61.64 %\n",
      "Epoch:130/200 AVG Training Loss:0.645 AVG Validation Loss:0.659 AVG Training Acc 62.12 % AVG Validation Acc 61.64 %\n",
      "Epoch:140/200 AVG Training Loss:0.645 AVG Validation Loss:0.659 AVG Training Acc 62.23 % AVG Validation Acc 61.64 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.646 AVG Validation Loss:0.660 AVG Training Acc 62.18 % AVG Validation Acc 61.64 %\n",
      "Epoch:160/200 AVG Training Loss:0.646 AVG Validation Loss:0.660 AVG Training Acc 62.24 % AVG Validation Acc 61.64 %\n",
      "Epoch:170/200 AVG Training Loss:0.644 AVG Validation Loss:0.660 AVG Training Acc 62.21 % AVG Validation Acc 61.64 %\n",
      "Epoch:180/200 AVG Training Loss:0.647 AVG Validation Loss:0.660 AVG Training Acc 62.08 % AVG Validation Acc 61.73 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.645 AVG Validation Loss:0.660 AVG Training Acc 62.13 % AVG Validation Acc 61.64 %\n",
      "Epoch:200/200 AVG Training Loss:0.645 AVG Validation Loss:0.660 AVG Training Acc 62.22 % AVG Validation Acc 61.64 %\n",
      "Split 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4540aa2aafb445d5ac8f5bf6eb2f3466",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 61.87 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.661 AVG Validation Loss:0.660 AVG Training Acc 61.81 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.660 AVG Validation Loss:0.661 AVG Training Acc 61.92 % AVG Validation Acc 61.82 %\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.657 AVG Validation Loss:0.661 AVG Training Acc 61.94 % AVG Validation Acc 61.73 %\n",
      "Epoch:50/200 AVG Training Loss:0.655 AVG Validation Loss:0.662 AVG Training Acc 62.02 % AVG Validation Acc 61.82 %\n",
      "Epoch:60/200 AVG Training Loss:0.653 AVG Validation Loss:0.663 AVG Training Acc 62.07 % AVG Validation Acc 61.82 %\n",
      "Epoch:70/200 AVG Training Loss:0.651 AVG Validation Loss:0.666 AVG Training Acc 62.13 % AVG Validation Acc 61.91 %\n",
      "Epoch    70: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.648 AVG Validation Loss:0.666 AVG Training Acc 62.10 % AVG Validation Acc 61.73 %\n",
      "Epoch:90/200 AVG Training Loss:0.648 AVG Validation Loss:0.666 AVG Training Acc 62.04 % AVG Validation Acc 61.64 %\n",
      "Epoch:100/200 AVG Training Loss:0.648 AVG Validation Loss:0.667 AVG Training Acc 62.23 % AVG Validation Acc 61.64 %\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.647 AVG Validation Loss:0.668 AVG Training Acc 62.29 % AVG Validation Acc 61.55 %\n",
      "Epoch:120/200 AVG Training Loss:0.648 AVG Validation Loss:0.667 AVG Training Acc 62.21 % AVG Validation Acc 61.64 %\n",
      "Epoch:130/200 AVG Training Loss:0.646 AVG Validation Loss:0.667 AVG Training Acc 62.50 % AVG Validation Acc 61.55 %\n",
      "Epoch   132: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.649 AVG Validation Loss:0.667 AVG Training Acc 61.95 % AVG Validation Acc 61.64 %\n",
      "Epoch:150/200 AVG Training Loss:0.647 AVG Validation Loss:0.668 AVG Training Acc 62.19 % AVG Validation Acc 61.64 %\n",
      "Epoch:160/200 AVG Training Loss:0.646 AVG Validation Loss:0.668 AVG Training Acc 62.03 % AVG Validation Acc 61.64 %\n",
      "Epoch   163: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.647 AVG Validation Loss:0.668 AVG Training Acc 62.28 % AVG Validation Acc 61.55 %\n",
      "Epoch:180/200 AVG Training Loss:0.648 AVG Validation Loss:0.667 AVG Training Acc 62.06 % AVG Validation Acc 61.55 %\n",
      "Epoch:190/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 62.15 % AVG Validation Acc 61.73 %\n",
      "Epoch   194: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.647 AVG Validation Loss:0.668 AVG Training Acc 62.40 % AVG Validation Acc 61.64 %\n",
      "Split 101\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "058f27da00c94df08a07f0e908d3212a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.662 AVG Validation Loss:0.656 AVG Training Acc 61.88 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.656 AVG Training Acc 61.95 % AVG Validation Acc 61.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.661 AVG Training Acc 61.97 % AVG Validation Acc 61.86 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.648 AVG Validation Loss:0.662 AVG Training Acc 62.23 % AVG Validation Acc 61.68 %\n",
      "Epoch:50/200 AVG Training Loss:0.644 AVG Validation Loss:0.665 AVG Training Acc 62.43 % AVG Validation Acc 61.59 %\n",
      "Epoch:60/200 AVG Training Loss:0.640 AVG Validation Loss:0.669 AVG Training Acc 62.49 % AVG Validation Acc 61.86 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.636 AVG Validation Loss:0.676 AVG Training Acc 62.87 % AVG Validation Acc 61.77 %\n",
      "Epoch:80/200 AVG Training Loss:0.635 AVG Validation Loss:0.677 AVG Training Acc 62.92 % AVG Validation Acc 61.77 %\n",
      "Epoch:90/200 AVG Training Loss:0.635 AVG Validation Loss:0.677 AVG Training Acc 62.73 % AVG Validation Acc 61.68 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.635 AVG Validation Loss:0.680 AVG Training Acc 62.72 % AVG Validation Acc 61.77 %\n",
      "Epoch:110/200 AVG Training Loss:0.635 AVG Validation Loss:0.679 AVG Training Acc 62.65 % AVG Validation Acc 61.77 %\n",
      "Epoch:120/200 AVG Training Loss:0.635 AVG Validation Loss:0.679 AVG Training Acc 62.88 % AVG Validation Acc 61.95 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.634 AVG Validation Loss:0.681 AVG Training Acc 62.72 % AVG Validation Acc 61.86 %\n",
      "Epoch:140/200 AVG Training Loss:0.634 AVG Validation Loss:0.679 AVG Training Acc 63.17 % AVG Validation Acc 61.77 %\n",
      "Epoch:150/200 AVG Training Loss:0.635 AVG Validation Loss:0.680 AVG Training Acc 62.66 % AVG Validation Acc 61.86 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.634 AVG Validation Loss:0.679 AVG Training Acc 62.89 % AVG Validation Acc 61.86 %\n",
      "Epoch:170/200 AVG Training Loss:0.635 AVG Validation Loss:0.680 AVG Training Acc 62.47 % AVG Validation Acc 61.77 %\n",
      "Epoch:180/200 AVG Training Loss:0.633 AVG Validation Loss:0.680 AVG Training Acc 63.12 % AVG Validation Acc 61.86 %\n",
      "Epoch:190/200 AVG Training Loss:0.634 AVG Validation Loss:0.679 AVG Training Acc 62.71 % AVG Validation Acc 61.77 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.635 AVG Validation Loss:0.680 AVG Training Acc 63.07 % AVG Validation Acc 61.77 %\n",
      "Split 102\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a81e8bcae5a143c3a1914d2e224751df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.660 AVG Training Acc 61.84 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.659 AVG Training Acc 61.93 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.658 AVG Validation Loss:0.659 AVG Training Acc 61.91 % AVG Validation Acc 61.77 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.658 AVG Training Acc 61.97 % AVG Validation Acc 61.86 %\n",
      "Epoch:50/200 AVG Training Loss:0.651 AVG Validation Loss:0.660 AVG Training Acc 62.04 % AVG Validation Acc 61.77 %\n",
      "Epoch:60/200 AVG Training Loss:0.649 AVG Validation Loss:0.661 AVG Training Acc 62.08 % AVG Validation Acc 61.68 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.649 AVG Validation Loss:0.662 AVG Training Acc 62.26 % AVG Validation Acc 61.59 %\n",
      "Epoch:80/200 AVG Training Loss:0.648 AVG Validation Loss:0.662 AVG Training Acc 62.07 % AVG Validation Acc 61.59 %\n",
      "Epoch:90/200 AVG Training Loss:0.646 AVG Validation Loss:0.662 AVG Training Acc 62.09 % AVG Validation Acc 61.50 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.648 AVG Validation Loss:0.663 AVG Training Acc 62.23 % AVG Validation Acc 61.50 %\n",
      "Epoch:110/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 62.08 % AVG Validation Acc 61.50 %\n",
      "Epoch:120/200 AVG Training Loss:0.646 AVG Validation Loss:0.663 AVG Training Acc 62.27 % AVG Validation Acc 61.50 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 62.39 % AVG Validation Acc 61.50 %\n",
      "Epoch:140/200 AVG Training Loss:0.646 AVG Validation Loss:0.662 AVG Training Acc 62.03 % AVG Validation Acc 61.50 %\n",
      "Epoch:150/200 AVG Training Loss:0.646 AVG Validation Loss:0.662 AVG Training Acc 62.25 % AVG Validation Acc 61.50 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 62.32 % AVG Validation Acc 61.50 %\n",
      "Epoch:170/200 AVG Training Loss:0.646 AVG Validation Loss:0.663 AVG Training Acc 62.16 % AVG Validation Acc 61.50 %\n",
      "Epoch:180/200 AVG Training Loss:0.646 AVG Validation Loss:0.663 AVG Training Acc 62.22 % AVG Validation Acc 61.59 %\n",
      "Epoch:190/200 AVG Training Loss:0.646 AVG Validation Loss:0.663 AVG Training Acc 62.36 % AVG Validation Acc 61.50 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 62.09 % AVG Validation Acc 61.59 %\n",
      "Split 103\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a485d13af3fd4c05b30f1e9410f5a98f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.662 AVG Training Acc 61.74 % AVG Validation Acc 61.86 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.656 AVG Validation Loss:0.662 AVG Training Acc 61.92 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.665 AVG Training Acc 61.95 % AVG Validation Acc 61.77 %\n",
      "Epoch:40/200 AVG Training Loss:0.650 AVG Validation Loss:0.666 AVG Training Acc 61.96 % AVG Validation Acc 61.14 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.646 AVG Validation Loss:0.670 AVG Training Acc 62.43 % AVG Validation Acc 60.60 %\n",
      "Epoch:60/200 AVG Training Loss:0.645 AVG Validation Loss:0.671 AVG Training Acc 62.07 % AVG Validation Acc 60.69 %\n",
      "Epoch:70/200 AVG Training Loss:0.644 AVG Validation Loss:0.671 AVG Training Acc 62.27 % AVG Validation Acc 60.60 %\n",
      "Epoch:80/200 AVG Training Loss:0.643 AVG Validation Loss:0.673 AVG Training Acc 62.33 % AVG Validation Acc 60.50 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.643 AVG Validation Loss:0.673 AVG Training Acc 62.21 % AVG Validation Acc 60.41 %\n",
      "Epoch:100/200 AVG Training Loss:0.643 AVG Validation Loss:0.674 AVG Training Acc 62.54 % AVG Validation Acc 60.23 %\n",
      "Epoch:110/200 AVG Training Loss:0.643 AVG Validation Loss:0.675 AVG Training Acc 62.49 % AVG Validation Acc 60.41 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.643 AVG Validation Loss:0.673 AVG Training Acc 62.30 % AVG Validation Acc 60.23 %\n",
      "Epoch:130/200 AVG Training Loss:0.642 AVG Validation Loss:0.674 AVG Training Acc 62.62 % AVG Validation Acc 60.60 %\n",
      "Epoch:140/200 AVG Training Loss:0.642 AVG Validation Loss:0.674 AVG Training Acc 62.17 % AVG Validation Acc 60.32 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.644 AVG Validation Loss:0.674 AVG Training Acc 62.32 % AVG Validation Acc 60.50 %\n",
      "Epoch:160/200 AVG Training Loss:0.642 AVG Validation Loss:0.674 AVG Training Acc 62.55 % AVG Validation Acc 60.41 %\n",
      "Epoch:170/200 AVG Training Loss:0.642 AVG Validation Loss:0.674 AVG Training Acc 62.67 % AVG Validation Acc 60.32 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.642 AVG Validation Loss:0.673 AVG Training Acc 62.37 % AVG Validation Acc 60.41 %\n",
      "Epoch:190/200 AVG Training Loss:0.643 AVG Validation Loss:0.673 AVG Training Acc 62.46 % AVG Validation Acc 60.41 %\n",
      "Epoch:200/200 AVG Training Loss:0.642 AVG Validation Loss:0.674 AVG Training Acc 62.63 % AVG Validation Acc 60.41 %\n",
      "Split 104\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ffb6927642042f0a14b26d785709280",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.660 AVG Training Acc 61.94 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.660 AVG Training Acc 61.75 % AVG Validation Acc 61.86 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.650 AVG Validation Loss:0.665 AVG Training Acc 62.37 % AVG Validation Acc 61.50 %\n",
      "Epoch:40/200 AVG Training Loss:0.644 AVG Validation Loss:0.674 AVG Training Acc 62.42 % AVG Validation Acc 61.41 %\n",
      "Epoch:50/200 AVG Training Loss:0.639 AVG Validation Loss:0.678 AVG Training Acc 62.07 % AVG Validation Acc 61.05 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.634 AVG Validation Loss:0.679 AVG Training Acc 62.65 % AVG Validation Acc 60.87 %\n",
      "Epoch:70/200 AVG Training Loss:0.632 AVG Validation Loss:0.681 AVG Training Acc 62.86 % AVG Validation Acc 61.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.633 AVG Validation Loss:0.681 AVG Training Acc 62.80 % AVG Validation Acc 61.32 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.632 AVG Validation Loss:0.688 AVG Training Acc 62.97 % AVG Validation Acc 61.05 %\n",
      "Epoch:100/200 AVG Training Loss:0.631 AVG Validation Loss:0.684 AVG Training Acc 62.89 % AVG Validation Acc 60.96 %\n",
      "Epoch:110/200 AVG Training Loss:0.631 AVG Validation Loss:0.686 AVG Training Acc 62.91 % AVG Validation Acc 61.05 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.633 AVG Validation Loss:0.686 AVG Training Acc 62.79 % AVG Validation Acc 61.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.632 AVG Validation Loss:0.689 AVG Training Acc 62.94 % AVG Validation Acc 60.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.632 AVG Validation Loss:0.685 AVG Training Acc 62.93 % AVG Validation Acc 60.96 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.631 AVG Validation Loss:0.687 AVG Training Acc 63.05 % AVG Validation Acc 60.78 %\n",
      "Epoch:160/200 AVG Training Loss:0.631 AVG Validation Loss:0.684 AVG Training Acc 62.74 % AVG Validation Acc 61.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.631 AVG Validation Loss:0.684 AVG Training Acc 63.01 % AVG Validation Acc 61.14 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.632 AVG Validation Loss:0.686 AVG Training Acc 62.85 % AVG Validation Acc 61.05 %\n",
      "Epoch:190/200 AVG Training Loss:0.631 AVG Validation Loss:0.686 AVG Training Acc 62.74 % AVG Validation Acc 61.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.631 AVG Validation Loss:0.686 AVG Training Acc 62.97 % AVG Validation Acc 60.96 %\n",
      "Split 105\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92bc32c9a9c942faa4244bcdfde19a46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.660 AVG Training Acc 61.87 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.660 AVG Training Acc 61.92 % AVG Validation Acc 61.95 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.660 AVG Training Acc 62.00 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.660 AVG Training Acc 62.00 % AVG Validation Acc 61.86 %\n",
      "Epoch:50/200 AVG Training Loss:0.653 AVG Validation Loss:0.659 AVG Training Acc 62.05 % AVG Validation Acc 61.95 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.650 AVG Validation Loss:0.661 AVG Training Acc 62.18 % AVG Validation Acc 61.95 %\n",
      "Epoch:70/200 AVG Training Loss:0.647 AVG Validation Loss:0.664 AVG Training Acc 62.14 % AVG Validation Acc 62.04 %\n",
      "Epoch:80/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.22 % AVG Validation Acc 62.04 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.648 AVG Validation Loss:0.665 AVG Training Acc 62.25 % AVG Validation Acc 61.95 %\n",
      "Epoch:100/200 AVG Training Loss:0.647 AVG Validation Loss:0.665 AVG Training Acc 62.30 % AVG Validation Acc 61.95 %\n",
      "Epoch:110/200 AVG Training Loss:0.648 AVG Validation Loss:0.665 AVG Training Acc 62.28 % AVG Validation Acc 61.95 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.648 AVG Validation Loss:0.665 AVG Training Acc 62.22 % AVG Validation Acc 61.95 %\n",
      "Epoch:130/200 AVG Training Loss:0.646 AVG Validation Loss:0.665 AVG Training Acc 62.34 % AVG Validation Acc 61.95 %\n",
      "Epoch:140/200 AVG Training Loss:0.647 AVG Validation Loss:0.665 AVG Training Acc 62.28 % AVG Validation Acc 61.95 %\n",
      "Epoch:150/200 AVG Training Loss:0.649 AVG Validation Loss:0.665 AVG Training Acc 62.23 % AVG Validation Acc 61.95 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.648 AVG Validation Loss:0.665 AVG Training Acc 62.26 % AVG Validation Acc 61.95 %\n",
      "Epoch:170/200 AVG Training Loss:0.648 AVG Validation Loss:0.665 AVG Training Acc 62.23 % AVG Validation Acc 61.95 %\n",
      "Epoch:180/200 AVG Training Loss:0.647 AVG Validation Loss:0.665 AVG Training Acc 62.22 % AVG Validation Acc 61.95 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.648 AVG Validation Loss:0.666 AVG Training Acc 62.20 % AVG Validation Acc 61.95 %\n",
      "Epoch:200/200 AVG Training Loss:0.647 AVG Validation Loss:0.666 AVG Training Acc 62.32 % AVG Validation Acc 61.95 %\n",
      "Split 106\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7164ca7178c49dfac3ec2bf1d893a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.660 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.663 AVG Training Acc 62.00 % AVG Validation Acc 61.82 %\n",
      "Epoch:30/200 AVG Training Loss:0.651 AVG Validation Loss:0.666 AVG Training Acc 62.06 % AVG Validation Acc 61.73 %\n",
      "Epoch:40/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 61.95 % AVG Validation Acc 61.64 %\n",
      "Epoch:50/200 AVG Training Loss:0.645 AVG Validation Loss:0.671 AVG Training Acc 62.18 % AVG Validation Acc 61.55 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.642 AVG Validation Loss:0.674 AVG Training Acc 62.24 % AVG Validation Acc 61.37 %\n",
      "Epoch:70/200 AVG Training Loss:0.642 AVG Validation Loss:0.676 AVG Training Acc 62.19 % AVG Validation Acc 60.74 %\n",
      "Epoch:80/200 AVG Training Loss:0.641 AVG Validation Loss:0.678 AVG Training Acc 62.42 % AVG Validation Acc 60.83 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.640 AVG Validation Loss:0.679 AVG Training Acc 62.76 % AVG Validation Acc 60.65 %\n",
      "Epoch:100/200 AVG Training Loss:0.641 AVG Validation Loss:0.682 AVG Training Acc 62.53 % AVG Validation Acc 60.74 %\n",
      "Epoch:110/200 AVG Training Loss:0.641 AVG Validation Loss:0.685 AVG Training Acc 62.40 % AVG Validation Acc 60.56 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.641 AVG Validation Loss:0.679 AVG Training Acc 62.56 % AVG Validation Acc 60.74 %\n",
      "Epoch:130/200 AVG Training Loss:0.640 AVG Validation Loss:0.682 AVG Training Acc 62.47 % AVG Validation Acc 60.74 %\n",
      "Epoch:140/200 AVG Training Loss:0.640 AVG Validation Loss:0.680 AVG Training Acc 62.49 % AVG Validation Acc 60.56 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.641 AVG Validation Loss:0.678 AVG Training Acc 62.42 % AVG Validation Acc 60.56 %\n",
      "Epoch:160/200 AVG Training Loss:0.640 AVG Validation Loss:0.678 AVG Training Acc 62.58 % AVG Validation Acc 60.65 %\n",
      "Epoch:170/200 AVG Training Loss:0.640 AVG Validation Loss:0.678 AVG Training Acc 62.32 % AVG Validation Acc 60.92 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.640 AVG Validation Loss:0.678 AVG Training Acc 62.60 % AVG Validation Acc 60.74 %\n",
      "Epoch:190/200 AVG Training Loss:0.639 AVG Validation Loss:0.682 AVG Training Acc 62.57 % AVG Validation Acc 60.74 %\n",
      "Epoch:200/200 AVG Training Loss:0.640 AVG Validation Loss:0.679 AVG Training Acc 62.32 % AVG Validation Acc 60.56 %\n",
      "Split 107\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff7674000d0c48b78e36f3a54368e3c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.658 AVG Training Acc 61.84 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.657 AVG Training Acc 61.86 % AVG Validation Acc 61.82 %\n",
      "Epoch:30/200 AVG Training Loss:0.658 AVG Validation Loss:0.656 AVG Training Acc 61.95 % AVG Validation Acc 61.82 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.655 AVG Training Acc 61.85 % AVG Validation Acc 61.73 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.646 AVG Validation Loss:0.659 AVG Training Acc 62.43 % AVG Validation Acc 61.28 %\n",
      "Epoch:60/200 AVG Training Loss:0.638 AVG Validation Loss:0.666 AVG Training Acc 62.56 % AVG Validation Acc 61.64 %\n",
      "Epoch:70/200 AVG Training Loss:0.632 AVG Validation Loss:0.670 AVG Training Acc 63.35 % AVG Validation Acc 61.10 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.629 AVG Validation Loss:0.668 AVG Training Acc 63.31 % AVG Validation Acc 60.83 %\n",
      "Epoch:90/200 AVG Training Loss:0.626 AVG Validation Loss:0.672 AVG Training Acc 63.48 % AVG Validation Acc 60.83 %\n",
      "Epoch:100/200 AVG Training Loss:0.626 AVG Validation Loss:0.672 AVG Training Acc 63.14 % AVG Validation Acc 60.83 %\n",
      "Epoch:110/200 AVG Training Loss:0.624 AVG Validation Loss:0.673 AVG Training Acc 63.46 % AVG Validation Acc 60.56 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.624 AVG Validation Loss:0.672 AVG Training Acc 63.18 % AVG Validation Acc 60.83 %\n",
      "Epoch:130/200 AVG Training Loss:0.626 AVG Validation Loss:0.676 AVG Training Acc 62.76 % AVG Validation Acc 60.74 %\n",
      "Epoch:140/200 AVG Training Loss:0.627 AVG Validation Loss:0.671 AVG Training Acc 63.50 % AVG Validation Acc 60.56 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.627 AVG Validation Loss:0.677 AVG Training Acc 63.20 % AVG Validation Acc 60.74 %\n",
      "Epoch:160/200 AVG Training Loss:0.623 AVG Validation Loss:0.674 AVG Training Acc 63.60 % AVG Validation Acc 60.74 %\n",
      "Epoch:170/200 AVG Training Loss:0.627 AVG Validation Loss:0.673 AVG Training Acc 63.66 % AVG Validation Acc 60.74 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.626 AVG Validation Loss:0.672 AVG Training Acc 63.24 % AVG Validation Acc 60.47 %\n",
      "Epoch:190/200 AVG Training Loss:0.625 AVG Validation Loss:0.678 AVG Training Acc 63.59 % AVG Validation Acc 60.56 %\n",
      "Epoch:200/200 AVG Training Loss:0.626 AVG Validation Loss:0.673 AVG Training Acc 63.09 % AVG Validation Acc 60.65 %\n",
      "Split 108\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47ea8f33b36045309e8e6df18cc49a11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.658 AVG Training Acc 61.85 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.658 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.659 AVG Validation Loss:0.655 AVG Training Acc 61.83 % AVG Validation Acc 62.00 %\n",
      "Epoch:40/200 AVG Training Loss:0.655 AVG Validation Loss:0.657 AVG Training Acc 61.95 % AVG Validation Acc 62.45 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.643 AVG Validation Loss:0.664 AVG Training Acc 62.47 % AVG Validation Acc 62.00 %\n",
      "Epoch:60/200 AVG Training Loss:0.635 AVG Validation Loss:0.669 AVG Training Acc 62.80 % AVG Validation Acc 62.91 %\n",
      "Epoch:70/200 AVG Training Loss:0.633 AVG Validation Loss:0.679 AVG Training Acc 63.31 % AVG Validation Acc 62.45 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.626 AVG Validation Loss:0.682 AVG Training Acc 63.95 % AVG Validation Acc 62.09 %\n",
      "Epoch:90/200 AVG Training Loss:0.626 AVG Validation Loss:0.683 AVG Training Acc 63.97 % AVG Validation Acc 61.82 %\n",
      "Epoch:100/200 AVG Training Loss:0.624 AVG Validation Loss:0.685 AVG Training Acc 64.54 % AVG Validation Acc 62.73 %\n",
      "Epoch:110/200 AVG Training Loss:0.624 AVG Validation Loss:0.686 AVG Training Acc 64.01 % AVG Validation Acc 61.82 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.623 AVG Validation Loss:0.684 AVG Training Acc 64.09 % AVG Validation Acc 62.27 %\n",
      "Epoch:130/200 AVG Training Loss:0.623 AVG Validation Loss:0.685 AVG Training Acc 64.26 % AVG Validation Acc 61.82 %\n",
      "Epoch:140/200 AVG Training Loss:0.623 AVG Validation Loss:0.685 AVG Training Acc 63.67 % AVG Validation Acc 61.82 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.624 AVG Validation Loss:0.686 AVG Training Acc 64.21 % AVG Validation Acc 61.82 %\n",
      "Epoch:160/200 AVG Training Loss:0.623 AVG Validation Loss:0.686 AVG Training Acc 64.50 % AVG Validation Acc 61.82 %\n",
      "Epoch:170/200 AVG Training Loss:0.624 AVG Validation Loss:0.685 AVG Training Acc 64.19 % AVG Validation Acc 62.45 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.624 AVG Validation Loss:0.685 AVG Training Acc 64.16 % AVG Validation Acc 62.09 %\n",
      "Epoch:190/200 AVG Training Loss:0.623 AVG Validation Loss:0.687 AVG Training Acc 64.16 % AVG Validation Acc 62.00 %\n",
      "Epoch:200/200 AVG Training Loss:0.623 AVG Validation Loss:0.685 AVG Training Acc 64.42 % AVG Validation Acc 61.73 %\n",
      "Split 109\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bacc7dd527d54762a09ba4a1354768ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.659 AVG Training Acc 61.87 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.662 AVG Training Acc 62.01 % AVG Validation Acc 61.73 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.662 AVG Training Acc 61.93 % AVG Validation Acc 61.73 %\n",
      "Epoch:40/200 AVG Training Loss:0.656 AVG Validation Loss:0.662 AVG Training Acc 61.89 % AVG Validation Acc 61.64 %\n",
      "Epoch:50/200 AVG Training Loss:0.654 AVG Validation Loss:0.663 AVG Training Acc 61.85 % AVG Validation Acc 61.64 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.654 AVG Validation Loss:0.663 AVG Training Acc 61.90 % AVG Validation Acc 61.64 %\n",
      "Epoch:70/200 AVG Training Loss:0.653 AVG Validation Loss:0.663 AVG Training Acc 61.94 % AVG Validation Acc 61.64 %\n",
      "Epoch:80/200 AVG Training Loss:0.652 AVG Validation Loss:0.663 AVG Training Acc 62.00 % AVG Validation Acc 61.64 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.652 AVG Validation Loss:0.663 AVG Training Acc 61.92 % AVG Validation Acc 61.64 %\n",
      "Epoch:100/200 AVG Training Loss:0.653 AVG Validation Loss:0.663 AVG Training Acc 62.07 % AVG Validation Acc 61.64 %\n",
      "Epoch:110/200 AVG Training Loss:0.652 AVG Validation Loss:0.663 AVG Training Acc 62.07 % AVG Validation Acc 61.55 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.652 AVG Validation Loss:0.663 AVG Training Acc 62.07 % AVG Validation Acc 61.55 %\n",
      "Epoch:130/200 AVG Training Loss:0.652 AVG Validation Loss:0.663 AVG Training Acc 61.86 % AVG Validation Acc 61.55 %\n",
      "Epoch:140/200 AVG Training Loss:0.653 AVG Validation Loss:0.663 AVG Training Acc 62.13 % AVG Validation Acc 61.55 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.653 AVG Validation Loss:0.663 AVG Training Acc 62.06 % AVG Validation Acc 61.55 %\n",
      "Epoch:160/200 AVG Training Loss:0.652 AVG Validation Loss:0.663 AVG Training Acc 62.09 % AVG Validation Acc 61.55 %\n",
      "Epoch:170/200 AVG Training Loss:0.653 AVG Validation Loss:0.663 AVG Training Acc 61.96 % AVG Validation Acc 61.55 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.652 AVG Validation Loss:0.663 AVG Training Acc 61.96 % AVG Validation Acc 61.55 %\n",
      "Epoch:190/200 AVG Training Loss:0.652 AVG Validation Loss:0.663 AVG Training Acc 62.11 % AVG Validation Acc 61.55 %\n",
      "Epoch:200/200 AVG Training Loss:0.652 AVG Validation Loss:0.663 AVG Training Acc 62.17 % AVG Validation Acc 61.55 %\n",
      "Split 110\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58b1440532c2467b81defac269b9c872",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.663 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.656 AVG Validation Loss:0.663 AVG Training Acc 61.92 % AVG Validation Acc 62.00 %\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.663 AVG Training Acc 62.01 % AVG Validation Acc 61.64 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.663 AVG Training Acc 61.93 % AVG Validation Acc 61.73 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.650 AVG Validation Loss:0.663 AVG Training Acc 61.83 % AVG Validation Acc 61.73 %\n",
      "Epoch:60/200 AVG Training Loss:0.649 AVG Validation Loss:0.663 AVG Training Acc 62.11 % AVG Validation Acc 61.73 %\n",
      "Epoch:70/200 AVG Training Loss:0.650 AVG Validation Loss:0.663 AVG Training Acc 62.15 % AVG Validation Acc 61.73 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.16 % AVG Validation Acc 61.73 %\n",
      "Epoch:90/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.05 % AVG Validation Acc 61.64 %\n",
      "Epoch:100/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 61.78 % AVG Validation Acc 61.64 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.04 % AVG Validation Acc 61.73 %\n",
      "Epoch:120/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.03 % AVG Validation Acc 61.73 %\n",
      "Epoch:130/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.07 % AVG Validation Acc 61.73 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.24 % AVG Validation Acc 61.73 %\n",
      "Epoch:150/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.31 % AVG Validation Acc 61.64 %\n",
      "Epoch:160/200 AVG Training Loss:0.649 AVG Validation Loss:0.663 AVG Training Acc 62.11 % AVG Validation Acc 61.73 %\n",
      "Epoch:170/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.25 % AVG Validation Acc 61.73 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.09 % AVG Validation Acc 61.64 %\n",
      "Epoch:190/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.27 % AVG Validation Acc 61.64 %\n",
      "Epoch:200/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.08 % AVG Validation Acc 61.73 %\n",
      "Split 111\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cb6e5b0fca94963a69a17da68086348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 61.82 % AVG Validation Acc 61.95 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.656 AVG Validation Loss:0.660 AVG Training Acc 61.89 % AVG Validation Acc 61.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.660 AVG Training Acc 61.93 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.661 AVG Training Acc 62.00 % AVG Validation Acc 62.13 %\n",
      "Epoch:50/200 AVG Training Loss:0.648 AVG Validation Loss:0.666 AVG Training Acc 62.30 % AVG Validation Acc 62.22 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 62.18 % AVG Validation Acc 62.22 %\n",
      "Epoch:70/200 AVG Training Loss:0.646 AVG Validation Loss:0.667 AVG Training Acc 62.18 % AVG Validation Acc 62.31 %\n",
      "Epoch:80/200 AVG Training Loss:0.648 AVG Validation Loss:0.667 AVG Training Acc 62.03 % AVG Validation Acc 62.13 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.646 AVG Validation Loss:0.667 AVG Training Acc 61.97 % AVG Validation Acc 62.40 %\n",
      "Epoch:100/200 AVG Training Loss:0.647 AVG Validation Loss:0.668 AVG Training Acc 61.75 % AVG Validation Acc 62.31 %\n",
      "Epoch:110/200 AVG Training Loss:0.645 AVG Validation Loss:0.668 AVG Training Acc 62.26 % AVG Validation Acc 62.40 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.646 AVG Validation Loss:0.669 AVG Training Acc 62.16 % AVG Validation Acc 62.40 %\n",
      "Epoch:130/200 AVG Training Loss:0.645 AVG Validation Loss:0.668 AVG Training Acc 62.09 % AVG Validation Acc 62.40 %\n",
      "Epoch:140/200 AVG Training Loss:0.646 AVG Validation Loss:0.668 AVG Training Acc 62.05 % AVG Validation Acc 62.31 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.646 AVG Validation Loss:0.668 AVG Training Acc 62.04 % AVG Validation Acc 62.04 %\n",
      "Epoch:160/200 AVG Training Loss:0.645 AVG Validation Loss:0.668 AVG Training Acc 62.16 % AVG Validation Acc 62.22 %\n",
      "Epoch:170/200 AVG Training Loss:0.645 AVG Validation Loss:0.668 AVG Training Acc 61.99 % AVG Validation Acc 62.22 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.645 AVG Validation Loss:0.668 AVG Training Acc 62.11 % AVG Validation Acc 62.40 %\n",
      "Epoch:190/200 AVG Training Loss:0.646 AVG Validation Loss:0.669 AVG Training Acc 62.37 % AVG Validation Acc 62.22 %\n",
      "Epoch:200/200 AVG Training Loss:0.645 AVG Validation Loss:0.668 AVG Training Acc 62.29 % AVG Validation Acc 62.31 %\n",
      "Split 112\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85a6fe77ccaf4dc9914481d8cf8adfb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.658 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.657 AVG Training Acc 61.93 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.659 AVG Validation Loss:0.657 AVG Training Acc 61.79 % AVG Validation Acc 61.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.657 AVG Validation Loss:0.658 AVG Training Acc 62.07 % AVG Validation Acc 61.59 %\n",
      "Epoch:50/200 AVG Training Loss:0.655 AVG Validation Loss:0.658 AVG Training Acc 61.98 % AVG Validation Acc 61.14 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.646 AVG Validation Loss:0.657 AVG Training Acc 62.47 % AVG Validation Acc 61.23 %\n",
      "Epoch:70/200 AVG Training Loss:0.641 AVG Validation Loss:0.661 AVG Training Acc 63.18 % AVG Validation Acc 60.87 %\n",
      "Epoch:80/200 AVG Training Loss:0.639 AVG Validation Loss:0.659 AVG Training Acc 63.02 % AVG Validation Acc 60.60 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.635 AVG Validation Loss:0.673 AVG Training Acc 63.42 % AVG Validation Acc 60.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.633 AVG Validation Loss:0.676 AVG Training Acc 63.61 % AVG Validation Acc 60.96 %\n",
      "Epoch:110/200 AVG Training Loss:0.632 AVG Validation Loss:0.679 AVG Training Acc 63.45 % AVG Validation Acc 61.14 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.631 AVG Validation Loss:0.676 AVG Training Acc 63.59 % AVG Validation Acc 61.41 %\n",
      "Epoch:130/200 AVG Training Loss:0.632 AVG Validation Loss:0.678 AVG Training Acc 63.59 % AVG Validation Acc 61.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.633 AVG Validation Loss:0.680 AVG Training Acc 63.86 % AVG Validation Acc 60.60 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.632 AVG Validation Loss:0.677 AVG Training Acc 63.75 % AVG Validation Acc 60.96 %\n",
      "Epoch:160/200 AVG Training Loss:0.632 AVG Validation Loss:0.677 AVG Training Acc 63.85 % AVG Validation Acc 61.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.631 AVG Validation Loss:0.678 AVG Training Acc 63.98 % AVG Validation Acc 60.69 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.631 AVG Validation Loss:0.677 AVG Training Acc 63.49 % AVG Validation Acc 60.96 %\n",
      "Epoch:190/200 AVG Training Loss:0.631 AVG Validation Loss:0.678 AVG Training Acc 63.71 % AVG Validation Acc 61.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.633 AVG Validation Loss:0.676 AVG Training Acc 63.66 % AVG Validation Acc 60.96 %\n",
      "Split 113\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67af65c908004828ba04578d2396024c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.654 AVG Training Acc 61.83 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.654 AVG Training Acc 61.87 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.658 AVG Validation Loss:0.653 AVG Training Acc 61.81 % AVG Validation Acc 61.86 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.653 AVG Training Acc 61.98 % AVG Validation Acc 61.86 %\n",
      "Epoch:50/200 AVG Training Loss:0.652 AVG Validation Loss:0.653 AVG Training Acc 61.83 % AVG Validation Acc 61.86 %\n",
      "Epoch:60/200 AVG Training Loss:0.651 AVG Validation Loss:0.654 AVG Training Acc 61.73 % AVG Validation Acc 61.59 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.647 AVG Validation Loss:0.655 AVG Training Acc 61.91 % AVG Validation Acc 62.22 %\n",
      "Epoch:80/200 AVG Training Loss:0.647 AVG Validation Loss:0.656 AVG Training Acc 61.91 % AVG Validation Acc 61.95 %\n",
      "Epoch:90/200 AVG Training Loss:0.646 AVG Validation Loss:0.655 AVG Training Acc 62.20 % AVG Validation Acc 62.31 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.647 AVG Validation Loss:0.656 AVG Training Acc 62.02 % AVG Validation Acc 62.31 %\n",
      "Epoch:110/200 AVG Training Loss:0.647 AVG Validation Loss:0.656 AVG Training Acc 62.18 % AVG Validation Acc 62.13 %\n",
      "Epoch:120/200 AVG Training Loss:0.646 AVG Validation Loss:0.656 AVG Training Acc 62.22 % AVG Validation Acc 62.22 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.646 AVG Validation Loss:0.655 AVG Training Acc 62.19 % AVG Validation Acc 62.22 %\n",
      "Epoch:140/200 AVG Training Loss:0.645 AVG Validation Loss:0.655 AVG Training Acc 62.10 % AVG Validation Acc 62.40 %\n",
      "Epoch:150/200 AVG Training Loss:0.646 AVG Validation Loss:0.655 AVG Training Acc 62.09 % AVG Validation Acc 62.40 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.646 AVG Validation Loss:0.656 AVG Training Acc 62.01 % AVG Validation Acc 62.22 %\n",
      "Epoch:170/200 AVG Training Loss:0.646 AVG Validation Loss:0.657 AVG Training Acc 61.92 % AVG Validation Acc 62.13 %\n",
      "Epoch:180/200 AVG Training Loss:0.645 AVG Validation Loss:0.656 AVG Training Acc 62.35 % AVG Validation Acc 62.31 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.646 AVG Validation Loss:0.655 AVG Training Acc 62.31 % AVG Validation Acc 62.22 %\n",
      "Epoch:200/200 AVG Training Loss:0.646 AVG Validation Loss:0.656 AVG Training Acc 61.87 % AVG Validation Acc 62.13 %\n",
      "Split 114\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7637423ee9784bd2a8293f5883d77351",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.658 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.657 AVG Training Acc 61.92 % AVG Validation Acc 61.86 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.659 AVG Training Acc 61.97 % AVG Validation Acc 61.68 %\n",
      "Epoch:40/200 AVG Training Loss:0.649 AVG Validation Loss:0.663 AVG Training Acc 62.01 % AVG Validation Acc 61.86 %\n",
      "Epoch:50/200 AVG Training Loss:0.647 AVG Validation Loss:0.670 AVG Training Acc 62.01 % AVG Validation Acc 61.68 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.645 AVG Validation Loss:0.671 AVG Training Acc 62.08 % AVG Validation Acc 61.50 %\n",
      "Epoch:70/200 AVG Training Loss:0.642 AVG Validation Loss:0.674 AVG Training Acc 62.21 % AVG Validation Acc 61.23 %\n",
      "Epoch:80/200 AVG Training Loss:0.643 AVG Validation Loss:0.673 AVG Training Acc 62.15 % AVG Validation Acc 61.41 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.642 AVG Validation Loss:0.673 AVG Training Acc 62.27 % AVG Validation Acc 61.23 %\n",
      "Epoch:100/200 AVG Training Loss:0.642 AVG Validation Loss:0.674 AVG Training Acc 62.27 % AVG Validation Acc 61.23 %\n",
      "Epoch:110/200 AVG Training Loss:0.643 AVG Validation Loss:0.674 AVG Training Acc 62.27 % AVG Validation Acc 61.23 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.642 AVG Validation Loss:0.674 AVG Training Acc 62.09 % AVG Validation Acc 61.23 %\n",
      "Epoch:130/200 AVG Training Loss:0.642 AVG Validation Loss:0.673 AVG Training Acc 62.25 % AVG Validation Acc 61.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.643 AVG Validation Loss:0.674 AVG Training Acc 62.00 % AVG Validation Acc 61.14 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.643 AVG Validation Loss:0.674 AVG Training Acc 62.38 % AVG Validation Acc 61.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.643 AVG Validation Loss:0.674 AVG Training Acc 62.05 % AVG Validation Acc 61.32 %\n",
      "Epoch:170/200 AVG Training Loss:0.643 AVG Validation Loss:0.674 AVG Training Acc 62.30 % AVG Validation Acc 61.23 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.643 AVG Validation Loss:0.674 AVG Training Acc 62.43 % AVG Validation Acc 61.23 %\n",
      "Epoch:190/200 AVG Training Loss:0.643 AVG Validation Loss:0.673 AVG Training Acc 62.11 % AVG Validation Acc 61.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.642 AVG Validation Loss:0.674 AVG Training Acc 62.23 % AVG Validation Acc 61.14 %\n",
      "Split 115\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b60385c4a8240e28cbf86cbbe37ef93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.659 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.657 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.658 AVG Training Acc 61.87 % AVG Validation Acc 61.77 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.658 AVG Training Acc 62.04 % AVG Validation Acc 61.77 %\n",
      "Epoch:50/200 AVG Training Loss:0.648 AVG Validation Loss:0.657 AVG Training Acc 62.17 % AVG Validation Acc 61.95 %\n",
      "Epoch:60/200 AVG Training Loss:0.643 AVG Validation Loss:0.663 AVG Training Acc 62.46 % AVG Validation Acc 61.86 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.641 AVG Validation Loss:0.665 AVG Training Acc 62.52 % AVG Validation Acc 61.77 %\n",
      "Epoch:80/200 AVG Training Loss:0.640 AVG Validation Loss:0.667 AVG Training Acc 62.56 % AVG Validation Acc 61.77 %\n",
      "Epoch:90/200 AVG Training Loss:0.641 AVG Validation Loss:0.667 AVG Training Acc 62.56 % AVG Validation Acc 62.13 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.639 AVG Validation Loss:0.666 AVG Training Acc 62.63 % AVG Validation Acc 61.86 %\n",
      "Epoch:110/200 AVG Training Loss:0.638 AVG Validation Loss:0.667 AVG Training Acc 62.70 % AVG Validation Acc 61.77 %\n",
      "Epoch:120/200 AVG Training Loss:0.640 AVG Validation Loss:0.667 AVG Training Acc 62.48 % AVG Validation Acc 61.59 %\n",
      "Epoch:130/200 AVG Training Loss:0.640 AVG Validation Loss:0.668 AVG Training Acc 62.64 % AVG Validation Acc 61.59 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.640 AVG Validation Loss:0.667 AVG Training Acc 62.58 % AVG Validation Acc 61.77 %\n",
      "Epoch:150/200 AVG Training Loss:0.639 AVG Validation Loss:0.669 AVG Training Acc 62.69 % AVG Validation Acc 61.77 %\n",
      "Epoch:160/200 AVG Training Loss:0.640 AVG Validation Loss:0.667 AVG Training Acc 62.42 % AVG Validation Acc 61.77 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.639 AVG Validation Loss:0.667 AVG Training Acc 62.72 % AVG Validation Acc 61.77 %\n",
      "Epoch:180/200 AVG Training Loss:0.639 AVG Validation Loss:0.667 AVG Training Acc 62.59 % AVG Validation Acc 62.04 %\n",
      "Epoch:190/200 AVG Training Loss:0.639 AVG Validation Loss:0.668 AVG Training Acc 62.50 % AVG Validation Acc 61.59 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.640 AVG Validation Loss:0.668 AVG Training Acc 62.64 % AVG Validation Acc 61.77 %\n",
      "Split 116\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a28bc50d8b24aacb3c32e7d4b3c5572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.666 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:0.665 AVG Training Acc 61.93 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.650 AVG Validation Loss:0.670 AVG Training Acc 61.77 % AVG Validation Acc 61.91 %\n",
      "Epoch:40/200 AVG Training Loss:0.647 AVG Validation Loss:0.674 AVG Training Acc 61.86 % AVG Validation Acc 61.91 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.643 AVG Validation Loss:0.685 AVG Training Acc 62.27 % AVG Validation Acc 61.46 %\n",
      "Epoch:60/200 AVG Training Loss:0.641 AVG Validation Loss:0.687 AVG Training Acc 62.28 % AVG Validation Acc 61.55 %\n",
      "Epoch:70/200 AVG Training Loss:0.640 AVG Validation Loss:0.690 AVG Training Acc 62.29 % AVG Validation Acc 61.46 %\n",
      "Epoch:80/200 AVG Training Loss:0.640 AVG Validation Loss:0.690 AVG Training Acc 62.31 % AVG Validation Acc 61.37 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.639 AVG Validation Loss:0.691 AVG Training Acc 62.54 % AVG Validation Acc 61.55 %\n",
      "Epoch:100/200 AVG Training Loss:0.639 AVG Validation Loss:0.692 AVG Training Acc 62.20 % AVG Validation Acc 61.46 %\n",
      "Epoch:110/200 AVG Training Loss:0.639 AVG Validation Loss:0.692 AVG Training Acc 62.29 % AVG Validation Acc 61.55 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.639 AVG Validation Loss:0.692 AVG Training Acc 62.34 % AVG Validation Acc 61.55 %\n",
      "Epoch:130/200 AVG Training Loss:0.639 AVG Validation Loss:0.691 AVG Training Acc 62.35 % AVG Validation Acc 61.64 %\n",
      "Epoch:140/200 AVG Training Loss:0.639 AVG Validation Loss:0.691 AVG Training Acc 62.49 % AVG Validation Acc 61.55 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.639 AVG Validation Loss:0.692 AVG Training Acc 62.66 % AVG Validation Acc 61.55 %\n",
      "Epoch:160/200 AVG Training Loss:0.640 AVG Validation Loss:0.691 AVG Training Acc 62.31 % AVG Validation Acc 61.55 %\n",
      "Epoch:170/200 AVG Training Loss:0.639 AVG Validation Loss:0.692 AVG Training Acc 62.07 % AVG Validation Acc 61.55 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.639 AVG Validation Loss:0.692 AVG Training Acc 62.46 % AVG Validation Acc 61.55 %\n",
      "Epoch:190/200 AVG Training Loss:0.639 AVG Validation Loss:0.692 AVG Training Acc 62.26 % AVG Validation Acc 61.55 %\n",
      "Epoch:200/200 AVG Training Loss:0.640 AVG Validation Loss:0.692 AVG Training Acc 62.27 % AVG Validation Acc 61.55 %\n",
      "Split 117\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ded5ed197704b96ac240a1d773b64b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.661 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.661 AVG Training Acc 61.77 % AVG Validation Acc 61.82 %\n",
      "Epoch:30/200 AVG Training Loss:0.658 AVG Validation Loss:0.660 AVG Training Acc 61.61 % AVG Validation Acc 61.82 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.656 AVG Training Acc 61.87 % AVG Validation Acc 61.64 %\n",
      "Epoch:50/200 AVG Training Loss:0.648 AVG Validation Loss:0.661 AVG Training Acc 62.14 % AVG Validation Acc 61.28 %\n",
      "Epoch:60/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 61.89 % AVG Validation Acc 62.00 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:70/200 AVG Training Loss:0.638 AVG Validation Loss:0.655 AVG Training Acc 62.72 % AVG Validation Acc 61.82 %\n",
      "Epoch:80/200 AVG Training Loss:0.631 AVG Validation Loss:0.658 AVG Training Acc 63.10 % AVG Validation Acc 63.09 %\n",
      "Epoch:90/200 AVG Training Loss:0.629 AVG Validation Loss:0.663 AVG Training Acc 63.10 % AVG Validation Acc 62.82 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.625 AVG Validation Loss:0.661 AVG Training Acc 63.38 % AVG Validation Acc 63.00 %\n",
      "Epoch:110/200 AVG Training Loss:0.626 AVG Validation Loss:0.662 AVG Training Acc 63.43 % AVG Validation Acc 62.64 %\n",
      "Epoch:120/200 AVG Training Loss:0.622 AVG Validation Loss:0.666 AVG Training Acc 63.24 % AVG Validation Acc 62.64 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.622 AVG Validation Loss:0.664 AVG Training Acc 63.51 % AVG Validation Acc 62.73 %\n",
      "Epoch:140/200 AVG Training Loss:0.623 AVG Validation Loss:0.664 AVG Training Acc 63.76 % AVG Validation Acc 62.73 %\n",
      "Epoch:150/200 AVG Training Loss:0.621 AVG Validation Loss:0.664 AVG Training Acc 63.62 % AVG Validation Acc 62.91 %\n",
      "Epoch:160/200 AVG Training Loss:0.623 AVG Validation Loss:0.666 AVG Training Acc 63.77 % AVG Validation Acc 63.09 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:170/200 AVG Training Loss:0.622 AVG Validation Loss:0.664 AVG Training Acc 63.43 % AVG Validation Acc 62.27 %\n",
      "Epoch:180/200 AVG Training Loss:0.622 AVG Validation Loss:0.667 AVG Training Acc 63.84 % AVG Validation Acc 62.64 %\n",
      "Epoch:190/200 AVG Training Loss:0.622 AVG Validation Loss:0.666 AVG Training Acc 63.68 % AVG Validation Acc 62.18 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:200/200 AVG Training Loss:0.623 AVG Validation Loss:0.665 AVG Training Acc 63.50 % AVG Validation Acc 62.91 %\n",
      "Split 118\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "795f872ea60d426099def696e484d098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.658 AVG Training Acc 61.81 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.659 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.659 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch:40/200 AVG Training Loss:0.655 AVG Validation Loss:0.660 AVG Training Acc 61.82 % AVG Validation Acc 62.00 %\n",
      "Epoch:50/200 AVG Training Loss:0.653 AVG Validation Loss:0.661 AVG Training Acc 61.94 % AVG Validation Acc 62.09 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.650 AVG Validation Loss:0.664 AVG Training Acc 62.00 % AVG Validation Acc 61.91 %\n",
      "Epoch:70/200 AVG Training Loss:0.650 AVG Validation Loss:0.665 AVG Training Acc 62.03 % AVG Validation Acc 61.82 %\n",
      "Epoch:80/200 AVG Training Loss:0.649 AVG Validation Loss:0.665 AVG Training Acc 62.00 % AVG Validation Acc 61.91 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.648 AVG Validation Loss:0.666 AVG Training Acc 62.23 % AVG Validation Acc 61.91 %\n",
      "Epoch:100/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 61.98 % AVG Validation Acc 61.73 %\n",
      "Epoch:110/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 62.11 % AVG Validation Acc 61.82 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 62.08 % AVG Validation Acc 61.73 %\n",
      "Epoch:130/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 62.05 % AVG Validation Acc 61.82 %\n",
      "Epoch:140/200 AVG Training Loss:0.648 AVG Validation Loss:0.666 AVG Training Acc 61.95 % AVG Validation Acc 61.82 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.649 AVG Validation Loss:0.667 AVG Training Acc 62.11 % AVG Validation Acc 61.82 %\n",
      "Epoch:160/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 62.10 % AVG Validation Acc 61.73 %\n",
      "Epoch:170/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 62.03 % AVG Validation Acc 61.91 %\n",
      "Epoch:180/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 62.13 % AVG Validation Acc 61.82 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.650 AVG Validation Loss:0.665 AVG Training Acc 62.04 % AVG Validation Acc 62.00 %\n",
      "Epoch:200/200 AVG Training Loss:0.648 AVG Validation Loss:0.666 AVG Training Acc 62.04 % AVG Validation Acc 61.91 %\n",
      "Split 119\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b739befa9a474ef4ad6121ea72ceb8e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.663 AVG Training Acc 61.85 % AVG Validation Acc 61.91 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.656 AVG Validation Loss:0.662 AVG Training Acc 61.90 % AVG Validation Acc 61.82 %\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.663 AVG Training Acc 61.83 % AVG Validation Acc 61.82 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.665 AVG Training Acc 61.72 % AVG Validation Acc 61.82 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.646 AVG Validation Loss:0.670 AVG Training Acc 61.97 % AVG Validation Acc 61.64 %\n",
      "Epoch:60/200 AVG Training Loss:0.646 AVG Validation Loss:0.673 AVG Training Acc 62.38 % AVG Validation Acc 61.64 %\n",
      "Epoch:70/200 AVG Training Loss:0.646 AVG Validation Loss:0.675 AVG Training Acc 61.94 % AVG Validation Acc 61.55 %\n",
      "Epoch:80/200 AVG Training Loss:0.645 AVG Validation Loss:0.677 AVG Training Acc 62.01 % AVG Validation Acc 61.28 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.645 AVG Validation Loss:0.677 AVG Training Acc 62.10 % AVG Validation Acc 61.19 %\n",
      "Epoch:100/200 AVG Training Loss:0.644 AVG Validation Loss:0.677 AVG Training Acc 61.82 % AVG Validation Acc 61.10 %\n",
      "Epoch:110/200 AVG Training Loss:0.644 AVG Validation Loss:0.677 AVG Training Acc 62.21 % AVG Validation Acc 61.10 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.645 AVG Validation Loss:0.677 AVG Training Acc 62.08 % AVG Validation Acc 61.19 %\n",
      "Epoch:130/200 AVG Training Loss:0.645 AVG Validation Loss:0.677 AVG Training Acc 62.19 % AVG Validation Acc 61.01 %\n",
      "Epoch:140/200 AVG Training Loss:0.644 AVG Validation Loss:0.678 AVG Training Acc 62.29 % AVG Validation Acc 61.10 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.645 AVG Validation Loss:0.677 AVG Training Acc 62.24 % AVG Validation Acc 61.10 %\n",
      "Epoch:160/200 AVG Training Loss:0.644 AVG Validation Loss:0.677 AVG Training Acc 62.36 % AVG Validation Acc 61.01 %\n",
      "Epoch:170/200 AVG Training Loss:0.645 AVG Validation Loss:0.678 AVG Training Acc 62.26 % AVG Validation Acc 61.10 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.645 AVG Validation Loss:0.677 AVG Training Acc 61.92 % AVG Validation Acc 61.01 %\n",
      "Epoch:190/200 AVG Training Loss:0.645 AVG Validation Loss:0.677 AVG Training Acc 62.14 % AVG Validation Acc 61.01 %\n",
      "Epoch:200/200 AVG Training Loss:0.644 AVG Validation Loss:0.677 AVG Training Acc 62.22 % AVG Validation Acc 61.19 %\n",
      "Split 120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "029e27a70baf406eb119f863566466dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.662 AVG Training Acc 61.80 % AVG Validation Acc 62.00 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.661 AVG Training Acc 61.88 % AVG Validation Acc 62.00 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.664 AVG Training Acc 61.55 % AVG Validation Acc 61.91 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.649 AVG Validation Loss:0.667 AVG Training Acc 61.86 % AVG Validation Acc 61.73 %\n",
      "Epoch:50/200 AVG Training Loss:0.646 AVG Validation Loss:0.670 AVG Training Acc 62.11 % AVG Validation Acc 61.82 %\n",
      "Epoch:60/200 AVG Training Loss:0.645 AVG Validation Loss:0.672 AVG Training Acc 62.16 % AVG Validation Acc 61.82 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.641 AVG Validation Loss:0.674 AVG Training Acc 62.18 % AVG Validation Acc 62.18 %\n",
      "Epoch:80/200 AVG Training Loss:0.642 AVG Validation Loss:0.673 AVG Training Acc 62.17 % AVG Validation Acc 62.27 %\n",
      "Epoch:90/200 AVG Training Loss:0.642 AVG Validation Loss:0.673 AVG Training Acc 62.24 % AVG Validation Acc 62.00 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.641 AVG Validation Loss:0.674 AVG Training Acc 61.96 % AVG Validation Acc 62.00 %\n",
      "Epoch:110/200 AVG Training Loss:0.641 AVG Validation Loss:0.675 AVG Training Acc 62.23 % AVG Validation Acc 61.91 %\n",
      "Epoch:120/200 AVG Training Loss:0.641 AVG Validation Loss:0.674 AVG Training Acc 62.30 % AVG Validation Acc 61.91 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.641 AVG Validation Loss:0.675 AVG Training Acc 62.25 % AVG Validation Acc 61.82 %\n",
      "Epoch:140/200 AVG Training Loss:0.643 AVG Validation Loss:0.674 AVG Training Acc 62.17 % AVG Validation Acc 61.91 %\n",
      "Epoch:150/200 AVG Training Loss:0.641 AVG Validation Loss:0.674 AVG Training Acc 62.20 % AVG Validation Acc 61.82 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.642 AVG Validation Loss:0.675 AVG Training Acc 62.07 % AVG Validation Acc 61.73 %\n",
      "Epoch:170/200 AVG Training Loss:0.642 AVG Validation Loss:0.675 AVG Training Acc 62.41 % AVG Validation Acc 61.91 %\n",
      "Epoch:180/200 AVG Training Loss:0.642 AVG Validation Loss:0.675 AVG Training Acc 62.21 % AVG Validation Acc 61.91 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.642 AVG Validation Loss:0.674 AVG Training Acc 62.28 % AVG Validation Acc 61.82 %\n",
      "Epoch:200/200 AVG Training Loss:0.642 AVG Validation Loss:0.675 AVG Training Acc 62.22 % AVG Validation Acc 61.91 %\n",
      "Split 121\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4eaa42693c542e58c249545ef2c96ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.661 AVG Training Acc 61.86 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.660 AVG Training Acc 61.93 % AVG Validation Acc 62.04 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.659 AVG Training Acc 61.90 % AVG Validation Acc 62.04 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.660 AVG Training Acc 61.92 % AVG Validation Acc 61.95 %\n",
      "Epoch:50/200 AVG Training Loss:0.648 AVG Validation Loss:0.656 AVG Training Acc 62.21 % AVG Validation Acc 62.58 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.633 AVG Validation Loss:0.661 AVG Training Acc 63.56 % AVG Validation Acc 60.50 %\n",
      "Epoch:70/200 AVG Training Loss:0.628 AVG Validation Loss:0.667 AVG Training Acc 63.61 % AVG Validation Acc 61.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.623 AVG Validation Loss:0.670 AVG Training Acc 64.14 % AVG Validation Acc 60.60 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.617 AVG Validation Loss:0.663 AVG Training Acc 65.04 % AVG Validation Acc 61.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.617 AVG Validation Loss:0.661 AVG Training Acc 64.76 % AVG Validation Acc 62.04 %\n",
      "Epoch:110/200 AVG Training Loss:0.615 AVG Validation Loss:0.665 AVG Training Acc 65.02 % AVG Validation Acc 60.96 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.616 AVG Validation Loss:0.670 AVG Training Acc 64.85 % AVG Validation Acc 61.86 %\n",
      "Epoch:130/200 AVG Training Loss:0.618 AVG Validation Loss:0.663 AVG Training Acc 64.37 % AVG Validation Acc 61.50 %\n",
      "Epoch:140/200 AVG Training Loss:0.616 AVG Validation Loss:0.668 AVG Training Acc 64.99 % AVG Validation Acc 61.32 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.614 AVG Validation Loss:0.665 AVG Training Acc 64.62 % AVG Validation Acc 61.50 %\n",
      "Epoch:160/200 AVG Training Loss:0.615 AVG Validation Loss:0.671 AVG Training Acc 65.20 % AVG Validation Acc 60.60 %\n",
      "Epoch:170/200 AVG Training Loss:0.615 AVG Validation Loss:0.666 AVG Training Acc 64.70 % AVG Validation Acc 60.87 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.615 AVG Validation Loss:0.664 AVG Training Acc 64.55 % AVG Validation Acc 61.50 %\n",
      "Epoch:190/200 AVG Training Loss:0.618 AVG Validation Loss:0.666 AVG Training Acc 64.70 % AVG Validation Acc 61.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.616 AVG Validation Loss:0.666 AVG Training Acc 64.69 % AVG Validation Acc 61.05 %\n",
      "Split 122\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bac4cecb956424cb237b78e23902c43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.657 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.656 AVG Training Acc 61.84 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.659 AVG Validation Loss:0.660 AVG Training Acc 61.89 % AVG Validation Acc 61.77 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.662 AVG Training Acc 61.99 % AVG Validation Acc 61.50 %\n",
      "Epoch:50/200 AVG Training Loss:0.651 AVG Validation Loss:0.660 AVG Training Acc 62.06 % AVG Validation Acc 61.50 %\n",
      "Epoch:60/200 AVG Training Loss:0.647 AVG Validation Loss:0.664 AVG Training Acc 62.06 % AVG Validation Acc 61.50 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.646 AVG Validation Loss:0.669 AVG Training Acc 62.17 % AVG Validation Acc 61.32 %\n",
      "Epoch:80/200 AVG Training Loss:0.645 AVG Validation Loss:0.668 AVG Training Acc 62.20 % AVG Validation Acc 61.32 %\n",
      "Epoch:90/200 AVG Training Loss:0.646 AVG Validation Loss:0.668 AVG Training Acc 62.07 % AVG Validation Acc 61.32 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.644 AVG Validation Loss:0.668 AVG Training Acc 62.05 % AVG Validation Acc 61.41 %\n",
      "Epoch:110/200 AVG Training Loss:0.644 AVG Validation Loss:0.668 AVG Training Acc 62.02 % AVG Validation Acc 61.23 %\n",
      "Epoch:120/200 AVG Training Loss:0.643 AVG Validation Loss:0.668 AVG Training Acc 62.24 % AVG Validation Acc 61.41 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.643 AVG Validation Loss:0.669 AVG Training Acc 62.09 % AVG Validation Acc 61.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.644 AVG Validation Loss:0.669 AVG Training Acc 62.05 % AVG Validation Acc 61.23 %\n",
      "Epoch:150/200 AVG Training Loss:0.644 AVG Validation Loss:0.669 AVG Training Acc 62.01 % AVG Validation Acc 61.32 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.644 AVG Validation Loss:0.669 AVG Training Acc 61.89 % AVG Validation Acc 61.23 %\n",
      "Epoch:170/200 AVG Training Loss:0.644 AVG Validation Loss:0.668 AVG Training Acc 61.98 % AVG Validation Acc 61.32 %\n",
      "Epoch:180/200 AVG Training Loss:0.644 AVG Validation Loss:0.669 AVG Training Acc 62.23 % AVG Validation Acc 61.23 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.643 AVG Validation Loss:0.667 AVG Training Acc 62.25 % AVG Validation Acc 61.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.644 AVG Validation Loss:0.667 AVG Training Acc 61.98 % AVG Validation Acc 61.23 %\n",
      "Split 123\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c5cda9a13194112bbf535c38f38a24f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.664 AVG Training Acc 61.88 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.671 AVG Training Acc 61.73 % AVG Validation Acc 61.86 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.665 AVG Training Acc 61.92 % AVG Validation Acc 62.22 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.666 AVG Training Acc 62.13 % AVG Validation Acc 61.77 %\n",
      "Epoch:50/200 AVG Training Loss:0.647 AVG Validation Loss:0.670 AVG Training Acc 62.12 % AVG Validation Acc 61.59 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.647 AVG Validation Loss:0.673 AVG Training Acc 62.13 % AVG Validation Acc 60.87 %\n",
      "Epoch:70/200 AVG Training Loss:0.645 AVG Validation Loss:0.675 AVG Training Acc 62.49 % AVG Validation Acc 60.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.645 AVG Validation Loss:0.675 AVG Training Acc 62.34 % AVG Validation Acc 61.41 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.645 AVG Validation Loss:0.675 AVG Training Acc 62.36 % AVG Validation Acc 61.32 %\n",
      "Epoch:100/200 AVG Training Loss:0.644 AVG Validation Loss:0.676 AVG Training Acc 62.29 % AVG Validation Acc 61.50 %\n",
      "Epoch:110/200 AVG Training Loss:0.644 AVG Validation Loss:0.675 AVG Training Acc 62.18 % AVG Validation Acc 61.32 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.645 AVG Validation Loss:0.676 AVG Training Acc 62.40 % AVG Validation Acc 61.05 %\n",
      "Epoch:130/200 AVG Training Loss:0.645 AVG Validation Loss:0.675 AVG Training Acc 62.35 % AVG Validation Acc 61.41 %\n",
      "Epoch:140/200 AVG Training Loss:0.645 AVG Validation Loss:0.676 AVG Training Acc 62.30 % AVG Validation Acc 61.23 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.646 AVG Validation Loss:0.676 AVG Training Acc 62.06 % AVG Validation Acc 61.41 %\n",
      "Epoch:160/200 AVG Training Loss:0.645 AVG Validation Loss:0.676 AVG Training Acc 62.27 % AVG Validation Acc 61.41 %\n",
      "Epoch:170/200 AVG Training Loss:0.645 AVG Validation Loss:0.676 AVG Training Acc 62.30 % AVG Validation Acc 61.23 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.645 AVG Validation Loss:0.676 AVG Training Acc 62.16 % AVG Validation Acc 61.32 %\n",
      "Epoch:190/200 AVG Training Loss:0.644 AVG Validation Loss:0.676 AVG Training Acc 62.58 % AVG Validation Acc 61.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.645 AVG Validation Loss:0.676 AVG Training Acc 62.35 % AVG Validation Acc 61.14 %\n",
      "Split 124\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "044f25969bb240108c45696887e2ef0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.655 AVG Training Acc 61.96 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.655 AVG Training Acc 61.93 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.656 AVG Training Acc 61.71 % AVG Validation Acc 61.68 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.650 AVG Validation Loss:0.658 AVG Training Acc 62.13 % AVG Validation Acc 61.86 %\n",
      "Epoch:50/200 AVG Training Loss:0.646 AVG Validation Loss:0.665 AVG Training Acc 62.16 % AVG Validation Acc 61.68 %\n",
      "Epoch:60/200 AVG Training Loss:0.645 AVG Validation Loss:0.673 AVG Training Acc 62.33 % AVG Validation Acc 61.59 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.643 AVG Validation Loss:0.671 AVG Training Acc 62.29 % AVG Validation Acc 61.32 %\n",
      "Epoch:80/200 AVG Training Loss:0.641 AVG Validation Loss:0.674 AVG Training Acc 62.48 % AVG Validation Acc 61.23 %\n",
      "Epoch:90/200 AVG Training Loss:0.642 AVG Validation Loss:0.674 AVG Training Acc 62.60 % AVG Validation Acc 61.32 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.642 AVG Validation Loss:0.674 AVG Training Acc 62.42 % AVG Validation Acc 61.32 %\n",
      "Epoch:110/200 AVG Training Loss:0.640 AVG Validation Loss:0.676 AVG Training Acc 62.41 % AVG Validation Acc 61.23 %\n",
      "Epoch:120/200 AVG Training Loss:0.640 AVG Validation Loss:0.675 AVG Training Acc 62.52 % AVG Validation Acc 61.14 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.641 AVG Validation Loss:0.677 AVG Training Acc 62.48 % AVG Validation Acc 61.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.639 AVG Validation Loss:0.675 AVG Training Acc 62.58 % AVG Validation Acc 61.23 %\n",
      "Epoch:150/200 AVG Training Loss:0.642 AVG Validation Loss:0.676 AVG Training Acc 62.55 % AVG Validation Acc 61.32 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.640 AVG Validation Loss:0.675 AVG Training Acc 62.42 % AVG Validation Acc 61.32 %\n",
      "Epoch:170/200 AVG Training Loss:0.641 AVG Validation Loss:0.675 AVG Training Acc 62.48 % AVG Validation Acc 61.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.642 AVG Validation Loss:0.675 AVG Training Acc 62.33 % AVG Validation Acc 61.23 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.641 AVG Validation Loss:0.676 AVG Training Acc 62.52 % AVG Validation Acc 61.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.640 AVG Validation Loss:0.679 AVG Training Acc 62.53 % AVG Validation Acc 61.23 %\n",
      "Split 125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "498d718a072448a5924d9d4c8942931e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.661 AVG Training Acc 61.85 % AVG Validation Acc 61.86 %\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.658 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.657 AVG Training Acc 61.91 % AVG Validation Acc 61.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.655 AVG Validation Loss:0.659 AVG Training Acc 61.81 % AVG Validation Acc 62.04 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.653 AVG Validation Loss:0.660 AVG Training Acc 62.03 % AVG Validation Acc 61.77 %\n",
      "Epoch:60/200 AVG Training Loss:0.653 AVG Validation Loss:0.659 AVG Training Acc 62.07 % AVG Validation Acc 61.86 %\n",
      "Epoch:70/200 AVG Training Loss:0.653 AVG Validation Loss:0.659 AVG Training Acc 62.05 % AVG Validation Acc 61.86 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.651 AVG Validation Loss:0.659 AVG Training Acc 62.03 % AVG Validation Acc 61.77 %\n",
      "Epoch:90/200 AVG Training Loss:0.652 AVG Validation Loss:0.658 AVG Training Acc 62.01 % AVG Validation Acc 61.86 %\n",
      "Epoch:100/200 AVG Training Loss:0.652 AVG Validation Loss:0.659 AVG Training Acc 62.11 % AVG Validation Acc 61.86 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.652 AVG Validation Loss:0.658 AVG Training Acc 62.12 % AVG Validation Acc 61.95 %\n",
      "Epoch:120/200 AVG Training Loss:0.652 AVG Validation Loss:0.659 AVG Training Acc 61.95 % AVG Validation Acc 61.95 %\n",
      "Epoch:130/200 AVG Training Loss:0.652 AVG Validation Loss:0.659 AVG Training Acc 62.14 % AVG Validation Acc 61.95 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.652 AVG Validation Loss:0.658 AVG Training Acc 62.12 % AVG Validation Acc 61.95 %\n",
      "Epoch:150/200 AVG Training Loss:0.653 AVG Validation Loss:0.659 AVG Training Acc 62.02 % AVG Validation Acc 61.95 %\n",
      "Epoch:160/200 AVG Training Loss:0.652 AVG Validation Loss:0.659 AVG Training Acc 62.01 % AVG Validation Acc 61.95 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.651 AVG Validation Loss:0.659 AVG Training Acc 62.04 % AVG Validation Acc 61.95 %\n",
      "Epoch:180/200 AVG Training Loss:0.652 AVG Validation Loss:0.659 AVG Training Acc 61.97 % AVG Validation Acc 61.95 %\n",
      "Epoch:190/200 AVG Training Loss:0.652 AVG Validation Loss:0.659 AVG Training Acc 62.06 % AVG Validation Acc 61.95 %\n",
      "Epoch:200/200 AVG Training Loss:0.652 AVG Validation Loss:0.659 AVG Training Acc 61.90 % AVG Validation Acc 61.95 %\n",
      "Split 126\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1e1119a941a4c838a1581805935479c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.658 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.659 AVG Training Acc 62.01 % AVG Validation Acc 61.73 %\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.661 AVG Training Acc 61.90 % AVG Validation Acc 61.64 %\n",
      "Epoch:40/200 AVG Training Loss:0.650 AVG Validation Loss:0.665 AVG Training Acc 62.21 % AVG Validation Acc 61.37 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.645 AVG Validation Loss:0.666 AVG Training Acc 62.30 % AVG Validation Acc 61.28 %\n",
      "Epoch:60/200 AVG Training Loss:0.643 AVG Validation Loss:0.668 AVG Training Acc 62.07 % AVG Validation Acc 61.19 %\n",
      "Epoch:70/200 AVG Training Loss:0.645 AVG Validation Loss:0.669 AVG Training Acc 62.07 % AVG Validation Acc 61.01 %\n",
      "Epoch:80/200 AVG Training Loss:0.643 AVG Validation Loss:0.670 AVG Training Acc 62.33 % AVG Validation Acc 61.01 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.643 AVG Validation Loss:0.670 AVG Training Acc 62.31 % AVG Validation Acc 61.01 %\n",
      "Epoch:100/200 AVG Training Loss:0.642 AVG Validation Loss:0.670 AVG Training Acc 62.55 % AVG Validation Acc 61.01 %\n",
      "Epoch:110/200 AVG Training Loss:0.642 AVG Validation Loss:0.670 AVG Training Acc 62.20 % AVG Validation Acc 61.01 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.642 AVG Validation Loss:0.670 AVG Training Acc 62.30 % AVG Validation Acc 61.01 %\n",
      "Epoch:130/200 AVG Training Loss:0.642 AVG Validation Loss:0.670 AVG Training Acc 62.05 % AVG Validation Acc 60.92 %\n",
      "Epoch:140/200 AVG Training Loss:0.642 AVG Validation Loss:0.670 AVG Training Acc 62.40 % AVG Validation Acc 61.10 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.641 AVG Validation Loss:0.669 AVG Training Acc 62.54 % AVG Validation Acc 61.01 %\n",
      "Epoch:160/200 AVG Training Loss:0.642 AVG Validation Loss:0.670 AVG Training Acc 62.33 % AVG Validation Acc 60.92 %\n",
      "Epoch:170/200 AVG Training Loss:0.643 AVG Validation Loss:0.670 AVG Training Acc 62.49 % AVG Validation Acc 60.92 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.642 AVG Validation Loss:0.670 AVG Training Acc 62.15 % AVG Validation Acc 61.01 %\n",
      "Epoch:190/200 AVG Training Loss:0.641 AVG Validation Loss:0.670 AVG Training Acc 62.46 % AVG Validation Acc 61.01 %\n",
      "Epoch:200/200 AVG Training Loss:0.642 AVG Validation Loss:0.670 AVG Training Acc 62.45 % AVG Validation Acc 61.01 %\n",
      "Split 127\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b7d80078783471391a593c636003eb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.667 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.666 AVG Validation Loss:0.664 AVG Training Acc 61.84 % AVG Validation Acc 61.91 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.659 AVG Validation Loss:0.664 AVG Training Acc 61.93 % AVG Validation Acc 62.00 %\n",
      "Epoch:40/200 AVG Training Loss:0.655 AVG Validation Loss:0.666 AVG Training Acc 61.97 % AVG Validation Acc 61.82 %\n",
      "Epoch:50/200 AVG Training Loss:0.656 AVG Validation Loss:0.669 AVG Training Acc 61.95 % AVG Validation Acc 61.82 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.653 AVG Validation Loss:0.669 AVG Training Acc 61.98 % AVG Validation Acc 61.82 %\n",
      "Epoch:70/200 AVG Training Loss:0.653 AVG Validation Loss:0.670 AVG Training Acc 61.99 % AVG Validation Acc 61.82 %\n",
      "Epoch:80/200 AVG Training Loss:0.652 AVG Validation Loss:0.671 AVG Training Acc 62.04 % AVG Validation Acc 61.82 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.652 AVG Validation Loss:0.670 AVG Training Acc 61.94 % AVG Validation Acc 61.82 %\n",
      "Epoch:100/200 AVG Training Loss:0.652 AVG Validation Loss:0.671 AVG Training Acc 61.99 % AVG Validation Acc 61.82 %\n",
      "Epoch:110/200 AVG Training Loss:0.652 AVG Validation Loss:0.671 AVG Training Acc 61.98 % AVG Validation Acc 61.82 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.652 AVG Validation Loss:0.671 AVG Training Acc 61.99 % AVG Validation Acc 61.82 %\n",
      "Epoch:130/200 AVG Training Loss:0.652 AVG Validation Loss:0.671 AVG Training Acc 62.00 % AVG Validation Acc 61.82 %\n",
      "Epoch:140/200 AVG Training Loss:0.652 AVG Validation Loss:0.672 AVG Training Acc 62.01 % AVG Validation Acc 61.82 %\n",
      "Epoch:150/200 AVG Training Loss:0.652 AVG Validation Loss:0.671 AVG Training Acc 61.97 % AVG Validation Acc 61.82 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.652 AVG Validation Loss:0.672 AVG Training Acc 61.99 % AVG Validation Acc 61.82 %\n",
      "Epoch:170/200 AVG Training Loss:0.653 AVG Validation Loss:0.672 AVG Training Acc 62.00 % AVG Validation Acc 61.82 %\n",
      "Epoch:180/200 AVG Training Loss:0.652 AVG Validation Loss:0.672 AVG Training Acc 62.04 % AVG Validation Acc 61.82 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.653 AVG Validation Loss:0.672 AVG Training Acc 61.98 % AVG Validation Acc 61.82 %\n",
      "Epoch:200/200 AVG Training Loss:0.652 AVG Validation Loss:0.672 AVG Training Acc 62.00 % AVG Validation Acc 61.82 %\n",
      "Split 128\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "695d2b83690a4f0f8c082852dd9174ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.661 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.659 AVG Training Acc 61.89 % AVG Validation Acc 62.00 %\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.658 AVG Training Acc 61.97 % AVG Validation Acc 62.09 %\n",
      "Epoch:40/200 AVG Training Loss:0.655 AVG Validation Loss:0.656 AVG Training Acc 61.78 % AVG Validation Acc 62.09 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.646 AVG Validation Loss:0.660 AVG Training Acc 62.11 % AVG Validation Acc 61.82 %\n",
      "Epoch:60/200 AVG Training Loss:0.643 AVG Validation Loss:0.663 AVG Training Acc 62.58 % AVG Validation Acc 61.73 %\n",
      "Epoch:70/200 AVG Training Loss:0.640 AVG Validation Loss:0.665 AVG Training Acc 62.75 % AVG Validation Acc 61.55 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.635 AVG Validation Loss:0.666 AVG Training Acc 62.92 % AVG Validation Acc 61.64 %\n",
      "Epoch:90/200 AVG Training Loss:0.636 AVG Validation Loss:0.667 AVG Training Acc 62.59 % AVG Validation Acc 62.00 %\n",
      "Epoch:100/200 AVG Training Loss:0.636 AVG Validation Loss:0.666 AVG Training Acc 62.88 % AVG Validation Acc 61.91 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.635 AVG Validation Loss:0.668 AVG Training Acc 62.82 % AVG Validation Acc 61.64 %\n",
      "Epoch:120/200 AVG Training Loss:0.635 AVG Validation Loss:0.668 AVG Training Acc 62.97 % AVG Validation Acc 61.73 %\n",
      "Epoch:130/200 AVG Training Loss:0.634 AVG Validation Loss:0.669 AVG Training Acc 63.06 % AVG Validation Acc 61.64 %\n",
      "Epoch:140/200 AVG Training Loss:0.634 AVG Validation Loss:0.668 AVG Training Acc 63.21 % AVG Validation Acc 61.55 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.634 AVG Validation Loss:0.668 AVG Training Acc 62.91 % AVG Validation Acc 61.64 %\n",
      "Epoch:160/200 AVG Training Loss:0.633 AVG Validation Loss:0.669 AVG Training Acc 63.19 % AVG Validation Acc 61.37 %\n",
      "Epoch:170/200 AVG Training Loss:0.636 AVG Validation Loss:0.668 AVG Training Acc 62.92 % AVG Validation Acc 61.37 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.635 AVG Validation Loss:0.667 AVG Training Acc 62.93 % AVG Validation Acc 61.73 %\n",
      "Epoch:190/200 AVG Training Loss:0.634 AVG Validation Loss:0.668 AVG Training Acc 63.01 % AVG Validation Acc 61.73 %\n",
      "Epoch:200/200 AVG Training Loss:0.635 AVG Validation Loss:0.668 AVG Training Acc 63.10 % AVG Validation Acc 61.46 %\n",
      "Split 129\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ba97f0eba74ac1a49aa97ee75d6010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.660 AVG Training Acc 61.88 % AVG Validation Acc 62.00 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.663 AVG Training Acc 61.82 % AVG Validation Acc 61.91 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.662 AVG Training Acc 61.98 % AVG Validation Acc 62.00 %\n",
      "Epoch:40/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 61.69 % AVG Validation Acc 61.46 %\n",
      "Epoch:50/200 AVG Training Loss:0.646 AVG Validation Loss:0.667 AVG Training Acc 61.77 % AVG Validation Acc 61.64 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.640 AVG Validation Loss:0.671 AVG Training Acc 62.42 % AVG Validation Acc 61.19 %\n",
      "Epoch:70/200 AVG Training Loss:0.639 AVG Validation Loss:0.672 AVG Training Acc 62.42 % AVG Validation Acc 60.83 %\n",
      "Epoch:80/200 AVG Training Loss:0.638 AVG Validation Loss:0.673 AVG Training Acc 62.37 % AVG Validation Acc 61.01 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.637 AVG Validation Loss:0.673 AVG Training Acc 62.08 % AVG Validation Acc 61.10 %\n",
      "Epoch:100/200 AVG Training Loss:0.638 AVG Validation Loss:0.673 AVG Training Acc 62.49 % AVG Validation Acc 61.10 %\n",
      "Epoch:110/200 AVG Training Loss:0.638 AVG Validation Loss:0.673 AVG Training Acc 62.54 % AVG Validation Acc 61.01 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.636 AVG Validation Loss:0.673 AVG Training Acc 62.59 % AVG Validation Acc 61.46 %\n",
      "Epoch:130/200 AVG Training Loss:0.637 AVG Validation Loss:0.672 AVG Training Acc 62.22 % AVG Validation Acc 61.10 %\n",
      "Epoch:140/200 AVG Training Loss:0.636 AVG Validation Loss:0.672 AVG Training Acc 62.35 % AVG Validation Acc 61.01 %\n",
      "Epoch:150/200 AVG Training Loss:0.638 AVG Validation Loss:0.674 AVG Training Acc 62.16 % AVG Validation Acc 61.19 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.637 AVG Validation Loss:0.672 AVG Training Acc 62.10 % AVG Validation Acc 61.19 %\n",
      "Epoch:170/200 AVG Training Loss:0.639 AVG Validation Loss:0.672 AVG Training Acc 62.16 % AVG Validation Acc 60.92 %\n",
      "Epoch:180/200 AVG Training Loss:0.638 AVG Validation Loss:0.673 AVG Training Acc 62.52 % AVG Validation Acc 61.28 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.637 AVG Validation Loss:0.671 AVG Training Acc 62.14 % AVG Validation Acc 61.37 %\n",
      "Epoch:200/200 AVG Training Loss:0.637 AVG Validation Loss:0.672 AVG Training Acc 62.20 % AVG Validation Acc 61.01 %\n",
      "Split 130\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "887e73c92b3749308c292173dedac919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.660 AVG Training Acc 61.86 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.663 AVG Training Acc 61.77 % AVG Validation Acc 61.91 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.661 AVG Training Acc 62.00 % AVG Validation Acc 61.82 %\n",
      "Epoch:40/200 AVG Training Loss:0.649 AVG Validation Loss:0.665 AVG Training Acc 62.11 % AVG Validation Acc 61.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.646 AVG Validation Loss:0.672 AVG Training Acc 62.20 % AVG Validation Acc 61.82 %\n",
      "Epoch:60/200 AVG Training Loss:0.641 AVG Validation Loss:0.674 AVG Training Acc 62.30 % AVG Validation Acc 61.46 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.640 AVG Validation Loss:0.680 AVG Training Acc 62.38 % AVG Validation Acc 61.28 %\n",
      "Epoch:80/200 AVG Training Loss:0.639 AVG Validation Loss:0.679 AVG Training Acc 62.48 % AVG Validation Acc 61.10 %\n",
      "Epoch:90/200 AVG Training Loss:0.637 AVG Validation Loss:0.681 AVG Training Acc 62.65 % AVG Validation Acc 61.10 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.638 AVG Validation Loss:0.682 AVG Training Acc 62.37 % AVG Validation Acc 61.10 %\n",
      "Epoch:110/200 AVG Training Loss:0.639 AVG Validation Loss:0.682 AVG Training Acc 62.43 % AVG Validation Acc 61.19 %\n",
      "Epoch:120/200 AVG Training Loss:0.637 AVG Validation Loss:0.681 AVG Training Acc 62.61 % AVG Validation Acc 61.01 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.637 AVG Validation Loss:0.681 AVG Training Acc 62.35 % AVG Validation Acc 61.19 %\n",
      "Epoch:140/200 AVG Training Loss:0.635 AVG Validation Loss:0.681 AVG Training Acc 62.51 % AVG Validation Acc 61.10 %\n",
      "Epoch:150/200 AVG Training Loss:0.638 AVG Validation Loss:0.680 AVG Training Acc 62.64 % AVG Validation Acc 61.10 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.639 AVG Validation Loss:0.680 AVG Training Acc 62.44 % AVG Validation Acc 61.10 %\n",
      "Epoch:170/200 AVG Training Loss:0.638 AVG Validation Loss:0.681 AVG Training Acc 62.55 % AVG Validation Acc 61.10 %\n",
      "Epoch:180/200 AVG Training Loss:0.639 AVG Validation Loss:0.681 AVG Training Acc 62.47 % AVG Validation Acc 61.01 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.638 AVG Validation Loss:0.680 AVG Training Acc 62.46 % AVG Validation Acc 61.10 %\n",
      "Epoch:200/200 AVG Training Loss:0.636 AVG Validation Loss:0.680 AVG Training Acc 62.66 % AVG Validation Acc 61.19 %\n",
      "Split 131\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fca94672327e4d83a328d9c113f31733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.659 AVG Training Acc 61.81 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.657 AVG Training Acc 61.83 % AVG Validation Acc 62.13 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.660 AVG Training Acc 61.86 % AVG Validation Acc 62.04 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 62.08 % AVG Validation Acc 61.77 %\n",
      "Epoch:50/200 AVG Training Loss:0.644 AVG Validation Loss:0.668 AVG Training Acc 62.31 % AVG Validation Acc 61.86 %\n",
      "Epoch:60/200 AVG Training Loss:0.640 AVG Validation Loss:0.674 AVG Training Acc 62.19 % AVG Validation Acc 61.77 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.638 AVG Validation Loss:0.680 AVG Training Acc 62.62 % AVG Validation Acc 61.59 %\n",
      "Epoch:80/200 AVG Training Loss:0.636 AVG Validation Loss:0.681 AVG Training Acc 62.28 % AVG Validation Acc 61.50 %\n",
      "Epoch:90/200 AVG Training Loss:0.636 AVG Validation Loss:0.680 AVG Training Acc 62.37 % AVG Validation Acc 61.68 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.636 AVG Validation Loss:0.680 AVG Training Acc 62.27 % AVG Validation Acc 61.41 %\n",
      "Epoch:110/200 AVG Training Loss:0.635 AVG Validation Loss:0.680 AVG Training Acc 62.35 % AVG Validation Acc 61.41 %\n",
      "Epoch:120/200 AVG Training Loss:0.635 AVG Validation Loss:0.680 AVG Training Acc 62.70 % AVG Validation Acc 61.50 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.636 AVG Validation Loss:0.683 AVG Training Acc 62.38 % AVG Validation Acc 61.50 %\n",
      "Epoch:140/200 AVG Training Loss:0.636 AVG Validation Loss:0.683 AVG Training Acc 62.58 % AVG Validation Acc 61.50 %\n",
      "Epoch:150/200 AVG Training Loss:0.635 AVG Validation Loss:0.681 AVG Training Acc 62.55 % AVG Validation Acc 61.41 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.636 AVG Validation Loss:0.681 AVG Training Acc 62.42 % AVG Validation Acc 61.50 %\n",
      "Epoch:170/200 AVG Training Loss:0.635 AVG Validation Loss:0.682 AVG Training Acc 62.54 % AVG Validation Acc 61.50 %\n",
      "Epoch:180/200 AVG Training Loss:0.636 AVG Validation Loss:0.681 AVG Training Acc 62.42 % AVG Validation Acc 61.50 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.636 AVG Validation Loss:0.683 AVG Training Acc 62.68 % AVG Validation Acc 61.41 %\n",
      "Epoch:200/200 AVG Training Loss:0.636 AVG Validation Loss:0.682 AVG Training Acc 62.42 % AVG Validation Acc 61.50 %\n",
      "Split 132\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7342ca95a9f1436592eb04e14a8a3e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.657 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.656 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.659 AVG Validation Loss:0.657 AVG Training Acc 61.91 % AVG Validation Acc 61.95 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.654 AVG Validation Loss:0.657 AVG Training Acc 61.98 % AVG Validation Acc 61.68 %\n",
      "Epoch:50/200 AVG Training Loss:0.651 AVG Validation Loss:0.659 AVG Training Acc 62.12 % AVG Validation Acc 61.68 %\n",
      "Epoch:60/200 AVG Training Loss:0.650 AVG Validation Loss:0.659 AVG Training Acc 61.96 % AVG Validation Acc 61.77 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.647 AVG Validation Loss:0.662 AVG Training Acc 62.18 % AVG Validation Acc 61.32 %\n",
      "Epoch:80/200 AVG Training Loss:0.647 AVG Validation Loss:0.664 AVG Training Acc 62.31 % AVG Validation Acc 61.50 %\n",
      "Epoch:90/200 AVG Training Loss:0.646 AVG Validation Loss:0.664 AVG Training Acc 62.54 % AVG Validation Acc 61.23 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.646 AVG Validation Loss:0.664 AVG Training Acc 62.17 % AVG Validation Acc 61.23 %\n",
      "Epoch:110/200 AVG Training Loss:0.645 AVG Validation Loss:0.665 AVG Training Acc 62.43 % AVG Validation Acc 61.41 %\n",
      "Epoch:120/200 AVG Training Loss:0.647 AVG Validation Loss:0.666 AVG Training Acc 62.04 % AVG Validation Acc 61.32 %\n",
      "Epoch:130/200 AVG Training Loss:0.645 AVG Validation Loss:0.665 AVG Training Acc 62.30 % AVG Validation Acc 61.32 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.645 AVG Validation Loss:0.665 AVG Training Acc 62.13 % AVG Validation Acc 61.23 %\n",
      "Epoch:150/200 AVG Training Loss:0.646 AVG Validation Loss:0.665 AVG Training Acc 62.45 % AVG Validation Acc 61.32 %\n",
      "Epoch:160/200 AVG Training Loss:0.646 AVG Validation Loss:0.665 AVG Training Acc 62.26 % AVG Validation Acc 61.23 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.646 AVG Validation Loss:0.665 AVG Training Acc 62.25 % AVG Validation Acc 61.41 %\n",
      "Epoch:180/200 AVG Training Loss:0.646 AVG Validation Loss:0.664 AVG Training Acc 62.37 % AVG Validation Acc 61.32 %\n",
      "Epoch:190/200 AVG Training Loss:0.645 AVG Validation Loss:0.665 AVG Training Acc 62.33 % AVG Validation Acc 61.32 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.645 AVG Validation Loss:0.665 AVG Training Acc 62.36 % AVG Validation Acc 61.32 %\n",
      "Split 133\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4b3e463036245eab14dcfd36e33e6fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.655 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.654 AVG Training Acc 61.86 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.659 AVG Validation Loss:0.655 AVG Training Acc 61.91 % AVG Validation Acc 61.77 %\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.661 AVG Validation Loss:0.659 AVG Training Acc 61.95 % AVG Validation Acc 61.86 %\n",
      "Epoch:50/200 AVG Training Loss:0.659 AVG Validation Loss:0.656 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:60/200 AVG Training Loss:0.658 AVG Validation Loss:0.656 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:70/200 AVG Training Loss:0.657 AVG Validation Loss:0.656 AVG Training Acc 61.90 % AVG Validation Acc 61.77 %\n",
      "Epoch    70: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.656 AVG Validation Loss:0.655 AVG Training Acc 61.88 % AVG Validation Acc 61.77 %\n",
      "Epoch:90/200 AVG Training Loss:0.656 AVG Validation Loss:0.655 AVG Training Acc 61.97 % AVG Validation Acc 61.77 %\n",
      "Epoch:100/200 AVG Training Loss:0.657 AVG Validation Loss:0.655 AVG Training Acc 61.95 % AVG Validation Acc 61.77 %\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.655 AVG Validation Loss:0.656 AVG Training Acc 61.93 % AVG Validation Acc 61.77 %\n",
      "Epoch:120/200 AVG Training Loss:0.656 AVG Validation Loss:0.655 AVG Training Acc 61.92 % AVG Validation Acc 61.77 %\n",
      "Epoch:130/200 AVG Training Loss:0.655 AVG Validation Loss:0.655 AVG Training Acc 61.97 % AVG Validation Acc 61.77 %\n",
      "Epoch   132: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.656 AVG Validation Loss:0.655 AVG Training Acc 61.92 % AVG Validation Acc 61.77 %\n",
      "Epoch:150/200 AVG Training Loss:0.655 AVG Validation Loss:0.655 AVG Training Acc 61.95 % AVG Validation Acc 61.77 %\n",
      "Epoch:160/200 AVG Training Loss:0.656 AVG Validation Loss:0.655 AVG Training Acc 61.96 % AVG Validation Acc 61.77 %\n",
      "Epoch   163: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.654 AVG Validation Loss:0.655 AVG Training Acc 61.95 % AVG Validation Acc 61.77 %\n",
      "Epoch:180/200 AVG Training Loss:0.656 AVG Validation Loss:0.655 AVG Training Acc 61.92 % AVG Validation Acc 61.77 %\n",
      "Epoch:190/200 AVG Training Loss:0.656 AVG Validation Loss:0.655 AVG Training Acc 61.90 % AVG Validation Acc 61.77 %\n",
      "Epoch   194: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.657 AVG Validation Loss:0.655 AVG Training Acc 61.92 % AVG Validation Acc 61.77 %\n",
      "Split 134\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5f791053fa34e65bb2dc8244312b7b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.663 AVG Training Acc 61.85 % AVG Validation Acc 61.95 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:0.670 AVG Training Acc 61.97 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.673 AVG Training Acc 61.83 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.673 AVG Training Acc 61.90 % AVG Validation Acc 61.68 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.650 AVG Validation Loss:0.675 AVG Training Acc 62.07 % AVG Validation Acc 61.86 %\n",
      "Epoch:60/200 AVG Training Loss:0.650 AVG Validation Loss:0.676 AVG Training Acc 61.96 % AVG Validation Acc 61.77 %\n",
      "Epoch:70/200 AVG Training Loss:0.650 AVG Validation Loss:0.676 AVG Training Acc 62.06 % AVG Validation Acc 61.68 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.649 AVG Validation Loss:0.677 AVG Training Acc 62.15 % AVG Validation Acc 61.77 %\n",
      "Epoch:90/200 AVG Training Loss:0.649 AVG Validation Loss:0.677 AVG Training Acc 62.22 % AVG Validation Acc 61.68 %\n",
      "Epoch:100/200 AVG Training Loss:0.648 AVG Validation Loss:0.677 AVG Training Acc 62.20 % AVG Validation Acc 61.68 %\n",
      "Epoch:110/200 AVG Training Loss:0.649 AVG Validation Loss:0.677 AVG Training Acc 62.06 % AVG Validation Acc 61.68 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.649 AVG Validation Loss:0.677 AVG Training Acc 62.02 % AVG Validation Acc 61.68 %\n",
      "Epoch:130/200 AVG Training Loss:0.648 AVG Validation Loss:0.677 AVG Training Acc 61.89 % AVG Validation Acc 61.77 %\n",
      "Epoch:140/200 AVG Training Loss:0.649 AVG Validation Loss:0.677 AVG Training Acc 62.17 % AVG Validation Acc 61.77 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.649 AVG Validation Loss:0.677 AVG Training Acc 62.07 % AVG Validation Acc 61.68 %\n",
      "Epoch:160/200 AVG Training Loss:0.649 AVG Validation Loss:0.677 AVG Training Acc 62.04 % AVG Validation Acc 61.68 %\n",
      "Epoch:170/200 AVG Training Loss:0.649 AVG Validation Loss:0.677 AVG Training Acc 61.83 % AVG Validation Acc 61.68 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.650 AVG Validation Loss:0.677 AVG Training Acc 61.98 % AVG Validation Acc 61.68 %\n",
      "Epoch:190/200 AVG Training Loss:0.648 AVG Validation Loss:0.677 AVG Training Acc 62.14 % AVG Validation Acc 61.68 %\n",
      "Epoch:200/200 AVG Training Loss:0.649 AVG Validation Loss:0.677 AVG Training Acc 62.06 % AVG Validation Acc 61.77 %\n",
      "Split 135\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "728bfc641af8478aa86c988a97dad14b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.664 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.663 AVG Training Acc 61.94 % AVG Validation Acc 61.86 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.670 AVG Training Acc 62.07 % AVG Validation Acc 61.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.649 AVG Validation Loss:0.676 AVG Training Acc 62.12 % AVG Validation Acc 61.77 %\n",
      "Epoch:50/200 AVG Training Loss:0.643 AVG Validation Loss:0.686 AVG Training Acc 62.33 % AVG Validation Acc 61.41 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.638 AVG Validation Loss:0.690 AVG Training Acc 62.46 % AVG Validation Acc 61.23 %\n",
      "Epoch:70/200 AVG Training Loss:0.638 AVG Validation Loss:0.691 AVG Training Acc 62.45 % AVG Validation Acc 61.23 %\n",
      "Epoch:80/200 AVG Training Loss:0.637 AVG Validation Loss:0.693 AVG Training Acc 62.62 % AVG Validation Acc 61.23 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.635 AVG Validation Loss:0.695 AVG Training Acc 62.66 % AVG Validation Acc 61.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.635 AVG Validation Loss:0.694 AVG Training Acc 62.52 % AVG Validation Acc 61.23 %\n",
      "Epoch:110/200 AVG Training Loss:0.635 AVG Validation Loss:0.693 AVG Training Acc 62.52 % AVG Validation Acc 61.23 %\n",
      "Epoch:120/200 AVG Training Loss:0.635 AVG Validation Loss:0.693 AVG Training Acc 62.61 % AVG Validation Acc 61.23 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.636 AVG Validation Loss:0.692 AVG Training Acc 62.65 % AVG Validation Acc 61.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.635 AVG Validation Loss:0.694 AVG Training Acc 62.55 % AVG Validation Acc 61.23 %\n",
      "Epoch:150/200 AVG Training Loss:0.636 AVG Validation Loss:0.694 AVG Training Acc 62.41 % AVG Validation Acc 61.32 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.635 AVG Validation Loss:0.695 AVG Training Acc 62.57 % AVG Validation Acc 61.32 %\n",
      "Epoch:170/200 AVG Training Loss:0.635 AVG Validation Loss:0.694 AVG Training Acc 62.64 % AVG Validation Acc 61.23 %\n",
      "Epoch:180/200 AVG Training Loss:0.636 AVG Validation Loss:0.694 AVG Training Acc 62.72 % AVG Validation Acc 61.14 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.636 AVG Validation Loss:0.694 AVG Training Acc 62.61 % AVG Validation Acc 61.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.634 AVG Validation Loss:0.694 AVG Training Acc 62.81 % AVG Validation Acc 61.23 %\n",
      "Split 136\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b19271c131454bc192275de13047c9db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 61.91 % AVG Validation Acc 62.00 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.663 AVG Training Acc 61.85 % AVG Validation Acc 61.91 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.651 AVG Validation Loss:0.667 AVG Training Acc 61.98 % AVG Validation Acc 61.82 %\n",
      "Epoch:40/200 AVG Training Loss:0.646 AVG Validation Loss:0.673 AVG Training Acc 62.14 % AVG Validation Acc 61.64 %\n",
      "Epoch:50/200 AVG Training Loss:0.642 AVG Validation Loss:0.680 AVG Training Acc 62.15 % AVG Validation Acc 61.55 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.639 AVG Validation Loss:0.686 AVG Training Acc 62.33 % AVG Validation Acc 61.64 %\n",
      "Epoch:70/200 AVG Training Loss:0.638 AVG Validation Loss:0.686 AVG Training Acc 62.39 % AVG Validation Acc 61.64 %\n",
      "Epoch:80/200 AVG Training Loss:0.638 AVG Validation Loss:0.686 AVG Training Acc 62.41 % AVG Validation Acc 61.82 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.637 AVG Validation Loss:0.687 AVG Training Acc 62.58 % AVG Validation Acc 61.91 %\n",
      "Epoch:100/200 AVG Training Loss:0.638 AVG Validation Loss:0.690 AVG Training Acc 62.45 % AVG Validation Acc 61.55 %\n",
      "Epoch:110/200 AVG Training Loss:0.637 AVG Validation Loss:0.686 AVG Training Acc 62.60 % AVG Validation Acc 61.55 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.637 AVG Validation Loss:0.688 AVG Training Acc 62.51 % AVG Validation Acc 61.73 %\n",
      "Epoch:130/200 AVG Training Loss:0.634 AVG Validation Loss:0.688 AVG Training Acc 62.82 % AVG Validation Acc 61.64 %\n",
      "Epoch:140/200 AVG Training Loss:0.638 AVG Validation Loss:0.688 AVG Training Acc 62.38 % AVG Validation Acc 61.82 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.637 AVG Validation Loss:0.688 AVG Training Acc 62.41 % AVG Validation Acc 61.91 %\n",
      "Epoch:160/200 AVG Training Loss:0.637 AVG Validation Loss:0.688 AVG Training Acc 62.51 % AVG Validation Acc 61.55 %\n",
      "Epoch:170/200 AVG Training Loss:0.638 AVG Validation Loss:0.687 AVG Training Acc 62.62 % AVG Validation Acc 61.64 %\n",
      "Epoch:180/200 AVG Training Loss:0.636 AVG Validation Loss:0.690 AVG Training Acc 62.76 % AVG Validation Acc 61.55 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.635 AVG Validation Loss:0.688 AVG Training Acc 62.70 % AVG Validation Acc 61.82 %\n",
      "Epoch:200/200 AVG Training Loss:0.636 AVG Validation Loss:0.690 AVG Training Acc 62.46 % AVG Validation Acc 61.64 %\n",
      "Split 137\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb47a980e40b441d901da71e64eac462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.663 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.664 AVG Training Acc 61.95 % AVG Validation Acc 61.82 %\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.665 AVG Training Acc 61.93 % AVG Validation Acc 61.82 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.667 AVG Training Acc 62.10 % AVG Validation Acc 61.91 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.649 AVG Validation Loss:0.669 AVG Training Acc 62.08 % AVG Validation Acc 61.91 %\n",
      "Epoch:60/200 AVG Training Loss:0.649 AVG Validation Loss:0.670 AVG Training Acc 61.69 % AVG Validation Acc 62.00 %\n",
      "Epoch:70/200 AVG Training Loss:0.648 AVG Validation Loss:0.671 AVG Training Acc 61.76 % AVG Validation Acc 61.91 %\n",
      "Epoch:80/200 AVG Training Loss:0.647 AVG Validation Loss:0.672 AVG Training Acc 61.86 % AVG Validation Acc 62.09 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.647 AVG Validation Loss:0.672 AVG Training Acc 61.97 % AVG Validation Acc 62.09 %\n",
      "Epoch:100/200 AVG Training Loss:0.647 AVG Validation Loss:0.673 AVG Training Acc 61.93 % AVG Validation Acc 62.18 %\n",
      "Epoch:110/200 AVG Training Loss:0.647 AVG Validation Loss:0.673 AVG Training Acc 61.81 % AVG Validation Acc 62.09 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.646 AVG Validation Loss:0.673 AVG Training Acc 62.01 % AVG Validation Acc 62.09 %\n",
      "Epoch:130/200 AVG Training Loss:0.647 AVG Validation Loss:0.672 AVG Training Acc 62.15 % AVG Validation Acc 62.18 %\n",
      "Epoch:140/200 AVG Training Loss:0.647 AVG Validation Loss:0.672 AVG Training Acc 61.84 % AVG Validation Acc 62.00 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.648 AVG Validation Loss:0.673 AVG Training Acc 61.84 % AVG Validation Acc 62.18 %\n",
      "Epoch:160/200 AVG Training Loss:0.646 AVG Validation Loss:0.672 AVG Training Acc 62.07 % AVG Validation Acc 62.09 %\n",
      "Epoch:170/200 AVG Training Loss:0.648 AVG Validation Loss:0.673 AVG Training Acc 62.07 % AVG Validation Acc 62.18 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.647 AVG Validation Loss:0.672 AVG Training Acc 62.07 % AVG Validation Acc 62.18 %\n",
      "Epoch:190/200 AVG Training Loss:0.645 AVG Validation Loss:0.672 AVG Training Acc 62.20 % AVG Validation Acc 62.09 %\n",
      "Epoch:200/200 AVG Training Loss:0.646 AVG Validation Loss:0.673 AVG Training Acc 62.10 % AVG Validation Acc 62.18 %\n",
      "Split 138\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85f89cc580e44b7b7360c8f6bb3efb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.658 AVG Training Acc 61.88 % AVG Validation Acc 62.00 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.657 AVG Training Acc 61.86 % AVG Validation Acc 61.82 %\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.661 AVG Training Acc 61.93 % AVG Validation Acc 62.00 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.655 AVG Training Acc 61.88 % AVG Validation Acc 62.18 %\n",
      "Epoch:50/200 AVG Training Loss:0.649 AVG Validation Loss:0.660 AVG Training Acc 62.39 % AVG Validation Acc 61.82 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.640 AVG Validation Loss:0.661 AVG Training Acc 62.76 % AVG Validation Acc 62.18 %\n",
      "Epoch:70/200 AVG Training Loss:0.636 AVG Validation Loss:0.661 AVG Training Acc 63.00 % AVG Validation Acc 62.64 %\n",
      "Epoch:80/200 AVG Training Loss:0.632 AVG Validation Loss:0.663 AVG Training Acc 63.42 % AVG Validation Acc 62.09 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.634 AVG Validation Loss:0.665 AVG Training Acc 63.39 % AVG Validation Acc 61.73 %\n",
      "Epoch:100/200 AVG Training Loss:0.630 AVG Validation Loss:0.666 AVG Training Acc 63.46 % AVG Validation Acc 62.09 %\n",
      "Epoch:110/200 AVG Training Loss:0.631 AVG Validation Loss:0.667 AVG Training Acc 63.39 % AVG Validation Acc 61.73 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.630 AVG Validation Loss:0.680 AVG Training Acc 63.31 % AVG Validation Acc 61.82 %\n",
      "Epoch:130/200 AVG Training Loss:0.630 AVG Validation Loss:0.680 AVG Training Acc 63.66 % AVG Validation Acc 61.82 %\n",
      "Epoch:140/200 AVG Training Loss:0.629 AVG Validation Loss:0.667 AVG Training Acc 63.62 % AVG Validation Acc 61.91 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.630 AVG Validation Loss:0.678 AVG Training Acc 63.46 % AVG Validation Acc 62.00 %\n",
      "Epoch:160/200 AVG Training Loss:0.629 AVG Validation Loss:0.666 AVG Training Acc 63.55 % AVG Validation Acc 62.00 %\n",
      "Epoch:170/200 AVG Training Loss:0.628 AVG Validation Loss:0.668 AVG Training Acc 63.65 % AVG Validation Acc 61.64 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.630 AVG Validation Loss:0.680 AVG Training Acc 63.76 % AVG Validation Acc 61.64 %\n",
      "Epoch:190/200 AVG Training Loss:0.630 AVG Validation Loss:0.668 AVG Training Acc 63.30 % AVG Validation Acc 61.82 %\n",
      "Epoch:200/200 AVG Training Loss:0.630 AVG Validation Loss:0.667 AVG Training Acc 63.75 % AVG Validation Acc 61.91 %\n",
      "Split 139\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "957d89e041b949aaaeecda19c4a9708b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.662 AVG Validation Loss:0.658 AVG Training Acc 61.86 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.656 AVG Training Acc 61.92 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.655 AVG Training Acc 61.84 % AVG Validation Acc 61.73 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.658 AVG Training Acc 62.11 % AVG Validation Acc 62.45 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.642 AVG Validation Loss:0.661 AVG Training Acc 62.14 % AVG Validation Acc 62.27 %\n",
      "Epoch:60/200 AVG Training Loss:0.637 AVG Validation Loss:0.666 AVG Training Acc 62.65 % AVG Validation Acc 61.73 %\n",
      "Epoch:70/200 AVG Training Loss:0.632 AVG Validation Loss:0.667 AVG Training Acc 63.20 % AVG Validation Acc 61.28 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.629 AVG Validation Loss:0.674 AVG Training Acc 63.43 % AVG Validation Acc 60.83 %\n",
      "Epoch:90/200 AVG Training Loss:0.629 AVG Validation Loss:0.674 AVG Training Acc 63.33 % AVG Validation Acc 61.64 %\n",
      "Epoch:100/200 AVG Training Loss:0.626 AVG Validation Loss:0.677 AVG Training Acc 63.46 % AVG Validation Acc 61.55 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.627 AVG Validation Loss:0.677 AVG Training Acc 63.60 % AVG Validation Acc 61.19 %\n",
      "Epoch:120/200 AVG Training Loss:0.628 AVG Validation Loss:0.677 AVG Training Acc 63.48 % AVG Validation Acc 61.28 %\n",
      "Epoch:130/200 AVG Training Loss:0.627 AVG Validation Loss:0.678 AVG Training Acc 63.59 % AVG Validation Acc 61.10 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.628 AVG Validation Loss:0.678 AVG Training Acc 63.32 % AVG Validation Acc 61.19 %\n",
      "Epoch:150/200 AVG Training Loss:0.629 AVG Validation Loss:0.678 AVG Training Acc 63.23 % AVG Validation Acc 61.19 %\n",
      "Epoch:160/200 AVG Training Loss:0.626 AVG Validation Loss:0.676 AVG Training Acc 63.53 % AVG Validation Acc 61.55 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.626 AVG Validation Loss:0.677 AVG Training Acc 63.45 % AVG Validation Acc 61.37 %\n",
      "Epoch:180/200 AVG Training Loss:0.627 AVG Validation Loss:0.677 AVG Training Acc 63.25 % AVG Validation Acc 61.19 %\n",
      "Epoch:190/200 AVG Training Loss:0.627 AVG Validation Loss:0.673 AVG Training Acc 63.49 % AVG Validation Acc 61.28 %\n",
      "Epoch:200/200 AVG Training Loss:0.627 AVG Validation Loss:0.675 AVG Training Acc 63.06 % AVG Validation Acc 61.37 %\n",
      "Epoch   200: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Split 140\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b18217d7144048fcbad98493079c3671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.661 AVG Training Acc 61.91 % AVG Validation Acc 61.82 %\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.666 AVG Training Acc 61.70 % AVG Validation Acc 61.64 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.644 AVG Validation Loss:0.665 AVG Training Acc 62.04 % AVG Validation Acc 61.64 %\n",
      "Epoch:50/200 AVG Training Loss:0.640 AVG Validation Loss:0.667 AVG Training Acc 62.54 % AVG Validation Acc 61.55 %\n",
      "Epoch:60/200 AVG Training Loss:0.635 AVG Validation Loss:0.668 AVG Training Acc 62.67 % AVG Validation Acc 61.64 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.631 AVG Validation Loss:0.674 AVG Training Acc 62.48 % AVG Validation Acc 61.01 %\n",
      "Epoch:80/200 AVG Training Loss:0.629 AVG Validation Loss:0.677 AVG Training Acc 62.73 % AVG Validation Acc 60.56 %\n",
      "Epoch:90/200 AVG Training Loss:0.630 AVG Validation Loss:0.678 AVG Training Acc 62.38 % AVG Validation Acc 60.83 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.629 AVG Validation Loss:0.679 AVG Training Acc 62.72 % AVG Validation Acc 60.83 %\n",
      "Epoch:110/200 AVG Training Loss:0.628 AVG Validation Loss:0.678 AVG Training Acc 62.80 % AVG Validation Acc 60.83 %\n",
      "Epoch:120/200 AVG Training Loss:0.628 AVG Validation Loss:0.679 AVG Training Acc 63.10 % AVG Validation Acc 60.65 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.629 AVG Validation Loss:0.678 AVG Training Acc 62.87 % AVG Validation Acc 60.83 %\n",
      "Epoch:140/200 AVG Training Loss:0.630 AVG Validation Loss:0.678 AVG Training Acc 62.52 % AVG Validation Acc 61.01 %\n",
      "Epoch:150/200 AVG Training Loss:0.628 AVG Validation Loss:0.678 AVG Training Acc 62.78 % AVG Validation Acc 60.92 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.631 AVG Validation Loss:0.680 AVG Training Acc 62.90 % AVG Validation Acc 60.83 %\n",
      "Epoch:170/200 AVG Training Loss:0.629 AVG Validation Loss:0.678 AVG Training Acc 62.57 % AVG Validation Acc 61.10 %\n",
      "Epoch:180/200 AVG Training Loss:0.628 AVG Validation Loss:0.678 AVG Training Acc 62.77 % AVG Validation Acc 60.83 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.628 AVG Validation Loss:0.679 AVG Training Acc 62.98 % AVG Validation Acc 60.74 %\n",
      "Epoch:200/200 AVG Training Loss:0.630 AVG Validation Loss:0.678 AVG Training Acc 62.86 % AVG Validation Acc 60.92 %\n",
      "Split 141\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec0719f13d5b4c95bdbbdd1b300e874a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 61.83 % AVG Validation Acc 61.95 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.663 AVG Training Acc 61.92 % AVG Validation Acc 61.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.651 AVG Validation Loss:0.664 AVG Training Acc 62.12 % AVG Validation Acc 61.77 %\n",
      "Epoch:40/200 AVG Training Loss:0.648 AVG Validation Loss:0.667 AVG Training Acc 62.06 % AVG Validation Acc 61.95 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.644 AVG Validation Loss:0.667 AVG Training Acc 62.24 % AVG Validation Acc 61.95 %\n",
      "Epoch:60/200 AVG Training Loss:0.643 AVG Validation Loss:0.668 AVG Training Acc 62.04 % AVG Validation Acc 61.86 %\n",
      "Epoch:70/200 AVG Training Loss:0.643 AVG Validation Loss:0.669 AVG Training Acc 62.37 % AVG Validation Acc 61.14 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.641 AVG Validation Loss:0.670 AVG Training Acc 62.30 % AVG Validation Acc 61.32 %\n",
      "Epoch:90/200 AVG Training Loss:0.641 AVG Validation Loss:0.671 AVG Training Acc 62.25 % AVG Validation Acc 61.32 %\n",
      "Epoch:100/200 AVG Training Loss:0.641 AVG Validation Loss:0.671 AVG Training Acc 62.20 % AVG Validation Acc 61.23 %\n",
      "Epoch:110/200 AVG Training Loss:0.640 AVG Validation Loss:0.671 AVG Training Acc 62.31 % AVG Validation Acc 61.05 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.641 AVG Validation Loss:0.671 AVG Training Acc 62.35 % AVG Validation Acc 61.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.642 AVG Validation Loss:0.671 AVG Training Acc 62.35 % AVG Validation Acc 61.41 %\n",
      "Epoch:140/200 AVG Training Loss:0.641 AVG Validation Loss:0.671 AVG Training Acc 62.39 % AVG Validation Acc 61.14 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.641 AVG Validation Loss:0.671 AVG Training Acc 62.36 % AVG Validation Acc 61.50 %\n",
      "Epoch:160/200 AVG Training Loss:0.641 AVG Validation Loss:0.671 AVG Training Acc 62.37 % AVG Validation Acc 61.50 %\n",
      "Epoch:170/200 AVG Training Loss:0.642 AVG Validation Loss:0.671 AVG Training Acc 62.11 % AVG Validation Acc 61.32 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.640 AVG Validation Loss:0.670 AVG Training Acc 62.49 % AVG Validation Acc 61.32 %\n",
      "Epoch:190/200 AVG Training Loss:0.641 AVG Validation Loss:0.671 AVG Training Acc 62.67 % AVG Validation Acc 61.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.640 AVG Validation Loss:0.671 AVG Training Acc 62.35 % AVG Validation Acc 61.14 %\n",
      "Split 142\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83832673eb3c44e5ae467c4f534093e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.655 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.656 AVG Training Acc 61.88 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.659 AVG Validation Loss:0.655 AVG Training Acc 61.79 % AVG Validation Acc 61.86 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.655 AVG Training Acc 61.99 % AVG Validation Acc 62.13 %\n",
      "Epoch:50/200 AVG Training Loss:0.650 AVG Validation Loss:0.656 AVG Training Acc 62.05 % AVG Validation Acc 61.95 %\n",
      "Epoch:60/200 AVG Training Loss:0.649 AVG Validation Loss:0.657 AVG Training Acc 61.90 % AVG Validation Acc 61.68 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.647 AVG Validation Loss:0.660 AVG Training Acc 62.00 % AVG Validation Acc 61.59 %\n",
      "Epoch:80/200 AVG Training Loss:0.647 AVG Validation Loss:0.659 AVG Training Acc 62.35 % AVG Validation Acc 61.95 %\n",
      "Epoch:90/200 AVG Training Loss:0.648 AVG Validation Loss:0.659 AVG Training Acc 62.14 % AVG Validation Acc 62.40 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.646 AVG Validation Loss:0.660 AVG Training Acc 62.14 % AVG Validation Acc 61.95 %\n",
      "Epoch:110/200 AVG Training Loss:0.647 AVG Validation Loss:0.660 AVG Training Acc 62.23 % AVG Validation Acc 61.77 %\n",
      "Epoch:120/200 AVG Training Loss:0.646 AVG Validation Loss:0.660 AVG Training Acc 62.35 % AVG Validation Acc 62.13 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.647 AVG Validation Loss:0.661 AVG Training Acc 61.92 % AVG Validation Acc 61.77 %\n",
      "Epoch:140/200 AVG Training Loss:0.646 AVG Validation Loss:0.661 AVG Training Acc 62.19 % AVG Validation Acc 61.86 %\n",
      "Epoch:150/200 AVG Training Loss:0.647 AVG Validation Loss:0.659 AVG Training Acc 62.06 % AVG Validation Acc 61.86 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.646 AVG Validation Loss:0.660 AVG Training Acc 62.17 % AVG Validation Acc 62.13 %\n",
      "Epoch:170/200 AVG Training Loss:0.646 AVG Validation Loss:0.660 AVG Training Acc 62.47 % AVG Validation Acc 62.22 %\n",
      "Epoch:180/200 AVG Training Loss:0.647 AVG Validation Loss:0.660 AVG Training Acc 62.34 % AVG Validation Acc 61.77 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.646 AVG Validation Loss:0.660 AVG Training Acc 62.10 % AVG Validation Acc 61.86 %\n",
      "Epoch:200/200 AVG Training Loss:0.646 AVG Validation Loss:0.662 AVG Training Acc 62.22 % AVG Validation Acc 61.86 %\n",
      "Split 143\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a877f2107c6d4eb8961099d329013de2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.658 AVG Training Acc 61.88 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.657 AVG Training Acc 61.91 % AVG Validation Acc 62.04 %\n",
      "Epoch:30/200 AVG Training Loss:0.665 AVG Validation Loss:0.659 AVG Training Acc 61.54 % AVG Validation Acc 61.86 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.656 AVG Validation Loss:0.658 AVG Training Acc 62.05 % AVG Validation Acc 61.86 %\n",
      "Epoch:50/200 AVG Training Loss:0.655 AVG Validation Loss:0.657 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:60/200 AVG Training Loss:0.651 AVG Validation Loss:0.658 AVG Training Acc 62.13 % AVG Validation Acc 61.95 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.648 AVG Validation Loss:0.658 AVG Training Acc 62.03 % AVG Validation Acc 61.41 %\n",
      "Epoch:80/200 AVG Training Loss:0.648 AVG Validation Loss:0.659 AVG Training Acc 62.29 % AVG Validation Acc 61.23 %\n",
      "Epoch:90/200 AVG Training Loss:0.648 AVG Validation Loss:0.659 AVG Training Acc 62.11 % AVG Validation Acc 61.41 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.647 AVG Validation Loss:0.659 AVG Training Acc 62.16 % AVG Validation Acc 61.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.647 AVG Validation Loss:0.659 AVG Training Acc 62.18 % AVG Validation Acc 61.41 %\n",
      "Epoch:120/200 AVG Training Loss:0.649 AVG Validation Loss:0.659 AVG Training Acc 62.26 % AVG Validation Acc 61.32 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.649 AVG Validation Loss:0.660 AVG Training Acc 62.19 % AVG Validation Acc 61.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.646 AVG Validation Loss:0.659 AVG Training Acc 62.18 % AVG Validation Acc 61.32 %\n",
      "Epoch:150/200 AVG Training Loss:0.647 AVG Validation Loss:0.659 AVG Training Acc 62.07 % AVG Validation Acc 61.32 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.648 AVG Validation Loss:0.659 AVG Training Acc 62.34 % AVG Validation Acc 61.23 %\n",
      "Epoch:170/200 AVG Training Loss:0.645 AVG Validation Loss:0.659 AVG Training Acc 62.58 % AVG Validation Acc 61.23 %\n",
      "Epoch:180/200 AVG Training Loss:0.647 AVG Validation Loss:0.660 AVG Training Acc 61.86 % AVG Validation Acc 61.14 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.648 AVG Validation Loss:0.659 AVG Training Acc 62.05 % AVG Validation Acc 61.32 %\n",
      "Epoch:200/200 AVG Training Loss:0.647 AVG Validation Loss:0.658 AVG Training Acc 62.44 % AVG Validation Acc 61.32 %\n",
      "Split 144\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b763fc96f95412ebd210081813a59d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.660 AVG Training Acc 61.88 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.661 AVG Training Acc 61.79 % AVG Validation Acc 61.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.662 AVG Training Acc 61.77 % AVG Validation Acc 61.77 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.647 AVG Validation Loss:0.658 AVG Training Acc 61.95 % AVG Validation Acc 61.86 %\n",
      "Epoch:50/200 AVG Training Loss:0.644 AVG Validation Loss:0.662 AVG Training Acc 62.38 % AVG Validation Acc 61.32 %\n",
      "Epoch:60/200 AVG Training Loss:0.639 AVG Validation Loss:0.665 AVG Training Acc 62.63 % AVG Validation Acc 61.05 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.636 AVG Validation Loss:0.667 AVG Training Acc 62.87 % AVG Validation Acc 60.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.635 AVG Validation Loss:0.670 AVG Training Acc 62.71 % AVG Validation Acc 60.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.634 AVG Validation Loss:0.670 AVG Training Acc 62.63 % AVG Validation Acc 60.87 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.634 AVG Validation Loss:0.672 AVG Training Acc 62.91 % AVG Validation Acc 60.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.633 AVG Validation Loss:0.670 AVG Training Acc 63.11 % AVG Validation Acc 60.87 %\n",
      "Epoch:120/200 AVG Training Loss:0.635 AVG Validation Loss:0.671 AVG Training Acc 62.94 % AVG Validation Acc 60.78 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.634 AVG Validation Loss:0.671 AVG Training Acc 62.67 % AVG Validation Acc 61.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.633 AVG Validation Loss:0.671 AVG Training Acc 63.14 % AVG Validation Acc 60.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.635 AVG Validation Loss:0.670 AVG Training Acc 62.90 % AVG Validation Acc 60.96 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.634 AVG Validation Loss:0.671 AVG Training Acc 62.65 % AVG Validation Acc 60.96 %\n",
      "Epoch:170/200 AVG Training Loss:0.634 AVG Validation Loss:0.670 AVG Training Acc 62.98 % AVG Validation Acc 60.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.635 AVG Validation Loss:0.671 AVG Training Acc 62.81 % AVG Validation Acc 60.87 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.632 AVG Validation Loss:0.672 AVG Training Acc 62.91 % AVG Validation Acc 60.87 %\n",
      "Epoch:200/200 AVG Training Loss:0.633 AVG Validation Loss:0.672 AVG Training Acc 62.92 % AVG Validation Acc 60.78 %\n",
      "Split 145\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "efcc2f8287b24706bcf3e7c24bbb0d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.658 AVG Training Acc 61.94 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.657 AVG Training Acc 61.92 % AVG Validation Acc 61.86 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.658 AVG Training Acc 61.98 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.655 AVG Validation Loss:0.659 AVG Training Acc 62.00 % AVG Validation Acc 61.77 %\n",
      "Epoch:50/200 AVG Training Loss:0.653 AVG Validation Loss:0.660 AVG Training Acc 62.05 % AVG Validation Acc 61.77 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.651 AVG Validation Loss:0.661 AVG Training Acc 62.12 % AVG Validation Acc 61.77 %\n",
      "Epoch:70/200 AVG Training Loss:0.651 AVG Validation Loss:0.660 AVG Training Acc 62.16 % AVG Validation Acc 61.77 %\n",
      "Epoch:80/200 AVG Training Loss:0.649 AVG Validation Loss:0.660 AVG Training Acc 62.13 % AVG Validation Acc 61.77 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.650 AVG Validation Loss:0.662 AVG Training Acc 62.19 % AVG Validation Acc 61.77 %\n",
      "Epoch:100/200 AVG Training Loss:0.649 AVG Validation Loss:0.661 AVG Training Acc 62.23 % AVG Validation Acc 61.77 %\n",
      "Epoch:110/200 AVG Training Loss:0.650 AVG Validation Loss:0.661 AVG Training Acc 62.16 % AVG Validation Acc 61.77 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.650 AVG Validation Loss:0.662 AVG Training Acc 62.18 % AVG Validation Acc 61.77 %\n",
      "Epoch:130/200 AVG Training Loss:0.650 AVG Validation Loss:0.661 AVG Training Acc 62.20 % AVG Validation Acc 61.77 %\n",
      "Epoch:140/200 AVG Training Loss:0.650 AVG Validation Loss:0.662 AVG Training Acc 62.09 % AVG Validation Acc 61.77 %\n",
      "Epoch:150/200 AVG Training Loss:0.649 AVG Validation Loss:0.661 AVG Training Acc 62.15 % AVG Validation Acc 61.77 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.648 AVG Validation Loss:0.661 AVG Training Acc 62.21 % AVG Validation Acc 61.77 %\n",
      "Epoch:170/200 AVG Training Loss:0.650 AVG Validation Loss:0.662 AVG Training Acc 62.12 % AVG Validation Acc 61.77 %\n",
      "Epoch:180/200 AVG Training Loss:0.649 AVG Validation Loss:0.662 AVG Training Acc 62.11 % AVG Validation Acc 61.77 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.650 AVG Validation Loss:0.661 AVG Training Acc 62.17 % AVG Validation Acc 61.77 %\n",
      "Epoch:200/200 AVG Training Loss:0.650 AVG Validation Loss:0.661 AVG Training Acc 62.20 % AVG Validation Acc 61.77 %\n",
      "Split 146\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5ff4fbf909c4fd2b9ed56f8592dd102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.665 AVG Training Acc 61.73 % AVG Validation Acc 61.91 %\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:0.664 AVG Training Acc 61.91 % AVG Validation Acc 61.73 %\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.663 AVG Training Acc 61.96 % AVG Validation Acc 61.46 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.667 AVG Training Acc 61.91 % AVG Validation Acc 61.28 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 62.14 % AVG Validation Acc 61.19 %\n",
      "Epoch:60/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 62.24 % AVG Validation Acc 61.28 %\n",
      "Epoch:70/200 AVG Training Loss:0.648 AVG Validation Loss:0.668 AVG Training Acc 62.09 % AVG Validation Acc 61.28 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.647 AVG Validation Loss:0.668 AVG Training Acc 62.30 % AVG Validation Acc 61.28 %\n",
      "Epoch:90/200 AVG Training Loss:0.648 AVG Validation Loss:0.668 AVG Training Acc 62.20 % AVG Validation Acc 61.28 %\n",
      "Epoch:100/200 AVG Training Loss:0.648 AVG Validation Loss:0.669 AVG Training Acc 62.12 % AVG Validation Acc 61.37 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.648 AVG Validation Loss:0.669 AVG Training Acc 62.03 % AVG Validation Acc 61.37 %\n",
      "Epoch:120/200 AVG Training Loss:0.647 AVG Validation Loss:0.668 AVG Training Acc 62.27 % AVG Validation Acc 61.28 %\n",
      "Epoch:130/200 AVG Training Loss:0.648 AVG Validation Loss:0.669 AVG Training Acc 62.16 % AVG Validation Acc 61.37 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.647 AVG Validation Loss:0.669 AVG Training Acc 62.25 % AVG Validation Acc 61.37 %\n",
      "Epoch:150/200 AVG Training Loss:0.647 AVG Validation Loss:0.669 AVG Training Acc 62.26 % AVG Validation Acc 61.37 %\n",
      "Epoch:160/200 AVG Training Loss:0.648 AVG Validation Loss:0.668 AVG Training Acc 62.11 % AVG Validation Acc 61.37 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.647 AVG Validation Loss:0.669 AVG Training Acc 62.22 % AVG Validation Acc 61.37 %\n",
      "Epoch:180/200 AVG Training Loss:0.647 AVG Validation Loss:0.669 AVG Training Acc 62.18 % AVG Validation Acc 61.37 %\n",
      "Epoch:190/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 61.93 % AVG Validation Acc 61.37 %\n",
      "Epoch:200/200 AVG Training Loss:0.647 AVG Validation Loss:0.669 AVG Training Acc 62.22 % AVG Validation Acc 61.37 %\n",
      "Split 147\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9566fc1047904bce8599c64d78d5afff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.663 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.660 AVG Training Acc 61.92 % AVG Validation Acc 62.00 %\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.665 AVG Training Acc 61.82 % AVG Validation Acc 61.73 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.644 AVG Validation Loss:0.668 AVG Training Acc 62.53 % AVG Validation Acc 61.19 %\n",
      "Epoch:50/200 AVG Training Loss:0.639 AVG Validation Loss:0.678 AVG Training Acc 62.81 % AVG Validation Acc 59.93 %\n",
      "Epoch:60/200 AVG Training Loss:0.636 AVG Validation Loss:0.689 AVG Training Acc 62.77 % AVG Validation Acc 60.74 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.631 AVG Validation Loss:0.695 AVG Training Acc 63.13 % AVG Validation Acc 60.20 %\n",
      "Epoch:80/200 AVG Training Loss:0.630 AVG Validation Loss:0.693 AVG Training Acc 63.44 % AVG Validation Acc 60.20 %\n",
      "Epoch:90/200 AVG Training Loss:0.630 AVG Validation Loss:0.695 AVG Training Acc 63.32 % AVG Validation Acc 60.74 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.631 AVG Validation Loss:0.696 AVG Training Acc 63.09 % AVG Validation Acc 60.02 %\n",
      "Epoch:110/200 AVG Training Loss:0.630 AVG Validation Loss:0.696 AVG Training Acc 63.33 % AVG Validation Acc 60.29 %\n",
      "Epoch:120/200 AVG Training Loss:0.630 AVG Validation Loss:0.696 AVG Training Acc 63.21 % AVG Validation Acc 60.29 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.630 AVG Validation Loss:0.699 AVG Training Acc 62.91 % AVG Validation Acc 60.29 %\n",
      "Epoch:140/200 AVG Training Loss:0.631 AVG Validation Loss:0.697 AVG Training Acc 63.28 % AVG Validation Acc 60.11 %\n",
      "Epoch:150/200 AVG Training Loss:0.631 AVG Validation Loss:0.695 AVG Training Acc 62.98 % AVG Validation Acc 60.02 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.629 AVG Validation Loss:0.696 AVG Training Acc 62.92 % AVG Validation Acc 60.47 %\n",
      "Epoch:170/200 AVG Training Loss:0.630 AVG Validation Loss:0.697 AVG Training Acc 63.17 % AVG Validation Acc 60.65 %\n",
      "Epoch:180/200 AVG Training Loss:0.631 AVG Validation Loss:0.695 AVG Training Acc 62.72 % AVG Validation Acc 60.74 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.630 AVG Validation Loss:0.697 AVG Training Acc 63.09 % AVG Validation Acc 60.11 %\n",
      "Epoch:200/200 AVG Training Loss:0.629 AVG Validation Loss:0.695 AVG Training Acc 63.14 % AVG Validation Acc 59.93 %\n",
      "Split 148\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9f4ae84fd7d480ab19f23947933a468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.665 AVG Training Acc 61.73 % AVG Validation Acc 62.00 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:0.669 AVG Training Acc 61.96 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.673 AVG Training Acc 62.03 % AVG Validation Acc 62.00 %\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.680 AVG Training Acc 62.05 % AVG Validation Acc 61.91 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.645 AVG Validation Loss:0.687 AVG Training Acc 62.13 % AVG Validation Acc 61.82 %\n",
      "Epoch:60/200 AVG Training Loss:0.645 AVG Validation Loss:0.689 AVG Training Acc 62.13 % AVG Validation Acc 61.82 %\n",
      "Epoch:70/200 AVG Training Loss:0.643 AVG Validation Loss:0.691 AVG Training Acc 62.18 % AVG Validation Acc 61.82 %\n",
      "Epoch:80/200 AVG Training Loss:0.644 AVG Validation Loss:0.691 AVG Training Acc 62.28 % AVG Validation Acc 61.82 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.643 AVG Validation Loss:0.691 AVG Training Acc 62.35 % AVG Validation Acc 61.91 %\n",
      "Epoch:100/200 AVG Training Loss:0.644 AVG Validation Loss:0.691 AVG Training Acc 62.40 % AVG Validation Acc 61.82 %\n",
      "Epoch:110/200 AVG Training Loss:0.643 AVG Validation Loss:0.693 AVG Training Acc 62.25 % AVG Validation Acc 61.82 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.643 AVG Validation Loss:0.690 AVG Training Acc 62.14 % AVG Validation Acc 61.91 %\n",
      "Epoch:130/200 AVG Training Loss:0.643 AVG Validation Loss:0.692 AVG Training Acc 62.34 % AVG Validation Acc 61.91 %\n",
      "Epoch:140/200 AVG Training Loss:0.643 AVG Validation Loss:0.693 AVG Training Acc 62.19 % AVG Validation Acc 61.91 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.644 AVG Validation Loss:0.692 AVG Training Acc 62.08 % AVG Validation Acc 61.91 %\n",
      "Epoch:160/200 AVG Training Loss:0.642 AVG Validation Loss:0.692 AVG Training Acc 62.19 % AVG Validation Acc 61.91 %\n",
      "Epoch:170/200 AVG Training Loss:0.644 AVG Validation Loss:0.692 AVG Training Acc 62.32 % AVG Validation Acc 61.73 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.644 AVG Validation Loss:0.692 AVG Training Acc 62.11 % AVG Validation Acc 61.91 %\n",
      "Epoch:190/200 AVG Training Loss:0.644 AVG Validation Loss:0.691 AVG Training Acc 62.07 % AVG Validation Acc 61.73 %\n",
      "Epoch:200/200 AVG Training Loss:0.643 AVG Validation Loss:0.692 AVG Training Acc 62.22 % AVG Validation Acc 61.91 %\n",
      "Split 149\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4413ddc8a4a442783d4cdbe376de239",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.659 AVG Training Acc 61.85 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.659 AVG Training Acc 61.84 % AVG Validation Acc 61.82 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.658 AVG Training Acc 61.93 % AVG Validation Acc 61.82 %\n",
      "Epoch:40/200 AVG Training Loss:0.655 AVG Validation Loss:0.660 AVG Training Acc 62.01 % AVG Validation Acc 61.82 %\n",
      "Epoch:50/200 AVG Training Loss:0.654 AVG Validation Loss:0.660 AVG Training Acc 61.69 % AVG Validation Acc 61.73 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.651 AVG Validation Loss:0.662 AVG Training Acc 62.05 % AVG Validation Acc 61.82 %\n",
      "Epoch:70/200 AVG Training Loss:0.651 AVG Validation Loss:0.663 AVG Training Acc 61.98 % AVG Validation Acc 61.82 %\n",
      "Epoch:80/200 AVG Training Loss:0.651 AVG Validation Loss:0.663 AVG Training Acc 61.92 % AVG Validation Acc 61.91 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.650 AVG Validation Loss:0.664 AVG Training Acc 62.12 % AVG Validation Acc 61.82 %\n",
      "Epoch:100/200 AVG Training Loss:0.650 AVG Validation Loss:0.664 AVG Training Acc 61.98 % AVG Validation Acc 61.91 %\n",
      "Epoch:110/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.23 % AVG Validation Acc 61.82 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.650 AVG Validation Loss:0.663 AVG Training Acc 62.14 % AVG Validation Acc 61.82 %\n",
      "Epoch:130/200 AVG Training Loss:0.650 AVG Validation Loss:0.664 AVG Training Acc 61.91 % AVG Validation Acc 61.73 %\n",
      "Epoch:140/200 AVG Training Loss:0.650 AVG Validation Loss:0.664 AVG Training Acc 61.85 % AVG Validation Acc 61.82 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.650 AVG Validation Loss:0.664 AVG Training Acc 62.28 % AVG Validation Acc 61.82 %\n",
      "Epoch:160/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.12 % AVG Validation Acc 61.91 %\n",
      "Epoch:170/200 AVG Training Loss:0.650 AVG Validation Loss:0.665 AVG Training Acc 62.19 % AVG Validation Acc 61.82 %\n",
      "Epoch:180/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.15 % AVG Validation Acc 61.82 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.649 AVG Validation Loss:0.663 AVG Training Acc 62.28 % AVG Validation Acc 61.73 %\n",
      "Epoch:200/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.12 % AVG Validation Acc 61.91 %\n",
      "Split 150\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a9b53cf83834171ab40f426c2af7a08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.660 AVG Training Acc 61.87 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.660 AVG Training Acc 61.77 % AVG Validation Acc 61.91 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.663 AVG Training Acc 61.99 % AVG Validation Acc 61.73 %\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.662 AVG Training Acc 61.94 % AVG Validation Acc 61.64 %\n",
      "Epoch:50/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.14 % AVG Validation Acc 61.37 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.644 AVG Validation Loss:0.667 AVG Training Acc 62.28 % AVG Validation Acc 61.37 %\n",
      "Epoch:70/200 AVG Training Loss:0.643 AVG Validation Loss:0.668 AVG Training Acc 62.43 % AVG Validation Acc 61.28 %\n",
      "Epoch:80/200 AVG Training Loss:0.643 AVG Validation Loss:0.669 AVG Training Acc 62.49 % AVG Validation Acc 61.37 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.641 AVG Validation Loss:0.670 AVG Training Acc 62.66 % AVG Validation Acc 61.10 %\n",
      "Epoch:100/200 AVG Training Loss:0.642 AVG Validation Loss:0.669 AVG Training Acc 62.45 % AVG Validation Acc 61.19 %\n",
      "Epoch:110/200 AVG Training Loss:0.642 AVG Validation Loss:0.670 AVG Training Acc 62.22 % AVG Validation Acc 61.19 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.642 AVG Validation Loss:0.669 AVG Training Acc 62.51 % AVG Validation Acc 61.19 %\n",
      "Epoch:130/200 AVG Training Loss:0.642 AVG Validation Loss:0.670 AVG Training Acc 62.41 % AVG Validation Acc 60.74 %\n",
      "Epoch:140/200 AVG Training Loss:0.641 AVG Validation Loss:0.669 AVG Training Acc 62.24 % AVG Validation Acc 60.92 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.643 AVG Validation Loss:0.669 AVG Training Acc 62.38 % AVG Validation Acc 61.01 %\n",
      "Epoch:160/200 AVG Training Loss:0.641 AVG Validation Loss:0.670 AVG Training Acc 62.42 % AVG Validation Acc 61.28 %\n",
      "Epoch:170/200 AVG Training Loss:0.642 AVG Validation Loss:0.670 AVG Training Acc 62.37 % AVG Validation Acc 61.28 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.642 AVG Validation Loss:0.670 AVG Training Acc 62.24 % AVG Validation Acc 61.10 %\n",
      "Epoch:190/200 AVG Training Loss:0.642 AVG Validation Loss:0.670 AVG Training Acc 62.28 % AVG Validation Acc 61.19 %\n",
      "Epoch:200/200 AVG Training Loss:0.641 AVG Validation Loss:0.671 AVG Training Acc 62.35 % AVG Validation Acc 60.92 %\n",
      "Split 151\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "444abe1ce84e4d20880614d06df6a9ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.657 AVG Training Acc 61.87 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.656 AVG Training Acc 61.83 % AVG Validation Acc 61.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.654 AVG Training Acc 61.94 % AVG Validation Acc 61.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.657 AVG Validation Loss:0.656 AVG Training Acc 61.84 % AVG Validation Acc 61.86 %\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.650 AVG Validation Loss:0.660 AVG Training Acc 62.22 % AVG Validation Acc 62.31 %\n",
      "Epoch:60/200 AVG Training Loss:0.648 AVG Validation Loss:0.666 AVG Training Acc 62.31 % AVG Validation Acc 61.86 %\n",
      "Epoch:70/200 AVG Training Loss:0.644 AVG Validation Loss:0.672 AVG Training Acc 62.66 % AVG Validation Acc 61.77 %\n",
      "Epoch    71: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.642 AVG Validation Loss:0.675 AVG Training Acc 62.67 % AVG Validation Acc 61.95 %\n",
      "Epoch:90/200 AVG Training Loss:0.644 AVG Validation Loss:0.676 AVG Training Acc 62.57 % AVG Validation Acc 61.77 %\n",
      "Epoch:100/200 AVG Training Loss:0.643 AVG Validation Loss:0.676 AVG Training Acc 62.62 % AVG Validation Acc 61.68 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.643 AVG Validation Loss:0.677 AVG Training Acc 62.46 % AVG Validation Acc 61.95 %\n",
      "Epoch:120/200 AVG Training Loss:0.644 AVG Validation Loss:0.677 AVG Training Acc 62.32 % AVG Validation Acc 61.59 %\n",
      "Epoch:130/200 AVG Training Loss:0.642 AVG Validation Loss:0.679 AVG Training Acc 62.41 % AVG Validation Acc 61.68 %\n",
      "Epoch   133: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.642 AVG Validation Loss:0.677 AVG Training Acc 62.48 % AVG Validation Acc 61.59 %\n",
      "Epoch:150/200 AVG Training Loss:0.644 AVG Validation Loss:0.677 AVG Training Acc 62.39 % AVG Validation Acc 62.04 %\n",
      "Epoch:160/200 AVG Training Loss:0.642 AVG Validation Loss:0.676 AVG Training Acc 62.49 % AVG Validation Acc 61.86 %\n",
      "Epoch   164: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.643 AVG Validation Loss:0.676 AVG Training Acc 62.46 % AVG Validation Acc 61.68 %\n",
      "Epoch:180/200 AVG Training Loss:0.642 AVG Validation Loss:0.677 AVG Training Acc 62.45 % AVG Validation Acc 61.86 %\n",
      "Epoch:190/200 AVG Training Loss:0.642 AVG Validation Loss:0.676 AVG Training Acc 62.79 % AVG Validation Acc 61.86 %\n",
      "Epoch   195: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.641 AVG Validation Loss:0.676 AVG Training Acc 62.97 % AVG Validation Acc 61.77 %\n",
      "Split 152\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5402b241a2f44c8787438a36606d3964",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.661 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 61.83 % AVG Validation Acc 61.68 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.664 AVG Training Acc 62.10 % AVG Validation Acc 61.50 %\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.667 AVG Training Acc 62.11 % AVG Validation Acc 61.41 %\n",
      "Epoch:50/200 AVG Training Loss:0.648 AVG Validation Loss:0.670 AVG Training Acc 62.16 % AVG Validation Acc 61.50 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.645 AVG Validation Loss:0.674 AVG Training Acc 62.29 % AVG Validation Acc 61.41 %\n",
      "Epoch:70/200 AVG Training Loss:0.645 AVG Validation Loss:0.675 AVG Training Acc 62.13 % AVG Validation Acc 61.50 %\n",
      "Epoch:80/200 AVG Training Loss:0.645 AVG Validation Loss:0.676 AVG Training Acc 62.16 % AVG Validation Acc 61.41 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.644 AVG Validation Loss:0.676 AVG Training Acc 62.14 % AVG Validation Acc 61.23 %\n",
      "Epoch:100/200 AVG Training Loss:0.643 AVG Validation Loss:0.677 AVG Training Acc 62.39 % AVG Validation Acc 61.23 %\n",
      "Epoch:110/200 AVG Training Loss:0.643 AVG Validation Loss:0.677 AVG Training Acc 62.24 % AVG Validation Acc 61.32 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.643 AVG Validation Loss:0.677 AVG Training Acc 62.28 % AVG Validation Acc 61.41 %\n",
      "Epoch:130/200 AVG Training Loss:0.643 AVG Validation Loss:0.677 AVG Training Acc 62.35 % AVG Validation Acc 61.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.644 AVG Validation Loss:0.677 AVG Training Acc 62.31 % AVG Validation Acc 61.32 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.643 AVG Validation Loss:0.677 AVG Training Acc 62.22 % AVG Validation Acc 61.41 %\n",
      "Epoch:160/200 AVG Training Loss:0.644 AVG Validation Loss:0.676 AVG Training Acc 62.12 % AVG Validation Acc 61.32 %\n",
      "Epoch:170/200 AVG Training Loss:0.645 AVG Validation Loss:0.678 AVG Training Acc 62.31 % AVG Validation Acc 61.23 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.645 AVG Validation Loss:0.677 AVG Training Acc 62.29 % AVG Validation Acc 61.41 %\n",
      "Epoch:190/200 AVG Training Loss:0.644 AVG Validation Loss:0.677 AVG Training Acc 62.16 % AVG Validation Acc 61.32 %\n",
      "Epoch:200/200 AVG Training Loss:0.643 AVG Validation Loss:0.677 AVG Training Acc 62.21 % AVG Validation Acc 61.23 %\n",
      "Split 153\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa84552d825a4c7499f5375c72f9286b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.666 AVG Training Acc 61.93 % AVG Validation Acc 61.86 %\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.664 AVG Training Acc 61.96 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.664 AVG Training Acc 62.01 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.655 AVG Validation Loss:0.664 AVG Training Acc 62.00 % AVG Validation Acc 61.86 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.653 AVG Validation Loss:0.665 AVG Training Acc 62.11 % AVG Validation Acc 61.77 %\n",
      "Epoch:60/200 AVG Training Loss:0.651 AVG Validation Loss:0.666 AVG Training Acc 62.17 % AVG Validation Acc 61.68 %\n",
      "Epoch:70/200 AVG Training Loss:0.651 AVG Validation Loss:0.667 AVG Training Acc 61.98 % AVG Validation Acc 61.68 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.651 AVG Validation Loss:0.667 AVG Training Acc 62.10 % AVG Validation Acc 61.68 %\n",
      "Epoch:90/200 AVG Training Loss:0.651 AVG Validation Loss:0.667 AVG Training Acc 62.13 % AVG Validation Acc 61.68 %\n",
      "Epoch:100/200 AVG Training Loss:0.650 AVG Validation Loss:0.667 AVG Training Acc 61.97 % AVG Validation Acc 61.68 %\n",
      "Epoch:110/200 AVG Training Loss:0.650 AVG Validation Loss:0.668 AVG Training Acc 61.99 % AVG Validation Acc 61.77 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.650 AVG Validation Loss:0.668 AVG Training Acc 62.15 % AVG Validation Acc 61.77 %\n",
      "Epoch:130/200 AVG Training Loss:0.651 AVG Validation Loss:0.668 AVG Training Acc 61.98 % AVG Validation Acc 61.77 %\n",
      "Epoch:140/200 AVG Training Loss:0.650 AVG Validation Loss:0.668 AVG Training Acc 62.15 % AVG Validation Acc 61.77 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 62.32 % AVG Validation Acc 61.77 %\n",
      "Epoch:160/200 AVG Training Loss:0.651 AVG Validation Loss:0.668 AVG Training Acc 61.92 % AVG Validation Acc 61.77 %\n",
      "Epoch:170/200 AVG Training Loss:0.650 AVG Validation Loss:0.668 AVG Training Acc 62.16 % AVG Validation Acc 61.77 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.651 AVG Validation Loss:0.668 AVG Training Acc 62.15 % AVG Validation Acc 61.77 %\n",
      "Epoch:190/200 AVG Training Loss:0.651 AVG Validation Loss:0.668 AVG Training Acc 62.15 % AVG Validation Acc 61.77 %\n",
      "Epoch:200/200 AVG Training Loss:0.650 AVG Validation Loss:0.668 AVG Training Acc 62.07 % AVG Validation Acc 61.77 %\n",
      "Split 154\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b012d9edd3dd47258faf05d94714e7ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.666 AVG Training Acc 61.90 % AVG Validation Acc 61.95 %\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:0.662 AVG Training Acc 61.90 % AVG Validation Acc 61.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.664 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.648 AVG Validation Loss:0.668 AVG Training Acc 62.06 % AVG Validation Acc 61.95 %\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.645 AVG Validation Loss:0.673 AVG Training Acc 62.04 % AVG Validation Acc 62.04 %\n",
      "Epoch:60/200 AVG Training Loss:0.644 AVG Validation Loss:0.675 AVG Training Acc 62.17 % AVG Validation Acc 61.86 %\n",
      "Epoch:70/200 AVG Training Loss:0.643 AVG Validation Loss:0.677 AVG Training Acc 61.79 % AVG Validation Acc 61.95 %\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.643 AVG Validation Loss:0.678 AVG Training Acc 62.00 % AVG Validation Acc 62.13 %\n",
      "Epoch:90/200 AVG Training Loss:0.642 AVG Validation Loss:0.679 AVG Training Acc 62.19 % AVG Validation Acc 62.04 %\n",
      "Epoch:100/200 AVG Training Loss:0.642 AVG Validation Loss:0.679 AVG Training Acc 62.07 % AVG Validation Acc 62.13 %\n",
      "Epoch   106: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.642 AVG Validation Loss:0.679 AVG Training Acc 62.19 % AVG Validation Acc 61.95 %\n",
      "Epoch:120/200 AVG Training Loss:0.641 AVG Validation Loss:0.679 AVG Training Acc 62.43 % AVG Validation Acc 62.04 %\n",
      "Epoch:130/200 AVG Training Loss:0.642 AVG Validation Loss:0.680 AVG Training Acc 62.00 % AVG Validation Acc 61.86 %\n",
      "Epoch   137: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.643 AVG Validation Loss:0.680 AVG Training Acc 62.17 % AVG Validation Acc 61.86 %\n",
      "Epoch:150/200 AVG Training Loss:0.641 AVG Validation Loss:0.679 AVG Training Acc 62.08 % AVG Validation Acc 61.95 %\n",
      "Epoch:160/200 AVG Training Loss:0.643 AVG Validation Loss:0.679 AVG Training Acc 61.96 % AVG Validation Acc 61.86 %\n",
      "Epoch   168: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.643 AVG Validation Loss:0.679 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch:180/200 AVG Training Loss:0.642 AVG Validation Loss:0.679 AVG Training Acc 61.99 % AVG Validation Acc 62.13 %\n",
      "Epoch:190/200 AVG Training Loss:0.643 AVG Validation Loss:0.679 AVG Training Acc 61.94 % AVG Validation Acc 61.95 %\n",
      "Epoch:200/200 AVG Training Loss:0.642 AVG Validation Loss:0.679 AVG Training Acc 62.23 % AVG Validation Acc 61.95 %\n",
      "Split 155\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "974e95a6b49c4f3f9ccf30c043ad0d1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.659 AVG Training Acc 61.82 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.661 AVG Training Acc 61.92 % AVG Validation Acc 61.86 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.662 AVG Training Acc 61.96 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.665 AVG Training Acc 61.76 % AVG Validation Acc 61.77 %\n",
      "Epoch:50/200 AVG Training Loss:0.650 AVG Validation Loss:0.669 AVG Training Acc 61.97 % AVG Validation Acc 61.77 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.647 AVG Validation Loss:0.670 AVG Training Acc 62.05 % AVG Validation Acc 61.50 %\n",
      "Epoch:70/200 AVG Training Loss:0.646 AVG Validation Loss:0.673 AVG Training Acc 62.01 % AVG Validation Acc 61.59 %\n",
      "Epoch:80/200 AVG Training Loss:0.646 AVG Validation Loss:0.673 AVG Training Acc 62.11 % AVG Validation Acc 61.41 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.646 AVG Validation Loss:0.672 AVG Training Acc 62.05 % AVG Validation Acc 61.41 %\n",
      "Epoch:100/200 AVG Training Loss:0.646 AVG Validation Loss:0.673 AVG Training Acc 62.08 % AVG Validation Acc 61.41 %\n",
      "Epoch:110/200 AVG Training Loss:0.646 AVG Validation Loss:0.672 AVG Training Acc 62.21 % AVG Validation Acc 61.32 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.646 AVG Validation Loss:0.671 AVG Training Acc 62.03 % AVG Validation Acc 61.23 %\n",
      "Epoch:130/200 AVG Training Loss:0.647 AVG Validation Loss:0.673 AVG Training Acc 62.20 % AVG Validation Acc 61.32 %\n",
      "Epoch:140/200 AVG Training Loss:0.646 AVG Validation Loss:0.671 AVG Training Acc 62.06 % AVG Validation Acc 61.41 %\n",
      "Epoch:150/200 AVG Training Loss:0.646 AVG Validation Loss:0.673 AVG Training Acc 62.10 % AVG Validation Acc 61.32 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.646 AVG Validation Loss:0.671 AVG Training Acc 62.11 % AVG Validation Acc 61.41 %\n",
      "Epoch:170/200 AVG Training Loss:0.644 AVG Validation Loss:0.672 AVG Training Acc 62.33 % AVG Validation Acc 61.32 %\n",
      "Epoch:180/200 AVG Training Loss:0.645 AVG Validation Loss:0.672 AVG Training Acc 61.95 % AVG Validation Acc 61.41 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.647 AVG Validation Loss:0.672 AVG Training Acc 61.92 % AVG Validation Acc 60.96 %\n",
      "Epoch:200/200 AVG Training Loss:0.647 AVG Validation Loss:0.672 AVG Training Acc 62.01 % AVG Validation Acc 61.14 %\n",
      "Split 156\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beca3f3bfd70491ab4fa0e5626e87e54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.659 AVG Training Acc 61.91 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.660 AVG Training Acc 61.90 % AVG Validation Acc 62.00 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.662 AVG Training Acc 62.09 % AVG Validation Acc 62.00 %\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.666 AVG Training Acc 62.12 % AVG Validation Acc 62.09 %\n",
      "Epoch:50/200 AVG Training Loss:0.650 AVG Validation Loss:0.670 AVG Training Acc 62.16 % AVG Validation Acc 61.82 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.648 AVG Validation Loss:0.671 AVG Training Acc 62.29 % AVG Validation Acc 62.00 %\n",
      "Epoch:70/200 AVG Training Loss:0.647 AVG Validation Loss:0.672 AVG Training Acc 62.29 % AVG Validation Acc 61.91 %\n",
      "Epoch:80/200 AVG Training Loss:0.646 AVG Validation Loss:0.672 AVG Training Acc 62.36 % AVG Validation Acc 61.91 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.646 AVG Validation Loss:0.673 AVG Training Acc 62.30 % AVG Validation Acc 61.82 %\n",
      "Epoch:100/200 AVG Training Loss:0.646 AVG Validation Loss:0.673 AVG Training Acc 62.37 % AVG Validation Acc 61.82 %\n",
      "Epoch:110/200 AVG Training Loss:0.646 AVG Validation Loss:0.672 AVG Training Acc 62.30 % AVG Validation Acc 61.82 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.646 AVG Validation Loss:0.673 AVG Training Acc 62.32 % AVG Validation Acc 61.82 %\n",
      "Epoch:130/200 AVG Training Loss:0.646 AVG Validation Loss:0.672 AVG Training Acc 62.39 % AVG Validation Acc 61.82 %\n",
      "Epoch:140/200 AVG Training Loss:0.645 AVG Validation Loss:0.673 AVG Training Acc 62.37 % AVG Validation Acc 61.82 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.645 AVG Validation Loss:0.673 AVG Training Acc 62.39 % AVG Validation Acc 61.82 %\n",
      "Epoch:160/200 AVG Training Loss:0.646 AVG Validation Loss:0.673 AVG Training Acc 62.43 % AVG Validation Acc 61.82 %\n",
      "Epoch:170/200 AVG Training Loss:0.646 AVG Validation Loss:0.673 AVG Training Acc 62.32 % AVG Validation Acc 61.82 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.646 AVG Validation Loss:0.673 AVG Training Acc 62.30 % AVG Validation Acc 61.82 %\n",
      "Epoch:190/200 AVG Training Loss:0.645 AVG Validation Loss:0.673 AVG Training Acc 62.39 % AVG Validation Acc 61.82 %\n",
      "Epoch:200/200 AVG Training Loss:0.646 AVG Validation Loss:0.673 AVG Training Acc 62.34 % AVG Validation Acc 61.82 %\n",
      "Split 157\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97214833702c474bb9b7ed66d7ae7936",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.663 AVG Training Acc 61.74 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.665 AVG Training Acc 61.94 % AVG Validation Acc 61.91 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.669 AVG Training Acc 61.81 % AVG Validation Acc 61.73 %\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.671 AVG Training Acc 61.78 % AVG Validation Acc 61.46 %\n",
      "Epoch:50/200 AVG Training Loss:0.648 AVG Validation Loss:0.676 AVG Training Acc 62.00 % AVG Validation Acc 61.55 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.644 AVG Validation Loss:0.678 AVG Training Acc 62.14 % AVG Validation Acc 61.55 %\n",
      "Epoch:70/200 AVG Training Loss:0.642 AVG Validation Loss:0.678 AVG Training Acc 62.42 % AVG Validation Acc 61.37 %\n",
      "Epoch:80/200 AVG Training Loss:0.643 AVG Validation Loss:0.679 AVG Training Acc 62.18 % AVG Validation Acc 61.37 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.644 AVG Validation Loss:0.679 AVG Training Acc 62.25 % AVG Validation Acc 61.37 %\n",
      "Epoch:100/200 AVG Training Loss:0.643 AVG Validation Loss:0.679 AVG Training Acc 62.41 % AVG Validation Acc 61.37 %\n",
      "Epoch:110/200 AVG Training Loss:0.643 AVG Validation Loss:0.679 AVG Training Acc 62.44 % AVG Validation Acc 61.37 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.643 AVG Validation Loss:0.679 AVG Training Acc 62.29 % AVG Validation Acc 61.37 %\n",
      "Epoch:130/200 AVG Training Loss:0.643 AVG Validation Loss:0.679 AVG Training Acc 62.24 % AVG Validation Acc 61.37 %\n",
      "Epoch:140/200 AVG Training Loss:0.643 AVG Validation Loss:0.679 AVG Training Acc 62.54 % AVG Validation Acc 61.28 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.643 AVG Validation Loss:0.678 AVG Training Acc 62.39 % AVG Validation Acc 61.46 %\n",
      "Epoch:160/200 AVG Training Loss:0.643 AVG Validation Loss:0.679 AVG Training Acc 62.20 % AVG Validation Acc 61.28 %\n",
      "Epoch:170/200 AVG Training Loss:0.641 AVG Validation Loss:0.679 AVG Training Acc 62.34 % AVG Validation Acc 61.37 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.642 AVG Validation Loss:0.679 AVG Training Acc 62.43 % AVG Validation Acc 61.28 %\n",
      "Epoch:190/200 AVG Training Loss:0.643 AVG Validation Loss:0.679 AVG Training Acc 62.43 % AVG Validation Acc 61.19 %\n",
      "Epoch:200/200 AVG Training Loss:0.643 AVG Validation Loss:0.679 AVG Training Acc 62.49 % AVG Validation Acc 61.37 %\n",
      "Split 158\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "686ae82833184001b908d06fa06b8202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.649 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.649 AVG Training Acc 61.89 % AVG Validation Acc 62.00 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.650 AVG Training Acc 61.97 % AVG Validation Acc 61.82 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.655 AVG Training Acc 61.85 % AVG Validation Acc 61.73 %\n",
      "Epoch:50/200 AVG Training Loss:0.651 AVG Validation Loss:0.656 AVG Training Acc 61.94 % AVG Validation Acc 61.82 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.648 AVG Validation Loss:0.659 AVG Training Acc 62.13 % AVG Validation Acc 61.64 %\n",
      "Epoch:70/200 AVG Training Loss:0.646 AVG Validation Loss:0.660 AVG Training Acc 62.12 % AVG Validation Acc 61.64 %\n",
      "Epoch:80/200 AVG Training Loss:0.647 AVG Validation Loss:0.660 AVG Training Acc 62.30 % AVG Validation Acc 61.64 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.647 AVG Validation Loss:0.661 AVG Training Acc 62.43 % AVG Validation Acc 61.64 %\n",
      "Epoch:100/200 AVG Training Loss:0.648 AVG Validation Loss:0.660 AVG Training Acc 62.12 % AVG Validation Acc 61.73 %\n",
      "Epoch:110/200 AVG Training Loss:0.646 AVG Validation Loss:0.660 AVG Training Acc 62.28 % AVG Validation Acc 61.55 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.646 AVG Validation Loss:0.660 AVG Training Acc 62.22 % AVG Validation Acc 61.55 %\n",
      "Epoch:130/200 AVG Training Loss:0.647 AVG Validation Loss:0.660 AVG Training Acc 62.26 % AVG Validation Acc 61.64 %\n",
      "Epoch:140/200 AVG Training Loss:0.646 AVG Validation Loss:0.661 AVG Training Acc 62.38 % AVG Validation Acc 61.64 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.646 AVG Validation Loss:0.661 AVG Training Acc 62.33 % AVG Validation Acc 61.46 %\n",
      "Epoch:160/200 AVG Training Loss:0.647 AVG Validation Loss:0.660 AVG Training Acc 62.22 % AVG Validation Acc 61.55 %\n",
      "Epoch:170/200 AVG Training Loss:0.646 AVG Validation Loss:0.661 AVG Training Acc 61.95 % AVG Validation Acc 61.46 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.647 AVG Validation Loss:0.661 AVG Training Acc 62.31 % AVG Validation Acc 61.73 %\n",
      "Epoch:190/200 AVG Training Loss:0.647 AVG Validation Loss:0.660 AVG Training Acc 62.16 % AVG Validation Acc 61.64 %\n",
      "Epoch:200/200 AVG Training Loss:0.646 AVG Validation Loss:0.660 AVG Training Acc 62.42 % AVG Validation Acc 61.73 %\n",
      "Split 159\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2eecf8bf21d44e79f0e0dda1e1b54ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.660 AVG Training Acc 61.87 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.661 AVG Training Acc 61.84 % AVG Validation Acc 61.91 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.658 AVG Training Acc 62.02 % AVG Validation Acc 61.64 %\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.659 AVG Training Acc 61.87 % AVG Validation Acc 61.28 %\n",
      "Epoch:50/200 AVG Training Loss:0.648 AVG Validation Loss:0.661 AVG Training Acc 62.11 % AVG Validation Acc 61.37 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.645 AVG Validation Loss:0.662 AVG Training Acc 62.44 % AVG Validation Acc 61.28 %\n",
      "Epoch:70/200 AVG Training Loss:0.645 AVG Validation Loss:0.664 AVG Training Acc 62.26 % AVG Validation Acc 60.92 %\n",
      "Epoch:80/200 AVG Training Loss:0.644 AVG Validation Loss:0.666 AVG Training Acc 62.57 % AVG Validation Acc 60.92 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.645 AVG Validation Loss:0.665 AVG Training Acc 62.40 % AVG Validation Acc 60.92 %\n",
      "Epoch:100/200 AVG Training Loss:0.645 AVG Validation Loss:0.665 AVG Training Acc 62.32 % AVG Validation Acc 61.10 %\n",
      "Epoch:110/200 AVG Training Loss:0.644 AVG Validation Loss:0.665 AVG Training Acc 62.46 % AVG Validation Acc 61.10 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.644 AVG Validation Loss:0.665 AVG Training Acc 62.39 % AVG Validation Acc 60.74 %\n",
      "Epoch:130/200 AVG Training Loss:0.643 AVG Validation Loss:0.666 AVG Training Acc 62.31 % AVG Validation Acc 60.92 %\n",
      "Epoch:140/200 AVG Training Loss:0.644 AVG Validation Loss:0.666 AVG Training Acc 62.34 % AVG Validation Acc 60.83 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.645 AVG Validation Loss:0.665 AVG Training Acc 62.21 % AVG Validation Acc 60.92 %\n",
      "Epoch:160/200 AVG Training Loss:0.645 AVG Validation Loss:0.666 AVG Training Acc 62.24 % AVG Validation Acc 60.74 %\n",
      "Epoch:170/200 AVG Training Loss:0.645 AVG Validation Loss:0.665 AVG Training Acc 62.41 % AVG Validation Acc 60.83 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.645 AVG Validation Loss:0.666 AVG Training Acc 62.43 % AVG Validation Acc 61.01 %\n",
      "Epoch:190/200 AVG Training Loss:0.643 AVG Validation Loss:0.666 AVG Training Acc 62.42 % AVG Validation Acc 60.83 %\n",
      "Epoch:200/200 AVG Training Loss:0.644 AVG Validation Loss:0.666 AVG Training Acc 62.58 % AVG Validation Acc 60.83 %\n",
      "Split 160\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c840e3419a34ca38ac3d6f92c8e11a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.657 AVG Training Acc 61.87 % AVG Validation Acc 61.91 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.656 AVG Validation Loss:0.657 AVG Training Acc 61.95 % AVG Validation Acc 62.00 %\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.655 AVG Training Acc 61.96 % AVG Validation Acc 62.00 %\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.656 AVG Training Acc 61.93 % AVG Validation Acc 61.73 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.649 AVG Validation Loss:0.659 AVG Training Acc 62.23 % AVG Validation Acc 61.73 %\n",
      "Epoch:60/200 AVG Training Loss:0.649 AVG Validation Loss:0.658 AVG Training Acc 61.82 % AVG Validation Acc 61.73 %\n",
      "Epoch:70/200 AVG Training Loss:0.647 AVG Validation Loss:0.658 AVG Training Acc 62.12 % AVG Validation Acc 61.64 %\n",
      "Epoch:80/200 AVG Training Loss:0.647 AVG Validation Loss:0.660 AVG Training Acc 62.15 % AVG Validation Acc 61.64 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.648 AVG Validation Loss:0.659 AVG Training Acc 62.29 % AVG Validation Acc 61.64 %\n",
      "Epoch:100/200 AVG Training Loss:0.647 AVG Validation Loss:0.658 AVG Training Acc 62.11 % AVG Validation Acc 61.73 %\n",
      "Epoch:110/200 AVG Training Loss:0.647 AVG Validation Loss:0.660 AVG Training Acc 61.88 % AVG Validation Acc 61.64 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.647 AVG Validation Loss:0.659 AVG Training Acc 62.16 % AVG Validation Acc 61.73 %\n",
      "Epoch:130/200 AVG Training Loss:0.648 AVG Validation Loss:0.659 AVG Training Acc 62.10 % AVG Validation Acc 61.73 %\n",
      "Epoch:140/200 AVG Training Loss:0.647 AVG Validation Loss:0.659 AVG Training Acc 62.16 % AVG Validation Acc 61.73 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.647 AVG Validation Loss:0.660 AVG Training Acc 62.23 % AVG Validation Acc 61.64 %\n",
      "Epoch:160/200 AVG Training Loss:0.647 AVG Validation Loss:0.660 AVG Training Acc 62.08 % AVG Validation Acc 61.64 %\n",
      "Epoch:170/200 AVG Training Loss:0.647 AVG Validation Loss:0.658 AVG Training Acc 62.11 % AVG Validation Acc 61.73 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.647 AVG Validation Loss:0.659 AVG Training Acc 61.96 % AVG Validation Acc 61.73 %\n",
      "Epoch:190/200 AVG Training Loss:0.646 AVG Validation Loss:0.659 AVG Training Acc 62.12 % AVG Validation Acc 61.73 %\n",
      "Epoch:200/200 AVG Training Loss:0.647 AVG Validation Loss:0.659 AVG Training Acc 62.00 % AVG Validation Acc 61.64 %\n",
      "Split 161\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0b0faba4a6340759cbb687c6c4d4ac3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.661 AVG Training Acc 61.88 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.661 AVG Training Acc 61.78 % AVG Validation Acc 61.95 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.652 AVG Validation Loss:0.663 AVG Training Acc 62.01 % AVG Validation Acc 62.31 %\n",
      "Epoch:40/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.12 % AVG Validation Acc 62.49 %\n",
      "Epoch:50/200 AVG Training Loss:0.643 AVG Validation Loss:0.670 AVG Training Acc 61.93 % AVG Validation Acc 62.40 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.641 AVG Validation Loss:0.675 AVG Training Acc 62.23 % AVG Validation Acc 61.86 %\n",
      "Epoch:70/200 AVG Training Loss:0.639 AVG Validation Loss:0.680 AVG Training Acc 62.23 % AVG Validation Acc 61.77 %\n",
      "Epoch:80/200 AVG Training Loss:0.638 AVG Validation Loss:0.682 AVG Training Acc 62.34 % AVG Validation Acc 61.86 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.637 AVG Validation Loss:0.679 AVG Training Acc 62.27 % AVG Validation Acc 61.95 %\n",
      "Epoch:100/200 AVG Training Loss:0.637 AVG Validation Loss:0.681 AVG Training Acc 62.29 % AVG Validation Acc 61.77 %\n",
      "Epoch:110/200 AVG Training Loss:0.637 AVG Validation Loss:0.681 AVG Training Acc 62.59 % AVG Validation Acc 61.77 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.636 AVG Validation Loss:0.682 AVG Training Acc 62.36 % AVG Validation Acc 61.68 %\n",
      "Epoch:130/200 AVG Training Loss:0.636 AVG Validation Loss:0.681 AVG Training Acc 62.44 % AVG Validation Acc 61.68 %\n",
      "Epoch:140/200 AVG Training Loss:0.637 AVG Validation Loss:0.683 AVG Training Acc 62.52 % AVG Validation Acc 61.59 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.637 AVG Validation Loss:0.681 AVG Training Acc 62.28 % AVG Validation Acc 61.77 %\n",
      "Epoch:160/200 AVG Training Loss:0.637 AVG Validation Loss:0.682 AVG Training Acc 62.44 % AVG Validation Acc 61.59 %\n",
      "Epoch:170/200 AVG Training Loss:0.636 AVG Validation Loss:0.683 AVG Training Acc 62.34 % AVG Validation Acc 61.59 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.637 AVG Validation Loss:0.682 AVG Training Acc 62.56 % AVG Validation Acc 61.59 %\n",
      "Epoch:190/200 AVG Training Loss:0.634 AVG Validation Loss:0.684 AVG Training Acc 62.43 % AVG Validation Acc 61.68 %\n",
      "Epoch:200/200 AVG Training Loss:0.637 AVG Validation Loss:0.684 AVG Training Acc 62.33 % AVG Validation Acc 61.68 %\n",
      "Split 162\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cae9d4e769c43ff8744bc7b9fe61bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.663 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.664 AVG Training Acc 61.93 % AVG Validation Acc 61.77 %\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.665 AVG Training Acc 61.97 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.654 AVG Validation Loss:0.665 AVG Training Acc 62.01 % AVG Validation Acc 61.86 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.653 AVG Validation Loss:0.665 AVG Training Acc 62.03 % AVG Validation Acc 61.77 %\n",
      "Epoch:60/200 AVG Training Loss:0.652 AVG Validation Loss:0.665 AVG Training Acc 62.09 % AVG Validation Acc 61.68 %\n",
      "Epoch:70/200 AVG Training Loss:0.652 AVG Validation Loss:0.665 AVG Training Acc 62.13 % AVG Validation Acc 61.68 %\n",
      "Epoch:80/200 AVG Training Loss:0.652 AVG Validation Loss:0.664 AVG Training Acc 62.11 % AVG Validation Acc 61.77 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.652 AVG Validation Loss:0.664 AVG Training Acc 62.11 % AVG Validation Acc 61.77 %\n",
      "Epoch:100/200 AVG Training Loss:0.651 AVG Validation Loss:0.664 AVG Training Acc 62.22 % AVG Validation Acc 61.77 %\n",
      "Epoch:110/200 AVG Training Loss:0.653 AVG Validation Loss:0.664 AVG Training Acc 62.06 % AVG Validation Acc 61.77 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.652 AVG Validation Loss:0.664 AVG Training Acc 62.08 % AVG Validation Acc 61.77 %\n",
      "Epoch:130/200 AVG Training Loss:0.652 AVG Validation Loss:0.664 AVG Training Acc 62.08 % AVG Validation Acc 61.77 %\n",
      "Epoch:140/200 AVG Training Loss:0.652 AVG Validation Loss:0.664 AVG Training Acc 62.16 % AVG Validation Acc 61.77 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.653 AVG Validation Loss:0.664 AVG Training Acc 62.08 % AVG Validation Acc 61.77 %\n",
      "Epoch:160/200 AVG Training Loss:0.653 AVG Validation Loss:0.664 AVG Training Acc 62.07 % AVG Validation Acc 61.77 %\n",
      "Epoch:170/200 AVG Training Loss:0.652 AVG Validation Loss:0.664 AVG Training Acc 62.08 % AVG Validation Acc 61.77 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.652 AVG Validation Loss:0.664 AVG Training Acc 62.14 % AVG Validation Acc 61.77 %\n",
      "Epoch:190/200 AVG Training Loss:0.651 AVG Validation Loss:0.664 AVG Training Acc 62.21 % AVG Validation Acc 61.77 %\n",
      "Epoch:200/200 AVG Training Loss:0.652 AVG Validation Loss:0.664 AVG Training Acc 62.05 % AVG Validation Acc 61.77 %\n",
      "Split 163\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0b31aee015543ca80d4c180dc96ae08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.662 AVG Training Acc 61.95 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.664 AVG Training Acc 61.96 % AVG Validation Acc 61.59 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.663 AVG Training Acc 61.98 % AVG Validation Acc 61.77 %\n",
      "Epoch:40/200 AVG Training Loss:0.654 AVG Validation Loss:0.663 AVG Training Acc 62.09 % AVG Validation Acc 61.68 %\n",
      "Epoch:50/200 AVG Training Loss:0.650 AVG Validation Loss:0.664 AVG Training Acc 62.19 % AVG Validation Acc 61.59 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.648 AVG Validation Loss:0.667 AVG Training Acc 62.38 % AVG Validation Acc 61.77 %\n",
      "Epoch:70/200 AVG Training Loss:0.647 AVG Validation Loss:0.665 AVG Training Acc 62.41 % AVG Validation Acc 61.77 %\n",
      "Epoch:80/200 AVG Training Loss:0.647 AVG Validation Loss:0.666 AVG Training Acc 62.03 % AVG Validation Acc 61.59 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.648 AVG Validation Loss:0.667 AVG Training Acc 62.50 % AVG Validation Acc 61.50 %\n",
      "Epoch:100/200 AVG Training Loss:0.646 AVG Validation Loss:0.667 AVG Training Acc 62.46 % AVG Validation Acc 61.41 %\n",
      "Epoch:110/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 62.33 % AVG Validation Acc 61.50 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 62.24 % AVG Validation Acc 61.41 %\n",
      "Epoch:130/200 AVG Training Loss:0.646 AVG Validation Loss:0.667 AVG Training Acc 62.35 % AVG Validation Acc 61.50 %\n",
      "Epoch:140/200 AVG Training Loss:0.645 AVG Validation Loss:0.667 AVG Training Acc 62.31 % AVG Validation Acc 61.59 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.646 AVG Validation Loss:0.666 AVG Training Acc 62.29 % AVG Validation Acc 61.50 %\n",
      "Epoch:160/200 AVG Training Loss:0.647 AVG Validation Loss:0.666 AVG Training Acc 62.35 % AVG Validation Acc 61.50 %\n",
      "Epoch:170/200 AVG Training Loss:0.646 AVG Validation Loss:0.667 AVG Training Acc 62.36 % AVG Validation Acc 61.59 %\n",
      "Epoch:180/200 AVG Training Loss:0.646 AVG Validation Loss:0.666 AVG Training Acc 62.21 % AVG Validation Acc 61.50 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 62.16 % AVG Validation Acc 61.50 %\n",
      "Epoch:200/200 AVG Training Loss:0.647 AVG Validation Loss:0.666 AVG Training Acc 62.12 % AVG Validation Acc 61.50 %\n",
      "Split 164\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c921cd7ac84ce7b590c3fe45cca491",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.659 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 61.92 % AVG Validation Acc 61.77 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.663 AVG Training Acc 61.78 % AVG Validation Acc 61.59 %\n",
      "Epoch:40/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.08 % AVG Validation Acc 61.59 %\n",
      "Epoch:50/200 AVG Training Loss:0.648 AVG Validation Loss:0.667 AVG Training Acc 62.07 % AVG Validation Acc 61.32 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.642 AVG Validation Loss:0.670 AVG Training Acc 62.60 % AVG Validation Acc 60.96 %\n",
      "Epoch:70/200 AVG Training Loss:0.643 AVG Validation Loss:0.673 AVG Training Acc 62.39 % AVG Validation Acc 60.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.642 AVG Validation Loss:0.672 AVG Training Acc 62.61 % AVG Validation Acc 61.14 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.643 AVG Validation Loss:0.671 AVG Training Acc 62.35 % AVG Validation Acc 60.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.641 AVG Validation Loss:0.671 AVG Training Acc 62.70 % AVG Validation Acc 60.96 %\n",
      "Epoch:110/200 AVG Training Loss:0.643 AVG Validation Loss:0.673 AVG Training Acc 62.22 % AVG Validation Acc 60.96 %\n",
      "Epoch:120/200 AVG Training Loss:0.641 AVG Validation Loss:0.672 AVG Training Acc 62.35 % AVG Validation Acc 60.78 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.642 AVG Validation Loss:0.670 AVG Training Acc 62.49 % AVG Validation Acc 61.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.641 AVG Validation Loss:0.671 AVG Training Acc 62.56 % AVG Validation Acc 61.23 %\n",
      "Epoch:150/200 AVG Training Loss:0.641 AVG Validation Loss:0.672 AVG Training Acc 62.66 % AVG Validation Acc 60.78 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.642 AVG Validation Loss:0.671 AVG Training Acc 62.78 % AVG Validation Acc 61.32 %\n",
      "Epoch:170/200 AVG Training Loss:0.642 AVG Validation Loss:0.671 AVG Training Acc 62.48 % AVG Validation Acc 61.05 %\n",
      "Epoch:180/200 AVG Training Loss:0.642 AVG Validation Loss:0.672 AVG Training Acc 62.43 % AVG Validation Acc 61.23 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.643 AVG Validation Loss:0.670 AVG Training Acc 62.58 % AVG Validation Acc 61.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.641 AVG Validation Loss:0.673 AVG Training Acc 62.69 % AVG Validation Acc 61.14 %\n",
      "Split 165\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae6f51eb14654668815e3672503e4b14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.659 AVG Training Acc 61.83 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.659 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.658 AVG Training Acc 61.84 % AVG Validation Acc 62.04 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.644 AVG Validation Loss:0.665 AVG Training Acc 62.26 % AVG Validation Acc 62.04 %\n",
      "Epoch:50/200 AVG Training Loss:0.638 AVG Validation Loss:0.669 AVG Training Acc 62.35 % AVG Validation Acc 61.86 %\n",
      "Epoch:60/200 AVG Training Loss:0.633 AVG Validation Loss:0.677 AVG Training Acc 62.54 % AVG Validation Acc 61.77 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.628 AVG Validation Loss:0.676 AVG Training Acc 62.93 % AVG Validation Acc 61.77 %\n",
      "Epoch:80/200 AVG Training Loss:0.628 AVG Validation Loss:0.677 AVG Training Acc 63.15 % AVG Validation Acc 62.31 %\n",
      "Epoch:90/200 AVG Training Loss:0.626 AVG Validation Loss:0.681 AVG Training Acc 62.75 % AVG Validation Acc 61.95 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.627 AVG Validation Loss:0.681 AVG Training Acc 63.01 % AVG Validation Acc 61.68 %\n",
      "Epoch:110/200 AVG Training Loss:0.626 AVG Validation Loss:0.682 AVG Training Acc 63.14 % AVG Validation Acc 61.86 %\n",
      "Epoch:120/200 AVG Training Loss:0.626 AVG Validation Loss:0.678 AVG Training Acc 63.07 % AVG Validation Acc 61.95 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.624 AVG Validation Loss:0.681 AVG Training Acc 63.10 % AVG Validation Acc 62.13 %\n",
      "Epoch:140/200 AVG Training Loss:0.625 AVG Validation Loss:0.680 AVG Training Acc 63.07 % AVG Validation Acc 61.95 %\n",
      "Epoch:150/200 AVG Training Loss:0.626 AVG Validation Loss:0.681 AVG Training Acc 62.89 % AVG Validation Acc 61.95 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.624 AVG Validation Loss:0.682 AVG Training Acc 63.16 % AVG Validation Acc 61.86 %\n",
      "Epoch:170/200 AVG Training Loss:0.627 AVG Validation Loss:0.681 AVG Training Acc 63.12 % AVG Validation Acc 61.77 %\n",
      "Epoch:180/200 AVG Training Loss:0.625 AVG Validation Loss:0.683 AVG Training Acc 63.20 % AVG Validation Acc 61.77 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.624 AVG Validation Loss:0.681 AVG Training Acc 63.51 % AVG Validation Acc 61.95 %\n",
      "Epoch:200/200 AVG Training Loss:0.626 AVG Validation Loss:0.679 AVG Training Acc 62.97 % AVG Validation Acc 61.95 %\n",
      "Split 166\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a072a17fa8048ceba14c3591f82cbc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.658 AVG Training Acc 61.87 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.659 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.659 AVG Training Acc 61.92 % AVG Validation Acc 61.91 %\n",
      "Epoch:40/200 AVG Training Loss:0.656 AVG Validation Loss:0.660 AVG Training Acc 61.92 % AVG Validation Acc 61.82 %\n",
      "Epoch:50/200 AVG Training Loss:0.654 AVG Validation Loss:0.662 AVG Training Acc 61.98 % AVG Validation Acc 61.91 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.652 AVG Validation Loss:0.664 AVG Training Acc 62.02 % AVG Validation Acc 61.91 %\n",
      "Epoch:70/200 AVG Training Loss:0.652 AVG Validation Loss:0.665 AVG Training Acc 61.98 % AVG Validation Acc 61.91 %\n",
      "Epoch:80/200 AVG Training Loss:0.651 AVG Validation Loss:0.666 AVG Training Acc 62.09 % AVG Validation Acc 61.82 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.651 AVG Validation Loss:0.667 AVG Training Acc 62.11 % AVG Validation Acc 61.82 %\n",
      "Epoch:100/200 AVG Training Loss:0.650 AVG Validation Loss:0.667 AVG Training Acc 62.06 % AVG Validation Acc 61.82 %\n",
      "Epoch:110/200 AVG Training Loss:0.651 AVG Validation Loss:0.667 AVG Training Acc 62.18 % AVG Validation Acc 61.82 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.651 AVG Validation Loss:0.667 AVG Training Acc 62.01 % AVG Validation Acc 61.82 %\n",
      "Epoch:130/200 AVG Training Loss:0.651 AVG Validation Loss:0.667 AVG Training Acc 62.04 % AVG Validation Acc 61.82 %\n",
      "Epoch:140/200 AVG Training Loss:0.650 AVG Validation Loss:0.667 AVG Training Acc 62.07 % AVG Validation Acc 61.82 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.651 AVG Validation Loss:0.667 AVG Training Acc 61.98 % AVG Validation Acc 61.82 %\n",
      "Epoch:160/200 AVG Training Loss:0.651 AVG Validation Loss:0.668 AVG Training Acc 62.06 % AVG Validation Acc 61.82 %\n",
      "Epoch:170/200 AVG Training Loss:0.651 AVG Validation Loss:0.668 AVG Training Acc 62.01 % AVG Validation Acc 61.82 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.651 AVG Validation Loss:0.667 AVG Training Acc 61.96 % AVG Validation Acc 61.82 %\n",
      "Epoch:190/200 AVG Training Loss:0.651 AVG Validation Loss:0.667 AVG Training Acc 62.00 % AVG Validation Acc 61.82 %\n",
      "Epoch:200/200 AVG Training Loss:0.650 AVG Validation Loss:0.667 AVG Training Acc 61.98 % AVG Validation Acc 61.82 %\n",
      "Split 167\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d64d7ced26784780a731d540824efd57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.661 AVG Training Acc 61.87 % AVG Validation Acc 61.91 %\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.657 AVG Training Acc 61.81 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.657 AVG Training Acc 61.79 % AVG Validation Acc 62.00 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.656 AVG Training Acc 61.88 % AVG Validation Acc 62.00 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.649 AVG Validation Loss:0.657 AVG Training Acc 62.03 % AVG Validation Acc 62.18 %\n",
      "Epoch:60/200 AVG Training Loss:0.646 AVG Validation Loss:0.658 AVG Training Acc 62.18 % AVG Validation Acc 62.36 %\n",
      "Epoch:70/200 AVG Training Loss:0.647 AVG Validation Loss:0.658 AVG Training Acc 62.02 % AVG Validation Acc 62.27 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.646 AVG Validation Loss:0.659 AVG Training Acc 62.09 % AVG Validation Acc 62.27 %\n",
      "Epoch:90/200 AVG Training Loss:0.647 AVG Validation Loss:0.659 AVG Training Acc 61.62 % AVG Validation Acc 62.18 %\n",
      "Epoch:100/200 AVG Training Loss:0.646 AVG Validation Loss:0.659 AVG Training Acc 61.90 % AVG Validation Acc 62.36 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.647 AVG Validation Loss:0.659 AVG Training Acc 62.23 % AVG Validation Acc 62.18 %\n",
      "Epoch:120/200 AVG Training Loss:0.647 AVG Validation Loss:0.659 AVG Training Acc 61.95 % AVG Validation Acc 62.18 %\n",
      "Epoch:130/200 AVG Training Loss:0.647 AVG Validation Loss:0.659 AVG Training Acc 61.99 % AVG Validation Acc 62.18 %\n",
      "Epoch:140/200 AVG Training Loss:0.647 AVG Validation Loss:0.659 AVG Training Acc 61.99 % AVG Validation Acc 62.55 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.646 AVG Validation Loss:0.659 AVG Training Acc 62.04 % AVG Validation Acc 62.27 %\n",
      "Epoch:160/200 AVG Training Loss:0.646 AVG Validation Loss:0.659 AVG Training Acc 62.13 % AVG Validation Acc 62.36 %\n",
      "Epoch:170/200 AVG Training Loss:0.646 AVG Validation Loss:0.659 AVG Training Acc 62.26 % AVG Validation Acc 62.18 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.646 AVG Validation Loss:0.659 AVG Training Acc 62.17 % AVG Validation Acc 62.27 %\n",
      "Epoch:190/200 AVG Training Loss:0.646 AVG Validation Loss:0.659 AVG Training Acc 62.09 % AVG Validation Acc 62.18 %\n",
      "Epoch:200/200 AVG Training Loss:0.645 AVG Validation Loss:0.659 AVG Training Acc 61.97 % AVG Validation Acc 62.27 %\n",
      "Split 168\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "639cb64fcc7341c88e0b09956f6d54af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.659 AVG Training Acc 61.85 % AVG Validation Acc 61.91 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.659 AVG Training Acc 61.95 % AVG Validation Acc 61.82 %\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.664 AVG Training Acc 62.07 % AVG Validation Acc 61.64 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.665 AVG Training Acc 62.01 % AVG Validation Acc 61.73 %\n",
      "Epoch:50/200 AVG Training Loss:0.650 AVG Validation Loss:0.670 AVG Training Acc 62.12 % AVG Validation Acc 61.37 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.648 AVG Validation Loss:0.670 AVG Training Acc 62.11 % AVG Validation Acc 61.55 %\n",
      "Epoch:70/200 AVG Training Loss:0.648 AVG Validation Loss:0.670 AVG Training Acc 62.08 % AVG Validation Acc 61.55 %\n",
      "Epoch:80/200 AVG Training Loss:0.646 AVG Validation Loss:0.670 AVG Training Acc 62.02 % AVG Validation Acc 61.37 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.647 AVG Validation Loss:0.670 AVG Training Acc 62.00 % AVG Validation Acc 61.37 %\n",
      "Epoch:100/200 AVG Training Loss:0.647 AVG Validation Loss:0.670 AVG Training Acc 62.04 % AVG Validation Acc 61.19 %\n",
      "Epoch:110/200 AVG Training Loss:0.647 AVG Validation Loss:0.671 AVG Training Acc 62.09 % AVG Validation Acc 61.19 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.646 AVG Validation Loss:0.670 AVG Training Acc 62.16 % AVG Validation Acc 61.28 %\n",
      "Epoch:130/200 AVG Training Loss:0.646 AVG Validation Loss:0.670 AVG Training Acc 62.22 % AVG Validation Acc 61.28 %\n",
      "Epoch:140/200 AVG Training Loss:0.646 AVG Validation Loss:0.671 AVG Training Acc 62.18 % AVG Validation Acc 61.28 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.646 AVG Validation Loss:0.670 AVG Training Acc 62.20 % AVG Validation Acc 61.46 %\n",
      "Epoch:160/200 AVG Training Loss:0.646 AVG Validation Loss:0.670 AVG Training Acc 62.10 % AVG Validation Acc 61.28 %\n",
      "Epoch:170/200 AVG Training Loss:0.646 AVG Validation Loss:0.670 AVG Training Acc 62.01 % AVG Validation Acc 61.19 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.647 AVG Validation Loss:0.670 AVG Training Acc 62.29 % AVG Validation Acc 61.28 %\n",
      "Epoch:190/200 AVG Training Loss:0.646 AVG Validation Loss:0.671 AVG Training Acc 62.24 % AVG Validation Acc 61.37 %\n",
      "Epoch:200/200 AVG Training Loss:0.646 AVG Validation Loss:0.670 AVG Training Acc 62.10 % AVG Validation Acc 61.19 %\n",
      "Split 169\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e92729a66aa24e87941bd72e009be6d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.656 AVG Training Acc 61.78 % AVG Validation Acc 61.91 %\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.655 AVG Training Acc 61.87 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.653 AVG Training Acc 61.97 % AVG Validation Acc 62.00 %\n",
      "Epoch:40/200 AVG Training Loss:0.650 AVG Validation Loss:0.655 AVG Training Acc 62.00 % AVG Validation Acc 62.09 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.645 AVG Validation Loss:0.657 AVG Training Acc 62.33 % AVG Validation Acc 62.45 %\n",
      "Epoch:60/200 AVG Training Loss:0.644 AVG Validation Loss:0.658 AVG Training Acc 62.55 % AVG Validation Acc 62.09 %\n",
      "Epoch:70/200 AVG Training Loss:0.645 AVG Validation Loss:0.658 AVG Training Acc 62.12 % AVG Validation Acc 62.27 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.644 AVG Validation Loss:0.659 AVG Training Acc 61.95 % AVG Validation Acc 62.18 %\n",
      "Epoch:90/200 AVG Training Loss:0.644 AVG Validation Loss:0.659 AVG Training Acc 61.92 % AVG Validation Acc 62.27 %\n",
      "Epoch:100/200 AVG Training Loss:0.643 AVG Validation Loss:0.658 AVG Training Acc 62.30 % AVG Validation Acc 62.09 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.644 AVG Validation Loss:0.659 AVG Training Acc 62.15 % AVG Validation Acc 62.00 %\n",
      "Epoch:120/200 AVG Training Loss:0.644 AVG Validation Loss:0.658 AVG Training Acc 61.99 % AVG Validation Acc 61.91 %\n",
      "Epoch:130/200 AVG Training Loss:0.644 AVG Validation Loss:0.659 AVG Training Acc 62.13 % AVG Validation Acc 62.00 %\n",
      "Epoch:140/200 AVG Training Loss:0.643 AVG Validation Loss:0.658 AVG Training Acc 62.33 % AVG Validation Acc 62.09 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.644 AVG Validation Loss:0.658 AVG Training Acc 62.16 % AVG Validation Acc 62.18 %\n",
      "Epoch:160/200 AVG Training Loss:0.644 AVG Validation Loss:0.659 AVG Training Acc 62.24 % AVG Validation Acc 62.00 %\n",
      "Epoch:170/200 AVG Training Loss:0.644 AVG Validation Loss:0.658 AVG Training Acc 62.25 % AVG Validation Acc 62.18 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.644 AVG Validation Loss:0.658 AVG Training Acc 62.10 % AVG Validation Acc 62.18 %\n",
      "Epoch:190/200 AVG Training Loss:0.644 AVG Validation Loss:0.659 AVG Training Acc 62.06 % AVG Validation Acc 62.09 %\n",
      "Epoch:200/200 AVG Training Loss:0.644 AVG Validation Loss:0.659 AVG Training Acc 62.06 % AVG Validation Acc 62.00 %\n",
      "Split 170\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17922ea458084994bdafeb25a04413e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.662 AVG Validation Loss:0.658 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.664 AVG Validation Loss:0.662 AVG Training Acc 61.82 % AVG Validation Acc 61.91 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.655 AVG Validation Loss:0.658 AVG Training Acc 61.93 % AVG Validation Acc 61.82 %\n",
      "Epoch:50/200 AVG Training Loss:0.650 AVG Validation Loss:0.659 AVG Training Acc 62.09 % AVG Validation Acc 61.91 %\n",
      "Epoch:60/200 AVG Training Loss:0.646 AVG Validation Loss:0.662 AVG Training Acc 62.23 % AVG Validation Acc 61.82 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.643 AVG Validation Loss:0.663 AVG Training Acc 62.38 % AVG Validation Acc 61.64 %\n",
      "Epoch:80/200 AVG Training Loss:0.643 AVG Validation Loss:0.666 AVG Training Acc 62.29 % AVG Validation Acc 61.82 %\n",
      "Epoch:90/200 AVG Training Loss:0.642 AVG Validation Loss:0.664 AVG Training Acc 62.40 % AVG Validation Acc 61.64 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.643 AVG Validation Loss:0.665 AVG Training Acc 62.28 % AVG Validation Acc 61.73 %\n",
      "Epoch:110/200 AVG Training Loss:0.642 AVG Validation Loss:0.664 AVG Training Acc 62.38 % AVG Validation Acc 61.64 %\n",
      "Epoch:120/200 AVG Training Loss:0.642 AVG Validation Loss:0.664 AVG Training Acc 62.28 % AVG Validation Acc 61.73 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.642 AVG Validation Loss:0.665 AVG Training Acc 62.31 % AVG Validation Acc 61.55 %\n",
      "Epoch:140/200 AVG Training Loss:0.642 AVG Validation Loss:0.665 AVG Training Acc 62.43 % AVG Validation Acc 61.64 %\n",
      "Epoch:150/200 AVG Training Loss:0.642 AVG Validation Loss:0.665 AVG Training Acc 62.25 % AVG Validation Acc 61.55 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.641 AVG Validation Loss:0.664 AVG Training Acc 62.42 % AVG Validation Acc 61.73 %\n",
      "Epoch:170/200 AVG Training Loss:0.643 AVG Validation Loss:0.665 AVG Training Acc 62.17 % AVG Validation Acc 61.73 %\n",
      "Epoch:180/200 AVG Training Loss:0.644 AVG Validation Loss:0.664 AVG Training Acc 62.16 % AVG Validation Acc 61.73 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.643 AVG Validation Loss:0.665 AVG Training Acc 62.21 % AVG Validation Acc 61.64 %\n",
      "Epoch:200/200 AVG Training Loss:0.643 AVG Validation Loss:0.667 AVG Training Acc 62.20 % AVG Validation Acc 61.64 %\n",
      "Split 171\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79c4383a9a0c4e87ad089845846c4cfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.658 AVG Training Acc 61.88 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.661 AVG Training Acc 61.82 % AVG Validation Acc 61.95 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.662 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.668 AVG Training Acc 61.97 % AVG Validation Acc 61.95 %\n",
      "Epoch:50/200 AVG Training Loss:0.651 AVG Validation Loss:0.672 AVG Training Acc 62.01 % AVG Validation Acc 61.95 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.647 AVG Validation Loss:0.672 AVG Training Acc 62.05 % AVG Validation Acc 61.77 %\n",
      "Epoch:70/200 AVG Training Loss:0.648 AVG Validation Loss:0.672 AVG Training Acc 62.01 % AVG Validation Acc 61.86 %\n",
      "Epoch:80/200 AVG Training Loss:0.646 AVG Validation Loss:0.672 AVG Training Acc 62.26 % AVG Validation Acc 61.95 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.644 AVG Validation Loss:0.673 AVG Training Acc 62.10 % AVG Validation Acc 61.95 %\n",
      "Epoch:100/200 AVG Training Loss:0.646 AVG Validation Loss:0.672 AVG Training Acc 62.01 % AVG Validation Acc 61.86 %\n",
      "Epoch:110/200 AVG Training Loss:0.645 AVG Validation Loss:0.671 AVG Training Acc 62.06 % AVG Validation Acc 61.95 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.646 AVG Validation Loss:0.672 AVG Training Acc 62.05 % AVG Validation Acc 61.95 %\n",
      "Epoch:130/200 AVG Training Loss:0.644 AVG Validation Loss:0.672 AVG Training Acc 62.16 % AVG Validation Acc 61.95 %\n",
      "Epoch:140/200 AVG Training Loss:0.645 AVG Validation Loss:0.672 AVG Training Acc 62.07 % AVG Validation Acc 61.95 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.645 AVG Validation Loss:0.672 AVG Training Acc 62.11 % AVG Validation Acc 61.86 %\n",
      "Epoch:160/200 AVG Training Loss:0.646 AVG Validation Loss:0.672 AVG Training Acc 62.08 % AVG Validation Acc 61.95 %\n",
      "Epoch:170/200 AVG Training Loss:0.646 AVG Validation Loss:0.672 AVG Training Acc 62.07 % AVG Validation Acc 61.95 %\n",
      "Epoch:180/200 AVG Training Loss:0.645 AVG Validation Loss:0.672 AVG Training Acc 62.08 % AVG Validation Acc 61.95 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.647 AVG Validation Loss:0.671 AVG Training Acc 62.01 % AVG Validation Acc 61.95 %\n",
      "Epoch:200/200 AVG Training Loss:0.645 AVG Validation Loss:0.672 AVG Training Acc 62.10 % AVG Validation Acc 61.95 %\n",
      "Split 172\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dfe2aa0bdb6a4a158d603f6c57f98fb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.661 AVG Training Acc 61.93 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.660 AVG Training Acc 61.61 % AVG Validation Acc 61.86 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.663 AVG Training Acc 61.99 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.646 AVG Validation Loss:0.664 AVG Training Acc 62.08 % AVG Validation Acc 61.95 %\n",
      "Epoch:50/200 AVG Training Loss:0.639 AVG Validation Loss:0.666 AVG Training Acc 62.38 % AVG Validation Acc 62.04 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.636 AVG Validation Loss:0.667 AVG Training Acc 63.08 % AVG Validation Acc 61.86 %\n",
      "Epoch:70/200 AVG Training Loss:0.633 AVG Validation Loss:0.669 AVG Training Acc 62.52 % AVG Validation Acc 60.87 %\n",
      "Epoch:80/200 AVG Training Loss:0.631 AVG Validation Loss:0.668 AVG Training Acc 62.89 % AVG Validation Acc 61.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.630 AVG Validation Loss:0.670 AVG Training Acc 63.19 % AVG Validation Acc 61.05 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.630 AVG Validation Loss:0.669 AVG Training Acc 63.09 % AVG Validation Acc 60.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.631 AVG Validation Loss:0.670 AVG Training Acc 62.59 % AVG Validation Acc 60.96 %\n",
      "Epoch:120/200 AVG Training Loss:0.629 AVG Validation Loss:0.671 AVG Training Acc 63.01 % AVG Validation Acc 60.87 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.629 AVG Validation Loss:0.671 AVG Training Acc 62.90 % AVG Validation Acc 60.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.630 AVG Validation Loss:0.670 AVG Training Acc 63.08 % AVG Validation Acc 60.87 %\n",
      "Epoch:150/200 AVG Training Loss:0.631 AVG Validation Loss:0.671 AVG Training Acc 62.97 % AVG Validation Acc 60.87 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.630 AVG Validation Loss:0.670 AVG Training Acc 62.85 % AVG Validation Acc 61.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.631 AVG Validation Loss:0.671 AVG Training Acc 62.99 % AVG Validation Acc 60.87 %\n",
      "Epoch:180/200 AVG Training Loss:0.630 AVG Validation Loss:0.671 AVG Training Acc 62.82 % AVG Validation Acc 60.87 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.629 AVG Validation Loss:0.671 AVG Training Acc 62.84 % AVG Validation Acc 60.78 %\n",
      "Epoch:200/200 AVG Training Loss:0.630 AVG Validation Loss:0.671 AVG Training Acc 63.11 % AVG Validation Acc 60.96 %\n",
      "Split 173\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1d2c9a453d9490c80f4fb5683fb8919",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.664 AVG Training Acc 61.80 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.663 AVG Training Acc 61.76 % AVG Validation Acc 61.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.661 AVG Training Acc 61.66 % AVG Validation Acc 61.68 %\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.667 AVG Training Acc 61.73 % AVG Validation Acc 61.68 %\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.643 AVG Validation Loss:0.672 AVG Training Acc 62.64 % AVG Validation Acc 61.59 %\n",
      "Epoch:60/200 AVG Training Loss:0.639 AVG Validation Loss:0.674 AVG Training Acc 62.33 % AVG Validation Acc 61.95 %\n",
      "Epoch:70/200 AVG Training Loss:0.634 AVG Validation Loss:0.676 AVG Training Acc 62.93 % AVG Validation Acc 61.50 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.631 AVG Validation Loss:0.680 AVG Training Acc 62.80 % AVG Validation Acc 61.50 %\n",
      "Epoch:90/200 AVG Training Loss:0.629 AVG Validation Loss:0.678 AVG Training Acc 63.36 % AVG Validation Acc 61.50 %\n",
      "Epoch:100/200 AVG Training Loss:0.633 AVG Validation Loss:0.682 AVG Training Acc 63.07 % AVG Validation Acc 61.59 %\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.631 AVG Validation Loss:0.683 AVG Training Acc 63.26 % AVG Validation Acc 61.23 %\n",
      "Epoch:120/200 AVG Training Loss:0.630 AVG Validation Loss:0.682 AVG Training Acc 63.25 % AVG Validation Acc 61.05 %\n",
      "Epoch:130/200 AVG Training Loss:0.628 AVG Validation Loss:0.681 AVG Training Acc 63.78 % AVG Validation Acc 61.59 %\n",
      "Epoch   134: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.631 AVG Validation Loss:0.683 AVG Training Acc 63.13 % AVG Validation Acc 61.23 %\n",
      "Epoch:150/200 AVG Training Loss:0.630 AVG Validation Loss:0.684 AVG Training Acc 62.93 % AVG Validation Acc 61.05 %\n",
      "Epoch:160/200 AVG Training Loss:0.630 AVG Validation Loss:0.681 AVG Training Acc 63.11 % AVG Validation Acc 60.87 %\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.629 AVG Validation Loss:0.683 AVG Training Acc 63.24 % AVG Validation Acc 61.32 %\n",
      "Epoch:180/200 AVG Training Loss:0.630 AVG Validation Loss:0.684 AVG Training Acc 63.66 % AVG Validation Acc 60.96 %\n",
      "Epoch:190/200 AVG Training Loss:0.630 AVG Validation Loss:0.682 AVG Training Acc 63.04 % AVG Validation Acc 61.23 %\n",
      "Epoch   196: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.630 AVG Validation Loss:0.684 AVG Training Acc 63.14 % AVG Validation Acc 61.41 %\n",
      "Split 174\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c4e3875be504e2dac987a23931ee227",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 61.88 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.661 AVG Training Acc 61.73 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.661 AVG Training Acc 61.82 % AVG Validation Acc 61.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.654 AVG Validation Loss:0.659 AVG Training Acc 61.80 % AVG Validation Acc 61.68 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.643 AVG Validation Loss:0.666 AVG Training Acc 62.62 % AVG Validation Acc 62.13 %\n",
      "Epoch:60/200 AVG Training Loss:0.638 AVG Validation Loss:0.668 AVG Training Acc 62.89 % AVG Validation Acc 61.59 %\n",
      "Epoch:70/200 AVG Training Loss:0.632 AVG Validation Loss:0.672 AVG Training Acc 62.88 % AVG Validation Acc 61.50 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.627 AVG Validation Loss:0.674 AVG Training Acc 63.56 % AVG Validation Acc 61.50 %\n",
      "Epoch:90/200 AVG Training Loss:0.626 AVG Validation Loss:0.675 AVG Training Acc 63.41 % AVG Validation Acc 61.23 %\n",
      "Epoch:100/200 AVG Training Loss:0.626 AVG Validation Loss:0.677 AVG Training Acc 63.23 % AVG Validation Acc 61.14 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.624 AVG Validation Loss:0.679 AVG Training Acc 63.58 % AVG Validation Acc 61.05 %\n",
      "Epoch:120/200 AVG Training Loss:0.624 AVG Validation Loss:0.682 AVG Training Acc 63.43 % AVG Validation Acc 61.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.624 AVG Validation Loss:0.683 AVG Training Acc 63.69 % AVG Validation Acc 60.96 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.625 AVG Validation Loss:0.678 AVG Training Acc 63.54 % AVG Validation Acc 61.23 %\n",
      "Epoch:150/200 AVG Training Loss:0.626 AVG Validation Loss:0.680 AVG Training Acc 63.32 % AVG Validation Acc 60.96 %\n",
      "Epoch:160/200 AVG Training Loss:0.624 AVG Validation Loss:0.680 AVG Training Acc 63.35 % AVG Validation Acc 61.14 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.624 AVG Validation Loss:0.678 AVG Training Acc 63.05 % AVG Validation Acc 61.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.623 AVG Validation Loss:0.680 AVG Training Acc 63.26 % AVG Validation Acc 61.05 %\n",
      "Epoch:190/200 AVG Training Loss:0.623 AVG Validation Loss:0.678 AVG Training Acc 63.58 % AVG Validation Acc 61.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.624 AVG Validation Loss:0.680 AVG Training Acc 63.20 % AVG Validation Acc 61.05 %\n",
      "Epoch   200: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Split 175\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dca0559660241fcab821f749383f637",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.658 AVG Training Acc 61.85 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.658 AVG Training Acc 61.90 % AVG Validation Acc 61.68 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.657 AVG Training Acc 61.97 % AVG Validation Acc 61.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.649 AVG Validation Loss:0.657 AVG Training Acc 62.18 % AVG Validation Acc 61.32 %\n",
      "Epoch:50/200 AVG Training Loss:0.645 AVG Validation Loss:0.659 AVG Training Acc 62.28 % AVG Validation Acc 60.87 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.640 AVG Validation Loss:0.663 AVG Training Acc 62.73 % AVG Validation Acc 60.41 %\n",
      "Epoch:70/200 AVG Training Loss:0.638 AVG Validation Loss:0.664 AVG Training Acc 63.02 % AVG Validation Acc 59.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.636 AVG Validation Loss:0.666 AVG Training Acc 62.92 % AVG Validation Acc 59.60 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.636 AVG Validation Loss:0.666 AVG Training Acc 62.75 % AVG Validation Acc 59.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.636 AVG Validation Loss:0.666 AVG Training Acc 63.10 % AVG Validation Acc 59.96 %\n",
      "Epoch:110/200 AVG Training Loss:0.635 AVG Validation Loss:0.666 AVG Training Acc 63.16 % AVG Validation Acc 60.05 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.636 AVG Validation Loss:0.666 AVG Training Acc 63.00 % AVG Validation Acc 59.60 %\n",
      "Epoch:130/200 AVG Training Loss:0.634 AVG Validation Loss:0.666 AVG Training Acc 63.25 % AVG Validation Acc 59.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.637 AVG Validation Loss:0.667 AVG Training Acc 63.06 % AVG Validation Acc 60.05 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.636 AVG Validation Loss:0.667 AVG Training Acc 63.15 % AVG Validation Acc 59.60 %\n",
      "Epoch:160/200 AVG Training Loss:0.636 AVG Validation Loss:0.666 AVG Training Acc 62.88 % AVG Validation Acc 60.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.636 AVG Validation Loss:0.667 AVG Training Acc 62.82 % AVG Validation Acc 59.69 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.635 AVG Validation Loss:0.668 AVG Training Acc 63.01 % AVG Validation Acc 59.78 %\n",
      "Epoch:190/200 AVG Training Loss:0.636 AVG Validation Loss:0.665 AVG Training Acc 62.78 % AVG Validation Acc 59.96 %\n",
      "Epoch:200/200 AVG Training Loss:0.637 AVG Validation Loss:0.665 AVG Training Acc 62.89 % AVG Validation Acc 59.69 %\n",
      "Split 176\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b3dfa3bf6f4857ba0eb6d3ef34ca1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.657 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.657 AVG Training Acc 61.92 % AVG Validation Acc 62.00 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.651 AVG Validation Loss:0.659 AVG Training Acc 62.08 % AVG Validation Acc 61.91 %\n",
      "Epoch:40/200 AVG Training Loss:0.646 AVG Validation Loss:0.663 AVG Training Acc 62.13 % AVG Validation Acc 62.09 %\n",
      "Epoch:50/200 AVG Training Loss:0.638 AVG Validation Loss:0.668 AVG Training Acc 62.81 % AVG Validation Acc 61.46 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.632 AVG Validation Loss:0.679 AVG Training Acc 62.80 % AVG Validation Acc 61.64 %\n",
      "Epoch:70/200 AVG Training Loss:0.631 AVG Validation Loss:0.682 AVG Training Acc 62.84 % AVG Validation Acc 61.37 %\n",
      "Epoch:80/200 AVG Training Loss:0.629 AVG Validation Loss:0.684 AVG Training Acc 62.91 % AVG Validation Acc 61.46 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.628 AVG Validation Loss:0.687 AVG Training Acc 62.86 % AVG Validation Acc 61.46 %\n",
      "Epoch:100/200 AVG Training Loss:0.629 AVG Validation Loss:0.688 AVG Training Acc 63.11 % AVG Validation Acc 61.28 %\n",
      "Epoch:110/200 AVG Training Loss:0.629 AVG Validation Loss:0.686 AVG Training Acc 63.18 % AVG Validation Acc 61.28 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.629 AVG Validation Loss:0.690 AVG Training Acc 63.11 % AVG Validation Acc 61.19 %\n",
      "Epoch:130/200 AVG Training Loss:0.627 AVG Validation Loss:0.689 AVG Training Acc 63.08 % AVG Validation Acc 61.19 %\n",
      "Epoch:140/200 AVG Training Loss:0.628 AVG Validation Loss:0.687 AVG Training Acc 63.20 % AVG Validation Acc 61.28 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.627 AVG Validation Loss:0.689 AVG Training Acc 63.26 % AVG Validation Acc 61.46 %\n",
      "Epoch:160/200 AVG Training Loss:0.628 AVG Validation Loss:0.688 AVG Training Acc 63.01 % AVG Validation Acc 61.46 %\n",
      "Epoch:170/200 AVG Training Loss:0.627 AVG Validation Loss:0.688 AVG Training Acc 63.10 % AVG Validation Acc 61.64 %\n",
      "Epoch:180/200 AVG Training Loss:0.627 AVG Validation Loss:0.688 AVG Training Acc 63.20 % AVG Validation Acc 61.28 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.627 AVG Validation Loss:0.689 AVG Training Acc 63.11 % AVG Validation Acc 61.28 %\n",
      "Epoch:200/200 AVG Training Loss:0.630 AVG Validation Loss:0.687 AVG Training Acc 62.85 % AVG Validation Acc 61.64 %\n",
      "Split 177\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a78a09fe08844c08d81fd3706310eb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.655 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.656 AVG Training Acc 61.79 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.658 AVG Validation Loss:0.655 AVG Training Acc 61.97 % AVG Validation Acc 61.91 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.654 AVG Training Acc 61.98 % AVG Validation Acc 61.82 %\n",
      "Epoch:50/200 AVG Training Loss:0.647 AVG Validation Loss:0.654 AVG Training Acc 61.75 % AVG Validation Acc 61.82 %\n",
      "Epoch:60/200 AVG Training Loss:0.644 AVG Validation Loss:0.665 AVG Training Acc 61.99 % AVG Validation Acc 62.00 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.640 AVG Validation Loss:0.664 AVG Training Acc 62.03 % AVG Validation Acc 62.27 %\n",
      "Epoch:80/200 AVG Training Loss:0.639 AVG Validation Loss:0.666 AVG Training Acc 62.40 % AVG Validation Acc 62.00 %\n",
      "Epoch:90/200 AVG Training Loss:0.639 AVG Validation Loss:0.667 AVG Training Acc 62.22 % AVG Validation Acc 62.00 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.638 AVG Validation Loss:0.667 AVG Training Acc 62.52 % AVG Validation Acc 61.55 %\n",
      "Epoch:110/200 AVG Training Loss:0.638 AVG Validation Loss:0.666 AVG Training Acc 62.52 % AVG Validation Acc 61.73 %\n",
      "Epoch:120/200 AVG Training Loss:0.638 AVG Validation Loss:0.664 AVG Training Acc 62.24 % AVG Validation Acc 61.91 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.638 AVG Validation Loss:0.665 AVG Training Acc 62.26 % AVG Validation Acc 61.73 %\n",
      "Epoch:140/200 AVG Training Loss:0.639 AVG Validation Loss:0.666 AVG Training Acc 62.03 % AVG Validation Acc 61.82 %\n",
      "Epoch:150/200 AVG Training Loss:0.638 AVG Validation Loss:0.667 AVG Training Acc 62.41 % AVG Validation Acc 62.18 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.638 AVG Validation Loss:0.665 AVG Training Acc 62.09 % AVG Validation Acc 61.73 %\n",
      "Epoch:170/200 AVG Training Loss:0.638 AVG Validation Loss:0.667 AVG Training Acc 61.82 % AVG Validation Acc 61.73 %\n",
      "Epoch:180/200 AVG Training Loss:0.639 AVG Validation Loss:0.667 AVG Training Acc 62.10 % AVG Validation Acc 61.82 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.639 AVG Validation Loss:0.666 AVG Training Acc 62.40 % AVG Validation Acc 61.82 %\n",
      "Epoch:200/200 AVG Training Loss:0.639 AVG Validation Loss:0.667 AVG Training Acc 62.16 % AVG Validation Acc 61.91 %\n",
      "Split 178\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5070a49d3d1c4141b02eae99a100f172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.658 AVG Training Acc 61.85 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.656 AVG Training Acc 61.75 % AVG Validation Acc 61.82 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.656 AVG Training Acc 62.01 % AVG Validation Acc 61.82 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.660 AVG Training Acc 62.03 % AVG Validation Acc 61.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.651 AVG Validation Loss:0.661 AVG Training Acc 62.15 % AVG Validation Acc 61.82 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.650 AVG Validation Loss:0.663 AVG Training Acc 62.23 % AVG Validation Acc 61.82 %\n",
      "Epoch:70/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.26 % AVG Validation Acc 61.91 %\n",
      "Epoch:80/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.25 % AVG Validation Acc 62.00 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.25 % AVG Validation Acc 62.00 %\n",
      "Epoch:100/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.18 % AVG Validation Acc 61.82 %\n",
      "Epoch:110/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.39 % AVG Validation Acc 61.91 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.33 % AVG Validation Acc 62.00 %\n",
      "Epoch:130/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.28 % AVG Validation Acc 61.91 %\n",
      "Epoch:140/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.20 % AVG Validation Acc 61.91 %\n",
      "Epoch:150/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.27 % AVG Validation Acc 62.00 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.32 % AVG Validation Acc 61.91 %\n",
      "Epoch:170/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.20 % AVG Validation Acc 61.91 %\n",
      "Epoch:180/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.38 % AVG Validation Acc 61.91 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.38 % AVG Validation Acc 61.91 %\n",
      "Epoch:200/200 AVG Training Loss:0.648 AVG Validation Loss:0.665 AVG Training Acc 62.36 % AVG Validation Acc 61.82 %\n",
      "Split 179\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ac07756c6542118b6e99baf252131d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.663 AVG Training Acc 61.80 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.665 AVG Training Acc 61.67 % AVG Validation Acc 61.82 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.650 AVG Validation Loss:0.670 AVG Training Acc 61.88 % AVG Validation Acc 61.55 %\n",
      "Epoch:40/200 AVG Training Loss:0.649 AVG Validation Loss:0.671 AVG Training Acc 61.88 % AVG Validation Acc 61.46 %\n",
      "Epoch:50/200 AVG Training Loss:0.643 AVG Validation Loss:0.673 AVG Training Acc 62.26 % AVG Validation Acc 61.28 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.641 AVG Validation Loss:0.673 AVG Training Acc 62.20 % AVG Validation Acc 61.28 %\n",
      "Epoch:70/200 AVG Training Loss:0.640 AVG Validation Loss:0.673 AVG Training Acc 62.09 % AVG Validation Acc 61.10 %\n",
      "Epoch:80/200 AVG Training Loss:0.640 AVG Validation Loss:0.673 AVG Training Acc 62.05 % AVG Validation Acc 61.55 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.639 AVG Validation Loss:0.673 AVG Training Acc 62.14 % AVG Validation Acc 61.28 %\n",
      "Epoch:100/200 AVG Training Loss:0.638 AVG Validation Loss:0.674 AVG Training Acc 62.02 % AVG Validation Acc 61.28 %\n",
      "Epoch:110/200 AVG Training Loss:0.639 AVG Validation Loss:0.674 AVG Training Acc 62.43 % AVG Validation Acc 61.28 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.638 AVG Validation Loss:0.674 AVG Training Acc 62.12 % AVG Validation Acc 61.19 %\n",
      "Epoch:130/200 AVG Training Loss:0.638 AVG Validation Loss:0.673 AVG Training Acc 62.51 % AVG Validation Acc 61.10 %\n",
      "Epoch:140/200 AVG Training Loss:0.639 AVG Validation Loss:0.673 AVG Training Acc 62.29 % AVG Validation Acc 61.28 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.638 AVG Validation Loss:0.674 AVG Training Acc 62.36 % AVG Validation Acc 61.37 %\n",
      "Epoch:160/200 AVG Training Loss:0.638 AVG Validation Loss:0.674 AVG Training Acc 61.90 % AVG Validation Acc 61.10 %\n",
      "Epoch:170/200 AVG Training Loss:0.638 AVG Validation Loss:0.673 AVG Training Acc 62.18 % AVG Validation Acc 61.37 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.639 AVG Validation Loss:0.674 AVG Training Acc 62.13 % AVG Validation Acc 61.37 %\n",
      "Epoch:190/200 AVG Training Loss:0.638 AVG Validation Loss:0.674 AVG Training Acc 62.34 % AVG Validation Acc 61.19 %\n",
      "Epoch:200/200 AVG Training Loss:0.639 AVG Validation Loss:0.674 AVG Training Acc 62.28 % AVG Validation Acc 61.37 %\n",
      "Split 180\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a43990c1d8945728d58ce37af729880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.659 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.660 AVG Training Acc 61.95 % AVG Validation Acc 61.91 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.658 AVG Training Acc 61.97 % AVG Validation Acc 62.00 %\n",
      "Epoch:40/200 AVG Training Loss:0.654 AVG Validation Loss:0.659 AVG Training Acc 62.05 % AVG Validation Acc 61.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.651 AVG Validation Loss:0.661 AVG Training Acc 62.11 % AVG Validation Acc 61.91 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 62.24 % AVG Validation Acc 61.73 %\n",
      "Epoch:70/200 AVG Training Loss:0.646 AVG Validation Loss:0.663 AVG Training Acc 62.34 % AVG Validation Acc 61.73 %\n",
      "Epoch:80/200 AVG Training Loss:0.646 AVG Validation Loss:0.664 AVG Training Acc 62.34 % AVG Validation Acc 61.82 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.646 AVG Validation Loss:0.664 AVG Training Acc 62.30 % AVG Validation Acc 61.64 %\n",
      "Epoch:100/200 AVG Training Loss:0.645 AVG Validation Loss:0.664 AVG Training Acc 62.33 % AVG Validation Acc 61.73 %\n",
      "Epoch:110/200 AVG Training Loss:0.644 AVG Validation Loss:0.665 AVG Training Acc 62.54 % AVG Validation Acc 61.64 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.646 AVG Validation Loss:0.664 AVG Training Acc 62.46 % AVG Validation Acc 61.73 %\n",
      "Epoch:130/200 AVG Training Loss:0.644 AVG Validation Loss:0.664 AVG Training Acc 62.37 % AVG Validation Acc 61.64 %\n",
      "Epoch:140/200 AVG Training Loss:0.645 AVG Validation Loss:0.664 AVG Training Acc 62.42 % AVG Validation Acc 61.55 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.645 AVG Validation Loss:0.664 AVG Training Acc 62.32 % AVG Validation Acc 61.73 %\n",
      "Epoch:160/200 AVG Training Loss:0.647 AVG Validation Loss:0.665 AVG Training Acc 62.27 % AVG Validation Acc 61.64 %\n",
      "Epoch:170/200 AVG Training Loss:0.645 AVG Validation Loss:0.664 AVG Training Acc 62.37 % AVG Validation Acc 61.64 %\n",
      "Epoch:180/200 AVG Training Loss:0.645 AVG Validation Loss:0.664 AVG Training Acc 62.32 % AVG Validation Acc 61.73 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.646 AVG Validation Loss:0.664 AVG Training Acc 62.31 % AVG Validation Acc 61.73 %\n",
      "Epoch:200/200 AVG Training Loss:0.645 AVG Validation Loss:0.664 AVG Training Acc 62.28 % AVG Validation Acc 61.64 %\n",
      "Split 181\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c0a3c07239464cbd0dc5d992e642bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.660 AVG Training Acc 61.89 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 61.91 % AVG Validation Acc 62.31 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.651 AVG Validation Loss:0.663 AVG Training Acc 61.84 % AVG Validation Acc 61.77 %\n",
      "Epoch:40/200 AVG Training Loss:0.643 AVG Validation Loss:0.668 AVG Training Acc 62.52 % AVG Validation Acc 61.68 %\n",
      "Epoch:50/200 AVG Training Loss:0.637 AVG Validation Loss:0.677 AVG Training Acc 62.81 % AVG Validation Acc 61.59 %\n",
      "Epoch:60/200 AVG Training Loss:0.635 AVG Validation Loss:0.686 AVG Training Acc 63.11 % AVG Validation Acc 61.59 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.631 AVG Validation Loss:0.689 AVG Training Acc 63.12 % AVG Validation Acc 61.41 %\n",
      "Epoch:80/200 AVG Training Loss:0.630 AVG Validation Loss:0.689 AVG Training Acc 63.21 % AVG Validation Acc 61.68 %\n",
      "Epoch:90/200 AVG Training Loss:0.629 AVG Validation Loss:0.693 AVG Training Acc 63.21 % AVG Validation Acc 61.59 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.629 AVG Validation Loss:0.692 AVG Training Acc 63.35 % AVG Validation Acc 61.50 %\n",
      "Epoch:110/200 AVG Training Loss:0.629 AVG Validation Loss:0.692 AVG Training Acc 63.16 % AVG Validation Acc 61.32 %\n",
      "Epoch:120/200 AVG Training Loss:0.629 AVG Validation Loss:0.692 AVG Training Acc 63.13 % AVG Validation Acc 61.32 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.630 AVG Validation Loss:0.694 AVG Training Acc 63.18 % AVG Validation Acc 61.41 %\n",
      "Epoch:140/200 AVG Training Loss:0.627 AVG Validation Loss:0.693 AVG Training Acc 63.52 % AVG Validation Acc 61.32 %\n",
      "Epoch:150/200 AVG Training Loss:0.629 AVG Validation Loss:0.692 AVG Training Acc 63.15 % AVG Validation Acc 61.32 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.629 AVG Validation Loss:0.692 AVG Training Acc 63.27 % AVG Validation Acc 61.41 %\n",
      "Epoch:170/200 AVG Training Loss:0.629 AVG Validation Loss:0.693 AVG Training Acc 63.14 % AVG Validation Acc 61.32 %\n",
      "Epoch:180/200 AVG Training Loss:0.630 AVG Validation Loss:0.692 AVG Training Acc 63.06 % AVG Validation Acc 61.41 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.629 AVG Validation Loss:0.695 AVG Training Acc 63.35 % AVG Validation Acc 61.41 %\n",
      "Epoch:200/200 AVG Training Loss:0.628 AVG Validation Loss:0.694 AVG Training Acc 63.06 % AVG Validation Acc 61.32 %\n",
      "Split 182\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43845d4dcbae48b7b44996ca3cc0f2ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.658 AVG Training Acc 61.86 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.658 AVG Training Acc 61.73 % AVG Validation Acc 61.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.664 AVG Training Acc 61.70 % AVG Validation Acc 61.68 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.644 AVG Validation Loss:0.661 AVG Training Acc 62.30 % AVG Validation Acc 62.13 %\n",
      "Epoch:50/200 AVG Training Loss:0.640 AVG Validation Loss:0.665 AVG Training Acc 62.18 % AVG Validation Acc 62.40 %\n",
      "Epoch:60/200 AVG Training Loss:0.634 AVG Validation Loss:0.670 AVG Training Acc 62.52 % AVG Validation Acc 62.04 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.631 AVG Validation Loss:0.675 AVG Training Acc 62.54 % AVG Validation Acc 62.13 %\n",
      "Epoch:80/200 AVG Training Loss:0.630 AVG Validation Loss:0.675 AVG Training Acc 62.77 % AVG Validation Acc 61.77 %\n",
      "Epoch:90/200 AVG Training Loss:0.628 AVG Validation Loss:0.674 AVG Training Acc 62.70 % AVG Validation Acc 61.50 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.629 AVG Validation Loss:0.674 AVG Training Acc 63.44 % AVG Validation Acc 61.68 %\n",
      "Epoch:110/200 AVG Training Loss:0.630 AVG Validation Loss:0.675 AVG Training Acc 62.51 % AVG Validation Acc 61.41 %\n",
      "Epoch:120/200 AVG Training Loss:0.628 AVG Validation Loss:0.678 AVG Training Acc 63.15 % AVG Validation Acc 61.68 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.628 AVG Validation Loss:0.673 AVG Training Acc 63.04 % AVG Validation Acc 61.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.627 AVG Validation Loss:0.676 AVG Training Acc 63.01 % AVG Validation Acc 61.77 %\n",
      "Epoch:150/200 AVG Training Loss:0.629 AVG Validation Loss:0.675 AVG Training Acc 62.81 % AVG Validation Acc 61.14 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.628 AVG Validation Loss:0.680 AVG Training Acc 63.29 % AVG Validation Acc 61.77 %\n",
      "Epoch:170/200 AVG Training Loss:0.626 AVG Validation Loss:0.677 AVG Training Acc 63.44 % AVG Validation Acc 61.41 %\n",
      "Epoch:180/200 AVG Training Loss:0.630 AVG Validation Loss:0.674 AVG Training Acc 62.51 % AVG Validation Acc 61.41 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.626 AVG Validation Loss:0.679 AVG Training Acc 63.44 % AVG Validation Acc 61.68 %\n",
      "Epoch:200/200 AVG Training Loss:0.627 AVG Validation Loss:0.677 AVG Training Acc 62.98 % AVG Validation Acc 61.14 %\n",
      "Split 183\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a37905dfc91b4750941f7cf2c0d5f3e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.663 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.665 AVG Training Acc 61.88 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.662 AVG Training Acc 61.65 % AVG Validation Acc 61.86 %\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.662 AVG Validation Loss:0.663 AVG Training Acc 61.87 % AVG Validation Acc 61.86 %\n",
      "Epoch:50/200 AVG Training Loss:0.661 AVG Validation Loss:0.662 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:60/200 AVG Training Loss:0.660 AVG Validation Loss:0.663 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:70/200 AVG Training Loss:0.659 AVG Validation Loss:0.661 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch    70: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:90/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:100/200 AVG Training Loss:0.659 AVG Validation Loss:0.664 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.660 AVG Validation Loss:0.663 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:120/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:130/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch   132: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.658 AVG Validation Loss:0.663 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:150/200 AVG Training Loss:0.659 AVG Validation Loss:0.662 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:160/200 AVG Training Loss:0.660 AVG Validation Loss:0.663 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch   163: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:180/200 AVG Training Loss:0.659 AVG Validation Loss:0.663 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:190/200 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch   194: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Split 184\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3d49e39afa34533b14250408fb22533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.660 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 61.75 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.658 AVG Validation Loss:0.658 AVG Training Acc 61.83 % AVG Validation Acc 62.04 %\n",
      "Epoch:40/200 AVG Training Loss:0.671 AVG Validation Loss:0.673 AVG Training Acc 60.87 % AVG Validation Acc 61.86 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.663 AVG Validation Loss:0.665 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:60/200 AVG Training Loss:0.661 AVG Validation Loss:0.662 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:70/200 AVG Training Loss:0.662 AVG Validation Loss:0.663 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.662 AVG Validation Loss:0.664 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:90/200 AVG Training Loss:0.662 AVG Validation Loss:0.666 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:100/200 AVG Training Loss:0.661 AVG Validation Loss:0.664 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.662 AVG Validation Loss:0.663 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:120/200 AVG Training Loss:0.662 AVG Validation Loss:0.665 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:130/200 AVG Training Loss:0.662 AVG Validation Loss:0.665 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.662 AVG Validation Loss:0.665 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:150/200 AVG Training Loss:0.662 AVG Validation Loss:0.664 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:160/200 AVG Training Loss:0.662 AVG Validation Loss:0.665 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.661 AVG Validation Loss:0.664 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:180/200 AVG Training Loss:0.662 AVG Validation Loss:0.665 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:190/200 AVG Training Loss:0.662 AVG Validation Loss:0.664 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:200/200 AVG Training Loss:0.661 AVG Validation Loss:0.665 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch   200: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Split 185\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f68e8b8c5f240b0b87657a6b25fabd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.660 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.660 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.659 AVG Training Acc 61.88 % AVG Validation Acc 61.77 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.661 AVG Training Acc 61.92 % AVG Validation Acc 61.77 %\n",
      "Epoch:50/200 AVG Training Loss:0.651 AVG Validation Loss:0.661 AVG Training Acc 62.10 % AVG Validation Acc 61.86 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.648 AVG Validation Loss:0.662 AVG Training Acc 62.27 % AVG Validation Acc 61.86 %\n",
      "Epoch:70/200 AVG Training Loss:0.649 AVG Validation Loss:0.663 AVG Training Acc 62.05 % AVG Validation Acc 61.86 %\n",
      "Epoch:80/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 62.11 % AVG Validation Acc 61.86 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.648 AVG Validation Loss:0.663 AVG Training Acc 62.10 % AVG Validation Acc 61.77 %\n",
      "Epoch:100/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 62.01 % AVG Validation Acc 61.86 %\n",
      "Epoch:110/200 AVG Training Loss:0.648 AVG Validation Loss:0.663 AVG Training Acc 62.19 % AVG Validation Acc 61.86 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.646 AVG Validation Loss:0.663 AVG Training Acc 62.35 % AVG Validation Acc 61.77 %\n",
      "Epoch:130/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 62.21 % AVG Validation Acc 61.77 %\n",
      "Epoch:140/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 62.21 % AVG Validation Acc 61.77 %\n",
      "Epoch:150/200 AVG Training Loss:0.646 AVG Validation Loss:0.663 AVG Training Acc 62.38 % AVG Validation Acc 61.86 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.646 AVG Validation Loss:0.663 AVG Training Acc 62.47 % AVG Validation Acc 61.86 %\n",
      "Epoch:170/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.10 % AVG Validation Acc 61.86 %\n",
      "Epoch:180/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 62.15 % AVG Validation Acc 61.86 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 62.19 % AVG Validation Acc 61.86 %\n",
      "Epoch:200/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 62.23 % AVG Validation Acc 61.86 %\n",
      "Split 186\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45d069cc5c404d89831bd6c1e70217db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.661 AVG Training Acc 61.82 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.661 AVG Training Acc 61.61 % AVG Validation Acc 61.91 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.662 AVG Training Acc 61.98 % AVG Validation Acc 61.91 %\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.664 AVG Training Acc 61.69 % AVG Validation Acc 61.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.647 AVG Validation Loss:0.664 AVG Training Acc 62.03 % AVG Validation Acc 61.82 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.643 AVG Validation Loss:0.662 AVG Training Acc 61.84 % AVG Validation Acc 61.91 %\n",
      "Epoch:70/200 AVG Training Loss:0.642 AVG Validation Loss:0.663 AVG Training Acc 62.06 % AVG Validation Acc 61.91 %\n",
      "Epoch:80/200 AVG Training Loss:0.642 AVG Validation Loss:0.662 AVG Training Acc 62.11 % AVG Validation Acc 61.91 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.641 AVG Validation Loss:0.662 AVG Training Acc 62.08 % AVG Validation Acc 61.91 %\n",
      "Epoch:100/200 AVG Training Loss:0.642 AVG Validation Loss:0.662 AVG Training Acc 62.00 % AVG Validation Acc 61.91 %\n",
      "Epoch:110/200 AVG Training Loss:0.639 AVG Validation Loss:0.663 AVG Training Acc 62.16 % AVG Validation Acc 61.91 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.642 AVG Validation Loss:0.663 AVG Training Acc 62.09 % AVG Validation Acc 61.91 %\n",
      "Epoch:130/200 AVG Training Loss:0.640 AVG Validation Loss:0.663 AVG Training Acc 62.20 % AVG Validation Acc 61.91 %\n",
      "Epoch:140/200 AVG Training Loss:0.641 AVG Validation Loss:0.663 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.641 AVG Validation Loss:0.663 AVG Training Acc 62.00 % AVG Validation Acc 61.91 %\n",
      "Epoch:160/200 AVG Training Loss:0.641 AVG Validation Loss:0.663 AVG Training Acc 62.11 % AVG Validation Acc 61.91 %\n",
      "Epoch:170/200 AVG Training Loss:0.641 AVG Validation Loss:0.663 AVG Training Acc 62.19 % AVG Validation Acc 61.91 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.641 AVG Validation Loss:0.663 AVG Training Acc 61.93 % AVG Validation Acc 61.91 %\n",
      "Epoch:190/200 AVG Training Loss:0.642 AVG Validation Loss:0.663 AVG Training Acc 62.12 % AVG Validation Acc 61.91 %\n",
      "Epoch:200/200 AVG Training Loss:0.642 AVG Validation Loss:0.662 AVG Training Acc 61.84 % AVG Validation Acc 61.91 %\n",
      "Split 187\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ece9ec51b74a4017a02a1dbb4921dd94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.663 AVG Training Acc 61.87 % AVG Validation Acc 61.91 %\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:0.664 AVG Training Acc 61.82 % AVG Validation Acc 61.73 %\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.665 AVG Training Acc 62.05 % AVG Validation Acc 61.73 %\n",
      "Epoch:40/200 AVG Training Loss:0.650 AVG Validation Loss:0.666 AVG Training Acc 62.30 % AVG Validation Acc 61.64 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.648 AVG Validation Loss:0.667 AVG Training Acc 62.18 % AVG Validation Acc 61.01 %\n",
      "Epoch:60/200 AVG Training Loss:0.648 AVG Validation Loss:0.668 AVG Training Acc 62.04 % AVG Validation Acc 60.92 %\n",
      "Epoch:70/200 AVG Training Loss:0.646 AVG Validation Loss:0.669 AVG Training Acc 62.41 % AVG Validation Acc 60.92 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.646 AVG Validation Loss:0.669 AVG Training Acc 62.28 % AVG Validation Acc 60.83 %\n",
      "Epoch:90/200 AVG Training Loss:0.646 AVG Validation Loss:0.669 AVG Training Acc 62.44 % AVG Validation Acc 60.83 %\n",
      "Epoch:100/200 AVG Training Loss:0.646 AVG Validation Loss:0.670 AVG Training Acc 62.30 % AVG Validation Acc 60.83 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.646 AVG Validation Loss:0.670 AVG Training Acc 62.31 % AVG Validation Acc 60.74 %\n",
      "Epoch:120/200 AVG Training Loss:0.646 AVG Validation Loss:0.670 AVG Training Acc 62.17 % AVG Validation Acc 60.74 %\n",
      "Epoch:130/200 AVG Training Loss:0.646 AVG Validation Loss:0.670 AVG Training Acc 62.46 % AVG Validation Acc 60.56 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.646 AVG Validation Loss:0.669 AVG Training Acc 62.40 % AVG Validation Acc 60.65 %\n",
      "Epoch:150/200 AVG Training Loss:0.648 AVG Validation Loss:0.669 AVG Training Acc 61.83 % AVG Validation Acc 60.74 %\n",
      "Epoch:160/200 AVG Training Loss:0.645 AVG Validation Loss:0.670 AVG Training Acc 62.29 % AVG Validation Acc 60.83 %\n",
      "Epoch:170/200 AVG Training Loss:0.646 AVG Validation Loss:0.670 AVG Training Acc 62.78 % AVG Validation Acc 60.74 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.646 AVG Validation Loss:0.670 AVG Training Acc 62.55 % AVG Validation Acc 60.56 %\n",
      "Epoch:190/200 AVG Training Loss:0.646 AVG Validation Loss:0.670 AVG Training Acc 62.09 % AVG Validation Acc 60.83 %\n",
      "Epoch:200/200 AVG Training Loss:0.645 AVG Validation Loss:0.670 AVG Training Acc 62.39 % AVG Validation Acc 60.83 %\n",
      "Split 188\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93c507be600044cab9e6c9e112723990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.658 AVG Training Acc 62.02 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.658 AVG Training Acc 61.85 % AVG Validation Acc 61.91 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.661 AVG Training Acc 61.95 % AVG Validation Acc 61.91 %\n",
      "Epoch:40/200 AVG Training Loss:0.654 AVG Validation Loss:0.663 AVG Training Acc 61.99 % AVG Validation Acc 61.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.651 AVG Validation Loss:0.667 AVG Training Acc 62.10 % AVG Validation Acc 61.73 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.650 AVG Validation Loss:0.667 AVG Training Acc 62.19 % AVG Validation Acc 61.55 %\n",
      "Epoch:70/200 AVG Training Loss:0.650 AVG Validation Loss:0.667 AVG Training Acc 62.13 % AVG Validation Acc 61.55 %\n",
      "Epoch:80/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 62.16 % AVG Validation Acc 61.55 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.648 AVG Validation Loss:0.668 AVG Training Acc 62.23 % AVG Validation Acc 61.46 %\n",
      "Epoch:100/200 AVG Training Loss:0.648 AVG Validation Loss:0.668 AVG Training Acc 62.22 % AVG Validation Acc 61.46 %\n",
      "Epoch:110/200 AVG Training Loss:0.650 AVG Validation Loss:0.668 AVG Training Acc 62.09 % AVG Validation Acc 61.46 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.650 AVG Validation Loss:0.668 AVG Training Acc 62.27 % AVG Validation Acc 61.46 %\n",
      "Epoch:130/200 AVG Training Loss:0.649 AVG Validation Loss:0.669 AVG Training Acc 62.15 % AVG Validation Acc 61.46 %\n",
      "Epoch:140/200 AVG Training Loss:0.649 AVG Validation Loss:0.669 AVG Training Acc 62.29 % AVG Validation Acc 61.46 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 62.12 % AVG Validation Acc 61.46 %\n",
      "Epoch:160/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 62.11 % AVG Validation Acc 61.46 %\n",
      "Epoch:170/200 AVG Training Loss:0.649 AVG Validation Loss:0.669 AVG Training Acc 62.18 % AVG Validation Acc 61.55 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 62.06 % AVG Validation Acc 61.46 %\n",
      "Epoch:190/200 AVG Training Loss:0.649 AVG Validation Loss:0.669 AVG Training Acc 62.18 % AVG Validation Acc 61.46 %\n",
      "Epoch:200/200 AVG Training Loss:0.649 AVG Validation Loss:0.669 AVG Training Acc 62.21 % AVG Validation Acc 61.46 %\n",
      "Split 189\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b10f4356446b4f47bc6dc38dc7a2acd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 61.91 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.675 AVG Validation Loss:0.665 AVG Training Acc 60.66 % AVG Validation Acc 61.91 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.662 AVG Validation Loss:0.663 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Epoch:40/200 AVG Training Loss:0.662 AVG Validation Loss:0.665 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.662 AVG Validation Loss:0.667 AVG Training Acc 61.95 % AVG Validation Acc 61.91 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.661 AVG Validation Loss:0.667 AVG Training Acc 61.94 % AVG Validation Acc 62.00 %\n",
      "Epoch:70/200 AVG Training Loss:0.661 AVG Validation Loss:0.667 AVG Training Acc 61.93 % AVG Validation Acc 62.00 %\n",
      "Epoch:80/200 AVG Training Loss:0.661 AVG Validation Loss:0.667 AVG Training Acc 61.93 % AVG Validation Acc 62.00 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.660 AVG Validation Loss:0.667 AVG Training Acc 61.96 % AVG Validation Acc 62.00 %\n",
      "Epoch:100/200 AVG Training Loss:0.660 AVG Validation Loss:0.667 AVG Training Acc 61.93 % AVG Validation Acc 62.00 %\n",
      "Epoch:110/200 AVG Training Loss:0.660 AVG Validation Loss:0.667 AVG Training Acc 61.91 % AVG Validation Acc 62.00 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.660 AVG Validation Loss:0.667 AVG Training Acc 61.90 % AVG Validation Acc 62.00 %\n",
      "Epoch:130/200 AVG Training Loss:0.660 AVG Validation Loss:0.666 AVG Training Acc 61.91 % AVG Validation Acc 62.00 %\n",
      "Epoch:140/200 AVG Training Loss:0.660 AVG Validation Loss:0.667 AVG Training Acc 61.99 % AVG Validation Acc 62.00 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.661 AVG Validation Loss:0.666 AVG Training Acc 61.94 % AVG Validation Acc 62.00 %\n",
      "Epoch:160/200 AVG Training Loss:0.660 AVG Validation Loss:0.667 AVG Training Acc 61.92 % AVG Validation Acc 62.00 %\n",
      "Epoch:170/200 AVG Training Loss:0.660 AVG Validation Loss:0.667 AVG Training Acc 61.89 % AVG Validation Acc 62.00 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.661 AVG Validation Loss:0.667 AVG Training Acc 61.95 % AVG Validation Acc 62.00 %\n",
      "Epoch:190/200 AVG Training Loss:0.660 AVG Validation Loss:0.666 AVG Training Acc 61.90 % AVG Validation Acc 62.00 %\n",
      "Epoch:200/200 AVG Training Loss:0.661 AVG Validation Loss:0.667 AVG Training Acc 61.91 % AVG Validation Acc 62.00 %\n",
      "Split 190\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b69f1482c1bd4c57a9cef70b0e296fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.653 AVG Training Acc 61.80 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.653 AVG Training Acc 61.88 % AVG Validation Acc 61.82 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.653 AVG Training Acc 61.93 % AVG Validation Acc 61.91 %\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.654 AVG Training Acc 62.16 % AVG Validation Acc 62.00 %\n",
      "Epoch:50/200 AVG Training Loss:0.647 AVG Validation Loss:0.656 AVG Training Acc 62.20 % AVG Validation Acc 61.28 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.643 AVG Validation Loss:0.658 AVG Training Acc 62.32 % AVG Validation Acc 60.92 %\n",
      "Epoch:70/200 AVG Training Loss:0.643 AVG Validation Loss:0.660 AVG Training Acc 62.51 % AVG Validation Acc 60.83 %\n",
      "Epoch:80/200 AVG Training Loss:0.642 AVG Validation Loss:0.661 AVG Training Acc 62.47 % AVG Validation Acc 60.83 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.641 AVG Validation Loss:0.660 AVG Training Acc 62.45 % AVG Validation Acc 60.83 %\n",
      "Epoch:100/200 AVG Training Loss:0.641 AVG Validation Loss:0.661 AVG Training Acc 62.46 % AVG Validation Acc 60.56 %\n",
      "Epoch:110/200 AVG Training Loss:0.641 AVG Validation Loss:0.662 AVG Training Acc 62.44 % AVG Validation Acc 60.74 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.641 AVG Validation Loss:0.661 AVG Training Acc 62.54 % AVG Validation Acc 60.83 %\n",
      "Epoch:130/200 AVG Training Loss:0.641 AVG Validation Loss:0.661 AVG Training Acc 62.46 % AVG Validation Acc 60.65 %\n",
      "Epoch:140/200 AVG Training Loss:0.641 AVG Validation Loss:0.661 AVG Training Acc 62.53 % AVG Validation Acc 60.74 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.641 AVG Validation Loss:0.661 AVG Training Acc 62.44 % AVG Validation Acc 60.83 %\n",
      "Epoch:160/200 AVG Training Loss:0.640 AVG Validation Loss:0.660 AVG Training Acc 62.43 % AVG Validation Acc 60.83 %\n",
      "Epoch:170/200 AVG Training Loss:0.641 AVG Validation Loss:0.661 AVG Training Acc 62.57 % AVG Validation Acc 60.83 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.641 AVG Validation Loss:0.660 AVG Training Acc 62.42 % AVG Validation Acc 60.65 %\n",
      "Epoch:190/200 AVG Training Loss:0.641 AVG Validation Loss:0.661 AVG Training Acc 62.49 % AVG Validation Acc 60.65 %\n",
      "Epoch:200/200 AVG Training Loss:0.641 AVG Validation Loss:0.661 AVG Training Acc 62.45 % AVG Validation Acc 60.65 %\n",
      "Split 191\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5b9033b0468491b90a8e82c08a7ad10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.664 AVG Training Acc 61.84 % AVG Validation Acc 61.95 %\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.656 AVG Validation Loss:0.662 AVG Training Acc 61.92 % AVG Validation Acc 62.31 %\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.662 AVG Training Acc 61.88 % AVG Validation Acc 62.13 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.663 AVG Training Acc 62.06 % AVG Validation Acc 61.77 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.650 AVG Validation Loss:0.663 AVG Training Acc 62.19 % AVG Validation Acc 61.95 %\n",
      "Epoch:60/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.17 % AVG Validation Acc 62.13 %\n",
      "Epoch:70/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.05 % AVG Validation Acc 61.86 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 61.99 % AVG Validation Acc 61.86 %\n",
      "Epoch:90/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.05 % AVG Validation Acc 61.77 %\n",
      "Epoch:100/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.13 % AVG Validation Acc 61.86 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.09 % AVG Validation Acc 61.68 %\n",
      "Epoch:120/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.10 % AVG Validation Acc 61.86 %\n",
      "Epoch:130/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.17 % AVG Validation Acc 61.95 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.18 % AVG Validation Acc 61.68 %\n",
      "Epoch:150/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.06 % AVG Validation Acc 61.95 %\n",
      "Epoch:160/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.32 % AVG Validation Acc 61.86 %\n",
      "Epoch:170/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.23 % AVG Validation Acc 61.77 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.06 % AVG Validation Acc 61.77 %\n",
      "Epoch:190/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.20 % AVG Validation Acc 61.86 %\n",
      "Epoch:200/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.13 % AVG Validation Acc 61.86 %\n",
      "Split 192\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2226d5a916e439fa7c85aa745629d3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.658 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 61.68 % AVG Validation Acc 61.95 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.659 AVG Training Acc 61.98 % AVG Validation Acc 61.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.650 AVG Validation Loss:0.663 AVG Training Acc 62.04 % AVG Validation Acc 62.22 %\n",
      "Epoch:50/200 AVG Training Loss:0.646 AVG Validation Loss:0.666 AVG Training Acc 62.23 % AVG Validation Acc 62.13 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.644 AVG Validation Loss:0.670 AVG Training Acc 62.27 % AVG Validation Acc 61.86 %\n",
      "Epoch:70/200 AVG Training Loss:0.643 AVG Validation Loss:0.670 AVG Training Acc 62.35 % AVG Validation Acc 61.86 %\n",
      "Epoch:80/200 AVG Training Loss:0.643 AVG Validation Loss:0.670 AVG Training Acc 62.50 % AVG Validation Acc 61.68 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.643 AVG Validation Loss:0.671 AVG Training Acc 62.18 % AVG Validation Acc 61.77 %\n",
      "Epoch:100/200 AVG Training Loss:0.642 AVG Validation Loss:0.671 AVG Training Acc 62.33 % AVG Validation Acc 61.86 %\n",
      "Epoch:110/200 AVG Training Loss:0.643 AVG Validation Loss:0.671 AVG Training Acc 62.43 % AVG Validation Acc 61.68 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.643 AVG Validation Loss:0.670 AVG Training Acc 62.50 % AVG Validation Acc 61.86 %\n",
      "Epoch:130/200 AVG Training Loss:0.643 AVG Validation Loss:0.671 AVG Training Acc 62.28 % AVG Validation Acc 61.68 %\n",
      "Epoch:140/200 AVG Training Loss:0.642 AVG Validation Loss:0.672 AVG Training Acc 62.24 % AVG Validation Acc 61.68 %\n",
      "Epoch:150/200 AVG Training Loss:0.643 AVG Validation Loss:0.671 AVG Training Acc 62.48 % AVG Validation Acc 61.68 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.643 AVG Validation Loss:0.671 AVG Training Acc 62.14 % AVG Validation Acc 61.95 %\n",
      "Epoch:170/200 AVG Training Loss:0.644 AVG Validation Loss:0.671 AVG Training Acc 62.19 % AVG Validation Acc 61.86 %\n",
      "Epoch:180/200 AVG Training Loss:0.641 AVG Validation Loss:0.671 AVG Training Acc 62.45 % AVG Validation Acc 61.77 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.642 AVG Validation Loss:0.671 AVG Training Acc 62.43 % AVG Validation Acc 61.86 %\n",
      "Epoch:200/200 AVG Training Loss:0.643 AVG Validation Loss:0.672 AVG Training Acc 62.28 % AVG Validation Acc 61.86 %\n",
      "Split 193\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c444bd956754c1d8a63e4e5dd7e3c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.658 AVG Training Acc 61.85 % AVG Validation Acc 61.86 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.656 AVG Training Acc 61.95 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.657 AVG Training Acc 61.85 % AVG Validation Acc 61.77 %\n",
      "Epoch:40/200 AVG Training Loss:0.655 AVG Validation Loss:0.657 AVG Training Acc 61.85 % AVG Validation Acc 61.86 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.652 AVG Validation Loss:0.657 AVG Training Acc 62.00 % AVG Validation Acc 61.77 %\n",
      "Epoch:60/200 AVG Training Loss:0.652 AVG Validation Loss:0.656 AVG Training Acc 62.09 % AVG Validation Acc 61.77 %\n",
      "Epoch:70/200 AVG Training Loss:0.652 AVG Validation Loss:0.656 AVG Training Acc 61.93 % AVG Validation Acc 61.77 %\n",
      "Epoch:80/200 AVG Training Loss:0.650 AVG Validation Loss:0.657 AVG Training Acc 62.09 % AVG Validation Acc 61.77 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.651 AVG Validation Loss:0.656 AVG Training Acc 62.02 % AVG Validation Acc 61.77 %\n",
      "Epoch:100/200 AVG Training Loss:0.651 AVG Validation Loss:0.657 AVG Training Acc 62.05 % AVG Validation Acc 61.77 %\n",
      "Epoch:110/200 AVG Training Loss:0.651 AVG Validation Loss:0.657 AVG Training Acc 61.99 % AVG Validation Acc 61.77 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.650 AVG Validation Loss:0.657 AVG Training Acc 62.04 % AVG Validation Acc 61.77 %\n",
      "Epoch:130/200 AVG Training Loss:0.650 AVG Validation Loss:0.656 AVG Training Acc 62.08 % AVG Validation Acc 61.77 %\n",
      "Epoch:140/200 AVG Training Loss:0.650 AVG Validation Loss:0.657 AVG Training Acc 62.21 % AVG Validation Acc 61.77 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.651 AVG Validation Loss:0.656 AVG Training Acc 61.95 % AVG Validation Acc 61.77 %\n",
      "Epoch:160/200 AVG Training Loss:0.651 AVG Validation Loss:0.656 AVG Training Acc 62.07 % AVG Validation Acc 61.77 %\n",
      "Epoch:170/200 AVG Training Loss:0.651 AVG Validation Loss:0.656 AVG Training Acc 61.99 % AVG Validation Acc 61.77 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.650 AVG Validation Loss:0.656 AVG Training Acc 61.90 % AVG Validation Acc 61.77 %\n",
      "Epoch:190/200 AVG Training Loss:0.651 AVG Validation Loss:0.657 AVG Training Acc 61.91 % AVG Validation Acc 61.77 %\n",
      "Epoch:200/200 AVG Training Loss:0.651 AVG Validation Loss:0.657 AVG Training Acc 62.05 % AVG Validation Acc 61.77 %\n",
      "Split 194\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80fd82236cda49499411dd39871bb6a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.657 AVG Training Acc 61.86 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.654 AVG Training Acc 61.64 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.660 AVG Validation Loss:0.655 AVG Training Acc 61.86 % AVG Validation Acc 61.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.664 AVG Validation Loss:0.667 AVG Training Acc 61.31 % AVG Validation Acc 61.95 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.664 AVG Validation Loss:0.659 AVG Training Acc 61.69 % AVG Validation Acc 61.77 %\n",
      "Epoch:60/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 61.98 % AVG Validation Acc 61.95 %\n",
      "Epoch:70/200 AVG Training Loss:0.660 AVG Validation Loss:0.657 AVG Training Acc 61.95 % AVG Validation Acc 61.95 %\n",
      "Epoch:80/200 AVG Training Loss:0.660 AVG Validation Loss:0.657 AVG Training Acc 61.95 % AVG Validation Acc 61.86 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.658 AVG Validation Loss:0.657 AVG Training Acc 61.93 % AVG Validation Acc 61.95 %\n",
      "Epoch:100/200 AVG Training Loss:0.658 AVG Validation Loss:0.658 AVG Training Acc 61.93 % AVG Validation Acc 61.95 %\n",
      "Epoch:110/200 AVG Training Loss:0.657 AVG Validation Loss:0.657 AVG Training Acc 61.98 % AVG Validation Acc 61.95 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.658 AVG Validation Loss:0.656 AVG Training Acc 61.99 % AVG Validation Acc 61.95 %\n",
      "Epoch:130/200 AVG Training Loss:0.658 AVG Validation Loss:0.657 AVG Training Acc 62.03 % AVG Validation Acc 61.95 %\n",
      "Epoch:140/200 AVG Training Loss:0.657 AVG Validation Loss:0.656 AVG Training Acc 62.02 % AVG Validation Acc 61.95 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.658 AVG Validation Loss:0.656 AVG Training Acc 61.94 % AVG Validation Acc 61.95 %\n",
      "Epoch:160/200 AVG Training Loss:0.657 AVG Validation Loss:0.656 AVG Training Acc 61.99 % AVG Validation Acc 61.95 %\n",
      "Epoch:170/200 AVG Training Loss:0.659 AVG Validation Loss:0.657 AVG Training Acc 61.99 % AVG Validation Acc 61.95 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.658 AVG Validation Loss:0.656 AVG Training Acc 61.96 % AVG Validation Acc 61.86 %\n",
      "Epoch:190/200 AVG Training Loss:0.657 AVG Validation Loss:0.657 AVG Training Acc 62.01 % AVG Validation Acc 61.95 %\n",
      "Epoch:200/200 AVG Training Loss:0.657 AVG Validation Loss:0.656 AVG Training Acc 61.94 % AVG Validation Acc 61.95 %\n",
      "Split 195\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09091d8f863c4415a0b19e56a705fa59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.660 AVG Training Acc 61.86 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.661 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.661 AVG Training Acc 61.93 % AVG Validation Acc 61.77 %\n",
      "Epoch:40/200 AVG Training Loss:0.654 AVG Validation Loss:0.663 AVG Training Acc 61.87 % AVG Validation Acc 61.86 %\n",
      "Epoch:50/200 AVG Training Loss:0.652 AVG Validation Loss:0.665 AVG Training Acc 62.21 % AVG Validation Acc 61.86 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.650 AVG Validation Loss:0.666 AVG Training Acc 61.99 % AVG Validation Acc 61.68 %\n",
      "Epoch:70/200 AVG Training Loss:0.649 AVG Validation Loss:0.667 AVG Training Acc 62.07 % AVG Validation Acc 61.23 %\n",
      "Epoch:80/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 62.20 % AVG Validation Acc 61.50 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.648 AVG Validation Loss:0.667 AVG Training Acc 62.35 % AVG Validation Acc 61.50 %\n",
      "Epoch:100/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 62.08 % AVG Validation Acc 61.23 %\n",
      "Epoch:110/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 62.03 % AVG Validation Acc 61.14 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 61.93 % AVG Validation Acc 61.05 %\n",
      "Epoch:130/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 61.75 % AVG Validation Acc 61.50 %\n",
      "Epoch:140/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 62.38 % AVG Validation Acc 61.41 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.648 AVG Validation Loss:0.668 AVG Training Acc 62.21 % AVG Validation Acc 61.77 %\n",
      "Epoch:160/200 AVG Training Loss:0.648 AVG Validation Loss:0.668 AVG Training Acc 62.09 % AVG Validation Acc 61.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.648 AVG Validation Loss:0.668 AVG Training Acc 62.13 % AVG Validation Acc 61.41 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.648 AVG Validation Loss:0.668 AVG Training Acc 62.07 % AVG Validation Acc 61.77 %\n",
      "Epoch:190/200 AVG Training Loss:0.648 AVG Validation Loss:0.667 AVG Training Acc 62.04 % AVG Validation Acc 61.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 62.06 % AVG Validation Acc 61.59 %\n",
      "Split 196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a26abbcf84a49148177c458a6b831b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.661 AVG Training Acc 61.89 % AVG Validation Acc 61.82 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.663 AVG Training Acc 61.79 % AVG Validation Acc 61.82 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.652 AVG Validation Loss:0.665 AVG Training Acc 61.94 % AVG Validation Acc 61.46 %\n",
      "Epoch:40/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 62.11 % AVG Validation Acc 61.55 %\n",
      "Epoch:50/200 AVG Training Loss:0.645 AVG Validation Loss:0.671 AVG Training Acc 62.11 % AVG Validation Acc 61.73 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.641 AVG Validation Loss:0.672 AVG Training Acc 62.57 % AVG Validation Acc 61.28 %\n",
      "Epoch:70/200 AVG Training Loss:0.642 AVG Validation Loss:0.673 AVG Training Acc 62.30 % AVG Validation Acc 61.10 %\n",
      "Epoch:80/200 AVG Training Loss:0.641 AVG Validation Loss:0.674 AVG Training Acc 62.56 % AVG Validation Acc 61.10 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.640 AVG Validation Loss:0.674 AVG Training Acc 62.51 % AVG Validation Acc 61.10 %\n",
      "Epoch:100/200 AVG Training Loss:0.640 AVG Validation Loss:0.674 AVG Training Acc 62.39 % AVG Validation Acc 60.92 %\n",
      "Epoch:110/200 AVG Training Loss:0.641 AVG Validation Loss:0.676 AVG Training Acc 62.34 % AVG Validation Acc 61.19 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.640 AVG Validation Loss:0.675 AVG Training Acc 62.77 % AVG Validation Acc 61.19 %\n",
      "Epoch:130/200 AVG Training Loss:0.641 AVG Validation Loss:0.674 AVG Training Acc 62.38 % AVG Validation Acc 61.01 %\n",
      "Epoch:140/200 AVG Training Loss:0.642 AVG Validation Loss:0.673 AVG Training Acc 62.45 % AVG Validation Acc 61.10 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.641 AVG Validation Loss:0.674 AVG Training Acc 62.29 % AVG Validation Acc 61.01 %\n",
      "Epoch:160/200 AVG Training Loss:0.642 AVG Validation Loss:0.674 AVG Training Acc 62.64 % AVG Validation Acc 61.01 %\n",
      "Epoch:170/200 AVG Training Loss:0.640 AVG Validation Loss:0.675 AVG Training Acc 62.55 % AVG Validation Acc 60.74 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.642 AVG Validation Loss:0.674 AVG Training Acc 62.50 % AVG Validation Acc 60.83 %\n",
      "Epoch:190/200 AVG Training Loss:0.641 AVG Validation Loss:0.675 AVG Training Acc 62.08 % AVG Validation Acc 61.28 %\n",
      "Epoch:200/200 AVG Training Loss:0.641 AVG Validation Loss:0.674 AVG Training Acc 62.41 % AVG Validation Acc 61.10 %\n",
      "Split 197\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ff6a6f6fd5f416cb5a4e83f98197af1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.655 AVG Training Acc 61.92 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.657 AVG Training Acc 61.82 % AVG Validation Acc 61.91 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.657 AVG Training Acc 61.89 % AVG Validation Acc 62.00 %\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.665 AVG Training Acc 62.02 % AVG Validation Acc 61.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.649 AVG Validation Loss:0.669 AVG Training Acc 61.99 % AVG Validation Acc 61.91 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.645 AVG Validation Loss:0.675 AVG Training Acc 62.46 % AVG Validation Acc 61.91 %\n",
      "Epoch:70/200 AVG Training Loss:0.646 AVG Validation Loss:0.676 AVG Training Acc 62.35 % AVG Validation Acc 61.55 %\n",
      "Epoch:80/200 AVG Training Loss:0.645 AVG Validation Loss:0.675 AVG Training Acc 61.96 % AVG Validation Acc 61.55 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.645 AVG Validation Loss:0.676 AVG Training Acc 62.21 % AVG Validation Acc 61.82 %\n",
      "Epoch:100/200 AVG Training Loss:0.645 AVG Validation Loss:0.677 AVG Training Acc 62.31 % AVG Validation Acc 61.55 %\n",
      "Epoch:110/200 AVG Training Loss:0.645 AVG Validation Loss:0.676 AVG Training Acc 62.10 % AVG Validation Acc 61.37 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.644 AVG Validation Loss:0.677 AVG Training Acc 62.06 % AVG Validation Acc 61.73 %\n",
      "Epoch:130/200 AVG Training Loss:0.645 AVG Validation Loss:0.677 AVG Training Acc 62.35 % AVG Validation Acc 61.64 %\n",
      "Epoch:140/200 AVG Training Loss:0.644 AVG Validation Loss:0.677 AVG Training Acc 62.37 % AVG Validation Acc 61.73 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.644 AVG Validation Loss:0.676 AVG Training Acc 62.11 % AVG Validation Acc 61.64 %\n",
      "Epoch:160/200 AVG Training Loss:0.645 AVG Validation Loss:0.676 AVG Training Acc 61.88 % AVG Validation Acc 61.37 %\n",
      "Epoch:170/200 AVG Training Loss:0.646 AVG Validation Loss:0.677 AVG Training Acc 61.92 % AVG Validation Acc 61.73 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.646 AVG Validation Loss:0.676 AVG Training Acc 62.11 % AVG Validation Acc 61.64 %\n",
      "Epoch:190/200 AVG Training Loss:0.644 AVG Validation Loss:0.677 AVG Training Acc 62.37 % AVG Validation Acc 61.91 %\n",
      "Epoch:200/200 AVG Training Loss:0.643 AVG Validation Loss:0.677 AVG Training Acc 62.11 % AVG Validation Acc 61.91 %\n",
      "Split 198\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37fc1aef3166405e8c1834ceba3fc8b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.658 AVG Training Acc 61.88 % AVG Validation Acc 62.00 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.657 AVG Training Acc 61.79 % AVG Validation Acc 62.00 %\n",
      "Epoch:30/200 AVG Training Loss:0.658 AVG Validation Loss:0.657 AVG Training Acc 61.77 % AVG Validation Acc 62.09 %\n",
      "Epoch:40/200 AVG Training Loss:0.655 AVG Validation Loss:0.653 AVG Training Acc 61.75 % AVG Validation Acc 62.00 %\n",
      "Epoch:50/200 AVG Training Loss:0.651 AVG Validation Loss:0.651 AVG Training Acc 61.97 % AVG Validation Acc 62.73 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.642 AVG Validation Loss:0.646 AVG Training Acc 62.39 % AVG Validation Acc 63.45 %\n",
      "Epoch:70/200 AVG Training Loss:0.632 AVG Validation Loss:0.651 AVG Training Acc 63.57 % AVG Validation Acc 62.00 %\n",
      "Epoch:80/200 AVG Training Loss:0.628 AVG Validation Loss:0.654 AVG Training Acc 63.77 % AVG Validation Acc 62.00 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.626 AVG Validation Loss:0.652 AVG Training Acc 63.86 % AVG Validation Acc 62.45 %\n",
      "Epoch:100/200 AVG Training Loss:0.625 AVG Validation Loss:0.656 AVG Training Acc 63.70 % AVG Validation Acc 61.91 %\n",
      "Epoch:110/200 AVG Training Loss:0.624 AVG Validation Loss:0.655 AVG Training Acc 63.56 % AVG Validation Acc 62.45 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.622 AVG Validation Loss:0.655 AVG Training Acc 64.24 % AVG Validation Acc 62.64 %\n",
      "Epoch:130/200 AVG Training Loss:0.623 AVG Validation Loss:0.653 AVG Training Acc 63.92 % AVG Validation Acc 63.09 %\n",
      "Epoch:140/200 AVG Training Loss:0.622 AVG Validation Loss:0.654 AVG Training Acc 63.91 % AVG Validation Acc 62.36 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.621 AVG Validation Loss:0.654 AVG Training Acc 64.34 % AVG Validation Acc 62.27 %\n",
      "Epoch:160/200 AVG Training Loss:0.622 AVG Validation Loss:0.657 AVG Training Acc 63.34 % AVG Validation Acc 62.36 %\n",
      "Epoch:170/200 AVG Training Loss:0.620 AVG Validation Loss:0.656 AVG Training Acc 64.37 % AVG Validation Acc 62.82 %\n",
      "Epoch:180/200 AVG Training Loss:0.622 AVG Validation Loss:0.653 AVG Training Acc 63.90 % AVG Validation Acc 62.82 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.620 AVG Validation Loss:0.655 AVG Training Acc 64.43 % AVG Validation Acc 62.18 %\n",
      "Epoch:200/200 AVG Training Loss:0.621 AVG Validation Loss:0.653 AVG Training Acc 64.39 % AVG Validation Acc 62.64 %\n",
      "Split 199\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be045ce7cabc42c5a704d14b42743a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.663 AVG Training Acc 61.92 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.661 AVG Training Acc 61.90 % AVG Validation Acc 62.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.660 AVG Training Acc 61.67 % AVG Validation Acc 62.09 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.663 AVG Training Acc 62.07 % AVG Validation Acc 62.27 %\n",
      "Epoch:50/200 AVG Training Loss:0.648 AVG Validation Loss:0.667 AVG Training Acc 62.07 % AVG Validation Acc 62.18 %\n",
      "Epoch:60/200 AVG Training Loss:0.645 AVG Validation Loss:0.671 AVG Training Acc 62.31 % AVG Validation Acc 62.00 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.643 AVG Validation Loss:0.675 AVG Training Acc 62.61 % AVG Validation Acc 61.55 %\n",
      "Epoch:80/200 AVG Training Loss:0.640 AVG Validation Loss:0.677 AVG Training Acc 62.77 % AVG Validation Acc 61.55 %\n",
      "Epoch:90/200 AVG Training Loss:0.642 AVG Validation Loss:0.675 AVG Training Acc 62.64 % AVG Validation Acc 61.46 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.640 AVG Validation Loss:0.678 AVG Training Acc 62.89 % AVG Validation Acc 61.64 %\n",
      "Epoch:110/200 AVG Training Loss:0.641 AVG Validation Loss:0.678 AVG Training Acc 62.82 % AVG Validation Acc 61.73 %\n",
      "Epoch:120/200 AVG Training Loss:0.640 AVG Validation Loss:0.676 AVG Training Acc 63.02 % AVG Validation Acc 61.82 %\n",
      "Epoch:130/200 AVG Training Loss:0.641 AVG Validation Loss:0.677 AVG Training Acc 62.61 % AVG Validation Acc 61.64 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.639 AVG Validation Loss:0.676 AVG Training Acc 62.97 % AVG Validation Acc 61.73 %\n",
      "Epoch:150/200 AVG Training Loss:0.640 AVG Validation Loss:0.677 AVG Training Acc 63.00 % AVG Validation Acc 61.82 %\n",
      "Epoch:160/200 AVG Training Loss:0.639 AVG Validation Loss:0.678 AVG Training Acc 63.17 % AVG Validation Acc 61.91 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.640 AVG Validation Loss:0.675 AVG Training Acc 62.90 % AVG Validation Acc 61.64 %\n",
      "Epoch:180/200 AVG Training Loss:0.639 AVG Validation Loss:0.678 AVG Training Acc 63.03 % AVG Validation Acc 61.73 %\n",
      "Epoch:190/200 AVG Training Loss:0.639 AVG Validation Loss:0.676 AVG Training Acc 63.18 % AVG Validation Acc 61.82 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.641 AVG Validation Loss:0.675 AVG Training Acc 62.66 % AVG Validation Acc 61.64 %\n",
      "Split 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2a2c80c36dc45e0b7eab5cdd9db0576",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.661 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 61.87 % AVG Validation Acc 61.91 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.664 AVG Training Acc 61.94 % AVG Validation Acc 61.82 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.669 AVG Training Acc 61.80 % AVG Validation Acc 61.82 %\n",
      "Epoch:50/200 AVG Training Loss:0.648 AVG Validation Loss:0.681 AVG Training Acc 62.09 % AVG Validation Acc 61.46 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.644 AVG Validation Loss:0.687 AVG Training Acc 62.01 % AVG Validation Acc 60.83 %\n",
      "Epoch:70/200 AVG Training Loss:0.644 AVG Validation Loss:0.686 AVG Training Acc 61.99 % AVG Validation Acc 60.92 %\n",
      "Epoch:80/200 AVG Training Loss:0.644 AVG Validation Loss:0.686 AVG Training Acc 62.09 % AVG Validation Acc 60.83 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.642 AVG Validation Loss:0.686 AVG Training Acc 62.22 % AVG Validation Acc 60.74 %\n",
      "Epoch:100/200 AVG Training Loss:0.642 AVG Validation Loss:0.687 AVG Training Acc 62.32 % AVG Validation Acc 60.83 %\n",
      "Epoch:110/200 AVG Training Loss:0.641 AVG Validation Loss:0.687 AVG Training Acc 62.46 % AVG Validation Acc 60.65 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.642 AVG Validation Loss:0.687 AVG Training Acc 62.03 % AVG Validation Acc 60.65 %\n",
      "Epoch:130/200 AVG Training Loss:0.643 AVG Validation Loss:0.687 AVG Training Acc 61.99 % AVG Validation Acc 60.65 %\n",
      "Epoch:140/200 AVG Training Loss:0.643 AVG Validation Loss:0.688 AVG Training Acc 62.22 % AVG Validation Acc 60.56 %\n",
      "Epoch:150/200 AVG Training Loss:0.642 AVG Validation Loss:0.688 AVG Training Acc 62.26 % AVG Validation Acc 60.56 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.642 AVG Validation Loss:0.686 AVG Training Acc 62.04 % AVG Validation Acc 60.74 %\n",
      "Epoch:170/200 AVG Training Loss:0.643 AVG Validation Loss:0.688 AVG Training Acc 61.93 % AVG Validation Acc 60.74 %\n",
      "Epoch:180/200 AVG Training Loss:0.643 AVG Validation Loss:0.687 AVG Training Acc 62.19 % AVG Validation Acc 60.65 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.643 AVG Validation Loss:0.687 AVG Training Acc 62.23 % AVG Validation Acc 60.56 %\n",
      "Epoch:200/200 AVG Training Loss:0.643 AVG Validation Loss:0.687 AVG Training Acc 62.14 % AVG Validation Acc 60.74 %\n",
      "Split 201\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0225e4eb96a744ac97f3cebdacdd45f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.656 AVG Training Acc 61.85 % AVG Validation Acc 61.86 %\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.656 AVG Validation Loss:0.657 AVG Training Acc 61.93 % AVG Validation Acc 61.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.659 AVG Training Acc 62.02 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.654 AVG Validation Loss:0.660 AVG Training Acc 61.97 % AVG Validation Acc 61.59 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.651 AVG Validation Loss:0.660 AVG Training Acc 62.05 % AVG Validation Acc 61.41 %\n",
      "Epoch:60/200 AVG Training Loss:0.651 AVG Validation Loss:0.661 AVG Training Acc 62.10 % AVG Validation Acc 61.41 %\n",
      "Epoch:70/200 AVG Training Loss:0.651 AVG Validation Loss:0.662 AVG Training Acc 62.08 % AVG Validation Acc 61.50 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.650 AVG Validation Loss:0.663 AVG Training Acc 62.14 % AVG Validation Acc 61.41 %\n",
      "Epoch:90/200 AVG Training Loss:0.649 AVG Validation Loss:0.662 AVG Training Acc 62.13 % AVG Validation Acc 61.41 %\n",
      "Epoch:100/200 AVG Training Loss:0.650 AVG Validation Loss:0.662 AVG Training Acc 62.08 % AVG Validation Acc 61.41 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.650 AVG Validation Loss:0.662 AVG Training Acc 62.19 % AVG Validation Acc 61.41 %\n",
      "Epoch:120/200 AVG Training Loss:0.650 AVG Validation Loss:0.663 AVG Training Acc 62.04 % AVG Validation Acc 61.41 %\n",
      "Epoch:130/200 AVG Training Loss:0.650 AVG Validation Loss:0.663 AVG Training Acc 62.06 % AVG Validation Acc 61.41 %\n",
      "Epoch:140/200 AVG Training Loss:0.650 AVG Validation Loss:0.662 AVG Training Acc 62.03 % AVG Validation Acc 61.41 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.650 AVG Validation Loss:0.662 AVG Training Acc 62.23 % AVG Validation Acc 61.41 %\n",
      "Epoch:160/200 AVG Training Loss:0.650 AVG Validation Loss:0.662 AVG Training Acc 62.14 % AVG Validation Acc 61.41 %\n",
      "Epoch:170/200 AVG Training Loss:0.650 AVG Validation Loss:0.663 AVG Training Acc 62.05 % AVG Validation Acc 61.41 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.650 AVG Validation Loss:0.662 AVG Training Acc 62.09 % AVG Validation Acc 61.41 %\n",
      "Epoch:190/200 AVG Training Loss:0.650 AVG Validation Loss:0.662 AVG Training Acc 62.25 % AVG Validation Acc 61.41 %\n",
      "Epoch:200/200 AVG Training Loss:0.650 AVG Validation Loss:0.663 AVG Training Acc 62.08 % AVG Validation Acc 61.41 %\n",
      "Split 202\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6eef908f52542ac9661c0c14df27616",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.662 AVG Training Acc 61.86 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 61.83 % AVG Validation Acc 61.86 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.661 AVG Training Acc 61.97 % AVG Validation Acc 61.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.655 AVG Validation Loss:0.660 AVG Training Acc 61.88 % AVG Validation Acc 61.86 %\n",
      "Epoch:50/200 AVG Training Loss:0.651 AVG Validation Loss:0.661 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.651 AVG Validation Loss:0.661 AVG Training Acc 62.05 % AVG Validation Acc 61.95 %\n",
      "Epoch:70/200 AVG Training Loss:0.651 AVG Validation Loss:0.661 AVG Training Acc 61.96 % AVG Validation Acc 61.95 %\n",
      "Epoch:80/200 AVG Training Loss:0.650 AVG Validation Loss:0.661 AVG Training Acc 61.87 % AVG Validation Acc 61.86 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.649 AVG Validation Loss:0.661 AVG Training Acc 62.12 % AVG Validation Acc 61.77 %\n",
      "Epoch:100/200 AVG Training Loss:0.648 AVG Validation Loss:0.661 AVG Training Acc 62.03 % AVG Validation Acc 61.77 %\n",
      "Epoch:110/200 AVG Training Loss:0.649 AVG Validation Loss:0.662 AVG Training Acc 62.00 % AVG Validation Acc 61.68 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.648 AVG Validation Loss:0.662 AVG Training Acc 62.04 % AVG Validation Acc 61.68 %\n",
      "Epoch:130/200 AVG Training Loss:0.650 AVG Validation Loss:0.662 AVG Training Acc 62.02 % AVG Validation Acc 61.68 %\n",
      "Epoch:140/200 AVG Training Loss:0.649 AVG Validation Loss:0.662 AVG Training Acc 62.19 % AVG Validation Acc 61.77 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.648 AVG Validation Loss:0.662 AVG Training Acc 62.15 % AVG Validation Acc 61.68 %\n",
      "Epoch:160/200 AVG Training Loss:0.649 AVG Validation Loss:0.662 AVG Training Acc 62.17 % AVG Validation Acc 61.77 %\n",
      "Epoch:170/200 AVG Training Loss:0.649 AVG Validation Loss:0.662 AVG Training Acc 62.00 % AVG Validation Acc 61.77 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.648 AVG Validation Loss:0.662 AVG Training Acc 62.01 % AVG Validation Acc 61.68 %\n",
      "Epoch:190/200 AVG Training Loss:0.649 AVG Validation Loss:0.661 AVG Training Acc 61.91 % AVG Validation Acc 61.77 %\n",
      "Epoch:200/200 AVG Training Loss:0.649 AVG Validation Loss:0.662 AVG Training Acc 62.04 % AVG Validation Acc 61.77 %\n",
      "Split 203\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35648eb72dd8446c8656be811bd7ae65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.656 AVG Training Acc 61.87 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.657 AVG Training Acc 61.92 % AVG Validation Acc 61.86 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.658 AVG Training Acc 61.94 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.654 AVG Validation Loss:0.657 AVG Training Acc 61.97 % AVG Validation Acc 61.77 %\n",
      "Epoch:50/200 AVG Training Loss:0.652 AVG Validation Loss:0.658 AVG Training Acc 61.85 % AVG Validation Acc 61.77 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.650 AVG Validation Loss:0.656 AVG Training Acc 62.05 % AVG Validation Acc 61.77 %\n",
      "Epoch:70/200 AVG Training Loss:0.650 AVG Validation Loss:0.656 AVG Training Acc 62.15 % AVG Validation Acc 61.77 %\n",
      "Epoch:80/200 AVG Training Loss:0.650 AVG Validation Loss:0.657 AVG Training Acc 61.86 % AVG Validation Acc 61.77 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.648 AVG Validation Loss:0.656 AVG Training Acc 61.83 % AVG Validation Acc 61.77 %\n",
      "Epoch:100/200 AVG Training Loss:0.649 AVG Validation Loss:0.657 AVG Training Acc 61.86 % AVG Validation Acc 61.77 %\n",
      "Epoch:110/200 AVG Training Loss:0.650 AVG Validation Loss:0.657 AVG Training Acc 61.81 % AVG Validation Acc 61.77 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.649 AVG Validation Loss:0.657 AVG Training Acc 61.82 % AVG Validation Acc 61.77 %\n",
      "Epoch:130/200 AVG Training Loss:0.649 AVG Validation Loss:0.657 AVG Training Acc 62.01 % AVG Validation Acc 61.77 %\n",
      "Epoch:140/200 AVG Training Loss:0.650 AVG Validation Loss:0.656 AVG Training Acc 61.87 % AVG Validation Acc 61.77 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.649 AVG Validation Loss:0.657 AVG Training Acc 61.93 % AVG Validation Acc 61.77 %\n",
      "Epoch:160/200 AVG Training Loss:0.650 AVG Validation Loss:0.657 AVG Training Acc 61.76 % AVG Validation Acc 61.77 %\n",
      "Epoch:170/200 AVG Training Loss:0.650 AVG Validation Loss:0.656 AVG Training Acc 61.87 % AVG Validation Acc 61.68 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.649 AVG Validation Loss:0.657 AVG Training Acc 62.13 % AVG Validation Acc 61.77 %\n",
      "Epoch:190/200 AVG Training Loss:0.649 AVG Validation Loss:0.657 AVG Training Acc 61.84 % AVG Validation Acc 61.77 %\n",
      "Epoch:200/200 AVG Training Loss:0.650 AVG Validation Loss:0.657 AVG Training Acc 61.92 % AVG Validation Acc 61.77 %\n",
      "Split 204\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf319c2986384710a076e0fadbf6689e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.663 AVG Training Acc 61.88 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.670 AVG Validation Loss:0.669 AVG Training Acc 61.35 % AVG Validation Acc 61.86 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.661 AVG Validation Loss:0.665 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:50/200 AVG Training Loss:0.660 AVG Validation Loss:0.666 AVG Training Acc 61.96 % AVG Validation Acc 61.77 %\n",
      "Epoch:60/200 AVG Training Loss:0.658 AVG Validation Loss:0.665 AVG Training Acc 61.98 % AVG Validation Acc 61.86 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.659 AVG Validation Loss:0.662 AVG Training Acc 62.05 % AVG Validation Acc 61.86 %\n",
      "Epoch:80/200 AVG Training Loss:0.659 AVG Validation Loss:0.663 AVG Training Acc 61.99 % AVG Validation Acc 61.86 %\n",
      "Epoch:90/200 AVG Training Loss:0.659 AVG Validation Loss:0.662 AVG Training Acc 62.06 % AVG Validation Acc 61.77 %\n",
      "Epoch:100/200 AVG Training Loss:0.659 AVG Validation Loss:0.660 AVG Training Acc 62.05 % AVG Validation Acc 61.86 %\n",
      "Epoch:110/200 AVG Training Loss:0.659 AVG Validation Loss:0.662 AVG Training Acc 62.05 % AVG Validation Acc 61.77 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 62.01 % AVG Validation Acc 61.68 %\n",
      "Epoch:130/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 62.06 % AVG Validation Acc 61.68 %\n",
      "Epoch:140/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 62.09 % AVG Validation Acc 61.86 %\n",
      "Epoch:150/200 AVG Training Loss:0.658 AVG Validation Loss:0.661 AVG Training Acc 62.10 % AVG Validation Acc 61.77 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.659 AVG Validation Loss:0.661 AVG Training Acc 62.03 % AVG Validation Acc 61.77 %\n",
      "Epoch:170/200 AVG Training Loss:0.659 AVG Validation Loss:0.662 AVG Training Acc 62.08 % AVG Validation Acc 61.86 %\n",
      "Epoch:180/200 AVG Training Loss:0.659 AVG Validation Loss:0.661 AVG Training Acc 62.08 % AVG Validation Acc 61.95 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 62.11 % AVG Validation Acc 61.68 %\n",
      "Epoch:200/200 AVG Training Loss:0.658 AVG Validation Loss:0.661 AVG Training Acc 62.10 % AVG Validation Acc 61.77 %\n",
      "Split 205\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c69e1f3c8024484ca40de0bcbdd6deaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 61.87 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.664 AVG Training Acc 61.93 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.667 AVG Training Acc 61.80 % AVG Validation Acc 61.68 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.663 AVG Training Acc 61.93 % AVG Validation Acc 61.77 %\n",
      "Epoch:50/200 AVG Training Loss:0.649 AVG Validation Loss:0.663 AVG Training Acc 61.85 % AVG Validation Acc 61.77 %\n",
      "Epoch:60/200 AVG Training Loss:0.647 AVG Validation Loss:0.664 AVG Training Acc 62.13 % AVG Validation Acc 61.68 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.644 AVG Validation Loss:0.670 AVG Training Acc 62.34 % AVG Validation Acc 61.41 %\n",
      "Epoch:80/200 AVG Training Loss:0.644 AVG Validation Loss:0.667 AVG Training Acc 62.57 % AVG Validation Acc 61.77 %\n",
      "Epoch:90/200 AVG Training Loss:0.645 AVG Validation Loss:0.668 AVG Training Acc 62.06 % AVG Validation Acc 61.32 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.644 AVG Validation Loss:0.667 AVG Training Acc 62.26 % AVG Validation Acc 61.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.644 AVG Validation Loss:0.668 AVG Training Acc 62.32 % AVG Validation Acc 61.32 %\n",
      "Epoch:120/200 AVG Training Loss:0.644 AVG Validation Loss:0.668 AVG Training Acc 62.54 % AVG Validation Acc 61.32 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.643 AVG Validation Loss:0.668 AVG Training Acc 62.16 % AVG Validation Acc 61.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.645 AVG Validation Loss:0.670 AVG Training Acc 61.90 % AVG Validation Acc 61.41 %\n",
      "Epoch:150/200 AVG Training Loss:0.643 AVG Validation Loss:0.668 AVG Training Acc 62.31 % AVG Validation Acc 61.05 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.644 AVG Validation Loss:0.671 AVG Training Acc 62.31 % AVG Validation Acc 61.23 %\n",
      "Epoch:170/200 AVG Training Loss:0.643 AVG Validation Loss:0.668 AVG Training Acc 62.16 % AVG Validation Acc 61.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.645 AVG Validation Loss:0.668 AVG Training Acc 62.19 % AVG Validation Acc 61.05 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.644 AVG Validation Loss:0.671 AVG Training Acc 62.31 % AVG Validation Acc 61.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.644 AVG Validation Loss:0.669 AVG Training Acc 62.37 % AVG Validation Acc 60.96 %\n",
      "Split 206\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45f1048809754a36b145cb73289ae2e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.655 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.656 AVG Training Acc 62.00 % AVG Validation Acc 61.82 %\n",
      "Epoch:30/200 AVG Training Loss:0.658 AVG Validation Loss:0.655 AVG Training Acc 61.90 % AVG Validation Acc 61.82 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.650 AVG Validation Loss:0.655 AVG Training Acc 62.07 % AVG Validation Acc 62.00 %\n",
      "Epoch:50/200 AVG Training Loss:0.646 AVG Validation Loss:0.657 AVG Training Acc 61.98 % AVG Validation Acc 61.82 %\n",
      "Epoch:60/200 AVG Training Loss:0.643 AVG Validation Loss:0.661 AVG Training Acc 61.87 % AVG Validation Acc 61.64 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.640 AVG Validation Loss:0.665 AVG Training Acc 62.54 % AVG Validation Acc 61.55 %\n",
      "Epoch:80/200 AVG Training Loss:0.640 AVG Validation Loss:0.665 AVG Training Acc 62.29 % AVG Validation Acc 61.73 %\n",
      "Epoch:90/200 AVG Training Loss:0.639 AVG Validation Loss:0.666 AVG Training Acc 62.49 % AVG Validation Acc 61.73 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.637 AVG Validation Loss:0.666 AVG Training Acc 62.67 % AVG Validation Acc 61.64 %\n",
      "Epoch:110/200 AVG Training Loss:0.638 AVG Validation Loss:0.666 AVG Training Acc 62.74 % AVG Validation Acc 61.46 %\n",
      "Epoch:120/200 AVG Training Loss:0.639 AVG Validation Loss:0.665 AVG Training Acc 62.47 % AVG Validation Acc 61.64 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.638 AVG Validation Loss:0.665 AVG Training Acc 62.72 % AVG Validation Acc 61.73 %\n",
      "Epoch:140/200 AVG Training Loss:0.638 AVG Validation Loss:0.666 AVG Training Acc 62.51 % AVG Validation Acc 61.46 %\n",
      "Epoch:150/200 AVG Training Loss:0.638 AVG Validation Loss:0.665 AVG Training Acc 62.54 % AVG Validation Acc 61.73 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.639 AVG Validation Loss:0.664 AVG Training Acc 62.31 % AVG Validation Acc 61.55 %\n",
      "Epoch:170/200 AVG Training Loss:0.639 AVG Validation Loss:0.666 AVG Training Acc 62.56 % AVG Validation Acc 61.55 %\n",
      "Epoch:180/200 AVG Training Loss:0.638 AVG Validation Loss:0.665 AVG Training Acc 62.97 % AVG Validation Acc 61.73 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.638 AVG Validation Loss:0.666 AVG Training Acc 62.67 % AVG Validation Acc 61.73 %\n",
      "Epoch:200/200 AVG Training Loss:0.638 AVG Validation Loss:0.666 AVG Training Acc 62.71 % AVG Validation Acc 61.64 %\n",
      "Split 207\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa7c2c66cea491f9f5fac632b5ad719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.663 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:0.663 AVG Training Acc 61.92 % AVG Validation Acc 62.00 %\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.662 AVG Training Acc 61.92 % AVG Validation Acc 62.00 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.662 AVG Training Acc 61.96 % AVG Validation Acc 61.91 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.648 AVG Validation Loss:0.665 AVG Training Acc 62.17 % AVG Validation Acc 61.46 %\n",
      "Epoch:60/200 AVG Training Loss:0.646 AVG Validation Loss:0.664 AVG Training Acc 62.13 % AVG Validation Acc 61.55 %\n",
      "Epoch:70/200 AVG Training Loss:0.645 AVG Validation Loss:0.665 AVG Training Acc 62.04 % AVG Validation Acc 61.46 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.645 AVG Validation Loss:0.666 AVG Training Acc 62.39 % AVG Validation Acc 61.19 %\n",
      "Epoch:90/200 AVG Training Loss:0.645 AVG Validation Loss:0.666 AVG Training Acc 62.04 % AVG Validation Acc 61.55 %\n",
      "Epoch:100/200 AVG Training Loss:0.645 AVG Validation Loss:0.666 AVG Training Acc 62.58 % AVG Validation Acc 61.73 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.645 AVG Validation Loss:0.666 AVG Training Acc 62.34 % AVG Validation Acc 61.37 %\n",
      "Epoch:120/200 AVG Training Loss:0.645 AVG Validation Loss:0.665 AVG Training Acc 62.36 % AVG Validation Acc 61.64 %\n",
      "Epoch:130/200 AVG Training Loss:0.645 AVG Validation Loss:0.667 AVG Training Acc 62.23 % AVG Validation Acc 61.55 %\n",
      "Epoch:140/200 AVG Training Loss:0.645 AVG Validation Loss:0.666 AVG Training Acc 62.30 % AVG Validation Acc 61.46 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.644 AVG Validation Loss:0.667 AVG Training Acc 62.28 % AVG Validation Acc 61.19 %\n",
      "Epoch:160/200 AVG Training Loss:0.644 AVG Validation Loss:0.667 AVG Training Acc 62.21 % AVG Validation Acc 61.28 %\n",
      "Epoch:170/200 AVG Training Loss:0.645 AVG Validation Loss:0.667 AVG Training Acc 62.45 % AVG Validation Acc 61.46 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.643 AVG Validation Loss:0.667 AVG Training Acc 62.40 % AVG Validation Acc 61.46 %\n",
      "Epoch:190/200 AVG Training Loss:0.645 AVG Validation Loss:0.666 AVG Training Acc 62.54 % AVG Validation Acc 61.28 %\n",
      "Epoch:200/200 AVG Training Loss:0.646 AVG Validation Loss:0.666 AVG Training Acc 62.00 % AVG Validation Acc 61.46 %\n",
      "Split 208\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d7f6b4cac1b41f7b50f0354694b5e7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.665 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.663 AVG Training Acc 61.92 % AVG Validation Acc 62.00 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.663 AVG Training Acc 61.87 % AVG Validation Acc 62.00 %\n",
      "Epoch:40/200 AVG Training Loss:0.654 AVG Validation Loss:0.664 AVG Training Acc 61.90 % AVG Validation Acc 62.00 %\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.653 AVG Validation Loss:0.663 AVG Training Acc 61.98 % AVG Validation Acc 62.09 %\n",
      "Epoch:60/200 AVG Training Loss:0.652 AVG Validation Loss:0.664 AVG Training Acc 62.03 % AVG Validation Acc 62.18 %\n",
      "Epoch:70/200 AVG Training Loss:0.652 AVG Validation Loss:0.664 AVG Training Acc 62.15 % AVG Validation Acc 62.09 %\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.652 AVG Validation Loss:0.664 AVG Training Acc 62.20 % AVG Validation Acc 62.09 %\n",
      "Epoch:90/200 AVG Training Loss:0.652 AVG Validation Loss:0.665 AVG Training Acc 62.27 % AVG Validation Acc 62.09 %\n",
      "Epoch:100/200 AVG Training Loss:0.652 AVG Validation Loss:0.664 AVG Training Acc 62.07 % AVG Validation Acc 62.09 %\n",
      "Epoch   106: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.651 AVG Validation Loss:0.664 AVG Training Acc 62.09 % AVG Validation Acc 62.09 %\n",
      "Epoch:120/200 AVG Training Loss:0.651 AVG Validation Loss:0.664 AVG Training Acc 62.00 % AVG Validation Acc 62.09 %\n",
      "Epoch:130/200 AVG Training Loss:0.652 AVG Validation Loss:0.664 AVG Training Acc 61.97 % AVG Validation Acc 62.09 %\n",
      "Epoch   137: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.653 AVG Validation Loss:0.664 AVG Training Acc 61.92 % AVG Validation Acc 62.09 %\n",
      "Epoch:150/200 AVG Training Loss:0.651 AVG Validation Loss:0.664 AVG Training Acc 62.01 % AVG Validation Acc 62.09 %\n",
      "Epoch:160/200 AVG Training Loss:0.652 AVG Validation Loss:0.664 AVG Training Acc 62.14 % AVG Validation Acc 62.09 %\n",
      "Epoch   168: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.652 AVG Validation Loss:0.664 AVG Training Acc 62.15 % AVG Validation Acc 62.09 %\n",
      "Epoch:180/200 AVG Training Loss:0.651 AVG Validation Loss:0.664 AVG Training Acc 62.10 % AVG Validation Acc 62.09 %\n",
      "Epoch:190/200 AVG Training Loss:0.651 AVG Validation Loss:0.664 AVG Training Acc 62.03 % AVG Validation Acc 62.09 %\n",
      "Epoch:200/200 AVG Training Loss:0.652 AVG Validation Loss:0.664 AVG Training Acc 62.18 % AVG Validation Acc 62.09 %\n",
      "Split 209\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f35d49fdc6466c85e5a9e81b4a7517",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.660 AVG Training Acc 61.93 % AVG Validation Acc 61.91 %\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.656 AVG Validation Loss:0.662 AVG Training Acc 61.88 % AVG Validation Acc 61.82 %\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.663 AVG Training Acc 62.05 % AVG Validation Acc 61.91 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.666 AVG Training Acc 61.76 % AVG Validation Acc 61.64 %\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.652 AVG Validation Loss:0.666 AVG Training Acc 62.09 % AVG Validation Acc 61.46 %\n",
      "Epoch:60/200 AVG Training Loss:0.652 AVG Validation Loss:0.667 AVG Training Acc 61.98 % AVG Validation Acc 61.37 %\n",
      "Epoch:70/200 AVG Training Loss:0.653 AVG Validation Loss:0.668 AVG Training Acc 62.10 % AVG Validation Acc 61.46 %\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.651 AVG Validation Loss:0.668 AVG Training Acc 62.02 % AVG Validation Acc 61.37 %\n",
      "Epoch:90/200 AVG Training Loss:0.651 AVG Validation Loss:0.668 AVG Training Acc 61.81 % AVG Validation Acc 61.19 %\n",
      "Epoch:100/200 AVG Training Loss:0.652 AVG Validation Loss:0.668 AVG Training Acc 61.86 % AVG Validation Acc 61.46 %\n",
      "Epoch   106: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.651 AVG Validation Loss:0.668 AVG Training Acc 61.98 % AVG Validation Acc 61.37 %\n",
      "Epoch:120/200 AVG Training Loss:0.652 AVG Validation Loss:0.668 AVG Training Acc 61.93 % AVG Validation Acc 61.46 %\n",
      "Epoch:130/200 AVG Training Loss:0.651 AVG Validation Loss:0.668 AVG Training Acc 62.10 % AVG Validation Acc 61.28 %\n",
      "Epoch   137: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.651 AVG Validation Loss:0.668 AVG Training Acc 62.30 % AVG Validation Acc 61.46 %\n",
      "Epoch:150/200 AVG Training Loss:0.651 AVG Validation Loss:0.668 AVG Training Acc 62.19 % AVG Validation Acc 61.28 %\n",
      "Epoch:160/200 AVG Training Loss:0.651 AVG Validation Loss:0.668 AVG Training Acc 62.18 % AVG Validation Acc 61.46 %\n",
      "Epoch   168: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.651 AVG Validation Loss:0.668 AVG Training Acc 62.11 % AVG Validation Acc 61.46 %\n",
      "Epoch:180/200 AVG Training Loss:0.650 AVG Validation Loss:0.668 AVG Training Acc 62.17 % AVG Validation Acc 61.46 %\n",
      "Epoch:190/200 AVG Training Loss:0.652 AVG Validation Loss:0.668 AVG Training Acc 61.69 % AVG Validation Acc 61.37 %\n",
      "Epoch:200/200 AVG Training Loss:0.650 AVG Validation Loss:0.668 AVG Training Acc 61.92 % AVG Validation Acc 61.37 %\n",
      "Split 210\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f1f52f70035406b9f1501e57b423c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.658 AVG Training Acc 61.84 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.659 AVG Training Acc 61.75 % AVG Validation Acc 61.91 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.660 AVG Training Acc 61.82 % AVG Validation Acc 62.00 %\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.665 AVG Training Acc 61.96 % AVG Validation Acc 62.09 %\n",
      "Epoch:50/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.11 % AVG Validation Acc 62.27 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.647 AVG Validation Loss:0.664 AVG Training Acc 62.22 % AVG Validation Acc 62.18 %\n",
      "Epoch:70/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 61.93 % AVG Validation Acc 62.00 %\n",
      "Epoch:80/200 AVG Training Loss:0.647 AVG Validation Loss:0.670 AVG Training Acc 62.09 % AVG Validation Acc 61.82 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.646 AVG Validation Loss:0.671 AVG Training Acc 62.41 % AVG Validation Acc 61.64 %\n",
      "Epoch:100/200 AVG Training Loss:0.646 AVG Validation Loss:0.672 AVG Training Acc 62.37 % AVG Validation Acc 61.73 %\n",
      "Epoch:110/200 AVG Training Loss:0.646 AVG Validation Loss:0.672 AVG Training Acc 62.25 % AVG Validation Acc 61.55 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.645 AVG Validation Loss:0.672 AVG Training Acc 62.47 % AVG Validation Acc 61.55 %\n",
      "Epoch:130/200 AVG Training Loss:0.646 AVG Validation Loss:0.672 AVG Training Acc 62.41 % AVG Validation Acc 61.55 %\n",
      "Epoch:140/200 AVG Training Loss:0.646 AVG Validation Loss:0.672 AVG Training Acc 62.26 % AVG Validation Acc 61.82 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.646 AVG Validation Loss:0.672 AVG Training Acc 62.08 % AVG Validation Acc 61.64 %\n",
      "Epoch:160/200 AVG Training Loss:0.645 AVG Validation Loss:0.672 AVG Training Acc 62.49 % AVG Validation Acc 61.64 %\n",
      "Epoch:170/200 AVG Training Loss:0.645 AVG Validation Loss:0.672 AVG Training Acc 62.27 % AVG Validation Acc 61.64 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.646 AVG Validation Loss:0.673 AVG Training Acc 62.09 % AVG Validation Acc 61.64 %\n",
      "Epoch:190/200 AVG Training Loss:0.645 AVG Validation Loss:0.672 AVG Training Acc 62.19 % AVG Validation Acc 61.73 %\n",
      "Epoch:200/200 AVG Training Loss:0.647 AVG Validation Loss:0.672 AVG Training Acc 62.10 % AVG Validation Acc 61.64 %\n",
      "Split 211\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "827ffc93f318492386f8f16078ba4a45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.663 AVG Training Acc 61.87 % AVG Validation Acc 61.95 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.656 AVG Validation Loss:0.665 AVG Training Acc 61.93 % AVG Validation Acc 61.68 %\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.665 AVG Training Acc 61.94 % AVG Validation Acc 61.68 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.668 AVG Training Acc 61.98 % AVG Validation Acc 61.68 %\n",
      "Epoch:50/200 AVG Training Loss:0.648 AVG Validation Loss:0.670 AVG Training Acc 62.09 % AVG Validation Acc 61.50 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.648 AVG Validation Loss:0.672 AVG Training Acc 61.99 % AVG Validation Acc 61.32 %\n",
      "Epoch:70/200 AVG Training Loss:0.648 AVG Validation Loss:0.673 AVG Training Acc 62.29 % AVG Validation Acc 61.23 %\n",
      "Epoch:80/200 AVG Training Loss:0.647 AVG Validation Loss:0.674 AVG Training Acc 62.12 % AVG Validation Acc 61.23 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.646 AVG Validation Loss:0.674 AVG Training Acc 62.22 % AVG Validation Acc 61.23 %\n",
      "Epoch:100/200 AVG Training Loss:0.647 AVG Validation Loss:0.674 AVG Training Acc 62.21 % AVG Validation Acc 61.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.646 AVG Validation Loss:0.675 AVG Training Acc 62.28 % AVG Validation Acc 61.14 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.646 AVG Validation Loss:0.675 AVG Training Acc 62.16 % AVG Validation Acc 61.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.647 AVG Validation Loss:0.675 AVG Training Acc 62.54 % AVG Validation Acc 61.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.646 AVG Validation Loss:0.675 AVG Training Acc 62.58 % AVG Validation Acc 61.14 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.646 AVG Validation Loss:0.675 AVG Training Acc 61.93 % AVG Validation Acc 61.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.646 AVG Validation Loss:0.675 AVG Training Acc 62.36 % AVG Validation Acc 61.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.646 AVG Validation Loss:0.675 AVG Training Acc 62.29 % AVG Validation Acc 61.14 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.645 AVG Validation Loss:0.675 AVG Training Acc 62.21 % AVG Validation Acc 61.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.647 AVG Validation Loss:0.675 AVG Training Acc 62.17 % AVG Validation Acc 61.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.646 AVG Validation Loss:0.675 AVG Training Acc 62.04 % AVG Validation Acc 61.14 %\n",
      "Split 212\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c58d58391e54c01b9c8f8fcdf6fe000",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.659 AVG Training Acc 61.84 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.659 AVG Training Acc 61.88 % AVG Validation Acc 61.86 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.660 AVG Training Acc 62.03 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.654 AVG Validation Loss:0.662 AVG Training Acc 62.07 % AVG Validation Acc 61.77 %\n",
      "Epoch:50/200 AVG Training Loss:0.651 AVG Validation Loss:0.663 AVG Training Acc 62.07 % AVG Validation Acc 61.86 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 62.34 % AVG Validation Acc 61.68 %\n",
      "Epoch:70/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 62.25 % AVG Validation Acc 61.77 %\n",
      "Epoch:80/200 AVG Training Loss:0.646 AVG Validation Loss:0.667 AVG Training Acc 62.35 % AVG Validation Acc 61.68 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.646 AVG Validation Loss:0.668 AVG Training Acc 62.35 % AVG Validation Acc 61.77 %\n",
      "Epoch:100/200 AVG Training Loss:0.645 AVG Validation Loss:0.668 AVG Training Acc 62.42 % AVG Validation Acc 61.77 %\n",
      "Epoch:110/200 AVG Training Loss:0.645 AVG Validation Loss:0.668 AVG Training Acc 62.36 % AVG Validation Acc 61.68 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.644 AVG Validation Loss:0.669 AVG Training Acc 62.51 % AVG Validation Acc 61.68 %\n",
      "Epoch:130/200 AVG Training Loss:0.646 AVG Validation Loss:0.668 AVG Training Acc 62.38 % AVG Validation Acc 61.68 %\n",
      "Epoch:140/200 AVG Training Loss:0.644 AVG Validation Loss:0.668 AVG Training Acc 62.44 % AVG Validation Acc 61.77 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.645 AVG Validation Loss:0.668 AVG Training Acc 62.39 % AVG Validation Acc 61.68 %\n",
      "Epoch:160/200 AVG Training Loss:0.645 AVG Validation Loss:0.668 AVG Training Acc 62.25 % AVG Validation Acc 61.77 %\n",
      "Epoch:170/200 AVG Training Loss:0.646 AVG Validation Loss:0.668 AVG Training Acc 62.37 % AVG Validation Acc 61.68 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.645 AVG Validation Loss:0.668 AVG Training Acc 62.36 % AVG Validation Acc 61.68 %\n",
      "Epoch:190/200 AVG Training Loss:0.645 AVG Validation Loss:0.668 AVG Training Acc 62.34 % AVG Validation Acc 61.77 %\n",
      "Epoch:200/200 AVG Training Loss:0.645 AVG Validation Loss:0.668 AVG Training Acc 62.53 % AVG Validation Acc 61.68 %\n",
      "Split 213\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34d3663975f44493aa310cf807f65cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.656 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.657 AVG Training Acc 61.94 % AVG Validation Acc 61.95 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.660 AVG Training Acc 62.05 % AVG Validation Acc 61.59 %\n",
      "Epoch:40/200 AVG Training Loss:0.647 AVG Validation Loss:0.666 AVG Training Acc 62.33 % AVG Validation Acc 61.50 %\n",
      "Epoch:50/200 AVG Training Loss:0.643 AVG Validation Loss:0.674 AVG Training Acc 62.23 % AVG Validation Acc 61.59 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.639 AVG Validation Loss:0.685 AVG Training Acc 62.62 % AVG Validation Acc 62.04 %\n",
      "Epoch:70/200 AVG Training Loss:0.637 AVG Validation Loss:0.682 AVG Training Acc 62.55 % AVG Validation Acc 61.86 %\n",
      "Epoch:80/200 AVG Training Loss:0.635 AVG Validation Loss:0.682 AVG Training Acc 62.63 % AVG Validation Acc 62.13 %\n",
      "Epoch:90/200 AVG Training Loss:0.635 AVG Validation Loss:0.684 AVG Training Acc 62.52 % AVG Validation Acc 62.49 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.636 AVG Validation Loss:0.684 AVG Training Acc 62.51 % AVG Validation Acc 62.13 %\n",
      "Epoch:110/200 AVG Training Loss:0.635 AVG Validation Loss:0.684 AVG Training Acc 62.51 % AVG Validation Acc 62.58 %\n",
      "Epoch:120/200 AVG Training Loss:0.634 AVG Validation Loss:0.684 AVG Training Acc 62.58 % AVG Validation Acc 61.95 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.635 AVG Validation Loss:0.684 AVG Training Acc 62.57 % AVG Validation Acc 62.22 %\n",
      "Epoch:140/200 AVG Training Loss:0.634 AVG Validation Loss:0.685 AVG Training Acc 62.54 % AVG Validation Acc 61.95 %\n",
      "Epoch:150/200 AVG Training Loss:0.635 AVG Validation Loss:0.685 AVG Training Acc 62.57 % AVG Validation Acc 61.95 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.635 AVG Validation Loss:0.684 AVG Training Acc 62.81 % AVG Validation Acc 62.22 %\n",
      "Epoch:170/200 AVG Training Loss:0.634 AVG Validation Loss:0.685 AVG Training Acc 62.62 % AVG Validation Acc 62.31 %\n",
      "Epoch:180/200 AVG Training Loss:0.634 AVG Validation Loss:0.685 AVG Training Acc 62.81 % AVG Validation Acc 62.22 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.635 AVG Validation Loss:0.685 AVG Training Acc 62.91 % AVG Validation Acc 62.13 %\n",
      "Epoch:200/200 AVG Training Loss:0.634 AVG Validation Loss:0.684 AVG Training Acc 62.64 % AVG Validation Acc 62.40 %\n",
      "Split 214\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ace8ac25b9044518c167f97a698bc47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.667 AVG Training Acc 61.95 % AVG Validation Acc 61.86 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.656 AVG Validation Loss:0.663 AVG Training Acc 61.87 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.663 AVG Training Acc 61.87 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.664 AVG Training Acc 62.01 % AVG Validation Acc 61.95 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.649 AVG Validation Loss:0.667 AVG Training Acc 62.09 % AVG Validation Acc 61.68 %\n",
      "Epoch:60/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 61.93 % AVG Validation Acc 61.68 %\n",
      "Epoch:70/200 AVG Training Loss:0.648 AVG Validation Loss:0.668 AVG Training Acc 61.93 % AVG Validation Acc 61.68 %\n",
      "Epoch:80/200 AVG Training Loss:0.647 AVG Validation Loss:0.669 AVG Training Acc 61.78 % AVG Validation Acc 61.68 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.647 AVG Validation Loss:0.670 AVG Training Acc 62.01 % AVG Validation Acc 61.68 %\n",
      "Epoch:100/200 AVG Training Loss:0.647 AVG Validation Loss:0.670 AVG Training Acc 62.12 % AVG Validation Acc 61.68 %\n",
      "Epoch:110/200 AVG Training Loss:0.647 AVG Validation Loss:0.670 AVG Training Acc 61.95 % AVG Validation Acc 61.68 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.646 AVG Validation Loss:0.670 AVG Training Acc 62.14 % AVG Validation Acc 61.68 %\n",
      "Epoch:130/200 AVG Training Loss:0.647 AVG Validation Loss:0.670 AVG Training Acc 61.80 % AVG Validation Acc 61.68 %\n",
      "Epoch:140/200 AVG Training Loss:0.648 AVG Validation Loss:0.669 AVG Training Acc 61.85 % AVG Validation Acc 61.68 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.647 AVG Validation Loss:0.670 AVG Training Acc 62.06 % AVG Validation Acc 61.68 %\n",
      "Epoch:160/200 AVG Training Loss:0.647 AVG Validation Loss:0.670 AVG Training Acc 62.05 % AVG Validation Acc 61.68 %\n",
      "Epoch:170/200 AVG Training Loss:0.647 AVG Validation Loss:0.669 AVG Training Acc 62.04 % AVG Validation Acc 61.68 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.647 AVG Validation Loss:0.669 AVG Training Acc 61.97 % AVG Validation Acc 61.77 %\n",
      "Epoch:190/200 AVG Training Loss:0.647 AVG Validation Loss:0.670 AVG Training Acc 61.87 % AVG Validation Acc 61.68 %\n",
      "Epoch:200/200 AVG Training Loss:0.647 AVG Validation Loss:0.669 AVG Training Acc 62.00 % AVG Validation Acc 61.68 %\n",
      "Split 215\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ecef882206a4dbab04bb4f70668cac7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.657 AVG Training Acc 61.80 % AVG Validation Acc 61.86 %\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.658 AVG Training Acc 61.92 % AVG Validation Acc 61.77 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.657 AVG Training Acc 61.89 % AVG Validation Acc 61.77 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.660 AVG Training Acc 61.93 % AVG Validation Acc 61.77 %\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.649 AVG Validation Loss:0.662 AVG Training Acc 62.02 % AVG Validation Acc 61.86 %\n",
      "Epoch:60/200 AVG Training Loss:0.649 AVG Validation Loss:0.662 AVG Training Acc 62.03 % AVG Validation Acc 62.13 %\n",
      "Epoch:70/200 AVG Training Loss:0.649 AVG Validation Loss:0.662 AVG Training Acc 62.06 % AVG Validation Acc 62.13 %\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.648 AVG Validation Loss:0.663 AVG Training Acc 62.06 % AVG Validation Acc 62.04 %\n",
      "Epoch:90/200 AVG Training Loss:0.649 AVG Validation Loss:0.663 AVG Training Acc 62.06 % AVG Validation Acc 62.04 %\n",
      "Epoch:100/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 62.05 % AVG Validation Acc 62.04 %\n",
      "Epoch   106: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 62.20 % AVG Validation Acc 62.04 %\n",
      "Epoch:120/200 AVG Training Loss:0.648 AVG Validation Loss:0.663 AVG Training Acc 61.94 % AVG Validation Acc 62.04 %\n",
      "Epoch:130/200 AVG Training Loss:0.647 AVG Validation Loss:0.662 AVG Training Acc 62.10 % AVG Validation Acc 62.04 %\n",
      "Epoch   137: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.646 AVG Validation Loss:0.662 AVG Training Acc 62.35 % AVG Validation Acc 62.04 %\n",
      "Epoch:150/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 62.28 % AVG Validation Acc 62.04 %\n",
      "Epoch:160/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 62.13 % AVG Validation Acc 62.04 %\n",
      "Epoch   168: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.648 AVG Validation Loss:0.663 AVG Training Acc 62.17 % AVG Validation Acc 62.04 %\n",
      "Epoch:180/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 62.28 % AVG Validation Acc 62.04 %\n",
      "Epoch:190/200 AVG Training Loss:0.648 AVG Validation Loss:0.662 AVG Training Acc 62.08 % AVG Validation Acc 62.04 %\n",
      "Epoch:200/200 AVG Training Loss:0.648 AVG Validation Loss:0.663 AVG Training Acc 62.11 % AVG Validation Acc 61.95 %\n",
      "Split 216\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53e6cb02e8fd49b487bcc4d59cfdbd28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.659 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.660 AVG Training Acc 61.83 % AVG Validation Acc 62.00 %\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.659 AVG Training Acc 61.92 % AVG Validation Acc 62.00 %\n",
      "Epoch:40/200 AVG Training Loss:0.654 AVG Validation Loss:0.660 AVG Training Acc 61.83 % AVG Validation Acc 61.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.652 AVG Validation Loss:0.658 AVG Training Acc 62.13 % AVG Validation Acc 61.37 %\n",
      "Epoch:60/200 AVG Training Loss:0.648 AVG Validation Loss:0.662 AVG Training Acc 62.73 % AVG Validation Acc 62.18 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:70/200 AVG Training Loss:0.639 AVG Validation Loss:0.659 AVG Training Acc 62.52 % AVG Validation Acc 62.00 %\n",
      "Epoch:80/200 AVG Training Loss:0.635 AVG Validation Loss:0.665 AVG Training Acc 62.85 % AVG Validation Acc 62.00 %\n",
      "Epoch:90/200 AVG Training Loss:0.631 AVG Validation Loss:0.662 AVG Training Acc 62.94 % AVG Validation Acc 61.46 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.628 AVG Validation Loss:0.664 AVG Training Acc 63.13 % AVG Validation Acc 62.27 %\n",
      "Epoch:110/200 AVG Training Loss:0.628 AVG Validation Loss:0.672 AVG Training Acc 63.34 % AVG Validation Acc 62.09 %\n",
      "Epoch:120/200 AVG Training Loss:0.628 AVG Validation Loss:0.668 AVG Training Acc 62.96 % AVG Validation Acc 62.18 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.627 AVG Validation Loss:0.664 AVG Training Acc 63.39 % AVG Validation Acc 62.00 %\n",
      "Epoch:140/200 AVG Training Loss:0.628 AVG Validation Loss:0.663 AVG Training Acc 63.23 % AVG Validation Acc 61.73 %\n",
      "Epoch:150/200 AVG Training Loss:0.628 AVG Validation Loss:0.665 AVG Training Acc 63.33 % AVG Validation Acc 61.64 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.628 AVG Validation Loss:0.667 AVG Training Acc 63.44 % AVG Validation Acc 61.64 %\n",
      "Epoch:170/200 AVG Training Loss:0.624 AVG Validation Loss:0.671 AVG Training Acc 63.73 % AVG Validation Acc 61.91 %\n",
      "Epoch:180/200 AVG Training Loss:0.626 AVG Validation Loss:0.664 AVG Training Acc 63.72 % AVG Validation Acc 61.91 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.626 AVG Validation Loss:0.670 AVG Training Acc 63.72 % AVG Validation Acc 61.82 %\n",
      "Epoch:200/200 AVG Training Loss:0.626 AVG Validation Loss:0.672 AVG Training Acc 63.48 % AVG Validation Acc 61.46 %\n",
      "Split 217\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a8116df6f240d69301b8c281479cde",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.660 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 61.96 % AVG Validation Acc 61.82 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.652 AVG Validation Loss:0.666 AVG Training Acc 62.04 % AVG Validation Acc 61.73 %\n",
      "Epoch:40/200 AVG Training Loss:0.645 AVG Validation Loss:0.672 AVG Training Acc 62.27 % AVG Validation Acc 61.46 %\n",
      "Epoch:50/200 AVG Training Loss:0.642 AVG Validation Loss:0.680 AVG Training Acc 62.35 % AVG Validation Acc 61.01 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.638 AVG Validation Loss:0.686 AVG Training Acc 62.57 % AVG Validation Acc 60.83 %\n",
      "Epoch:70/200 AVG Training Loss:0.636 AVG Validation Loss:0.687 AVG Training Acc 62.21 % AVG Validation Acc 60.56 %\n",
      "Epoch:80/200 AVG Training Loss:0.636 AVG Validation Loss:0.688 AVG Training Acc 62.37 % AVG Validation Acc 60.38 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.635 AVG Validation Loss:0.692 AVG Training Acc 62.63 % AVG Validation Acc 60.47 %\n",
      "Epoch:100/200 AVG Training Loss:0.634 AVG Validation Loss:0.693 AVG Training Acc 62.60 % AVG Validation Acc 60.47 %\n",
      "Epoch:110/200 AVG Training Loss:0.636 AVG Validation Loss:0.693 AVG Training Acc 62.48 % AVG Validation Acc 60.20 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.635 AVG Validation Loss:0.693 AVG Training Acc 62.46 % AVG Validation Acc 60.20 %\n",
      "Epoch:130/200 AVG Training Loss:0.635 AVG Validation Loss:0.693 AVG Training Acc 62.62 % AVG Validation Acc 60.11 %\n",
      "Epoch:140/200 AVG Training Loss:0.635 AVG Validation Loss:0.694 AVG Training Acc 62.73 % AVG Validation Acc 60.02 %\n",
      "Epoch:150/200 AVG Training Loss:0.635 AVG Validation Loss:0.693 AVG Training Acc 62.66 % AVG Validation Acc 60.38 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.634 AVG Validation Loss:0.695 AVG Training Acc 62.57 % AVG Validation Acc 60.38 %\n",
      "Epoch:170/200 AVG Training Loss:0.635 AVG Validation Loss:0.694 AVG Training Acc 62.57 % AVG Validation Acc 60.29 %\n",
      "Epoch:180/200 AVG Training Loss:0.635 AVG Validation Loss:0.693 AVG Training Acc 62.51 % AVG Validation Acc 60.56 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.634 AVG Validation Loss:0.692 AVG Training Acc 62.53 % AVG Validation Acc 60.47 %\n",
      "Epoch:200/200 AVG Training Loss:0.635 AVG Validation Loss:0.695 AVG Training Acc 62.67 % AVG Validation Acc 60.47 %\n",
      "Split 218\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f13d2f38203642619d58dfe48e21c5c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.661 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.663 AVG Training Acc 61.87 % AVG Validation Acc 61.91 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.661 AVG Training Acc 61.85 % AVG Validation Acc 61.91 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.661 AVG Training Acc 62.03 % AVG Validation Acc 61.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.652 AVG Validation Loss:0.661 AVG Training Acc 61.80 % AVG Validation Acc 61.91 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.651 AVG Validation Loss:0.662 AVG Training Acc 61.75 % AVG Validation Acc 61.82 %\n",
      "Epoch:70/200 AVG Training Loss:0.649 AVG Validation Loss:0.663 AVG Training Acc 62.01 % AVG Validation Acc 61.46 %\n",
      "Epoch:80/200 AVG Training Loss:0.651 AVG Validation Loss:0.662 AVG Training Acc 61.84 % AVG Validation Acc 61.91 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.648 AVG Validation Loss:0.663 AVG Training Acc 62.12 % AVG Validation Acc 61.82 %\n",
      "Epoch:100/200 AVG Training Loss:0.650 AVG Validation Loss:0.664 AVG Training Acc 61.71 % AVG Validation Acc 61.64 %\n",
      "Epoch:110/200 AVG Training Loss:0.648 AVG Validation Loss:0.663 AVG Training Acc 61.98 % AVG Validation Acc 61.91 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 61.87 % AVG Validation Acc 61.73 %\n",
      "Epoch:130/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.10 % AVG Validation Acc 61.73 %\n",
      "Epoch:140/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.05 % AVG Validation Acc 61.82 %\n",
      "Epoch:150/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 61.97 % AVG Validation Acc 61.91 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.647 AVG Validation Loss:0.664 AVG Training Acc 62.06 % AVG Validation Acc 61.82 %\n",
      "Epoch:170/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 61.74 % AVG Validation Acc 61.91 %\n",
      "Epoch:180/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.14 % AVG Validation Acc 62.00 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.648 AVG Validation Loss:0.663 AVG Training Acc 61.94 % AVG Validation Acc 61.82 %\n",
      "Epoch:200/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 61.98 % AVG Validation Acc 62.00 %\n",
      "Split 219\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a3af56a09fe48b68c26b20e638031a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.660 AVG Training Acc 61.87 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 61.84 % AVG Validation Acc 61.91 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.659 AVG Training Acc 61.78 % AVG Validation Acc 62.09 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.660 AVG Training Acc 61.93 % AVG Validation Acc 62.00 %\n",
      "Epoch:50/200 AVG Training Loss:0.651 AVG Validation Loss:0.666 AVG Training Acc 62.15 % AVG Validation Acc 61.91 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.650 AVG Validation Loss:0.667 AVG Training Acc 62.24 % AVG Validation Acc 61.73 %\n",
      "Epoch:70/200 AVG Training Loss:0.650 AVG Validation Loss:0.668 AVG Training Acc 62.09 % AVG Validation Acc 61.37 %\n",
      "Epoch:80/200 AVG Training Loss:0.648 AVG Validation Loss:0.668 AVG Training Acc 62.36 % AVG Validation Acc 61.46 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 62.25 % AVG Validation Acc 61.46 %\n",
      "Epoch:100/200 AVG Training Loss:0.649 AVG Validation Loss:0.669 AVG Training Acc 62.17 % AVG Validation Acc 61.55 %\n",
      "Epoch:110/200 AVG Training Loss:0.648 AVG Validation Loss:0.669 AVG Training Acc 62.06 % AVG Validation Acc 61.55 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.647 AVG Validation Loss:0.668 AVG Training Acc 62.40 % AVG Validation Acc 61.55 %\n",
      "Epoch:130/200 AVG Training Loss:0.648 AVG Validation Loss:0.669 AVG Training Acc 62.16 % AVG Validation Acc 61.55 %\n",
      "Epoch:140/200 AVG Training Loss:0.648 AVG Validation Loss:0.668 AVG Training Acc 62.11 % AVG Validation Acc 61.55 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.648 AVG Validation Loss:0.669 AVG Training Acc 62.12 % AVG Validation Acc 61.55 %\n",
      "Epoch:160/200 AVG Training Loss:0.648 AVG Validation Loss:0.669 AVG Training Acc 62.08 % AVG Validation Acc 61.55 %\n",
      "Epoch:170/200 AVG Training Loss:0.649 AVG Validation Loss:0.669 AVG Training Acc 62.18 % AVG Validation Acc 61.55 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.647 AVG Validation Loss:0.669 AVG Training Acc 62.46 % AVG Validation Acc 61.55 %\n",
      "Epoch:190/200 AVG Training Loss:0.648 AVG Validation Loss:0.668 AVG Training Acc 62.01 % AVG Validation Acc 61.55 %\n",
      "Epoch:200/200 AVG Training Loss:0.648 AVG Validation Loss:0.668 AVG Training Acc 62.11 % AVG Validation Acc 61.55 %\n",
      "Split 220\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42862a0a34404f4fad4080288f8c87ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.661 AVG Training Acc 61.82 % AVG Validation Acc 61.91 %\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.662 AVG Training Acc 61.88 % AVG Validation Acc 61.64 %\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.662 AVG Training Acc 62.01 % AVG Validation Acc 61.91 %\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.665 AVG Training Acc 61.91 % AVG Validation Acc 61.55 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.646 AVG Validation Loss:0.665 AVG Training Acc 62.31 % AVG Validation Acc 61.55 %\n",
      "Epoch:60/200 AVG Training Loss:0.646 AVG Validation Loss:0.665 AVG Training Acc 62.04 % AVG Validation Acc 61.55 %\n",
      "Epoch:70/200 AVG Training Loss:0.645 AVG Validation Loss:0.665 AVG Training Acc 62.08 % AVG Validation Acc 61.46 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.644 AVG Validation Loss:0.666 AVG Training Acc 62.22 % AVG Validation Acc 61.37 %\n",
      "Epoch:90/200 AVG Training Loss:0.643 AVG Validation Loss:0.666 AVG Training Acc 62.52 % AVG Validation Acc 61.37 %\n",
      "Epoch:100/200 AVG Training Loss:0.644 AVG Validation Loss:0.667 AVG Training Acc 62.41 % AVG Validation Acc 61.37 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.644 AVG Validation Loss:0.666 AVG Training Acc 62.34 % AVG Validation Acc 61.28 %\n",
      "Epoch:120/200 AVG Training Loss:0.644 AVG Validation Loss:0.666 AVG Training Acc 62.39 % AVG Validation Acc 61.28 %\n",
      "Epoch:130/200 AVG Training Loss:0.644 AVG Validation Loss:0.666 AVG Training Acc 62.40 % AVG Validation Acc 61.28 %\n",
      "Epoch:140/200 AVG Training Loss:0.643 AVG Validation Loss:0.666 AVG Training Acc 62.37 % AVG Validation Acc 61.37 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.644 AVG Validation Loss:0.666 AVG Training Acc 62.11 % AVG Validation Acc 61.28 %\n",
      "Epoch:160/200 AVG Training Loss:0.644 AVG Validation Loss:0.667 AVG Training Acc 62.52 % AVG Validation Acc 61.28 %\n",
      "Epoch:170/200 AVG Training Loss:0.643 AVG Validation Loss:0.667 AVG Training Acc 62.24 % AVG Validation Acc 61.37 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.643 AVG Validation Loss:0.667 AVG Training Acc 62.05 % AVG Validation Acc 61.19 %\n",
      "Epoch:190/200 AVG Training Loss:0.643 AVG Validation Loss:0.666 AVG Training Acc 62.53 % AVG Validation Acc 61.37 %\n",
      "Epoch:200/200 AVG Training Loss:0.643 AVG Validation Loss:0.666 AVG Training Acc 62.33 % AVG Validation Acc 61.37 %\n",
      "Split 221\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e255e7ac51b844ef8237803e04eac44f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.659 AVG Training Acc 61.87 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.660 AVG Training Acc 61.67 % AVG Validation Acc 61.95 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.659 AVG Training Acc 61.97 % AVG Validation Acc 61.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.656 AVG Validation Loss:0.657 AVG Training Acc 62.02 % AVG Validation Acc 62.04 %\n",
      "Epoch:50/200 AVG Training Loss:0.653 AVG Validation Loss:0.657 AVG Training Acc 62.01 % AVG Validation Acc 62.04 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.651 AVG Validation Loss:0.658 AVG Training Acc 62.08 % AVG Validation Acc 62.04 %\n",
      "Epoch:70/200 AVG Training Loss:0.650 AVG Validation Loss:0.660 AVG Training Acc 62.04 % AVG Validation Acc 61.95 %\n",
      "Epoch:80/200 AVG Training Loss:0.649 AVG Validation Loss:0.662 AVG Training Acc 62.13 % AVG Validation Acc 61.95 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.648 AVG Validation Loss:0.663 AVG Training Acc 62.03 % AVG Validation Acc 61.95 %\n",
      "Epoch:100/200 AVG Training Loss:0.649 AVG Validation Loss:0.663 AVG Training Acc 62.04 % AVG Validation Acc 61.95 %\n",
      "Epoch:110/200 AVG Training Loss:0.649 AVG Validation Loss:0.663 AVG Training Acc 62.13 % AVG Validation Acc 61.95 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.05 % AVG Validation Acc 61.95 %\n",
      "Epoch:130/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.08 % AVG Validation Acc 61.95 %\n",
      "Epoch:140/200 AVG Training Loss:0.648 AVG Validation Loss:0.663 AVG Training Acc 62.01 % AVG Validation Acc 61.95 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.649 AVG Validation Loss:0.663 AVG Training Acc 62.12 % AVG Validation Acc 61.95 %\n",
      "Epoch:160/200 AVG Training Loss:0.649 AVG Validation Loss:0.663 AVG Training Acc 62.04 % AVG Validation Acc 61.95 %\n",
      "Epoch:170/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.10 % AVG Validation Acc 61.95 %\n",
      "Epoch:180/200 AVG Training Loss:0.648 AVG Validation Loss:0.663 AVG Training Acc 62.05 % AVG Validation Acc 61.95 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.04 % AVG Validation Acc 61.95 %\n",
      "Epoch:200/200 AVG Training Loss:0.648 AVG Validation Loss:0.663 AVG Training Acc 62.09 % AVG Validation Acc 61.95 %\n",
      "Split 222\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "927a510b85c2484c82ab6dd718ed2e0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.658 AVG Training Acc 61.85 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.657 AVG Training Acc 62.09 % AVG Validation Acc 61.59 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.659 AVG Training Acc 61.89 % AVG Validation Acc 61.77 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.654 AVG Validation Loss:0.665 AVG Training Acc 62.03 % AVG Validation Acc 61.68 %\n",
      "Epoch:50/200 AVG Training Loss:0.651 AVG Validation Loss:0.670 AVG Training Acc 62.08 % AVG Validation Acc 61.68 %\n",
      "Epoch:60/200 AVG Training Loss:0.648 AVG Validation Loss:0.675 AVG Training Acc 62.11 % AVG Validation Acc 61.68 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.644 AVG Validation Loss:0.679 AVG Training Acc 62.23 % AVG Validation Acc 61.68 %\n",
      "Epoch:80/200 AVG Training Loss:0.644 AVG Validation Loss:0.681 AVG Training Acc 62.23 % AVG Validation Acc 61.68 %\n",
      "Epoch:90/200 AVG Training Loss:0.643 AVG Validation Loss:0.681 AVG Training Acc 62.37 % AVG Validation Acc 61.68 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.643 AVG Validation Loss:0.683 AVG Training Acc 62.18 % AVG Validation Acc 61.68 %\n",
      "Epoch:110/200 AVG Training Loss:0.643 AVG Validation Loss:0.676 AVG Training Acc 62.20 % AVG Validation Acc 61.68 %\n",
      "Epoch:120/200 AVG Training Loss:0.644 AVG Validation Loss:0.682 AVG Training Acc 62.28 % AVG Validation Acc 61.68 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.644 AVG Validation Loss:0.682 AVG Training Acc 62.33 % AVG Validation Acc 61.68 %\n",
      "Epoch:140/200 AVG Training Loss:0.643 AVG Validation Loss:0.683 AVG Training Acc 62.25 % AVG Validation Acc 61.68 %\n",
      "Epoch:150/200 AVG Training Loss:0.644 AVG Validation Loss:0.676 AVG Training Acc 62.22 % AVG Validation Acc 61.77 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.643 AVG Validation Loss:0.683 AVG Training Acc 62.12 % AVG Validation Acc 61.68 %\n",
      "Epoch:170/200 AVG Training Loss:0.644 AVG Validation Loss:0.676 AVG Training Acc 62.23 % AVG Validation Acc 61.77 %\n",
      "Epoch:180/200 AVG Training Loss:0.643 AVG Validation Loss:0.681 AVG Training Acc 62.15 % AVG Validation Acc 61.68 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.643 AVG Validation Loss:0.682 AVG Training Acc 62.31 % AVG Validation Acc 61.68 %\n",
      "Epoch:200/200 AVG Training Loss:0.643 AVG Validation Loss:0.676 AVG Training Acc 62.29 % AVG Validation Acc 61.77 %\n",
      "Split 223\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6c390cb8cdd49b88d3eb9e6cdce719e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.663 AVG Training Acc 61.88 % AVG Validation Acc 61.95 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:0.664 AVG Training Acc 61.94 % AVG Validation Acc 62.04 %\n",
      "Epoch:30/200 AVG Training Loss:0.652 AVG Validation Loss:0.666 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.650 AVG Validation Loss:0.667 AVG Training Acc 61.84 % AVG Validation Acc 61.77 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.646 AVG Validation Loss:0.670 AVG Training Acc 62.06 % AVG Validation Acc 61.77 %\n",
      "Epoch:60/200 AVG Training Loss:0.645 AVG Validation Loss:0.672 AVG Training Acc 61.93 % AVG Validation Acc 61.59 %\n",
      "Epoch:70/200 AVG Training Loss:0.644 AVG Validation Loss:0.672 AVG Training Acc 62.42 % AVG Validation Acc 61.68 %\n",
      "Epoch:80/200 AVG Training Loss:0.644 AVG Validation Loss:0.674 AVG Training Acc 62.37 % AVG Validation Acc 61.86 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.644 AVG Validation Loss:0.674 AVG Training Acc 61.95 % AVG Validation Acc 61.77 %\n",
      "Epoch:100/200 AVG Training Loss:0.643 AVG Validation Loss:0.674 AVG Training Acc 62.05 % AVG Validation Acc 61.77 %\n",
      "Epoch:110/200 AVG Training Loss:0.643 AVG Validation Loss:0.674 AVG Training Acc 62.38 % AVG Validation Acc 61.77 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.643 AVG Validation Loss:0.674 AVG Training Acc 62.12 % AVG Validation Acc 61.77 %\n",
      "Epoch:130/200 AVG Training Loss:0.643 AVG Validation Loss:0.674 AVG Training Acc 62.20 % AVG Validation Acc 61.86 %\n",
      "Epoch:140/200 AVG Training Loss:0.644 AVG Validation Loss:0.674 AVG Training Acc 62.44 % AVG Validation Acc 61.95 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.642 AVG Validation Loss:0.673 AVG Training Acc 62.34 % AVG Validation Acc 61.77 %\n",
      "Epoch:160/200 AVG Training Loss:0.643 AVG Validation Loss:0.674 AVG Training Acc 62.20 % AVG Validation Acc 61.77 %\n",
      "Epoch:170/200 AVG Training Loss:0.643 AVG Validation Loss:0.674 AVG Training Acc 62.25 % AVG Validation Acc 61.95 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.644 AVG Validation Loss:0.674 AVG Training Acc 61.93 % AVG Validation Acc 61.77 %\n",
      "Epoch:190/200 AVG Training Loss:0.644 AVG Validation Loss:0.674 AVG Training Acc 62.38 % AVG Validation Acc 61.86 %\n",
      "Epoch:200/200 AVG Training Loss:0.643 AVG Validation Loss:0.674 AVG Training Acc 62.16 % AVG Validation Acc 61.95 %\n",
      "Split 224\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a02539675f7148f0bb2081f932868aee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 61.87 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.661 AVG Training Acc 61.87 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.662 AVG Training Acc 61.76 % AVG Validation Acc 61.95 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.665 AVG Training Acc 62.00 % AVG Validation Acc 61.77 %\n",
      "Epoch:50/200 AVG Training Loss:0.644 AVG Validation Loss:0.668 AVG Training Acc 62.20 % AVG Validation Acc 61.68 %\n",
      "Epoch:60/200 AVG Training Loss:0.637 AVG Validation Loss:0.673 AVG Training Acc 62.45 % AVG Validation Acc 61.77 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.635 AVG Validation Loss:0.686 AVG Training Acc 62.45 % AVG Validation Acc 61.77 %\n",
      "Epoch:80/200 AVG Training Loss:0.632 AVG Validation Loss:0.684 AVG Training Acc 62.67 % AVG Validation Acc 61.50 %\n",
      "Epoch:90/200 AVG Training Loss:0.634 AVG Validation Loss:0.683 AVG Training Acc 62.49 % AVG Validation Acc 61.50 %\n",
      "Epoch:100/200 AVG Training Loss:0.631 AVG Validation Loss:0.684 AVG Training Acc 62.35 % AVG Validation Acc 61.50 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.631 AVG Validation Loss:0.684 AVG Training Acc 62.58 % AVG Validation Acc 61.59 %\n",
      "Epoch:120/200 AVG Training Loss:0.631 AVG Validation Loss:0.682 AVG Training Acc 62.45 % AVG Validation Acc 61.86 %\n",
      "Epoch:130/200 AVG Training Loss:0.631 AVG Validation Loss:0.685 AVG Training Acc 62.37 % AVG Validation Acc 61.86 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.630 AVG Validation Loss:0.685 AVG Training Acc 62.30 % AVG Validation Acc 61.86 %\n",
      "Epoch:150/200 AVG Training Loss:0.630 AVG Validation Loss:0.681 AVG Training Acc 62.66 % AVG Validation Acc 61.77 %\n",
      "Epoch:160/200 AVG Training Loss:0.631 AVG Validation Loss:0.684 AVG Training Acc 62.53 % AVG Validation Acc 61.77 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.631 AVG Validation Loss:0.686 AVG Training Acc 62.66 % AVG Validation Acc 61.77 %\n",
      "Epoch:180/200 AVG Training Loss:0.631 AVG Validation Loss:0.685 AVG Training Acc 62.58 % AVG Validation Acc 61.50 %\n",
      "Epoch:190/200 AVG Training Loss:0.631 AVG Validation Loss:0.686 AVG Training Acc 62.42 % AVG Validation Acc 61.68 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.631 AVG Validation Loss:0.684 AVG Training Acc 62.29 % AVG Validation Acc 61.59 %\n",
      "Split 225\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea75e5d154ab4ce89e09aca6ea50cbf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.659 AVG Training Acc 61.93 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.656 AVG Training Acc 61.84 % AVG Validation Acc 61.77 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.657 AVG Training Acc 61.74 % AVG Validation Acc 61.77 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.658 AVG Training Acc 61.86 % AVG Validation Acc 62.31 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.644 AVG Validation Loss:0.660 AVG Training Acc 62.17 % AVG Validation Acc 62.04 %\n",
      "Epoch:60/200 AVG Training Loss:0.636 AVG Validation Loss:0.664 AVG Training Acc 62.26 % AVG Validation Acc 61.50 %\n",
      "Epoch:70/200 AVG Training Loss:0.633 AVG Validation Loss:0.668 AVG Training Acc 62.55 % AVG Validation Acc 61.50 %\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.631 AVG Validation Loss:0.668 AVG Training Acc 62.93 % AVG Validation Acc 61.32 %\n",
      "Epoch:90/200 AVG Training Loss:0.630 AVG Validation Loss:0.670 AVG Training Acc 62.60 % AVG Validation Acc 61.32 %\n",
      "Epoch:100/200 AVG Training Loss:0.630 AVG Validation Loss:0.671 AVG Training Acc 62.75 % AVG Validation Acc 61.14 %\n",
      "Epoch   104: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.628 AVG Validation Loss:0.673 AVG Training Acc 62.84 % AVG Validation Acc 60.96 %\n",
      "Epoch:120/200 AVG Training Loss:0.627 AVG Validation Loss:0.673 AVG Training Acc 63.30 % AVG Validation Acc 61.23 %\n",
      "Epoch:130/200 AVG Training Loss:0.629 AVG Validation Loss:0.673 AVG Training Acc 62.62 % AVG Validation Acc 60.96 %\n",
      "Epoch   135: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.628 AVG Validation Loss:0.674 AVG Training Acc 62.87 % AVG Validation Acc 61.23 %\n",
      "Epoch:150/200 AVG Training Loss:0.627 AVG Validation Loss:0.671 AVG Training Acc 63.01 % AVG Validation Acc 61.05 %\n",
      "Epoch:160/200 AVG Training Loss:0.629 AVG Validation Loss:0.672 AVG Training Acc 62.72 % AVG Validation Acc 61.32 %\n",
      "Epoch   166: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.627 AVG Validation Loss:0.673 AVG Training Acc 62.86 % AVG Validation Acc 60.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.626 AVG Validation Loss:0.674 AVG Training Acc 62.84 % AVG Validation Acc 60.87 %\n",
      "Epoch:190/200 AVG Training Loss:0.628 AVG Validation Loss:0.670 AVG Training Acc 62.95 % AVG Validation Acc 60.96 %\n",
      "Epoch   197: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.627 AVG Validation Loss:0.673 AVG Training Acc 62.90 % AVG Validation Acc 60.96 %\n",
      "Split 226\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00c84cbc568a49878cfc173c31f19f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.659 AVG Training Acc 61.87 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.659 AVG Training Acc 61.87 % AVG Validation Acc 61.91 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.659 AVG Training Acc 61.83 % AVG Validation Acc 61.82 %\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.659 AVG Training Acc 61.87 % AVG Validation Acc 61.73 %\n",
      "Epoch:50/200 AVG Training Loss:0.651 AVG Validation Loss:0.664 AVG Training Acc 62.02 % AVG Validation Acc 61.64 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.647 AVG Validation Loss:0.671 AVG Training Acc 62.23 % AVG Validation Acc 61.73 %\n",
      "Epoch:70/200 AVG Training Loss:0.646 AVG Validation Loss:0.671 AVG Training Acc 62.31 % AVG Validation Acc 61.82 %\n",
      "Epoch:80/200 AVG Training Loss:0.645 AVG Validation Loss:0.673 AVG Training Acc 62.38 % AVG Validation Acc 61.73 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.645 AVG Validation Loss:0.674 AVG Training Acc 62.25 % AVG Validation Acc 61.82 %\n",
      "Epoch:100/200 AVG Training Loss:0.646 AVG Validation Loss:0.674 AVG Training Acc 61.96 % AVG Validation Acc 61.64 %\n",
      "Epoch:110/200 AVG Training Loss:0.646 AVG Validation Loss:0.674 AVG Training Acc 62.11 % AVG Validation Acc 61.64 %\n",
      "Epoch:120/200 AVG Training Loss:0.645 AVG Validation Loss:0.675 AVG Training Acc 62.32 % AVG Validation Acc 61.46 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.644 AVG Validation Loss:0.674 AVG Training Acc 62.23 % AVG Validation Acc 61.73 %\n",
      "Epoch:140/200 AVG Training Loss:0.645 AVG Validation Loss:0.674 AVG Training Acc 62.25 % AVG Validation Acc 61.73 %\n",
      "Epoch:150/200 AVG Training Loss:0.645 AVG Validation Loss:0.674 AVG Training Acc 62.30 % AVG Validation Acc 61.73 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.644 AVG Validation Loss:0.674 AVG Training Acc 62.43 % AVG Validation Acc 61.64 %\n",
      "Epoch:170/200 AVG Training Loss:0.645 AVG Validation Loss:0.674 AVG Training Acc 62.10 % AVG Validation Acc 61.55 %\n",
      "Epoch:180/200 AVG Training Loss:0.645 AVG Validation Loss:0.674 AVG Training Acc 62.22 % AVG Validation Acc 61.64 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.644 AVG Validation Loss:0.674 AVG Training Acc 62.22 % AVG Validation Acc 61.55 %\n",
      "Epoch:200/200 AVG Training Loss:0.645 AVG Validation Loss:0.673 AVG Training Acc 62.20 % AVG Validation Acc 61.73 %\n",
      "Split 227\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c26ea966834c9386f32b28e01df8cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.660 AVG Training Acc 61.85 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.661 AVG Training Acc 61.75 % AVG Validation Acc 61.82 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.652 AVG Validation Loss:0.667 AVG Training Acc 62.10 % AVG Validation Acc 61.82 %\n",
      "Epoch:40/200 AVG Training Loss:0.650 AVG Validation Loss:0.675 AVG Training Acc 62.02 % AVG Validation Acc 61.73 %\n",
      "Epoch:50/200 AVG Training Loss:0.645 AVG Validation Loss:0.680 AVG Training Acc 62.17 % AVG Validation Acc 61.19 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.643 AVG Validation Loss:0.685 AVG Training Acc 62.10 % AVG Validation Acc 61.19 %\n",
      "Epoch:70/200 AVG Training Loss:0.642 AVG Validation Loss:0.688 AVG Training Acc 62.31 % AVG Validation Acc 61.10 %\n",
      "Epoch:80/200 AVG Training Loss:0.640 AVG Validation Loss:0.690 AVG Training Acc 62.47 % AVG Validation Acc 61.10 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.640 AVG Validation Loss:0.689 AVG Training Acc 62.55 % AVG Validation Acc 61.19 %\n",
      "Epoch:100/200 AVG Training Loss:0.641 AVG Validation Loss:0.691 AVG Training Acc 62.35 % AVG Validation Acc 61.19 %\n",
      "Epoch:110/200 AVG Training Loss:0.641 AVG Validation Loss:0.691 AVG Training Acc 62.47 % AVG Validation Acc 61.19 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.640 AVG Validation Loss:0.691 AVG Training Acc 62.58 % AVG Validation Acc 61.19 %\n",
      "Epoch:130/200 AVG Training Loss:0.639 AVG Validation Loss:0.690 AVG Training Acc 62.54 % AVG Validation Acc 61.19 %\n",
      "Epoch:140/200 AVG Training Loss:0.640 AVG Validation Loss:0.691 AVG Training Acc 62.66 % AVG Validation Acc 61.19 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.639 AVG Validation Loss:0.691 AVG Training Acc 62.62 % AVG Validation Acc 61.19 %\n",
      "Epoch:160/200 AVG Training Loss:0.640 AVG Validation Loss:0.690 AVG Training Acc 62.45 % AVG Validation Acc 61.19 %\n",
      "Epoch:170/200 AVG Training Loss:0.639 AVG Validation Loss:0.692 AVG Training Acc 62.44 % AVG Validation Acc 61.19 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.640 AVG Validation Loss:0.691 AVG Training Acc 62.45 % AVG Validation Acc 61.19 %\n",
      "Epoch:190/200 AVG Training Loss:0.641 AVG Validation Loss:0.690 AVG Training Acc 62.32 % AVG Validation Acc 61.19 %\n",
      "Epoch:200/200 AVG Training Loss:0.639 AVG Validation Loss:0.691 AVG Training Acc 62.64 % AVG Validation Acc 61.19 %\n",
      "Split 228\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be842f060b71411da6d2accbc2cbd1a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.660 AVG Training Acc 61.81 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.657 AVG Training Acc 61.82 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.656 AVG Training Acc 61.77 % AVG Validation Acc 62.00 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.662 AVG Training Acc 62.22 % AVG Validation Acc 61.82 %\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.640 AVG Validation Loss:0.664 AVG Training Acc 62.77 % AVG Validation Acc 61.64 %\n",
      "Epoch:60/200 AVG Training Loss:0.633 AVG Validation Loss:0.673 AVG Training Acc 63.25 % AVG Validation Acc 61.10 %\n",
      "Epoch:70/200 AVG Training Loss:0.630 AVG Validation Loss:0.674 AVG Training Acc 63.26 % AVG Validation Acc 61.01 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.626 AVG Validation Loss:0.675 AVG Training Acc 63.84 % AVG Validation Acc 60.83 %\n",
      "Epoch:90/200 AVG Training Loss:0.627 AVG Validation Loss:0.677 AVG Training Acc 63.71 % AVG Validation Acc 60.65 %\n",
      "Epoch:100/200 AVG Training Loss:0.626 AVG Validation Loss:0.680 AVG Training Acc 63.84 % AVG Validation Acc 60.20 %\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.624 AVG Validation Loss:0.681 AVG Training Acc 63.75 % AVG Validation Acc 60.65 %\n",
      "Epoch:120/200 AVG Training Loss:0.626 AVG Validation Loss:0.677 AVG Training Acc 63.25 % AVG Validation Acc 60.74 %\n",
      "Epoch:130/200 AVG Training Loss:0.625 AVG Validation Loss:0.679 AVG Training Acc 63.83 % AVG Validation Acc 60.38 %\n",
      "Epoch   134: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.624 AVG Validation Loss:0.679 AVG Training Acc 64.00 % AVG Validation Acc 60.92 %\n",
      "Epoch:150/200 AVG Training Loss:0.623 AVG Validation Loss:0.679 AVG Training Acc 63.92 % AVG Validation Acc 60.65 %\n",
      "Epoch:160/200 AVG Training Loss:0.626 AVG Validation Loss:0.678 AVG Training Acc 63.89 % AVG Validation Acc 60.65 %\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.624 AVG Validation Loss:0.681 AVG Training Acc 64.14 % AVG Validation Acc 60.38 %\n",
      "Epoch:180/200 AVG Training Loss:0.622 AVG Validation Loss:0.680 AVG Training Acc 64.22 % AVG Validation Acc 60.11 %\n",
      "Epoch:190/200 AVG Training Loss:0.626 AVG Validation Loss:0.678 AVG Training Acc 63.52 % AVG Validation Acc 60.65 %\n",
      "Epoch   196: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.624 AVG Validation Loss:0.678 AVG Training Acc 64.36 % AVG Validation Acc 60.65 %\n",
      "Split 229\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e25ee399d5f14b38a93990b61a1b2ab7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.662 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.660 AVG Training Acc 61.92 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.661 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.656 AVG Validation Loss:0.660 AVG Training Acc 61.98 % AVG Validation Acc 62.09 %\n",
      "Epoch:50/200 AVG Training Loss:0.650 AVG Validation Loss:0.667 AVG Training Acc 62.09 % AVG Validation Acc 61.82 %\n",
      "Epoch:60/200 AVG Training Loss:0.647 AVG Validation Loss:0.673 AVG Training Acc 62.22 % AVG Validation Acc 61.73 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.641 AVG Validation Loss:0.681 AVG Training Acc 62.62 % AVG Validation Acc 61.73 %\n",
      "Epoch:80/200 AVG Training Loss:0.642 AVG Validation Loss:0.682 AVG Training Acc 62.43 % AVG Validation Acc 62.09 %\n",
      "Epoch:90/200 AVG Training Loss:0.640 AVG Validation Loss:0.685 AVG Training Acc 62.67 % AVG Validation Acc 61.64 %\n",
      "Epoch:100/200 AVG Training Loss:0.640 AVG Validation Loss:0.686 AVG Training Acc 62.37 % AVG Validation Acc 61.73 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.639 AVG Validation Loss:0.687 AVG Training Acc 62.70 % AVG Validation Acc 61.82 %\n",
      "Epoch:120/200 AVG Training Loss:0.639 AVG Validation Loss:0.686 AVG Training Acc 62.67 % AVG Validation Acc 61.82 %\n",
      "Epoch:130/200 AVG Training Loss:0.638 AVG Validation Loss:0.688 AVG Training Acc 62.60 % AVG Validation Acc 61.73 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.639 AVG Validation Loss:0.688 AVG Training Acc 62.61 % AVG Validation Acc 61.55 %\n",
      "Epoch:150/200 AVG Training Loss:0.639 AVG Validation Loss:0.688 AVG Training Acc 62.71 % AVG Validation Acc 61.73 %\n",
      "Epoch:160/200 AVG Training Loss:0.639 AVG Validation Loss:0.686 AVG Training Acc 62.59 % AVG Validation Acc 61.73 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.639 AVG Validation Loss:0.688 AVG Training Acc 62.75 % AVG Validation Acc 61.64 %\n",
      "Epoch:180/200 AVG Training Loss:0.638 AVG Validation Loss:0.687 AVG Training Acc 62.66 % AVG Validation Acc 61.82 %\n",
      "Epoch:190/200 AVG Training Loss:0.640 AVG Validation Loss:0.687 AVG Training Acc 62.73 % AVG Validation Acc 61.82 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.639 AVG Validation Loss:0.686 AVG Training Acc 62.65 % AVG Validation Acc 61.64 %\n",
      "Split 230\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48687927a3e641a293ab27326612f7c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.656 AVG Training Acc 61.73 % AVG Validation Acc 61.91 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.656 AVG Validation Loss:0.656 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.659 AVG Training Acc 61.96 % AVG Validation Acc 61.91 %\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.658 AVG Training Acc 62.03 % AVG Validation Acc 62.00 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.648 AVG Validation Loss:0.659 AVG Training Acc 62.17 % AVG Validation Acc 61.91 %\n",
      "Epoch:60/200 AVG Training Loss:0.646 AVG Validation Loss:0.661 AVG Training Acc 62.06 % AVG Validation Acc 61.82 %\n",
      "Epoch:70/200 AVG Training Loss:0.646 AVG Validation Loss:0.661 AVG Training Acc 62.20 % AVG Validation Acc 61.82 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.644 AVG Validation Loss:0.661 AVG Training Acc 62.14 % AVG Validation Acc 61.73 %\n",
      "Epoch:90/200 AVG Training Loss:0.645 AVG Validation Loss:0.661 AVG Training Acc 62.43 % AVG Validation Acc 61.82 %\n",
      "Epoch:100/200 AVG Training Loss:0.646 AVG Validation Loss:0.662 AVG Training Acc 62.34 % AVG Validation Acc 61.64 %\n",
      "Epoch:110/200 AVG Training Loss:0.644 AVG Validation Loss:0.661 AVG Training Acc 62.08 % AVG Validation Acc 61.73 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.645 AVG Validation Loss:0.661 AVG Training Acc 62.47 % AVG Validation Acc 61.55 %\n",
      "Epoch:130/200 AVG Training Loss:0.645 AVG Validation Loss:0.661 AVG Training Acc 62.12 % AVG Validation Acc 61.64 %\n",
      "Epoch:140/200 AVG Training Loss:0.645 AVG Validation Loss:0.662 AVG Training Acc 62.08 % AVG Validation Acc 61.55 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.646 AVG Validation Loss:0.662 AVG Training Acc 62.23 % AVG Validation Acc 61.64 %\n",
      "Epoch:160/200 AVG Training Loss:0.644 AVG Validation Loss:0.662 AVG Training Acc 62.37 % AVG Validation Acc 61.64 %\n",
      "Epoch:170/200 AVG Training Loss:0.645 AVG Validation Loss:0.661 AVG Training Acc 62.06 % AVG Validation Acc 61.73 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.644 AVG Validation Loss:0.662 AVG Training Acc 62.18 % AVG Validation Acc 61.73 %\n",
      "Epoch:190/200 AVG Training Loss:0.645 AVG Validation Loss:0.662 AVG Training Acc 62.22 % AVG Validation Acc 61.82 %\n",
      "Epoch:200/200 AVG Training Loss:0.644 AVG Validation Loss:0.662 AVG Training Acc 62.28 % AVG Validation Acc 61.55 %\n",
      "Split 231\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec1b5f4b5f1b41f5b3dd1ea1978ed65e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.662 AVG Validation Loss:0.657 AVG Training Acc 61.89 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.656 AVG Training Acc 62.00 % AVG Validation Acc 61.95 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.659 AVG Training Acc 61.96 % AVG Validation Acc 62.04 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.661 AVG Training Acc 61.97 % AVG Validation Acc 62.04 %\n",
      "Epoch:50/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 62.13 % AVG Validation Acc 62.13 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.644 AVG Validation Loss:0.666 AVG Training Acc 62.15 % AVG Validation Acc 61.86 %\n",
      "Epoch:70/200 AVG Training Loss:0.643 AVG Validation Loss:0.667 AVG Training Acc 62.22 % AVG Validation Acc 61.86 %\n",
      "Epoch:80/200 AVG Training Loss:0.641 AVG Validation Loss:0.667 AVG Training Acc 62.22 % AVG Validation Acc 61.77 %\n",
      "Epoch:90/200 AVG Training Loss:0.641 AVG Validation Loss:0.669 AVG Training Acc 62.38 % AVG Validation Acc 61.86 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.643 AVG Validation Loss:0.670 AVG Training Acc 62.28 % AVG Validation Acc 61.86 %\n",
      "Epoch:110/200 AVG Training Loss:0.643 AVG Validation Loss:0.670 AVG Training Acc 62.15 % AVG Validation Acc 61.86 %\n",
      "Epoch:120/200 AVG Training Loss:0.642 AVG Validation Loss:0.670 AVG Training Acc 62.03 % AVG Validation Acc 61.86 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.642 AVG Validation Loss:0.670 AVG Training Acc 62.26 % AVG Validation Acc 61.77 %\n",
      "Epoch:140/200 AVG Training Loss:0.643 AVG Validation Loss:0.670 AVG Training Acc 62.40 % AVG Validation Acc 61.77 %\n",
      "Epoch:150/200 AVG Training Loss:0.641 AVG Validation Loss:0.669 AVG Training Acc 62.39 % AVG Validation Acc 61.68 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.642 AVG Validation Loss:0.669 AVG Training Acc 62.34 % AVG Validation Acc 61.77 %\n",
      "Epoch:170/200 AVG Training Loss:0.642 AVG Validation Loss:0.669 AVG Training Acc 62.30 % AVG Validation Acc 61.86 %\n",
      "Epoch:180/200 AVG Training Loss:0.642 AVG Validation Loss:0.669 AVG Training Acc 62.40 % AVG Validation Acc 61.86 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.642 AVG Validation Loss:0.671 AVG Training Acc 62.24 % AVG Validation Acc 61.86 %\n",
      "Epoch:200/200 AVG Training Loss:0.642 AVG Validation Loss:0.669 AVG Training Acc 62.27 % AVG Validation Acc 61.77 %\n",
      "Split 232\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "593ce94c7f4946bda64b6ec5eae3a11e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.658 AVG Training Acc 61.81 % AVG Validation Acc 61.86 %\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.658 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.659 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.655 AVG Validation Loss:0.660 AVG Training Acc 62.00 % AVG Validation Acc 61.86 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.655 AVG Validation Loss:0.659 AVG Training Acc 61.94 % AVG Validation Acc 61.86 %\n",
      "Epoch:60/200 AVG Training Loss:0.654 AVG Validation Loss:0.660 AVG Training Acc 61.72 % AVG Validation Acc 61.86 %\n",
      "Epoch:70/200 AVG Training Loss:0.653 AVG Validation Loss:0.660 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.654 AVG Validation Loss:0.660 AVG Training Acc 61.80 % AVG Validation Acc 61.86 %\n",
      "Epoch:90/200 AVG Training Loss:0.653 AVG Validation Loss:0.660 AVG Training Acc 61.84 % AVG Validation Acc 61.86 %\n",
      "Epoch:100/200 AVG Training Loss:0.654 AVG Validation Loss:0.660 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.654 AVG Validation Loss:0.660 AVG Training Acc 61.95 % AVG Validation Acc 61.86 %\n",
      "Epoch:120/200 AVG Training Loss:0.653 AVG Validation Loss:0.660 AVG Training Acc 61.99 % AVG Validation Acc 61.86 %\n",
      "Epoch:130/200 AVG Training Loss:0.654 AVG Validation Loss:0.660 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch:140/200 AVG Training Loss:0.654 AVG Validation Loss:0.660 AVG Training Acc 61.87 % AVG Validation Acc 61.86 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.654 AVG Validation Loss:0.660 AVG Training Acc 61.99 % AVG Validation Acc 61.86 %\n",
      "Epoch:160/200 AVG Training Loss:0.654 AVG Validation Loss:0.660 AVG Training Acc 61.77 % AVG Validation Acc 61.86 %\n",
      "Epoch:170/200 AVG Training Loss:0.653 AVG Validation Loss:0.660 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.653 AVG Validation Loss:0.660 AVG Training Acc 61.88 % AVG Validation Acc 61.86 %\n",
      "Epoch:190/200 AVG Training Loss:0.654 AVG Validation Loss:0.660 AVG Training Acc 62.12 % AVG Validation Acc 61.86 %\n",
      "Epoch:200/200 AVG Training Loss:0.653 AVG Validation Loss:0.660 AVG Training Acc 61.93 % AVG Validation Acc 61.86 %\n",
      "Split 233\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef6a6b3810864acdb308dd46df387d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.658 AVG Training Acc 61.92 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.657 AVG Training Acc 61.89 % AVG Validation Acc 61.95 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.663 AVG Validation Loss:0.662 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 61.94 % AVG Validation Acc 61.86 %\n",
      "Epoch:50/200 AVG Training Loss:0.656 AVG Validation Loss:0.658 AVG Training Acc 61.95 % AVG Validation Acc 61.95 %\n",
      "Epoch:60/200 AVG Training Loss:0.654 AVG Validation Loss:0.658 AVG Training Acc 61.85 % AVG Validation Acc 62.04 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.653 AVG Validation Loss:0.658 AVG Training Acc 61.95 % AVG Validation Acc 62.13 %\n",
      "Epoch:80/200 AVG Training Loss:0.652 AVG Validation Loss:0.658 AVG Training Acc 61.76 % AVG Validation Acc 62.04 %\n",
      "Epoch:90/200 AVG Training Loss:0.653 AVG Validation Loss:0.659 AVG Training Acc 61.97 % AVG Validation Acc 62.04 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.652 AVG Validation Loss:0.658 AVG Training Acc 61.82 % AVG Validation Acc 62.04 %\n",
      "Epoch:110/200 AVG Training Loss:0.652 AVG Validation Loss:0.658 AVG Training Acc 61.92 % AVG Validation Acc 62.04 %\n",
      "Epoch:120/200 AVG Training Loss:0.652 AVG Validation Loss:0.659 AVG Training Acc 62.00 % AVG Validation Acc 62.04 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.652 AVG Validation Loss:0.659 AVG Training Acc 61.85 % AVG Validation Acc 62.04 %\n",
      "Epoch:140/200 AVG Training Loss:0.653 AVG Validation Loss:0.659 AVG Training Acc 61.83 % AVG Validation Acc 62.04 %\n",
      "Epoch:150/200 AVG Training Loss:0.652 AVG Validation Loss:0.659 AVG Training Acc 62.04 % AVG Validation Acc 62.04 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.653 AVG Validation Loss:0.659 AVG Training Acc 61.81 % AVG Validation Acc 62.13 %\n",
      "Epoch:170/200 AVG Training Loss:0.651 AVG Validation Loss:0.659 AVG Training Acc 62.02 % AVG Validation Acc 62.13 %\n",
      "Epoch:180/200 AVG Training Loss:0.652 AVG Validation Loss:0.658 AVG Training Acc 61.94 % AVG Validation Acc 62.04 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.652 AVG Validation Loss:0.659 AVG Training Acc 62.00 % AVG Validation Acc 62.04 %\n",
      "Epoch:200/200 AVG Training Loss:0.652 AVG Validation Loss:0.658 AVG Training Acc 61.89 % AVG Validation Acc 62.04 %\n",
      "Split 234\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "538125e3a8c647e9a2038ea5ee158fbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.664 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 61.82 % AVG Validation Acc 61.77 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.652 AVG Validation Loss:0.663 AVG Training Acc 62.05 % AVG Validation Acc 61.23 %\n",
      "Epoch:40/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 61.98 % AVG Validation Acc 60.87 %\n",
      "Epoch:50/200 AVG Training Loss:0.645 AVG Validation Loss:0.671 AVG Training Acc 61.81 % AVG Validation Acc 61.32 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.640 AVG Validation Loss:0.673 AVG Training Acc 62.57 % AVG Validation Acc 61.23 %\n",
      "Epoch:70/200 AVG Training Loss:0.640 AVG Validation Loss:0.675 AVG Training Acc 62.61 % AVG Validation Acc 61.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.638 AVG Validation Loss:0.676 AVG Training Acc 62.68 % AVG Validation Acc 60.96 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.637 AVG Validation Loss:0.678 AVG Training Acc 62.55 % AVG Validation Acc 60.78 %\n",
      "Epoch:100/200 AVG Training Loss:0.637 AVG Validation Loss:0.678 AVG Training Acc 62.80 % AVG Validation Acc 60.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.637 AVG Validation Loss:0.677 AVG Training Acc 62.73 % AVG Validation Acc 60.96 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.637 AVG Validation Loss:0.676 AVG Training Acc 62.80 % AVG Validation Acc 60.96 %\n",
      "Epoch:130/200 AVG Training Loss:0.638 AVG Validation Loss:0.677 AVG Training Acc 62.42 % AVG Validation Acc 60.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.637 AVG Validation Loss:0.676 AVG Training Acc 62.69 % AVG Validation Acc 60.96 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.638 AVG Validation Loss:0.677 AVG Training Acc 62.51 % AVG Validation Acc 61.05 %\n",
      "Epoch:160/200 AVG Training Loss:0.637 AVG Validation Loss:0.675 AVG Training Acc 62.58 % AVG Validation Acc 60.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.638 AVG Validation Loss:0.677 AVG Training Acc 62.43 % AVG Validation Acc 61.14 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.638 AVG Validation Loss:0.677 AVG Training Acc 62.46 % AVG Validation Acc 61.05 %\n",
      "Epoch:190/200 AVG Training Loss:0.637 AVG Validation Loss:0.677 AVG Training Acc 62.00 % AVG Validation Acc 60.96 %\n",
      "Epoch:200/200 AVG Training Loss:0.637 AVG Validation Loss:0.677 AVG Training Acc 62.51 % AVG Validation Acc 60.78 %\n",
      "Split 235\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db47a659d43147bcb78a1beb135d1649",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.660 AVG Training Acc 61.85 % AVG Validation Acc 61.86 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.659 AVG Training Acc 61.93 % AVG Validation Acc 61.68 %\n",
      "Epoch:40/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 61.92 % AVG Validation Acc 61.86 %\n",
      "Epoch:50/200 AVG Training Loss:0.643 AVG Validation Loss:0.669 AVG Training Acc 62.25 % AVG Validation Acc 61.77 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.639 AVG Validation Loss:0.676 AVG Training Acc 62.41 % AVG Validation Acc 61.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.639 AVG Validation Loss:0.676 AVG Training Acc 62.31 % AVG Validation Acc 60.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.637 AVG Validation Loss:0.677 AVG Training Acc 62.31 % AVG Validation Acc 61.05 %\n",
      "Epoch:90/200 AVG Training Loss:0.638 AVG Validation Loss:0.679 AVG Training Acc 62.32 % AVG Validation Acc 61.05 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.638 AVG Validation Loss:0.678 AVG Training Acc 62.59 % AVG Validation Acc 61.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.637 AVG Validation Loss:0.678 AVG Training Acc 62.53 % AVG Validation Acc 61.14 %\n",
      "Epoch:120/200 AVG Training Loss:0.635 AVG Validation Loss:0.678 AVG Training Acc 62.86 % AVG Validation Acc 61.05 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.637 AVG Validation Loss:0.678 AVG Training Acc 62.54 % AVG Validation Acc 61.50 %\n",
      "Epoch:140/200 AVG Training Loss:0.636 AVG Validation Loss:0.679 AVG Training Acc 62.38 % AVG Validation Acc 61.14 %\n",
      "Epoch:150/200 AVG Training Loss:0.636 AVG Validation Loss:0.678 AVG Training Acc 62.48 % AVG Validation Acc 61.14 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.636 AVG Validation Loss:0.677 AVG Training Acc 62.65 % AVG Validation Acc 61.23 %\n",
      "Epoch:170/200 AVG Training Loss:0.638 AVG Validation Loss:0.677 AVG Training Acc 62.35 % AVG Validation Acc 61.23 %\n",
      "Epoch:180/200 AVG Training Loss:0.636 AVG Validation Loss:0.678 AVG Training Acc 62.30 % AVG Validation Acc 60.87 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.635 AVG Validation Loss:0.679 AVG Training Acc 62.52 % AVG Validation Acc 61.32 %\n",
      "Epoch:200/200 AVG Training Loss:0.637 AVG Validation Loss:0.680 AVG Training Acc 62.37 % AVG Validation Acc 61.32 %\n",
      "Split 236\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f78caa0f85ce4691873eb43406a17e41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:0.662 AVG Training Acc 61.78 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.661 AVG Training Acc 61.91 % AVG Validation Acc 62.09 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.661 AVG Training Acc 61.94 % AVG Validation Acc 62.09 %\n",
      "Epoch:50/200 AVG Training Loss:0.649 AVG Validation Loss:0.661 AVG Training Acc 61.97 % AVG Validation Acc 62.00 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.647 AVG Validation Loss:0.665 AVG Training Acc 61.99 % AVG Validation Acc 62.09 %\n",
      "Epoch:70/200 AVG Training Loss:0.646 AVG Validation Loss:0.665 AVG Training Acc 62.16 % AVG Validation Acc 62.09 %\n",
      "Epoch:80/200 AVG Training Loss:0.646 AVG Validation Loss:0.665 AVG Training Acc 62.05 % AVG Validation Acc 61.73 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.643 AVG Validation Loss:0.666 AVG Training Acc 62.13 % AVG Validation Acc 62.00 %\n",
      "Epoch:100/200 AVG Training Loss:0.643 AVG Validation Loss:0.665 AVG Training Acc 62.17 % AVG Validation Acc 61.91 %\n",
      "Epoch:110/200 AVG Training Loss:0.644 AVG Validation Loss:0.666 AVG Training Acc 62.19 % AVG Validation Acc 62.09 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.645 AVG Validation Loss:0.666 AVG Training Acc 62.11 % AVG Validation Acc 62.00 %\n",
      "Epoch:130/200 AVG Training Loss:0.644 AVG Validation Loss:0.665 AVG Training Acc 62.27 % AVG Validation Acc 61.91 %\n",
      "Epoch:140/200 AVG Training Loss:0.644 AVG Validation Loss:0.665 AVG Training Acc 62.09 % AVG Validation Acc 61.91 %\n",
      "Epoch:150/200 AVG Training Loss:0.644 AVG Validation Loss:0.666 AVG Training Acc 62.31 % AVG Validation Acc 61.91 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.644 AVG Validation Loss:0.666 AVG Training Acc 62.12 % AVG Validation Acc 62.00 %\n",
      "Epoch:170/200 AVG Training Loss:0.644 AVG Validation Loss:0.666 AVG Training Acc 62.31 % AVG Validation Acc 61.91 %\n",
      "Epoch:180/200 AVG Training Loss:0.644 AVG Validation Loss:0.666 AVG Training Acc 62.36 % AVG Validation Acc 61.91 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.644 AVG Validation Loss:0.666 AVG Training Acc 62.10 % AVG Validation Acc 61.91 %\n",
      "Epoch:200/200 AVG Training Loss:0.644 AVG Validation Loss:0.665 AVG Training Acc 62.01 % AVG Validation Acc 62.00 %\n",
      "Split 237\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48db960453134b30a3a223d95311631f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.660 AVG Training Acc 61.86 % AVG Validation Acc 62.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.660 AVG Training Acc 61.77 % AVG Validation Acc 62.09 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.662 AVG Training Acc 61.99 % AVG Validation Acc 61.73 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.664 AVG Training Acc 61.99 % AVG Validation Acc 61.73 %\n",
      "Epoch:50/200 AVG Training Loss:0.651 AVG Validation Loss:0.665 AVG Training Acc 62.08 % AVG Validation Acc 61.73 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 62.11 % AVG Validation Acc 61.82 %\n",
      "Epoch:70/200 AVG Training Loss:0.648 AVG Validation Loss:0.666 AVG Training Acc 62.13 % AVG Validation Acc 61.82 %\n",
      "Epoch:80/200 AVG Training Loss:0.648 AVG Validation Loss:0.666 AVG Training Acc 62.06 % AVG Validation Acc 61.82 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 62.20 % AVG Validation Acc 61.91 %\n",
      "Epoch:100/200 AVG Training Loss:0.648 AVG Validation Loss:0.666 AVG Training Acc 62.20 % AVG Validation Acc 61.82 %\n",
      "Epoch:110/200 AVG Training Loss:0.648 AVG Validation Loss:0.666 AVG Training Acc 62.15 % AVG Validation Acc 61.82 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.648 AVG Validation Loss:0.667 AVG Training Acc 62.17 % AVG Validation Acc 61.91 %\n",
      "Epoch:130/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 62.23 % AVG Validation Acc 61.82 %\n",
      "Epoch:140/200 AVG Training Loss:0.648 AVG Validation Loss:0.667 AVG Training Acc 62.14 % AVG Validation Acc 61.82 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.649 AVG Validation Loss:0.667 AVG Training Acc 62.04 % AVG Validation Acc 61.91 %\n",
      "Epoch:160/200 AVG Training Loss:0.649 AVG Validation Loss:0.667 AVG Training Acc 62.00 % AVG Validation Acc 61.82 %\n",
      "Epoch:170/200 AVG Training Loss:0.648 AVG Validation Loss:0.667 AVG Training Acc 62.28 % AVG Validation Acc 61.82 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.648 AVG Validation Loss:0.666 AVG Training Acc 62.27 % AVG Validation Acc 61.91 %\n",
      "Epoch:190/200 AVG Training Loss:0.649 AVG Validation Loss:0.667 AVG Training Acc 62.20 % AVG Validation Acc 61.82 %\n",
      "Epoch:200/200 AVG Training Loss:0.649 AVG Validation Loss:0.667 AVG Training Acc 62.41 % AVG Validation Acc 61.82 %\n",
      "Split 238\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59bac90a249e463abb1ac8fe7c1bfd4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 61.85 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.666 AVG Training Acc 61.91 % AVG Validation Acc 61.91 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.652 AVG Validation Loss:0.665 AVG Training Acc 61.89 % AVG Validation Acc 62.00 %\n",
      "Epoch:40/200 AVG Training Loss:0.650 AVG Validation Loss:0.664 AVG Training Acc 61.96 % AVG Validation Acc 61.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.647 AVG Validation Loss:0.661 AVG Training Acc 62.13 % AVG Validation Acc 62.00 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.643 AVG Validation Loss:0.664 AVG Training Acc 62.33 % AVG Validation Acc 61.37 %\n",
      "Epoch:70/200 AVG Training Loss:0.642 AVG Validation Loss:0.665 AVG Training Acc 62.29 % AVG Validation Acc 60.92 %\n",
      "Epoch:80/200 AVG Training Loss:0.641 AVG Validation Loss:0.666 AVG Training Acc 62.57 % AVG Validation Acc 61.10 %\n",
      "Epoch:90/200 AVG Training Loss:0.640 AVG Validation Loss:0.665 AVG Training Acc 62.14 % AVG Validation Acc 60.92 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.641 AVG Validation Loss:0.665 AVG Training Acc 62.35 % AVG Validation Acc 60.74 %\n",
      "Epoch:110/200 AVG Training Loss:0.640 AVG Validation Loss:0.666 AVG Training Acc 62.48 % AVG Validation Acc 60.92 %\n",
      "Epoch:120/200 AVG Training Loss:0.641 AVG Validation Loss:0.665 AVG Training Acc 62.90 % AVG Validation Acc 60.83 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.641 AVG Validation Loss:0.666 AVG Training Acc 62.68 % AVG Validation Acc 61.01 %\n",
      "Epoch:140/200 AVG Training Loss:0.640 AVG Validation Loss:0.666 AVG Training Acc 62.48 % AVG Validation Acc 60.83 %\n",
      "Epoch:150/200 AVG Training Loss:0.641 AVG Validation Loss:0.666 AVG Training Acc 62.29 % AVG Validation Acc 60.65 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.641 AVG Validation Loss:0.665 AVG Training Acc 62.48 % AVG Validation Acc 60.83 %\n",
      "Epoch:170/200 AVG Training Loss:0.640 AVG Validation Loss:0.664 AVG Training Acc 62.43 % AVG Validation Acc 60.92 %\n",
      "Epoch:180/200 AVG Training Loss:0.641 AVG Validation Loss:0.665 AVG Training Acc 62.42 % AVG Validation Acc 60.92 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.640 AVG Validation Loss:0.667 AVG Training Acc 62.58 % AVG Validation Acc 60.83 %\n",
      "Epoch:200/200 AVG Training Loss:0.640 AVG Validation Loss:0.665 AVG Training Acc 62.59 % AVG Validation Acc 60.74 %\n",
      "Split 239\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de97ae40dc0849ed9c96cc3391aaa530",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.660 AVG Training Acc 61.87 % AVG Validation Acc 61.91 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.658 AVG Training Acc 61.92 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.663 AVG Training Acc 62.05 % AVG Validation Acc 61.82 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.667 AVG Training Acc 62.03 % AVG Validation Acc 61.82 %\n",
      "Epoch:50/200 AVG Training Loss:0.650 AVG Validation Loss:0.676 AVG Training Acc 62.17 % AVG Validation Acc 61.55 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.648 AVG Validation Loss:0.679 AVG Training Acc 62.16 % AVG Validation Acc 61.55 %\n",
      "Epoch:70/200 AVG Training Loss:0.648 AVG Validation Loss:0.681 AVG Training Acc 62.19 % AVG Validation Acc 61.55 %\n",
      "Epoch:80/200 AVG Training Loss:0.647 AVG Validation Loss:0.683 AVG Training Acc 62.28 % AVG Validation Acc 61.46 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.646 AVG Validation Loss:0.684 AVG Training Acc 62.26 % AVG Validation Acc 61.46 %\n",
      "Epoch:100/200 AVG Training Loss:0.646 AVG Validation Loss:0.685 AVG Training Acc 62.23 % AVG Validation Acc 61.37 %\n",
      "Epoch:110/200 AVG Training Loss:0.645 AVG Validation Loss:0.686 AVG Training Acc 62.23 % AVG Validation Acc 61.37 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.646 AVG Validation Loss:0.685 AVG Training Acc 62.23 % AVG Validation Acc 61.37 %\n",
      "Epoch:130/200 AVG Training Loss:0.646 AVG Validation Loss:0.686 AVG Training Acc 62.20 % AVG Validation Acc 61.37 %\n",
      "Epoch:140/200 AVG Training Loss:0.647 AVG Validation Loss:0.685 AVG Training Acc 62.21 % AVG Validation Acc 61.37 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.645 AVG Validation Loss:0.686 AVG Training Acc 62.30 % AVG Validation Acc 61.37 %\n",
      "Epoch:160/200 AVG Training Loss:0.646 AVG Validation Loss:0.686 AVG Training Acc 62.29 % AVG Validation Acc 61.37 %\n",
      "Epoch:170/200 AVG Training Loss:0.647 AVG Validation Loss:0.686 AVG Training Acc 62.23 % AVG Validation Acc 61.37 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.645 AVG Validation Loss:0.686 AVG Training Acc 62.29 % AVG Validation Acc 61.37 %\n",
      "Epoch:190/200 AVG Training Loss:0.646 AVG Validation Loss:0.685 AVG Training Acc 62.21 % AVG Validation Acc 61.37 %\n",
      "Epoch:200/200 AVG Training Loss:0.646 AVG Validation Loss:0.685 AVG Training Acc 62.20 % AVG Validation Acc 61.37 %\n",
      "Split 240\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed5c5175b064ced9f8d12bc7d8a0ccf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.662 AVG Validation Loss:0.662 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.665 AVG Training Acc 61.95 % AVG Validation Acc 62.00 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.651 AVG Validation Loss:0.673 AVG Training Acc 62.01 % AVG Validation Acc 61.91 %\n",
      "Epoch:40/200 AVG Training Loss:0.647 AVG Validation Loss:0.681 AVG Training Acc 62.23 % AVG Validation Acc 62.09 %\n",
      "Epoch:50/200 AVG Training Loss:0.642 AVG Validation Loss:0.691 AVG Training Acc 62.28 % AVG Validation Acc 62.00 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.637 AVG Validation Loss:0.699 AVG Training Acc 62.61 % AVG Validation Acc 62.09 %\n",
      "Epoch:70/200 AVG Training Loss:0.638 AVG Validation Loss:0.701 AVG Training Acc 62.48 % AVG Validation Acc 62.00 %\n",
      "Epoch:80/200 AVG Training Loss:0.637 AVG Validation Loss:0.703 AVG Training Acc 62.52 % AVG Validation Acc 62.00 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.637 AVG Validation Loss:0.704 AVG Training Acc 62.51 % AVG Validation Acc 62.09 %\n",
      "Epoch:100/200 AVG Training Loss:0.636 AVG Validation Loss:0.704 AVG Training Acc 62.48 % AVG Validation Acc 62.09 %\n",
      "Epoch:110/200 AVG Training Loss:0.636 AVG Validation Loss:0.704 AVG Training Acc 62.67 % AVG Validation Acc 62.09 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.636 AVG Validation Loss:0.704 AVG Training Acc 62.60 % AVG Validation Acc 61.91 %\n",
      "Epoch:130/200 AVG Training Loss:0.635 AVG Validation Loss:0.704 AVG Training Acc 62.60 % AVG Validation Acc 62.00 %\n",
      "Epoch:140/200 AVG Training Loss:0.636 AVG Validation Loss:0.704 AVG Training Acc 62.41 % AVG Validation Acc 61.91 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.636 AVG Validation Loss:0.704 AVG Training Acc 62.47 % AVG Validation Acc 62.00 %\n",
      "Epoch:160/200 AVG Training Loss:0.636 AVG Validation Loss:0.704 AVG Training Acc 62.57 % AVG Validation Acc 62.09 %\n",
      "Epoch:170/200 AVG Training Loss:0.636 AVG Validation Loss:0.704 AVG Training Acc 62.47 % AVG Validation Acc 62.00 %\n",
      "Epoch:180/200 AVG Training Loss:0.635 AVG Validation Loss:0.704 AVG Training Acc 62.65 % AVG Validation Acc 62.09 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.636 AVG Validation Loss:0.704 AVG Training Acc 62.43 % AVG Validation Acc 62.00 %\n",
      "Epoch:200/200 AVG Training Loss:0.635 AVG Validation Loss:0.704 AVG Training Acc 62.69 % AVG Validation Acc 62.00 %\n",
      "Split 241\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f1672def6b042cb98ffea1465588c74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.663 AVG Training Acc 61.83 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.661 AVG Training Acc 61.78 % AVG Validation Acc 61.95 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.661 AVG Training Acc 61.98 % AVG Validation Acc 62.13 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.661 AVG Training Acc 61.98 % AVG Validation Acc 62.04 %\n",
      "Epoch:50/200 AVG Training Loss:0.649 AVG Validation Loss:0.662 AVG Training Acc 61.88 % AVG Validation Acc 62.04 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 62.17 % AVG Validation Acc 61.77 %\n",
      "Epoch:70/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 61.79 % AVG Validation Acc 62.13 %\n",
      "Epoch:80/200 AVG Training Loss:0.647 AVG Validation Loss:0.664 AVG Training Acc 62.01 % AVG Validation Acc 61.86 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.646 AVG Validation Loss:0.665 AVG Training Acc 62.05 % AVG Validation Acc 61.86 %\n",
      "Epoch:100/200 AVG Training Loss:0.646 AVG Validation Loss:0.665 AVG Training Acc 62.02 % AVG Validation Acc 62.04 %\n",
      "Epoch:110/200 AVG Training Loss:0.646 AVG Validation Loss:0.665 AVG Training Acc 62.03 % AVG Validation Acc 62.04 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.645 AVG Validation Loss:0.665 AVG Training Acc 62.10 % AVG Validation Acc 62.04 %\n",
      "Epoch:130/200 AVG Training Loss:0.646 AVG Validation Loss:0.665 AVG Training Acc 62.08 % AVG Validation Acc 62.04 %\n",
      "Epoch:140/200 AVG Training Loss:0.647 AVG Validation Loss:0.665 AVG Training Acc 62.15 % AVG Validation Acc 62.31 %\n",
      "Epoch:150/200 AVG Training Loss:0.646 AVG Validation Loss:0.665 AVG Training Acc 62.15 % AVG Validation Acc 61.95 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.647 AVG Validation Loss:0.665 AVG Training Acc 62.04 % AVG Validation Acc 61.86 %\n",
      "Epoch:170/200 AVG Training Loss:0.646 AVG Validation Loss:0.665 AVG Training Acc 62.09 % AVG Validation Acc 62.04 %\n",
      "Epoch:180/200 AVG Training Loss:0.647 AVG Validation Loss:0.665 AVG Training Acc 61.84 % AVG Validation Acc 61.95 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.647 AVG Validation Loss:0.665 AVG Training Acc 62.05 % AVG Validation Acc 62.04 %\n",
      "Epoch:200/200 AVG Training Loss:0.647 AVG Validation Loss:0.665 AVG Training Acc 62.17 % AVG Validation Acc 62.31 %\n",
      "Split 242\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2938315f7d04db19dbd1399dcf537d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.659 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.661 AVG Validation Loss:0.662 AVG Training Acc 61.82 % AVG Validation Acc 61.86 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.660 AVG Training Acc 62.07 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.661 AVG Training Acc 61.84 % AVG Validation Acc 61.77 %\n",
      "Epoch:50/200 AVG Training Loss:0.649 AVG Validation Loss:0.663 AVG Training Acc 61.99 % AVG Validation Acc 61.68 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.646 AVG Validation Loss:0.666 AVG Training Acc 62.23 % AVG Validation Acc 61.32 %\n",
      "Epoch:70/200 AVG Training Loss:0.646 AVG Validation Loss:0.667 AVG Training Acc 62.02 % AVG Validation Acc 61.23 %\n",
      "Epoch:80/200 AVG Training Loss:0.648 AVG Validation Loss:0.668 AVG Training Acc 62.21 % AVG Validation Acc 61.23 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.646 AVG Validation Loss:0.669 AVG Training Acc 62.22 % AVG Validation Acc 61.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.646 AVG Validation Loss:0.668 AVG Training Acc 62.18 % AVG Validation Acc 61.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.646 AVG Validation Loss:0.668 AVG Training Acc 62.06 % AVG Validation Acc 61.14 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.646 AVG Validation Loss:0.669 AVG Training Acc 62.35 % AVG Validation Acc 61.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.646 AVG Validation Loss:0.668 AVG Training Acc 62.08 % AVG Validation Acc 61.32 %\n",
      "Epoch:140/200 AVG Training Loss:0.646 AVG Validation Loss:0.669 AVG Training Acc 61.98 % AVG Validation Acc 61.23 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.646 AVG Validation Loss:0.669 AVG Training Acc 62.28 % AVG Validation Acc 61.23 %\n",
      "Epoch:160/200 AVG Training Loss:0.645 AVG Validation Loss:0.669 AVG Training Acc 62.25 % AVG Validation Acc 61.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.645 AVG Validation Loss:0.669 AVG Training Acc 62.24 % AVG Validation Acc 61.23 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.646 AVG Validation Loss:0.669 AVG Training Acc 62.22 % AVG Validation Acc 61.23 %\n",
      "Epoch:190/200 AVG Training Loss:0.646 AVG Validation Loss:0.668 AVG Training Acc 62.02 % AVG Validation Acc 61.32 %\n",
      "Epoch:200/200 AVG Training Loss:0.646 AVG Validation Loss:0.669 AVG Training Acc 62.13 % AVG Validation Acc 61.05 %\n",
      "Split 243\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73d249c9aeef4242b68a5b0b6c587818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.663 AVG Training Acc 61.86 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.662 AVG Training Acc 61.98 % AVG Validation Acc 61.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.672 AVG Training Acc 61.99 % AVG Validation Acc 61.95 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.648 AVG Validation Loss:0.673 AVG Training Acc 62.12 % AVG Validation Acc 62.04 %\n",
      "Epoch:50/200 AVG Training Loss:0.644 AVG Validation Loss:0.681 AVG Training Acc 62.22 % AVG Validation Acc 62.04 %\n",
      "Epoch:60/200 AVG Training Loss:0.639 AVG Validation Loss:0.694 AVG Training Acc 62.42 % AVG Validation Acc 61.68 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.636 AVG Validation Loss:0.703 AVG Training Acc 62.50 % AVG Validation Acc 61.50 %\n",
      "Epoch:80/200 AVG Training Loss:0.634 AVG Validation Loss:0.706 AVG Training Acc 62.55 % AVG Validation Acc 61.50 %\n",
      "Epoch:90/200 AVG Training Loss:0.634 AVG Validation Loss:0.705 AVG Training Acc 62.53 % AVG Validation Acc 61.59 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.635 AVG Validation Loss:0.706 AVG Training Acc 62.50 % AVG Validation Acc 61.50 %\n",
      "Epoch:110/200 AVG Training Loss:0.634 AVG Validation Loss:0.707 AVG Training Acc 62.70 % AVG Validation Acc 61.50 %\n",
      "Epoch:120/200 AVG Training Loss:0.634 AVG Validation Loss:0.708 AVG Training Acc 62.50 % AVG Validation Acc 61.50 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.632 AVG Validation Loss:0.707 AVG Training Acc 62.46 % AVG Validation Acc 61.59 %\n",
      "Epoch:140/200 AVG Training Loss:0.632 AVG Validation Loss:0.707 AVG Training Acc 62.68 % AVG Validation Acc 61.41 %\n",
      "Epoch:150/200 AVG Training Loss:0.633 AVG Validation Loss:0.706 AVG Training Acc 62.58 % AVG Validation Acc 61.41 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.633 AVG Validation Loss:0.708 AVG Training Acc 62.57 % AVG Validation Acc 61.50 %\n",
      "Epoch:170/200 AVG Training Loss:0.634 AVG Validation Loss:0.706 AVG Training Acc 62.59 % AVG Validation Acc 61.59 %\n",
      "Epoch:180/200 AVG Training Loss:0.634 AVG Validation Loss:0.707 AVG Training Acc 62.60 % AVG Validation Acc 61.50 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.633 AVG Validation Loss:0.706 AVG Training Acc 62.54 % AVG Validation Acc 61.50 %\n",
      "Epoch:200/200 AVG Training Loss:0.631 AVG Validation Loss:0.707 AVG Training Acc 62.68 % AVG Validation Acc 61.41 %\n",
      "Split 244\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca8b7151045b460e8aed1805d3a73d1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.660 AVG Training Acc 61.92 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.659 AVG Training Acc 61.84 % AVG Validation Acc 62.04 %\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.659 AVG Training Acc 61.68 % AVG Validation Acc 62.04 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.650 AVG Validation Loss:0.660 AVG Training Acc 62.20 % AVG Validation Acc 61.59 %\n",
      "Epoch:50/200 AVG Training Loss:0.647 AVG Validation Loss:0.662 AVG Training Acc 62.67 % AVG Validation Acc 61.68 %\n",
      "Epoch:60/200 AVG Training Loss:0.643 AVG Validation Loss:0.671 AVG Training Acc 62.48 % AVG Validation Acc 61.59 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.640 AVG Validation Loss:0.667 AVG Training Acc 62.70 % AVG Validation Acc 61.41 %\n",
      "Epoch:80/200 AVG Training Loss:0.640 AVG Validation Loss:0.668 AVG Training Acc 62.48 % AVG Validation Acc 60.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.639 AVG Validation Loss:0.670 AVG Training Acc 62.39 % AVG Validation Acc 61.23 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.638 AVG Validation Loss:0.672 AVG Training Acc 62.24 % AVG Validation Acc 61.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.638 AVG Validation Loss:0.672 AVG Training Acc 62.56 % AVG Validation Acc 61.14 %\n",
      "Epoch:120/200 AVG Training Loss:0.638 AVG Validation Loss:0.672 AVG Training Acc 62.81 % AVG Validation Acc 61.41 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.638 AVG Validation Loss:0.672 AVG Training Acc 62.47 % AVG Validation Acc 60.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.639 AVG Validation Loss:0.671 AVG Training Acc 62.32 % AVG Validation Acc 61.41 %\n",
      "Epoch:150/200 AVG Training Loss:0.638 AVG Validation Loss:0.672 AVG Training Acc 62.58 % AVG Validation Acc 61.32 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.638 AVG Validation Loss:0.671 AVG Training Acc 62.60 % AVG Validation Acc 61.23 %\n",
      "Epoch:170/200 AVG Training Loss:0.638 AVG Validation Loss:0.672 AVG Training Acc 62.53 % AVG Validation Acc 61.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.638 AVG Validation Loss:0.670 AVG Training Acc 62.54 % AVG Validation Acc 61.68 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.637 AVG Validation Loss:0.672 AVG Training Acc 62.48 % AVG Validation Acc 61.32 %\n",
      "Epoch:200/200 AVG Training Loss:0.639 AVG Validation Loss:0.672 AVG Training Acc 62.32 % AVG Validation Acc 61.32 %\n",
      "Split 245\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbf53970eecc4d318ed35df17d170d34",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.664 AVG Training Acc 61.81 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.661 AVG Training Acc 61.94 % AVG Validation Acc 61.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.670 AVG Training Acc 62.21 % AVG Validation Acc 61.68 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.646 AVG Validation Loss:0.676 AVG Training Acc 62.12 % AVG Validation Acc 61.50 %\n",
      "Epoch:50/200 AVG Training Loss:0.643 AVG Validation Loss:0.681 AVG Training Acc 62.17 % AVG Validation Acc 61.50 %\n",
      "Epoch:60/200 AVG Training Loss:0.638 AVG Validation Loss:0.685 AVG Training Acc 62.45 % AVG Validation Acc 61.50 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.635 AVG Validation Loss:0.689 AVG Training Acc 62.63 % AVG Validation Acc 60.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.633 AVG Validation Loss:0.692 AVG Training Acc 62.66 % AVG Validation Acc 61.05 %\n",
      "Epoch:90/200 AVG Training Loss:0.636 AVG Validation Loss:0.693 AVG Training Acc 62.63 % AVG Validation Acc 60.69 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.633 AVG Validation Loss:0.692 AVG Training Acc 62.91 % AVG Validation Acc 60.69 %\n",
      "Epoch:110/200 AVG Training Loss:0.634 AVG Validation Loss:0.693 AVG Training Acc 63.03 % AVG Validation Acc 60.60 %\n",
      "Epoch:120/200 AVG Training Loss:0.636 AVG Validation Loss:0.693 AVG Training Acc 62.84 % AVG Validation Acc 60.60 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.634 AVG Validation Loss:0.694 AVG Training Acc 62.84 % AVG Validation Acc 60.60 %\n",
      "Epoch:140/200 AVG Training Loss:0.633 AVG Validation Loss:0.693 AVG Training Acc 63.23 % AVG Validation Acc 60.69 %\n",
      "Epoch:150/200 AVG Training Loss:0.635 AVG Validation Loss:0.695 AVG Training Acc 62.96 % AVG Validation Acc 60.60 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.633 AVG Validation Loss:0.694 AVG Training Acc 62.96 % AVG Validation Acc 60.60 %\n",
      "Epoch:170/200 AVG Training Loss:0.632 AVG Validation Loss:0.692 AVG Training Acc 63.03 % AVG Validation Acc 60.60 %\n",
      "Epoch:180/200 AVG Training Loss:0.634 AVG Validation Loss:0.692 AVG Training Acc 63.03 % AVG Validation Acc 60.50 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.633 AVG Validation Loss:0.694 AVG Training Acc 62.96 % AVG Validation Acc 60.60 %\n",
      "Epoch:200/200 AVG Training Loss:0.634 AVG Validation Loss:0.693 AVG Training Acc 63.01 % AVG Validation Acc 60.60 %\n",
      "Split 246\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c7f3ad44e124d53b953d620aa1f3b5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.653 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.656 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.659 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.658 AVG Training Acc 61.97 % AVG Validation Acc 61.64 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.651 AVG Validation Loss:0.658 AVG Training Acc 62.16 % AVG Validation Acc 61.55 %\n",
      "Epoch:60/200 AVG Training Loss:0.650 AVG Validation Loss:0.659 AVG Training Acc 62.10 % AVG Validation Acc 61.55 %\n",
      "Epoch:70/200 AVG Training Loss:0.649 AVG Validation Loss:0.659 AVG Training Acc 62.11 % AVG Validation Acc 61.73 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.649 AVG Validation Loss:0.660 AVG Training Acc 62.24 % AVG Validation Acc 61.73 %\n",
      "Epoch:90/200 AVG Training Loss:0.649 AVG Validation Loss:0.660 AVG Training Acc 62.15 % AVG Validation Acc 61.73 %\n",
      "Epoch:100/200 AVG Training Loss:0.648 AVG Validation Loss:0.661 AVG Training Acc 62.17 % AVG Validation Acc 61.73 %\n",
      "Epoch:110/200 AVG Training Loss:0.648 AVG Validation Loss:0.661 AVG Training Acc 62.16 % AVG Validation Acc 61.73 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.648 AVG Validation Loss:0.661 AVG Training Acc 62.28 % AVG Validation Acc 61.73 %\n",
      "Epoch:130/200 AVG Training Loss:0.649 AVG Validation Loss:0.661 AVG Training Acc 62.19 % AVG Validation Acc 61.73 %\n",
      "Epoch:140/200 AVG Training Loss:0.649 AVG Validation Loss:0.661 AVG Training Acc 62.18 % AVG Validation Acc 61.73 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.648 AVG Validation Loss:0.661 AVG Training Acc 62.12 % AVG Validation Acc 61.73 %\n",
      "Epoch:160/200 AVG Training Loss:0.649 AVG Validation Loss:0.661 AVG Training Acc 62.22 % AVG Validation Acc 61.73 %\n",
      "Epoch:170/200 AVG Training Loss:0.649 AVG Validation Loss:0.661 AVG Training Acc 62.17 % AVG Validation Acc 61.73 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.648 AVG Validation Loss:0.661 AVG Training Acc 62.16 % AVG Validation Acc 61.64 %\n",
      "Epoch:190/200 AVG Training Loss:0.650 AVG Validation Loss:0.661 AVG Training Acc 62.11 % AVG Validation Acc 61.73 %\n",
      "Epoch:200/200 AVG Training Loss:0.648 AVG Validation Loss:0.661 AVG Training Acc 62.14 % AVG Validation Acc 61.73 %\n",
      "Split 247\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a7516c6d3b147a8903782eee93083d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.661 AVG Training Acc 61.87 % AVG Validation Acc 61.91 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.661 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.659 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch:40/200 AVG Training Loss:0.654 AVG Validation Loss:0.656 AVG Training Acc 61.89 % AVG Validation Acc 62.00 %\n",
      "Epoch:50/200 AVG Training Loss:0.651 AVG Validation Loss:0.658 AVG Training Acc 61.91 % AVG Validation Acc 61.91 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.649 AVG Validation Loss:0.659 AVG Training Acc 61.90 % AVG Validation Acc 61.82 %\n",
      "Epoch:70/200 AVG Training Loss:0.649 AVG Validation Loss:0.659 AVG Training Acc 61.82 % AVG Validation Acc 61.82 %\n",
      "Epoch:80/200 AVG Training Loss:0.649 AVG Validation Loss:0.660 AVG Training Acc 62.02 % AVG Validation Acc 61.82 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.646 AVG Validation Loss:0.660 AVG Training Acc 61.93 % AVG Validation Acc 61.82 %\n",
      "Epoch:100/200 AVG Training Loss:0.647 AVG Validation Loss:0.660 AVG Training Acc 62.08 % AVG Validation Acc 61.82 %\n",
      "Epoch:110/200 AVG Training Loss:0.648 AVG Validation Loss:0.660 AVG Training Acc 61.99 % AVG Validation Acc 61.82 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.647 AVG Validation Loss:0.660 AVG Training Acc 62.03 % AVG Validation Acc 61.82 %\n",
      "Epoch:130/200 AVG Training Loss:0.647 AVG Validation Loss:0.660 AVG Training Acc 61.94 % AVG Validation Acc 61.82 %\n",
      "Epoch:140/200 AVG Training Loss:0.648 AVG Validation Loss:0.660 AVG Training Acc 62.00 % AVG Validation Acc 61.82 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.648 AVG Validation Loss:0.660 AVG Training Acc 62.20 % AVG Validation Acc 61.82 %\n",
      "Epoch:160/200 AVG Training Loss:0.647 AVG Validation Loss:0.660 AVG Training Acc 62.02 % AVG Validation Acc 61.82 %\n",
      "Epoch:170/200 AVG Training Loss:0.648 AVG Validation Loss:0.660 AVG Training Acc 61.94 % AVG Validation Acc 61.82 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.648 AVG Validation Loss:0.660 AVG Training Acc 62.00 % AVG Validation Acc 61.82 %\n",
      "Epoch:190/200 AVG Training Loss:0.649 AVG Validation Loss:0.660 AVG Training Acc 62.01 % AVG Validation Acc 61.82 %\n",
      "Epoch:200/200 AVG Training Loss:0.646 AVG Validation Loss:0.660 AVG Training Acc 62.07 % AVG Validation Acc 61.82 %\n",
      "Split 248\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c5942d719744e58b2b311daad1d3f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.659 AVG Training Acc 61.83 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.657 AVG Training Acc 61.92 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.662 AVG Training Acc 61.86 % AVG Validation Acc 61.82 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.662 AVG Training Acc 62.09 % AVG Validation Acc 62.09 %\n",
      "Epoch:50/200 AVG Training Loss:0.648 AVG Validation Loss:0.665 AVG Training Acc 62.03 % AVG Validation Acc 61.82 %\n",
      "Epoch:60/200 AVG Training Loss:0.645 AVG Validation Loss:0.670 AVG Training Acc 62.58 % AVG Validation Acc 61.28 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.645 AVG Validation Loss:0.668 AVG Training Acc 62.37 % AVG Validation Acc 61.55 %\n",
      "Epoch:80/200 AVG Training Loss:0.643 AVG Validation Loss:0.671 AVG Training Acc 62.17 % AVG Validation Acc 61.55 %\n",
      "Epoch:90/200 AVG Training Loss:0.644 AVG Validation Loss:0.670 AVG Training Acc 62.39 % AVG Validation Acc 61.55 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.644 AVG Validation Loss:0.671 AVG Training Acc 62.27 % AVG Validation Acc 61.37 %\n",
      "Epoch:110/200 AVG Training Loss:0.643 AVG Validation Loss:0.672 AVG Training Acc 62.52 % AVG Validation Acc 61.55 %\n",
      "Epoch:120/200 AVG Training Loss:0.643 AVG Validation Loss:0.672 AVG Training Acc 62.56 % AVG Validation Acc 61.46 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.643 AVG Validation Loss:0.672 AVG Training Acc 62.40 % AVG Validation Acc 61.46 %\n",
      "Epoch:140/200 AVG Training Loss:0.644 AVG Validation Loss:0.671 AVG Training Acc 62.23 % AVG Validation Acc 61.37 %\n",
      "Epoch:150/200 AVG Training Loss:0.644 AVG Validation Loss:0.671 AVG Training Acc 62.48 % AVG Validation Acc 61.46 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.643 AVG Validation Loss:0.672 AVG Training Acc 62.54 % AVG Validation Acc 61.37 %\n",
      "Epoch:170/200 AVG Training Loss:0.643 AVG Validation Loss:0.673 AVG Training Acc 62.35 % AVG Validation Acc 61.28 %\n",
      "Epoch:180/200 AVG Training Loss:0.644 AVG Validation Loss:0.671 AVG Training Acc 62.42 % AVG Validation Acc 61.55 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.644 AVG Validation Loss:0.671 AVG Training Acc 62.11 % AVG Validation Acc 61.55 %\n",
      "Epoch:200/200 AVG Training Loss:0.643 AVG Validation Loss:0.672 AVG Training Acc 62.52 % AVG Validation Acc 61.46 %\n",
      "Split 249\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "342fb6da97524632bf578a721d320941",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.664 AVG Training Acc 61.93 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.664 AVG Training Acc 61.95 % AVG Validation Acc 61.55 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.652 AVG Validation Loss:0.663 AVG Training Acc 61.89 % AVG Validation Acc 61.55 %\n",
      "Epoch:40/200 AVG Training Loss:0.648 AVG Validation Loss:0.663 AVG Training Acc 61.96 % AVG Validation Acc 61.28 %\n",
      "Epoch:50/200 AVG Training Loss:0.644 AVG Validation Loss:0.662 AVG Training Acc 62.09 % AVG Validation Acc 61.19 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.640 AVG Validation Loss:0.664 AVG Training Acc 62.42 % AVG Validation Acc 60.83 %\n",
      "Epoch:70/200 AVG Training Loss:0.638 AVG Validation Loss:0.665 AVG Training Acc 62.45 % AVG Validation Acc 60.65 %\n",
      "Epoch:80/200 AVG Training Loss:0.638 AVG Validation Loss:0.667 AVG Training Acc 62.37 % AVG Validation Acc 60.47 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.638 AVG Validation Loss:0.668 AVG Training Acc 62.57 % AVG Validation Acc 60.29 %\n",
      "Epoch:100/200 AVG Training Loss:0.638 AVG Validation Loss:0.668 AVG Training Acc 62.72 % AVG Validation Acc 60.47 %\n",
      "Epoch:110/200 AVG Training Loss:0.638 AVG Validation Loss:0.666 AVG Training Acc 62.74 % AVG Validation Acc 60.65 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.638 AVG Validation Loss:0.668 AVG Training Acc 62.44 % AVG Validation Acc 60.47 %\n",
      "Epoch:130/200 AVG Training Loss:0.639 AVG Validation Loss:0.669 AVG Training Acc 62.37 % AVG Validation Acc 60.20 %\n",
      "Epoch:140/200 AVG Training Loss:0.638 AVG Validation Loss:0.668 AVG Training Acc 62.59 % AVG Validation Acc 60.38 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.637 AVG Validation Loss:0.665 AVG Training Acc 62.34 % AVG Validation Acc 60.56 %\n",
      "Epoch:160/200 AVG Training Loss:0.637 AVG Validation Loss:0.667 AVG Training Acc 62.95 % AVG Validation Acc 60.38 %\n",
      "Epoch:170/200 AVG Training Loss:0.639 AVG Validation Loss:0.668 AVG Training Acc 62.62 % AVG Validation Acc 60.47 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.638 AVG Validation Loss:0.666 AVG Training Acc 62.43 % AVG Validation Acc 60.56 %\n",
      "Epoch:190/200 AVG Training Loss:0.637 AVG Validation Loss:0.668 AVG Training Acc 62.19 % AVG Validation Acc 60.38 %\n",
      "Epoch:200/200 AVG Training Loss:0.637 AVG Validation Loss:0.667 AVG Training Acc 62.55 % AVG Validation Acc 60.47 %\n",
      "Split 250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d82fde704de94e9bbf8984022c05db33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.659 AVG Training Acc 61.92 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.657 AVG Training Acc 61.82 % AVG Validation Acc 61.82 %\n",
      "Epoch:30/200 AVG Training Loss:0.658 AVG Validation Loss:0.656 AVG Training Acc 61.87 % AVG Validation Acc 62.00 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.655 AVG Training Acc 61.87 % AVG Validation Acc 62.00 %\n",
      "Epoch:50/200 AVG Training Loss:0.648 AVG Validation Loss:0.658 AVG Training Acc 62.29 % AVG Validation Acc 61.91 %\n",
      "Epoch:60/200 AVG Training Loss:0.644 AVG Validation Loss:0.656 AVG Training Acc 62.37 % AVG Validation Acc 61.82 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.641 AVG Validation Loss:0.661 AVG Training Acc 62.90 % AVG Validation Acc 62.18 %\n",
      "Epoch:80/200 AVG Training Loss:0.639 AVG Validation Loss:0.663 AVG Training Acc 62.80 % AVG Validation Acc 62.36 %\n",
      "Epoch:90/200 AVG Training Loss:0.638 AVG Validation Loss:0.662 AVG Training Acc 63.02 % AVG Validation Acc 62.36 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.639 AVG Validation Loss:0.662 AVG Training Acc 63.14 % AVG Validation Acc 62.36 %\n",
      "Epoch:110/200 AVG Training Loss:0.640 AVG Validation Loss:0.662 AVG Training Acc 63.14 % AVG Validation Acc 62.64 %\n",
      "Epoch:120/200 AVG Training Loss:0.639 AVG Validation Loss:0.663 AVG Training Acc 63.02 % AVG Validation Acc 62.27 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.637 AVG Validation Loss:0.664 AVG Training Acc 63.36 % AVG Validation Acc 62.45 %\n",
      "Epoch:140/200 AVG Training Loss:0.639 AVG Validation Loss:0.664 AVG Training Acc 63.06 % AVG Validation Acc 62.45 %\n",
      "Epoch:150/200 AVG Training Loss:0.638 AVG Validation Loss:0.663 AVG Training Acc 62.81 % AVG Validation Acc 62.45 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.637 AVG Validation Loss:0.663 AVG Training Acc 63.06 % AVG Validation Acc 62.45 %\n",
      "Epoch:170/200 AVG Training Loss:0.638 AVG Validation Loss:0.664 AVG Training Acc 63.24 % AVG Validation Acc 62.45 %\n",
      "Epoch:180/200 AVG Training Loss:0.638 AVG Validation Loss:0.661 AVG Training Acc 62.95 % AVG Validation Acc 62.64 %\n",
      "Epoch:190/200 AVG Training Loss:0.637 AVG Validation Loss:0.662 AVG Training Acc 63.10 % AVG Validation Acc 62.09 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.638 AVG Validation Loss:0.662 AVG Training Acc 63.07 % AVG Validation Acc 62.27 %\n",
      "Split 251\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d503a58acd1403bb879bea072b55268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.659 AVG Training Acc 61.93 % AVG Validation Acc 61.95 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.662 AVG Training Acc 61.95 % AVG Validation Acc 61.50 %\n",
      "Epoch:30/200 AVG Training Loss:0.652 AVG Validation Loss:0.664 AVG Training Acc 61.92 % AVG Validation Acc 61.41 %\n",
      "Epoch:40/200 AVG Training Loss:0.648 AVG Validation Loss:0.667 AVG Training Acc 62.13 % AVG Validation Acc 61.32 %\n",
      "Epoch:50/200 AVG Training Loss:0.645 AVG Validation Loss:0.671 AVG Training Acc 62.09 % AVG Validation Acc 61.05 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.641 AVG Validation Loss:0.674 AVG Training Acc 62.27 % AVG Validation Acc 61.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.641 AVG Validation Loss:0.675 AVG Training Acc 62.29 % AVG Validation Acc 60.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.640 AVG Validation Loss:0.677 AVG Training Acc 62.40 % AVG Validation Acc 61.05 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.638 AVG Validation Loss:0.677 AVG Training Acc 62.64 % AVG Validation Acc 61.05 %\n",
      "Epoch:100/200 AVG Training Loss:0.639 AVG Validation Loss:0.678 AVG Training Acc 62.57 % AVG Validation Acc 61.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.640 AVG Validation Loss:0.678 AVG Training Acc 62.40 % AVG Validation Acc 61.05 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.639 AVG Validation Loss:0.678 AVG Training Acc 62.42 % AVG Validation Acc 60.96 %\n",
      "Epoch:130/200 AVG Training Loss:0.640 AVG Validation Loss:0.677 AVG Training Acc 62.32 % AVG Validation Acc 61.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.637 AVG Validation Loss:0.677 AVG Training Acc 62.61 % AVG Validation Acc 61.14 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.639 AVG Validation Loss:0.677 AVG Training Acc 62.52 % AVG Validation Acc 61.05 %\n",
      "Epoch:160/200 AVG Training Loss:0.640 AVG Validation Loss:0.677 AVG Training Acc 62.59 % AVG Validation Acc 61.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.639 AVG Validation Loss:0.678 AVG Training Acc 62.39 % AVG Validation Acc 61.05 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.639 AVG Validation Loss:0.677 AVG Training Acc 62.36 % AVG Validation Acc 60.96 %\n",
      "Epoch:190/200 AVG Training Loss:0.640 AVG Validation Loss:0.678 AVG Training Acc 62.31 % AVG Validation Acc 61.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.640 AVG Validation Loss:0.678 AVG Training Acc 62.53 % AVG Validation Acc 61.14 %\n",
      "Split 252\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6528f628e241e38f314bf708ad54ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.660 AVG Training Acc 61.87 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.660 AVG Training Acc 61.97 % AVG Validation Acc 62.04 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.659 AVG Training Acc 61.98 % AVG Validation Acc 61.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.662 AVG Training Acc 62.17 % AVG Validation Acc 61.59 %\n",
      "Epoch:50/200 AVG Training Loss:0.650 AVG Validation Loss:0.670 AVG Training Acc 62.42 % AVG Validation Acc 61.14 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.647 AVG Validation Loss:0.674 AVG Training Acc 62.41 % AVG Validation Acc 61.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.645 AVG Validation Loss:0.676 AVG Training Acc 62.49 % AVG Validation Acc 61.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.645 AVG Validation Loss:0.677 AVG Training Acc 62.52 % AVG Validation Acc 61.05 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.645 AVG Validation Loss:0.677 AVG Training Acc 62.53 % AVG Validation Acc 61.23 %\n",
      "Epoch:100/200 AVG Training Loss:0.646 AVG Validation Loss:0.679 AVG Training Acc 62.44 % AVG Validation Acc 61.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.645 AVG Validation Loss:0.679 AVG Training Acc 62.64 % AVG Validation Acc 61.14 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.645 AVG Validation Loss:0.679 AVG Training Acc 62.56 % AVG Validation Acc 61.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.645 AVG Validation Loss:0.678 AVG Training Acc 62.54 % AVG Validation Acc 61.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.643 AVG Validation Loss:0.678 AVG Training Acc 62.62 % AVG Validation Acc 61.14 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.645 AVG Validation Loss:0.677 AVG Training Acc 62.50 % AVG Validation Acc 61.23 %\n",
      "Epoch:160/200 AVG Training Loss:0.645 AVG Validation Loss:0.678 AVG Training Acc 62.56 % AVG Validation Acc 61.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.644 AVG Validation Loss:0.677 AVG Training Acc 62.52 % AVG Validation Acc 61.14 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.645 AVG Validation Loss:0.678 AVG Training Acc 62.49 % AVG Validation Acc 61.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.645 AVG Validation Loss:0.678 AVG Training Acc 62.56 % AVG Validation Acc 61.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.644 AVG Validation Loss:0.678 AVG Training Acc 62.57 % AVG Validation Acc 61.14 %\n",
      "Split 253\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30125f50e7de4ac9b318c0d4e12ad690",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.664 AVG Training Acc 61.92 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.663 AVG Training Acc 61.95 % AVG Validation Acc 61.86 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.652 AVG Validation Loss:0.666 AVG Training Acc 62.09 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.649 AVG Validation Loss:0.672 AVG Training Acc 61.96 % AVG Validation Acc 61.77 %\n",
      "Epoch:50/200 AVG Training Loss:0.646 AVG Validation Loss:0.680 AVG Training Acc 62.53 % AVG Validation Acc 61.41 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.641 AVG Validation Loss:0.692 AVG Training Acc 62.41 % AVG Validation Acc 60.96 %\n",
      "Epoch:70/200 AVG Training Loss:0.637 AVG Validation Loss:0.694 AVG Training Acc 62.86 % AVG Validation Acc 61.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.639 AVG Validation Loss:0.697 AVG Training Acc 62.63 % AVG Validation Acc 61.05 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.638 AVG Validation Loss:0.698 AVG Training Acc 62.50 % AVG Validation Acc 60.60 %\n",
      "Epoch:100/200 AVG Training Loss:0.637 AVG Validation Loss:0.699 AVG Training Acc 62.74 % AVG Validation Acc 60.69 %\n",
      "Epoch:110/200 AVG Training Loss:0.637 AVG Validation Loss:0.697 AVG Training Acc 62.84 % AVG Validation Acc 60.78 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.638 AVG Validation Loss:0.699 AVG Training Acc 62.80 % AVG Validation Acc 60.78 %\n",
      "Epoch:130/200 AVG Training Loss:0.636 AVG Validation Loss:0.699 AVG Training Acc 62.79 % AVG Validation Acc 60.69 %\n",
      "Epoch:140/200 AVG Training Loss:0.637 AVG Validation Loss:0.699 AVG Training Acc 62.74 % AVG Validation Acc 60.60 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.637 AVG Validation Loss:0.698 AVG Training Acc 62.93 % AVG Validation Acc 60.78 %\n",
      "Epoch:160/200 AVG Training Loss:0.635 AVG Validation Loss:0.700 AVG Training Acc 62.70 % AVG Validation Acc 60.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.636 AVG Validation Loss:0.700 AVG Training Acc 62.78 % AVG Validation Acc 60.50 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.636 AVG Validation Loss:0.698 AVG Training Acc 62.62 % AVG Validation Acc 60.69 %\n",
      "Epoch:190/200 AVG Training Loss:0.636 AVG Validation Loss:0.698 AVG Training Acc 62.76 % AVG Validation Acc 60.78 %\n",
      "Epoch:200/200 AVG Training Loss:0.636 AVG Validation Loss:0.699 AVG Training Acc 62.65 % AVG Validation Acc 60.23 %\n",
      "Split 254\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7852850527944649110e5481b9ad8b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.658 AVG Training Acc 61.79 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.657 AVG Training Acc 61.89 % AVG Validation Acc 61.77 %\n",
      "Epoch:30/200 AVG Training Loss:0.659 AVG Validation Loss:0.660 AVG Training Acc 61.81 % AVG Validation Acc 61.86 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.650 AVG Validation Loss:0.661 AVG Training Acc 62.20 % AVG Validation Acc 61.77 %\n",
      "Epoch:50/200 AVG Training Loss:0.646 AVG Validation Loss:0.662 AVG Training Acc 62.23 % AVG Validation Acc 61.86 %\n",
      "Epoch:60/200 AVG Training Loss:0.641 AVG Validation Loss:0.665 AVG Training Acc 61.95 % AVG Validation Acc 61.86 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.637 AVG Validation Loss:0.667 AVG Training Acc 62.38 % AVG Validation Acc 61.95 %\n",
      "Epoch:80/200 AVG Training Loss:0.639 AVG Validation Loss:0.666 AVG Training Acc 62.02 % AVG Validation Acc 62.04 %\n",
      "Epoch:90/200 AVG Training Loss:0.639 AVG Validation Loss:0.667 AVG Training Acc 62.40 % AVG Validation Acc 62.13 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.638 AVG Validation Loss:0.668 AVG Training Acc 62.25 % AVG Validation Acc 62.13 %\n",
      "Epoch:110/200 AVG Training Loss:0.638 AVG Validation Loss:0.668 AVG Training Acc 62.21 % AVG Validation Acc 62.13 %\n",
      "Epoch:120/200 AVG Training Loss:0.637 AVG Validation Loss:0.668 AVG Training Acc 62.51 % AVG Validation Acc 62.13 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.637 AVG Validation Loss:0.669 AVG Training Acc 62.12 % AVG Validation Acc 62.04 %\n",
      "Epoch:140/200 AVG Training Loss:0.638 AVG Validation Loss:0.667 AVG Training Acc 62.24 % AVG Validation Acc 62.22 %\n",
      "Epoch:150/200 AVG Training Loss:0.637 AVG Validation Loss:0.667 AVG Training Acc 61.98 % AVG Validation Acc 62.22 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.637 AVG Validation Loss:0.668 AVG Training Acc 62.12 % AVG Validation Acc 62.04 %\n",
      "Epoch:170/200 AVG Training Loss:0.638 AVG Validation Loss:0.669 AVG Training Acc 62.10 % AVG Validation Acc 62.13 %\n",
      "Epoch:180/200 AVG Training Loss:0.637 AVG Validation Loss:0.667 AVG Training Acc 62.27 % AVG Validation Acc 61.86 %\n",
      "Epoch:190/200 AVG Training Loss:0.636 AVG Validation Loss:0.668 AVG Training Acc 62.21 % AVG Validation Acc 62.22 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.638 AVG Validation Loss:0.667 AVG Training Acc 62.30 % AVG Validation Acc 62.04 %\n",
      "Split 255\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12306b0231a94bbc8b3d1b17556c2912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.660 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.658 AVG Validation Loss:0.666 AVG Training Acc 61.88 % AVG Validation Acc 61.86 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.666 AVG Training Acc 62.00 % AVG Validation Acc 61.68 %\n",
      "Epoch:50/200 AVG Training Loss:0.651 AVG Validation Loss:0.669 AVG Training Acc 62.16 % AVG Validation Acc 61.59 %\n",
      "Epoch:60/200 AVG Training Loss:0.647 AVG Validation Loss:0.683 AVG Training Acc 62.21 % AVG Validation Acc 61.41 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.642 AVG Validation Loss:0.684 AVG Training Acc 62.55 % AVG Validation Acc 61.32 %\n",
      "Epoch:80/200 AVG Training Loss:0.644 AVG Validation Loss:0.687 AVG Training Acc 62.53 % AVG Validation Acc 61.23 %\n",
      "Epoch:90/200 AVG Training Loss:0.643 AVG Validation Loss:0.687 AVG Training Acc 62.54 % AVG Validation Acc 61.23 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.642 AVG Validation Loss:0.688 AVG Training Acc 62.60 % AVG Validation Acc 61.32 %\n",
      "Epoch:110/200 AVG Training Loss:0.642 AVG Validation Loss:0.688 AVG Training Acc 62.57 % AVG Validation Acc 61.41 %\n",
      "Epoch:120/200 AVG Training Loss:0.642 AVG Validation Loss:0.689 AVG Training Acc 62.47 % AVG Validation Acc 61.41 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.641 AVG Validation Loss:0.689 AVG Training Acc 62.55 % AVG Validation Acc 61.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.642 AVG Validation Loss:0.688 AVG Training Acc 62.45 % AVG Validation Acc 61.32 %\n",
      "Epoch:150/200 AVG Training Loss:0.642 AVG Validation Loss:0.689 AVG Training Acc 62.56 % AVG Validation Acc 61.05 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.643 AVG Validation Loss:0.687 AVG Training Acc 62.45 % AVG Validation Acc 61.32 %\n",
      "Epoch:170/200 AVG Training Loss:0.642 AVG Validation Loss:0.688 AVG Training Acc 62.58 % AVG Validation Acc 61.32 %\n",
      "Epoch:180/200 AVG Training Loss:0.642 AVG Validation Loss:0.688 AVG Training Acc 62.52 % AVG Validation Acc 61.32 %\n",
      "Epoch:190/200 AVG Training Loss:0.642 AVG Validation Loss:0.687 AVG Training Acc 62.48 % AVG Validation Acc 61.41 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.642 AVG Validation Loss:0.688 AVG Training Acc 62.66 % AVG Validation Acc 61.32 %\n",
      "Split 256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bb3b6d4011a42279bcf748e568f3d95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.658 AVG Training Acc 61.87 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.657 AVG Training Acc 61.92 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.654 AVG Training Acc 61.71 % AVG Validation Acc 62.18 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.651 AVG Training Acc 61.85 % AVG Validation Acc 62.18 %\n",
      "Epoch:50/200 AVG Training Loss:0.646 AVG Validation Loss:0.655 AVG Training Acc 62.20 % AVG Validation Acc 61.82 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.632 AVG Validation Loss:0.652 AVG Training Acc 62.86 % AVG Validation Acc 62.27 %\n",
      "Epoch:70/200 AVG Training Loss:0.627 AVG Validation Loss:0.657 AVG Training Acc 63.31 % AVG Validation Acc 62.00 %\n",
      "Epoch:80/200 AVG Training Loss:0.623 AVG Validation Loss:0.662 AVG Training Acc 63.54 % AVG Validation Acc 62.36 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.619 AVG Validation Loss:0.657 AVG Training Acc 64.03 % AVG Validation Acc 62.09 %\n",
      "Epoch:100/200 AVG Training Loss:0.619 AVG Validation Loss:0.657 AVG Training Acc 64.13 % AVG Validation Acc 61.73 %\n",
      "Epoch:110/200 AVG Training Loss:0.618 AVG Validation Loss:0.667 AVG Training Acc 64.09 % AVG Validation Acc 61.46 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.615 AVG Validation Loss:0.661 AVG Training Acc 64.22 % AVG Validation Acc 61.91 %\n",
      "Epoch:130/200 AVG Training Loss:0.617 AVG Validation Loss:0.659 AVG Training Acc 63.95 % AVG Validation Acc 62.00 %\n",
      "Epoch:140/200 AVG Training Loss:0.619 AVG Validation Loss:0.667 AVG Training Acc 63.97 % AVG Validation Acc 61.91 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.616 AVG Validation Loss:0.667 AVG Training Acc 63.99 % AVG Validation Acc 62.09 %\n",
      "Epoch:160/200 AVG Training Loss:0.617 AVG Validation Loss:0.656 AVG Training Acc 64.07 % AVG Validation Acc 62.18 %\n",
      "Epoch:170/200 AVG Training Loss:0.617 AVG Validation Loss:0.667 AVG Training Acc 64.10 % AVG Validation Acc 61.55 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.618 AVG Validation Loss:0.659 AVG Training Acc 63.99 % AVG Validation Acc 62.00 %\n",
      "Epoch:190/200 AVG Training Loss:0.617 AVG Validation Loss:0.662 AVG Training Acc 63.92 % AVG Validation Acc 61.73 %\n",
      "Epoch:200/200 AVG Training Loss:0.617 AVG Validation Loss:0.662 AVG Training Acc 63.88 % AVG Validation Acc 61.64 %\n",
      "Split 257\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65a4ce5b901e4e3bb83ff86d239737ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.661 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.660 AVG Training Acc 61.91 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.661 AVG Training Acc 61.73 % AVG Validation Acc 62.00 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.648 AVG Validation Loss:0.662 AVG Training Acc 61.83 % AVG Validation Acc 61.82 %\n",
      "Epoch:50/200 AVG Training Loss:0.643 AVG Validation Loss:0.666 AVG Training Acc 62.33 % AVG Validation Acc 61.64 %\n",
      "Epoch:60/200 AVG Training Loss:0.641 AVG Validation Loss:0.671 AVG Training Acc 62.46 % AVG Validation Acc 61.46 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.637 AVG Validation Loss:0.671 AVG Training Acc 62.57 % AVG Validation Acc 61.19 %\n",
      "Epoch:80/200 AVG Training Loss:0.637 AVG Validation Loss:0.674 AVG Training Acc 62.75 % AVG Validation Acc 61.46 %\n",
      "Epoch:90/200 AVG Training Loss:0.634 AVG Validation Loss:0.675 AVG Training Acc 62.69 % AVG Validation Acc 61.01 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.636 AVG Validation Loss:0.675 AVG Training Acc 62.52 % AVG Validation Acc 61.01 %\n",
      "Epoch:110/200 AVG Training Loss:0.635 AVG Validation Loss:0.674 AVG Training Acc 62.67 % AVG Validation Acc 60.92 %\n",
      "Epoch:120/200 AVG Training Loss:0.634 AVG Validation Loss:0.674 AVG Training Acc 62.45 % AVG Validation Acc 60.92 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.637 AVG Validation Loss:0.674 AVG Training Acc 62.71 % AVG Validation Acc 61.10 %\n",
      "Epoch:140/200 AVG Training Loss:0.635 AVG Validation Loss:0.676 AVG Training Acc 62.51 % AVG Validation Acc 60.83 %\n",
      "Epoch:150/200 AVG Training Loss:0.635 AVG Validation Loss:0.676 AVG Training Acc 62.43 % AVG Validation Acc 61.10 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.635 AVG Validation Loss:0.678 AVG Training Acc 62.78 % AVG Validation Acc 61.10 %\n",
      "Epoch:170/200 AVG Training Loss:0.637 AVG Validation Loss:0.676 AVG Training Acc 62.59 % AVG Validation Acc 60.83 %\n",
      "Epoch:180/200 AVG Training Loss:0.635 AVG Validation Loss:0.676 AVG Training Acc 62.56 % AVG Validation Acc 61.10 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.636 AVG Validation Loss:0.675 AVG Training Acc 62.82 % AVG Validation Acc 61.19 %\n",
      "Epoch:200/200 AVG Training Loss:0.635 AVG Validation Loss:0.676 AVG Training Acc 62.69 % AVG Validation Acc 60.92 %\n",
      "Split 258\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7e12edb0be44a48f6d5cff335e9345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.661 AVG Training Acc 61.92 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 61.76 % AVG Validation Acc 61.91 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.661 AVG Training Acc 61.99 % AVG Validation Acc 61.91 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.663 AVG Training Acc 61.95 % AVG Validation Acc 61.73 %\n",
      "Epoch:50/200 AVG Training Loss:0.650 AVG Validation Loss:0.666 AVG Training Acc 62.00 % AVG Validation Acc 61.73 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.648 AVG Validation Loss:0.666 AVG Training Acc 62.02 % AVG Validation Acc 62.09 %\n",
      "Epoch:70/200 AVG Training Loss:0.648 AVG Validation Loss:0.667 AVG Training Acc 62.16 % AVG Validation Acc 62.18 %\n",
      "Epoch:80/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 62.23 % AVG Validation Acc 62.18 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 62.29 % AVG Validation Acc 62.18 %\n",
      "Epoch:100/200 AVG Training Loss:0.649 AVG Validation Loss:0.667 AVG Training Acc 62.06 % AVG Validation Acc 62.18 %\n",
      "Epoch:110/200 AVG Training Loss:0.648 AVG Validation Loss:0.668 AVG Training Acc 61.98 % AVG Validation Acc 62.18 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 62.24 % AVG Validation Acc 62.18 %\n",
      "Epoch:130/200 AVG Training Loss:0.648 AVG Validation Loss:0.667 AVG Training Acc 62.15 % AVG Validation Acc 62.18 %\n",
      "Epoch:140/200 AVG Training Loss:0.647 AVG Validation Loss:0.667 AVG Training Acc 62.21 % AVG Validation Acc 62.18 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.648 AVG Validation Loss:0.668 AVG Training Acc 62.09 % AVG Validation Acc 62.18 %\n",
      "Epoch:160/200 AVG Training Loss:0.647 AVG Validation Loss:0.668 AVG Training Acc 61.99 % AVG Validation Acc 62.18 %\n",
      "Epoch:170/200 AVG Training Loss:0.647 AVG Validation Loss:0.668 AVG Training Acc 62.08 % AVG Validation Acc 62.18 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.647 AVG Validation Loss:0.668 AVG Training Acc 62.36 % AVG Validation Acc 62.18 %\n",
      "Epoch:190/200 AVG Training Loss:0.648 AVG Validation Loss:0.668 AVG Training Acc 62.02 % AVG Validation Acc 62.18 %\n",
      "Epoch:200/200 AVG Training Loss:0.648 AVG Validation Loss:0.668 AVG Training Acc 62.27 % AVG Validation Acc 62.18 %\n",
      "Split 259\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "658eb22b9e4949c38890dfbe06bb9323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 61.91 % AVG Validation Acc 62.00 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.665 AVG Training Acc 61.85 % AVG Validation Acc 61.91 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.652 AVG Validation Loss:0.666 AVG Training Acc 62.06 % AVG Validation Acc 62.00 %\n",
      "Epoch:40/200 AVG Training Loss:0.649 AVG Validation Loss:0.672 AVG Training Acc 62.12 % AVG Validation Acc 61.82 %\n",
      "Epoch:50/200 AVG Training Loss:0.647 AVG Validation Loss:0.684 AVG Training Acc 62.10 % AVG Validation Acc 61.64 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.644 AVG Validation Loss:0.692 AVG Training Acc 62.15 % AVG Validation Acc 61.73 %\n",
      "Epoch:70/200 AVG Training Loss:0.643 AVG Validation Loss:0.690 AVG Training Acc 62.11 % AVG Validation Acc 61.64 %\n",
      "Epoch:80/200 AVG Training Loss:0.643 AVG Validation Loss:0.694 AVG Training Acc 62.23 % AVG Validation Acc 61.64 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.642 AVG Validation Loss:0.696 AVG Training Acc 62.25 % AVG Validation Acc 61.64 %\n",
      "Epoch:100/200 AVG Training Loss:0.641 AVG Validation Loss:0.696 AVG Training Acc 62.27 % AVG Validation Acc 61.73 %\n",
      "Epoch:110/200 AVG Training Loss:0.642 AVG Validation Loss:0.696 AVG Training Acc 62.17 % AVG Validation Acc 61.73 %\n",
      "Epoch:120/200 AVG Training Loss:0.642 AVG Validation Loss:0.696 AVG Training Acc 62.20 % AVG Validation Acc 61.73 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.642 AVG Validation Loss:0.695 AVG Training Acc 62.22 % AVG Validation Acc 61.73 %\n",
      "Epoch:140/200 AVG Training Loss:0.642 AVG Validation Loss:0.696 AVG Training Acc 62.20 % AVG Validation Acc 61.73 %\n",
      "Epoch:150/200 AVG Training Loss:0.641 AVG Validation Loss:0.697 AVG Training Acc 62.20 % AVG Validation Acc 61.64 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.641 AVG Validation Loss:0.696 AVG Training Acc 62.27 % AVG Validation Acc 61.64 %\n",
      "Epoch:170/200 AVG Training Loss:0.642 AVG Validation Loss:0.696 AVG Training Acc 62.25 % AVG Validation Acc 61.64 %\n",
      "Epoch:180/200 AVG Training Loss:0.641 AVG Validation Loss:0.697 AVG Training Acc 62.23 % AVG Validation Acc 61.64 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.642 AVG Validation Loss:0.697 AVG Training Acc 62.21 % AVG Validation Acc 61.73 %\n",
      "Epoch:200/200 AVG Training Loss:0.642 AVG Validation Loss:0.696 AVG Training Acc 62.26 % AVG Validation Acc 61.73 %\n",
      "Split 260\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "499472eae6d94c7aab4f38b09650e02b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.659 AVG Training Acc 61.86 % AVG Validation Acc 61.91 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.656 AVG Validation Loss:0.660 AVG Training Acc 61.96 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.660 AVG Training Acc 61.94 % AVG Validation Acc 61.73 %\n",
      "Epoch:40/200 AVG Training Loss:0.654 AVG Validation Loss:0.660 AVG Training Acc 62.04 % AVG Validation Acc 61.64 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.652 AVG Validation Loss:0.659 AVG Training Acc 62.08 % AVG Validation Acc 61.73 %\n",
      "Epoch:60/200 AVG Training Loss:0.651 AVG Validation Loss:0.659 AVG Training Acc 62.03 % AVG Validation Acc 61.82 %\n",
      "Epoch:70/200 AVG Training Loss:0.652 AVG Validation Loss:0.659 AVG Training Acc 61.99 % AVG Validation Acc 61.46 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.651 AVG Validation Loss:0.659 AVG Training Acc 62.22 % AVG Validation Acc 61.64 %\n",
      "Epoch:90/200 AVG Training Loss:0.651 AVG Validation Loss:0.659 AVG Training Acc 62.02 % AVG Validation Acc 61.64 %\n",
      "Epoch:100/200 AVG Training Loss:0.651 AVG Validation Loss:0.659 AVG Training Acc 62.20 % AVG Validation Acc 61.55 %\n",
      "Epoch:110/200 AVG Training Loss:0.651 AVG Validation Loss:0.659 AVG Training Acc 62.21 % AVG Validation Acc 61.73 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.651 AVG Validation Loss:0.660 AVG Training Acc 62.17 % AVG Validation Acc 61.46 %\n",
      "Epoch:130/200 AVG Training Loss:0.651 AVG Validation Loss:0.659 AVG Training Acc 62.25 % AVG Validation Acc 61.55 %\n",
      "Epoch:140/200 AVG Training Loss:0.651 AVG Validation Loss:0.659 AVG Training Acc 62.18 % AVG Validation Acc 61.55 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.651 AVG Validation Loss:0.659 AVG Training Acc 62.04 % AVG Validation Acc 61.55 %\n",
      "Epoch:160/200 AVG Training Loss:0.651 AVG Validation Loss:0.659 AVG Training Acc 61.92 % AVG Validation Acc 61.55 %\n",
      "Epoch:170/200 AVG Training Loss:0.651 AVG Validation Loss:0.659 AVG Training Acc 62.16 % AVG Validation Acc 61.46 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.652 AVG Validation Loss:0.659 AVG Training Acc 62.00 % AVG Validation Acc 61.55 %\n",
      "Epoch:190/200 AVG Training Loss:0.651 AVG Validation Loss:0.659 AVG Training Acc 62.26 % AVG Validation Acc 61.55 %\n",
      "Epoch:200/200 AVG Training Loss:0.652 AVG Validation Loss:0.659 AVG Training Acc 62.14 % AVG Validation Acc 61.46 %\n",
      "Split 261\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "618d9322dc4341a8bc3e0ee71530e56d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.661 AVG Training Acc 61.86 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.660 AVG Training Acc 61.80 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.659 AVG Validation Loss:0.659 AVG Training Acc 61.88 % AVG Validation Acc 61.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.656 AVG Validation Loss:0.658 AVG Training Acc 61.75 % AVG Validation Acc 61.95 %\n",
      "Epoch:50/200 AVG Training Loss:0.651 AVG Validation Loss:0.659 AVG Training Acc 61.70 % AVG Validation Acc 61.77 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.641 AVG Validation Loss:0.663 AVG Training Acc 62.96 % AVG Validation Acc 61.50 %\n",
      "Epoch:70/200 AVG Training Loss:0.634 AVG Validation Loss:0.676 AVG Training Acc 63.07 % AVG Validation Acc 61.41 %\n",
      "Epoch:80/200 AVG Training Loss:0.631 AVG Validation Loss:0.686 AVG Training Acc 63.47 % AVG Validation Acc 61.41 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.628 AVG Validation Loss:0.681 AVG Training Acc 63.54 % AVG Validation Acc 61.59 %\n",
      "Epoch:100/200 AVG Training Loss:0.628 AVG Validation Loss:0.680 AVG Training Acc 63.42 % AVG Validation Acc 61.77 %\n",
      "Epoch:110/200 AVG Training Loss:0.627 AVG Validation Loss:0.680 AVG Training Acc 63.65 % AVG Validation Acc 61.77 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.626 AVG Validation Loss:0.681 AVG Training Acc 63.80 % AVG Validation Acc 62.22 %\n",
      "Epoch:130/200 AVG Training Loss:0.626 AVG Validation Loss:0.682 AVG Training Acc 63.82 % AVG Validation Acc 61.86 %\n",
      "Epoch:140/200 AVG Training Loss:0.627 AVG Validation Loss:0.680 AVG Training Acc 63.38 % AVG Validation Acc 62.31 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.625 AVG Validation Loss:0.682 AVG Training Acc 63.70 % AVG Validation Acc 61.86 %\n",
      "Epoch:160/200 AVG Training Loss:0.626 AVG Validation Loss:0.685 AVG Training Acc 63.34 % AVG Validation Acc 61.77 %\n",
      "Epoch:170/200 AVG Training Loss:0.627 AVG Validation Loss:0.684 AVG Training Acc 63.53 % AVG Validation Acc 61.95 %\n",
      "Epoch:180/200 AVG Training Loss:0.626 AVG Validation Loss:0.683 AVG Training Acc 63.66 % AVG Validation Acc 62.04 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.626 AVG Validation Loss:0.685 AVG Training Acc 63.90 % AVG Validation Acc 61.95 %\n",
      "Epoch:200/200 AVG Training Loss:0.626 AVG Validation Loss:0.681 AVG Training Acc 63.17 % AVG Validation Acc 61.86 %\n",
      "Split 262\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3c0efd24d60406d862743a7d17f4a71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.659 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.665 AVG Training Acc 61.91 % AVG Validation Acc 62.04 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.659 AVG Training Acc 61.96 % AVG Validation Acc 61.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.659 AVG Training Acc 61.82 % AVG Validation Acc 62.04 %\n",
      "Epoch:50/200 AVG Training Loss:0.649 AVG Validation Loss:0.662 AVG Training Acc 62.13 % AVG Validation Acc 62.13 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.647 AVG Validation Loss:0.662 AVG Training Acc 62.27 % AVG Validation Acc 62.04 %\n",
      "Epoch:70/200 AVG Training Loss:0.645 AVG Validation Loss:0.663 AVG Training Acc 62.36 % AVG Validation Acc 62.13 %\n",
      "Epoch:80/200 AVG Training Loss:0.646 AVG Validation Loss:0.664 AVG Training Acc 62.15 % AVG Validation Acc 62.04 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.645 AVG Validation Loss:0.663 AVG Training Acc 62.10 % AVG Validation Acc 61.95 %\n",
      "Epoch:100/200 AVG Training Loss:0.646 AVG Validation Loss:0.664 AVG Training Acc 62.06 % AVG Validation Acc 61.86 %\n",
      "Epoch:110/200 AVG Training Loss:0.645 AVG Validation Loss:0.664 AVG Training Acc 62.12 % AVG Validation Acc 61.95 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.645 AVG Validation Loss:0.664 AVG Training Acc 62.31 % AVG Validation Acc 61.95 %\n",
      "Epoch:130/200 AVG Training Loss:0.646 AVG Validation Loss:0.664 AVG Training Acc 62.08 % AVG Validation Acc 61.95 %\n",
      "Epoch:140/200 AVG Training Loss:0.646 AVG Validation Loss:0.664 AVG Training Acc 62.04 % AVG Validation Acc 61.86 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.645 AVG Validation Loss:0.664 AVG Training Acc 62.26 % AVG Validation Acc 61.86 %\n",
      "Epoch:160/200 AVG Training Loss:0.646 AVG Validation Loss:0.664 AVG Training Acc 62.35 % AVG Validation Acc 61.86 %\n",
      "Epoch:170/200 AVG Training Loss:0.646 AVG Validation Loss:0.664 AVG Training Acc 62.39 % AVG Validation Acc 61.95 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.646 AVG Validation Loss:0.664 AVG Training Acc 62.02 % AVG Validation Acc 61.95 %\n",
      "Epoch:190/200 AVG Training Loss:0.645 AVG Validation Loss:0.664 AVG Training Acc 62.35 % AVG Validation Acc 61.86 %\n",
      "Epoch:200/200 AVG Training Loss:0.647 AVG Validation Loss:0.664 AVG Training Acc 61.87 % AVG Validation Acc 61.86 %\n",
      "Split 263\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e783ac9d65174d4da95b6906de19a3da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.661 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.661 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.662 AVG Training Acc 61.96 % AVG Validation Acc 61.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.654 AVG Validation Loss:0.664 AVG Training Acc 61.97 % AVG Validation Acc 61.86 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.651 AVG Validation Loss:0.665 AVG Training Acc 62.21 % AVG Validation Acc 61.95 %\n",
      "Epoch:60/200 AVG Training Loss:0.650 AVG Validation Loss:0.665 AVG Training Acc 61.99 % AVG Validation Acc 61.86 %\n",
      "Epoch:70/200 AVG Training Loss:0.650 AVG Validation Loss:0.666 AVG Training Acc 61.86 % AVG Validation Acc 61.95 %\n",
      "Epoch:80/200 AVG Training Loss:0.650 AVG Validation Loss:0.666 AVG Training Acc 61.91 % AVG Validation Acc 61.95 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 62.01 % AVG Validation Acc 61.95 %\n",
      "Epoch:100/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 62.11 % AVG Validation Acc 61.86 %\n",
      "Epoch:110/200 AVG Training Loss:0.650 AVG Validation Loss:0.666 AVG Training Acc 61.97 % AVG Validation Acc 62.04 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 62.01 % AVG Validation Acc 61.95 %\n",
      "Epoch:130/200 AVG Training Loss:0.648 AVG Validation Loss:0.665 AVG Training Acc 62.12 % AVG Validation Acc 61.68 %\n",
      "Epoch:140/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 62.11 % AVG Validation Acc 61.95 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.650 AVG Validation Loss:0.666 AVG Training Acc 61.84 % AVG Validation Acc 61.86 %\n",
      "Epoch:160/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 62.21 % AVG Validation Acc 61.86 %\n",
      "Epoch:170/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 61.91 % AVG Validation Acc 61.95 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 62.02 % AVG Validation Acc 61.95 %\n",
      "Epoch:190/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 62.10 % AVG Validation Acc 61.86 %\n",
      "Epoch:200/200 AVG Training Loss:0.649 AVG Validation Loss:0.665 AVG Training Acc 62.19 % AVG Validation Acc 61.86 %\n",
      "Split 264\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "122042398d2b472a85d89d31f09ac5cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.660 AVG Training Acc 61.86 % AVG Validation Acc 61.86 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.656 AVG Validation Loss:0.661 AVG Training Acc 61.93 % AVG Validation Acc 61.77 %\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.662 AVG Training Acc 61.98 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.649 AVG Validation Loss:0.671 AVG Training Acc 62.03 % AVG Validation Acc 61.68 %\n",
      "Epoch:50/200 AVG Training Loss:0.642 AVG Validation Loss:0.681 AVG Training Acc 62.28 % AVG Validation Acc 61.50 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.639 AVG Validation Loss:0.681 AVG Training Acc 62.08 % AVG Validation Acc 61.50 %\n",
      "Epoch:70/200 AVG Training Loss:0.636 AVG Validation Loss:0.683 AVG Training Acc 62.33 % AVG Validation Acc 61.50 %\n",
      "Epoch:80/200 AVG Training Loss:0.636 AVG Validation Loss:0.685 AVG Training Acc 62.45 % AVG Validation Acc 61.41 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.635 AVG Validation Loss:0.685 AVG Training Acc 62.71 % AVG Validation Acc 61.41 %\n",
      "Epoch:100/200 AVG Training Loss:0.637 AVG Validation Loss:0.685 AVG Training Acc 62.63 % AVG Validation Acc 61.41 %\n",
      "Epoch:110/200 AVG Training Loss:0.636 AVG Validation Loss:0.686 AVG Training Acc 62.59 % AVG Validation Acc 61.41 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.634 AVG Validation Loss:0.686 AVG Training Acc 62.60 % AVG Validation Acc 61.41 %\n",
      "Epoch:130/200 AVG Training Loss:0.635 AVG Validation Loss:0.685 AVG Training Acc 62.50 % AVG Validation Acc 61.41 %\n",
      "Epoch:140/200 AVG Training Loss:0.636 AVG Validation Loss:0.685 AVG Training Acc 62.46 % AVG Validation Acc 61.41 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.636 AVG Validation Loss:0.685 AVG Training Acc 62.52 % AVG Validation Acc 61.41 %\n",
      "Epoch:160/200 AVG Training Loss:0.636 AVG Validation Loss:0.685 AVG Training Acc 62.53 % AVG Validation Acc 61.41 %\n",
      "Epoch:170/200 AVG Training Loss:0.636 AVG Validation Loss:0.685 AVG Training Acc 62.86 % AVG Validation Acc 61.41 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.637 AVG Validation Loss:0.685 AVG Training Acc 62.29 % AVG Validation Acc 61.32 %\n",
      "Epoch:190/200 AVG Training Loss:0.635 AVG Validation Loss:0.685 AVG Training Acc 62.62 % AVG Validation Acc 61.41 %\n",
      "Epoch:200/200 AVG Training Loss:0.637 AVG Validation Loss:0.685 AVG Training Acc 62.61 % AVG Validation Acc 61.41 %\n",
      "Split 265\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d4bd98ec8cc40d9aba969fa53b1ba2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.653 AVG Training Acc 61.88 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.652 AVG Training Acc 61.88 % AVG Validation Acc 61.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.655 AVG Training Acc 61.73 % AVG Validation Acc 61.86 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.656 AVG Training Acc 62.13 % AVG Validation Acc 61.50 %\n",
      "Epoch:50/200 AVG Training Loss:0.648 AVG Validation Loss:0.658 AVG Training Acc 62.12 % AVG Validation Acc 61.23 %\n",
      "Epoch:60/200 AVG Training Loss:0.646 AVG Validation Loss:0.662 AVG Training Acc 62.67 % AVG Validation Acc 61.32 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.644 AVG Validation Loss:0.665 AVG Training Acc 62.72 % AVG Validation Acc 61.32 %\n",
      "Epoch:80/200 AVG Training Loss:0.643 AVG Validation Loss:0.666 AVG Training Acc 62.79 % AVG Validation Acc 60.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.642 AVG Validation Loss:0.667 AVG Training Acc 62.81 % AVG Validation Acc 60.87 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.644 AVG Validation Loss:0.668 AVG Training Acc 62.32 % AVG Validation Acc 60.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.642 AVG Validation Loss:0.667 AVG Training Acc 62.51 % AVG Validation Acc 60.96 %\n",
      "Epoch:120/200 AVG Training Loss:0.641 AVG Validation Loss:0.667 AVG Training Acc 62.82 % AVG Validation Acc 60.96 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.643 AVG Validation Loss:0.667 AVG Training Acc 62.72 % AVG Validation Acc 60.69 %\n",
      "Epoch:140/200 AVG Training Loss:0.643 AVG Validation Loss:0.667 AVG Training Acc 62.73 % AVG Validation Acc 61.05 %\n",
      "Epoch:150/200 AVG Training Loss:0.643 AVG Validation Loss:0.667 AVG Training Acc 62.57 % AVG Validation Acc 60.96 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.643 AVG Validation Loss:0.667 AVG Training Acc 62.57 % AVG Validation Acc 60.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.641 AVG Validation Loss:0.668 AVG Training Acc 62.75 % AVG Validation Acc 60.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.643 AVG Validation Loss:0.667 AVG Training Acc 62.41 % AVG Validation Acc 60.87 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.642 AVG Validation Loss:0.667 AVG Training Acc 62.63 % AVG Validation Acc 60.96 %\n",
      "Epoch:200/200 AVG Training Loss:0.642 AVG Validation Loss:0.667 AVG Training Acc 62.73 % AVG Validation Acc 60.96 %\n",
      "Split 266\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f10d671fe40e458589a765b93927e020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.657 AVG Training Acc 61.86 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.654 AVG Training Acc 61.90 % AVG Validation Acc 61.82 %\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.656 AVG Training Acc 61.93 % AVG Validation Acc 61.91 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.655 AVG Training Acc 62.10 % AVG Validation Acc 61.46 %\n",
      "Epoch:50/200 AVG Training Loss:0.649 AVG Validation Loss:0.656 AVG Training Acc 62.11 % AVG Validation Acc 61.46 %\n",
      "Epoch:60/200 AVG Training Loss:0.645 AVG Validation Loss:0.658 AVG Training Acc 62.27 % AVG Validation Acc 61.28 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.644 AVG Validation Loss:0.659 AVG Training Acc 62.19 % AVG Validation Acc 61.46 %\n",
      "Epoch:80/200 AVG Training Loss:0.643 AVG Validation Loss:0.659 AVG Training Acc 62.36 % AVG Validation Acc 61.37 %\n",
      "Epoch:90/200 AVG Training Loss:0.643 AVG Validation Loss:0.659 AVG Training Acc 62.01 % AVG Validation Acc 61.46 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.643 AVG Validation Loss:0.660 AVG Training Acc 62.17 % AVG Validation Acc 61.37 %\n",
      "Epoch:110/200 AVG Training Loss:0.642 AVG Validation Loss:0.659 AVG Training Acc 62.33 % AVG Validation Acc 61.55 %\n",
      "Epoch:120/200 AVG Training Loss:0.643 AVG Validation Loss:0.659 AVG Training Acc 62.39 % AVG Validation Acc 61.55 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.642 AVG Validation Loss:0.659 AVG Training Acc 62.18 % AVG Validation Acc 61.46 %\n",
      "Epoch:140/200 AVG Training Loss:0.644 AVG Validation Loss:0.660 AVG Training Acc 62.23 % AVG Validation Acc 61.55 %\n",
      "Epoch:150/200 AVG Training Loss:0.642 AVG Validation Loss:0.659 AVG Training Acc 62.27 % AVG Validation Acc 61.46 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.642 AVG Validation Loss:0.660 AVG Training Acc 62.33 % AVG Validation Acc 61.55 %\n",
      "Epoch:170/200 AVG Training Loss:0.643 AVG Validation Loss:0.659 AVG Training Acc 62.04 % AVG Validation Acc 61.46 %\n",
      "Epoch:180/200 AVG Training Loss:0.642 AVG Validation Loss:0.659 AVG Training Acc 62.52 % AVG Validation Acc 61.55 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.642 AVG Validation Loss:0.659 AVG Training Acc 62.21 % AVG Validation Acc 61.46 %\n",
      "Epoch:200/200 AVG Training Loss:0.642 AVG Validation Loss:0.659 AVG Training Acc 62.46 % AVG Validation Acc 61.37 %\n",
      "Split 267\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "117795f79e1b4d8dacf7748bc1b52df0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.662 AVG Training Acc 61.79 % AVG Validation Acc 62.00 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.652 AVG Validation Loss:0.669 AVG Training Acc 62.01 % AVG Validation Acc 61.82 %\n",
      "Epoch:40/200 AVG Training Loss:0.648 AVG Validation Loss:0.672 AVG Training Acc 61.97 % AVG Validation Acc 61.82 %\n",
      "Epoch:50/200 AVG Training Loss:0.644 AVG Validation Loss:0.680 AVG Training Acc 62.30 % AVG Validation Acc 61.46 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.640 AVG Validation Loss:0.685 AVG Training Acc 62.60 % AVG Validation Acc 61.55 %\n",
      "Epoch:70/200 AVG Training Loss:0.639 AVG Validation Loss:0.684 AVG Training Acc 62.44 % AVG Validation Acc 61.64 %\n",
      "Epoch:80/200 AVG Training Loss:0.640 AVG Validation Loss:0.685 AVG Training Acc 62.70 % AVG Validation Acc 61.37 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.637 AVG Validation Loss:0.686 AVG Training Acc 62.54 % AVG Validation Acc 61.37 %\n",
      "Epoch:100/200 AVG Training Loss:0.638 AVG Validation Loss:0.685 AVG Training Acc 62.59 % AVG Validation Acc 61.46 %\n",
      "Epoch:110/200 AVG Training Loss:0.637 AVG Validation Loss:0.686 AVG Training Acc 62.66 % AVG Validation Acc 61.55 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.637 AVG Validation Loss:0.686 AVG Training Acc 62.69 % AVG Validation Acc 61.28 %\n",
      "Epoch:130/200 AVG Training Loss:0.637 AVG Validation Loss:0.689 AVG Training Acc 62.62 % AVG Validation Acc 61.37 %\n",
      "Epoch:140/200 AVG Training Loss:0.636 AVG Validation Loss:0.688 AVG Training Acc 62.71 % AVG Validation Acc 61.37 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.637 AVG Validation Loss:0.686 AVG Training Acc 62.72 % AVG Validation Acc 61.46 %\n",
      "Epoch:160/200 AVG Training Loss:0.637 AVG Validation Loss:0.688 AVG Training Acc 62.76 % AVG Validation Acc 61.46 %\n",
      "Epoch:170/200 AVG Training Loss:0.637 AVG Validation Loss:0.690 AVG Training Acc 62.71 % AVG Validation Acc 61.37 %\n",
      "Epoch:180/200 AVG Training Loss:0.638 AVG Validation Loss:0.687 AVG Training Acc 62.58 % AVG Validation Acc 61.55 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.638 AVG Validation Loss:0.689 AVG Training Acc 62.60 % AVG Validation Acc 61.37 %\n",
      "Epoch:200/200 AVG Training Loss:0.638 AVG Validation Loss:0.687 AVG Training Acc 62.61 % AVG Validation Acc 61.55 %\n",
      "Split 268\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04a1f943ab264003bae14cb68a492d5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.664 AVG Training Acc 61.80 % AVG Validation Acc 61.91 %\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:0.669 AVG Training Acc 61.92 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.652 AVG Validation Loss:0.672 AVG Training Acc 61.92 % AVG Validation Acc 61.82 %\n",
      "Epoch:40/200 AVG Training Loss:0.650 AVG Validation Loss:0.675 AVG Training Acc 61.91 % AVG Validation Acc 61.82 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.647 AVG Validation Loss:0.676 AVG Training Acc 62.08 % AVG Validation Acc 61.82 %\n",
      "Epoch:60/200 AVG Training Loss:0.646 AVG Validation Loss:0.677 AVG Training Acc 62.08 % AVG Validation Acc 61.82 %\n",
      "Epoch:70/200 AVG Training Loss:0.645 AVG Validation Loss:0.679 AVG Training Acc 62.03 % AVG Validation Acc 61.82 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.644 AVG Validation Loss:0.679 AVG Training Acc 62.27 % AVG Validation Acc 61.64 %\n",
      "Epoch:90/200 AVG Training Loss:0.645 AVG Validation Loss:0.679 AVG Training Acc 62.16 % AVG Validation Acc 61.73 %\n",
      "Epoch:100/200 AVG Training Loss:0.644 AVG Validation Loss:0.679 AVG Training Acc 62.21 % AVG Validation Acc 61.73 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.643 AVG Validation Loss:0.679 AVG Training Acc 62.14 % AVG Validation Acc 61.73 %\n",
      "Epoch:120/200 AVG Training Loss:0.644 AVG Validation Loss:0.679 AVG Training Acc 62.18 % AVG Validation Acc 61.73 %\n",
      "Epoch:130/200 AVG Training Loss:0.645 AVG Validation Loss:0.679 AVG Training Acc 61.97 % AVG Validation Acc 61.73 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.643 AVG Validation Loss:0.679 AVG Training Acc 62.20 % AVG Validation Acc 61.73 %\n",
      "Epoch:150/200 AVG Training Loss:0.644 AVG Validation Loss:0.679 AVG Training Acc 62.14 % AVG Validation Acc 61.73 %\n",
      "Epoch:160/200 AVG Training Loss:0.645 AVG Validation Loss:0.679 AVG Training Acc 62.13 % AVG Validation Acc 61.73 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.644 AVG Validation Loss:0.679 AVG Training Acc 62.11 % AVG Validation Acc 61.73 %\n",
      "Epoch:180/200 AVG Training Loss:0.645 AVG Validation Loss:0.679 AVG Training Acc 62.06 % AVG Validation Acc 61.73 %\n",
      "Epoch:190/200 AVG Training Loss:0.645 AVG Validation Loss:0.679 AVG Training Acc 61.96 % AVG Validation Acc 61.73 %\n",
      "Epoch:200/200 AVG Training Loss:0.644 AVG Validation Loss:0.679 AVG Training Acc 62.15 % AVG Validation Acc 61.73 %\n",
      "Split 269\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec24f42aee3140e9992588e4cfd77994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.663 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.668 AVG Training Acc 61.72 % AVG Validation Acc 61.91 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.670 AVG Training Acc 61.92 % AVG Validation Acc 61.73 %\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.676 AVG Training Acc 61.98 % AVG Validation Acc 61.55 %\n",
      "Epoch:50/200 AVG Training Loss:0.650 AVG Validation Loss:0.678 AVG Training Acc 61.96 % AVG Validation Acc 61.46 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.647 AVG Validation Loss:0.680 AVG Training Acc 62.12 % AVG Validation Acc 61.46 %\n",
      "Epoch:70/200 AVG Training Loss:0.647 AVG Validation Loss:0.680 AVG Training Acc 62.12 % AVG Validation Acc 61.37 %\n",
      "Epoch:80/200 AVG Training Loss:0.647 AVG Validation Loss:0.681 AVG Training Acc 62.34 % AVG Validation Acc 61.37 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.647 AVG Validation Loss:0.682 AVG Training Acc 62.10 % AVG Validation Acc 61.28 %\n",
      "Epoch:100/200 AVG Training Loss:0.646 AVG Validation Loss:0.681 AVG Training Acc 62.31 % AVG Validation Acc 61.37 %\n",
      "Epoch:110/200 AVG Training Loss:0.646 AVG Validation Loss:0.681 AVG Training Acc 62.26 % AVG Validation Acc 61.19 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.646 AVG Validation Loss:0.682 AVG Training Acc 62.24 % AVG Validation Acc 61.28 %\n",
      "Epoch:130/200 AVG Training Loss:0.647 AVG Validation Loss:0.682 AVG Training Acc 62.28 % AVG Validation Acc 61.19 %\n",
      "Epoch:140/200 AVG Training Loss:0.647 AVG Validation Loss:0.682 AVG Training Acc 62.17 % AVG Validation Acc 61.19 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.646 AVG Validation Loss:0.681 AVG Training Acc 62.33 % AVG Validation Acc 61.19 %\n",
      "Epoch:160/200 AVG Training Loss:0.646 AVG Validation Loss:0.682 AVG Training Acc 62.15 % AVG Validation Acc 61.28 %\n",
      "Epoch:170/200 AVG Training Loss:0.646 AVG Validation Loss:0.681 AVG Training Acc 62.17 % AVG Validation Acc 61.28 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.645 AVG Validation Loss:0.681 AVG Training Acc 62.40 % AVG Validation Acc 61.28 %\n",
      "Epoch:190/200 AVG Training Loss:0.646 AVG Validation Loss:0.681 AVG Training Acc 62.03 % AVG Validation Acc 61.28 %\n",
      "Epoch:200/200 AVG Training Loss:0.646 AVG Validation Loss:0.682 AVG Training Acc 62.37 % AVG Validation Acc 61.28 %\n",
      "Split 270\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "212d0386647544198e0c492490f5e611",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.661 AVG Training Acc 61.80 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.659 AVG Training Acc 61.69 % AVG Validation Acc 61.73 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.648 AVG Validation Loss:0.660 AVG Training Acc 62.25 % AVG Validation Acc 61.73 %\n",
      "Epoch:50/200 AVG Training Loss:0.642 AVG Validation Loss:0.662 AVG Training Acc 62.83 % AVG Validation Acc 61.46 %\n",
      "Epoch:60/200 AVG Training Loss:0.636 AVG Validation Loss:0.663 AVG Training Acc 63.13 % AVG Validation Acc 61.82 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.632 AVG Validation Loss:0.674 AVG Training Acc 63.39 % AVG Validation Acc 61.64 %\n",
      "Epoch:80/200 AVG Training Loss:0.630 AVG Validation Loss:0.675 AVG Training Acc 64.08 % AVG Validation Acc 61.91 %\n",
      "Epoch:90/200 AVG Training Loss:0.628 AVG Validation Loss:0.678 AVG Training Acc 63.62 % AVG Validation Acc 61.91 %\n",
      "Epoch:100/200 AVG Training Loss:0.628 AVG Validation Loss:0.679 AVG Training Acc 64.04 % AVG Validation Acc 61.91 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.627 AVG Validation Loss:0.676 AVG Training Acc 63.92 % AVG Validation Acc 62.27 %\n",
      "Epoch:120/200 AVG Training Loss:0.627 AVG Validation Loss:0.678 AVG Training Acc 63.67 % AVG Validation Acc 62.36 %\n",
      "Epoch:130/200 AVG Training Loss:0.626 AVG Validation Loss:0.677 AVG Training Acc 63.93 % AVG Validation Acc 62.27 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.627 AVG Validation Loss:0.680 AVG Training Acc 63.61 % AVG Validation Acc 62.09 %\n",
      "Epoch:150/200 AVG Training Loss:0.629 AVG Validation Loss:0.676 AVG Training Acc 63.86 % AVG Validation Acc 61.91 %\n",
      "Epoch:160/200 AVG Training Loss:0.629 AVG Validation Loss:0.680 AVG Training Acc 63.81 % AVG Validation Acc 61.64 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.629 AVG Validation Loss:0.679 AVG Training Acc 64.01 % AVG Validation Acc 62.00 %\n",
      "Epoch:180/200 AVG Training Loss:0.627 AVG Validation Loss:0.678 AVG Training Acc 63.95 % AVG Validation Acc 62.09 %\n",
      "Epoch:190/200 AVG Training Loss:0.628 AVG Validation Loss:0.678 AVG Training Acc 63.69 % AVG Validation Acc 62.09 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.628 AVG Validation Loss:0.677 AVG Training Acc 63.76 % AVG Validation Acc 61.82 %\n",
      "Split 271\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93b7bc6ea3b24af69df4b2c1f1eaffcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.657 AVG Training Acc 61.88 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 61.82 % AVG Validation Acc 61.95 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.658 AVG Training Acc 61.87 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.654 AVG Validation Loss:0.659 AVG Training Acc 61.78 % AVG Validation Acc 61.86 %\n",
      "Epoch:50/200 AVG Training Loss:0.653 AVG Validation Loss:0.659 AVG Training Acc 62.06 % AVG Validation Acc 61.77 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.651 AVG Validation Loss:0.664 AVG Training Acc 61.91 % AVG Validation Acc 61.59 %\n",
      "Epoch:70/200 AVG Training Loss:0.649 AVG Validation Loss:0.665 AVG Training Acc 61.96 % AVG Validation Acc 61.59 %\n",
      "Epoch:80/200 AVG Training Loss:0.649 AVG Validation Loss:0.665 AVG Training Acc 61.91 % AVG Validation Acc 61.68 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.650 AVG Validation Loss:0.666 AVG Training Acc 62.00 % AVG Validation Acc 61.50 %\n",
      "Epoch:100/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 62.18 % AVG Validation Acc 61.50 %\n",
      "Epoch:110/200 AVG Training Loss:0.650 AVG Validation Loss:0.666 AVG Training Acc 61.97 % AVG Validation Acc 61.50 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 61.78 % AVG Validation Acc 61.59 %\n",
      "Epoch:130/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 62.00 % AVG Validation Acc 61.50 %\n",
      "Epoch:140/200 AVG Training Loss:0.648 AVG Validation Loss:0.666 AVG Training Acc 62.21 % AVG Validation Acc 61.50 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 62.17 % AVG Validation Acc 61.50 %\n",
      "Epoch:160/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 62.19 % AVG Validation Acc 61.59 %\n",
      "Epoch:170/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 62.07 % AVG Validation Acc 61.59 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 62.08 % AVG Validation Acc 61.50 %\n",
      "Epoch:190/200 AVG Training Loss:0.650 AVG Validation Loss:0.666 AVG Training Acc 61.91 % AVG Validation Acc 61.50 %\n",
      "Epoch:200/200 AVG Training Loss:0.648 AVG Validation Loss:0.666 AVG Training Acc 62.05 % AVG Validation Acc 61.59 %\n",
      "Split 272\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "546f011555784ca0b2f28427bfb3ccb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.659 AVG Training Acc 61.87 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.655 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.654 AVG Training Acc 61.79 % AVG Validation Acc 61.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.654 AVG Training Acc 61.77 % AVG Validation Acc 62.04 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.662 AVG Validation Loss:0.662 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:60/200 AVG Training Loss:0.661 AVG Validation Loss:0.660 AVG Training Acc 61.94 % AVG Validation Acc 61.86 %\n",
      "Epoch:70/200 AVG Training Loss:0.659 AVG Validation Loss:0.660 AVG Training Acc 61.99 % AVG Validation Acc 61.86 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.658 AVG Validation Loss:0.659 AVG Training Acc 61.92 % AVG Validation Acc 61.86 %\n",
      "Epoch:90/200 AVG Training Loss:0.657 AVG Validation Loss:0.658 AVG Training Acc 61.92 % AVG Validation Acc 61.86 %\n",
      "Epoch:100/200 AVG Training Loss:0.657 AVG Validation Loss:0.659 AVG Training Acc 61.95 % AVG Validation Acc 61.86 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.656 AVG Validation Loss:0.658 AVG Training Acc 61.98 % AVG Validation Acc 61.86 %\n",
      "Epoch:120/200 AVG Training Loss:0.656 AVG Validation Loss:0.658 AVG Training Acc 61.98 % AVG Validation Acc 61.86 %\n",
      "Epoch:130/200 AVG Training Loss:0.656 AVG Validation Loss:0.659 AVG Training Acc 61.97 % AVG Validation Acc 61.86 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.657 AVG Validation Loss:0.659 AVG Training Acc 61.96 % AVG Validation Acc 61.86 %\n",
      "Epoch:150/200 AVG Training Loss:0.656 AVG Validation Loss:0.659 AVG Training Acc 61.97 % AVG Validation Acc 61.86 %\n",
      "Epoch:160/200 AVG Training Loss:0.657 AVG Validation Loss:0.659 AVG Training Acc 61.95 % AVG Validation Acc 61.86 %\n",
      "Epoch:170/200 AVG Training Loss:0.656 AVG Validation Loss:0.658 AVG Training Acc 61.98 % AVG Validation Acc 61.86 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.657 AVG Validation Loss:0.658 AVG Training Acc 61.97 % AVG Validation Acc 61.86 %\n",
      "Epoch:190/200 AVG Training Loss:0.657 AVG Validation Loss:0.659 AVG Training Acc 61.98 % AVG Validation Acc 61.86 %\n",
      "Epoch:200/200 AVG Training Loss:0.657 AVG Validation Loss:0.658 AVG Training Acc 62.00 % AVG Validation Acc 61.86 %\n",
      "Split 273\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba15e3a52a141218d15091238151eb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.659 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.660 AVG Training Acc 61.85 % AVG Validation Acc 61.86 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.657 AVG Training Acc 61.94 % AVG Validation Acc 61.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.656 AVG Training Acc 62.06 % AVG Validation Acc 61.68 %\n",
      "Epoch:50/200 AVG Training Loss:0.647 AVG Validation Loss:0.657 AVG Training Acc 61.99 % AVG Validation Acc 61.68 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.643 AVG Validation Loss:0.657 AVG Training Acc 62.59 % AVG Validation Acc 61.68 %\n",
      "Epoch:70/200 AVG Training Loss:0.642 AVG Validation Loss:0.657 AVG Training Acc 62.09 % AVG Validation Acc 61.77 %\n",
      "Epoch:80/200 AVG Training Loss:0.642 AVG Validation Loss:0.657 AVG Training Acc 62.20 % AVG Validation Acc 61.86 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.642 AVG Validation Loss:0.658 AVG Training Acc 62.22 % AVG Validation Acc 61.59 %\n",
      "Epoch:100/200 AVG Training Loss:0.642 AVG Validation Loss:0.658 AVG Training Acc 61.99 % AVG Validation Acc 61.59 %\n",
      "Epoch:110/200 AVG Training Loss:0.641 AVG Validation Loss:0.658 AVG Training Acc 62.44 % AVG Validation Acc 61.77 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.641 AVG Validation Loss:0.657 AVG Training Acc 62.23 % AVG Validation Acc 61.50 %\n",
      "Epoch:130/200 AVG Training Loss:0.640 AVG Validation Loss:0.657 AVG Training Acc 62.75 % AVG Validation Acc 61.59 %\n",
      "Epoch:140/200 AVG Training Loss:0.640 AVG Validation Loss:0.658 AVG Training Acc 62.23 % AVG Validation Acc 61.59 %\n",
      "Epoch:150/200 AVG Training Loss:0.640 AVG Validation Loss:0.658 AVG Training Acc 62.70 % AVG Validation Acc 61.77 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.639 AVG Validation Loss:0.657 AVG Training Acc 62.42 % AVG Validation Acc 61.68 %\n",
      "Epoch:170/200 AVG Training Loss:0.641 AVG Validation Loss:0.657 AVG Training Acc 62.22 % AVG Validation Acc 61.59 %\n",
      "Epoch:180/200 AVG Training Loss:0.640 AVG Validation Loss:0.658 AVG Training Acc 62.51 % AVG Validation Acc 61.77 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.640 AVG Validation Loss:0.658 AVG Training Acc 62.55 % AVG Validation Acc 61.77 %\n",
      "Epoch:200/200 AVG Training Loss:0.640 AVG Validation Loss:0.657 AVG Training Acc 62.83 % AVG Validation Acc 61.77 %\n",
      "Split 274\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae913a5ac2bd4933a1960468924bd7f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.655 AVG Training Acc 61.88 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.654 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.653 AVG Training Acc 61.93 % AVG Validation Acc 61.68 %\n",
      "Epoch:40/200 AVG Training Loss:0.655 AVG Validation Loss:0.653 AVG Training Acc 62.02 % AVG Validation Acc 61.68 %\n",
      "Epoch:50/200 AVG Training Loss:0.653 AVG Validation Loss:0.654 AVG Training Acc 62.15 % AVG Validation Acc 61.59 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.650 AVG Validation Loss:0.656 AVG Training Acc 62.23 % AVG Validation Acc 61.59 %\n",
      "Epoch:70/200 AVG Training Loss:0.648 AVG Validation Loss:0.656 AVG Training Acc 62.23 % AVG Validation Acc 61.59 %\n",
      "Epoch:80/200 AVG Training Loss:0.649 AVG Validation Loss:0.657 AVG Training Acc 62.35 % AVG Validation Acc 61.50 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.648 AVG Validation Loss:0.658 AVG Training Acc 62.27 % AVG Validation Acc 61.50 %\n",
      "Epoch:100/200 AVG Training Loss:0.648 AVG Validation Loss:0.655 AVG Training Acc 62.32 % AVG Validation Acc 61.59 %\n",
      "Epoch:110/200 AVG Training Loss:0.649 AVG Validation Loss:0.657 AVG Training Acc 62.18 % AVG Validation Acc 61.50 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.648 AVG Validation Loss:0.655 AVG Training Acc 62.30 % AVG Validation Acc 61.59 %\n",
      "Epoch:130/200 AVG Training Loss:0.649 AVG Validation Loss:0.657 AVG Training Acc 62.24 % AVG Validation Acc 61.50 %\n",
      "Epoch:140/200 AVG Training Loss:0.649 AVG Validation Loss:0.657 AVG Training Acc 62.29 % AVG Validation Acc 61.50 %\n",
      "Epoch:150/200 AVG Training Loss:0.649 AVG Validation Loss:0.659 AVG Training Acc 62.27 % AVG Validation Acc 61.50 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.648 AVG Validation Loss:0.657 AVG Training Acc 62.35 % AVG Validation Acc 61.50 %\n",
      "Epoch:170/200 AVG Training Loss:0.648 AVG Validation Loss:0.655 AVG Training Acc 62.28 % AVG Validation Acc 61.59 %\n",
      "Epoch:180/200 AVG Training Loss:0.648 AVG Validation Loss:0.658 AVG Training Acc 62.33 % AVG Validation Acc 61.50 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.649 AVG Validation Loss:0.656 AVG Training Acc 62.37 % AVG Validation Acc 61.50 %\n",
      "Epoch:200/200 AVG Training Loss:0.649 AVG Validation Loss:0.659 AVG Training Acc 62.26 % AVG Validation Acc 61.50 %\n",
      "Split 275\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "119c542b090a4f9ab5653f570c88210d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.662 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.659 AVG Training Acc 61.95 % AVG Validation Acc 61.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.660 AVG Training Acc 62.00 % AVG Validation Acc 61.86 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.647 AVG Validation Loss:0.668 AVG Training Acc 61.96 % AVG Validation Acc 61.59 %\n",
      "Epoch:50/200 AVG Training Loss:0.642 AVG Validation Loss:0.673 AVG Training Acc 62.21 % AVG Validation Acc 61.95 %\n",
      "Epoch:60/200 AVG Training Loss:0.639 AVG Validation Loss:0.678 AVG Training Acc 62.78 % AVG Validation Acc 62.31 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.634 AVG Validation Loss:0.686 AVG Training Acc 62.72 % AVG Validation Acc 61.95 %\n",
      "Epoch:80/200 AVG Training Loss:0.631 AVG Validation Loss:0.686 AVG Training Acc 63.07 % AVG Validation Acc 62.13 %\n",
      "Epoch:90/200 AVG Training Loss:0.631 AVG Validation Loss:0.687 AVG Training Acc 62.70 % AVG Validation Acc 61.86 %\n",
      "Epoch:100/200 AVG Training Loss:0.631 AVG Validation Loss:0.687 AVG Training Acc 62.58 % AVG Validation Acc 61.95 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.630 AVG Validation Loss:0.689 AVG Training Acc 62.99 % AVG Validation Acc 61.77 %\n",
      "Epoch:120/200 AVG Training Loss:0.630 AVG Validation Loss:0.689 AVG Training Acc 63.00 % AVG Validation Acc 62.04 %\n",
      "Epoch:130/200 AVG Training Loss:0.631 AVG Validation Loss:0.692 AVG Training Acc 62.45 % AVG Validation Acc 61.86 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.630 AVG Validation Loss:0.692 AVG Training Acc 63.03 % AVG Validation Acc 61.68 %\n",
      "Epoch:150/200 AVG Training Loss:0.630 AVG Validation Loss:0.690 AVG Training Acc 63.08 % AVG Validation Acc 61.59 %\n",
      "Epoch:160/200 AVG Training Loss:0.630 AVG Validation Loss:0.690 AVG Training Acc 62.87 % AVG Validation Acc 61.86 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.631 AVG Validation Loss:0.689 AVG Training Acc 62.78 % AVG Validation Acc 61.86 %\n",
      "Epoch:180/200 AVG Training Loss:0.632 AVG Validation Loss:0.691 AVG Training Acc 62.69 % AVG Validation Acc 61.86 %\n",
      "Epoch:190/200 AVG Training Loss:0.631 AVG Validation Loss:0.690 AVG Training Acc 62.64 % AVG Validation Acc 62.04 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.630 AVG Validation Loss:0.691 AVG Training Acc 62.65 % AVG Validation Acc 61.86 %\n",
      "Split 276\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dc63783f364497e9236bef8d29f1fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.658 AVG Training Acc 61.85 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 61.83 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.661 AVG Validation Loss:0.663 AVG Training Acc 61.61 % AVG Validation Acc 61.82 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.654 AVG Validation Loss:0.656 AVG Training Acc 61.77 % AVG Validation Acc 61.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.654 AVG Validation Loss:0.654 AVG Training Acc 61.76 % AVG Validation Acc 61.91 %\n",
      "Epoch:60/200 AVG Training Loss:0.653 AVG Validation Loss:0.654 AVG Training Acc 61.77 % AVG Validation Acc 61.82 %\n",
      "Epoch:70/200 AVG Training Loss:0.652 AVG Validation Loss:0.654 AVG Training Acc 62.00 % AVG Validation Acc 61.91 %\n",
      "Epoch:80/200 AVG Training Loss:0.649 AVG Validation Loss:0.652 AVG Training Acc 62.01 % AVG Validation Acc 61.91 %\n",
      "Epoch:90/200 AVG Training Loss:0.648 AVG Validation Loss:0.652 AVG Training Acc 62.35 % AVG Validation Acc 62.09 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.645 AVG Validation Loss:0.652 AVG Training Acc 62.13 % AVG Validation Acc 62.00 %\n",
      "Epoch:110/200 AVG Training Loss:0.645 AVG Validation Loss:0.652 AVG Training Acc 62.04 % AVG Validation Acc 62.18 %\n",
      "Epoch:120/200 AVG Training Loss:0.646 AVG Validation Loss:0.651 AVG Training Acc 61.92 % AVG Validation Acc 62.18 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.644 AVG Validation Loss:0.652 AVG Training Acc 62.33 % AVG Validation Acc 62.18 %\n",
      "Epoch:140/200 AVG Training Loss:0.645 AVG Validation Loss:0.652 AVG Training Acc 62.44 % AVG Validation Acc 62.27 %\n",
      "Epoch:150/200 AVG Training Loss:0.646 AVG Validation Loss:0.652 AVG Training Acc 62.00 % AVG Validation Acc 62.36 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.644 AVG Validation Loss:0.652 AVG Training Acc 61.97 % AVG Validation Acc 62.18 %\n",
      "Epoch:170/200 AVG Training Loss:0.644 AVG Validation Loss:0.652 AVG Training Acc 61.83 % AVG Validation Acc 62.18 %\n",
      "Epoch:180/200 AVG Training Loss:0.644 AVG Validation Loss:0.652 AVG Training Acc 62.42 % AVG Validation Acc 62.27 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.645 AVG Validation Loss:0.652 AVG Training Acc 62.08 % AVG Validation Acc 62.18 %\n",
      "Epoch:200/200 AVG Training Loss:0.645 AVG Validation Loss:0.651 AVG Training Acc 62.24 % AVG Validation Acc 62.27 %\n",
      "Split 277\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db74b536cff940acb70d413164102408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.666 AVG Training Acc 61.78 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.666 AVG Training Acc 61.67 % AVG Validation Acc 61.82 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.652 AVG Validation Loss:0.671 AVG Training Acc 62.16 % AVG Validation Acc 61.64 %\n",
      "Epoch:40/200 AVG Training Loss:0.650 AVG Validation Loss:0.673 AVG Training Acc 61.94 % AVG Validation Acc 61.37 %\n",
      "Epoch:50/200 AVG Training Loss:0.648 AVG Validation Loss:0.676 AVG Training Acc 62.33 % AVG Validation Acc 61.82 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.645 AVG Validation Loss:0.672 AVG Training Acc 62.31 % AVG Validation Acc 61.46 %\n",
      "Epoch:70/200 AVG Training Loss:0.645 AVG Validation Loss:0.675 AVG Training Acc 62.29 % AVG Validation Acc 61.28 %\n",
      "Epoch:80/200 AVG Training Loss:0.643 AVG Validation Loss:0.681 AVG Training Acc 62.42 % AVG Validation Acc 60.29 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.642 AVG Validation Loss:0.681 AVG Training Acc 62.46 % AVG Validation Acc 60.38 %\n",
      "Epoch:100/200 AVG Training Loss:0.642 AVG Validation Loss:0.679 AVG Training Acc 62.57 % AVG Validation Acc 60.20 %\n",
      "Epoch:110/200 AVG Training Loss:0.643 AVG Validation Loss:0.681 AVG Training Acc 62.57 % AVG Validation Acc 60.83 %\n",
      "Epoch:120/200 AVG Training Loss:0.642 AVG Validation Loss:0.680 AVG Training Acc 62.51 % AVG Validation Acc 60.65 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.644 AVG Validation Loss:0.680 AVG Training Acc 62.20 % AVG Validation Acc 60.38 %\n",
      "Epoch:140/200 AVG Training Loss:0.641 AVG Validation Loss:0.679 AVG Training Acc 62.76 % AVG Validation Acc 60.38 %\n",
      "Epoch:150/200 AVG Training Loss:0.643 AVG Validation Loss:0.680 AVG Training Acc 62.32 % AVG Validation Acc 60.56 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.643 AVG Validation Loss:0.680 AVG Training Acc 62.15 % AVG Validation Acc 60.47 %\n",
      "Epoch:170/200 AVG Training Loss:0.643 AVG Validation Loss:0.681 AVG Training Acc 62.60 % AVG Validation Acc 60.29 %\n",
      "Epoch:180/200 AVG Training Loss:0.643 AVG Validation Loss:0.680 AVG Training Acc 62.50 % AVG Validation Acc 60.29 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.643 AVG Validation Loss:0.681 AVG Training Acc 62.20 % AVG Validation Acc 60.74 %\n",
      "Epoch:200/200 AVG Training Loss:0.644 AVG Validation Loss:0.682 AVG Training Acc 62.23 % AVG Validation Acc 60.38 %\n",
      "Split 278\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8787753fb023487e9223fdb601877d51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.661 AVG Training Acc 61.80 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.663 AVG Training Acc 61.72 % AVG Validation Acc 61.91 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 62.12 % AVG Validation Acc 61.37 %\n",
      "Epoch:40/200 AVG Training Loss:0.643 AVG Validation Loss:0.673 AVG Training Acc 62.36 % AVG Validation Acc 59.93 %\n",
      "Epoch:50/200 AVG Training Loss:0.638 AVG Validation Loss:0.681 AVG Training Acc 62.59 % AVG Validation Acc 59.66 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.631 AVG Validation Loss:0.686 AVG Training Acc 63.26 % AVG Validation Acc 58.75 %\n",
      "Epoch:70/200 AVG Training Loss:0.630 AVG Validation Loss:0.689 AVG Training Acc 63.01 % AVG Validation Acc 58.57 %\n",
      "Epoch:80/200 AVG Training Loss:0.628 AVG Validation Loss:0.690 AVG Training Acc 63.37 % AVG Validation Acc 58.48 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.628 AVG Validation Loss:0.691 AVG Training Acc 63.02 % AVG Validation Acc 58.21 %\n",
      "Epoch:100/200 AVG Training Loss:0.628 AVG Validation Loss:0.691 AVG Training Acc 63.43 % AVG Validation Acc 58.21 %\n",
      "Epoch:110/200 AVG Training Loss:0.626 AVG Validation Loss:0.689 AVG Training Acc 63.50 % AVG Validation Acc 58.03 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.626 AVG Validation Loss:0.691 AVG Training Acc 63.51 % AVG Validation Acc 57.67 %\n",
      "Epoch:130/200 AVG Training Loss:0.627 AVG Validation Loss:0.689 AVG Training Acc 63.29 % AVG Validation Acc 58.39 %\n",
      "Epoch:140/200 AVG Training Loss:0.626 AVG Validation Loss:0.691 AVG Training Acc 63.46 % AVG Validation Acc 58.66 %\n",
      "Epoch:150/200 AVG Training Loss:0.628 AVG Validation Loss:0.690 AVG Training Acc 62.96 % AVG Validation Acc 58.39 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.627 AVG Validation Loss:0.690 AVG Training Acc 63.17 % AVG Validation Acc 57.85 %\n",
      "Epoch:170/200 AVG Training Loss:0.628 AVG Validation Loss:0.690 AVG Training Acc 62.87 % AVG Validation Acc 58.21 %\n",
      "Epoch:180/200 AVG Training Loss:0.628 AVG Validation Loss:0.692 AVG Training Acc 62.53 % AVG Validation Acc 58.03 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.626 AVG Validation Loss:0.691 AVG Training Acc 62.89 % AVG Validation Acc 58.12 %\n",
      "Epoch:200/200 AVG Training Loss:0.629 AVG Validation Loss:0.689 AVG Training Acc 63.24 % AVG Validation Acc 58.30 %\n",
      "Split 279\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e5ee0055fa44b08859805dae34e4ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 61.95 % AVG Validation Acc 61.73 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.662 AVG Training Acc 61.97 % AVG Validation Acc 61.82 %\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.666 AVG Training Acc 61.89 % AVG Validation Acc 61.82 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.668 AVG Training Acc 61.93 % AVG Validation Acc 61.82 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.648 AVG Validation Loss:0.679 AVG Training Acc 62.05 % AVG Validation Acc 61.55 %\n",
      "Epoch:60/200 AVG Training Loss:0.645 AVG Validation Loss:0.682 AVG Training Acc 62.37 % AVG Validation Acc 61.37 %\n",
      "Epoch:70/200 AVG Training Loss:0.645 AVG Validation Loss:0.683 AVG Training Acc 62.17 % AVG Validation Acc 61.19 %\n",
      "Epoch:80/200 AVG Training Loss:0.645 AVG Validation Loss:0.684 AVG Training Acc 62.39 % AVG Validation Acc 61.28 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.643 AVG Validation Loss:0.683 AVG Training Acc 62.72 % AVG Validation Acc 61.28 %\n",
      "Epoch:100/200 AVG Training Loss:0.643 AVG Validation Loss:0.684 AVG Training Acc 62.35 % AVG Validation Acc 61.28 %\n",
      "Epoch:110/200 AVG Training Loss:0.642 AVG Validation Loss:0.684 AVG Training Acc 62.55 % AVG Validation Acc 61.19 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.644 AVG Validation Loss:0.684 AVG Training Acc 62.21 % AVG Validation Acc 61.19 %\n",
      "Epoch:130/200 AVG Training Loss:0.643 AVG Validation Loss:0.684 AVG Training Acc 62.41 % AVG Validation Acc 61.28 %\n",
      "Epoch:140/200 AVG Training Loss:0.645 AVG Validation Loss:0.684 AVG Training Acc 62.29 % AVG Validation Acc 61.28 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.643 AVG Validation Loss:0.684 AVG Training Acc 62.26 % AVG Validation Acc 61.37 %\n",
      "Epoch:160/200 AVG Training Loss:0.643 AVG Validation Loss:0.684 AVG Training Acc 62.31 % AVG Validation Acc 61.28 %\n",
      "Epoch:170/200 AVG Training Loss:0.644 AVG Validation Loss:0.684 AVG Training Acc 62.38 % AVG Validation Acc 61.37 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.643 AVG Validation Loss:0.684 AVG Training Acc 62.32 % AVG Validation Acc 61.28 %\n",
      "Epoch:190/200 AVG Training Loss:0.643 AVG Validation Loss:0.684 AVG Training Acc 62.22 % AVG Validation Acc 61.37 %\n",
      "Epoch:200/200 AVG Training Loss:0.644 AVG Validation Loss:0.684 AVG Training Acc 62.13 % AVG Validation Acc 61.37 %\n",
      "Split 280\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c395c744a27462694f10a86881e0eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 61.86 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.659 AVG Training Acc 61.99 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.659 AVG Training Acc 61.93 % AVG Validation Acc 61.91 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.646 AVG Validation Loss:0.667 AVG Training Acc 62.17 % AVG Validation Acc 61.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.644 AVG Validation Loss:0.670 AVG Training Acc 62.29 % AVG Validation Acc 61.73 %\n",
      "Epoch:60/200 AVG Training Loss:0.639 AVG Validation Loss:0.678 AVG Training Acc 62.71 % AVG Validation Acc 61.73 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.636 AVG Validation Loss:0.682 AVG Training Acc 62.63 % AVG Validation Acc 61.73 %\n",
      "Epoch:80/200 AVG Training Loss:0.634 AVG Validation Loss:0.684 AVG Training Acc 62.73 % AVG Validation Acc 61.64 %\n",
      "Epoch:90/200 AVG Training Loss:0.633 AVG Validation Loss:0.681 AVG Training Acc 62.89 % AVG Validation Acc 62.18 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.635 AVG Validation Loss:0.681 AVG Training Acc 62.49 % AVG Validation Acc 61.82 %\n",
      "Epoch:110/200 AVG Training Loss:0.635 AVG Validation Loss:0.686 AVG Training Acc 62.67 % AVG Validation Acc 61.91 %\n",
      "Epoch:120/200 AVG Training Loss:0.634 AVG Validation Loss:0.684 AVG Training Acc 62.46 % AVG Validation Acc 61.55 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.633 AVG Validation Loss:0.686 AVG Training Acc 62.64 % AVG Validation Acc 61.73 %\n",
      "Epoch:140/200 AVG Training Loss:0.635 AVG Validation Loss:0.685 AVG Training Acc 62.43 % AVG Validation Acc 61.73 %\n",
      "Epoch:150/200 AVG Training Loss:0.634 AVG Validation Loss:0.682 AVG Training Acc 62.76 % AVG Validation Acc 61.73 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.634 AVG Validation Loss:0.684 AVG Training Acc 62.56 % AVG Validation Acc 61.82 %\n",
      "Epoch:170/200 AVG Training Loss:0.634 AVG Validation Loss:0.686 AVG Training Acc 62.84 % AVG Validation Acc 61.91 %\n",
      "Epoch:180/200 AVG Training Loss:0.635 AVG Validation Loss:0.686 AVG Training Acc 62.39 % AVG Validation Acc 61.91 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.634 AVG Validation Loss:0.685 AVG Training Acc 62.66 % AVG Validation Acc 62.00 %\n",
      "Epoch:200/200 AVG Training Loss:0.634 AVG Validation Loss:0.685 AVG Training Acc 62.56 % AVG Validation Acc 61.91 %\n",
      "Split 281\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8330c8bc50204065a53d67b69a84810e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.664 AVG Training Acc 61.81 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.664 AVG Training Acc 61.91 % AVG Validation Acc 62.04 %\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.667 AVG Training Acc 61.45 % AVG Validation Acc 61.95 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.662 AVG Training Acc 61.86 % AVG Validation Acc 62.04 %\n",
      "Epoch:50/200 AVG Training Loss:0.649 AVG Validation Loss:0.667 AVG Training Acc 62.10 % AVG Validation Acc 61.68 %\n",
      "Epoch:60/200 AVG Training Loss:0.646 AVG Validation Loss:0.669 AVG Training Acc 62.31 % AVG Validation Acc 62.13 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.644 AVG Validation Loss:0.670 AVG Training Acc 62.50 % AVG Validation Acc 62.94 %\n",
      "Epoch:80/200 AVG Training Loss:0.641 AVG Validation Loss:0.673 AVG Training Acc 62.95 % AVG Validation Acc 62.58 %\n",
      "Epoch:90/200 AVG Training Loss:0.641 AVG Validation Loss:0.672 AVG Training Acc 62.76 % AVG Validation Acc 62.22 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.641 AVG Validation Loss:0.672 AVG Training Acc 62.67 % AVG Validation Acc 62.58 %\n",
      "Epoch:110/200 AVG Training Loss:0.641 AVG Validation Loss:0.673 AVG Training Acc 62.55 % AVG Validation Acc 62.49 %\n",
      "Epoch:120/200 AVG Training Loss:0.640 AVG Validation Loss:0.673 AVG Training Acc 62.98 % AVG Validation Acc 62.40 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.641 AVG Validation Loss:0.672 AVG Training Acc 62.74 % AVG Validation Acc 62.85 %\n",
      "Epoch:140/200 AVG Training Loss:0.640 AVG Validation Loss:0.673 AVG Training Acc 62.76 % AVG Validation Acc 62.40 %\n",
      "Epoch:150/200 AVG Training Loss:0.641 AVG Validation Loss:0.673 AVG Training Acc 62.45 % AVG Validation Acc 62.40 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.642 AVG Validation Loss:0.674 AVG Training Acc 62.74 % AVG Validation Acc 62.04 %\n",
      "Epoch:170/200 AVG Training Loss:0.640 AVG Validation Loss:0.673 AVG Training Acc 62.68 % AVG Validation Acc 62.04 %\n",
      "Epoch:180/200 AVG Training Loss:0.641 AVG Validation Loss:0.673 AVG Training Acc 62.26 % AVG Validation Acc 62.40 %\n",
      "Epoch:190/200 AVG Training Loss:0.641 AVG Validation Loss:0.672 AVG Training Acc 62.58 % AVG Validation Acc 62.13 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.641 AVG Validation Loss:0.673 AVG Training Acc 62.74 % AVG Validation Acc 62.40 %\n",
      "Split 282\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b04cc178e59c44198cf490b892fa2702",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.658 AVG Training Acc 61.78 % AVG Validation Acc 61.86 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:0.657 AVG Training Acc 61.81 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.651 AVG Validation Loss:0.657 AVG Training Acc 61.95 % AVG Validation Acc 61.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.647 AVG Validation Loss:0.657 AVG Training Acc 62.08 % AVG Validation Acc 61.95 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.643 AVG Validation Loss:0.660 AVG Training Acc 61.97 % AVG Validation Acc 61.95 %\n",
      "Epoch:60/200 AVG Training Loss:0.642 AVG Validation Loss:0.661 AVG Training Acc 62.34 % AVG Validation Acc 61.68 %\n",
      "Epoch:70/200 AVG Training Loss:0.641 AVG Validation Loss:0.661 AVG Training Acc 62.51 % AVG Validation Acc 61.41 %\n",
      "Epoch:80/200 AVG Training Loss:0.641 AVG Validation Loss:0.660 AVG Training Acc 62.10 % AVG Validation Acc 61.68 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.641 AVG Validation Loss:0.661 AVG Training Acc 62.17 % AVG Validation Acc 61.59 %\n",
      "Epoch:100/200 AVG Training Loss:0.640 AVG Validation Loss:0.660 AVG Training Acc 62.05 % AVG Validation Acc 61.68 %\n",
      "Epoch:110/200 AVG Training Loss:0.641 AVG Validation Loss:0.660 AVG Training Acc 62.25 % AVG Validation Acc 61.50 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.641 AVG Validation Loss:0.660 AVG Training Acc 62.17 % AVG Validation Acc 61.86 %\n",
      "Epoch:130/200 AVG Training Loss:0.641 AVG Validation Loss:0.660 AVG Training Acc 61.96 % AVG Validation Acc 61.68 %\n",
      "Epoch:140/200 AVG Training Loss:0.641 AVG Validation Loss:0.661 AVG Training Acc 62.12 % AVG Validation Acc 61.50 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.640 AVG Validation Loss:0.660 AVG Training Acc 62.59 % AVG Validation Acc 61.68 %\n",
      "Epoch:160/200 AVG Training Loss:0.640 AVG Validation Loss:0.660 AVG Training Acc 62.28 % AVG Validation Acc 61.77 %\n",
      "Epoch:170/200 AVG Training Loss:0.640 AVG Validation Loss:0.660 AVG Training Acc 62.21 % AVG Validation Acc 61.41 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.641 AVG Validation Loss:0.660 AVG Training Acc 62.27 % AVG Validation Acc 61.59 %\n",
      "Epoch:190/200 AVG Training Loss:0.641 AVG Validation Loss:0.660 AVG Training Acc 62.31 % AVG Validation Acc 61.77 %\n",
      "Epoch:200/200 AVG Training Loss:0.642 AVG Validation Loss:0.660 AVG Training Acc 62.22 % AVG Validation Acc 61.59 %\n",
      "Split 283\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d39985eb2940c7a2178471fed9796d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.657 AVG Training Acc 61.92 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.656 AVG Training Acc 61.93 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.657 AVG Training Acc 61.92 % AVG Validation Acc 61.77 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.658 AVG Training Acc 61.93 % AVG Validation Acc 62.04 %\n",
      "Epoch:50/200 AVG Training Loss:0.648 AVG Validation Loss:0.660 AVG Training Acc 62.10 % AVG Validation Acc 61.77 %\n",
      "Epoch:60/200 AVG Training Loss:0.646 AVG Validation Loss:0.661 AVG Training Acc 62.19 % AVG Validation Acc 61.95 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.642 AVG Validation Loss:0.661 AVG Training Acc 62.20 % AVG Validation Acc 61.77 %\n",
      "Epoch:80/200 AVG Training Loss:0.642 AVG Validation Loss:0.661 AVG Training Acc 62.35 % AVG Validation Acc 61.59 %\n",
      "Epoch:90/200 AVG Training Loss:0.642 AVG Validation Loss:0.662 AVG Training Acc 62.72 % AVG Validation Acc 61.59 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.641 AVG Validation Loss:0.662 AVG Training Acc 62.41 % AVG Validation Acc 61.59 %\n",
      "Epoch:110/200 AVG Training Loss:0.642 AVG Validation Loss:0.662 AVG Training Acc 62.19 % AVG Validation Acc 61.68 %\n",
      "Epoch:120/200 AVG Training Loss:0.641 AVG Validation Loss:0.664 AVG Training Acc 62.12 % AVG Validation Acc 61.59 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.641 AVG Validation Loss:0.662 AVG Training Acc 62.34 % AVG Validation Acc 61.77 %\n",
      "Epoch:140/200 AVG Training Loss:0.641 AVG Validation Loss:0.663 AVG Training Acc 62.41 % AVG Validation Acc 61.50 %\n",
      "Epoch:150/200 AVG Training Loss:0.642 AVG Validation Loss:0.663 AVG Training Acc 62.11 % AVG Validation Acc 61.50 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.641 AVG Validation Loss:0.662 AVG Training Acc 62.26 % AVG Validation Acc 61.77 %\n",
      "Epoch:170/200 AVG Training Loss:0.641 AVG Validation Loss:0.663 AVG Training Acc 62.21 % AVG Validation Acc 61.50 %\n",
      "Epoch:180/200 AVG Training Loss:0.642 AVG Validation Loss:0.662 AVG Training Acc 62.45 % AVG Validation Acc 61.50 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.642 AVG Validation Loss:0.663 AVG Training Acc 62.28 % AVG Validation Acc 61.50 %\n",
      "Epoch:200/200 AVG Training Loss:0.641 AVG Validation Loss:0.663 AVG Training Acc 61.95 % AVG Validation Acc 61.59 %\n",
      "Split 284\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92494a735ff34551a93337950140510f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.661 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:0.664 AVG Training Acc 61.87 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.666 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.649 AVG Validation Loss:0.672 AVG Training Acc 62.00 % AVG Validation Acc 61.86 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.648 AVG Validation Loss:0.676 AVG Training Acc 62.35 % AVG Validation Acc 61.68 %\n",
      "Epoch:60/200 AVG Training Loss:0.645 AVG Validation Loss:0.678 AVG Training Acc 62.12 % AVG Validation Acc 61.50 %\n",
      "Epoch:70/200 AVG Training Loss:0.646 AVG Validation Loss:0.677 AVG Training Acc 62.01 % AVG Validation Acc 61.68 %\n",
      "Epoch:80/200 AVG Training Loss:0.645 AVG Validation Loss:0.678 AVG Training Acc 62.11 % AVG Validation Acc 61.68 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.645 AVG Validation Loss:0.679 AVG Training Acc 62.09 % AVG Validation Acc 61.59 %\n",
      "Epoch:100/200 AVG Training Loss:0.645 AVG Validation Loss:0.679 AVG Training Acc 62.37 % AVG Validation Acc 61.50 %\n",
      "Epoch:110/200 AVG Training Loss:0.645 AVG Validation Loss:0.679 AVG Training Acc 62.07 % AVG Validation Acc 61.59 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.646 AVG Validation Loss:0.680 AVG Training Acc 61.92 % AVG Validation Acc 61.50 %\n",
      "Epoch:130/200 AVG Training Loss:0.644 AVG Validation Loss:0.680 AVG Training Acc 62.15 % AVG Validation Acc 61.50 %\n",
      "Epoch:140/200 AVG Training Loss:0.643 AVG Validation Loss:0.679 AVG Training Acc 62.30 % AVG Validation Acc 61.68 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.644 AVG Validation Loss:0.679 AVG Training Acc 62.41 % AVG Validation Acc 61.68 %\n",
      "Epoch:160/200 AVG Training Loss:0.644 AVG Validation Loss:0.678 AVG Training Acc 62.35 % AVG Validation Acc 61.50 %\n",
      "Epoch:170/200 AVG Training Loss:0.644 AVG Validation Loss:0.679 AVG Training Acc 62.66 % AVG Validation Acc 61.50 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.644 AVG Validation Loss:0.680 AVG Training Acc 62.43 % AVG Validation Acc 61.59 %\n",
      "Epoch:190/200 AVG Training Loss:0.645 AVG Validation Loss:0.679 AVG Training Acc 62.15 % AVG Validation Acc 61.68 %\n",
      "Epoch:200/200 AVG Training Loss:0.645 AVG Validation Loss:0.679 AVG Training Acc 61.99 % AVG Validation Acc 61.50 %\n",
      "Split 285\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0beaaf79bd4403383d47d2d2b44b045",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.660 AVG Training Acc 61.75 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.659 AVG Training Acc 61.94 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.658 AVG Validation Loss:0.663 AVG Training Acc 61.93 % AVG Validation Acc 61.68 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.650 AVG Validation Loss:0.665 AVG Training Acc 62.10 % AVG Validation Acc 61.50 %\n",
      "Epoch:50/200 AVG Training Loss:0.646 AVG Validation Loss:0.670 AVG Training Acc 62.33 % AVG Validation Acc 61.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.643 AVG Validation Loss:0.676 AVG Training Acc 62.12 % AVG Validation Acc 61.05 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.638 AVG Validation Loss:0.686 AVG Training Acc 62.57 % AVG Validation Acc 61.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.636 AVG Validation Loss:0.687 AVG Training Acc 62.56 % AVG Validation Acc 61.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.636 AVG Validation Loss:0.688 AVG Training Acc 62.59 % AVG Validation Acc 61.14 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.637 AVG Validation Loss:0.691 AVG Training Acc 62.52 % AVG Validation Acc 61.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.635 AVG Validation Loss:0.691 AVG Training Acc 62.83 % AVG Validation Acc 60.87 %\n",
      "Epoch:120/200 AVG Training Loss:0.636 AVG Validation Loss:0.690 AVG Training Acc 62.58 % AVG Validation Acc 61.05 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.635 AVG Validation Loss:0.689 AVG Training Acc 62.69 % AVG Validation Acc 60.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.635 AVG Validation Loss:0.689 AVG Training Acc 62.76 % AVG Validation Acc 61.05 %\n",
      "Epoch:150/200 AVG Training Loss:0.635 AVG Validation Loss:0.689 AVG Training Acc 62.81 % AVG Validation Acc 60.96 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.637 AVG Validation Loss:0.689 AVG Training Acc 62.54 % AVG Validation Acc 60.96 %\n",
      "Epoch:170/200 AVG Training Loss:0.637 AVG Validation Loss:0.692 AVG Training Acc 62.69 % AVG Validation Acc 60.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.634 AVG Validation Loss:0.692 AVG Training Acc 62.65 % AVG Validation Acc 60.96 %\n",
      "Epoch:190/200 AVG Training Loss:0.636 AVG Validation Loss:0.687 AVG Training Acc 62.55 % AVG Validation Acc 60.96 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.636 AVG Validation Loss:0.690 AVG Training Acc 62.57 % AVG Validation Acc 60.96 %\n",
      "Split 286\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fde4b569bb24d0eafd18101ca0f0bbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.665 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.664 AVG Training Acc 61.97 % AVG Validation Acc 61.91 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.667 AVG Training Acc 61.98 % AVG Validation Acc 61.73 %\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.669 AVG Training Acc 62.05 % AVG Validation Acc 61.64 %\n",
      "Epoch:50/200 AVG Training Loss:0.647 AVG Validation Loss:0.675 AVG Training Acc 62.06 % AVG Validation Acc 61.46 %\n",
      "Epoch:60/200 AVG Training Loss:0.644 AVG Validation Loss:0.690 AVG Training Acc 62.11 % AVG Validation Acc 61.46 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.642 AVG Validation Loss:0.690 AVG Training Acc 62.25 % AVG Validation Acc 61.37 %\n",
      "Epoch:80/200 AVG Training Loss:0.642 AVG Validation Loss:0.692 AVG Training Acc 62.13 % AVG Validation Acc 61.37 %\n",
      "Epoch:90/200 AVG Training Loss:0.641 AVG Validation Loss:0.694 AVG Training Acc 62.26 % AVG Validation Acc 61.28 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.641 AVG Validation Loss:0.692 AVG Training Acc 62.19 % AVG Validation Acc 61.37 %\n",
      "Epoch:110/200 AVG Training Loss:0.641 AVG Validation Loss:0.690 AVG Training Acc 62.10 % AVG Validation Acc 61.46 %\n",
      "Epoch:120/200 AVG Training Loss:0.641 AVG Validation Loss:0.693 AVG Training Acc 62.14 % AVG Validation Acc 61.28 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.640 AVG Validation Loss:0.692 AVG Training Acc 62.29 % AVG Validation Acc 61.37 %\n",
      "Epoch:140/200 AVG Training Loss:0.640 AVG Validation Loss:0.692 AVG Training Acc 62.24 % AVG Validation Acc 61.46 %\n",
      "Epoch:150/200 AVG Training Loss:0.641 AVG Validation Loss:0.693 AVG Training Acc 62.34 % AVG Validation Acc 61.37 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.640 AVG Validation Loss:0.692 AVG Training Acc 62.20 % AVG Validation Acc 61.46 %\n",
      "Epoch:170/200 AVG Training Loss:0.640 AVG Validation Loss:0.692 AVG Training Acc 62.37 % AVG Validation Acc 61.37 %\n",
      "Epoch:180/200 AVG Training Loss:0.640 AVG Validation Loss:0.691 AVG Training Acc 62.38 % AVG Validation Acc 61.37 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.642 AVG Validation Loss:0.693 AVG Training Acc 62.25 % AVG Validation Acc 61.46 %\n",
      "Epoch:200/200 AVG Training Loss:0.640 AVG Validation Loss:0.692 AVG Training Acc 62.27 % AVG Validation Acc 61.46 %\n",
      "Split 287\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df148e83e2664fd68638167518f78d5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.656 AVG Training Acc 61.91 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.656 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.656 AVG Training Acc 61.86 % AVG Validation Acc 61.82 %\n",
      "Epoch:40/200 AVG Training Loss:0.654 AVG Validation Loss:0.657 AVG Training Acc 62.01 % AVG Validation Acc 61.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.653 AVG Validation Loss:0.658 AVG Training Acc 62.02 % AVG Validation Acc 61.91 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.651 AVG Validation Loss:0.657 AVG Training Acc 62.04 % AVG Validation Acc 61.91 %\n",
      "Epoch:70/200 AVG Training Loss:0.651 AVG Validation Loss:0.659 AVG Training Acc 61.95 % AVG Validation Acc 61.82 %\n",
      "Epoch:80/200 AVG Training Loss:0.650 AVG Validation Loss:0.659 AVG Training Acc 62.14 % AVG Validation Acc 61.82 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.650 AVG Validation Loss:0.660 AVG Training Acc 62.09 % AVG Validation Acc 61.82 %\n",
      "Epoch:100/200 AVG Training Loss:0.650 AVG Validation Loss:0.660 AVG Training Acc 62.09 % AVG Validation Acc 61.82 %\n",
      "Epoch:110/200 AVG Training Loss:0.650 AVG Validation Loss:0.660 AVG Training Acc 62.18 % AVG Validation Acc 61.82 %\n",
      "Epoch:120/200 AVG Training Loss:0.649 AVG Validation Loss:0.660 AVG Training Acc 62.05 % AVG Validation Acc 61.82 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.650 AVG Validation Loss:0.659 AVG Training Acc 62.07 % AVG Validation Acc 61.91 %\n",
      "Epoch:140/200 AVG Training Loss:0.649 AVG Validation Loss:0.660 AVG Training Acc 62.15 % AVG Validation Acc 61.82 %\n",
      "Epoch:150/200 AVG Training Loss:0.650 AVG Validation Loss:0.660 AVG Training Acc 61.96 % AVG Validation Acc 61.82 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.650 AVG Validation Loss:0.660 AVG Training Acc 62.06 % AVG Validation Acc 61.82 %\n",
      "Epoch:170/200 AVG Training Loss:0.651 AVG Validation Loss:0.661 AVG Training Acc 62.04 % AVG Validation Acc 61.82 %\n",
      "Epoch:180/200 AVG Training Loss:0.650 AVG Validation Loss:0.660 AVG Training Acc 62.09 % AVG Validation Acc 61.91 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.650 AVG Validation Loss:0.661 AVG Training Acc 62.03 % AVG Validation Acc 61.82 %\n",
      "Epoch:200/200 AVG Training Loss:0.649 AVG Validation Loss:0.660 AVG Training Acc 62.11 % AVG Validation Acc 61.91 %\n",
      "Split 288\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf782dd61566450aa0f6b116cedc6b95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.657 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 61.83 % AVG Validation Acc 61.91 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.657 AVG Training Acc 62.04 % AVG Validation Acc 61.73 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.659 AVG Training Acc 62.16 % AVG Validation Acc 61.73 %\n",
      "Epoch:50/200 AVG Training Loss:0.652 AVG Validation Loss:0.660 AVG Training Acc 61.95 % AVG Validation Acc 61.73 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.647 AVG Validation Loss:0.662 AVG Training Acc 62.33 % AVG Validation Acc 62.18 %\n",
      "Epoch:70/200 AVG Training Loss:0.647 AVG Validation Loss:0.662 AVG Training Acc 62.18 % AVG Validation Acc 62.18 %\n",
      "Epoch:80/200 AVG Training Loss:0.647 AVG Validation Loss:0.662 AVG Training Acc 62.24 % AVG Validation Acc 62.18 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 62.35 % AVG Validation Acc 62.18 %\n",
      "Epoch:100/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 62.12 % AVG Validation Acc 62.18 %\n",
      "Epoch:110/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 62.26 % AVG Validation Acc 62.09 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.645 AVG Validation Loss:0.663 AVG Training Acc 62.28 % AVG Validation Acc 62.09 %\n",
      "Epoch:130/200 AVG Training Loss:0.646 AVG Validation Loss:0.663 AVG Training Acc 62.14 % AVG Validation Acc 62.18 %\n",
      "Epoch:140/200 AVG Training Loss:0.646 AVG Validation Loss:0.663 AVG Training Acc 62.31 % AVG Validation Acc 62.18 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 62.27 % AVG Validation Acc 62.18 %\n",
      "Epoch:160/200 AVG Training Loss:0.645 AVG Validation Loss:0.663 AVG Training Acc 62.26 % AVG Validation Acc 62.09 %\n",
      "Epoch:170/200 AVG Training Loss:0.646 AVG Validation Loss:0.663 AVG Training Acc 62.19 % AVG Validation Acc 62.18 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.646 AVG Validation Loss:0.663 AVG Training Acc 62.33 % AVG Validation Acc 62.18 %\n",
      "Epoch:190/200 AVG Training Loss:0.646 AVG Validation Loss:0.663 AVG Training Acc 62.20 % AVG Validation Acc 62.18 %\n",
      "Epoch:200/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 62.07 % AVG Validation Acc 62.18 %\n",
      "Split 289\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fed0da7d2f3e49b39e72b1f1671c92bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.663 AVG Training Acc 61.80 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.666 AVG Training Acc 61.67 % AVG Validation Acc 61.91 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.652 AVG Validation Loss:0.664 AVG Training Acc 61.88 % AVG Validation Acc 62.00 %\n",
      "Epoch:40/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 61.93 % AVG Validation Acc 62.00 %\n",
      "Epoch:50/200 AVG Training Loss:0.645 AVG Validation Loss:0.668 AVG Training Acc 62.27 % AVG Validation Acc 62.09 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.643 AVG Validation Loss:0.671 AVG Training Acc 62.33 % AVG Validation Acc 61.91 %\n",
      "Epoch:70/200 AVG Training Loss:0.642 AVG Validation Loss:0.671 AVG Training Acc 62.19 % AVG Validation Acc 61.73 %\n",
      "Epoch:80/200 AVG Training Loss:0.641 AVG Validation Loss:0.671 AVG Training Acc 62.57 % AVG Validation Acc 61.19 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.642 AVG Validation Loss:0.672 AVG Training Acc 62.21 % AVG Validation Acc 61.37 %\n",
      "Epoch:100/200 AVG Training Loss:0.642 AVG Validation Loss:0.672 AVG Training Acc 62.58 % AVG Validation Acc 61.19 %\n",
      "Epoch:110/200 AVG Training Loss:0.641 AVG Validation Loss:0.673 AVG Training Acc 62.42 % AVG Validation Acc 60.92 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.639 AVG Validation Loss:0.672 AVG Training Acc 62.37 % AVG Validation Acc 60.92 %\n",
      "Epoch:130/200 AVG Training Loss:0.641 AVG Validation Loss:0.672 AVG Training Acc 62.18 % AVG Validation Acc 60.92 %\n",
      "Epoch:140/200 AVG Training Loss:0.641 AVG Validation Loss:0.672 AVG Training Acc 62.64 % AVG Validation Acc 61.37 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.641 AVG Validation Loss:0.672 AVG Training Acc 62.40 % AVG Validation Acc 61.19 %\n",
      "Epoch:160/200 AVG Training Loss:0.639 AVG Validation Loss:0.672 AVG Training Acc 62.24 % AVG Validation Acc 61.10 %\n",
      "Epoch:170/200 AVG Training Loss:0.641 AVG Validation Loss:0.673 AVG Training Acc 62.40 % AVG Validation Acc 61.19 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.641 AVG Validation Loss:0.673 AVG Training Acc 62.47 % AVG Validation Acc 61.28 %\n",
      "Epoch:190/200 AVG Training Loss:0.641 AVG Validation Loss:0.672 AVG Training Acc 62.44 % AVG Validation Acc 61.37 %\n",
      "Epoch:200/200 AVG Training Loss:0.642 AVG Validation Loss:0.672 AVG Training Acc 62.41 % AVG Validation Acc 61.10 %\n",
      "Split 290\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72127a88fc614b889d578fa0c2d92c9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.659 AVG Training Acc 61.91 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.661 AVG Training Acc 61.81 % AVG Validation Acc 62.00 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.663 AVG Training Acc 61.85 % AVG Validation Acc 61.91 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:0.666 AVG Training Acc 61.87 % AVG Validation Acc 62.00 %\n",
      "Epoch:50/200 AVG Training Loss:0.650 AVG Validation Loss:0.667 AVG Training Acc 61.72 % AVG Validation Acc 62.00 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.647 AVG Validation Loss:0.668 AVG Training Acc 62.04 % AVG Validation Acc 61.64 %\n",
      "Epoch:70/200 AVG Training Loss:0.646 AVG Validation Loss:0.669 AVG Training Acc 62.15 % AVG Validation Acc 61.55 %\n",
      "Epoch:80/200 AVG Training Loss:0.646 AVG Validation Loss:0.669 AVG Training Acc 61.93 % AVG Validation Acc 61.82 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.645 AVG Validation Loss:0.669 AVG Training Acc 61.92 % AVG Validation Acc 61.73 %\n",
      "Epoch:100/200 AVG Training Loss:0.644 AVG Validation Loss:0.669 AVG Training Acc 62.33 % AVG Validation Acc 61.73 %\n",
      "Epoch:110/200 AVG Training Loss:0.646 AVG Validation Loss:0.669 AVG Training Acc 61.93 % AVG Validation Acc 61.73 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.646 AVG Validation Loss:0.670 AVG Training Acc 61.99 % AVG Validation Acc 61.82 %\n",
      "Epoch:130/200 AVG Training Loss:0.644 AVG Validation Loss:0.669 AVG Training Acc 62.24 % AVG Validation Acc 61.73 %\n",
      "Epoch:140/200 AVG Training Loss:0.645 AVG Validation Loss:0.670 AVG Training Acc 62.41 % AVG Validation Acc 61.64 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.646 AVG Validation Loss:0.670 AVG Training Acc 62.05 % AVG Validation Acc 61.73 %\n",
      "Epoch:160/200 AVG Training Loss:0.645 AVG Validation Loss:0.669 AVG Training Acc 62.00 % AVG Validation Acc 61.73 %\n",
      "Epoch:170/200 AVG Training Loss:0.646 AVG Validation Loss:0.670 AVG Training Acc 62.24 % AVG Validation Acc 61.73 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.645 AVG Validation Loss:0.669 AVG Training Acc 62.02 % AVG Validation Acc 61.82 %\n",
      "Epoch:190/200 AVG Training Loss:0.645 AVG Validation Loss:0.669 AVG Training Acc 62.02 % AVG Validation Acc 61.64 %\n",
      "Epoch:200/200 AVG Training Loss:0.646 AVG Validation Loss:0.669 AVG Training Acc 61.94 % AVG Validation Acc 61.73 %\n",
      "Split 291\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dddcfc17172d42da9041a1f088752c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.661 AVG Training Acc 61.86 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 61.87 % AVG Validation Acc 61.86 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.652 AVG Validation Loss:0.662 AVG Training Acc 61.90 % AVG Validation Acc 61.77 %\n",
      "Epoch:40/200 AVG Training Loss:0.649 AVG Validation Loss:0.667 AVG Training Acc 61.86 % AVG Validation Acc 61.59 %\n",
      "Epoch:50/200 AVG Training Loss:0.645 AVG Validation Loss:0.672 AVG Training Acc 62.36 % AVG Validation Acc 61.14 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.641 AVG Validation Loss:0.677 AVG Training Acc 62.28 % AVG Validation Acc 60.78 %\n",
      "Epoch:70/200 AVG Training Loss:0.641 AVG Validation Loss:0.678 AVG Training Acc 62.49 % AVG Validation Acc 61.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.640 AVG Validation Loss:0.680 AVG Training Acc 62.61 % AVG Validation Acc 60.96 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.641 AVG Validation Loss:0.681 AVG Training Acc 62.57 % AVG Validation Acc 60.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.640 AVG Validation Loss:0.681 AVG Training Acc 62.79 % AVG Validation Acc 61.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.639 AVG Validation Loss:0.680 AVG Training Acc 62.64 % AVG Validation Acc 61.05 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.641 AVG Validation Loss:0.682 AVG Training Acc 62.47 % AVG Validation Acc 61.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.639 AVG Validation Loss:0.681 AVG Training Acc 62.74 % AVG Validation Acc 61.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.639 AVG Validation Loss:0.681 AVG Training Acc 62.47 % AVG Validation Acc 61.23 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.639 AVG Validation Loss:0.681 AVG Training Acc 62.77 % AVG Validation Acc 60.96 %\n",
      "Epoch:160/200 AVG Training Loss:0.639 AVG Validation Loss:0.681 AVG Training Acc 62.78 % AVG Validation Acc 61.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.639 AVG Validation Loss:0.683 AVG Training Acc 62.45 % AVG Validation Acc 60.78 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.642 AVG Validation Loss:0.682 AVG Training Acc 62.50 % AVG Validation Acc 61.05 %\n",
      "Epoch:190/200 AVG Training Loss:0.640 AVG Validation Loss:0.681 AVG Training Acc 62.53 % AVG Validation Acc 60.96 %\n",
      "Epoch:200/200 AVG Training Loss:0.641 AVG Validation Loss:0.680 AVG Training Acc 62.71 % AVG Validation Acc 60.96 %\n",
      "Split 292\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26ce3cbe2e36404892bdf4d0d23d57ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.660 AVG Training Acc 61.92 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.658 AVG Validation Loss:0.660 AVG Training Acc 61.88 % AVG Validation Acc 61.86 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.664 AVG Training Acc 62.06 % AVG Validation Acc 61.95 %\n",
      "Epoch:50/200 AVG Training Loss:0.648 AVG Validation Loss:0.667 AVG Training Acc 62.17 % AVG Validation Acc 61.77 %\n",
      "Epoch:60/200 AVG Training Loss:0.643 AVG Validation Loss:0.675 AVG Training Acc 62.45 % AVG Validation Acc 61.95 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.637 AVG Validation Loss:0.685 AVG Training Acc 62.81 % AVG Validation Acc 62.22 %\n",
      "Epoch:80/200 AVG Training Loss:0.636 AVG Validation Loss:0.690 AVG Training Acc 62.75 % AVG Validation Acc 61.50 %\n",
      "Epoch:90/200 AVG Training Loss:0.635 AVG Validation Loss:0.691 AVG Training Acc 62.93 % AVG Validation Acc 61.41 %\n",
      "Epoch:100/200 AVG Training Loss:0.634 AVG Validation Loss:0.692 AVG Training Acc 62.60 % AVG Validation Acc 61.50 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.635 AVG Validation Loss:0.692 AVG Training Acc 62.91 % AVG Validation Acc 61.32 %\n",
      "Epoch:120/200 AVG Training Loss:0.634 AVG Validation Loss:0.692 AVG Training Acc 62.97 % AVG Validation Acc 61.41 %\n",
      "Epoch:130/200 AVG Training Loss:0.634 AVG Validation Loss:0.692 AVG Training Acc 62.80 % AVG Validation Acc 61.32 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.636 AVG Validation Loss:0.693 AVG Training Acc 62.57 % AVG Validation Acc 61.41 %\n",
      "Epoch:150/200 AVG Training Loss:0.635 AVG Validation Loss:0.693 AVG Training Acc 62.65 % AVG Validation Acc 61.41 %\n",
      "Epoch:160/200 AVG Training Loss:0.635 AVG Validation Loss:0.693 AVG Training Acc 62.72 % AVG Validation Acc 61.41 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.635 AVG Validation Loss:0.692 AVG Training Acc 62.94 % AVG Validation Acc 61.50 %\n",
      "Epoch:180/200 AVG Training Loss:0.635 AVG Validation Loss:0.692 AVG Training Acc 62.81 % AVG Validation Acc 61.32 %\n",
      "Epoch:190/200 AVG Training Loss:0.635 AVG Validation Loss:0.692 AVG Training Acc 62.61 % AVG Validation Acc 61.41 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.633 AVG Validation Loss:0.692 AVG Training Acc 62.87 % AVG Validation Acc 61.23 %\n",
      "Split 293\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbe5a5b5565149229b80ffdd49873a38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.658 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.656 AVG Training Acc 61.83 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.655 AVG Training Acc 61.98 % AVG Validation Acc 61.77 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.654 AVG Training Acc 61.95 % AVG Validation Acc 61.95 %\n",
      "Epoch:50/200 AVG Training Loss:0.646 AVG Validation Loss:0.656 AVG Training Acc 62.43 % AVG Validation Acc 61.95 %\n",
      "Epoch:60/200 AVG Training Loss:0.648 AVG Validation Loss:0.654 AVG Training Acc 62.39 % AVG Validation Acc 62.49 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:70/200 AVG Training Loss:0.638 AVG Validation Loss:0.662 AVG Training Acc 62.87 % AVG Validation Acc 62.22 %\n",
      "Epoch:80/200 AVG Training Loss:0.626 AVG Validation Loss:0.662 AVG Training Acc 63.52 % AVG Validation Acc 62.49 %\n",
      "Epoch:90/200 AVG Training Loss:0.624 AVG Validation Loss:0.672 AVG Training Acc 63.41 % AVG Validation Acc 61.95 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.618 AVG Validation Loss:0.669 AVG Training Acc 64.19 % AVG Validation Acc 62.58 %\n",
      "Epoch:110/200 AVG Training Loss:0.619 AVG Validation Loss:0.676 AVG Training Acc 64.06 % AVG Validation Acc 61.05 %\n",
      "Epoch:120/200 AVG Training Loss:0.617 AVG Validation Loss:0.673 AVG Training Acc 64.08 % AVG Validation Acc 62.04 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.614 AVG Validation Loss:0.673 AVG Training Acc 64.40 % AVG Validation Acc 61.32 %\n",
      "Epoch:140/200 AVG Training Loss:0.616 AVG Validation Loss:0.673 AVG Training Acc 64.23 % AVG Validation Acc 61.50 %\n",
      "Epoch:150/200 AVG Training Loss:0.616 AVG Validation Loss:0.677 AVG Training Acc 63.97 % AVG Validation Acc 61.41 %\n",
      "Epoch:160/200 AVG Training Loss:0.617 AVG Validation Loss:0.675 AVG Training Acc 63.91 % AVG Validation Acc 61.50 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:170/200 AVG Training Loss:0.616 AVG Validation Loss:0.678 AVG Training Acc 64.06 % AVG Validation Acc 61.32 %\n",
      "Epoch:180/200 AVG Training Loss:0.617 AVG Validation Loss:0.675 AVG Training Acc 64.26 % AVG Validation Acc 61.32 %\n",
      "Epoch:190/200 AVG Training Loss:0.616 AVG Validation Loss:0.673 AVG Training Acc 64.07 % AVG Validation Acc 61.68 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:200/200 AVG Training Loss:0.616 AVG Validation Loss:0.673 AVG Training Acc 64.20 % AVG Validation Acc 60.96 %\n",
      "Split 294\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983883d801194ec4ac18081af66ae0f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.660 AVG Training Acc 61.91 % AVG Validation Acc 61.77 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.660 AVG Training Acc 61.81 % AVG Validation Acc 61.86 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.651 AVG Validation Loss:0.660 AVG Training Acc 61.99 % AVG Validation Acc 61.68 %\n",
      "Epoch:40/200 AVG Training Loss:0.647 AVG Validation Loss:0.665 AVG Training Acc 61.93 % AVG Validation Acc 61.68 %\n",
      "Epoch:50/200 AVG Training Loss:0.645 AVG Validation Loss:0.669 AVG Training Acc 62.19 % AVG Validation Acc 61.77 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.641 AVG Validation Loss:0.676 AVG Training Acc 62.24 % AVG Validation Acc 61.95 %\n",
      "Epoch:70/200 AVG Training Loss:0.639 AVG Validation Loss:0.676 AVG Training Acc 62.34 % AVG Validation Acc 61.95 %\n",
      "Epoch:80/200 AVG Training Loss:0.638 AVG Validation Loss:0.678 AVG Training Acc 62.33 % AVG Validation Acc 62.04 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.639 AVG Validation Loss:0.678 AVG Training Acc 62.13 % AVG Validation Acc 62.04 %\n",
      "Epoch:100/200 AVG Training Loss:0.637 AVG Validation Loss:0.679 AVG Training Acc 62.30 % AVG Validation Acc 61.95 %\n",
      "Epoch:110/200 AVG Training Loss:0.637 AVG Validation Loss:0.676 AVG Training Acc 62.32 % AVG Validation Acc 62.13 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.639 AVG Validation Loss:0.680 AVG Training Acc 62.30 % AVG Validation Acc 61.86 %\n",
      "Epoch:130/200 AVG Training Loss:0.640 AVG Validation Loss:0.678 AVG Training Acc 62.14 % AVG Validation Acc 62.04 %\n",
      "Epoch:140/200 AVG Training Loss:0.638 AVG Validation Loss:0.680 AVG Training Acc 62.24 % AVG Validation Acc 62.04 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.638 AVG Validation Loss:0.677 AVG Training Acc 62.33 % AVG Validation Acc 62.13 %\n",
      "Epoch:160/200 AVG Training Loss:0.639 AVG Validation Loss:0.678 AVG Training Acc 62.40 % AVG Validation Acc 62.13 %\n",
      "Epoch:170/200 AVG Training Loss:0.638 AVG Validation Loss:0.679 AVG Training Acc 62.50 % AVG Validation Acc 62.04 %\n",
      "Epoch:180/200 AVG Training Loss:0.638 AVG Validation Loss:0.677 AVG Training Acc 62.26 % AVG Validation Acc 62.04 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.637 AVG Validation Loss:0.679 AVG Training Acc 62.39 % AVG Validation Acc 62.04 %\n",
      "Epoch:200/200 AVG Training Loss:0.639 AVG Validation Loss:0.679 AVG Training Acc 62.15 % AVG Validation Acc 62.04 %\n",
      "Split 295\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa41223b54204e5a84ca941692b83eb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 61.78 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.660 AVG Training Acc 61.78 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.664 AVG Training Acc 61.77 % AVG Validation Acc 61.95 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.663 AVG Training Acc 61.98 % AVG Validation Acc 61.95 %\n",
      "Epoch:50/200 AVG Training Loss:0.650 AVG Validation Loss:0.666 AVG Training Acc 61.98 % AVG Validation Acc 61.68 %\n",
      "Epoch:60/200 AVG Training Loss:0.647 AVG Validation Loss:0.671 AVG Training Acc 62.18 % AVG Validation Acc 61.32 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.646 AVG Validation Loss:0.674 AVG Training Acc 62.13 % AVG Validation Acc 61.32 %\n",
      "Epoch:80/200 AVG Training Loss:0.645 AVG Validation Loss:0.676 AVG Training Acc 62.16 % AVG Validation Acc 61.59 %\n",
      "Epoch:90/200 AVG Training Loss:0.644 AVG Validation Loss:0.677 AVG Training Acc 62.15 % AVG Validation Acc 61.23 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.644 AVG Validation Loss:0.678 AVG Training Acc 62.08 % AVG Validation Acc 61.23 %\n",
      "Epoch:110/200 AVG Training Loss:0.644 AVG Validation Loss:0.678 AVG Training Acc 62.39 % AVG Validation Acc 61.14 %\n",
      "Epoch:120/200 AVG Training Loss:0.644 AVG Validation Loss:0.678 AVG Training Acc 62.17 % AVG Validation Acc 61.14 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.644 AVG Validation Loss:0.679 AVG Training Acc 62.17 % AVG Validation Acc 61.41 %\n",
      "Epoch:140/200 AVG Training Loss:0.644 AVG Validation Loss:0.679 AVG Training Acc 62.12 % AVG Validation Acc 61.23 %\n",
      "Epoch:150/200 AVG Training Loss:0.644 AVG Validation Loss:0.679 AVG Training Acc 62.34 % AVG Validation Acc 61.14 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.645 AVG Validation Loss:0.678 AVG Training Acc 62.42 % AVG Validation Acc 61.32 %\n",
      "Epoch:170/200 AVG Training Loss:0.644 AVG Validation Loss:0.679 AVG Training Acc 62.48 % AVG Validation Acc 61.32 %\n",
      "Epoch:180/200 AVG Training Loss:0.645 AVG Validation Loss:0.679 AVG Training Acc 62.15 % AVG Validation Acc 61.41 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.644 AVG Validation Loss:0.679 AVG Training Acc 62.33 % AVG Validation Acc 61.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.645 AVG Validation Loss:0.679 AVG Training Acc 62.14 % AVG Validation Acc 61.23 %\n",
      "Split 296\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcefe1c0230649d0a59c527c7528e1be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.658 AVG Training Acc 61.87 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.657 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.661 AVG Validation Loss:0.659 AVG Training Acc 61.98 % AVG Validation Acc 61.82 %\n",
      "Epoch:40/200 AVG Training Loss:0.659 AVG Validation Loss:0.659 AVG Training Acc 61.93 % AVG Validation Acc 61.82 %\n",
      "Epoch:50/200 AVG Training Loss:0.656 AVG Validation Loss:0.658 AVG Training Acc 61.90 % AVG Validation Acc 62.00 %\n",
      "Epoch:60/200 AVG Training Loss:0.652 AVG Validation Loss:0.656 AVG Training Acc 62.10 % AVG Validation Acc 61.91 %\n",
      "Epoch:70/200 AVG Training Loss:0.649 AVG Validation Loss:0.656 AVG Training Acc 62.18 % AVG Validation Acc 61.91 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.646 AVG Validation Loss:0.656 AVG Training Acc 62.20 % AVG Validation Acc 61.82 %\n",
      "Epoch:90/200 AVG Training Loss:0.644 AVG Validation Loss:0.657 AVG Training Acc 62.21 % AVG Validation Acc 61.91 %\n",
      "Epoch:100/200 AVG Training Loss:0.646 AVG Validation Loss:0.657 AVG Training Acc 62.24 % AVG Validation Acc 62.00 %\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.645 AVG Validation Loss:0.657 AVG Training Acc 62.23 % AVG Validation Acc 62.00 %\n",
      "Epoch:120/200 AVG Training Loss:0.643 AVG Validation Loss:0.657 AVG Training Acc 62.33 % AVG Validation Acc 61.91 %\n",
      "Epoch:130/200 AVG Training Loss:0.643 AVG Validation Loss:0.657 AVG Training Acc 62.33 % AVG Validation Acc 61.91 %\n",
      "Epoch   134: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.643 AVG Validation Loss:0.658 AVG Training Acc 62.39 % AVG Validation Acc 61.91 %\n",
      "Epoch:150/200 AVG Training Loss:0.642 AVG Validation Loss:0.657 AVG Training Acc 62.35 % AVG Validation Acc 61.91 %\n",
      "Epoch:160/200 AVG Training Loss:0.643 AVG Validation Loss:0.658 AVG Training Acc 62.34 % AVG Validation Acc 61.82 %\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.644 AVG Validation Loss:0.657 AVG Training Acc 62.33 % AVG Validation Acc 62.00 %\n",
      "Epoch:180/200 AVG Training Loss:0.645 AVG Validation Loss:0.657 AVG Training Acc 62.22 % AVG Validation Acc 62.00 %\n",
      "Epoch:190/200 AVG Training Loss:0.641 AVG Validation Loss:0.657 AVG Training Acc 62.25 % AVG Validation Acc 62.00 %\n",
      "Epoch   196: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.642 AVG Validation Loss:0.658 AVG Training Acc 62.24 % AVG Validation Acc 61.91 %\n",
      "Split 297\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40f838428daa4561a9ad081737a2b1c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.663 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.665 AVG Training Acc 61.71 % AVG Validation Acc 61.91 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.650 AVG Validation Loss:0.665 AVG Training Acc 61.77 % AVG Validation Acc 62.18 %\n",
      "Epoch:40/200 AVG Training Loss:0.645 AVG Validation Loss:0.669 AVG Training Acc 62.25 % AVG Validation Acc 62.36 %\n",
      "Epoch:50/200 AVG Training Loss:0.640 AVG Validation Loss:0.672 AVG Training Acc 62.51 % AVG Validation Acc 62.18 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.638 AVG Validation Loss:0.676 AVG Training Acc 61.87 % AVG Validation Acc 62.64 %\n",
      "Epoch:70/200 AVG Training Loss:0.635 AVG Validation Loss:0.677 AVG Training Acc 62.12 % AVG Validation Acc 62.45 %\n",
      "Epoch:80/200 AVG Training Loss:0.636 AVG Validation Loss:0.678 AVG Training Acc 61.81 % AVG Validation Acc 62.27 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.634 AVG Validation Loss:0.679 AVG Training Acc 62.11 % AVG Validation Acc 62.27 %\n",
      "Epoch:100/200 AVG Training Loss:0.634 AVG Validation Loss:0.680 AVG Training Acc 62.19 % AVG Validation Acc 61.91 %\n",
      "Epoch:110/200 AVG Training Loss:0.634 AVG Validation Loss:0.678 AVG Training Acc 62.20 % AVG Validation Acc 62.00 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.635 AVG Validation Loss:0.678 AVG Training Acc 62.37 % AVG Validation Acc 61.82 %\n",
      "Epoch:130/200 AVG Training Loss:0.635 AVG Validation Loss:0.680 AVG Training Acc 61.98 % AVG Validation Acc 62.09 %\n",
      "Epoch:140/200 AVG Training Loss:0.633 AVG Validation Loss:0.678 AVG Training Acc 62.26 % AVG Validation Acc 61.82 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.633 AVG Validation Loss:0.679 AVG Training Acc 61.96 % AVG Validation Acc 61.82 %\n",
      "Epoch:160/200 AVG Training Loss:0.634 AVG Validation Loss:0.680 AVG Training Acc 62.26 % AVG Validation Acc 62.00 %\n",
      "Epoch:170/200 AVG Training Loss:0.634 AVG Validation Loss:0.680 AVG Training Acc 62.17 % AVG Validation Acc 62.09 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.634 AVG Validation Loss:0.678 AVG Training Acc 62.44 % AVG Validation Acc 62.18 %\n",
      "Epoch:190/200 AVG Training Loss:0.632 AVG Validation Loss:0.680 AVG Training Acc 62.26 % AVG Validation Acc 62.27 %\n",
      "Epoch:200/200 AVG Training Loss:0.635 AVG Validation Loss:0.678 AVG Training Acc 62.25 % AVG Validation Acc 61.91 %\n",
      "Split 298\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8cc00ef30bc4715ac3ad4ef85d71967",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.661 AVG Training Acc 61.91 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 61.85 % AVG Validation Acc 61.82 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.665 AVG Training Acc 62.03 % AVG Validation Acc 61.64 %\n",
      "Epoch:40/200 AVG Training Loss:0.650 AVG Validation Loss:0.669 AVG Training Acc 61.98 % AVG Validation Acc 61.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.646 AVG Validation Loss:0.672 AVG Training Acc 61.99 % AVG Validation Acc 61.73 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.643 AVG Validation Loss:0.675 AVG Training Acc 62.33 % AVG Validation Acc 61.55 %\n",
      "Epoch:70/200 AVG Training Loss:0.643 AVG Validation Loss:0.676 AVG Training Acc 62.22 % AVG Validation Acc 61.37 %\n",
      "Epoch:80/200 AVG Training Loss:0.644 AVG Validation Loss:0.677 AVG Training Acc 62.24 % AVG Validation Acc 61.46 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.644 AVG Validation Loss:0.677 AVG Training Acc 62.16 % AVG Validation Acc 61.28 %\n",
      "Epoch:100/200 AVG Training Loss:0.644 AVG Validation Loss:0.678 AVG Training Acc 62.05 % AVG Validation Acc 61.28 %\n",
      "Epoch:110/200 AVG Training Loss:0.644 AVG Validation Loss:0.677 AVG Training Acc 62.16 % AVG Validation Acc 61.46 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.644 AVG Validation Loss:0.677 AVG Training Acc 62.19 % AVG Validation Acc 61.37 %\n",
      "Epoch:130/200 AVG Training Loss:0.643 AVG Validation Loss:0.678 AVG Training Acc 62.50 % AVG Validation Acc 61.37 %\n",
      "Epoch:140/200 AVG Training Loss:0.643 AVG Validation Loss:0.677 AVG Training Acc 62.28 % AVG Validation Acc 61.28 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.644 AVG Validation Loss:0.676 AVG Training Acc 62.30 % AVG Validation Acc 61.19 %\n",
      "Epoch:160/200 AVG Training Loss:0.642 AVG Validation Loss:0.678 AVG Training Acc 62.57 % AVG Validation Acc 61.19 %\n",
      "Epoch:170/200 AVG Training Loss:0.644 AVG Validation Loss:0.677 AVG Training Acc 62.24 % AVG Validation Acc 61.19 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.643 AVG Validation Loss:0.678 AVG Training Acc 62.00 % AVG Validation Acc 61.19 %\n",
      "Epoch:190/200 AVG Training Loss:0.643 AVG Validation Loss:0.678 AVG Training Acc 62.42 % AVG Validation Acc 61.19 %\n",
      "Epoch:200/200 AVG Training Loss:0.645 AVG Validation Loss:0.678 AVG Training Acc 62.29 % AVG Validation Acc 61.37 %\n",
      "Split 299\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4b390d3c9c746ad8e0411f3b4e6ef33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.662 AVG Validation Loss:0.659 AVG Training Acc 61.85 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.657 AVG Training Acc 61.97 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.658 AVG Training Acc 61.90 % AVG Validation Acc 62.18 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.647 AVG Validation Loss:0.666 AVG Training Acc 62.26 % AVG Validation Acc 61.64 %\n",
      "Epoch:50/200 AVG Training Loss:0.645 AVG Validation Loss:0.673 AVG Training Acc 62.40 % AVG Validation Acc 61.28 %\n",
      "Epoch:60/200 AVG Training Loss:0.642 AVG Validation Loss:0.681 AVG Training Acc 62.53 % AVG Validation Acc 61.10 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.639 AVG Validation Loss:0.683 AVG Training Acc 62.55 % AVG Validation Acc 60.92 %\n",
      "Epoch:80/200 AVG Training Loss:0.640 AVG Validation Loss:0.683 AVG Training Acc 62.42 % AVG Validation Acc 60.83 %\n",
      "Epoch:90/200 AVG Training Loss:0.639 AVG Validation Loss:0.684 AVG Training Acc 62.82 % AVG Validation Acc 60.92 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.639 AVG Validation Loss:0.683 AVG Training Acc 62.57 % AVG Validation Acc 60.74 %\n",
      "Epoch:110/200 AVG Training Loss:0.639 AVG Validation Loss:0.685 AVG Training Acc 62.94 % AVG Validation Acc 60.83 %\n",
      "Epoch:120/200 AVG Training Loss:0.639 AVG Validation Loss:0.685 AVG Training Acc 62.71 % AVG Validation Acc 60.74 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.639 AVG Validation Loss:0.685 AVG Training Acc 62.66 % AVG Validation Acc 60.74 %\n",
      "Epoch:140/200 AVG Training Loss:0.639 AVG Validation Loss:0.684 AVG Training Acc 62.75 % AVG Validation Acc 60.74 %\n",
      "Epoch:150/200 AVG Training Loss:0.639 AVG Validation Loss:0.685 AVG Training Acc 62.87 % AVG Validation Acc 60.74 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.638 AVG Validation Loss:0.686 AVG Training Acc 62.79 % AVG Validation Acc 60.74 %\n",
      "Epoch:170/200 AVG Training Loss:0.639 AVG Validation Loss:0.684 AVG Training Acc 62.76 % AVG Validation Acc 60.65 %\n",
      "Epoch:180/200 AVG Training Loss:0.639 AVG Validation Loss:0.686 AVG Training Acc 62.67 % AVG Validation Acc 60.83 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.638 AVG Validation Loss:0.685 AVG Training Acc 62.77 % AVG Validation Acc 60.92 %\n",
      "Epoch:200/200 AVG Training Loss:0.639 AVG Validation Loss:0.684 AVG Training Acc 62.26 % AVG Validation Acc 60.83 %\n",
      "Split 300\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d61072800e419784a64b02d1af07e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.663 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.664 AVG Training Acc 61.84 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:0.666 AVG Training Acc 61.85 % AVG Validation Acc 61.28 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.667 AVG Training Acc 62.23 % AVG Validation Acc 62.00 %\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.650 AVG Validation Loss:0.668 AVG Training Acc 62.02 % AVG Validation Acc 62.36 %\n",
      "Epoch:60/200 AVG Training Loss:0.649 AVG Validation Loss:0.669 AVG Training Acc 62.27 % AVG Validation Acc 61.82 %\n",
      "Epoch:70/200 AVG Training Loss:0.649 AVG Validation Loss:0.670 AVG Training Acc 62.11 % AVG Validation Acc 62.09 %\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.648 AVG Validation Loss:0.671 AVG Training Acc 62.37 % AVG Validation Acc 62.00 %\n",
      "Epoch:90/200 AVG Training Loss:0.649 AVG Validation Loss:0.671 AVG Training Acc 62.33 % AVG Validation Acc 62.18 %\n",
      "Epoch:100/200 AVG Training Loss:0.649 AVG Validation Loss:0.671 AVG Training Acc 62.24 % AVG Validation Acc 62.09 %\n",
      "Epoch   106: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.648 AVG Validation Loss:0.671 AVG Training Acc 62.13 % AVG Validation Acc 62.00 %\n",
      "Epoch:120/200 AVG Training Loss:0.649 AVG Validation Loss:0.671 AVG Training Acc 62.50 % AVG Validation Acc 62.09 %\n",
      "Epoch:130/200 AVG Training Loss:0.648 AVG Validation Loss:0.671 AVG Training Acc 62.17 % AVG Validation Acc 62.09 %\n",
      "Epoch   137: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.649 AVG Validation Loss:0.671 AVG Training Acc 62.14 % AVG Validation Acc 62.00 %\n",
      "Epoch:150/200 AVG Training Loss:0.648 AVG Validation Loss:0.671 AVG Training Acc 62.26 % AVG Validation Acc 62.09 %\n",
      "Epoch:160/200 AVG Training Loss:0.648 AVG Validation Loss:0.671 AVG Training Acc 62.20 % AVG Validation Acc 62.00 %\n",
      "Epoch   168: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.649 AVG Validation Loss:0.671 AVG Training Acc 62.25 % AVG Validation Acc 62.09 %\n",
      "Epoch:180/200 AVG Training Loss:0.649 AVG Validation Loss:0.671 AVG Training Acc 62.21 % AVG Validation Acc 62.09 %\n",
      "Epoch:190/200 AVG Training Loss:0.649 AVG Validation Loss:0.671 AVG Training Acc 62.15 % AVG Validation Acc 61.91 %\n",
      "Epoch:200/200 AVG Training Loss:0.648 AVG Validation Loss:0.671 AVG Training Acc 62.25 % AVG Validation Acc 62.00 %\n",
      "final_gifted\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c500a39180c14a6f94cdf64a2c3d65e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f6fb357fddd4055be2e01529aba3cd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best Accuracy found: 80.16%\n",
      "Epoch: 1\n",
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.499 AVG Training Acc 80.25 % AVG Validation Acc 79.62 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.503 AVG Training Acc 80.36 % AVG Validation Acc 79.62 %\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.506 AVG Training Acc 80.44 % AVG Validation Acc 79.53 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.507 AVG Training Acc 80.66 % AVG Validation Acc 79.53 %\n",
      "Epoch:70/200 AVG Training Loss:0.484 AVG Validation Loss:0.507 AVG Training Acc 80.55 % AVG Validation Acc 79.62 %\n",
      "Epoch:80/200 AVG Training Loss:0.485 AVG Validation Loss:0.507 AVG Training Acc 80.57 % AVG Validation Acc 79.62 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.484 AVG Validation Loss:0.507 AVG Training Acc 80.60 % AVG Validation Acc 79.62 %\n",
      "Epoch:100/200 AVG Training Loss:0.484 AVG Validation Loss:0.508 AVG Training Acc 80.64 % AVG Validation Acc 79.53 %\n",
      "Epoch:110/200 AVG Training Loss:0.484 AVG Validation Loss:0.508 AVG Training Acc 80.54 % AVG Validation Acc 79.44 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.484 AVG Validation Loss:0.507 AVG Training Acc 80.63 % AVG Validation Acc 79.44 %\n",
      "Epoch:130/200 AVG Training Loss:0.484 AVG Validation Loss:0.507 AVG Training Acc 80.61 % AVG Validation Acc 79.53 %\n",
      "Epoch:140/200 AVG Training Loss:0.483 AVG Validation Loss:0.507 AVG Training Acc 80.72 % AVG Validation Acc 79.53 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.484 AVG Validation Loss:0.507 AVG Training Acc 80.52 % AVG Validation Acc 79.44 %\n",
      "Epoch:160/200 AVG Training Loss:0.483 AVG Validation Loss:0.508 AVG Training Acc 80.61 % AVG Validation Acc 79.44 %\n",
      "Epoch:170/200 AVG Training Loss:0.484 AVG Validation Loss:0.508 AVG Training Acc 80.63 % AVG Validation Acc 79.53 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.483 AVG Validation Loss:0.508 AVG Training Acc 80.59 % AVG Validation Acc 79.44 %\n",
      "Epoch:190/200 AVG Training Loss:0.484 AVG Validation Loss:0.508 AVG Training Acc 80.63 % AVG Validation Acc 79.35 %\n",
      "Epoch:200/200 AVG Training Loss:0.483 AVG Validation Loss:0.508 AVG Training Acc 80.69 % AVG Validation Acc 79.44 %\n",
      "Split 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba50355e07a24126b297ff07e6848566",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.493 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "New Best Accuracy found: 80.25%\n",
      "Epoch: 33\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.23 % AVG Validation Acc 80.07 %\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.24 % AVG Validation Acc 80.07 %\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.29 % AVG Validation Acc 79.98 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.22 % AVG Validation Acc 79.98 %\n",
      "Epoch:100/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.22 % AVG Validation Acc 79.98 %\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.22 % AVG Validation Acc 79.89 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.20 % AVG Validation Acc 79.89 %\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.20 % AVG Validation Acc 79.89 %\n",
      "Epoch:140/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.27 % AVG Validation Acc 79.89 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.27 % AVG Validation Acc 79.89 %\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.20 % AVG Validation Acc 79.89 %\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.27 % AVG Validation Acc 79.89 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.22 % AVG Validation Acc 79.89 %\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.22 % AVG Validation Acc 79.89 %\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.24 % AVG Validation Acc 79.89 %\n",
      "Split 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c74e502e911b4725a48964602df0e27c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.18 % AVG Validation Acc 80.25 %\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.20 % AVG Validation Acc 80.07 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.24 % AVG Validation Acc 80.25 %\n",
      "New Best Accuracy found: 80.34%\n",
      "Epoch: 63\n",
      "Epoch:70/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.30 % AVG Validation Acc 80.25 %\n",
      "Epoch:80/200 AVG Training Loss:0.485 AVG Validation Loss:0.494 AVG Training Acc 80.45 % AVG Validation Acc 80.16 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.35 % AVG Validation Acc 80.16 %\n",
      "Epoch:100/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.34 % AVG Validation Acc 80.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.32 % AVG Validation Acc 80.16 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.37 % AVG Validation Acc 80.16 %\n",
      "Epoch:130/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.41 % AVG Validation Acc 80.25 %\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.32 % AVG Validation Acc 80.25 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.39 % AVG Validation Acc 80.16 %\n",
      "Epoch:160/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.35 % AVG Validation Acc 80.16 %\n",
      "Epoch:170/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.38 % AVG Validation Acc 80.16 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.33 % AVG Validation Acc 80.16 %\n",
      "Epoch:190/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.44 % AVG Validation Acc 80.16 %\n",
      "Epoch:200/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.28 % AVG Validation Acc 80.16 %\n",
      "Split 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a951109fb8fa4eb9abff08674c70e5de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.499 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.499 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.497 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.25 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.496 AVG Training Acc 80.16 % AVG Validation Acc 80.25 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.490 AVG Validation Loss:0.496 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.22 % AVG Validation Acc 80.07 %\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.21 % AVG Validation Acc 80.16 %\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch:120/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.20 % AVG Validation Acc 80.16 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.21 % AVG Validation Acc 80.16 %\n",
      "Epoch:140/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:150/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch:170/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.24 % AVG Validation Acc 80.16 %\n",
      "Epoch:180/200 AVG Training Loss:0.490 AVG Validation Loss:0.497 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.20 % AVG Validation Acc 80.16 %\n",
      "Epoch:200/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Split 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76f21d82e1954b289d763bf6845a9a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.499 AVG Training Acc 80.16 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.500 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 79.98 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.18 % AVG Validation Acc 79.89 %\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.36 % AVG Validation Acc 79.80 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.36 % AVG Validation Acc 79.71 %\n",
      "Epoch:70/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.37 % AVG Validation Acc 79.71 %\n",
      "Epoch:80/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.33 % AVG Validation Acc 79.71 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.40 % AVG Validation Acc 79.62 %\n",
      "Epoch:100/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.34 % AVG Validation Acc 79.62 %\n",
      "Epoch:110/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.23 % AVG Validation Acc 79.62 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.39 % AVG Validation Acc 79.62 %\n",
      "Epoch:130/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.35 % AVG Validation Acc 79.62 %\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.35 % AVG Validation Acc 79.62 %\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.46 % AVG Validation Acc 79.62 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.37 % AVG Validation Acc 79.62 %\n",
      "Epoch:170/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.34 % AVG Validation Acc 79.62 %\n",
      "Epoch:180/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.33 % AVG Validation Acc 79.62 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.38 % AVG Validation Acc 79.62 %\n",
      "Epoch:200/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.35 % AVG Validation Acc 79.62 %\n",
      "Split 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f28627b6f3942b999f5274d38a7842a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.492 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.493 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.487 AVG Training Acc 80.22 % AVG Validation Acc 80.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.22 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.28 % AVG Validation Acc 80.05 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.490 AVG Training Acc 80.31 % AVG Validation Acc 80.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.35 % AVG Validation Acc 80.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.487 AVG Validation Loss:0.489 AVG Training Acc 80.37 % AVG Validation Acc 80.05 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.488 AVG Training Acc 80.30 % AVG Validation Acc 80.05 %\n",
      "Epoch:100/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.35 % AVG Validation Acc 80.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.35 % AVG Validation Acc 80.14 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.35 % AVG Validation Acc 80.05 %\n",
      "Epoch:130/200 AVG Training Loss:0.487 AVG Validation Loss:0.489 AVG Training Acc 80.33 % AVG Validation Acc 80.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.33 % AVG Validation Acc 80.14 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.33 % AVG Validation Acc 80.05 %\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.30 % AVG Validation Acc 80.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.487 AVG Validation Loss:0.489 AVG Training Acc 80.34 % AVG Validation Acc 80.05 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.40 % AVG Validation Acc 80.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.489 AVG Training Acc 80.38 % AVG Validation Acc 80.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.38 % AVG Validation Acc 80.14 %\n",
      "Split 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a284de16ec5a4faebfb6eccdce4e8e81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.497 AVG Training Acc 80.19 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.504 AVG Training Acc 80.41 % AVG Validation Acc 79.96 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.505 AVG Training Acc 80.44 % AVG Validation Acc 79.87 %\n",
      "Epoch:70/200 AVG Training Loss:0.481 AVG Validation Loss:0.507 AVG Training Acc 80.57 % AVG Validation Acc 79.60 %\n",
      "Epoch:80/200 AVG Training Loss:0.480 AVG Validation Loss:0.507 AVG Training Acc 80.66 % AVG Validation Acc 79.42 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.479 AVG Validation Loss:0.509 AVG Training Acc 80.68 % AVG Validation Acc 79.51 %\n",
      "Epoch:100/200 AVG Training Loss:0.478 AVG Validation Loss:0.509 AVG Training Acc 80.61 % AVG Validation Acc 79.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.478 AVG Validation Loss:0.508 AVG Training Acc 80.67 % AVG Validation Acc 79.60 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.479 AVG Validation Loss:0.509 AVG Training Acc 80.62 % AVG Validation Acc 79.51 %\n",
      "Epoch:130/200 AVG Training Loss:0.477 AVG Validation Loss:0.509 AVG Training Acc 80.72 % AVG Validation Acc 79.51 %\n",
      "Epoch:140/200 AVG Training Loss:0.479 AVG Validation Loss:0.510 AVG Training Acc 80.58 % AVG Validation Acc 79.42 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.477 AVG Validation Loss:0.509 AVG Training Acc 80.73 % AVG Validation Acc 79.60 %\n",
      "Epoch:160/200 AVG Training Loss:0.478 AVG Validation Loss:0.510 AVG Training Acc 80.65 % AVG Validation Acc 79.42 %\n",
      "Epoch:170/200 AVG Training Loss:0.479 AVG Validation Loss:0.510 AVG Training Acc 80.63 % AVG Validation Acc 79.42 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.478 AVG Validation Loss:0.510 AVG Training Acc 80.74 % AVG Validation Acc 79.42 %\n",
      "Epoch:190/200 AVG Training Loss:0.478 AVG Validation Loss:0.509 AVG Training Acc 80.71 % AVG Validation Acc 79.51 %\n",
      "Epoch:200/200 AVG Training Loss:0.479 AVG Validation Loss:0.510 AVG Training Acc 80.69 % AVG Validation Acc 79.51 %\n",
      "Split 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0779666b2e7943ea93debf53fef2407c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.493 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.493 AVG Training Acc 80.44 % AVG Validation Acc 80.23 %\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.501 AVG Training Acc 80.55 % AVG Validation Acc 80.32 %\n",
      "Epoch:70/200 AVG Training Loss:0.483 AVG Validation Loss:0.504 AVG Training Acc 80.60 % AVG Validation Acc 80.32 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.481 AVG Validation Loss:0.507 AVG Training Acc 80.73 % AVG Validation Acc 80.32 %\n",
      "Epoch:90/200 AVG Training Loss:0.482 AVG Validation Loss:0.507 AVG Training Acc 80.75 % AVG Validation Acc 80.32 %\n",
      "Epoch:100/200 AVG Training Loss:0.480 AVG Validation Loss:0.508 AVG Training Acc 80.74 % AVG Validation Acc 80.14 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.481 AVG Validation Loss:0.508 AVG Training Acc 80.79 % AVG Validation Acc 80.14 %\n",
      "Epoch:120/200 AVG Training Loss:0.481 AVG Validation Loss:0.508 AVG Training Acc 80.75 % AVG Validation Acc 80.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.481 AVG Validation Loss:0.507 AVG Training Acc 80.83 % AVG Validation Acc 80.23 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.480 AVG Validation Loss:0.507 AVG Training Acc 80.74 % AVG Validation Acc 80.14 %\n",
      "Epoch:150/200 AVG Training Loss:0.481 AVG Validation Loss:0.508 AVG Training Acc 80.65 % AVG Validation Acc 80.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.480 AVG Validation Loss:0.506 AVG Training Acc 80.69 % AVG Validation Acc 80.23 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.481 AVG Validation Loss:0.507 AVG Training Acc 80.71 % AVG Validation Acc 80.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.480 AVG Validation Loss:0.508 AVG Training Acc 80.60 % AVG Validation Acc 80.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.480 AVG Validation Loss:0.508 AVG Training Acc 80.82 % AVG Validation Acc 80.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.480 AVG Validation Loss:0.508 AVG Training Acc 80.74 % AVG Validation Acc 80.14 %\n",
      "Epoch   200: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Split 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea932bc4facb49b2bc47d9fedeb3ee32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.493 AVG Validation Loss:0.493 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "New Best Accuracy found: 80.42%\n",
      "Epoch: 33\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.485 AVG Validation Loss:0.493 AVG Training Acc 80.40 % AVG Validation Acc 80.42 %\n",
      "Epoch:50/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.54 % AVG Validation Acc 80.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.480 AVG Validation Loss:0.503 AVG Training Acc 80.66 % AVG Validation Acc 79.87 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.478 AVG Validation Loss:0.509 AVG Training Acc 80.74 % AVG Validation Acc 80.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.477 AVG Validation Loss:0.511 AVG Training Acc 80.75 % AVG Validation Acc 79.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.477 AVG Validation Loss:0.512 AVG Training Acc 80.71 % AVG Validation Acc 79.87 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.476 AVG Validation Loss:0.513 AVG Training Acc 80.78 % AVG Validation Acc 79.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.476 AVG Validation Loss:0.513 AVG Training Acc 80.76 % AVG Validation Acc 79.87 %\n",
      "Epoch:120/200 AVG Training Loss:0.476 AVG Validation Loss:0.514 AVG Training Acc 80.78 % AVG Validation Acc 79.87 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.477 AVG Validation Loss:0.514 AVG Training Acc 80.79 % AVG Validation Acc 79.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.476 AVG Validation Loss:0.513 AVG Training Acc 80.78 % AVG Validation Acc 79.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.476 AVG Validation Loss:0.514 AVG Training Acc 80.68 % AVG Validation Acc 79.78 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.475 AVG Validation Loss:0.513 AVG Training Acc 80.74 % AVG Validation Acc 79.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.477 AVG Validation Loss:0.512 AVG Training Acc 80.66 % AVG Validation Acc 79.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.477 AVG Validation Loss:0.514 AVG Training Acc 80.84 % AVG Validation Acc 79.96 %\n",
      "Epoch:190/200 AVG Training Loss:0.477 AVG Validation Loss:0.513 AVG Training Acc 80.76 % AVG Validation Acc 79.96 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.476 AVG Validation Loss:0.512 AVG Training Acc 80.80 % AVG Validation Acc 79.96 %\n",
      "Split 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c261aca2334481dba35135bd916c4cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.492 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.492 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.491 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.22 % AVG Validation Acc 80.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.27 % AVG Validation Acc 80.05 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.36 % AVG Validation Acc 80.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.29 % AVG Validation Acc 80.05 %\n",
      "Epoch:90/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.30 % AVG Validation Acc 80.05 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.34 % AVG Validation Acc 80.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.31 % AVG Validation Acc 80.05 %\n",
      "Epoch:120/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.29 % AVG Validation Acc 80.05 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.35 % AVG Validation Acc 80.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.486 AVG Validation Loss:0.492 AVG Training Acc 80.29 % AVG Validation Acc 80.05 %\n",
      "Epoch:150/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.34 % AVG Validation Acc 80.05 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.34 % AVG Validation Acc 80.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.30 % AVG Validation Acc 80.05 %\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.32 % AVG Validation Acc 80.05 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.29 % AVG Validation Acc 80.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.487 AVG Validation Loss:0.491 AVG Training Acc 80.31 % AVG Validation Acc 80.05 %\n",
      "Split 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b4c1022590e4405b256a086f3fcc59d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.492 AVG Validation Loss:0.489 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.486 AVG Training Acc 80.21 % AVG Validation Acc 80.25 %\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.484 AVG Training Acc 80.19 % AVG Validation Acc 80.34 %\n",
      "New Best Accuracy found: 80.43%\n",
      "Epoch: 66\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.485 AVG Training Acc 80.27 % AVG Validation Acc 80.25 %\n",
      "Epoch    71: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.485 AVG Training Acc 80.36 % AVG Validation Acc 80.25 %\n",
      "Epoch:90/200 AVG Training Loss:0.487 AVG Validation Loss:0.485 AVG Training Acc 80.34 % AVG Validation Acc 80.25 %\n",
      "Epoch:100/200 AVG Training Loss:0.487 AVG Validation Loss:0.485 AVG Training Acc 80.34 % AVG Validation Acc 80.25 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.487 AVG Validation Loss:0.485 AVG Training Acc 80.34 % AVG Validation Acc 80.25 %\n",
      "Epoch:120/200 AVG Training Loss:0.487 AVG Validation Loss:0.485 AVG Training Acc 80.30 % AVG Validation Acc 80.25 %\n",
      "Epoch:130/200 AVG Training Loss:0.487 AVG Validation Loss:0.485 AVG Training Acc 80.38 % AVG Validation Acc 80.25 %\n",
      "Epoch   133: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.485 AVG Training Acc 80.32 % AVG Validation Acc 80.25 %\n",
      "Epoch:150/200 AVG Training Loss:0.487 AVG Validation Loss:0.486 AVG Training Acc 80.41 % AVG Validation Acc 80.16 %\n",
      "Epoch:160/200 AVG Training Loss:0.487 AVG Validation Loss:0.485 AVG Training Acc 80.34 % AVG Validation Acc 80.25 %\n",
      "Epoch   164: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.487 AVG Validation Loss:0.485 AVG Training Acc 80.33 % AVG Validation Acc 80.16 %\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.485 AVG Training Acc 80.31 % AVG Validation Acc 80.25 %\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.485 AVG Training Acc 80.36 % AVG Validation Acc 80.25 %\n",
      "Epoch   195: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.487 AVG Validation Loss:0.485 AVG Training Acc 80.36 % AVG Validation Acc 80.25 %\n",
      "Split 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2423430491eb403badea686ae9270c1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.492 AVG Training Acc 80.15 % AVG Validation Acc 79.98 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.22 % AVG Validation Acc 79.98 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.17 % AVG Validation Acc 79.89 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.37 % AVG Validation Acc 79.71 %\n",
      "Epoch:60/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.35 % AVG Validation Acc 79.71 %\n",
      "Epoch:70/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.30 % AVG Validation Acc 79.71 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.36 % AVG Validation Acc 79.71 %\n",
      "Epoch:90/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.39 % AVG Validation Acc 79.71 %\n",
      "Epoch:100/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.35 % AVG Validation Acc 79.71 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.37 % AVG Validation Acc 79.71 %\n",
      "Epoch:120/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.40 % AVG Validation Acc 79.71 %\n",
      "Epoch:130/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.39 % AVG Validation Acc 79.71 %\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.30 % AVG Validation Acc 79.71 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.33 % AVG Validation Acc 79.71 %\n",
      "Epoch:160/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.45 % AVG Validation Acc 79.71 %\n",
      "Epoch:170/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.44 % AVG Validation Acc 79.71 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.38 % AVG Validation Acc 79.71 %\n",
      "Epoch:190/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.33 % AVG Validation Acc 79.71 %\n",
      "Epoch:200/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.35 % AVG Validation Acc 79.71 %\n",
      "Split 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a6a8689c48945aa8f0156203d01f039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.20 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.18 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.21 % AVG Validation Acc 80.16 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.18 % AVG Validation Acc 80.07 %\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.22 % AVG Validation Acc 80.07 %\n",
      "Epoch:80/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.23 % AVG Validation Acc 80.07 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.28 % AVG Validation Acc 80.07 %\n",
      "Epoch:100/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.21 % AVG Validation Acc 80.07 %\n",
      "Epoch:110/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.24 % AVG Validation Acc 80.07 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.19 % AVG Validation Acc 80.07 %\n",
      "Epoch:130/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.24 % AVG Validation Acc 80.07 %\n",
      "Epoch:140/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.23 % AVG Validation Acc 80.07 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch:160/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.23 % AVG Validation Acc 80.07 %\n",
      "Epoch:170/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.26 % AVG Validation Acc 80.07 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.20 % AVG Validation Acc 80.07 %\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.20 % AVG Validation Acc 80.07 %\n",
      "Epoch:200/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.18 % AVG Validation Acc 80.07 %\n",
      "Split 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57d44bd40e1746fc83d7cc55570b2793",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.488 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.492 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.486 AVG Training Acc 80.22 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.485 AVG Training Acc 80.34 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.486 AVG Training Acc 80.29 % AVG Validation Acc 80.25 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "New Best Accuracy found: 80.52%\n",
      "Epoch: 52\n",
      "Epoch:60/200 AVG Training Loss:0.487 AVG Validation Loss:0.486 AVG Training Acc 80.32 % AVG Validation Acc 80.43 %\n",
      "Epoch:70/200 AVG Training Loss:0.487 AVG Validation Loss:0.486 AVG Training Acc 80.40 % AVG Validation Acc 80.52 %\n",
      "Epoch:80/200 AVG Training Loss:0.487 AVG Validation Loss:0.486 AVG Training Acc 80.41 % AVG Validation Acc 80.52 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.485 AVG Validation Loss:0.486 AVG Training Acc 80.43 % AVG Validation Acc 80.52 %\n",
      "Epoch:100/200 AVG Training Loss:0.487 AVG Validation Loss:0.486 AVG Training Acc 80.39 % AVG Validation Acc 80.52 %\n",
      "Epoch:110/200 AVG Training Loss:0.487 AVG Validation Loss:0.486 AVG Training Acc 80.40 % AVG Validation Acc 80.52 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.486 AVG Validation Loss:0.486 AVG Training Acc 80.44 % AVG Validation Acc 80.52 %\n",
      "Epoch:130/200 AVG Training Loss:0.487 AVG Validation Loss:0.486 AVG Training Acc 80.38 % AVG Validation Acc 80.52 %\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.486 AVG Training Acc 80.30 % AVG Validation Acc 80.52 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.487 AVG Validation Loss:0.486 AVG Training Acc 80.38 % AVG Validation Acc 80.52 %\n",
      "Epoch:160/200 AVG Training Loss:0.487 AVG Validation Loss:0.486 AVG Training Acc 80.34 % AVG Validation Acc 80.52 %\n",
      "Epoch:170/200 AVG Training Loss:0.486 AVG Validation Loss:0.486 AVG Training Acc 80.38 % AVG Validation Acc 80.52 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.487 AVG Validation Loss:0.487 AVG Training Acc 80.35 % AVG Validation Acc 80.52 %\n",
      "Epoch:190/200 AVG Training Loss:0.486 AVG Validation Loss:0.487 AVG Training Acc 80.45 % AVG Validation Acc 80.52 %\n",
      "Epoch:200/200 AVG Training Loss:0.486 AVG Validation Loss:0.486 AVG Training Acc 80.40 % AVG Validation Acc 80.52 %\n",
      "Split 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e98d5ffc8d94ceb907b3f5cd1f2662c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.501 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.12 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.499 AVG Training Acc 80.18 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.498 AVG Training Acc 80.25 % AVG Validation Acc 80.16 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.16 % AVG Validation Acc 80.07 %\n",
      "Epoch:60/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.11 % AVG Validation Acc 80.07 %\n",
      "Epoch:70/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 80.07 %\n",
      "Epoch:80/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 80.07 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.30 % AVG Validation Acc 79.80 %\n",
      "Epoch:100/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.31 % AVG Validation Acc 79.80 %\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.28 % AVG Validation Acc 79.80 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.34 % AVG Validation Acc 79.80 %\n",
      "Epoch:130/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.41 % AVG Validation Acc 79.80 %\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.35 % AVG Validation Acc 79.80 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.29 % AVG Validation Acc 79.80 %\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.31 % AVG Validation Acc 79.80 %\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.30 % AVG Validation Acc 79.80 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.31 % AVG Validation Acc 79.80 %\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.39 % AVG Validation Acc 79.80 %\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.33 % AVG Validation Acc 79.80 %\n",
      "Split 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1c47accc4c044a8a8122e13515bcf9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.497 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.35 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.494 AVG Training Acc 80.50 % AVG Validation Acc 80.23 %\n",
      "Epoch:60/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.54 % AVG Validation Acc 80.23 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.483 AVG Validation Loss:0.496 AVG Training Acc 80.58 % AVG Validation Acc 80.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.483 AVG Validation Loss:0.496 AVG Training Acc 80.73 % AVG Validation Acc 80.05 %\n",
      "Epoch:90/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.65 % AVG Validation Acc 80.05 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.482 AVG Validation Loss:0.497 AVG Training Acc 80.70 % AVG Validation Acc 80.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.482 AVG Validation Loss:0.497 AVG Training Acc 80.72 % AVG Validation Acc 80.05 %\n",
      "Epoch:120/200 AVG Training Loss:0.482 AVG Validation Loss:0.497 AVG Training Acc 80.72 % AVG Validation Acc 80.05 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.482 AVG Validation Loss:0.498 AVG Training Acc 80.77 % AVG Validation Acc 80.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.482 AVG Validation Loss:0.498 AVG Training Acc 80.74 % AVG Validation Acc 80.05 %\n",
      "Epoch:150/200 AVG Training Loss:0.482 AVG Validation Loss:0.498 AVG Training Acc 80.74 % AVG Validation Acc 80.05 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.70 % AVG Validation Acc 80.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.69 % AVG Validation Acc 80.05 %\n",
      "Epoch:180/200 AVG Training Loss:0.482 AVG Validation Loss:0.497 AVG Training Acc 80.68 % AVG Validation Acc 80.05 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.482 AVG Validation Loss:0.497 AVG Training Acc 80.72 % AVG Validation Acc 80.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.482 AVG Validation Loss:0.498 AVG Training Acc 80.69 % AVG Validation Acc 80.05 %\n",
      "Split 17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e7dc281ad2246e8a6c62a843add7623",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.491 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.491 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.18 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.27 % AVG Validation Acc 79.96 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.34 % AVG Validation Acc 79.96 %\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.24 % AVG Validation Acc 79.78 %\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.25 % AVG Validation Acc 79.87 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.15 % AVG Validation Acc 79.87 %\n",
      "Epoch:100/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.37 % AVG Validation Acc 79.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.486 AVG Validation Loss:0.491 AVG Training Acc 80.28 % AVG Validation Acc 79.87 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.23 % AVG Validation Acc 79.87 %\n",
      "Epoch:130/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.23 % AVG Validation Acc 79.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.491 AVG Training Acc 80.38 % AVG Validation Acc 79.87 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.486 AVG Validation Loss:0.492 AVG Training Acc 80.25 % AVG Validation Acc 79.78 %\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.36 % AVG Validation Acc 79.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.487 AVG Validation Loss:0.491 AVG Training Acc 80.29 % AVG Validation Acc 79.87 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.487 AVG Validation Loss:0.491 AVG Training Acc 80.35 % AVG Validation Acc 79.78 %\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.491 AVG Training Acc 80.45 % AVG Validation Acc 79.78 %\n",
      "Epoch:200/200 AVG Training Loss:0.487 AVG Validation Loss:0.491 AVG Training Acc 80.34 % AVG Validation Acc 79.78 %\n",
      "Split 18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaf83e5a54b246b78d9ca36dbcccfe44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.20 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.30 % AVG Validation Acc 80.05 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.486 AVG Validation Loss:0.491 AVG Training Acc 80.47 % AVG Validation Acc 80.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.486 AVG Validation Loss:0.491 AVG Training Acc 80.36 % AVG Validation Acc 80.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.485 AVG Validation Loss:0.492 AVG Training Acc 80.44 % AVG Validation Acc 80.05 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.486 AVG Validation Loss:0.491 AVG Training Acc 80.40 % AVG Validation Acc 80.05 %\n",
      "Epoch:100/200 AVG Training Loss:0.485 AVG Validation Loss:0.492 AVG Training Acc 80.41 % AVG Validation Acc 80.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.485 AVG Validation Loss:0.491 AVG Training Acc 80.48 % AVG Validation Acc 80.05 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.485 AVG Validation Loss:0.492 AVG Training Acc 80.47 % AVG Validation Acc 80.05 %\n",
      "Epoch:130/200 AVG Training Loss:0.485 AVG Validation Loss:0.492 AVG Training Acc 80.50 % AVG Validation Acc 80.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.485 AVG Validation Loss:0.492 AVG Training Acc 80.47 % AVG Validation Acc 80.05 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.492 AVG Training Acc 80.48 % AVG Validation Acc 80.05 %\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.492 AVG Training Acc 80.51 % AVG Validation Acc 80.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.485 AVG Validation Loss:0.492 AVG Training Acc 80.50 % AVG Validation Acc 80.05 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.485 AVG Validation Loss:0.491 AVG Training Acc 80.48 % AVG Validation Acc 80.05 %\n",
      "Epoch:190/200 AVG Training Loss:0.485 AVG Validation Loss:0.492 AVG Training Acc 80.42 % AVG Validation Acc 80.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.485 AVG Validation Loss:0.491 AVG Training Acc 80.49 % AVG Validation Acc 80.05 %\n",
      "Split 19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e975500158a84e19b9eb15fe71dcbc7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.500 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.490 AVG Validation Loss:0.501 AVG Training Acc 80.15 % AVG Validation Acc 80.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.503 AVG Training Acc 80.17 % AVG Validation Acc 80.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.505 AVG Training Acc 80.27 % AVG Validation Acc 79.96 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.507 AVG Training Acc 80.28 % AVG Validation Acc 79.69 %\n",
      "Epoch:60/200 AVG Training Loss:0.485 AVG Validation Loss:0.507 AVG Training Acc 80.31 % AVG Validation Acc 79.87 %\n",
      "Epoch:70/200 AVG Training Loss:0.484 AVG Validation Loss:0.507 AVG Training Acc 80.38 % AVG Validation Acc 79.87 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.484 AVG Validation Loss:0.508 AVG Training Acc 80.26 % AVG Validation Acc 79.78 %\n",
      "Epoch:90/200 AVG Training Loss:0.484 AVG Validation Loss:0.507 AVG Training Acc 80.40 % AVG Validation Acc 79.78 %\n",
      "Epoch:100/200 AVG Training Loss:0.483 AVG Validation Loss:0.506 AVG Training Acc 80.38 % AVG Validation Acc 79.87 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.485 AVG Validation Loss:0.507 AVG Training Acc 80.34 % AVG Validation Acc 79.87 %\n",
      "Epoch:120/200 AVG Training Loss:0.484 AVG Validation Loss:0.507 AVG Training Acc 80.34 % AVG Validation Acc 79.87 %\n",
      "Epoch:130/200 AVG Training Loss:0.484 AVG Validation Loss:0.507 AVG Training Acc 80.39 % AVG Validation Acc 79.87 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.484 AVG Validation Loss:0.507 AVG Training Acc 80.46 % AVG Validation Acc 79.87 %\n",
      "Epoch:150/200 AVG Training Loss:0.484 AVG Validation Loss:0.507 AVG Training Acc 80.45 % AVG Validation Acc 79.87 %\n",
      "Epoch:160/200 AVG Training Loss:0.484 AVG Validation Loss:0.507 AVG Training Acc 80.41 % AVG Validation Acc 79.87 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.484 AVG Validation Loss:0.507 AVG Training Acc 80.33 % AVG Validation Acc 79.87 %\n",
      "Epoch:180/200 AVG Training Loss:0.483 AVG Validation Loss:0.507 AVG Training Acc 80.41 % AVG Validation Acc 79.87 %\n",
      "Epoch:190/200 AVG Training Loss:0.485 AVG Validation Loss:0.507 AVG Training Acc 80.37 % AVG Validation Acc 79.87 %\n",
      "Epoch:200/200 AVG Training Loss:0.484 AVG Validation Loss:0.507 AVG Training Acc 80.45 % AVG Validation Acc 79.87 %\n",
      "Split 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd1c61d5c20440c197c4367dc3508e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.501 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.502 AVG Training Acc 80.08 % AVG Validation Acc 80.14 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.501 AVG Training Acc 80.19 % AVG Validation Acc 80.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.503 AVG Training Acc 80.30 % AVG Validation Acc 79.87 %\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.507 AVG Training Acc 80.38 % AVG Validation Acc 79.87 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.484 AVG Validation Loss:0.508 AVG Training Acc 80.50 % AVG Validation Acc 79.78 %\n",
      "Epoch:70/200 AVG Training Loss:0.483 AVG Validation Loss:0.508 AVG Training Acc 80.46 % AVG Validation Acc 79.78 %\n",
      "Epoch:80/200 AVG Training Loss:0.483 AVG Validation Loss:0.508 AVG Training Acc 80.52 % AVG Validation Acc 79.87 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.482 AVG Validation Loss:0.507 AVG Training Acc 80.55 % AVG Validation Acc 79.87 %\n",
      "Epoch:100/200 AVG Training Loss:0.483 AVG Validation Loss:0.507 AVG Training Acc 80.58 % AVG Validation Acc 79.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.483 AVG Validation Loss:0.507 AVG Training Acc 80.47 % AVG Validation Acc 79.87 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.483 AVG Validation Loss:0.507 AVG Training Acc 80.45 % AVG Validation Acc 79.87 %\n",
      "Epoch:130/200 AVG Training Loss:0.482 AVG Validation Loss:0.507 AVG Training Acc 80.50 % AVG Validation Acc 79.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.482 AVG Validation Loss:0.507 AVG Training Acc 80.49 % AVG Validation Acc 79.87 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.482 AVG Validation Loss:0.507 AVG Training Acc 80.50 % AVG Validation Acc 79.87 %\n",
      "Epoch:160/200 AVG Training Loss:0.483 AVG Validation Loss:0.507 AVG Training Acc 80.50 % AVG Validation Acc 79.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.483 AVG Validation Loss:0.507 AVG Training Acc 80.44 % AVG Validation Acc 79.87 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.482 AVG Validation Loss:0.507 AVG Training Acc 80.54 % AVG Validation Acc 79.87 %\n",
      "Epoch:190/200 AVG Training Loss:0.482 AVG Validation Loss:0.507 AVG Training Acc 80.56 % AVG Validation Acc 79.87 %\n",
      "Epoch:200/200 AVG Training Loss:0.483 AVG Validation Loss:0.507 AVG Training Acc 80.48 % AVG Validation Acc 79.87 %\n",
      "Split 21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4ccb285a2b947c5a661abb6c59ae246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.493 AVG Training Acc 80.21 % AVG Validation Acc 80.07 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.499 AVG Training Acc 80.46 % AVG Validation Acc 79.80 %\n",
      "Epoch:50/200 AVG Training Loss:0.480 AVG Validation Loss:0.505 AVG Training Acc 80.63 % AVG Validation Acc 79.62 %\n",
      "Epoch:60/200 AVG Training Loss:0.479 AVG Validation Loss:0.509 AVG Training Acc 80.73 % AVG Validation Acc 79.17 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.476 AVG Validation Loss:0.511 AVG Training Acc 80.92 % AVG Validation Acc 79.17 %\n",
      "Epoch:80/200 AVG Training Loss:0.476 AVG Validation Loss:0.511 AVG Training Acc 80.87 % AVG Validation Acc 79.35 %\n",
      "Epoch:90/200 AVG Training Loss:0.475 AVG Validation Loss:0.514 AVG Training Acc 81.01 % AVG Validation Acc 78.99 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.474 AVG Validation Loss:0.513 AVG Training Acc 80.90 % AVG Validation Acc 79.08 %\n",
      "Epoch:110/200 AVG Training Loss:0.474 AVG Validation Loss:0.514 AVG Training Acc 80.92 % AVG Validation Acc 78.99 %\n",
      "Epoch:120/200 AVG Training Loss:0.475 AVG Validation Loss:0.515 AVG Training Acc 80.92 % AVG Validation Acc 79.17 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.474 AVG Validation Loss:0.514 AVG Training Acc 80.89 % AVG Validation Acc 79.08 %\n",
      "Epoch:140/200 AVG Training Loss:0.475 AVG Validation Loss:0.514 AVG Training Acc 80.83 % AVG Validation Acc 79.17 %\n",
      "Epoch:150/200 AVG Training Loss:0.475 AVG Validation Loss:0.512 AVG Training Acc 80.86 % AVG Validation Acc 79.44 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.474 AVG Validation Loss:0.515 AVG Training Acc 81.11 % AVG Validation Acc 79.08 %\n",
      "Epoch:170/200 AVG Training Loss:0.474 AVG Validation Loss:0.513 AVG Training Acc 81.00 % AVG Validation Acc 79.17 %\n",
      "Epoch:180/200 AVG Training Loss:0.475 AVG Validation Loss:0.513 AVG Training Acc 80.98 % AVG Validation Acc 78.99 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.475 AVG Validation Loss:0.515 AVG Training Acc 80.91 % AVG Validation Acc 78.90 %\n",
      "Epoch:200/200 AVG Training Loss:0.474 AVG Validation Loss:0.514 AVG Training Acc 80.87 % AVG Validation Acc 78.99 %\n",
      "Split 22\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "059fc3ec43704d978ba2ec4738abcf29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.22 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.34 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.499 AVG Training Acc 80.40 % AVG Validation Acc 80.25 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.484 AVG Validation Loss:0.501 AVG Training Acc 80.54 % AVG Validation Acc 80.25 %\n",
      "Epoch:70/200 AVG Training Loss:0.482 AVG Validation Loss:0.500 AVG Training Acc 80.64 % AVG Validation Acc 80.25 %\n",
      "Epoch:80/200 AVG Training Loss:0.482 AVG Validation Loss:0.498 AVG Training Acc 80.63 % AVG Validation Acc 80.34 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.482 AVG Validation Loss:0.498 AVG Training Acc 80.63 % AVG Validation Acc 80.25 %\n",
      "Epoch:100/200 AVG Training Loss:0.482 AVG Validation Loss:0.499 AVG Training Acc 80.63 % AVG Validation Acc 80.25 %\n",
      "Epoch:110/200 AVG Training Loss:0.482 AVG Validation Loss:0.500 AVG Training Acc 80.57 % AVG Validation Acc 80.25 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.482 AVG Validation Loss:0.500 AVG Training Acc 80.69 % AVG Validation Acc 80.25 %\n",
      "Epoch:130/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.73 % AVG Validation Acc 80.25 %\n",
      "Epoch:140/200 AVG Training Loss:0.482 AVG Validation Loss:0.499 AVG Training Acc 80.66 % AVG Validation Acc 80.25 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.482 AVG Validation Loss:0.500 AVG Training Acc 80.68 % AVG Validation Acc 80.25 %\n",
      "Epoch:160/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.68 % AVG Validation Acc 80.25 %\n",
      "Epoch:170/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.73 % AVG Validation Acc 80.25 %\n",
      "Epoch:180/200 AVG Training Loss:0.481 AVG Validation Loss:0.500 AVG Training Acc 80.62 % AVG Validation Acc 80.25 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.482 AVG Validation Loss:0.499 AVG Training Acc 80.69 % AVG Validation Acc 80.25 %\n",
      "Epoch:200/200 AVG Training Loss:0.482 AVG Validation Loss:0.500 AVG Training Acc 80.56 % AVG Validation Acc 80.25 %\n",
      "Split 23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a9fbcceb7814a1e85cc91eed98ca027",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.498 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.499 AVG Training Acc 80.21 % AVG Validation Acc 80.07 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.499 AVG Training Acc 80.44 % AVG Validation Acc 79.80 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.502 AVG Training Acc 80.60 % AVG Validation Acc 79.71 %\n",
      "Epoch:60/200 AVG Training Loss:0.484 AVG Validation Loss:0.502 AVG Training Acc 80.46 % AVG Validation Acc 79.89 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.483 AVG Validation Loss:0.503 AVG Training Acc 80.57 % AVG Validation Acc 79.80 %\n",
      "Epoch:80/200 AVG Training Loss:0.484 AVG Validation Loss:0.502 AVG Training Acc 80.57 % AVG Validation Acc 79.80 %\n",
      "Epoch:90/200 AVG Training Loss:0.483 AVG Validation Loss:0.503 AVG Training Acc 80.54 % AVG Validation Acc 79.71 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.482 AVG Validation Loss:0.503 AVG Training Acc 80.63 % AVG Validation Acc 79.71 %\n",
      "Epoch:110/200 AVG Training Loss:0.483 AVG Validation Loss:0.503 AVG Training Acc 80.64 % AVG Validation Acc 79.71 %\n",
      "Epoch:120/200 AVG Training Loss:0.482 AVG Validation Loss:0.503 AVG Training Acc 80.63 % AVG Validation Acc 79.71 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.482 AVG Validation Loss:0.503 AVG Training Acc 80.61 % AVG Validation Acc 79.71 %\n",
      "Epoch:140/200 AVG Training Loss:0.482 AVG Validation Loss:0.503 AVG Training Acc 80.68 % AVG Validation Acc 79.71 %\n",
      "Epoch:150/200 AVG Training Loss:0.482 AVG Validation Loss:0.503 AVG Training Acc 80.63 % AVG Validation Acc 79.71 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.483 AVG Validation Loss:0.504 AVG Training Acc 80.67 % AVG Validation Acc 79.71 %\n",
      "Epoch:170/200 AVG Training Loss:0.482 AVG Validation Loss:0.503 AVG Training Acc 80.70 % AVG Validation Acc 79.71 %\n",
      "Epoch:180/200 AVG Training Loss:0.483 AVG Validation Loss:0.504 AVG Training Acc 80.67 % AVG Validation Acc 79.71 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.483 AVG Validation Loss:0.503 AVG Training Acc 80.62 % AVG Validation Acc 79.71 %\n",
      "Epoch:200/200 AVG Training Loss:0.483 AVG Validation Loss:0.503 AVG Training Acc 80.61 % AVG Validation Acc 79.71 %\n",
      "Split 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c02b856a54fd49028d68a32b8a168c14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.39 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.43 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.54 % AVG Validation Acc 80.07 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.58 % AVG Validation Acc 79.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.57 % AVG Validation Acc 79.98 %\n",
      "Epoch:90/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.60 % AVG Validation Acc 80.07 %\n",
      "Epoch:100/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.72 % AVG Validation Acc 79.89 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.480 AVG Validation Loss:0.500 AVG Training Acc 80.64 % AVG Validation Acc 79.89 %\n",
      "Epoch:120/200 AVG Training Loss:0.482 AVG Validation Loss:0.500 AVG Training Acc 80.58 % AVG Validation Acc 79.98 %\n",
      "Epoch:130/200 AVG Training Loss:0.481 AVG Validation Loss:0.500 AVG Training Acc 80.62 % AVG Validation Acc 79.89 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.480 AVG Validation Loss:0.499 AVG Training Acc 80.70 % AVG Validation Acc 79.89 %\n",
      "Epoch:150/200 AVG Training Loss:0.482 AVG Validation Loss:0.500 AVG Training Acc 80.63 % AVG Validation Acc 79.98 %\n",
      "Epoch:160/200 AVG Training Loss:0.481 AVG Validation Loss:0.500 AVG Training Acc 80.63 % AVG Validation Acc 79.89 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.481 AVG Validation Loss:0.500 AVG Training Acc 80.62 % AVG Validation Acc 79.89 %\n",
      "Epoch:180/200 AVG Training Loss:0.480 AVG Validation Loss:0.500 AVG Training Acc 80.69 % AVG Validation Acc 79.89 %\n",
      "Epoch:190/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.63 % AVG Validation Acc 79.89 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.480 AVG Validation Loss:0.500 AVG Training Acc 80.64 % AVG Validation Acc 79.89 %\n",
      "Split 25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5016a7351dd4636914609d8667863c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.500 AVG Training Acc 80.12 % AVG Validation Acc 80.07 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.34 % AVG Validation Acc 79.80 %\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.499 AVG Training Acc 80.58 % AVG Validation Acc 79.44 %\n",
      "Epoch:50/200 AVG Training Loss:0.483 AVG Validation Loss:0.500 AVG Training Acc 80.66 % AVG Validation Acc 79.62 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.482 AVG Validation Loss:0.501 AVG Training Acc 80.69 % AVG Validation Acc 79.26 %\n",
      "Epoch:70/200 AVG Training Loss:0.481 AVG Validation Loss:0.501 AVG Training Acc 80.73 % AVG Validation Acc 79.35 %\n",
      "Epoch:80/200 AVG Training Loss:0.480 AVG Validation Loss:0.502 AVG Training Acc 80.73 % AVG Validation Acc 79.17 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.481 AVG Validation Loss:0.503 AVG Training Acc 80.73 % AVG Validation Acc 79.26 %\n",
      "Epoch:100/200 AVG Training Loss:0.480 AVG Validation Loss:0.502 AVG Training Acc 80.82 % AVG Validation Acc 79.26 %\n",
      "Epoch:110/200 AVG Training Loss:0.480 AVG Validation Loss:0.502 AVG Training Acc 80.77 % AVG Validation Acc 79.26 %\n",
      "Epoch:120/200 AVG Training Loss:0.481 AVG Validation Loss:0.502 AVG Training Acc 80.73 % AVG Validation Acc 79.26 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.481 AVG Validation Loss:0.503 AVG Training Acc 80.72 % AVG Validation Acc 79.26 %\n",
      "Epoch:140/200 AVG Training Loss:0.480 AVG Validation Loss:0.502 AVG Training Acc 80.76 % AVG Validation Acc 79.35 %\n",
      "Epoch:150/200 AVG Training Loss:0.481 AVG Validation Loss:0.503 AVG Training Acc 80.71 % AVG Validation Acc 79.26 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.481 AVG Validation Loss:0.503 AVG Training Acc 80.81 % AVG Validation Acc 79.26 %\n",
      "Epoch:170/200 AVG Training Loss:0.481 AVG Validation Loss:0.502 AVG Training Acc 80.77 % AVG Validation Acc 79.35 %\n",
      "Epoch:180/200 AVG Training Loss:0.480 AVG Validation Loss:0.502 AVG Training Acc 80.75 % AVG Validation Acc 79.26 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.481 AVG Validation Loss:0.502 AVG Training Acc 80.78 % AVG Validation Acc 79.26 %\n",
      "Epoch:200/200 AVG Training Loss:0.480 AVG Validation Loss:0.503 AVG Training Acc 80.71 % AVG Validation Acc 79.26 %\n",
      "Split 26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2edd22637b044a239470c5c01c0cea68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.496 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.497 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.497 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.490 AVG Validation Loss:0.496 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.490 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.24 % AVG Validation Acc 80.14 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch:120/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.490 AVG Validation Loss:0.496 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch:150/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.490 AVG Validation Loss:0.497 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.490 AVG Validation Loss:0.497 AVG Training Acc 80.25 % AVG Validation Acc 80.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.490 AVG Validation Loss:0.497 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Split 27\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03ba81666ed34325b86791d33c3369a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.489 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.19 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.26 % AVG Validation Acc 80.23 %\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.30 % AVG Validation Acc 80.23 %\n",
      "Epoch:80/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.25 % AVG Validation Acc 80.23 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.35 % AVG Validation Acc 80.23 %\n",
      "Epoch:100/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.23 % AVG Validation Acc 80.23 %\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.27 % AVG Validation Acc 80.23 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.28 % AVG Validation Acc 80.23 %\n",
      "Epoch:130/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.33 % AVG Validation Acc 80.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.21 % AVG Validation Acc 80.23 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.27 % AVG Validation Acc 80.23 %\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.31 % AVG Validation Acc 80.23 %\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.35 % AVG Validation Acc 80.23 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.29 % AVG Validation Acc 80.23 %\n",
      "Epoch:190/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.28 % AVG Validation Acc 80.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.32 % AVG Validation Acc 80.23 %\n",
      "Split 28\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa31a398657744ab83f53eff7ed087ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.17 % AVG Validation Acc 80.23 %\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.487 AVG Validation Loss:0.491 AVG Training Acc 80.28 % AVG Validation Acc 80.32 %\n",
      "Epoch:90/200 AVG Training Loss:0.486 AVG Validation Loss:0.491 AVG Training Acc 80.31 % AVG Validation Acc 80.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.485 AVG Validation Loss:0.490 AVG Training Acc 80.36 % AVG Validation Acc 80.32 %\n",
      "Epoch:110/200 AVG Training Loss:0.485 AVG Validation Loss:0.490 AVG Training Acc 80.47 % AVG Validation Acc 80.32 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:120/200 AVG Training Loss:0.482 AVG Validation Loss:0.490 AVG Training Acc 80.54 % AVG Validation Acc 80.32 %\n",
      "Epoch:130/200 AVG Training Loss:0.483 AVG Validation Loss:0.491 AVG Training Acc 80.46 % AVG Validation Acc 80.32 %\n",
      "Epoch:140/200 AVG Training Loss:0.483 AVG Validation Loss:0.492 AVG Training Acc 80.40 % AVG Validation Acc 80.32 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.483 AVG Validation Loss:0.492 AVG Training Acc 80.57 % AVG Validation Acc 80.32 %\n",
      "Epoch:160/200 AVG Training Loss:0.483 AVG Validation Loss:0.492 AVG Training Acc 80.57 % AVG Validation Acc 80.32 %\n",
      "Epoch:170/200 AVG Training Loss:0.483 AVG Validation Loss:0.492 AVG Training Acc 80.42 % AVG Validation Acc 80.32 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:180/200 AVG Training Loss:0.483 AVG Validation Loss:0.491 AVG Training Acc 80.57 % AVG Validation Acc 80.32 %\n",
      "Epoch:190/200 AVG Training Loss:0.483 AVG Validation Loss:0.492 AVG Training Acc 80.53 % AVG Validation Acc 80.32 %\n",
      "Epoch:200/200 AVG Training Loss:0.482 AVG Validation Loss:0.491 AVG Training Acc 80.50 % AVG Validation Acc 80.32 %\n",
      "Split 29\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c9c1a43d6b4ef792aee54b4e69a5a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.27 % AVG Validation Acc 79.96 %\n",
      "Epoch:60/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.36 % AVG Validation Acc 79.87 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.485 AVG Validation Loss:0.494 AVG Training Acc 80.42 % AVG Validation Acc 79.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.48 % AVG Validation Acc 79.87 %\n",
      "Epoch:90/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.55 % AVG Validation Acc 79.87 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.55 % AVG Validation Acc 79.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.46 % AVG Validation Acc 79.87 %\n",
      "Epoch:120/200 AVG Training Loss:0.483 AVG Validation Loss:0.496 AVG Training Acc 80.57 % AVG Validation Acc 79.87 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.53 % AVG Validation Acc 79.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.50 % AVG Validation Acc 79.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.56 % AVG Validation Acc 79.87 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.47 % AVG Validation Acc 79.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.47 % AVG Validation Acc 79.87 %\n",
      "Epoch:180/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.46 % AVG Validation Acc 79.87 %\n",
      "Epoch:190/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.54 % AVG Validation Acc 79.87 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.40 % AVG Validation Acc 79.87 %\n",
      "Split 30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d5f6d87d48d40b9a734063c2873f46e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.492 AVG Training Acc 80.10 % AVG Validation Acc 80.14 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.488 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.488 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.488 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.25 % AVG Validation Acc 80.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.33 % AVG Validation Acc 80.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.26 % AVG Validation Acc 79.96 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.28 % AVG Validation Acc 79.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.32 % AVG Validation Acc 80.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.20 % AVG Validation Acc 80.05 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.28 % AVG Validation Acc 80.05 %\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.32 % AVG Validation Acc 80.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.26 % AVG Validation Acc 80.05 %\n",
      "Epoch:150/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.29 % AVG Validation Acc 80.05 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.35 % AVG Validation Acc 80.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.31 % AVG Validation Acc 80.05 %\n",
      "Epoch:180/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.31 % AVG Validation Acc 80.05 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.32 % AVG Validation Acc 80.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.32 % AVG Validation Acc 80.05 %\n",
      "Split 31\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d678d866154b491cb1b02138e79fcbe4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.21 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.35 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.35 % AVG Validation Acc 80.07 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.47 % AVG Validation Acc 79.89 %\n",
      "Epoch:70/200 AVG Training Loss:0.483 AVG Validation Loss:0.496 AVG Training Acc 80.61 % AVG Validation Acc 79.89 %\n",
      "Epoch:80/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.54 % AVG Validation Acc 79.80 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.59 % AVG Validation Acc 79.80 %\n",
      "Epoch:100/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.49 % AVG Validation Acc 79.80 %\n",
      "Epoch:110/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.60 % AVG Validation Acc 79.89 %\n",
      "Epoch:120/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.58 % AVG Validation Acc 79.80 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.56 % AVG Validation Acc 79.80 %\n",
      "Epoch:140/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.64 % AVG Validation Acc 79.80 %\n",
      "Epoch:150/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.54 % AVG Validation Acc 79.80 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.482 AVG Validation Loss:0.497 AVG Training Acc 80.57 % AVG Validation Acc 79.80 %\n",
      "Epoch:170/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.64 % AVG Validation Acc 79.80 %\n",
      "Epoch:180/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.58 % AVG Validation Acc 79.80 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.49 % AVG Validation Acc 79.80 %\n",
      "Epoch:200/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.64 % AVG Validation Acc 79.80 %\n",
      "Split 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c772df84d6d41b8a79edabae3966cb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.492 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.493 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.27 % AVG Validation Acc 79.98 %\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.25 % AVG Validation Acc 79.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.28 % AVG Validation Acc 79.98 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.25 % AVG Validation Acc 79.98 %\n",
      "Epoch:100/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.19 % AVG Validation Acc 79.98 %\n",
      "Epoch:110/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.24 % AVG Validation Acc 79.98 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.17 % AVG Validation Acc 79.98 %\n",
      "Epoch:130/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.24 % AVG Validation Acc 79.98 %\n",
      "Epoch:140/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.28 % AVG Validation Acc 79.89 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.27 % AVG Validation Acc 79.98 %\n",
      "Epoch:160/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.21 % AVG Validation Acc 79.98 %\n",
      "Epoch:170/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.25 % AVG Validation Acc 79.98 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.28 % AVG Validation Acc 79.98 %\n",
      "Epoch:190/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.24 % AVG Validation Acc 79.98 %\n",
      "Epoch:200/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.25 % AVG Validation Acc 79.98 %\n",
      "Split 33\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cfd3bfe4d74492ab52cca8a8fb501e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.21 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.33 % AVG Validation Acc 80.07 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.484 AVG Validation Loss:0.492 AVG Training Acc 80.59 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.476 AVG Validation Loss:0.499 AVG Training Acc 80.90 % AVG Validation Acc 79.71 %\n",
      "Epoch:70/200 AVG Training Loss:0.473 AVG Validation Loss:0.502 AVG Training Acc 81.04 % AVG Validation Acc 79.53 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.470 AVG Validation Loss:0.503 AVG Training Acc 81.22 % AVG Validation Acc 79.53 %\n",
      "Epoch:90/200 AVG Training Loss:0.469 AVG Validation Loss:0.505 AVG Training Acc 81.13 % AVG Validation Acc 79.53 %\n",
      "Epoch:100/200 AVG Training Loss:0.469 AVG Validation Loss:0.504 AVG Training Acc 81.20 % AVG Validation Acc 79.71 %\n",
      "Epoch:110/200 AVG Training Loss:0.466 AVG Validation Loss:0.506 AVG Training Acc 81.44 % AVG Validation Acc 79.71 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.467 AVG Validation Loss:0.505 AVG Training Acc 81.34 % AVG Validation Acc 79.62 %\n",
      "Epoch:130/200 AVG Training Loss:0.468 AVG Validation Loss:0.507 AVG Training Acc 81.23 % AVG Validation Acc 79.62 %\n",
      "Epoch:140/200 AVG Training Loss:0.467 AVG Validation Loss:0.502 AVG Training Acc 81.37 % AVG Validation Acc 80.07 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.467 AVG Validation Loss:0.504 AVG Training Acc 81.37 % AVG Validation Acc 79.71 %\n",
      "Epoch:160/200 AVG Training Loss:0.467 AVG Validation Loss:0.505 AVG Training Acc 81.49 % AVG Validation Acc 79.89 %\n",
      "Epoch:170/200 AVG Training Loss:0.466 AVG Validation Loss:0.504 AVG Training Acc 81.42 % AVG Validation Acc 80.07 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.467 AVG Validation Loss:0.504 AVG Training Acc 81.37 % AVG Validation Acc 79.71 %\n",
      "Epoch:190/200 AVG Training Loss:0.467 AVG Validation Loss:0.503 AVG Training Acc 81.45 % AVG Validation Acc 79.80 %\n",
      "Epoch:200/200 AVG Training Loss:0.467 AVG Validation Loss:0.505 AVG Training Acc 81.46 % AVG Validation Acc 79.80 %\n",
      "Split 34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40b6abbed64a4616a60d2ac196337c3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.489 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.493 AVG Validation Loss:0.490 AVG Training Acc 80.16 % AVG Validation Acc 80.25 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.485 AVG Training Acc 80.21 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.487 AVG Training Acc 80.28 % AVG Validation Acc 80.07 %\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.24 % AVG Validation Acc 79.80 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.32 % AVG Validation Acc 79.80 %\n",
      "Epoch:80/200 AVG Training Loss:0.487 AVG Validation Loss:0.489 AVG Training Acc 80.31 % AVG Validation Acc 79.89 %\n",
      "Epoch:90/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.42 % AVG Validation Acc 79.98 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.43 % AVG Validation Acc 79.89 %\n",
      "Epoch:110/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.34 % AVG Validation Acc 79.98 %\n",
      "Epoch:120/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.46 % AVG Validation Acc 79.98 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.31 % AVG Validation Acc 79.89 %\n",
      "Epoch:140/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.45 % AVG Validation Acc 79.80 %\n",
      "Epoch:150/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.33 % AVG Validation Acc 79.89 %\n",
      "Epoch:160/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.37 % AVG Validation Acc 79.98 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.35 % AVG Validation Acc 79.89 %\n",
      "Epoch:180/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.36 % AVG Validation Acc 79.89 %\n",
      "Epoch:190/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.42 % AVG Validation Acc 79.98 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.28 % AVG Validation Acc 79.98 %\n",
      "Split 35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1493c0742c3a42ef9d6f5a5b9b65287a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.501 AVG Training Acc 80.13 % AVG Validation Acc 80.07 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.499 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.499 AVG Training Acc 80.18 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.500 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.500 AVG Training Acc 80.31 % AVG Validation Acc 79.98 %\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.502 AVG Training Acc 80.33 % AVG Validation Acc 79.98 %\n",
      "Epoch:70/200 AVG Training Loss:0.487 AVG Validation Loss:0.501 AVG Training Acc 80.33 % AVG Validation Acc 79.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.487 AVG Validation Loss:0.502 AVG Training Acc 80.35 % AVG Validation Acc 79.98 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.487 AVG Validation Loss:0.502 AVG Training Acc 80.34 % AVG Validation Acc 79.98 %\n",
      "Epoch:100/200 AVG Training Loss:0.486 AVG Validation Loss:0.501 AVG Training Acc 80.34 % AVG Validation Acc 79.98 %\n",
      "Epoch:110/200 AVG Training Loss:0.487 AVG Validation Loss:0.501 AVG Training Acc 80.35 % AVG Validation Acc 79.98 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.487 AVG Validation Loss:0.502 AVG Training Acc 80.35 % AVG Validation Acc 79.89 %\n",
      "Epoch:130/200 AVG Training Loss:0.487 AVG Validation Loss:0.501 AVG Training Acc 80.34 % AVG Validation Acc 79.89 %\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.501 AVG Training Acc 80.31 % AVG Validation Acc 79.89 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.486 AVG Validation Loss:0.502 AVG Training Acc 80.41 % AVG Validation Acc 79.89 %\n",
      "Epoch:160/200 AVG Training Loss:0.486 AVG Validation Loss:0.501 AVG Training Acc 80.31 % AVG Validation Acc 79.89 %\n",
      "Epoch:170/200 AVG Training Loss:0.486 AVG Validation Loss:0.502 AVG Training Acc 80.38 % AVG Validation Acc 79.89 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.487 AVG Validation Loss:0.502 AVG Training Acc 80.35 % AVG Validation Acc 79.89 %\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.502 AVG Training Acc 80.34 % AVG Validation Acc 79.89 %\n",
      "Epoch:200/200 AVG Training Loss:0.487 AVG Validation Loss:0.501 AVG Training Acc 80.41 % AVG Validation Acc 79.89 %\n",
      "Split 36\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8af6424faefa40ab9e77264117019d62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.501 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.490 AVG Validation Loss:0.502 AVG Training Acc 80.16 % AVG Validation Acc 80.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.502 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.502 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.502 AVG Training Acc 80.24 % AVG Validation Acc 80.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.502 AVG Training Acc 80.21 % AVG Validation Acc 80.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.487 AVG Validation Loss:0.502 AVG Training Acc 80.36 % AVG Validation Acc 80.05 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.503 AVG Training Acc 80.29 % AVG Validation Acc 80.05 %\n",
      "Epoch:90/200 AVG Training Loss:0.487 AVG Validation Loss:0.502 AVG Training Acc 80.34 % AVG Validation Acc 80.05 %\n",
      "Epoch:100/200 AVG Training Loss:0.487 AVG Validation Loss:0.503 AVG Training Acc 80.29 % AVG Validation Acc 80.05 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.487 AVG Validation Loss:0.503 AVG Training Acc 80.28 % AVG Validation Acc 80.05 %\n",
      "Epoch:120/200 AVG Training Loss:0.487 AVG Validation Loss:0.503 AVG Training Acc 80.25 % AVG Validation Acc 80.05 %\n",
      "Epoch:130/200 AVG Training Loss:0.487 AVG Validation Loss:0.503 AVG Training Acc 80.35 % AVG Validation Acc 80.05 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.503 AVG Training Acc 80.30 % AVG Validation Acc 80.05 %\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.503 AVG Training Acc 80.28 % AVG Validation Acc 80.05 %\n",
      "Epoch:160/200 AVG Training Loss:0.487 AVG Validation Loss:0.503 AVG Training Acc 80.33 % AVG Validation Acc 80.05 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.487 AVG Validation Loss:0.503 AVG Training Acc 80.30 % AVG Validation Acc 80.05 %\n",
      "Epoch:180/200 AVG Training Loss:0.487 AVG Validation Loss:0.503 AVG Training Acc 80.26 % AVG Validation Acc 80.05 %\n",
      "Epoch:190/200 AVG Training Loss:0.486 AVG Validation Loss:0.503 AVG Training Acc 80.36 % AVG Validation Acc 80.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.503 AVG Training Acc 80.25 % AVG Validation Acc 80.05 %\n",
      "Split 37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ef46c2f43c463aa55e688daf3980f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.23 %\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.18 % AVG Validation Acc 80.23 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.27 % AVG Validation Acc 80.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.30 % AVG Validation Acc 80.23 %\n",
      "Epoch:80/200 AVG Training Loss:0.486 AVG Validation Loss:0.499 AVG Training Acc 80.42 % AVG Validation Acc 80.14 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.486 AVG Validation Loss:0.499 AVG Training Acc 80.32 % AVG Validation Acc 80.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.485 AVG Validation Loss:0.499 AVG Training Acc 80.31 % AVG Validation Acc 80.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.485 AVG Validation Loss:0.499 AVG Training Acc 80.36 % AVG Validation Acc 80.14 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.29 % AVG Validation Acc 80.23 %\n",
      "Epoch:130/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.34 % AVG Validation Acc 80.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.485 AVG Validation Loss:0.499 AVG Training Acc 80.35 % AVG Validation Acc 80.14 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.484 AVG Validation Loss:0.499 AVG Training Acc 80.50 % AVG Validation Acc 80.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.486 AVG Validation Loss:0.499 AVG Training Acc 80.30 % AVG Validation Acc 80.23 %\n",
      "Epoch:170/200 AVG Training Loss:0.485 AVG Validation Loss:0.499 AVG Training Acc 80.38 % AVG Validation Acc 80.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.38 % AVG Validation Acc 80.23 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.40 % AVG Validation Acc 80.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.486 AVG Validation Loss:0.499 AVG Training Acc 80.44 % AVG Validation Acc 80.23 %\n",
      "Split 38\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf476000ad7453db6b158ddf718d20b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.498 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.34 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.42 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.35 % AVG Validation Acc 79.96 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.42 % AVG Validation Acc 79.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.483 AVG Validation Loss:0.496 AVG Training Acc 80.53 % AVG Validation Acc 79.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.66 % AVG Validation Acc 79.96 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.49 % AVG Validation Acc 79.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.51 % AVG Validation Acc 79.78 %\n",
      "Epoch:120/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.53 % AVG Validation Acc 79.87 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.49 % AVG Validation Acc 79.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.53 % AVG Validation Acc 79.87 %\n",
      "Epoch:150/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.52 % AVG Validation Acc 79.78 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.58 % AVG Validation Acc 79.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.55 % AVG Validation Acc 79.78 %\n",
      "Epoch:180/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.51 % AVG Validation Acc 79.87 %\n",
      "Epoch:190/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.50 % AVG Validation Acc 79.78 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.52 % AVG Validation Acc 79.87 %\n",
      "Split 39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b70ec82ae24f8a99310ca0d3c54cc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.492 AVG Training Acc 80.19 % AVG Validation Acc 80.23 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.492 AVG Training Acc 80.34 % AVG Validation Acc 80.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.482 AVG Validation Loss:0.497 AVG Training Acc 80.42 % AVG Validation Acc 79.60 %\n",
      "Epoch:70/200 AVG Training Loss:0.480 AVG Validation Loss:0.502 AVG Training Acc 80.67 % AVG Validation Acc 79.42 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.477 AVG Validation Loss:0.504 AVG Training Acc 80.79 % AVG Validation Acc 79.33 %\n",
      "Epoch:90/200 AVG Training Loss:0.477 AVG Validation Loss:0.506 AVG Training Acc 80.75 % AVG Validation Acc 79.24 %\n",
      "Epoch:100/200 AVG Training Loss:0.477 AVG Validation Loss:0.507 AVG Training Acc 80.79 % AVG Validation Acc 79.24 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.476 AVG Validation Loss:0.507 AVG Training Acc 80.86 % AVG Validation Acc 79.06 %\n",
      "Epoch:120/200 AVG Training Loss:0.477 AVG Validation Loss:0.505 AVG Training Acc 80.85 % AVG Validation Acc 79.42 %\n",
      "Epoch:130/200 AVG Training Loss:0.476 AVG Validation Loss:0.508 AVG Training Acc 80.77 % AVG Validation Acc 78.97 %\n",
      "Epoch:140/200 AVG Training Loss:0.476 AVG Validation Loss:0.507 AVG Training Acc 80.84 % AVG Validation Acc 79.15 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.476 AVG Validation Loss:0.507 AVG Training Acc 80.91 % AVG Validation Acc 79.24 %\n",
      "Epoch:160/200 AVG Training Loss:0.476 AVG Validation Loss:0.505 AVG Training Acc 80.88 % AVG Validation Acc 79.24 %\n",
      "Epoch:170/200 AVG Training Loss:0.475 AVG Validation Loss:0.508 AVG Training Acc 80.85 % AVG Validation Acc 79.15 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.476 AVG Validation Loss:0.507 AVG Training Acc 80.88 % AVG Validation Acc 79.06 %\n",
      "Epoch:190/200 AVG Training Loss:0.476 AVG Validation Loss:0.507 AVG Training Acc 80.85 % AVG Validation Acc 79.15 %\n",
      "Epoch:200/200 AVG Training Loss:0.475 AVG Validation Loss:0.505 AVG Training Acc 80.93 % AVG Validation Acc 79.15 %\n",
      "Split 40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e57fea1c110d4b43baf9b403a7b16a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.490 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.493 AVG Validation Loss:0.491 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.492 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.489 AVG Training Acc 80.34 % AVG Validation Acc 80.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.482 AVG Validation Loss:0.489 AVG Training Acc 80.73 % AVG Validation Acc 79.96 %\n",
      "Epoch:70/200 AVG Training Loss:0.479 AVG Validation Loss:0.492 AVG Training Acc 80.84 % AVG Validation Acc 79.60 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.478 AVG Validation Loss:0.494 AVG Training Acc 81.01 % AVG Validation Acc 79.60 %\n",
      "Epoch:90/200 AVG Training Loss:0.476 AVG Validation Loss:0.495 AVG Training Acc 81.02 % AVG Validation Acc 79.60 %\n",
      "Epoch:100/200 AVG Training Loss:0.475 AVG Validation Loss:0.496 AVG Training Acc 81.05 % AVG Validation Acc 79.51 %\n",
      "Epoch:110/200 AVG Training Loss:0.475 AVG Validation Loss:0.496 AVG Training Acc 81.05 % AVG Validation Acc 79.51 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.474 AVG Validation Loss:0.496 AVG Training Acc 81.13 % AVG Validation Acc 79.60 %\n",
      "Epoch:130/200 AVG Training Loss:0.475 AVG Validation Loss:0.496 AVG Training Acc 81.06 % AVG Validation Acc 79.51 %\n",
      "Epoch:140/200 AVG Training Loss:0.475 AVG Validation Loss:0.497 AVG Training Acc 81.03 % AVG Validation Acc 79.51 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.476 AVG Validation Loss:0.495 AVG Training Acc 81.07 % AVG Validation Acc 79.60 %\n",
      "Epoch:160/200 AVG Training Loss:0.475 AVG Validation Loss:0.496 AVG Training Acc 81.05 % AVG Validation Acc 79.51 %\n",
      "Epoch:170/200 AVG Training Loss:0.475 AVG Validation Loss:0.497 AVG Training Acc 81.02 % AVG Validation Acc 79.51 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.475 AVG Validation Loss:0.497 AVG Training Acc 81.00 % AVG Validation Acc 79.60 %\n",
      "Epoch:190/200 AVG Training Loss:0.475 AVG Validation Loss:0.496 AVG Training Acc 81.13 % AVG Validation Acc 79.60 %\n",
      "Epoch:200/200 AVG Training Loss:0.475 AVG Validation Loss:0.497 AVG Training Acc 81.04 % AVG Validation Acc 79.42 %\n",
      "Split 41\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9ad90d2afd544748837efdc99596415",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.06 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.493 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.493 AVG Validation Loss:0.493 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.489 AVG Training Acc 80.23 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.490 AVG Training Acc 80.30 % AVG Validation Acc 80.25 %\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.25 % AVG Validation Acc 80.25 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.31 % AVG Validation Acc 80.07 %\n",
      "Epoch:80/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.36 % AVG Validation Acc 80.07 %\n",
      "Epoch:90/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.36 % AVG Validation Acc 80.16 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.40 % AVG Validation Acc 80.25 %\n",
      "Epoch:110/200 AVG Training Loss:0.486 AVG Validation Loss:0.489 AVG Training Acc 80.38 % AVG Validation Acc 80.25 %\n",
      "Epoch:120/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.29 % AVG Validation Acc 80.16 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.485 AVG Validation Loss:0.493 AVG Training Acc 80.40 % AVG Validation Acc 80.16 %\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.32 % AVG Validation Acc 80.16 %\n",
      "Epoch:150/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.42 % AVG Validation Acc 80.16 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.487 AVG Validation Loss:0.491 AVG Training Acc 80.34 % AVG Validation Acc 80.25 %\n",
      "Epoch:170/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.27 % AVG Validation Acc 80.25 %\n",
      "Epoch:180/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.34 % AVG Validation Acc 80.16 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.41 % AVG Validation Acc 80.25 %\n",
      "Epoch:200/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.32 % AVG Validation Acc 80.25 %\n",
      "Split 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "379aacb9224b4358b6a988f51bcc9c85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.21 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.503 AVG Training Acc 80.21 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.498 AVG Training Acc 80.22 % AVG Validation Acc 80.07 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.501 AVG Training Acc 80.19 % AVG Validation Acc 80.07 %\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.502 AVG Training Acc 80.20 % AVG Validation Acc 80.16 %\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.502 AVG Training Acc 80.21 % AVG Validation Acc 80.07 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.502 AVG Training Acc 80.29 % AVG Validation Acc 80.07 %\n",
      "Epoch:100/200 AVG Training Loss:0.488 AVG Validation Loss:0.503 AVG Training Acc 80.24 % AVG Validation Acc 80.07 %\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.503 AVG Training Acc 80.22 % AVG Validation Acc 80.07 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.488 AVG Validation Loss:0.502 AVG Training Acc 80.21 % AVG Validation Acc 80.07 %\n",
      "Epoch:130/200 AVG Training Loss:0.487 AVG Validation Loss:0.503 AVG Training Acc 80.24 % AVG Validation Acc 80.07 %\n",
      "Epoch:140/200 AVG Training Loss:0.488 AVG Validation Loss:0.503 AVG Training Acc 80.21 % AVG Validation Acc 80.07 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.503 AVG Training Acc 80.22 % AVG Validation Acc 80.07 %\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.503 AVG Training Acc 80.25 % AVG Validation Acc 80.07 %\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.502 AVG Training Acc 80.21 % AVG Validation Acc 80.07 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.503 AVG Training Acc 80.22 % AVG Validation Acc 80.07 %\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.502 AVG Training Acc 80.24 % AVG Validation Acc 80.07 %\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.503 AVG Training Acc 80.25 % AVG Validation Acc 80.07 %\n",
      "Split 43\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3f14837a70c4a64b398d13e8b80f065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.492 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.23 % AVG Validation Acc 80.16 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.23 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.27 % AVG Validation Acc 80.16 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.24 % AVG Validation Acc 80.16 %\n",
      "Epoch:100/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.24 % AVG Validation Acc 80.16 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.20 % AVG Validation Acc 80.16 %\n",
      "Epoch:140/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.24 % AVG Validation Acc 80.16 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.21 % AVG Validation Acc 80.16 %\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch:170/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.26 % AVG Validation Acc 80.16 %\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.20 % AVG Validation Acc 80.16 %\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.27 % AVG Validation Acc 80.16 %\n",
      "Split 44\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bafc152890d4cbb89c4a47b3f6d8f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.23 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.24 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.28 % AVG Validation Acc 80.25 %\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.34 % AVG Validation Acc 80.25 %\n",
      "Epoch:90/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.36 % AVG Validation Acc 80.25 %\n",
      "Epoch:100/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.38 % AVG Validation Acc 80.16 %\n",
      "Epoch   104: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.37 % AVG Validation Acc 80.07 %\n",
      "Epoch:120/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.41 % AVG Validation Acc 80.16 %\n",
      "Epoch:130/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.40 % AVG Validation Acc 80.16 %\n",
      "Epoch   135: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.38 % AVG Validation Acc 80.16 %\n",
      "Epoch:150/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.41 % AVG Validation Acc 80.16 %\n",
      "Epoch:160/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.38 % AVG Validation Acc 80.16 %\n",
      "Epoch   166: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.39 % AVG Validation Acc 80.16 %\n",
      "Epoch:180/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.40 % AVG Validation Acc 80.16 %\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.40 % AVG Validation Acc 80.16 %\n",
      "Epoch   197: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.37 % AVG Validation Acc 80.16 %\n",
      "Split 45\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c23ace8d25a94717bbd04d1a70bf1b83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.499 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.499 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.497 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.498 AVG Training Acc 80.25 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.499 AVG Training Acc 80.20 % AVG Validation Acc 79.98 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.501 AVG Training Acc 80.25 % AVG Validation Acc 79.98 %\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.500 AVG Training Acc 80.20 % AVG Validation Acc 79.89 %\n",
      "Epoch:80/200 AVG Training Loss:0.487 AVG Validation Loss:0.501 AVG Training Acc 80.21 % AVG Validation Acc 79.80 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.487 AVG Validation Loss:0.501 AVG Training Acc 80.26 % AVG Validation Acc 79.62 %\n",
      "Epoch:100/200 AVG Training Loss:0.488 AVG Validation Loss:0.501 AVG Training Acc 80.18 % AVG Validation Acc 79.62 %\n",
      "Epoch:110/200 AVG Training Loss:0.487 AVG Validation Loss:0.501 AVG Training Acc 80.24 % AVG Validation Acc 79.62 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.488 AVG Validation Loss:0.501 AVG Training Acc 80.25 % AVG Validation Acc 79.62 %\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.501 AVG Training Acc 80.26 % AVG Validation Acc 79.62 %\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.503 AVG Training Acc 80.22 % AVG Validation Acc 79.62 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.487 AVG Validation Loss:0.501 AVG Training Acc 80.29 % AVG Validation Acc 79.62 %\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.501 AVG Training Acc 80.25 % AVG Validation Acc 79.62 %\n",
      "Epoch:170/200 AVG Training Loss:0.487 AVG Validation Loss:0.501 AVG Training Acc 80.20 % AVG Validation Acc 79.62 %\n",
      "Epoch:180/200 AVG Training Loss:0.487 AVG Validation Loss:0.501 AVG Training Acc 80.31 % AVG Validation Acc 79.62 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.488 AVG Validation Loss:0.502 AVG Training Acc 80.23 % AVG Validation Acc 79.62 %\n",
      "Epoch:200/200 AVG Training Loss:0.487 AVG Validation Loss:0.502 AVG Training Acc 80.22 % AVG Validation Acc 79.62 %\n",
      "Split 46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1124611fcb5049489d1209d658c97d74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.493 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.492 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.487 AVG Training Acc 80.41 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.482 AVG Validation Loss:0.486 AVG Training Acc 80.57 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.491 AVG Validation Loss:0.496 AVG Training Acc 80.09 % AVG Validation Acc 80.32 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.482 AVG Validation Loss:0.494 AVG Training Acc 80.54 % AVG Validation Acc 79.87 %\n",
      "Epoch:90/200 AVG Training Loss:0.480 AVG Validation Loss:0.494 AVG Training Acc 80.70 % AVG Validation Acc 79.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.480 AVG Validation Loss:0.494 AVG Training Acc 80.69 % AVG Validation Acc 79.96 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.481 AVG Validation Loss:0.494 AVG Training Acc 80.52 % AVG Validation Acc 79.96 %\n",
      "Epoch:120/200 AVG Training Loss:0.479 AVG Validation Loss:0.494 AVG Training Acc 80.68 % AVG Validation Acc 79.96 %\n",
      "Epoch:130/200 AVG Training Loss:0.481 AVG Validation Loss:0.494 AVG Training Acc 80.52 % AVG Validation Acc 79.96 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.480 AVG Validation Loss:0.494 AVG Training Acc 80.65 % AVG Validation Acc 79.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.481 AVG Validation Loss:0.493 AVG Training Acc 80.67 % AVG Validation Acc 79.96 %\n",
      "Epoch:160/200 AVG Training Loss:0.481 AVG Validation Loss:0.494 AVG Training Acc 80.67 % AVG Validation Acc 79.96 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.479 AVG Validation Loss:0.494 AVG Training Acc 80.58 % AVG Validation Acc 79.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.480 AVG Validation Loss:0.494 AVG Training Acc 80.66 % AVG Validation Acc 79.96 %\n",
      "Epoch:190/200 AVG Training Loss:0.480 AVG Validation Loss:0.494 AVG Training Acc 80.76 % AVG Validation Acc 79.87 %\n",
      "Epoch   198: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.480 AVG Validation Loss:0.494 AVG Training Acc 80.53 % AVG Validation Acc 79.96 %\n",
      "Split 47\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45487e03f9584a62ad4720e2364114c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.499 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.496 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.496 AVG Training Acc 80.23 % AVG Validation Acc 80.05 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.25 % AVG Validation Acc 80.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.20 % AVG Validation Acc 79.87 %\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.21 % AVG Validation Acc 79.87 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.490 AVG Validation Loss:0.496 AVG Training Acc 80.26 % AVG Validation Acc 79.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.490 AVG Validation Loss:0.496 AVG Training Acc 80.20 % AVG Validation Acc 79.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.20 % AVG Validation Acc 79.96 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.23 % AVG Validation Acc 79.87 %\n",
      "Epoch:120/200 AVG Training Loss:0.490 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 79.96 %\n",
      "Epoch:130/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.30 % AVG Validation Acc 79.96 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.28 % AVG Validation Acc 79.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.21 % AVG Validation Acc 79.96 %\n",
      "Epoch:160/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.26 % AVG Validation Acc 79.87 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 79.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.25 % AVG Validation Acc 79.87 %\n",
      "Epoch:190/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.37 % AVG Validation Acc 79.96 %\n",
      "Epoch:200/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.18 % AVG Validation Acc 79.96 %\n",
      "Split 48\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aea26e80a2f4f91a134647a11dc4d8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.27 % AVG Validation Acc 80.05 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.488 AVG Training Acc 80.36 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.484 AVG Validation Loss:0.487 AVG Training Acc 80.51 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.481 AVG Validation Loss:0.487 AVG Training Acc 80.68 % AVG Validation Acc 80.42 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.479 AVG Validation Loss:0.488 AVG Training Acc 80.81 % AVG Validation Acc 80.42 %\n",
      "Epoch:90/200 AVG Training Loss:0.479 AVG Validation Loss:0.487 AVG Training Acc 80.78 % AVG Validation Acc 80.32 %\n",
      "Epoch:100/200 AVG Training Loss:0.479 AVG Validation Loss:0.489 AVG Training Acc 80.85 % AVG Validation Acc 80.32 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.479 AVG Validation Loss:0.488 AVG Training Acc 80.71 % AVG Validation Acc 80.42 %\n",
      "Epoch:120/200 AVG Training Loss:0.477 AVG Validation Loss:0.489 AVG Training Acc 80.95 % AVG Validation Acc 80.32 %\n",
      "Epoch:130/200 AVG Training Loss:0.478 AVG Validation Loss:0.490 AVG Training Acc 80.82 % AVG Validation Acc 80.32 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.478 AVG Validation Loss:0.490 AVG Training Acc 80.92 % AVG Validation Acc 80.42 %\n",
      "Epoch:150/200 AVG Training Loss:0.477 AVG Validation Loss:0.490 AVG Training Acc 81.05 % AVG Validation Acc 80.42 %\n",
      "Epoch:160/200 AVG Training Loss:0.478 AVG Validation Loss:0.490 AVG Training Acc 80.83 % AVG Validation Acc 80.32 %\n",
      "Epoch:170/200 AVG Training Loss:0.478 AVG Validation Loss:0.489 AVG Training Acc 80.90 % AVG Validation Acc 80.32 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.478 AVG Validation Loss:0.489 AVG Training Acc 80.87 % AVG Validation Acc 80.42 %\n",
      "Epoch:190/200 AVG Training Loss:0.477 AVG Validation Loss:0.489 AVG Training Acc 80.94 % AVG Validation Acc 80.42 %\n",
      "Epoch:200/200 AVG Training Loss:0.479 AVG Validation Loss:0.488 AVG Training Acc 80.88 % AVG Validation Acc 80.42 %\n",
      "Split 49\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f4ab6c726b5465ab497272c821b18d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.498 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.502 AVG Training Acc 80.08 % AVG Validation Acc 80.14 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 80.23 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.18 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.29 % AVG Validation Acc 80.23 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.31 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.33 % AVG Validation Acc 80.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.32 % AVG Validation Acc 80.14 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.36 % AVG Validation Acc 80.05 %\n",
      "Epoch:100/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.44 % AVG Validation Acc 80.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.45 % AVG Validation Acc 80.05 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.38 % AVG Validation Acc 79.96 %\n",
      "Epoch:130/200 AVG Training Loss:0.487 AVG Validation Loss:0.498 AVG Training Acc 80.36 % AVG Validation Acc 80.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.42 % AVG Validation Acc 80.05 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.36 % AVG Validation Acc 80.05 %\n",
      "Epoch:160/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.41 % AVG Validation Acc 79.96 %\n",
      "Epoch:170/200 AVG Training Loss:0.487 AVG Validation Loss:0.498 AVG Training Acc 80.32 % AVG Validation Acc 80.05 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.34 % AVG Validation Acc 80.05 %\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.498 AVG Training Acc 80.44 % AVG Validation Acc 80.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.38 % AVG Validation Acc 80.14 %\n",
      "Split 50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef2fb3add02c4feab016855c28c9c68c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.492 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.493 AVG Validation Loss:0.493 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.492 AVG Validation Loss:0.489 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.491 AVG Validation Loss:0.489 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.490 AVG Validation Loss:0.488 AVG Training Acc 80.18 % AVG Validation Acc 80.32 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.21 % AVG Validation Acc 80.32 %\n",
      "Epoch:80/200 AVG Training Loss:0.489 AVG Validation Loss:0.488 AVG Training Acc 80.16 % AVG Validation Acc 80.32 %\n",
      "Epoch:90/200 AVG Training Loss:0.489 AVG Validation Loss:0.488 AVG Training Acc 80.20 % AVG Validation Acc 80.32 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.20 % AVG Validation Acc 80.32 %\n",
      "Epoch:110/200 AVG Training Loss:0.489 AVG Validation Loss:0.488 AVG Training Acc 80.17 % AVG Validation Acc 80.32 %\n",
      "Epoch:120/200 AVG Training Loss:0.490 AVG Validation Loss:0.488 AVG Training Acc 80.17 % AVG Validation Acc 80.32 %\n",
      "Epoch:130/200 AVG Training Loss:0.489 AVG Validation Loss:0.488 AVG Training Acc 80.19 % AVG Validation Acc 80.32 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.489 AVG Validation Loss:0.488 AVG Training Acc 80.21 % AVG Validation Acc 80.32 %\n",
      "Epoch:150/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.18 % AVG Validation Acc 80.32 %\n",
      "Epoch:160/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.18 % AVG Validation Acc 80.32 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.489 AVG Validation Loss:0.488 AVG Training Acc 80.20 % AVG Validation Acc 80.32 %\n",
      "Epoch:180/200 AVG Training Loss:0.490 AVG Validation Loss:0.489 AVG Training Acc 80.19 % AVG Validation Acc 80.32 %\n",
      "Epoch:190/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.19 % AVG Validation Acc 80.32 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.489 AVG Validation Loss:0.488 AVG Training Acc 80.19 % AVG Validation Acc 80.32 %\n",
      "Split 51\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e46da4ceee984422aeda9dcbc7dea9c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.22 % AVG Validation Acc 79.98 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.27 % AVG Validation Acc 79.98 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.36 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.500 AVG Training Acc 80.46 % AVG Validation Acc 80.07 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.478 AVG Validation Loss:0.517 AVG Training Acc 80.89 % AVG Validation Acc 79.08 %\n",
      "Epoch:70/200 AVG Training Loss:0.475 AVG Validation Loss:0.531 AVG Training Acc 81.10 % AVG Validation Acc 79.17 %\n",
      "Epoch:80/200 AVG Training Loss:0.473 AVG Validation Loss:0.541 AVG Training Acc 81.18 % AVG Validation Acc 78.99 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.472 AVG Validation Loss:0.548 AVG Training Acc 81.20 % AVG Validation Acc 78.81 %\n",
      "Epoch:100/200 AVG Training Loss:0.471 AVG Validation Loss:0.549 AVG Training Acc 81.26 % AVG Validation Acc 79.08 %\n",
      "Epoch:110/200 AVG Training Loss:0.472 AVG Validation Loss:0.551 AVG Training Acc 81.21 % AVG Validation Acc 78.72 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.470 AVG Validation Loss:0.552 AVG Training Acc 81.27 % AVG Validation Acc 78.81 %\n",
      "Epoch:130/200 AVG Training Loss:0.471 AVG Validation Loss:0.551 AVG Training Acc 81.30 % AVG Validation Acc 78.81 %\n",
      "Epoch:140/200 AVG Training Loss:0.471 AVG Validation Loss:0.554 AVG Training Acc 81.21 % AVG Validation Acc 78.72 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.472 AVG Validation Loss:0.553 AVG Training Acc 81.31 % AVG Validation Acc 78.81 %\n",
      "Epoch:160/200 AVG Training Loss:0.471 AVG Validation Loss:0.554 AVG Training Acc 81.31 % AVG Validation Acc 78.90 %\n",
      "Epoch:170/200 AVG Training Loss:0.471 AVG Validation Loss:0.552 AVG Training Acc 81.35 % AVG Validation Acc 78.72 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.471 AVG Validation Loss:0.552 AVG Training Acc 81.30 % AVG Validation Acc 78.72 %\n",
      "Epoch:190/200 AVG Training Loss:0.471 AVG Validation Loss:0.553 AVG Training Acc 81.28 % AVG Validation Acc 78.81 %\n",
      "Epoch:200/200 AVG Training Loss:0.471 AVG Validation Loss:0.552 AVG Training Acc 81.15 % AVG Validation Acc 78.90 %\n",
      "Split 52\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "677914804ac94ca6971000d44e262b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.21 % AVG Validation Acc 80.07 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.23 % AVG Validation Acc 80.07 %\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.22 % AVG Validation Acc 80.07 %\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.24 % AVG Validation Acc 80.07 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.487 AVG Validation Loss:0.498 AVG Training Acc 80.22 % AVG Validation Acc 79.98 %\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.23 % AVG Validation Acc 79.98 %\n",
      "Epoch:100/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.29 % AVG Validation Acc 79.98 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.23 % AVG Validation Acc 79.98 %\n",
      "Epoch:120/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.24 % AVG Validation Acc 79.98 %\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.23 % AVG Validation Acc 79.98 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.18 % AVG Validation Acc 79.98 %\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.24 % AVG Validation Acc 79.98 %\n",
      "Epoch:160/200 AVG Training Loss:0.487 AVG Validation Loss:0.498 AVG Training Acc 80.31 % AVG Validation Acc 79.98 %\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.22 % AVG Validation Acc 79.98 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.25 % AVG Validation Acc 79.98 %\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.35 % AVG Validation Acc 79.98 %\n",
      "Epoch:200/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.28 % AVG Validation Acc 79.98 %\n",
      "Split 53\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb3858a3f5844d9a921b81b962f132d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.492 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.493 AVG Validation Loss:0.492 AVG Training Acc 80.15 % AVG Validation Acc 80.25 %\n",
      "Epoch:40/200 AVG Training Loss:0.493 AVG Validation Loss:0.493 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.491 AVG Validation Loss:0.489 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.31 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.484 AVG Validation Loss:0.493 AVG Training Acc 80.29 % AVG Validation Acc 79.80 %\n",
      "Epoch:80/200 AVG Training Loss:0.481 AVG Validation Loss:0.494 AVG Training Acc 80.71 % AVG Validation Acc 79.80 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.478 AVG Validation Loss:0.494 AVG Training Acc 80.69 % AVG Validation Acc 79.89 %\n",
      "Epoch:100/200 AVG Training Loss:0.480 AVG Validation Loss:0.494 AVG Training Acc 80.74 % AVG Validation Acc 79.98 %\n",
      "Epoch:110/200 AVG Training Loss:0.480 AVG Validation Loss:0.494 AVG Training Acc 80.70 % AVG Validation Acc 79.98 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.481 AVG Validation Loss:0.495 AVG Training Acc 80.73 % AVG Validation Acc 79.80 %\n",
      "Epoch:130/200 AVG Training Loss:0.480 AVG Validation Loss:0.495 AVG Training Acc 80.84 % AVG Validation Acc 79.89 %\n",
      "Epoch:140/200 AVG Training Loss:0.479 AVG Validation Loss:0.495 AVG Training Acc 80.87 % AVG Validation Acc 79.89 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.478 AVG Validation Loss:0.494 AVG Training Acc 80.76 % AVG Validation Acc 79.89 %\n",
      "Epoch:160/200 AVG Training Loss:0.479 AVG Validation Loss:0.495 AVG Training Acc 80.79 % AVG Validation Acc 79.80 %\n",
      "Epoch:170/200 AVG Training Loss:0.479 AVG Validation Loss:0.495 AVG Training Acc 80.93 % AVG Validation Acc 79.89 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.480 AVG Validation Loss:0.495 AVG Training Acc 80.76 % AVG Validation Acc 79.80 %\n",
      "Epoch:190/200 AVG Training Loss:0.479 AVG Validation Loss:0.495 AVG Training Acc 80.85 % AVG Validation Acc 79.80 %\n",
      "Epoch:200/200 AVG Training Loss:0.479 AVG Validation Loss:0.495 AVG Training Acc 80.84 % AVG Validation Acc 79.89 %\n",
      "Split 54\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f40359732abc4d708aded2154f4d1eb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.20 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.27 % AVG Validation Acc 80.25 %\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.499 AVG Training Acc 80.41 % AVG Validation Acc 79.98 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.483 AVG Validation Loss:0.501 AVG Training Acc 80.63 % AVG Validation Acc 79.89 %\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.501 AVG Training Acc 80.67 % AVG Validation Acc 79.98 %\n",
      "Epoch:70/200 AVG Training Loss:0.482 AVG Validation Loss:0.501 AVG Training Acc 80.69 % AVG Validation Acc 79.80 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.481 AVG Validation Loss:0.502 AVG Training Acc 80.72 % AVG Validation Acc 79.71 %\n",
      "Epoch:90/200 AVG Training Loss:0.481 AVG Validation Loss:0.503 AVG Training Acc 80.77 % AVG Validation Acc 79.62 %\n",
      "Epoch:100/200 AVG Training Loss:0.482 AVG Validation Loss:0.503 AVG Training Acc 80.73 % AVG Validation Acc 79.71 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.481 AVG Validation Loss:0.502 AVG Training Acc 80.66 % AVG Validation Acc 79.80 %\n",
      "Epoch:120/200 AVG Training Loss:0.482 AVG Validation Loss:0.502 AVG Training Acc 80.66 % AVG Validation Acc 79.71 %\n",
      "Epoch:130/200 AVG Training Loss:0.481 AVG Validation Loss:0.502 AVG Training Acc 80.66 % AVG Validation Acc 79.80 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.482 AVG Validation Loss:0.502 AVG Training Acc 80.78 % AVG Validation Acc 79.71 %\n",
      "Epoch:150/200 AVG Training Loss:0.481 AVG Validation Loss:0.502 AVG Training Acc 80.75 % AVG Validation Acc 79.80 %\n",
      "Epoch:160/200 AVG Training Loss:0.481 AVG Validation Loss:0.502 AVG Training Acc 80.66 % AVG Validation Acc 79.71 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.481 AVG Validation Loss:0.502 AVG Training Acc 80.65 % AVG Validation Acc 79.71 %\n",
      "Epoch:180/200 AVG Training Loss:0.482 AVG Validation Loss:0.502 AVG Training Acc 80.74 % AVG Validation Acc 79.80 %\n",
      "Epoch:190/200 AVG Training Loss:0.482 AVG Validation Loss:0.502 AVG Training Acc 80.66 % AVG Validation Acc 79.80 %\n",
      "Epoch:200/200 AVG Training Loss:0.481 AVG Validation Loss:0.502 AVG Training Acc 80.68 % AVG Validation Acc 79.71 %\n",
      "Split 55\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "500969740de94908b032154e8919335b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.27 % AVG Validation Acc 79.89 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.32 % AVG Validation Acc 79.80 %\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.34 % AVG Validation Acc 79.98 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.36 % AVG Validation Acc 79.80 %\n",
      "Epoch:70/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.43 % AVG Validation Acc 79.71 %\n",
      "Epoch:80/200 AVG Training Loss:0.485 AVG Validation Loss:0.499 AVG Training Acc 80.51 % AVG Validation Acc 79.62 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.485 AVG Validation Loss:0.500 AVG Training Acc 80.40 % AVG Validation Acc 79.62 %\n",
      "Epoch:100/200 AVG Training Loss:0.484 AVG Validation Loss:0.499 AVG Training Acc 80.46 % AVG Validation Acc 79.62 %\n",
      "Epoch:110/200 AVG Training Loss:0.486 AVG Validation Loss:0.499 AVG Training Acc 80.41 % AVG Validation Acc 79.62 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.485 AVG Validation Loss:0.499 AVG Training Acc 80.45 % AVG Validation Acc 79.53 %\n",
      "Epoch:130/200 AVG Training Loss:0.486 AVG Validation Loss:0.499 AVG Training Acc 80.51 % AVG Validation Acc 79.53 %\n",
      "Epoch:140/200 AVG Training Loss:0.485 AVG Validation Loss:0.499 AVG Training Acc 80.36 % AVG Validation Acc 79.53 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.499 AVG Training Acc 80.50 % AVG Validation Acc 79.53 %\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.500 AVG Training Acc 80.47 % AVG Validation Acc 79.62 %\n",
      "Epoch:170/200 AVG Training Loss:0.485 AVG Validation Loss:0.499 AVG Training Acc 80.42 % AVG Validation Acc 79.53 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.485 AVG Validation Loss:0.500 AVG Training Acc 80.43 % AVG Validation Acc 79.53 %\n",
      "Epoch:190/200 AVG Training Loss:0.485 AVG Validation Loss:0.499 AVG Training Acc 80.46 % AVG Validation Acc 79.53 %\n",
      "Epoch:200/200 AVG Training Loss:0.485 AVG Validation Loss:0.499 AVG Training Acc 80.39 % AVG Validation Acc 79.62 %\n",
      "Split 56\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22e21fd1addb4a4593ec2d0fbbc9ab0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.490 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.490 AVG Training Acc 80.33 % AVG Validation Acc 79.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.492 AVG Training Acc 80.56 % AVG Validation Acc 79.69 %\n",
      "Epoch:50/200 AVG Training Loss:0.483 AVG Validation Loss:0.494 AVG Training Acc 80.75 % AVG Validation Acc 79.87 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.479 AVG Validation Loss:0.495 AVG Training Acc 80.96 % AVG Validation Acc 79.78 %\n",
      "Epoch:70/200 AVG Training Loss:0.479 AVG Validation Loss:0.496 AVG Training Acc 80.92 % AVG Validation Acc 79.87 %\n",
      "Epoch:80/200 AVG Training Loss:0.478 AVG Validation Loss:0.496 AVG Training Acc 80.95 % AVG Validation Acc 79.96 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.478 AVG Validation Loss:0.496 AVG Training Acc 80.97 % AVG Validation Acc 79.87 %\n",
      "Epoch:100/200 AVG Training Loss:0.478 AVG Validation Loss:0.496 AVG Training Acc 81.00 % AVG Validation Acc 79.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.477 AVG Validation Loss:0.497 AVG Training Acc 81.10 % AVG Validation Acc 79.87 %\n",
      "Epoch:120/200 AVG Training Loss:0.478 AVG Validation Loss:0.496 AVG Training Acc 80.96 % AVG Validation Acc 79.96 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.478 AVG Validation Loss:0.496 AVG Training Acc 80.86 % AVG Validation Acc 79.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.477 AVG Validation Loss:0.496 AVG Training Acc 81.04 % AVG Validation Acc 79.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.479 AVG Validation Loss:0.496 AVG Training Acc 81.03 % AVG Validation Acc 79.87 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.477 AVG Validation Loss:0.495 AVG Training Acc 81.08 % AVG Validation Acc 79.96 %\n",
      "Epoch:170/200 AVG Training Loss:0.478 AVG Validation Loss:0.496 AVG Training Acc 81.02 % AVG Validation Acc 79.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.478 AVG Validation Loss:0.497 AVG Training Acc 80.98 % AVG Validation Acc 79.78 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.478 AVG Validation Loss:0.496 AVG Training Acc 81.06 % AVG Validation Acc 79.87 %\n",
      "Epoch:200/200 AVG Training Loss:0.478 AVG Validation Loss:0.496 AVG Training Acc 80.94 % AVG Validation Acc 79.96 %\n",
      "Split 57\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ffdbc1ef37545e19874b365ac82d5cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.497 AVG Training Acc 80.10 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.500 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.500 AVG Training Acc 80.47 % AVG Validation Acc 80.32 %\n",
      "Epoch:50/200 AVG Training Loss:0.481 AVG Validation Loss:0.502 AVG Training Acc 80.45 % AVG Validation Acc 80.23 %\n",
      "Epoch:60/200 AVG Training Loss:0.480 AVG Validation Loss:0.504 AVG Training Acc 80.66 % AVG Validation Acc 80.23 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.478 AVG Validation Loss:0.503 AVG Training Acc 80.75 % AVG Validation Acc 80.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.477 AVG Validation Loss:0.504 AVG Training Acc 80.79 % AVG Validation Acc 79.87 %\n",
      "Epoch:90/200 AVG Training Loss:0.478 AVG Validation Loss:0.504 AVG Training Acc 80.73 % AVG Validation Acc 79.96 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.478 AVG Validation Loss:0.504 AVG Training Acc 80.70 % AVG Validation Acc 79.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.478 AVG Validation Loss:0.504 AVG Training Acc 80.70 % AVG Validation Acc 79.96 %\n",
      "Epoch:120/200 AVG Training Loss:0.477 AVG Validation Loss:0.506 AVG Training Acc 80.70 % AVG Validation Acc 79.87 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.478 AVG Validation Loss:0.506 AVG Training Acc 80.59 % AVG Validation Acc 79.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.477 AVG Validation Loss:0.505 AVG Training Acc 80.72 % AVG Validation Acc 79.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.476 AVG Validation Loss:0.505 AVG Training Acc 80.79 % AVG Validation Acc 79.87 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.475 AVG Validation Loss:0.504 AVG Training Acc 80.70 % AVG Validation Acc 79.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.477 AVG Validation Loss:0.505 AVG Training Acc 80.67 % AVG Validation Acc 79.78 %\n",
      "Epoch:180/200 AVG Training Loss:0.477 AVG Validation Loss:0.506 AVG Training Acc 80.75 % AVG Validation Acc 79.78 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.476 AVG Validation Loss:0.505 AVG Training Acc 80.80 % AVG Validation Acc 80.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.477 AVG Validation Loss:0.505 AVG Training Acc 80.74 % AVG Validation Acc 79.96 %\n",
      "Split 58\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bd64a303353432297d5ce9572055b5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.18 % AVG Validation Acc 80.05 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.25 % AVG Validation Acc 79.87 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.500 AVG Training Acc 80.47 % AVG Validation Acc 79.69 %\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.500 AVG Training Acc 80.54 % AVG Validation Acc 79.60 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.481 AVG Validation Loss:0.509 AVG Training Acc 80.60 % AVG Validation Acc 79.60 %\n",
      "Epoch:80/200 AVG Training Loss:0.481 AVG Validation Loss:0.512 AVG Training Acc 80.61 % AVG Validation Acc 79.60 %\n",
      "Epoch:90/200 AVG Training Loss:0.480 AVG Validation Loss:0.511 AVG Training Acc 80.66 % AVG Validation Acc 79.60 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.481 AVG Validation Loss:0.513 AVG Training Acc 80.72 % AVG Validation Acc 79.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.481 AVG Validation Loss:0.512 AVG Training Acc 80.63 % AVG Validation Acc 79.51 %\n",
      "Epoch:120/200 AVG Training Loss:0.480 AVG Validation Loss:0.513 AVG Training Acc 80.67 % AVG Validation Acc 79.60 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.481 AVG Validation Loss:0.514 AVG Training Acc 80.68 % AVG Validation Acc 79.51 %\n",
      "Epoch:140/200 AVG Training Loss:0.480 AVG Validation Loss:0.513 AVG Training Acc 80.71 % AVG Validation Acc 79.51 %\n",
      "Epoch:150/200 AVG Training Loss:0.481 AVG Validation Loss:0.514 AVG Training Acc 80.66 % AVG Validation Acc 79.51 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.480 AVG Validation Loss:0.513 AVG Training Acc 80.72 % AVG Validation Acc 79.51 %\n",
      "Epoch:170/200 AVG Training Loss:0.480 AVG Validation Loss:0.513 AVG Training Acc 80.70 % AVG Validation Acc 79.51 %\n",
      "Epoch:180/200 AVG Training Loss:0.480 AVG Validation Loss:0.513 AVG Training Acc 80.78 % AVG Validation Acc 79.51 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.481 AVG Validation Loss:0.513 AVG Training Acc 80.56 % AVG Validation Acc 79.51 %\n",
      "Epoch:200/200 AVG Training Loss:0.480 AVG Validation Loss:0.515 AVG Training Acc 80.68 % AVG Validation Acc 79.51 %\n",
      "Split 59\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f9b02f869df430b9c0d1e42100ac731",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.501 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.500 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.500 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.500 AVG Training Acc 80.13 % AVG Validation Acc 80.05 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.500 AVG Training Acc 80.12 % AVG Validation Acc 80.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.500 AVG Training Acc 80.25 % AVG Validation Acc 80.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.500 AVG Training Acc 80.19 % AVG Validation Acc 80.05 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.489 AVG Validation Loss:0.500 AVG Training Acc 80.20 % AVG Validation Acc 80.05 %\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.500 AVG Training Acc 80.22 % AVG Validation Acc 80.05 %\n",
      "Epoch:100/200 AVG Training Loss:0.489 AVG Validation Loss:0.500 AVG Training Acc 80.20 % AVG Validation Acc 80.05 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.489 AVG Validation Loss:0.500 AVG Training Acc 80.16 % AVG Validation Acc 80.05 %\n",
      "Epoch:120/200 AVG Training Loss:0.488 AVG Validation Loss:0.500 AVG Training Acc 80.20 % AVG Validation Acc 80.05 %\n",
      "Epoch:130/200 AVG Training Loss:0.489 AVG Validation Loss:0.500 AVG Training Acc 80.17 % AVG Validation Acc 80.05 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.489 AVG Validation Loss:0.500 AVG Training Acc 80.17 % AVG Validation Acc 80.05 %\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.500 AVG Training Acc 80.18 % AVG Validation Acc 80.05 %\n",
      "Epoch:160/200 AVG Training Loss:0.489 AVG Validation Loss:0.500 AVG Training Acc 80.20 % AVG Validation Acc 80.05 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.500 AVG Training Acc 80.24 % AVG Validation Acc 80.05 %\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.500 AVG Training Acc 80.22 % AVG Validation Acc 80.05 %\n",
      "Epoch:190/200 AVG Training Loss:0.489 AVG Validation Loss:0.500 AVG Training Acc 80.30 % AVG Validation Acc 80.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.489 AVG Validation Loss:0.500 AVG Training Acc 80.20 % AVG Validation Acc 80.05 %\n",
      "Split 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd38cd99ef7d4109bbc3e8ac7e3ff31f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.27 % AVG Validation Acc 80.14 %\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.52 % AVG Validation Acc 80.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.481 AVG Validation Loss:0.502 AVG Training Acc 80.67 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.477 AVG Validation Loss:0.503 AVG Training Acc 81.00 % AVG Validation Acc 80.05 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.477 AVG Validation Loss:0.503 AVG Training Acc 80.86 % AVG Validation Acc 80.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.476 AVG Validation Loss:0.504 AVG Training Acc 81.03 % AVG Validation Acc 80.05 %\n",
      "Epoch:100/200 AVG Training Loss:0.476 AVG Validation Loss:0.506 AVG Training Acc 80.92 % AVG Validation Acc 79.96 %\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.475 AVG Validation Loss:0.506 AVG Training Acc 80.95 % AVG Validation Acc 79.96 %\n",
      "Epoch:120/200 AVG Training Loss:0.475 AVG Validation Loss:0.506 AVG Training Acc 80.97 % AVG Validation Acc 79.96 %\n",
      "Epoch:130/200 AVG Training Loss:0.476 AVG Validation Loss:0.506 AVG Training Acc 80.92 % AVG Validation Acc 79.96 %\n",
      "Epoch   134: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.476 AVG Validation Loss:0.506 AVG Training Acc 80.86 % AVG Validation Acc 79.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.476 AVG Validation Loss:0.507 AVG Training Acc 80.88 % AVG Validation Acc 79.96 %\n",
      "Epoch:160/200 AVG Training Loss:0.476 AVG Validation Loss:0.506 AVG Training Acc 80.86 % AVG Validation Acc 79.96 %\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.475 AVG Validation Loss:0.506 AVG Training Acc 80.92 % AVG Validation Acc 79.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.475 AVG Validation Loss:0.507 AVG Training Acc 80.96 % AVG Validation Acc 79.96 %\n",
      "Epoch:190/200 AVG Training Loss:0.476 AVG Validation Loss:0.506 AVG Training Acc 80.95 % AVG Validation Acc 79.96 %\n",
      "Epoch   196: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.476 AVG Validation Loss:0.506 AVG Training Acc 80.94 % AVG Validation Acc 79.96 %\n",
      "Split 61\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8045107b18b468f9787905634fbe6ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.490 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.16 % AVG Validation Acc 80.34 %\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.491 AVG Training Acc 80.36 % AVG Validation Acc 80.34 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.486 AVG Validation Loss:0.491 AVG Training Acc 80.46 % AVG Validation Acc 80.34 %\n",
      "Epoch:70/200 AVG Training Loss:0.485 AVG Validation Loss:0.492 AVG Training Acc 80.54 % AVG Validation Acc 80.34 %\n",
      "New Best Accuracy found: 80.61%\n",
      "Epoch: 73\n",
      "Epoch:80/200 AVG Training Loss:0.485 AVG Validation Loss:0.491 AVG Training Acc 80.53 % AVG Validation Acc 80.61 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.484 AVG Validation Loss:0.492 AVG Training Acc 80.54 % AVG Validation Acc 80.52 %\n",
      "Epoch:100/200 AVG Training Loss:0.484 AVG Validation Loss:0.491 AVG Training Acc 80.65 % AVG Validation Acc 80.52 %\n",
      "Epoch:110/200 AVG Training Loss:0.484 AVG Validation Loss:0.491 AVG Training Acc 80.61 % AVG Validation Acc 80.43 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.484 AVG Validation Loss:0.492 AVG Training Acc 80.58 % AVG Validation Acc 80.52 %\n",
      "Epoch:130/200 AVG Training Loss:0.484 AVG Validation Loss:0.491 AVG Training Acc 80.55 % AVG Validation Acc 80.52 %\n",
      "Epoch:140/200 AVG Training Loss:0.483 AVG Validation Loss:0.492 AVG Training Acc 80.57 % AVG Validation Acc 80.52 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.484 AVG Validation Loss:0.491 AVG Training Acc 80.62 % AVG Validation Acc 80.43 %\n",
      "Epoch:160/200 AVG Training Loss:0.484 AVG Validation Loss:0.491 AVG Training Acc 80.58 % AVG Validation Acc 80.43 %\n",
      "Epoch:170/200 AVG Training Loss:0.484 AVG Validation Loss:0.491 AVG Training Acc 80.63 % AVG Validation Acc 80.43 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.484 AVG Validation Loss:0.491 AVG Training Acc 80.57 % AVG Validation Acc 80.43 %\n",
      "Epoch:190/200 AVG Training Loss:0.484 AVG Validation Loss:0.491 AVG Training Acc 80.54 % AVG Validation Acc 80.34 %\n",
      "Epoch:200/200 AVG Training Loss:0.485 AVG Validation Loss:0.491 AVG Training Acc 80.52 % AVG Validation Acc 80.34 %\n",
      "Split 62\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "153d6a0cbff24cd38ac4af26ec63ea4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.498 AVG Training Acc 80.22 % AVG Validation Acc 79.98 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.27 % AVG Validation Acc 79.98 %\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.23 % AVG Validation Acc 79.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.24 % AVG Validation Acc 80.07 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.25 % AVG Validation Acc 79.98 %\n",
      "Epoch:100/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.26 % AVG Validation Acc 79.98 %\n",
      "Epoch:110/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.22 % AVG Validation Acc 79.98 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.27 % AVG Validation Acc 79.98 %\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.26 % AVG Validation Acc 79.98 %\n",
      "Epoch:140/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.22 % AVG Validation Acc 79.98 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.31 % AVG Validation Acc 79.98 %\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.23 % AVG Validation Acc 79.98 %\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.29 % AVG Validation Acc 79.98 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.27 % AVG Validation Acc 79.98 %\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.28 % AVG Validation Acc 79.98 %\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.17 % AVG Validation Acc 79.98 %\n",
      "Split 63\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2472ed310a084e279144c0a2f76eb8c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.493 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.19 % AVG Validation Acc 80.34 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.19 % AVG Validation Acc 80.25 %\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.490 AVG Training Acc 80.24 % AVG Validation Acc 80.34 %\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.28 % AVG Validation Acc 80.25 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.485 AVG Validation Loss:0.491 AVG Training Acc 80.34 % AVG Validation Acc 80.25 %\n",
      "Epoch:80/200 AVG Training Loss:0.485 AVG Validation Loss:0.491 AVG Training Acc 80.36 % AVG Validation Acc 80.16 %\n",
      "Epoch:90/200 AVG Training Loss:0.485 AVG Validation Loss:0.492 AVG Training Acc 80.43 % AVG Validation Acc 80.25 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.485 AVG Validation Loss:0.491 AVG Training Acc 80.41 % AVG Validation Acc 80.25 %\n",
      "Epoch:110/200 AVG Training Loss:0.485 AVG Validation Loss:0.492 AVG Training Acc 80.35 % AVG Validation Acc 80.25 %\n",
      "Epoch:120/200 AVG Training Loss:0.485 AVG Validation Loss:0.492 AVG Training Acc 80.42 % AVG Validation Acc 80.25 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.484 AVG Validation Loss:0.492 AVG Training Acc 80.56 % AVG Validation Acc 80.25 %\n",
      "Epoch:140/200 AVG Training Loss:0.485 AVG Validation Loss:0.492 AVG Training Acc 80.41 % AVG Validation Acc 80.25 %\n",
      "Epoch:150/200 AVG Training Loss:0.484 AVG Validation Loss:0.492 AVG Training Acc 80.45 % AVG Validation Acc 80.25 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.492 AVG Training Acc 80.30 % AVG Validation Acc 80.25 %\n",
      "Epoch:170/200 AVG Training Loss:0.485 AVG Validation Loss:0.492 AVG Training Acc 80.41 % AVG Validation Acc 80.25 %\n",
      "Epoch:180/200 AVG Training Loss:0.485 AVG Validation Loss:0.492 AVG Training Acc 80.40 % AVG Validation Acc 80.25 %\n",
      "Epoch:190/200 AVG Training Loss:0.483 AVG Validation Loss:0.492 AVG Training Acc 80.44 % AVG Validation Acc 80.25 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.484 AVG Validation Loss:0.492 AVG Training Acc 80.48 % AVG Validation Acc 80.25 %\n",
      "Split 64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a85cc08fe7fc4c3eb24c5789e7ac598b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.12 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.499 AVG Training Acc 80.25 % AVG Validation Acc 79.89 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.485 AVG Validation Loss:0.500 AVG Training Acc 80.36 % AVG Validation Acc 79.80 %\n",
      "Epoch:50/200 AVG Training Loss:0.482 AVG Validation Loss:0.510 AVG Training Acc 80.59 % AVG Validation Acc 79.62 %\n",
      "Epoch:60/200 AVG Training Loss:0.481 AVG Validation Loss:0.506 AVG Training Acc 80.61 % AVG Validation Acc 79.80 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.481 AVG Validation Loss:0.505 AVG Training Acc 80.67 % AVG Validation Acc 79.53 %\n",
      "Epoch:80/200 AVG Training Loss:0.480 AVG Validation Loss:0.504 AVG Training Acc 80.67 % AVG Validation Acc 79.62 %\n",
      "Epoch:90/200 AVG Training Loss:0.481 AVG Validation Loss:0.504 AVG Training Acc 80.63 % AVG Validation Acc 79.62 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.479 AVG Validation Loss:0.505 AVG Training Acc 80.74 % AVG Validation Acc 79.71 %\n",
      "Epoch:110/200 AVG Training Loss:0.480 AVG Validation Loss:0.505 AVG Training Acc 80.73 % AVG Validation Acc 79.71 %\n",
      "Epoch:120/200 AVG Training Loss:0.479 AVG Validation Loss:0.504 AVG Training Acc 80.73 % AVG Validation Acc 79.71 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.479 AVG Validation Loss:0.505 AVG Training Acc 80.80 % AVG Validation Acc 79.71 %\n",
      "Epoch:140/200 AVG Training Loss:0.480 AVG Validation Loss:0.505 AVG Training Acc 80.78 % AVG Validation Acc 79.62 %\n",
      "Epoch:150/200 AVG Training Loss:0.480 AVG Validation Loss:0.505 AVG Training Acc 80.72 % AVG Validation Acc 79.62 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.480 AVG Validation Loss:0.505 AVG Training Acc 80.70 % AVG Validation Acc 79.71 %\n",
      "Epoch:170/200 AVG Training Loss:0.479 AVG Validation Loss:0.504 AVG Training Acc 80.83 % AVG Validation Acc 79.62 %\n",
      "Epoch:180/200 AVG Training Loss:0.480 AVG Validation Loss:0.505 AVG Training Acc 80.65 % AVG Validation Acc 79.62 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.479 AVG Validation Loss:0.505 AVG Training Acc 80.65 % AVG Validation Acc 79.71 %\n",
      "Epoch:200/200 AVG Training Loss:0.480 AVG Validation Loss:0.504 AVG Training Acc 80.78 % AVG Validation Acc 79.62 %\n",
      "Split 65\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c03ed96d75984b2795d2a19bea18f348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.19 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.21 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.20 % AVG Validation Acc 80.16 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.22 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.23 % AVG Validation Acc 80.07 %\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.30 % AVG Validation Acc 79.89 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.25 % AVG Validation Acc 79.98 %\n",
      "Epoch:100/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.22 % AVG Validation Acc 79.98 %\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.28 % AVG Validation Acc 79.98 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.20 % AVG Validation Acc 79.98 %\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.17 % AVG Validation Acc 79.98 %\n",
      "Epoch:140/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.26 % AVG Validation Acc 79.98 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.25 % AVG Validation Acc 79.98 %\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.24 % AVG Validation Acc 79.98 %\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 79.98 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.29 % AVG Validation Acc 79.98 %\n",
      "Epoch:190/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.27 % AVG Validation Acc 79.98 %\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.25 % AVG Validation Acc 79.98 %\n",
      "Split 66\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3897fb8962e3477ea3f9b3b17a687677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.499 AVG Training Acc 80.22 % AVG Validation Acc 79.96 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.498 AVG Training Acc 80.36 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.501 AVG Training Acc 80.50 % AVG Validation Acc 80.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.484 AVG Validation Loss:0.505 AVG Training Acc 80.58 % AVG Validation Acc 80.05 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.482 AVG Validation Loss:0.508 AVG Training Acc 80.71 % AVG Validation Acc 79.69 %\n",
      "Epoch:80/200 AVG Training Loss:0.481 AVG Validation Loss:0.510 AVG Training Acc 80.77 % AVG Validation Acc 79.69 %\n",
      "Epoch:90/200 AVG Training Loss:0.480 AVG Validation Loss:0.509 AVG Training Acc 80.81 % AVG Validation Acc 79.69 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.481 AVG Validation Loss:0.511 AVG Training Acc 80.75 % AVG Validation Acc 79.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.482 AVG Validation Loss:0.511 AVG Training Acc 80.73 % AVG Validation Acc 79.60 %\n",
      "Epoch:120/200 AVG Training Loss:0.481 AVG Validation Loss:0.511 AVG Training Acc 80.65 % AVG Validation Acc 79.51 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.481 AVG Validation Loss:0.511 AVG Training Acc 80.80 % AVG Validation Acc 79.60 %\n",
      "Epoch:140/200 AVG Training Loss:0.480 AVG Validation Loss:0.510 AVG Training Acc 80.80 % AVG Validation Acc 79.69 %\n",
      "Epoch:150/200 AVG Training Loss:0.481 AVG Validation Loss:0.511 AVG Training Acc 80.88 % AVG Validation Acc 79.60 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.480 AVG Validation Loss:0.511 AVG Training Acc 80.69 % AVG Validation Acc 79.69 %\n",
      "Epoch:170/200 AVG Training Loss:0.481 AVG Validation Loss:0.511 AVG Training Acc 80.80 % AVG Validation Acc 79.60 %\n",
      "Epoch:180/200 AVG Training Loss:0.481 AVG Validation Loss:0.511 AVG Training Acc 80.77 % AVG Validation Acc 79.69 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.481 AVG Validation Loss:0.511 AVG Training Acc 80.80 % AVG Validation Acc 79.51 %\n",
      "Epoch:200/200 AVG Training Loss:0.481 AVG Validation Loss:0.511 AVG Training Acc 80.79 % AVG Validation Acc 79.60 %\n",
      "Split 67\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8790ca92a1954d8fab8edf9402bd3094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.10 % AVG Validation Acc 80.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.06 % AVG Validation Acc 80.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Split 68\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1643c7eb16c04c25967cf732d3d69bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.490 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.489 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.488 AVG Training Acc 80.27 % AVG Validation Acc 80.14 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.494 AVG Training Acc 80.58 % AVG Validation Acc 79.78 %\n",
      "Epoch:50/200 AVG Training Loss:0.482 AVG Validation Loss:0.498 AVG Training Acc 80.69 % AVG Validation Acc 79.60 %\n",
      "Epoch:60/200 AVG Training Loss:0.479 AVG Validation Loss:0.506 AVG Training Acc 80.86 % AVG Validation Acc 79.06 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.475 AVG Validation Loss:0.508 AVG Training Acc 81.09 % AVG Validation Acc 78.88 %\n",
      "Epoch:80/200 AVG Training Loss:0.475 AVG Validation Loss:0.508 AVG Training Acc 81.09 % AVG Validation Acc 78.88 %\n",
      "Epoch:90/200 AVG Training Loss:0.474 AVG Validation Loss:0.511 AVG Training Acc 81.14 % AVG Validation Acc 78.97 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.472 AVG Validation Loss:0.510 AVG Training Acc 81.27 % AVG Validation Acc 78.70 %\n",
      "Epoch:110/200 AVG Training Loss:0.475 AVG Validation Loss:0.513 AVG Training Acc 81.08 % AVG Validation Acc 78.79 %\n",
      "Epoch:120/200 AVG Training Loss:0.475 AVG Validation Loss:0.512 AVG Training Acc 81.13 % AVG Validation Acc 78.88 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.474 AVG Validation Loss:0.513 AVG Training Acc 81.17 % AVG Validation Acc 78.61 %\n",
      "Epoch:140/200 AVG Training Loss:0.474 AVG Validation Loss:0.512 AVG Training Acc 81.19 % AVG Validation Acc 78.70 %\n",
      "Epoch:150/200 AVG Training Loss:0.473 AVG Validation Loss:0.511 AVG Training Acc 81.22 % AVG Validation Acc 78.61 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.474 AVG Validation Loss:0.510 AVG Training Acc 81.21 % AVG Validation Acc 78.70 %\n",
      "Epoch:170/200 AVG Training Loss:0.474 AVG Validation Loss:0.511 AVG Training Acc 81.19 % AVG Validation Acc 78.70 %\n",
      "Epoch:180/200 AVG Training Loss:0.475 AVG Validation Loss:0.513 AVG Training Acc 81.22 % AVG Validation Acc 78.70 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.474 AVG Validation Loss:0.510 AVG Training Acc 81.12 % AVG Validation Acc 78.70 %\n",
      "Epoch:200/200 AVG Training Loss:0.473 AVG Validation Loss:0.513 AVG Training Acc 81.18 % AVG Validation Acc 78.79 %\n",
      "Split 69\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7470025f7b248f99180ac01c13c888a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.499 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.498 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.498 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.492 AVG Validation Loss:0.497 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.25 % AVG Validation Acc 80.14 %\n",
      "Epoch    71: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.24 % AVG Validation Acc 80.05 %\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.31 % AVG Validation Acc 80.05 %\n",
      "Epoch:100/200 AVG Training Loss:0.487 AVG Validation Loss:0.498 AVG Training Acc 80.38 % AVG Validation Acc 80.14 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.30 % AVG Validation Acc 80.14 %\n",
      "Epoch:120/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.31 % AVG Validation Acc 80.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.27 % AVG Validation Acc 80.05 %\n",
      "Epoch   133: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.488 AVG Validation Loss:0.498 AVG Training Acc 80.24 % AVG Validation Acc 80.05 %\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.32 % AVG Validation Acc 80.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.26 % AVG Validation Acc 80.14 %\n",
      "Epoch   164: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.498 AVG Training Acc 80.32 % AVG Validation Acc 80.05 %\n",
      "Epoch:190/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.25 % AVG Validation Acc 80.05 %\n",
      "Epoch   195: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.498 AVG Training Acc 80.25 % AVG Validation Acc 80.14 %\n",
      "Split 70\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26c877647fa746239c637b9382ee3a0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.499 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.500 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.29 % AVG Validation Acc 79.96 %\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.37 % AVG Validation Acc 79.78 %\n",
      "Epoch:60/200 AVG Training Loss:0.484 AVG Validation Loss:0.493 AVG Training Acc 80.46 % AVG Validation Acc 79.87 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.482 AVG Validation Loss:0.493 AVG Training Acc 80.58 % AVG Validation Acc 79.87 %\n",
      "Epoch:80/200 AVG Training Loss:0.482 AVG Validation Loss:0.494 AVG Training Acc 80.58 % AVG Validation Acc 79.87 %\n",
      "Epoch:90/200 AVG Training Loss:0.481 AVG Validation Loss:0.494 AVG Training Acc 80.72 % AVG Validation Acc 79.78 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.482 AVG Validation Loss:0.493 AVG Training Acc 80.49 % AVG Validation Acc 79.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.481 AVG Validation Loss:0.494 AVG Training Acc 80.58 % AVG Validation Acc 79.87 %\n",
      "Epoch:120/200 AVG Training Loss:0.480 AVG Validation Loss:0.494 AVG Training Acc 80.64 % AVG Validation Acc 79.87 %\n",
      "Epoch:130/200 AVG Training Loss:0.481 AVG Validation Loss:0.494 AVG Training Acc 80.54 % AVG Validation Acc 79.87 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.481 AVG Validation Loss:0.495 AVG Training Acc 80.58 % AVG Validation Acc 79.87 %\n",
      "Epoch:150/200 AVG Training Loss:0.482 AVG Validation Loss:0.495 AVG Training Acc 80.52 % AVG Validation Acc 79.87 %\n",
      "Epoch:160/200 AVG Training Loss:0.481 AVG Validation Loss:0.494 AVG Training Acc 80.68 % AVG Validation Acc 79.87 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.481 AVG Validation Loss:0.494 AVG Training Acc 80.61 % AVG Validation Acc 79.87 %\n",
      "Epoch:180/200 AVG Training Loss:0.481 AVG Validation Loss:0.494 AVG Training Acc 80.51 % AVG Validation Acc 79.87 %\n",
      "Epoch:190/200 AVG Training Loss:0.482 AVG Validation Loss:0.493 AVG Training Acc 80.62 % AVG Validation Acc 79.87 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.480 AVG Validation Loss:0.494 AVG Training Acc 80.58 % AVG Validation Acc 79.87 %\n",
      "Split 71\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "527c384925b940abbbecb3fd27eb4752",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.12 % AVG Validation Acc 80.07 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.19 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.24 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.491 AVG Training Acc 80.30 % AVG Validation Acc 80.16 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.486 AVG Validation Loss:0.493 AVG Training Acc 80.41 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.485 AVG Validation Loss:0.494 AVG Training Acc 80.50 % AVG Validation Acc 80.07 %\n",
      "Epoch:80/200 AVG Training Loss:0.486 AVG Validation Loss:0.493 AVG Training Acc 80.33 % AVG Validation Acc 80.07 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.485 AVG Validation Loss:0.493 AVG Training Acc 80.46 % AVG Validation Acc 80.07 %\n",
      "Epoch:100/200 AVG Training Loss:0.485 AVG Validation Loss:0.493 AVG Training Acc 80.42 % AVG Validation Acc 80.07 %\n",
      "Epoch:110/200 AVG Training Loss:0.485 AVG Validation Loss:0.493 AVG Training Acc 80.36 % AVG Validation Acc 80.07 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.485 AVG Validation Loss:0.493 AVG Training Acc 80.42 % AVG Validation Acc 80.07 %\n",
      "Epoch:130/200 AVG Training Loss:0.485 AVG Validation Loss:0.494 AVG Training Acc 80.33 % AVG Validation Acc 80.07 %\n",
      "Epoch:140/200 AVG Training Loss:0.485 AVG Validation Loss:0.494 AVG Training Acc 80.38 % AVG Validation Acc 80.07 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.494 AVG Training Acc 80.43 % AVG Validation Acc 80.07 %\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.494 AVG Training Acc 80.42 % AVG Validation Acc 80.07 %\n",
      "Epoch:170/200 AVG Training Loss:0.485 AVG Validation Loss:0.494 AVG Training Acc 80.31 % AVG Validation Acc 80.07 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.485 AVG Validation Loss:0.493 AVG Training Acc 80.44 % AVG Validation Acc 80.07 %\n",
      "Epoch:190/200 AVG Training Loss:0.484 AVG Validation Loss:0.493 AVG Training Acc 80.37 % AVG Validation Acc 80.07 %\n",
      "Epoch:200/200 AVG Training Loss:0.485 AVG Validation Loss:0.493 AVG Training Acc 80.38 % AVG Validation Acc 80.07 %\n",
      "Split 72\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef91220c7fb340e982c63e848d6ba572",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.491 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.491 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.492 AVG Training Acc 80.23 % AVG Validation Acc 80.07 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.37 % AVG Validation Acc 79.80 %\n",
      "Epoch:50/200 AVG Training Loss:0.482 AVG Validation Loss:0.500 AVG Training Acc 80.59 % AVG Validation Acc 79.98 %\n",
      "Epoch:60/200 AVG Training Loss:0.480 AVG Validation Loss:0.506 AVG Training Acc 80.69 % AVG Validation Acc 79.89 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.477 AVG Validation Loss:0.509 AVG Training Acc 80.84 % AVG Validation Acc 79.89 %\n",
      "Epoch:80/200 AVG Training Loss:0.476 AVG Validation Loss:0.510 AVG Training Acc 81.01 % AVG Validation Acc 79.89 %\n",
      "Epoch:90/200 AVG Training Loss:0.476 AVG Validation Loss:0.511 AVG Training Acc 80.94 % AVG Validation Acc 79.89 %\n",
      "Epoch:100/200 AVG Training Loss:0.476 AVG Validation Loss:0.511 AVG Training Acc 80.94 % AVG Validation Acc 79.89 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.475 AVG Validation Loss:0.510 AVG Training Acc 80.96 % AVG Validation Acc 79.89 %\n",
      "Epoch:120/200 AVG Training Loss:0.475 AVG Validation Loss:0.511 AVG Training Acc 81.02 % AVG Validation Acc 79.89 %\n",
      "Epoch:130/200 AVG Training Loss:0.475 AVG Validation Loss:0.511 AVG Training Acc 81.08 % AVG Validation Acc 79.89 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.476 AVG Validation Loss:0.511 AVG Training Acc 81.05 % AVG Validation Acc 79.80 %\n",
      "Epoch:150/200 AVG Training Loss:0.475 AVG Validation Loss:0.511 AVG Training Acc 80.92 % AVG Validation Acc 79.89 %\n",
      "Epoch:160/200 AVG Training Loss:0.474 AVG Validation Loss:0.511 AVG Training Acc 81.00 % AVG Validation Acc 79.80 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.475 AVG Validation Loss:0.511 AVG Training Acc 81.03 % AVG Validation Acc 79.80 %\n",
      "Epoch:180/200 AVG Training Loss:0.475 AVG Validation Loss:0.511 AVG Training Acc 81.00 % AVG Validation Acc 79.80 %\n",
      "Epoch:190/200 AVG Training Loss:0.476 AVG Validation Loss:0.511 AVG Training Acc 80.98 % AVG Validation Acc 79.80 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.475 AVG Validation Loss:0.510 AVG Training Acc 81.00 % AVG Validation Acc 79.89 %\n",
      "Split 73\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5d37b5c36af455aa31d6d9959f46510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.493 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.488 AVG Training Acc 80.38 % AVG Validation Acc 79.98 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.494 AVG Training Acc 80.53 % AVG Validation Acc 79.98 %\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.63 % AVG Validation Acc 80.07 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.482 AVG Validation Loss:0.497 AVG Training Acc 80.68 % AVG Validation Acc 80.07 %\n",
      "Epoch:80/200 AVG Training Loss:0.481 AVG Validation Loss:0.498 AVG Training Acc 80.70 % AVG Validation Acc 80.07 %\n",
      "Epoch:90/200 AVG Training Loss:0.482 AVG Validation Loss:0.497 AVG Training Acc 80.68 % AVG Validation Acc 80.07 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.481 AVG Validation Loss:0.498 AVG Training Acc 80.70 % AVG Validation Acc 79.98 %\n",
      "Epoch:110/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.71 % AVG Validation Acc 80.07 %\n",
      "Epoch:120/200 AVG Training Loss:0.481 AVG Validation Loss:0.498 AVG Training Acc 80.75 % AVG Validation Acc 79.98 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.481 AVG Validation Loss:0.498 AVG Training Acc 80.67 % AVG Validation Acc 79.98 %\n",
      "Epoch:140/200 AVG Training Loss:0.481 AVG Validation Loss:0.498 AVG Training Acc 80.63 % AVG Validation Acc 80.07 %\n",
      "Epoch:150/200 AVG Training Loss:0.482 AVG Validation Loss:0.498 AVG Training Acc 80.63 % AVG Validation Acc 79.98 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.66 % AVG Validation Acc 80.07 %\n",
      "Epoch:170/200 AVG Training Loss:0.481 AVG Validation Loss:0.498 AVG Training Acc 80.70 % AVG Validation Acc 79.98 %\n",
      "Epoch:180/200 AVG Training Loss:0.481 AVG Validation Loss:0.497 AVG Training Acc 80.81 % AVG Validation Acc 80.07 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.481 AVG Validation Loss:0.498 AVG Training Acc 80.71 % AVG Validation Acc 79.98 %\n",
      "Epoch:200/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.64 % AVG Validation Acc 79.98 %\n",
      "Split 74\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce69d83ee5f54972bf79139f85fbcafa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.19 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.27 % AVG Validation Acc 79.98 %\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.28 % AVG Validation Acc 79.98 %\n",
      "Epoch:60/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.32 % AVG Validation Acc 79.89 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.41 % AVG Validation Acc 79.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.39 % AVG Validation Acc 79.98 %\n",
      "Epoch:90/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.44 % AVG Validation Acc 79.89 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.32 % AVG Validation Acc 79.80 %\n",
      "Epoch:110/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.45 % AVG Validation Acc 79.89 %\n",
      "Epoch:120/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.47 % AVG Validation Acc 79.80 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.35 % AVG Validation Acc 79.80 %\n",
      "Epoch:140/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.36 % AVG Validation Acc 79.80 %\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.35 % AVG Validation Acc 79.80 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.40 % AVG Validation Acc 79.80 %\n",
      "Epoch:170/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.37 % AVG Validation Acc 79.80 %\n",
      "Epoch:180/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.41 % AVG Validation Acc 79.80 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.51 % AVG Validation Acc 79.80 %\n",
      "Epoch:200/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.46 % AVG Validation Acc 79.80 %\n",
      "Split 75\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4aac7683b57a456d8e04a08ae22a32a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.499 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.493 AVG Training Acc 80.20 % AVG Validation Acc 79.98 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 79.98 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.18 % AVG Validation Acc 79.98 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.19 % AVG Validation Acc 79.98 %\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 79.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 79.98 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.17 % AVG Validation Acc 79.98 %\n",
      "Epoch:100/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.19 % AVG Validation Acc 79.98 %\n",
      "Epoch:110/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 79.98 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 79.98 %\n",
      "Epoch:130/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 79.98 %\n",
      "Epoch:140/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.22 % AVG Validation Acc 79.98 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.18 % AVG Validation Acc 79.98 %\n",
      "Epoch:160/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.17 % AVG Validation Acc 79.98 %\n",
      "Epoch:170/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 79.98 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 79.98 %\n",
      "Epoch:190/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 79.98 %\n",
      "Epoch:200/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.19 % AVG Validation Acc 79.98 %\n",
      "Split 76\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09d6b3f3adbe4c058233f7b015b42d4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.19 % AVG Validation Acc 80.23 %\n",
      "Epoch:60/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.18 % AVG Validation Acc 80.23 %\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.16 % AVG Validation Acc 80.23 %\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.21 % AVG Validation Acc 80.23 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.25 % AVG Validation Acc 80.23 %\n",
      "Epoch:100/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.28 % AVG Validation Acc 80.23 %\n",
      "Epoch:110/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.22 % AVG Validation Acc 80.23 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.26 % AVG Validation Acc 80.23 %\n",
      "Epoch:130/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.22 % AVG Validation Acc 80.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.29 % AVG Validation Acc 80.23 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.40 % AVG Validation Acc 80.23 %\n",
      "Epoch:160/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.24 % AVG Validation Acc 80.23 %\n",
      "Epoch:170/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.39 % AVG Validation Acc 80.23 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.31 % AVG Validation Acc 80.23 %\n",
      "Epoch:190/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.28 % AVG Validation Acc 80.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.28 % AVG Validation Acc 80.23 %\n",
      "Split 77\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c7c23e5c8d44539c5418fa6c592049",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.499 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.498 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.26 % AVG Validation Acc 79.96 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.40 % AVG Validation Acc 79.96 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.51 % AVG Validation Acc 79.87 %\n",
      "Epoch:70/200 AVG Training Loss:0.482 AVG Validation Loss:0.499 AVG Training Acc 80.54 % AVG Validation Acc 79.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.482 AVG Validation Loss:0.499 AVG Training Acc 80.55 % AVG Validation Acc 79.87 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.73 % AVG Validation Acc 79.78 %\n",
      "Epoch:100/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.67 % AVG Validation Acc 79.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.55 % AVG Validation Acc 79.78 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.481 AVG Validation Loss:0.500 AVG Training Acc 80.49 % AVG Validation Acc 79.78 %\n",
      "Epoch:130/200 AVG Training Loss:0.480 AVG Validation Loss:0.499 AVG Training Acc 80.65 % AVG Validation Acc 79.69 %\n",
      "Epoch:140/200 AVG Training Loss:0.482 AVG Validation Loss:0.499 AVG Training Acc 80.56 % AVG Validation Acc 79.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.481 AVG Validation Loss:0.500 AVG Training Acc 80.53 % AVG Validation Acc 79.69 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.482 AVG Validation Loss:0.499 AVG Training Acc 80.64 % AVG Validation Acc 79.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.68 % AVG Validation Acc 79.78 %\n",
      "Epoch:180/200 AVG Training Loss:0.481 AVG Validation Loss:0.500 AVG Training Acc 80.62 % AVG Validation Acc 79.78 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.480 AVG Validation Loss:0.499 AVG Training Acc 80.73 % AVG Validation Acc 79.78 %\n",
      "Epoch:200/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.49 % AVG Validation Acc 79.78 %\n",
      "Split 78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98f2ed740bc44ee48aacaad8be079072",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.23 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.33 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.26 % AVG Validation Acc 80.23 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.40 % AVG Validation Acc 80.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.36 % AVG Validation Acc 80.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.38 % AVG Validation Acc 80.14 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.36 % AVG Validation Acc 80.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.40 % AVG Validation Acc 80.14 %\n",
      "Epoch:120/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.32 % AVG Validation Acc 80.14 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.47 % AVG Validation Acc 80.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.486 AVG Validation Loss:0.499 AVG Training Acc 80.39 % AVG Validation Acc 80.14 %\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.44 % AVG Validation Acc 80.14 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.486 AVG Validation Loss:0.499 AVG Training Acc 80.37 % AVG Validation Acc 80.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.486 AVG Validation Loss:0.499 AVG Training Acc 80.33 % AVG Validation Acc 80.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.39 % AVG Validation Acc 80.14 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.39 % AVG Validation Acc 80.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.34 % AVG Validation Acc 80.14 %\n",
      "Split 79\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4377cc6b3f24ef48bb93a9e9b349afb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.27 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.30 % AVG Validation Acc 80.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.487 AVG Validation Loss:0.489 AVG Training Acc 80.30 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.36 % AVG Validation Acc 80.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.484 AVG Validation Loss:0.491 AVG Training Acc 80.48 % AVG Validation Acc 80.14 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.482 AVG Validation Loss:0.492 AVG Training Acc 80.57 % AVG Validation Acc 80.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.481 AVG Validation Loss:0.492 AVG Training Acc 80.65 % AVG Validation Acc 80.23 %\n",
      "Epoch:110/200 AVG Training Loss:0.480 AVG Validation Loss:0.492 AVG Training Acc 80.61 % AVG Validation Acc 80.23 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.481 AVG Validation Loss:0.493 AVG Training Acc 80.64 % AVG Validation Acc 80.23 %\n",
      "Epoch:130/200 AVG Training Loss:0.481 AVG Validation Loss:0.493 AVG Training Acc 80.54 % AVG Validation Acc 80.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.481 AVG Validation Loss:0.492 AVG Training Acc 80.59 % AVG Validation Acc 80.14 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.480 AVG Validation Loss:0.492 AVG Training Acc 80.74 % AVG Validation Acc 80.23 %\n",
      "Epoch:160/200 AVG Training Loss:0.482 AVG Validation Loss:0.493 AVG Training Acc 80.64 % AVG Validation Acc 80.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.481 AVG Validation Loss:0.492 AVG Training Acc 80.63 % AVG Validation Acc 80.23 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.479 AVG Validation Loss:0.492 AVG Training Acc 80.65 % AVG Validation Acc 80.23 %\n",
      "Epoch:190/200 AVG Training Loss:0.480 AVG Validation Loss:0.492 AVG Training Acc 80.71 % AVG Validation Acc 80.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.481 AVG Validation Loss:0.492 AVG Training Acc 80.62 % AVG Validation Acc 80.23 %\n",
      "Split 80\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5a65320f41f43e08297e34c098d2a39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.17 % AVG Validation Acc 80.23 %\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.26 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.33 % AVG Validation Acc 80.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.29 % AVG Validation Acc 80.14 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.27 % AVG Validation Acc 80.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.25 % AVG Validation Acc 80.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.37 % AVG Validation Acc 80.14 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.29 % AVG Validation Acc 80.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.29 % AVG Validation Acc 80.14 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.25 % AVG Validation Acc 80.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.31 % AVG Validation Acc 80.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.31 % AVG Validation Acc 80.14 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.30 % AVG Validation Acc 80.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.29 % AVG Validation Acc 80.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.31 % AVG Validation Acc 80.14 %\n",
      "Split 81\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "798844acc3d443659338f360f44b9caf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.491 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.491 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.32 % AVG Validation Acc 79.98 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.30 % AVG Validation Acc 79.98 %\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.37 % AVG Validation Acc 79.89 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.37 % AVG Validation Acc 79.98 %\n",
      "Epoch:70/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.56 % AVG Validation Acc 79.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.49 % AVG Validation Acc 80.07 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.33 % AVG Validation Acc 80.07 %\n",
      "Epoch:100/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.51 % AVG Validation Acc 79.98 %\n",
      "Epoch:110/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.39 % AVG Validation Acc 80.07 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.38 % AVG Validation Acc 80.07 %\n",
      "Epoch:130/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.37 % AVG Validation Acc 80.07 %\n",
      "Epoch:140/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.35 % AVG Validation Acc 80.07 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.38 % AVG Validation Acc 80.07 %\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.52 % AVG Validation Acc 80.07 %\n",
      "Epoch:170/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.48 % AVG Validation Acc 80.07 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.47 % AVG Validation Acc 80.07 %\n",
      "Epoch:190/200 AVG Training Loss:0.484 AVG Validation Loss:0.498 AVG Training Acc 80.47 % AVG Validation Acc 80.07 %\n",
      "Epoch:200/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.45 % AVG Validation Acc 80.07 %\n",
      "Split 82\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a0d3fa5b1b4cdc95daa87b40cf2ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.19 % AVG Validation Acc 79.98 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.29 % AVG Validation Acc 79.98 %\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.34 % AVG Validation Acc 80.07 %\n",
      "Epoch:60/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.40 % AVG Validation Acc 80.16 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.483 AVG Validation Loss:0.494 AVG Training Acc 80.49 % AVG Validation Acc 80.16 %\n",
      "Epoch:80/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.53 % AVG Validation Acc 80.16 %\n",
      "Epoch:90/200 AVG Training Loss:0.484 AVG Validation Loss:0.494 AVG Training Acc 80.52 % AVG Validation Acc 80.16 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.483 AVG Validation Loss:0.495 AVG Training Acc 80.42 % AVG Validation Acc 80.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.45 % AVG Validation Acc 80.16 %\n",
      "Epoch:120/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.54 % AVG Validation Acc 80.16 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.484 AVG Validation Loss:0.494 AVG Training Acc 80.49 % AVG Validation Acc 80.16 %\n",
      "Epoch:140/200 AVG Training Loss:0.483 AVG Validation Loss:0.494 AVG Training Acc 80.44 % AVG Validation Acc 80.16 %\n",
      "Epoch:150/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.43 % AVG Validation Acc 80.16 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.49 % AVG Validation Acc 80.16 %\n",
      "Epoch:170/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.47 % AVG Validation Acc 80.16 %\n",
      "Epoch:180/200 AVG Training Loss:0.483 AVG Validation Loss:0.495 AVG Training Acc 80.51 % AVG Validation Acc 80.16 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.484 AVG Validation Loss:0.494 AVG Training Acc 80.42 % AVG Validation Acc 80.16 %\n",
      "Epoch:200/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.52 % AVG Validation Acc 80.16 %\n",
      "Split 83\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "599128e01e9440bf90dc058660391532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.492 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.18 % AVG Validation Acc 80.25 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.18 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.23 % AVG Validation Acc 80.25 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.21 % AVG Validation Acc 80.25 %\n",
      "Epoch:80/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.23 % AVG Validation Acc 80.25 %\n",
      "Epoch:90/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.22 % AVG Validation Acc 80.25 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.23 % AVG Validation Acc 80.25 %\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.490 AVG Training Acc 80.26 % AVG Validation Acc 80.25 %\n",
      "Epoch:120/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.23 % AVG Validation Acc 80.25 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.490 AVG Training Acc 80.24 % AVG Validation Acc 80.25 %\n",
      "Epoch:140/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.20 % AVG Validation Acc 80.25 %\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.25 % AVG Validation Acc 80.25 %\n",
      "Epoch:160/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.24 % AVG Validation Acc 80.25 %\n",
      "Epoch   163: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.490 AVG Training Acc 80.25 % AVG Validation Acc 80.25 %\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.490 AVG Training Acc 80.26 % AVG Validation Acc 80.25 %\n",
      "Epoch:190/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.25 % AVG Validation Acc 80.25 %\n",
      "Epoch   194: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.25 % AVG Validation Acc 80.25 %\n",
      "Split 84\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48590dbe47824a79aff75663a1277795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.492 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.24 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.31 % AVG Validation Acc 80.07 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.32 % AVG Validation Acc 80.25 %\n",
      "Epoch:60/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.39 % AVG Validation Acc 80.07 %\n",
      "Epoch:70/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.41 % AVG Validation Acc 80.07 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.40 % AVG Validation Acc 80.07 %\n",
      "Epoch:90/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.40 % AVG Validation Acc 80.07 %\n",
      "Epoch:100/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.40 % AVG Validation Acc 80.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.40 % AVG Validation Acc 80.07 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.38 % AVG Validation Acc 80.16 %\n",
      "Epoch:130/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.39 % AVG Validation Acc 80.07 %\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.37 % AVG Validation Acc 80.07 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.39 % AVG Validation Acc 80.07 %\n",
      "Epoch:160/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.44 % AVG Validation Acc 80.16 %\n",
      "Epoch:170/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.42 % AVG Validation Acc 80.07 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.40 % AVG Validation Acc 80.07 %\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.42 % AVG Validation Acc 80.07 %\n",
      "Epoch:200/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.38 % AVG Validation Acc 80.07 %\n",
      "Split 85\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "152defee6ab0473baae0b4a3ef15fd5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.502 AVG Training Acc 80.12 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.500 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.498 AVG Training Acc 80.20 % AVG Validation Acc 79.98 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.20 % AVG Validation Acc 79.98 %\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.32 % AVG Validation Acc 79.89 %\n",
      "Epoch:60/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.46 % AVG Validation Acc 80.07 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.51 % AVG Validation Acc 80.07 %\n",
      "Epoch:80/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.53 % AVG Validation Acc 79.98 %\n",
      "Epoch:90/200 AVG Training Loss:0.484 AVG Validation Loss:0.498 AVG Training Acc 80.50 % AVG Validation Acc 80.07 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.482 AVG Validation Loss:0.498 AVG Training Acc 80.57 % AVG Validation Acc 80.07 %\n",
      "Epoch:110/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.51 % AVG Validation Acc 80.07 %\n",
      "Epoch:120/200 AVG Training Loss:0.482 AVG Validation Loss:0.498 AVG Training Acc 80.67 % AVG Validation Acc 80.07 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.56 % AVG Validation Acc 80.07 %\n",
      "Epoch:140/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.53 % AVG Validation Acc 80.07 %\n",
      "Epoch:150/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.57 % AVG Validation Acc 80.07 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.482 AVG Validation Loss:0.498 AVG Training Acc 80.67 % AVG Validation Acc 80.07 %\n",
      "Epoch:170/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.62 % AVG Validation Acc 80.07 %\n",
      "Epoch:180/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.60 % AVG Validation Acc 80.07 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.75 % AVG Validation Acc 80.07 %\n",
      "Epoch:200/200 AVG Training Loss:0.482 AVG Validation Loss:0.498 AVG Training Acc 80.57 % AVG Validation Acc 80.07 %\n",
      "Split 86\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18c14f6014014d6b993e124f81e89ba7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.05 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.19 % AVG Validation Acc 80.05 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.21 % AVG Validation Acc 79.96 %\n",
      "Epoch:60/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.31 % AVG Validation Acc 79.96 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.44 % AVG Validation Acc 79.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.51 % AVG Validation Acc 79.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.47 % AVG Validation Acc 79.96 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.44 % AVG Validation Acc 79.96 %\n",
      "Epoch:110/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.45 % AVG Validation Acc 79.96 %\n",
      "Epoch:120/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.44 % AVG Validation Acc 80.05 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.49 % AVG Validation Acc 79.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.47 % AVG Validation Acc 80.05 %\n",
      "Epoch:150/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.52 % AVG Validation Acc 80.05 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.42 % AVG Validation Acc 79.96 %\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.53 % AVG Validation Acc 79.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.46 % AVG Validation Acc 79.96 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.48 % AVG Validation Acc 79.96 %\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.49 % AVG Validation Acc 79.96 %\n",
      "Split 87\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be751d18fea24316b09fcbd7fee7d361",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.12 % AVG Validation Acc 79.96 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.25 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.499 AVG Training Acc 80.40 % AVG Validation Acc 80.05 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.481 AVG Validation Loss:0.510 AVG Training Acc 80.72 % AVG Validation Acc 79.78 %\n",
      "Epoch:70/200 AVG Training Loss:0.477 AVG Validation Loss:0.514 AVG Training Acc 81.01 % AVG Validation Acc 79.69 %\n",
      "Epoch:80/200 AVG Training Loss:0.476 AVG Validation Loss:0.524 AVG Training Acc 80.97 % AVG Validation Acc 79.51 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.470 AVG Validation Loss:0.528 AVG Training Acc 81.34 % AVG Validation Acc 79.51 %\n",
      "Epoch:100/200 AVG Training Loss:0.471 AVG Validation Loss:0.528 AVG Training Acc 81.26 % AVG Validation Acc 79.51 %\n",
      "Epoch:110/200 AVG Training Loss:0.470 AVG Validation Loss:0.530 AVG Training Acc 81.44 % AVG Validation Acc 79.42 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.470 AVG Validation Loss:0.531 AVG Training Acc 81.29 % AVG Validation Acc 79.42 %\n",
      "Epoch:130/200 AVG Training Loss:0.471 AVG Validation Loss:0.523 AVG Training Acc 81.27 % AVG Validation Acc 79.42 %\n",
      "Epoch:140/200 AVG Training Loss:0.469 AVG Validation Loss:0.530 AVG Training Acc 81.37 % AVG Validation Acc 79.51 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.470 AVG Validation Loss:0.525 AVG Training Acc 81.23 % AVG Validation Acc 79.51 %\n",
      "Epoch:160/200 AVG Training Loss:0.468 AVG Validation Loss:0.531 AVG Training Acc 81.45 % AVG Validation Acc 79.33 %\n",
      "Epoch:170/200 AVG Training Loss:0.469 AVG Validation Loss:0.531 AVG Training Acc 81.46 % AVG Validation Acc 79.42 %\n",
      "Epoch:180/200 AVG Training Loss:0.469 AVG Validation Loss:0.524 AVG Training Acc 81.42 % AVG Validation Acc 79.51 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.469 AVG Validation Loss:0.519 AVG Training Acc 81.31 % AVG Validation Acc 79.60 %\n",
      "Epoch:200/200 AVG Training Loss:0.469 AVG Validation Loss:0.532 AVG Training Acc 81.54 % AVG Validation Acc 79.33 %\n",
      "Split 88\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b2ceb5749134300b228788a08fc0c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.32 %\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.503 AVG Training Acc 80.34 % AVG Validation Acc 80.05 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:70/200 AVG Training Loss:0.482 AVG Validation Loss:0.503 AVG Training Acc 80.58 % AVG Validation Acc 79.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.479 AVG Validation Loss:0.512 AVG Training Acc 80.89 % AVG Validation Acc 79.87 %\n",
      "Epoch:90/200 AVG Training Loss:0.477 AVG Validation Loss:0.520 AVG Training Acc 80.92 % AVG Validation Acc 79.87 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.476 AVG Validation Loss:0.524 AVG Training Acc 80.91 % AVG Validation Acc 79.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.474 AVG Validation Loss:0.530 AVG Training Acc 81.09 % AVG Validation Acc 79.33 %\n",
      "Epoch:120/200 AVG Training Loss:0.474 AVG Validation Loss:0.523 AVG Training Acc 81.08 % AVG Validation Acc 79.60 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.475 AVG Validation Loss:0.526 AVG Training Acc 81.00 % AVG Validation Acc 79.42 %\n",
      "Epoch:140/200 AVG Training Loss:0.475 AVG Validation Loss:0.524 AVG Training Acc 80.93 % AVG Validation Acc 79.42 %\n",
      "Epoch:150/200 AVG Training Loss:0.475 AVG Validation Loss:0.524 AVG Training Acc 80.95 % AVG Validation Acc 79.51 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.475 AVG Validation Loss:0.523 AVG Training Acc 81.05 % AVG Validation Acc 79.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.474 AVG Validation Loss:0.524 AVG Training Acc 81.09 % AVG Validation Acc 79.33 %\n",
      "Epoch:180/200 AVG Training Loss:0.475 AVG Validation Loss:0.526 AVG Training Acc 80.96 % AVG Validation Acc 79.42 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.474 AVG Validation Loss:0.523 AVG Training Acc 81.03 % AVG Validation Acc 79.60 %\n",
      "Epoch:200/200 AVG Training Loss:0.475 AVG Validation Loss:0.527 AVG Training Acc 80.91 % AVG Validation Acc 79.51 %\n",
      "Split 89\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a940ad587d949ebbffb6cebad0d58a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.500 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.498 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.28 % AVG Validation Acc 80.23 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.30 % AVG Validation Acc 80.23 %\n",
      "Epoch:70/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.36 % AVG Validation Acc 80.23 %\n",
      "Epoch:80/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.28 % AVG Validation Acc 80.23 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.30 % AVG Validation Acc 80.23 %\n",
      "Epoch:100/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.34 % AVG Validation Acc 80.23 %\n",
      "Epoch:110/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.31 % AVG Validation Acc 80.23 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.35 % AVG Validation Acc 80.23 %\n",
      "Epoch:130/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.31 % AVG Validation Acc 80.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.34 % AVG Validation Acc 80.23 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.35 % AVG Validation Acc 80.23 %\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.26 % AVG Validation Acc 80.23 %\n",
      "Epoch:170/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.36 % AVG Validation Acc 80.23 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.487 AVG Validation Loss:0.498 AVG Training Acc 80.32 % AVG Validation Acc 80.23 %\n",
      "Epoch:190/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.30 % AVG Validation Acc 80.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.47 % AVG Validation Acc 80.23 %\n",
      "Split 90\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c98f3166de7e4a8e8d41ef3e90ec761f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch:120/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Split 91\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b896b15ffbf74638a228e024a06a7ab9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.491 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.30 % AVG Validation Acc 80.25 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.34 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.36 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.33 % AVG Validation Acc 80.16 %\n",
      "Epoch:80/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.38 % AVG Validation Acc 80.16 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.38 % AVG Validation Acc 80.16 %\n",
      "Epoch:100/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.37 % AVG Validation Acc 80.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.35 % AVG Validation Acc 80.16 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.33 % AVG Validation Acc 80.16 %\n",
      "Epoch:130/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.41 % AVG Validation Acc 80.16 %\n",
      "Epoch:140/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.42 % AVG Validation Acc 80.16 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.35 % AVG Validation Acc 80.16 %\n",
      "Epoch:160/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.41 % AVG Validation Acc 80.16 %\n",
      "Epoch:170/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.32 % AVG Validation Acc 80.16 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.28 % AVG Validation Acc 80.16 %\n",
      "Epoch:190/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.37 % AVG Validation Acc 80.16 %\n",
      "Epoch:200/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.42 % AVG Validation Acc 80.16 %\n",
      "Split 92\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2477329f8fcb46b885e22b77639f7a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.498 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.498 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.20 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.499 AVG Training Acc 80.22 % AVG Validation Acc 79.89 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.503 AVG Training Acc 80.40 % AVG Validation Acc 79.80 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.484 AVG Validation Loss:0.504 AVG Training Acc 80.46 % AVG Validation Acc 79.80 %\n",
      "Epoch:70/200 AVG Training Loss:0.484 AVG Validation Loss:0.505 AVG Training Acc 80.57 % AVG Validation Acc 79.80 %\n",
      "Epoch:80/200 AVG Training Loss:0.483 AVG Validation Loss:0.507 AVG Training Acc 80.56 % AVG Validation Acc 79.71 %\n",
      "Epoch:90/200 AVG Training Loss:0.483 AVG Validation Loss:0.507 AVG Training Acc 80.61 % AVG Validation Acc 79.62 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.483 AVG Validation Loss:0.507 AVG Training Acc 80.57 % AVG Validation Acc 79.62 %\n",
      "Epoch:110/200 AVG Training Loss:0.482 AVG Validation Loss:0.507 AVG Training Acc 80.69 % AVG Validation Acc 79.71 %\n",
      "Epoch:120/200 AVG Training Loss:0.482 AVG Validation Loss:0.507 AVG Training Acc 80.57 % AVG Validation Acc 79.53 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.482 AVG Validation Loss:0.507 AVG Training Acc 80.62 % AVG Validation Acc 79.53 %\n",
      "Epoch:140/200 AVG Training Loss:0.483 AVG Validation Loss:0.507 AVG Training Acc 80.69 % AVG Validation Acc 79.71 %\n",
      "Epoch:150/200 AVG Training Loss:0.482 AVG Validation Loss:0.507 AVG Training Acc 80.63 % AVG Validation Acc 79.62 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.482 AVG Validation Loss:0.507 AVG Training Acc 80.70 % AVG Validation Acc 79.71 %\n",
      "Epoch:170/200 AVG Training Loss:0.483 AVG Validation Loss:0.507 AVG Training Acc 80.60 % AVG Validation Acc 79.62 %\n",
      "Epoch:180/200 AVG Training Loss:0.482 AVG Validation Loss:0.508 AVG Training Acc 80.75 % AVG Validation Acc 79.53 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.482 AVG Validation Loss:0.507 AVG Training Acc 80.55 % AVG Validation Acc 79.62 %\n",
      "Epoch:200/200 AVG Training Loss:0.482 AVG Validation Loss:0.507 AVG Training Acc 80.61 % AVG Validation Acc 79.53 %\n",
      "Split 93\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ce98373faa4a7eaa77f4284ddd74af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.10 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.27 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.33 % AVG Validation Acc 80.25 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.491 AVG Training Acc 80.53 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.477 AVG Validation Loss:0.489 AVG Training Acc 80.80 % AVG Validation Acc 80.43 %\n",
      "Epoch:70/200 AVG Training Loss:0.473 AVG Validation Loss:0.494 AVG Training Acc 81.11 % AVG Validation Acc 79.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.471 AVG Validation Loss:0.495 AVG Training Acc 81.31 % AVG Validation Acc 79.98 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.470 AVG Validation Loss:0.498 AVG Training Acc 81.30 % AVG Validation Acc 79.71 %\n",
      "Epoch:100/200 AVG Training Loss:0.468 AVG Validation Loss:0.498 AVG Training Acc 81.36 % AVG Validation Acc 79.53 %\n",
      "Epoch:110/200 AVG Training Loss:0.470 AVG Validation Loss:0.499 AVG Training Acc 81.21 % AVG Validation Acc 79.89 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.469 AVG Validation Loss:0.500 AVG Training Acc 81.46 % AVG Validation Acc 79.62 %\n",
      "Epoch:130/200 AVG Training Loss:0.469 AVG Validation Loss:0.499 AVG Training Acc 81.35 % AVG Validation Acc 79.71 %\n",
      "Epoch:140/200 AVG Training Loss:0.469 AVG Validation Loss:0.499 AVG Training Acc 81.34 % AVG Validation Acc 79.98 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.467 AVG Validation Loss:0.499 AVG Training Acc 81.43 % AVG Validation Acc 79.80 %\n",
      "Epoch:160/200 AVG Training Loss:0.468 AVG Validation Loss:0.498 AVG Training Acc 81.39 % AVG Validation Acc 79.62 %\n",
      "Epoch:170/200 AVG Training Loss:0.468 AVG Validation Loss:0.500 AVG Training Acc 81.36 % AVG Validation Acc 79.62 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.468 AVG Validation Loss:0.497 AVG Training Acc 81.24 % AVG Validation Acc 79.89 %\n",
      "Epoch:190/200 AVG Training Loss:0.468 AVG Validation Loss:0.499 AVG Training Acc 81.28 % AVG Validation Acc 79.71 %\n",
      "Epoch:200/200 AVG Training Loss:0.469 AVG Validation Loss:0.499 AVG Training Acc 81.39 % AVG Validation Acc 79.89 %\n",
      "Split 94\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fcc4c869ac6467e9d856f0cb2f031dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.501 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.490 AVG Validation Loss:0.499 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.499 AVG Training Acc 80.20 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.499 AVG Training Acc 80.21 % AVG Validation Acc 80.16 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.21 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.20 % AVG Validation Acc 80.16 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.487 AVG Validation Loss:0.500 AVG Training Acc 80.20 % AVG Validation Acc 80.16 %\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.500 AVG Training Acc 80.21 % AVG Validation Acc 80.16 %\n",
      "Epoch:100/200 AVG Training Loss:0.487 AVG Validation Loss:0.500 AVG Training Acc 80.20 % AVG Validation Acc 80.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.22 % AVG Validation Acc 80.16 %\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.23 % AVG Validation Acc 80.16 %\n",
      "Epoch:140/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.21 % AVG Validation Acc 80.16 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.500 AVG Training Acc 80.22 % AVG Validation Acc 80.16 %\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.22 % AVG Validation Acc 80.16 %\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.25 % AVG Validation Acc 80.16 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.500 AVG Training Acc 80.26 % AVG Validation Acc 80.16 %\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.500 AVG Training Acc 80.24 % AVG Validation Acc 80.16 %\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.22 % AVG Validation Acc 80.16 %\n",
      "Split 95\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58115a81ccdf44f8a8e849b8a9dc71de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.492 AVG Training Acc 80.18 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.491 AVG Training Acc 80.20 % AVG Validation Acc 79.98 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.23 % AVG Validation Acc 79.98 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.23 % AVG Validation Acc 79.98 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.30 % AVG Validation Acc 79.98 %\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.28 % AVG Validation Acc 79.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.30 % AVG Validation Acc 79.98 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.29 % AVG Validation Acc 79.98 %\n",
      "Epoch:100/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.28 % AVG Validation Acc 79.98 %\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.30 % AVG Validation Acc 79.98 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.28 % AVG Validation Acc 79.98 %\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.28 % AVG Validation Acc 79.98 %\n",
      "Epoch:140/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.33 % AVG Validation Acc 79.98 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.31 % AVG Validation Acc 79.98 %\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.28 % AVG Validation Acc 79.98 %\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.33 % AVG Validation Acc 79.98 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.28 % AVG Validation Acc 79.98 %\n",
      "Epoch:190/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.26 % AVG Validation Acc 79.98 %\n",
      "Epoch:200/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.22 % AVG Validation Acc 79.98 %\n",
      "Split 96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "743486fb51654e5c8899a1b546bb951e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.493 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.493 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.20 % AVG Validation Acc 80.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.25 % AVG Validation Acc 80.05 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.23 % AVG Validation Acc 80.05 %\n",
      "Epoch:130/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.21 % AVG Validation Acc 80.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.21 % AVG Validation Acc 80.05 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.23 % AVG Validation Acc 80.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.19 % AVG Validation Acc 80.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.21 % AVG Validation Acc 80.05 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.21 % AVG Validation Acc 80.05 %\n",
      "Epoch:190/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.22 % AVG Validation Acc 80.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.21 % AVG Validation Acc 80.05 %\n",
      "Split 97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0463677d044c458eb348125fbb5e5841",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.493 AVG Validation Loss:0.492 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.26 % AVG Validation Acc 79.87 %\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.31 % AVG Validation Acc 79.96 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.27 % AVG Validation Acc 79.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.37 % AVG Validation Acc 79.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.29 % AVG Validation Acc 79.87 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.26 % AVG Validation Acc 79.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.32 % AVG Validation Acc 79.78 %\n",
      "Epoch:120/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.35 % AVG Validation Acc 79.69 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.37 % AVG Validation Acc 79.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.35 % AVG Validation Acc 79.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.32 % AVG Validation Acc 79.78 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.34 % AVG Validation Acc 79.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.36 % AVG Validation Acc 79.78 %\n",
      "Epoch:180/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.31 % AVG Validation Acc 79.78 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.29 % AVG Validation Acc 79.78 %\n",
      "Epoch:200/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.31 % AVG Validation Acc 79.78 %\n",
      "Split 98\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd03611098b4457a9f30eba573ddc0fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.492 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.491 AVG Training Acc 80.19 % AVG Validation Acc 80.23 %\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.492 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.491 AVG Validation Loss:0.492 AVG Training Acc 80.14 % AVG Validation Acc 80.23 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.15 % AVG Validation Acc 80.23 %\n",
      "Epoch:70/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.21 % AVG Validation Acc 80.23 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.19 % AVG Validation Acc 80.23 %\n",
      "Epoch:100/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.17 % AVG Validation Acc 80.23 %\n",
      "Epoch:110/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.18 % AVG Validation Acc 80.23 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.22 % AVG Validation Acc 80.23 %\n",
      "Epoch:130/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.21 % AVG Validation Acc 80.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.15 % AVG Validation Acc 80.23 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.20 % AVG Validation Acc 80.23 %\n",
      "Epoch:160/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.20 % AVG Validation Acc 80.23 %\n",
      "Epoch:170/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.19 % AVG Validation Acc 80.23 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.21 % AVG Validation Acc 80.23 %\n",
      "Epoch:190/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.18 % AVG Validation Acc 80.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.19 % AVG Validation Acc 80.23 %\n",
      "Split 99\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b597591cb1c459b93c4eaab5334fbcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.28 % AVG Validation Acc 80.42 %\n",
      "Epoch:50/200 AVG Training Loss:0.483 AVG Validation Loss:0.492 AVG Training Acc 80.38 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.481 AVG Validation Loss:0.493 AVG Training Acc 80.57 % AVG Validation Acc 80.51 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.487 AVG Validation Loss:0.503 AVG Training Acc 80.31 % AVG Validation Acc 80.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.54 % AVG Validation Acc 79.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.483 AVG Validation Loss:0.496 AVG Training Acc 80.46 % AVG Validation Acc 80.23 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.482 AVG Validation Loss:0.497 AVG Training Acc 80.53 % AVG Validation Acc 79.96 %\n",
      "Epoch:110/200 AVG Training Loss:0.481 AVG Validation Loss:0.498 AVG Training Acc 80.63 % AVG Validation Acc 80.32 %\n",
      "Epoch:120/200 AVG Training Loss:0.481 AVG Validation Loss:0.498 AVG Training Acc 80.58 % AVG Validation Acc 80.14 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.482 AVG Validation Loss:0.497 AVG Training Acc 80.49 % AVG Validation Acc 80.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.481 AVG Validation Loss:0.496 AVG Training Acc 80.50 % AVG Validation Acc 80.23 %\n",
      "Epoch:150/200 AVG Training Loss:0.481 AVG Validation Loss:0.498 AVG Training Acc 80.53 % AVG Validation Acc 80.05 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.483 AVG Validation Loss:0.496 AVG Training Acc 80.40 % AVG Validation Acc 80.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.482 AVG Validation Loss:0.496 AVG Training Acc 80.60 % AVG Validation Acc 80.32 %\n",
      "Epoch:180/200 AVG Training Loss:0.482 AVG Validation Loss:0.496 AVG Training Acc 80.50 % AVG Validation Acc 80.32 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.481 AVG Validation Loss:0.496 AVG Training Acc 80.58 % AVG Validation Acc 80.32 %\n",
      "Epoch:200/200 AVG Training Loss:0.482 AVG Validation Loss:0.497 AVG Training Acc 80.42 % AVG Validation Acc 80.23 %\n",
      "Split 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0abf334dec47edacc7323475e76ef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.491 AVG Training Acc 80.14 % AVG Validation Acc 80.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.16 % AVG Validation Acc 80.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.25 % AVG Validation Acc 79.96 %\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.30 % AVG Validation Acc 80.05 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.487 AVG Validation Loss:0.491 AVG Training Acc 80.30 % AVG Validation Acc 80.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.37 % AVG Validation Acc 80.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.487 AVG Validation Loss:0.491 AVG Training Acc 80.32 % AVG Validation Acc 80.14 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.487 AVG Validation Loss:0.491 AVG Training Acc 80.36 % AVG Validation Acc 80.05 %\n",
      "Epoch:100/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.37 % AVG Validation Acc 80.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.36 % AVG Validation Acc 80.14 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.487 AVG Validation Loss:0.491 AVG Training Acc 80.31 % AVG Validation Acc 80.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.38 % AVG Validation Acc 80.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.491 AVG Training Acc 80.38 % AVG Validation Acc 80.05 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.486 AVG Validation Loss:0.491 AVG Training Acc 80.37 % AVG Validation Acc 80.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.35 % AVG Validation Acc 80.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.487 AVG Validation Loss:0.491 AVG Training Acc 80.31 % AVG Validation Acc 80.14 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.30 % AVG Validation Acc 80.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.491 AVG Training Acc 80.34 % AVG Validation Acc 80.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.487 AVG Validation Loss:0.491 AVG Training Acc 80.42 % AVG Validation Acc 80.14 %\n",
      "Split 101\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e96820daa3f04811ae5199074c7bc8b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.08 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.34 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.490 AVG Training Acc 80.39 % AVG Validation Acc 79.89 %\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.492 AVG Training Acc 80.44 % AVG Validation Acc 79.62 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.482 AVG Validation Loss:0.492 AVG Training Acc 80.61 % AVG Validation Acc 79.53 %\n",
      "Epoch:80/200 AVG Training Loss:0.481 AVG Validation Loss:0.493 AVG Training Acc 80.72 % AVG Validation Acc 79.53 %\n",
      "Epoch:90/200 AVG Training Loss:0.481 AVG Validation Loss:0.493 AVG Training Acc 80.67 % AVG Validation Acc 79.53 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.482 AVG Validation Loss:0.491 AVG Training Acc 80.49 % AVG Validation Acc 79.44 %\n",
      "Epoch:110/200 AVG Training Loss:0.481 AVG Validation Loss:0.493 AVG Training Acc 80.68 % AVG Validation Acc 79.44 %\n",
      "Epoch:120/200 AVG Training Loss:0.482 AVG Validation Loss:0.492 AVG Training Acc 80.57 % AVG Validation Acc 79.44 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.481 AVG Validation Loss:0.493 AVG Training Acc 80.60 % AVG Validation Acc 79.44 %\n",
      "Epoch:140/200 AVG Training Loss:0.480 AVG Validation Loss:0.493 AVG Training Acc 80.67 % AVG Validation Acc 79.44 %\n",
      "Epoch:150/200 AVG Training Loss:0.480 AVG Validation Loss:0.493 AVG Training Acc 80.81 % AVG Validation Acc 79.44 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.481 AVG Validation Loss:0.492 AVG Training Acc 80.73 % AVG Validation Acc 79.35 %\n",
      "Epoch:170/200 AVG Training Loss:0.480 AVG Validation Loss:0.493 AVG Training Acc 80.63 % AVG Validation Acc 79.44 %\n",
      "Epoch:180/200 AVG Training Loss:0.480 AVG Validation Loss:0.492 AVG Training Acc 80.67 % AVG Validation Acc 79.44 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.480 AVG Validation Loss:0.493 AVG Training Acc 80.60 % AVG Validation Acc 79.44 %\n",
      "Epoch:200/200 AVG Training Loss:0.481 AVG Validation Loss:0.492 AVG Training Acc 80.65 % AVG Validation Acc 79.44 %\n",
      "Split 102\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "454326d0ac5746b38ffc9f938b22679f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.34 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.484 AVG Validation Loss:0.494 AVG Training Acc 80.55 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.481 AVG Validation Loss:0.493 AVG Training Acc 80.72 % AVG Validation Acc 80.34 %\n",
      "Epoch:70/200 AVG Training Loss:0.480 AVG Validation Loss:0.498 AVG Training Acc 80.81 % AVG Validation Acc 80.16 %\n",
      "Epoch    70: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.480 AVG Validation Loss:0.498 AVG Training Acc 80.90 % AVG Validation Acc 79.98 %\n",
      "Epoch:90/200 AVG Training Loss:0.478 AVG Validation Loss:0.498 AVG Training Acc 80.86 % AVG Validation Acc 80.07 %\n",
      "Epoch:100/200 AVG Training Loss:0.477 AVG Validation Loss:0.502 AVG Training Acc 80.85 % AVG Validation Acc 80.07 %\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.478 AVG Validation Loss:0.503 AVG Training Acc 80.91 % AVG Validation Acc 79.98 %\n",
      "Epoch:120/200 AVG Training Loss:0.478 AVG Validation Loss:0.502 AVG Training Acc 80.81 % AVG Validation Acc 79.98 %\n",
      "Epoch:130/200 AVG Training Loss:0.477 AVG Validation Loss:0.502 AVG Training Acc 80.83 % AVG Validation Acc 80.07 %\n",
      "Epoch   132: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.478 AVG Validation Loss:0.502 AVG Training Acc 80.83 % AVG Validation Acc 80.07 %\n",
      "Epoch:150/200 AVG Training Loss:0.477 AVG Validation Loss:0.502 AVG Training Acc 80.96 % AVG Validation Acc 80.07 %\n",
      "Epoch:160/200 AVG Training Loss:0.478 AVG Validation Loss:0.503 AVG Training Acc 80.84 % AVG Validation Acc 79.98 %\n",
      "Epoch   163: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.479 AVG Validation Loss:0.503 AVG Training Acc 80.94 % AVG Validation Acc 80.07 %\n",
      "Epoch:180/200 AVG Training Loss:0.476 AVG Validation Loss:0.503 AVG Training Acc 80.98 % AVG Validation Acc 80.07 %\n",
      "Epoch:190/200 AVG Training Loss:0.477 AVG Validation Loss:0.503 AVG Training Acc 80.97 % AVG Validation Acc 80.07 %\n",
      "Epoch   194: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.477 AVG Validation Loss:0.503 AVG Training Acc 80.91 % AVG Validation Acc 80.07 %\n",
      "Split 103\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2788b45c43f4eb3bb1d5a5fb3267cce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.18 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.496 AVG Training Acc 80.16 % AVG Validation Acc 79.98 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.501 AVG Training Acc 80.37 % AVG Validation Acc 79.80 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.486 AVG Validation Loss:0.501 AVG Training Acc 80.41 % AVG Validation Acc 79.89 %\n",
      "Epoch:70/200 AVG Training Loss:0.485 AVG Validation Loss:0.501 AVG Training Acc 80.38 % AVG Validation Acc 79.80 %\n",
      "Epoch:80/200 AVG Training Loss:0.484 AVG Validation Loss:0.502 AVG Training Acc 80.58 % AVG Validation Acc 79.80 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.485 AVG Validation Loss:0.502 AVG Training Acc 80.48 % AVG Validation Acc 79.80 %\n",
      "Epoch:100/200 AVG Training Loss:0.485 AVG Validation Loss:0.502 AVG Training Acc 80.39 % AVG Validation Acc 79.80 %\n",
      "Epoch:110/200 AVG Training Loss:0.484 AVG Validation Loss:0.502 AVG Training Acc 80.44 % AVG Validation Acc 79.80 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.485 AVG Validation Loss:0.502 AVG Training Acc 80.41 % AVG Validation Acc 79.80 %\n",
      "Epoch:130/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.43 % AVG Validation Acc 79.80 %\n",
      "Epoch:140/200 AVG Training Loss:0.484 AVG Validation Loss:0.502 AVG Training Acc 80.43 % AVG Validation Acc 79.80 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.502 AVG Training Acc 80.45 % AVG Validation Acc 79.80 %\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.502 AVG Training Acc 80.51 % AVG Validation Acc 79.80 %\n",
      "Epoch:170/200 AVG Training Loss:0.484 AVG Validation Loss:0.502 AVG Training Acc 80.45 % AVG Validation Acc 79.80 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.484 AVG Validation Loss:0.502 AVG Training Acc 80.52 % AVG Validation Acc 79.80 %\n",
      "Epoch:190/200 AVG Training Loss:0.484 AVG Validation Loss:0.502 AVG Training Acc 80.49 % AVG Validation Acc 79.80 %\n",
      "Epoch:200/200 AVG Training Loss:0.485 AVG Validation Loss:0.502 AVG Training Acc 80.45 % AVG Validation Acc 79.80 %\n",
      "Split 104\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e999842c594f1e808f87841b9d3b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.492 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.32 % AVG Validation Acc 79.98 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.31 % AVG Validation Acc 79.98 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.38 % AVG Validation Acc 79.89 %\n",
      "Epoch:60/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.40 % AVG Validation Acc 79.98 %\n",
      "Epoch:70/200 AVG Training Loss:0.485 AVG Validation Loss:0.494 AVG Training Acc 80.44 % AVG Validation Acc 79.80 %\n",
      "Epoch:80/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.36 % AVG Validation Acc 79.80 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.39 % AVG Validation Acc 79.80 %\n",
      "Epoch:100/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.39 % AVG Validation Acc 79.98 %\n",
      "Epoch:110/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.40 % AVG Validation Acc 79.89 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.35 % AVG Validation Acc 79.80 %\n",
      "Epoch:130/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.40 % AVG Validation Acc 79.98 %\n",
      "Epoch:140/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.40 % AVG Validation Acc 79.89 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.50 % AVG Validation Acc 79.98 %\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.37 % AVG Validation Acc 79.89 %\n",
      "Epoch:170/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.38 % AVG Validation Acc 79.80 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.36 % AVG Validation Acc 79.80 %\n",
      "Epoch:190/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.51 % AVG Validation Acc 79.80 %\n",
      "Epoch:200/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.43 % AVG Validation Acc 79.89 %\n",
      "Split 105\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b3fe6f5390d4db79ed79e404dad8523",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.12 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.18 % AVG Validation Acc 80.07 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.489 AVG Training Acc 80.22 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.24 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.490 AVG Training Acc 80.36 % AVG Validation Acc 79.80 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.42 % AVG Validation Acc 80.07 %\n",
      "Epoch:70/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.41 % AVG Validation Acc 80.07 %\n",
      "Epoch:80/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.34 % AVG Validation Acc 80.07 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.44 % AVG Validation Acc 80.07 %\n",
      "Epoch:100/200 AVG Training Loss:0.485 AVG Validation Loss:0.490 AVG Training Acc 80.50 % AVG Validation Acc 80.07 %\n",
      "Epoch:110/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.42 % AVG Validation Acc 80.07 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.40 % AVG Validation Acc 80.07 %\n",
      "Epoch:130/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.40 % AVG Validation Acc 80.07 %\n",
      "Epoch:140/200 AVG Training Loss:0.485 AVG Validation Loss:0.490 AVG Training Acc 80.48 % AVG Validation Acc 80.07 %\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.490 AVG Training Acc 80.41 % AVG Validation Acc 80.07 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.43 % AVG Validation Acc 80.07 %\n",
      "Epoch:170/200 AVG Training Loss:0.485 AVG Validation Loss:0.490 AVG Training Acc 80.47 % AVG Validation Acc 80.07 %\n",
      "Epoch:180/200 AVG Training Loss:0.485 AVG Validation Loss:0.490 AVG Training Acc 80.44 % AVG Validation Acc 80.07 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.46 % AVG Validation Acc 80.07 %\n",
      "Epoch:200/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.37 % AVG Validation Acc 80.07 %\n",
      "Split 106\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45dcbf63b2842789fcb35cd65d4795d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.28 % AVG Validation Acc 79.87 %\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.499 AVG Training Acc 80.45 % AVG Validation Acc 79.51 %\n",
      "Epoch:50/200 AVG Training Loss:0.483 AVG Validation Loss:0.505 AVG Training Acc 80.56 % AVG Validation Acc 79.24 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.505 AVG Training Acc 80.70 % AVG Validation Acc 79.24 %\n",
      "Epoch:70/200 AVG Training Loss:0.481 AVG Validation Loss:0.508 AVG Training Acc 80.70 % AVG Validation Acc 79.24 %\n",
      "Epoch:80/200 AVG Training Loss:0.482 AVG Validation Loss:0.509 AVG Training Acc 80.67 % AVG Validation Acc 79.24 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.482 AVG Validation Loss:0.509 AVG Training Acc 80.66 % AVG Validation Acc 79.33 %\n",
      "Epoch:100/200 AVG Training Loss:0.482 AVG Validation Loss:0.510 AVG Training Acc 80.68 % AVG Validation Acc 79.24 %\n",
      "Epoch:110/200 AVG Training Loss:0.481 AVG Validation Loss:0.510 AVG Training Acc 80.65 % AVG Validation Acc 79.33 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.481 AVG Validation Loss:0.510 AVG Training Acc 80.70 % AVG Validation Acc 79.24 %\n",
      "Epoch:130/200 AVG Training Loss:0.481 AVG Validation Loss:0.509 AVG Training Acc 80.70 % AVG Validation Acc 79.24 %\n",
      "Epoch:140/200 AVG Training Loss:0.482 AVG Validation Loss:0.509 AVG Training Acc 80.69 % AVG Validation Acc 79.24 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.481 AVG Validation Loss:0.510 AVG Training Acc 80.78 % AVG Validation Acc 79.24 %\n",
      "Epoch:160/200 AVG Training Loss:0.481 AVG Validation Loss:0.511 AVG Training Acc 80.74 % AVG Validation Acc 79.33 %\n",
      "Epoch:170/200 AVG Training Loss:0.482 AVG Validation Loss:0.510 AVG Training Acc 80.79 % AVG Validation Acc 79.33 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.481 AVG Validation Loss:0.509 AVG Training Acc 80.71 % AVG Validation Acc 79.24 %\n",
      "Epoch:190/200 AVG Training Loss:0.481 AVG Validation Loss:0.510 AVG Training Acc 80.72 % AVG Validation Acc 79.24 %\n",
      "Epoch:200/200 AVG Training Loss:0.481 AVG Validation Loss:0.511 AVG Training Acc 80.66 % AVG Validation Acc 79.24 %\n",
      "Split 107\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f89bd71ff27c44a898695255fc9609b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.498 AVG Training Acc 80.09 % AVG Validation Acc 80.14 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.498 AVG Training Acc 80.10 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.05 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.19 % AVG Validation Acc 80.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.487 AVG Validation Loss:0.498 AVG Training Acc 80.28 % AVG Validation Acc 80.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.487 AVG Validation Loss:0.498 AVG Training Acc 80.28 % AVG Validation Acc 79.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.487 AVG Validation Loss:0.498 AVG Training Acc 80.28 % AVG Validation Acc 79.96 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.487 AVG Validation Loss:0.498 AVG Training Acc 80.35 % AVG Validation Acc 79.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.487 AVG Validation Loss:0.498 AVG Training Acc 80.26 % AVG Validation Acc 79.96 %\n",
      "Epoch:110/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.32 % AVG Validation Acc 79.96 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.25 % AVG Validation Acc 79.96 %\n",
      "Epoch:130/200 AVG Training Loss:0.487 AVG Validation Loss:0.499 AVG Training Acc 80.32 % AVG Validation Acc 79.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.30 % AVG Validation Acc 79.96 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.487 AVG Validation Loss:0.498 AVG Training Acc 80.27 % AVG Validation Acc 79.96 %\n",
      "Epoch:160/200 AVG Training Loss:0.487 AVG Validation Loss:0.498 AVG Training Acc 80.30 % AVG Validation Acc 79.96 %\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.21 % AVG Validation Acc 79.96 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.29 % AVG Validation Acc 79.96 %\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.498 AVG Training Acc 80.28 % AVG Validation Acc 79.96 %\n",
      "Epoch:200/200 AVG Training Loss:0.487 AVG Validation Loss:0.498 AVG Training Acc 80.33 % AVG Validation Acc 79.96 %\n",
      "Split 108\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90ee88d9d82545eebf479800b47a5ae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.498 AVG Training Acc 80.19 % AVG Validation Acc 80.05 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.499 AVG Training Acc 80.28 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.500 AVG Training Acc 80.34 % AVG Validation Acc 80.14 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.485 AVG Validation Loss:0.502 AVG Training Acc 80.45 % AVG Validation Acc 79.78 %\n",
      "Epoch:70/200 AVG Training Loss:0.486 AVG Validation Loss:0.502 AVG Training Acc 80.48 % AVG Validation Acc 79.87 %\n",
      "Epoch:80/200 AVG Training Loss:0.486 AVG Validation Loss:0.503 AVG Training Acc 80.48 % AVG Validation Acc 79.87 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.485 AVG Validation Loss:0.503 AVG Training Acc 80.50 % AVG Validation Acc 79.87 %\n",
      "Epoch:100/200 AVG Training Loss:0.485 AVG Validation Loss:0.503 AVG Training Acc 80.47 % AVG Validation Acc 79.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.485 AVG Validation Loss:0.503 AVG Training Acc 80.42 % AVG Validation Acc 79.87 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.485 AVG Validation Loss:0.503 AVG Training Acc 80.50 % AVG Validation Acc 79.87 %\n",
      "Epoch:130/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.53 % AVG Validation Acc 79.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.485 AVG Validation Loss:0.503 AVG Training Acc 80.44 % AVG Validation Acc 79.87 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.484 AVG Validation Loss:0.504 AVG Training Acc 80.48 % AVG Validation Acc 79.87 %\n",
      "Epoch:160/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.48 % AVG Validation Acc 79.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.45 % AVG Validation Acc 79.87 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.485 AVG Validation Loss:0.503 AVG Training Acc 80.46 % AVG Validation Acc 79.87 %\n",
      "Epoch:190/200 AVG Training Loss:0.485 AVG Validation Loss:0.503 AVG Training Acc 80.53 % AVG Validation Acc 79.87 %\n",
      "Epoch:200/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.51 % AVG Validation Acc 79.87 %\n",
      "Split 109\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1a83c820a344fe9b819a99cd925a7a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.492 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.27 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.27 % AVG Validation Acc 80.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.25 % AVG Validation Acc 80.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.30 % AVG Validation Acc 80.14 %\n",
      "Epoch:120/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.24 % AVG Validation Acc 80.14 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.26 % AVG Validation Acc 80.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.26 % AVG Validation Acc 80.14 %\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.29 % AVG Validation Acc 80.14 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.31 % AVG Validation Acc 80.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.23 % AVG Validation Acc 80.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.27 % AVG Validation Acc 80.14 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.24 % AVG Validation Acc 80.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.25 % AVG Validation Acc 80.14 %\n",
      "Split 110\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f45a12ee6a2944c19d3cd4841edf4f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.489 AVG Training Acc 80.22 % AVG Validation Acc 80.23 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.26 % AVG Validation Acc 80.42 %\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.490 AVG Training Acc 80.37 % AVG Validation Acc 80.32 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.486 AVG Validation Loss:0.491 AVG Training Acc 80.47 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.486 AVG Validation Loss:0.492 AVG Training Acc 80.46 % AVG Validation Acc 79.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.486 AVG Validation Loss:0.493 AVG Training Acc 80.46 % AVG Validation Acc 79.78 %\n",
      "Epoch:90/200 AVG Training Loss:0.486 AVG Validation Loss:0.493 AVG Training Acc 80.35 % AVG Validation Acc 79.78 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.485 AVG Validation Loss:0.493 AVG Training Acc 80.38 % AVG Validation Acc 79.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.486 AVG Validation Loss:0.493 AVG Training Acc 80.50 % AVG Validation Acc 79.78 %\n",
      "Epoch:120/200 AVG Training Loss:0.485 AVG Validation Loss:0.493 AVG Training Acc 80.52 % AVG Validation Acc 79.78 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.485 AVG Validation Loss:0.493 AVG Training Acc 80.42 % AVG Validation Acc 79.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.485 AVG Validation Loss:0.493 AVG Training Acc 80.40 % AVG Validation Acc 79.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.486 AVG Validation Loss:0.493 AVG Training Acc 80.50 % AVG Validation Acc 79.78 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.493 AVG Training Acc 80.39 % AVG Validation Acc 79.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.486 AVG Validation Loss:0.493 AVG Training Acc 80.49 % AVG Validation Acc 79.78 %\n",
      "Epoch:180/200 AVG Training Loss:0.485 AVG Validation Loss:0.493 AVG Training Acc 80.49 % AVG Validation Acc 79.78 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.486 AVG Validation Loss:0.493 AVG Training Acc 80.55 % AVG Validation Acc 79.78 %\n",
      "Epoch:200/200 AVG Training Loss:0.486 AVG Validation Loss:0.493 AVG Training Acc 80.42 % AVG Validation Acc 79.78 %\n",
      "Split 111\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29bda1619aa943ccaf753208b15f2df4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.496 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.493 AVG Validation Loss:0.489 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.492 AVG Validation Loss:0.489 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.491 AVG Validation Loss:0.488 AVG Training Acc 80.16 % AVG Validation Acc 80.25 %\n",
      "Epoch:60/200 AVG Training Loss:0.491 AVG Validation Loss:0.489 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.490 AVG Validation Loss:0.489 AVG Training Acc 80.22 % AVG Validation Acc 80.25 %\n",
      "Epoch:80/200 AVG Training Loss:0.490 AVG Validation Loss:0.488 AVG Training Acc 80.21 % AVG Validation Acc 80.25 %\n",
      "Epoch:90/200 AVG Training Loss:0.490 AVG Validation Loss:0.487 AVG Training Acc 80.18 % AVG Validation Acc 80.25 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.490 AVG Validation Loss:0.488 AVG Training Acc 80.16 % AVG Validation Acc 80.25 %\n",
      "Epoch:110/200 AVG Training Loss:0.489 AVG Validation Loss:0.488 AVG Training Acc 80.19 % AVG Validation Acc 80.25 %\n",
      "Epoch:120/200 AVG Training Loss:0.490 AVG Validation Loss:0.488 AVG Training Acc 80.16 % AVG Validation Acc 80.25 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.16 % AVG Validation Acc 80.25 %\n",
      "Epoch:140/200 AVG Training Loss:0.490 AVG Validation Loss:0.488 AVG Training Acc 80.13 % AVG Validation Acc 80.25 %\n",
      "Epoch:150/200 AVG Training Loss:0.490 AVG Validation Loss:0.488 AVG Training Acc 80.20 % AVG Validation Acc 80.25 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.490 AVG Validation Loss:0.489 AVG Training Acc 80.17 % AVG Validation Acc 80.25 %\n",
      "Epoch:170/200 AVG Training Loss:0.490 AVG Validation Loss:0.488 AVG Training Acc 80.21 % AVG Validation Acc 80.25 %\n",
      "Epoch:180/200 AVG Training Loss:0.490 AVG Validation Loss:0.489 AVG Training Acc 80.21 % AVG Validation Acc 80.25 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.490 AVG Validation Loss:0.489 AVG Training Acc 80.15 % AVG Validation Acc 80.25 %\n",
      "Epoch:200/200 AVG Training Loss:0.490 AVG Validation Loss:0.488 AVG Training Acc 80.15 % AVG Validation Acc 80.25 %\n",
      "Split 112\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e952e1ab5c4d0d91fa786a429c8262",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.496 AVG Training Acc 80.33 % AVG Validation Acc 80.16 %\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.484 AVG Validation Loss:0.501 AVG Training Acc 80.50 % AVG Validation Acc 79.98 %\n",
      "Epoch:60/200 AVG Training Loss:0.481 AVG Validation Loss:0.500 AVG Training Acc 80.69 % AVG Validation Acc 79.98 %\n",
      "Epoch:70/200 AVG Training Loss:0.480 AVG Validation Loss:0.517 AVG Training Acc 80.79 % AVG Validation Acc 79.62 %\n",
      "Epoch    71: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.479 AVG Validation Loss:0.517 AVG Training Acc 80.70 % AVG Validation Acc 79.71 %\n",
      "Epoch:90/200 AVG Training Loss:0.478 AVG Validation Loss:0.511 AVG Training Acc 80.83 % AVG Validation Acc 79.71 %\n",
      "Epoch:100/200 AVG Training Loss:0.478 AVG Validation Loss:0.518 AVG Training Acc 80.83 % AVG Validation Acc 79.80 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.478 AVG Validation Loss:0.513 AVG Training Acc 80.82 % AVG Validation Acc 79.71 %\n",
      "Epoch:120/200 AVG Training Loss:0.478 AVG Validation Loss:0.517 AVG Training Acc 80.88 % AVG Validation Acc 79.80 %\n",
      "Epoch:130/200 AVG Training Loss:0.478 AVG Validation Loss:0.521 AVG Training Acc 80.87 % AVG Validation Acc 79.62 %\n",
      "Epoch   133: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.477 AVG Validation Loss:0.517 AVG Training Acc 80.83 % AVG Validation Acc 79.71 %\n",
      "Epoch:150/200 AVG Training Loss:0.478 AVG Validation Loss:0.516 AVG Training Acc 80.85 % AVG Validation Acc 79.71 %\n",
      "Epoch:160/200 AVG Training Loss:0.478 AVG Validation Loss:0.517 AVG Training Acc 80.82 % AVG Validation Acc 79.71 %\n",
      "Epoch   164: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.479 AVG Validation Loss:0.517 AVG Training Acc 80.81 % AVG Validation Acc 79.71 %\n",
      "Epoch:180/200 AVG Training Loss:0.477 AVG Validation Loss:0.517 AVG Training Acc 80.89 % AVG Validation Acc 79.71 %\n",
      "Epoch:190/200 AVG Training Loss:0.479 AVG Validation Loss:0.518 AVG Training Acc 80.82 % AVG Validation Acc 79.62 %\n",
      "Epoch   195: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.479 AVG Validation Loss:0.518 AVG Training Acc 80.76 % AVG Validation Acc 79.62 %\n",
      "Split 113\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed3f7db9041541088eb77843aad24977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.493 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.496 AVG Training Acc 80.20 % AVG Validation Acc 80.16 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.493 AVG Training Acc 80.48 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.58 % AVG Validation Acc 80.07 %\n",
      "Epoch:60/200 AVG Training Loss:0.479 AVG Validation Loss:0.502 AVG Training Acc 80.74 % AVG Validation Acc 79.71 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.478 AVG Validation Loss:0.502 AVG Training Acc 80.87 % AVG Validation Acc 79.62 %\n",
      "Epoch:80/200 AVG Training Loss:0.477 AVG Validation Loss:0.503 AVG Training Acc 80.89 % AVG Validation Acc 79.71 %\n",
      "Epoch:90/200 AVG Training Loss:0.476 AVG Validation Loss:0.502 AVG Training Acc 80.96 % AVG Validation Acc 79.62 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.478 AVG Validation Loss:0.503 AVG Training Acc 80.86 % AVG Validation Acc 79.71 %\n",
      "Epoch:110/200 AVG Training Loss:0.478 AVG Validation Loss:0.501 AVG Training Acc 80.89 % AVG Validation Acc 79.71 %\n",
      "Epoch:120/200 AVG Training Loss:0.478 AVG Validation Loss:0.503 AVG Training Acc 80.92 % AVG Validation Acc 79.71 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.477 AVG Validation Loss:0.502 AVG Training Acc 80.94 % AVG Validation Acc 79.71 %\n",
      "Epoch:140/200 AVG Training Loss:0.478 AVG Validation Loss:0.501 AVG Training Acc 80.85 % AVG Validation Acc 79.71 %\n",
      "Epoch:150/200 AVG Training Loss:0.478 AVG Validation Loss:0.503 AVG Training Acc 80.78 % AVG Validation Acc 79.71 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.478 AVG Validation Loss:0.503 AVG Training Acc 80.92 % AVG Validation Acc 79.71 %\n",
      "Epoch:170/200 AVG Training Loss:0.478 AVG Validation Loss:0.503 AVG Training Acc 80.83 % AVG Validation Acc 79.71 %\n",
      "Epoch:180/200 AVG Training Loss:0.476 AVG Validation Loss:0.502 AVG Training Acc 80.81 % AVG Validation Acc 79.71 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.478 AVG Validation Loss:0.502 AVG Training Acc 80.91 % AVG Validation Acc 79.71 %\n",
      "Epoch:200/200 AVG Training Loss:0.478 AVG Validation Loss:0.502 AVG Training Acc 80.84 % AVG Validation Acc 79.71 %\n",
      "Split 114\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5796497df7364b83a52e94e390db903b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.491 AVG Training Acc 80.21 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.491 AVG Training Acc 80.23 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.21 % AVG Validation Acc 80.16 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.23 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.22 % AVG Validation Acc 80.16 %\n",
      "Epoch:80/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.23 % AVG Validation Acc 80.16 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.23 % AVG Validation Acc 80.07 %\n",
      "Epoch:100/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.24 % AVG Validation Acc 80.07 %\n",
      "Epoch:110/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.23 % AVG Validation Acc 80.07 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.21 % AVG Validation Acc 80.07 %\n",
      "Epoch:130/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.23 % AVG Validation Acc 80.07 %\n",
      "Epoch:140/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.24 % AVG Validation Acc 80.07 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.22 % AVG Validation Acc 80.07 %\n",
      "Epoch:160/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.22 % AVG Validation Acc 80.07 %\n",
      "Epoch:170/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.23 % AVG Validation Acc 80.07 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.22 % AVG Validation Acc 80.07 %\n",
      "Epoch:190/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.23 % AVG Validation Acc 80.07 %\n",
      "Epoch:200/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.24 % AVG Validation Acc 80.07 %\n",
      "Split 115\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5836765aa0ed44a39a3661ea9778cc13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.25 % AVG Validation Acc 79.89 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.35 % AVG Validation Acc 79.89 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.44 % AVG Validation Acc 79.98 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.44 % AVG Validation Acc 79.98 %\n",
      "Epoch:70/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.48 % AVG Validation Acc 79.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.48 % AVG Validation Acc 79.98 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.57 % AVG Validation Acc 79.98 %\n",
      "Epoch:100/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.50 % AVG Validation Acc 79.98 %\n",
      "Epoch:110/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.47 % AVG Validation Acc 79.98 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.52 % AVG Validation Acc 79.98 %\n",
      "Epoch:130/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.52 % AVG Validation Acc 79.98 %\n",
      "Epoch:140/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.52 % AVG Validation Acc 79.98 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.44 % AVG Validation Acc 79.98 %\n",
      "Epoch:160/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.56 % AVG Validation Acc 79.98 %\n",
      "Epoch:170/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.54 % AVG Validation Acc 79.98 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.46 % AVG Validation Acc 79.98 %\n",
      "Epoch:190/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.45 % AVG Validation Acc 79.98 %\n",
      "Epoch:200/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.46 % AVG Validation Acc 79.98 %\n",
      "Split 116\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1e4f773305e442da974a870677e790b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.10 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.35 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.50 % AVG Validation Acc 79.96 %\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.65 % AVG Validation Acc 79.69 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.482 AVG Validation Loss:0.501 AVG Training Acc 80.63 % AVG Validation Acc 79.78 %\n",
      "Epoch:80/200 AVG Training Loss:0.481 AVG Validation Loss:0.502 AVG Training Acc 80.70 % AVG Validation Acc 79.78 %\n",
      "Epoch:90/200 AVG Training Loss:0.481 AVG Validation Loss:0.504 AVG Training Acc 80.69 % AVG Validation Acc 79.78 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.480 AVG Validation Loss:0.502 AVG Training Acc 80.72 % AVG Validation Acc 79.69 %\n",
      "Epoch:110/200 AVG Training Loss:0.480 AVG Validation Loss:0.502 AVG Training Acc 80.69 % AVG Validation Acc 79.69 %\n",
      "Epoch:120/200 AVG Training Loss:0.481 AVG Validation Loss:0.501 AVG Training Acc 80.72 % AVG Validation Acc 79.78 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.480 AVG Validation Loss:0.502 AVG Training Acc 80.73 % AVG Validation Acc 79.69 %\n",
      "Epoch:140/200 AVG Training Loss:0.480 AVG Validation Loss:0.502 AVG Training Acc 80.73 % AVG Validation Acc 79.69 %\n",
      "Epoch:150/200 AVG Training Loss:0.480 AVG Validation Loss:0.502 AVG Training Acc 80.71 % AVG Validation Acc 79.78 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.480 AVG Validation Loss:0.502 AVG Training Acc 80.67 % AVG Validation Acc 79.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.480 AVG Validation Loss:0.502 AVG Training Acc 80.73 % AVG Validation Acc 79.69 %\n",
      "Epoch:180/200 AVG Training Loss:0.481 AVG Validation Loss:0.502 AVG Training Acc 80.71 % AVG Validation Acc 79.78 %\n",
      "Epoch:190/200 AVG Training Loss:0.480 AVG Validation Loss:0.502 AVG Training Acc 80.73 % AVG Validation Acc 79.78 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.481 AVG Validation Loss:0.502 AVG Training Acc 80.74 % AVG Validation Acc 79.69 %\n",
      "Split 117\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77ef2fd8941c4dfabbf019abab098ee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.24 % AVG Validation Acc 80.23 %\n",
      "Epoch:50/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.29 % AVG Validation Acc 80.23 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.485 AVG Validation Loss:0.494 AVG Training Acc 80.41 % AVG Validation Acc 80.32 %\n",
      "Epoch:70/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.55 % AVG Validation Acc 80.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.483 AVG Validation Loss:0.504 AVG Training Acc 80.58 % AVG Validation Acc 79.87 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.482 AVG Validation Loss:0.504 AVG Training Acc 80.65 % AVG Validation Acc 79.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.481 AVG Validation Loss:0.505 AVG Training Acc 80.66 % AVG Validation Acc 79.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.481 AVG Validation Loss:0.505 AVG Training Acc 80.72 % AVG Validation Acc 79.87 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.480 AVG Validation Loss:0.507 AVG Training Acc 80.75 % AVG Validation Acc 79.87 %\n",
      "Epoch:130/200 AVG Training Loss:0.481 AVG Validation Loss:0.507 AVG Training Acc 80.68 % AVG Validation Acc 79.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.481 AVG Validation Loss:0.506 AVG Training Acc 80.66 % AVG Validation Acc 79.96 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.481 AVG Validation Loss:0.507 AVG Training Acc 80.64 % AVG Validation Acc 79.87 %\n",
      "Epoch:160/200 AVG Training Loss:0.481 AVG Validation Loss:0.507 AVG Training Acc 80.71 % AVG Validation Acc 79.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.480 AVG Validation Loss:0.506 AVG Training Acc 80.86 % AVG Validation Acc 79.96 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.480 AVG Validation Loss:0.506 AVG Training Acc 80.75 % AVG Validation Acc 79.87 %\n",
      "Epoch:190/200 AVG Training Loss:0.482 AVG Validation Loss:0.507 AVG Training Acc 80.67 % AVG Validation Acc 79.87 %\n",
      "Epoch:200/200 AVG Training Loss:0.481 AVG Validation Loss:0.507 AVG Training Acc 80.70 % AVG Validation Acc 79.96 %\n",
      "Split 118\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e20fdc693943038c4a9f56e750ad96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.31 % AVG Validation Acc 80.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.49 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.55 % AVG Validation Acc 80.05 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.500 AVG Training Acc 80.70 % AVG Validation Acc 80.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.483 AVG Validation Loss:0.502 AVG Training Acc 80.67 % AVG Validation Acc 80.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.482 AVG Validation Loss:0.501 AVG Training Acc 80.67 % AVG Validation Acc 80.05 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.482 AVG Validation Loss:0.500 AVG Training Acc 80.70 % AVG Validation Acc 79.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.483 AVG Validation Loss:0.500 AVG Training Acc 80.62 % AVG Validation Acc 79.96 %\n",
      "Epoch:110/200 AVG Training Loss:0.483 AVG Validation Loss:0.501 AVG Training Acc 80.69 % AVG Validation Acc 79.96 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.482 AVG Validation Loss:0.501 AVG Training Acc 80.66 % AVG Validation Acc 79.96 %\n",
      "Epoch:130/200 AVG Training Loss:0.482 AVG Validation Loss:0.502 AVG Training Acc 80.73 % AVG Validation Acc 79.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.482 AVG Validation Loss:0.502 AVG Training Acc 80.69 % AVG Validation Acc 79.96 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.482 AVG Validation Loss:0.501 AVG Training Acc 80.71 % AVG Validation Acc 79.87 %\n",
      "Epoch:160/200 AVG Training Loss:0.482 AVG Validation Loss:0.501 AVG Training Acc 80.72 % AVG Validation Acc 79.96 %\n",
      "Epoch:170/200 AVG Training Loss:0.482 AVG Validation Loss:0.501 AVG Training Acc 80.68 % AVG Validation Acc 79.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.482 AVG Validation Loss:0.501 AVG Training Acc 80.62 % AVG Validation Acc 79.96 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.483 AVG Validation Loss:0.502 AVG Training Acc 80.66 % AVG Validation Acc 79.96 %\n",
      "Epoch:200/200 AVG Training Loss:0.483 AVG Validation Loss:0.501 AVG Training Acc 80.66 % AVG Validation Acc 79.96 %\n",
      "Split 119\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a12e754c4858432b84013b27161b04e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.09 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.46 % AVG Validation Acc 79.96 %\n",
      "Epoch:50/200 AVG Training Loss:0.482 AVG Validation Loss:0.500 AVG Training Acc 80.65 % AVG Validation Acc 79.87 %\n",
      "Epoch:60/200 AVG Training Loss:0.479 AVG Validation Loss:0.503 AVG Training Acc 80.88 % AVG Validation Acc 79.69 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.476 AVG Validation Loss:0.507 AVG Training Acc 81.01 % AVG Validation Acc 79.60 %\n",
      "Epoch:80/200 AVG Training Loss:0.475 AVG Validation Loss:0.508 AVG Training Acc 81.02 % AVG Validation Acc 79.42 %\n",
      "Epoch:90/200 AVG Training Loss:0.476 AVG Validation Loss:0.508 AVG Training Acc 80.98 % AVG Validation Acc 79.60 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.475 AVG Validation Loss:0.509 AVG Training Acc 81.02 % AVG Validation Acc 79.51 %\n",
      "Epoch:110/200 AVG Training Loss:0.473 AVG Validation Loss:0.509 AVG Training Acc 81.12 % AVG Validation Acc 79.42 %\n",
      "Epoch:120/200 AVG Training Loss:0.475 AVG Validation Loss:0.509 AVG Training Acc 81.10 % AVG Validation Acc 79.42 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.473 AVG Validation Loss:0.509 AVG Training Acc 80.99 % AVG Validation Acc 79.42 %\n",
      "Epoch:140/200 AVG Training Loss:0.475 AVG Validation Loss:0.508 AVG Training Acc 81.10 % AVG Validation Acc 79.42 %\n",
      "Epoch:150/200 AVG Training Loss:0.474 AVG Validation Loss:0.508 AVG Training Acc 81.09 % AVG Validation Acc 79.51 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.475 AVG Validation Loss:0.509 AVG Training Acc 81.01 % AVG Validation Acc 79.60 %\n",
      "Epoch:170/200 AVG Training Loss:0.475 AVG Validation Loss:0.508 AVG Training Acc 81.16 % AVG Validation Acc 79.51 %\n",
      "Epoch:180/200 AVG Training Loss:0.474 AVG Validation Loss:0.510 AVG Training Acc 81.04 % AVG Validation Acc 79.51 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.476 AVG Validation Loss:0.508 AVG Training Acc 81.10 % AVG Validation Acc 79.51 %\n",
      "Epoch:200/200 AVG Training Loss:0.475 AVG Validation Loss:0.508 AVG Training Acc 81.10 % AVG Validation Acc 79.51 %\n",
      "Split 120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "117da9847c384af7b29cb2bb1eeb00ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.499 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.22 % AVG Validation Acc 80.23 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.30 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.32 % AVG Validation Acc 80.42 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.32 % AVG Validation Acc 80.23 %\n",
      "Epoch:70/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.40 % AVG Validation Acc 80.23 %\n",
      "Epoch:80/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.36 % AVG Validation Acc 80.14 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.38 % AVG Validation Acc 80.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.40 % AVG Validation Acc 80.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.46 % AVG Validation Acc 80.23 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.47 % AVG Validation Acc 80.23 %\n",
      "Epoch:130/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.41 % AVG Validation Acc 80.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.26 % AVG Validation Acc 80.23 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.39 % AVG Validation Acc 80.23 %\n",
      "Epoch:160/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.37 % AVG Validation Acc 80.23 %\n",
      "Epoch:170/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.42 % AVG Validation Acc 80.23 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.40 % AVG Validation Acc 80.23 %\n",
      "Epoch:190/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.40 % AVG Validation Acc 80.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.41 % AVG Validation Acc 80.23 %\n",
      "Split 121\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9848f66d61c84cd888367720724d0aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.490 AVG Training Acc 80.14 % AVG Validation Acc 80.25 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.490 AVG Training Acc 80.19 % AVG Validation Acc 80.25 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.487 AVG Training Acc 80.32 % AVG Validation Acc 80.25 %\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.487 AVG Training Acc 80.53 % AVG Validation Acc 80.43 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.491 AVG Training Acc 80.70 % AVG Validation Acc 79.98 %\n",
      "Epoch:70/200 AVG Training Loss:0.479 AVG Validation Loss:0.494 AVG Training Acc 80.90 % AVG Validation Acc 79.71 %\n",
      "Epoch:80/200 AVG Training Loss:0.475 AVG Validation Loss:0.498 AVG Training Acc 80.93 % AVG Validation Acc 79.53 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.474 AVG Validation Loss:0.500 AVG Training Acc 81.14 % AVG Validation Acc 79.26 %\n",
      "Epoch:100/200 AVG Training Loss:0.474 AVG Validation Loss:0.501 AVG Training Acc 81.17 % AVG Validation Acc 79.17 %\n",
      "Epoch:110/200 AVG Training Loss:0.473 AVG Validation Loss:0.504 AVG Training Acc 81.14 % AVG Validation Acc 79.08 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.473 AVG Validation Loss:0.503 AVG Training Acc 81.16 % AVG Validation Acc 79.17 %\n",
      "Epoch:130/200 AVG Training Loss:0.473 AVG Validation Loss:0.504 AVG Training Acc 81.24 % AVG Validation Acc 79.17 %\n",
      "Epoch:140/200 AVG Training Loss:0.473 AVG Validation Loss:0.504 AVG Training Acc 81.15 % AVG Validation Acc 79.17 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.473 AVG Validation Loss:0.503 AVG Training Acc 81.13 % AVG Validation Acc 79.17 %\n",
      "Epoch:160/200 AVG Training Loss:0.472 AVG Validation Loss:0.505 AVG Training Acc 81.21 % AVG Validation Acc 79.17 %\n",
      "Epoch:170/200 AVG Training Loss:0.472 AVG Validation Loss:0.504 AVG Training Acc 81.22 % AVG Validation Acc 79.08 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.472 AVG Validation Loss:0.504 AVG Training Acc 81.24 % AVG Validation Acc 79.17 %\n",
      "Epoch:190/200 AVG Training Loss:0.472 AVG Validation Loss:0.504 AVG Training Acc 81.15 % AVG Validation Acc 79.17 %\n",
      "Epoch:200/200 AVG Training Loss:0.472 AVG Validation Loss:0.504 AVG Training Acc 81.18 % AVG Validation Acc 79.08 %\n",
      "Split 122\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1180d7e2d9b2404dae52494e1ceb6110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.23 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.24 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.508 AVG Training Acc 80.49 % AVG Validation Acc 79.71 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.483 AVG Validation Loss:0.508 AVG Training Acc 80.51 % AVG Validation Acc 79.80 %\n",
      "Epoch:80/200 AVG Training Loss:0.481 AVG Validation Loss:0.513 AVG Training Acc 80.60 % AVG Validation Acc 80.07 %\n",
      "Epoch:90/200 AVG Training Loss:0.481 AVG Validation Loss:0.514 AVG Training Acc 80.60 % AVG Validation Acc 80.16 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.482 AVG Validation Loss:0.512 AVG Training Acc 80.47 % AVG Validation Acc 79.98 %\n",
      "Epoch:110/200 AVG Training Loss:0.481 AVG Validation Loss:0.513 AVG Training Acc 80.61 % AVG Validation Acc 79.98 %\n",
      "Epoch:120/200 AVG Training Loss:0.482 AVG Validation Loss:0.512 AVG Training Acc 80.50 % AVG Validation Acc 79.98 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.480 AVG Validation Loss:0.512 AVG Training Acc 80.63 % AVG Validation Acc 79.98 %\n",
      "Epoch:140/200 AVG Training Loss:0.481 AVG Validation Loss:0.514 AVG Training Acc 80.62 % AVG Validation Acc 79.89 %\n",
      "Epoch:150/200 AVG Training Loss:0.481 AVG Validation Loss:0.514 AVG Training Acc 80.61 % AVG Validation Acc 79.89 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.481 AVG Validation Loss:0.513 AVG Training Acc 80.61 % AVG Validation Acc 79.98 %\n",
      "Epoch:170/200 AVG Training Loss:0.480 AVG Validation Loss:0.514 AVG Training Acc 80.56 % AVG Validation Acc 79.98 %\n",
      "Epoch:180/200 AVG Training Loss:0.480 AVG Validation Loss:0.512 AVG Training Acc 80.69 % AVG Validation Acc 79.98 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.482 AVG Validation Loss:0.514 AVG Training Acc 80.60 % AVG Validation Acc 79.98 %\n",
      "Epoch:200/200 AVG Training Loss:0.481 AVG Validation Loss:0.511 AVG Training Acc 80.56 % AVG Validation Acc 79.98 %\n",
      "Split 123\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87938d79dba345039b99bcc1e8f64ffe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.491 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.21 % AVG Validation Acc 80.25 %\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.24 % AVG Validation Acc 80.16 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.487 AVG Validation Loss:0.489 AVG Training Acc 80.29 % AVG Validation Acc 80.34 %\n",
      "Epoch:90/200 AVG Training Loss:0.487 AVG Validation Loss:0.489 AVG Training Acc 80.27 % AVG Validation Acc 80.25 %\n",
      "Epoch:100/200 AVG Training Loss:0.486 AVG Validation Loss:0.489 AVG Training Acc 80.33 % AVG Validation Acc 80.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.487 AVG Validation Loss:0.489 AVG Training Acc 80.31 % AVG Validation Acc 80.25 %\n",
      "Epoch:120/200 AVG Training Loss:0.485 AVG Validation Loss:0.489 AVG Training Acc 80.41 % AVG Validation Acc 80.16 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.485 AVG Validation Loss:0.489 AVG Training Acc 80.35 % AVG Validation Acc 80.07 %\n",
      "Epoch:140/200 AVG Training Loss:0.485 AVG Validation Loss:0.489 AVG Training Acc 80.43 % AVG Validation Acc 80.07 %\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.489 AVG Training Acc 80.40 % AVG Validation Acc 80.07 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.490 AVG Training Acc 80.31 % AVG Validation Acc 80.07 %\n",
      "Epoch:170/200 AVG Training Loss:0.486 AVG Validation Loss:0.489 AVG Training Acc 80.32 % AVG Validation Acc 80.07 %\n",
      "Epoch:180/200 AVG Training Loss:0.486 AVG Validation Loss:0.489 AVG Training Acc 80.37 % AVG Validation Acc 80.07 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.485 AVG Validation Loss:0.489 AVG Training Acc 80.39 % AVG Validation Acc 80.07 %\n",
      "Epoch:200/200 AVG Training Loss:0.485 AVG Validation Loss:0.490 AVG Training Acc 80.29 % AVG Validation Acc 80.07 %\n",
      "Split 124\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec4c027ef3e46f0910be1c855fd499d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.497 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.29 % AVG Validation Acc 79.80 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.501 AVG Training Acc 80.28 % AVG Validation Acc 79.89 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.499 AVG Training Acc 80.37 % AVG Validation Acc 80.07 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.502 AVG Training Acc 80.58 % AVG Validation Acc 79.89 %\n",
      "Epoch:70/200 AVG Training Loss:0.484 AVG Validation Loss:0.505 AVG Training Acc 80.43 % AVG Validation Acc 79.89 %\n",
      "Epoch:80/200 AVG Training Loss:0.482 AVG Validation Loss:0.507 AVG Training Acc 80.60 % AVG Validation Acc 79.80 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.481 AVG Validation Loss:0.507 AVG Training Acc 80.66 % AVG Validation Acc 79.89 %\n",
      "Epoch:100/200 AVG Training Loss:0.482 AVG Validation Loss:0.507 AVG Training Acc 80.55 % AVG Validation Acc 79.89 %\n",
      "Epoch:110/200 AVG Training Loss:0.481 AVG Validation Loss:0.507 AVG Training Acc 80.59 % AVG Validation Acc 79.80 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.482 AVG Validation Loss:0.507 AVG Training Acc 80.53 % AVG Validation Acc 79.80 %\n",
      "Epoch:130/200 AVG Training Loss:0.481 AVG Validation Loss:0.508 AVG Training Acc 80.66 % AVG Validation Acc 79.80 %\n",
      "Epoch:140/200 AVG Training Loss:0.482 AVG Validation Loss:0.507 AVG Training Acc 80.54 % AVG Validation Acc 79.80 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.483 AVG Validation Loss:0.507 AVG Training Acc 80.63 % AVG Validation Acc 79.80 %\n",
      "Epoch:160/200 AVG Training Loss:0.481 AVG Validation Loss:0.508 AVG Training Acc 80.60 % AVG Validation Acc 79.80 %\n",
      "Epoch:170/200 AVG Training Loss:0.481 AVG Validation Loss:0.508 AVG Training Acc 80.55 % AVG Validation Acc 79.80 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.482 AVG Validation Loss:0.508 AVG Training Acc 80.54 % AVG Validation Acc 79.80 %\n",
      "Epoch:190/200 AVG Training Loss:0.482 AVG Validation Loss:0.508 AVG Training Acc 80.69 % AVG Validation Acc 79.80 %\n",
      "Epoch:200/200 AVG Training Loss:0.482 AVG Validation Loss:0.507 AVG Training Acc 80.56 % AVG Validation Acc 79.80 %\n",
      "Split 125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "409db0913d574da1b90db983d86e506c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.499 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.24 % AVG Validation Acc 79.98 %\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.49 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.482 AVG Validation Loss:0.497 AVG Training Acc 80.63 % AVG Validation Acc 79.98 %\n",
      "Epoch:60/200 AVG Training Loss:0.480 AVG Validation Loss:0.495 AVG Training Acc 80.74 % AVG Validation Acc 79.89 %\n",
      "Epoch:70/200 AVG Training Loss:0.480 AVG Validation Loss:0.494 AVG Training Acc 80.72 % AVG Validation Acc 79.89 %\n",
      "Epoch:80/200 AVG Training Loss:0.478 AVG Validation Loss:0.497 AVG Training Acc 80.83 % AVG Validation Acc 79.98 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.477 AVG Validation Loss:0.495 AVG Training Acc 81.05 % AVG Validation Acc 79.53 %\n",
      "Epoch:100/200 AVG Training Loss:0.477 AVG Validation Loss:0.493 AVG Training Acc 80.98 % AVG Validation Acc 79.62 %\n",
      "Epoch:110/200 AVG Training Loss:0.475 AVG Validation Loss:0.495 AVG Training Acc 81.09 % AVG Validation Acc 79.53 %\n",
      "Epoch:120/200 AVG Training Loss:0.474 AVG Validation Loss:0.498 AVG Training Acc 81.09 % AVG Validation Acc 79.44 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.474 AVG Validation Loss:0.495 AVG Training Acc 81.18 % AVG Validation Acc 79.53 %\n",
      "Epoch:140/200 AVG Training Loss:0.474 AVG Validation Loss:0.494 AVG Training Acc 81.10 % AVG Validation Acc 79.53 %\n",
      "Epoch:150/200 AVG Training Loss:0.474 AVG Validation Loss:0.496 AVG Training Acc 81.12 % AVG Validation Acc 79.44 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.475 AVG Validation Loss:0.498 AVG Training Acc 81.22 % AVG Validation Acc 79.44 %\n",
      "Epoch:170/200 AVG Training Loss:0.475 AVG Validation Loss:0.495 AVG Training Acc 81.03 % AVG Validation Acc 79.26 %\n",
      "Epoch:180/200 AVG Training Loss:0.474 AVG Validation Loss:0.494 AVG Training Acc 81.21 % AVG Validation Acc 79.62 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.474 AVG Validation Loss:0.493 AVG Training Acc 81.07 % AVG Validation Acc 79.62 %\n",
      "Epoch:200/200 AVG Training Loss:0.475 AVG Validation Loss:0.496 AVG Training Acc 81.23 % AVG Validation Acc 79.62 %\n",
      "Split 126\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dcc2b75c16f478988e1158f5d2251ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.27 % AVG Validation Acc 79.96 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.492 AVG Training Acc 80.49 % AVG Validation Acc 79.87 %\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.495 AVG Training Acc 80.61 % AVG Validation Acc 79.78 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.482 AVG Validation Loss:0.495 AVG Training Acc 80.63 % AVG Validation Acc 79.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.482 AVG Validation Loss:0.495 AVG Training Acc 80.72 % AVG Validation Acc 79.87 %\n",
      "Epoch:90/200 AVG Training Loss:0.480 AVG Validation Loss:0.495 AVG Training Acc 80.73 % AVG Validation Acc 79.78 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.481 AVG Validation Loss:0.495 AVG Training Acc 80.61 % AVG Validation Acc 79.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.480 AVG Validation Loss:0.495 AVG Training Acc 80.72 % AVG Validation Acc 79.78 %\n",
      "Epoch:120/200 AVG Training Loss:0.481 AVG Validation Loss:0.495 AVG Training Acc 80.73 % AVG Validation Acc 79.78 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.480 AVG Validation Loss:0.495 AVG Training Acc 80.71 % AVG Validation Acc 79.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.481 AVG Validation Loss:0.496 AVG Training Acc 80.70 % AVG Validation Acc 79.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.481 AVG Validation Loss:0.495 AVG Training Acc 80.74 % AVG Validation Acc 79.69 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.480 AVG Validation Loss:0.496 AVG Training Acc 80.68 % AVG Validation Acc 79.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.482 AVG Validation Loss:0.496 AVG Training Acc 80.57 % AVG Validation Acc 79.69 %\n",
      "Epoch:180/200 AVG Training Loss:0.480 AVG Validation Loss:0.495 AVG Training Acc 80.71 % AVG Validation Acc 79.87 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.481 AVG Validation Loss:0.496 AVG Training Acc 80.76 % AVG Validation Acc 79.78 %\n",
      "Epoch:200/200 AVG Training Loss:0.480 AVG Validation Loss:0.495 AVG Training Acc 80.75 % AVG Validation Acc 79.78 %\n",
      "Split 127\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92cfdfd09f44f89b5adc8ac5f6ba4ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.493 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.23 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.490 AVG Training Acc 80.24 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.486 AVG Validation Loss:0.492 AVG Training Acc 80.32 % AVG Validation Acc 79.78 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.485 AVG Validation Loss:0.494 AVG Training Acc 80.42 % AVG Validation Acc 79.69 %\n",
      "Epoch:80/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.45 % AVG Validation Acc 79.69 %\n",
      "Epoch:90/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.53 % AVG Validation Acc 79.69 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.46 % AVG Validation Acc 79.69 %\n",
      "Epoch:110/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.53 % AVG Validation Acc 79.69 %\n",
      "Epoch:120/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.30 % AVG Validation Acc 79.69 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.41 % AVG Validation Acc 79.69 %\n",
      "Epoch:140/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.53 % AVG Validation Acc 79.69 %\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.47 % AVG Validation Acc 79.69 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.35 % AVG Validation Acc 79.69 %\n",
      "Epoch:170/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.35 % AVG Validation Acc 79.69 %\n",
      "Epoch:180/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.48 % AVG Validation Acc 79.69 %\n",
      "Epoch:190/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.45 % AVG Validation Acc 79.69 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.39 % AVG Validation Acc 79.69 %\n",
      "Split 128\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f1250d4e7954a71a672687d69b7ffe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.501 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.490 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.498 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.497 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.23 % AVG Validation Acc 80.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.489 AVG Validation Loss:0.498 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:120/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch:150/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.489 AVG Validation Loss:0.498 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Split 129\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df56f34449994f94a91d33a351ab044f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.31 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.491 AVG Training Acc 80.54 % AVG Validation Acc 80.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.49 % AVG Validation Acc 79.96 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.50 % AVG Validation Acc 79.87 %\n",
      "Epoch:80/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.49 % AVG Validation Acc 79.87 %\n",
      "Epoch:90/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.52 % AVG Validation Acc 79.87 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.51 % AVG Validation Acc 79.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.54 % AVG Validation Acc 79.87 %\n",
      "Epoch:120/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.53 % AVG Validation Acc 79.87 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.54 % AVG Validation Acc 79.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.56 % AVG Validation Acc 79.87 %\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.57 % AVG Validation Acc 79.87 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.58 % AVG Validation Acc 79.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.59 % AVG Validation Acc 79.87 %\n",
      "Epoch:180/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.55 % AVG Validation Acc 79.87 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.58 % AVG Validation Acc 79.87 %\n",
      "Epoch:200/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.55 % AVG Validation Acc 79.87 %\n",
      "Split 130\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e2f93451c9e435a99350b9deecb1c89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.498 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.05 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.499 AVG Training Acc 80.21 % AVG Validation Acc 79.87 %\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.503 AVG Training Acc 80.38 % AVG Validation Acc 79.87 %\n",
      "Epoch:50/200 AVG Training Loss:0.484 AVG Validation Loss:0.506 AVG Training Acc 80.48 % AVG Validation Acc 79.96 %\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.510 AVG Training Acc 80.56 % AVG Validation Acc 79.96 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.481 AVG Validation Loss:0.511 AVG Training Acc 80.60 % AVG Validation Acc 79.87 %\n",
      "Epoch:80/200 AVG Training Loss:0.482 AVG Validation Loss:0.512 AVG Training Acc 80.60 % AVG Validation Acc 79.78 %\n",
      "Epoch:90/200 AVG Training Loss:0.480 AVG Validation Loss:0.514 AVG Training Acc 80.67 % AVG Validation Acc 79.87 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.481 AVG Validation Loss:0.513 AVG Training Acc 80.59 % AVG Validation Acc 79.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.481 AVG Validation Loss:0.513 AVG Training Acc 80.63 % AVG Validation Acc 79.87 %\n",
      "Epoch:120/200 AVG Training Loss:0.480 AVG Validation Loss:0.513 AVG Training Acc 80.70 % AVG Validation Acc 79.78 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.481 AVG Validation Loss:0.514 AVG Training Acc 80.77 % AVG Validation Acc 79.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.480 AVG Validation Loss:0.514 AVG Training Acc 80.66 % AVG Validation Acc 79.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.481 AVG Validation Loss:0.514 AVG Training Acc 80.71 % AVG Validation Acc 79.87 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.480 AVG Validation Loss:0.513 AVG Training Acc 80.72 % AVG Validation Acc 79.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.480 AVG Validation Loss:0.514 AVG Training Acc 80.74 % AVG Validation Acc 79.78 %\n",
      "Epoch:180/200 AVG Training Loss:0.481 AVG Validation Loss:0.514 AVG Training Acc 80.61 % AVG Validation Acc 79.87 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.480 AVG Validation Loss:0.514 AVG Training Acc 80.69 % AVG Validation Acc 79.78 %\n",
      "Epoch:200/200 AVG Training Loss:0.481 AVG Validation Loss:0.514 AVG Training Acc 80.73 % AVG Validation Acc 79.78 %\n",
      "Split 131\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6c612aaf6944b682fcb6affe9b053f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.490 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.496 AVG Training Acc 80.18 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.496 AVG Training Acc 80.22 % AVG Validation Acc 80.25 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.497 AVG Training Acc 80.21 % AVG Validation Acc 80.16 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.25 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.27 % AVG Validation Acc 80.16 %\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.25 % AVG Validation Acc 80.16 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.23 % AVG Validation Acc 80.16 %\n",
      "Epoch:100/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.23 % AVG Validation Acc 80.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.25 % AVG Validation Acc 80.16 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.23 % AVG Validation Acc 80.16 %\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.22 % AVG Validation Acc 80.16 %\n",
      "Epoch:140/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.29 % AVG Validation Acc 80.16 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.24 % AVG Validation Acc 80.16 %\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.25 % AVG Validation Acc 80.16 %\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.20 % AVG Validation Acc 80.16 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.25 % AVG Validation Acc 80.16 %\n",
      "Epoch:190/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.27 % AVG Validation Acc 80.16 %\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.23 % AVG Validation Acc 80.16 %\n",
      "Split 132\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d4421b961be48b8bff05d598103cf92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.499 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.499 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.23 % AVG Validation Acc 80.25 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.29 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.34 % AVG Validation Acc 79.80 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.42 % AVG Validation Acc 79.62 %\n",
      "Epoch:70/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.52 % AVG Validation Acc 79.62 %\n",
      "Epoch:80/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.47 % AVG Validation Acc 79.62 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.482 AVG Validation Loss:0.498 AVG Training Acc 80.54 % AVG Validation Acc 79.53 %\n",
      "Epoch:100/200 AVG Training Loss:0.484 AVG Validation Loss:0.499 AVG Training Acc 80.44 % AVG Validation Acc 79.71 %\n",
      "Epoch:110/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.51 % AVG Validation Acc 79.71 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.483 AVG Validation Loss:0.499 AVG Training Acc 80.53 % AVG Validation Acc 79.62 %\n",
      "Epoch:130/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.54 % AVG Validation Acc 79.62 %\n",
      "Epoch:140/200 AVG Training Loss:0.482 AVG Validation Loss:0.499 AVG Training Acc 80.55 % AVG Validation Acc 79.53 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.482 AVG Validation Loss:0.498 AVG Training Acc 80.52 % AVG Validation Acc 79.53 %\n",
      "Epoch:160/200 AVG Training Loss:0.482 AVG Validation Loss:0.499 AVG Training Acc 80.53 % AVG Validation Acc 79.53 %\n",
      "Epoch:170/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.47 % AVG Validation Acc 79.62 %\n",
      "Epoch:180/200 AVG Training Loss:0.482 AVG Validation Loss:0.499 AVG Training Acc 80.56 % AVG Validation Acc 79.62 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.483 AVG Validation Loss:0.499 AVG Training Acc 80.50 % AVG Validation Acc 79.53 %\n",
      "Epoch:200/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.45 % AVG Validation Acc 79.53 %\n",
      "Split 133\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa9424fc27745668bb1cdf933c89719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.14 % AVG Validation Acc 80.25 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.17 % AVG Validation Acc 80.25 %\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.20 % AVG Validation Acc 80.25 %\n",
      "Epoch:80/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.18 % AVG Validation Acc 80.25 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.16 % AVG Validation Acc 80.25 %\n",
      "Epoch:100/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.20 % AVG Validation Acc 80.25 %\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.19 % AVG Validation Acc 80.25 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.18 % AVG Validation Acc 80.25 %\n",
      "Epoch:130/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.18 % AVG Validation Acc 80.25 %\n",
      "Epoch:140/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.18 % AVG Validation Acc 80.25 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.24 % AVG Validation Acc 80.25 %\n",
      "Epoch:160/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.17 % AVG Validation Acc 80.25 %\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.21 % AVG Validation Acc 80.25 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.18 % AVG Validation Acc 80.25 %\n",
      "Epoch:190/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.18 % AVG Validation Acc 80.25 %\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.20 % AVG Validation Acc 80.25 %\n",
      "Split 134\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28af0007dbf34885a8ddc45fc5d25fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.498 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.498 AVG Training Acc 80.09 % AVG Validation Acc 80.16 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.500 AVG Training Acc 80.22 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.27 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.487 AVG Validation Loss:0.499 AVG Training Acc 80.25 % AVG Validation Acc 80.16 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.487 AVG Validation Loss:0.499 AVG Training Acc 80.35 % AVG Validation Acc 80.16 %\n",
      "Epoch:80/200 AVG Training Loss:0.487 AVG Validation Loss:0.499 AVG Training Acc 80.39 % AVG Validation Acc 80.16 %\n",
      "Epoch:90/200 AVG Training Loss:0.486 AVG Validation Loss:0.500 AVG Training Acc 80.39 % AVG Validation Acc 80.16 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.487 AVG Validation Loss:0.500 AVG Training Acc 80.35 % AVG Validation Acc 80.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.486 AVG Validation Loss:0.500 AVG Training Acc 80.36 % AVG Validation Acc 80.16 %\n",
      "Epoch:120/200 AVG Training Loss:0.486 AVG Validation Loss:0.499 AVG Training Acc 80.33 % AVG Validation Acc 80.16 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.487 AVG Validation Loss:0.499 AVG Training Acc 80.35 % AVG Validation Acc 80.16 %\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.499 AVG Training Acc 80.29 % AVG Validation Acc 80.16 %\n",
      "Epoch:150/200 AVG Training Loss:0.486 AVG Validation Loss:0.499 AVG Training Acc 80.38 % AVG Validation Acc 80.16 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.487 AVG Validation Loss:0.499 AVG Training Acc 80.34 % AVG Validation Acc 80.16 %\n",
      "Epoch:170/200 AVG Training Loss:0.486 AVG Validation Loss:0.499 AVG Training Acc 80.37 % AVG Validation Acc 80.16 %\n",
      "Epoch:180/200 AVG Training Loss:0.487 AVG Validation Loss:0.500 AVG Training Acc 80.34 % AVG Validation Acc 80.16 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.485 AVG Validation Loss:0.499 AVG Training Acc 80.35 % AVG Validation Acc 80.16 %\n",
      "Epoch:200/200 AVG Training Loss:0.486 AVG Validation Loss:0.500 AVG Training Acc 80.38 % AVG Validation Acc 80.16 %\n",
      "Split 135\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9d6e6bda7f418eae7e11bdd7ac851c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.498 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.499 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.492 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.19 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.23 % AVG Validation Acc 79.98 %\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.26 % AVG Validation Acc 79.98 %\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.29 % AVG Validation Acc 79.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.490 AVG Training Acc 80.40 % AVG Validation Acc 80.25 %\n",
      "Epoch:90/200 AVG Training Loss:0.486 AVG Validation Loss:0.491 AVG Training Acc 80.47 % AVG Validation Acc 80.16 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.485 AVG Validation Loss:0.491 AVG Training Acc 80.55 % AVG Validation Acc 80.25 %\n",
      "Epoch:110/200 AVG Training Loss:0.485 AVG Validation Loss:0.491 AVG Training Acc 80.52 % AVG Validation Acc 80.25 %\n",
      "Epoch:120/200 AVG Training Loss:0.484 AVG Validation Loss:0.491 AVG Training Acc 80.50 % AVG Validation Acc 80.25 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.485 AVG Validation Loss:0.491 AVG Training Acc 80.57 % AVG Validation Acc 80.25 %\n",
      "Epoch:140/200 AVG Training Loss:0.484 AVG Validation Loss:0.491 AVG Training Acc 80.54 % AVG Validation Acc 80.34 %\n",
      "Epoch:150/200 AVG Training Loss:0.484 AVG Validation Loss:0.491 AVG Training Acc 80.64 % AVG Validation Acc 80.34 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.484 AVG Validation Loss:0.491 AVG Training Acc 80.60 % AVG Validation Acc 80.34 %\n",
      "Epoch:170/200 AVG Training Loss:0.485 AVG Validation Loss:0.491 AVG Training Acc 80.59 % AVG Validation Acc 80.34 %\n",
      "Epoch:180/200 AVG Training Loss:0.484 AVG Validation Loss:0.491 AVG Training Acc 80.53 % AVG Validation Acc 80.34 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.485 AVG Validation Loss:0.491 AVG Training Acc 80.60 % AVG Validation Acc 80.34 %\n",
      "Epoch:200/200 AVG Training Loss:0.484 AVG Validation Loss:0.491 AVG Training Acc 80.60 % AVG Validation Acc 80.34 %\n",
      "Split 136\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50e8e24285d9499084a53b6441b9d06c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.492 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.494 AVG Validation Loss:0.490 AVG Training Acc 80.20 % AVG Validation Acc 80.05 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.41 % AVG Validation Acc 79.87 %\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.44 % AVG Validation Acc 79.87 %\n",
      "Epoch:60/200 AVG Training Loss:0.485 AVG Validation Loss:0.499 AVG Training Acc 80.57 % AVG Validation Acc 79.87 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.483 AVG Validation Loss:0.504 AVG Training Acc 80.76 % AVG Validation Acc 79.42 %\n",
      "Epoch:80/200 AVG Training Loss:0.482 AVG Validation Loss:0.504 AVG Training Acc 80.71 % AVG Validation Acc 79.42 %\n",
      "Epoch:90/200 AVG Training Loss:0.482 AVG Validation Loss:0.504 AVG Training Acc 80.78 % AVG Validation Acc 79.51 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.483 AVG Validation Loss:0.504 AVG Training Acc 80.68 % AVG Validation Acc 79.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.482 AVG Validation Loss:0.504 AVG Training Acc 80.82 % AVG Validation Acc 79.60 %\n",
      "Epoch:120/200 AVG Training Loss:0.482 AVG Validation Loss:0.504 AVG Training Acc 80.65 % AVG Validation Acc 79.51 %\n",
      "Epoch:130/200 AVG Training Loss:0.482 AVG Validation Loss:0.504 AVG Training Acc 80.76 % AVG Validation Acc 79.60 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.482 AVG Validation Loss:0.505 AVG Training Acc 80.62 % AVG Validation Acc 79.51 %\n",
      "Epoch:150/200 AVG Training Loss:0.483 AVG Validation Loss:0.504 AVG Training Acc 80.77 % AVG Validation Acc 79.60 %\n",
      "Epoch:160/200 AVG Training Loss:0.482 AVG Validation Loss:0.504 AVG Training Acc 80.75 % AVG Validation Acc 79.60 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.482 AVG Validation Loss:0.504 AVG Training Acc 80.76 % AVG Validation Acc 79.51 %\n",
      "Epoch:180/200 AVG Training Loss:0.483 AVG Validation Loss:0.505 AVG Training Acc 80.60 % AVG Validation Acc 79.60 %\n",
      "Epoch:190/200 AVG Training Loss:0.482 AVG Validation Loss:0.504 AVG Training Acc 80.74 % AVG Validation Acc 79.51 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.482 AVG Validation Loss:0.505 AVG Training Acc 80.69 % AVG Validation Acc 79.51 %\n",
      "Split 137\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d18158c8dd84843a9a34dff1bf02a2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.492 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.488 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.488 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.491 AVG Validation Loss:0.487 AVG Training Acc 80.09 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.490 AVG Validation Loss:0.488 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.487 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.489 AVG Validation Loss:0.487 AVG Training Acc 80.14 % AVG Validation Acc 80.05 %\n",
      "Epoch:90/200 AVG Training Loss:0.489 AVG Validation Loss:0.488 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.490 AVG Validation Loss:0.487 AVG Training Acc 80.16 % AVG Validation Acc 80.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.489 AVG Validation Loss:0.488 AVG Training Acc 80.21 % AVG Validation Acc 80.05 %\n",
      "Epoch:120/200 AVG Training Loss:0.489 AVG Validation Loss:0.487 AVG Training Acc 80.13 % AVG Validation Acc 80.05 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.489 AVG Validation Loss:0.488 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.490 AVG Validation Loss:0.487 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch:150/200 AVG Training Loss:0.489 AVG Validation Loss:0.487 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.490 AVG Validation Loss:0.487 AVG Training Acc 80.15 % AVG Validation Acc 80.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.489 AVG Validation Loss:0.487 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.489 AVG Validation Loss:0.487 AVG Training Acc 80.24 % AVG Validation Acc 80.05 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.489 AVG Validation Loss:0.488 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.489 AVG Validation Loss:0.487 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Split 138\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c96b945ac62048f4905b4a6465fd7ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.499 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.499 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.498 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.35 % AVG Validation Acc 79.96 %\n",
      "Epoch:50/200 AVG Training Loss:0.484 AVG Validation Loss:0.499 AVG Training Acc 80.38 % AVG Validation Acc 79.96 %\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.500 AVG Training Acc 80.54 % AVG Validation Acc 79.96 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.482 AVG Validation Loss:0.502 AVG Training Acc 80.71 % AVG Validation Acc 79.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.482 AVG Validation Loss:0.503 AVG Training Acc 80.64 % AVG Validation Acc 79.87 %\n",
      "Epoch:90/200 AVG Training Loss:0.482 AVG Validation Loss:0.503 AVG Training Acc 80.65 % AVG Validation Acc 79.69 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.481 AVG Validation Loss:0.504 AVG Training Acc 80.70 % AVG Validation Acc 79.69 %\n",
      "Epoch:110/200 AVG Training Loss:0.482 AVG Validation Loss:0.504 AVG Training Acc 80.67 % AVG Validation Acc 79.69 %\n",
      "Epoch:120/200 AVG Training Loss:0.481 AVG Validation Loss:0.504 AVG Training Acc 80.70 % AVG Validation Acc 79.69 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.482 AVG Validation Loss:0.504 AVG Training Acc 80.60 % AVG Validation Acc 79.69 %\n",
      "Epoch:140/200 AVG Training Loss:0.482 AVG Validation Loss:0.504 AVG Training Acc 80.70 % AVG Validation Acc 79.69 %\n",
      "Epoch:150/200 AVG Training Loss:0.482 AVG Validation Loss:0.504 AVG Training Acc 80.58 % AVG Validation Acc 79.69 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.482 AVG Validation Loss:0.504 AVG Training Acc 80.54 % AVG Validation Acc 79.69 %\n",
      "Epoch:170/200 AVG Training Loss:0.482 AVG Validation Loss:0.504 AVG Training Acc 80.58 % AVG Validation Acc 79.69 %\n",
      "Epoch:180/200 AVG Training Loss:0.482 AVG Validation Loss:0.504 AVG Training Acc 80.59 % AVG Validation Acc 79.69 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.482 AVG Validation Loss:0.504 AVG Training Acc 80.52 % AVG Validation Acc 79.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.482 AVG Validation Loss:0.504 AVG Training Acc 80.64 % AVG Validation Acc 79.69 %\n",
      "Split 139\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85489069e43a4f78b6d331aa0a6fff7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.492 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.487 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.487 AVG Training Acc 80.22 % AVG Validation Acc 80.32 %\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.488 AVG Training Acc 80.24 % AVG Validation Acc 80.32 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.487 AVG Training Acc 80.30 % AVG Validation Acc 80.23 %\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.487 AVG Training Acc 80.36 % AVG Validation Acc 80.23 %\n",
      "Epoch:80/200 AVG Training Loss:0.489 AVG Validation Loss:0.487 AVG Training Acc 80.28 % AVG Validation Acc 80.23 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.488 AVG Training Acc 80.34 % AVG Validation Acc 80.23 %\n",
      "Epoch:100/200 AVG Training Loss:0.488 AVG Validation Loss:0.487 AVG Training Acc 80.36 % AVG Validation Acc 80.23 %\n",
      "Epoch:110/200 AVG Training Loss:0.489 AVG Validation Loss:0.487 AVG Training Acc 80.30 % AVG Validation Acc 80.23 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.488 AVG Validation Loss:0.487 AVG Training Acc 80.28 % AVG Validation Acc 80.23 %\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.487 AVG Training Acc 80.35 % AVG Validation Acc 80.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.488 AVG Validation Loss:0.487 AVG Training Acc 80.35 % AVG Validation Acc 80.23 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.487 AVG Training Acc 80.29 % AVG Validation Acc 80.23 %\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.488 AVG Training Acc 80.34 % AVG Validation Acc 80.23 %\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.488 AVG Training Acc 80.30 % AVG Validation Acc 80.23 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.487 AVG Training Acc 80.32 % AVG Validation Acc 80.23 %\n",
      "Epoch:190/200 AVG Training Loss:0.488 AVG Validation Loss:0.488 AVG Training Acc 80.35 % AVG Validation Acc 80.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.487 AVG Training Acc 80.33 % AVG Validation Acc 80.23 %\n",
      "Split 140\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7873c533a794077bb03d5429a94f962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.493 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.493 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.15 % AVG Validation Acc 80.32 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.31 % AVG Validation Acc 80.42 %\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.28 % AVG Validation Acc 80.23 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.35 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.39 % AVG Validation Acc 79.78 %\n",
      "Epoch:80/200 AVG Training Loss:0.484 AVG Validation Loss:0.494 AVG Training Acc 80.47 % AVG Validation Acc 79.78 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.37 % AVG Validation Acc 79.60 %\n",
      "Epoch:100/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.45 % AVG Validation Acc 79.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.39 % AVG Validation Acc 79.60 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.38 % AVG Validation Acc 79.69 %\n",
      "Epoch:130/200 AVG Training Loss:0.483 AVG Validation Loss:0.495 AVG Training Acc 80.48 % AVG Validation Acc 79.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.39 % AVG Validation Acc 79.69 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.38 % AVG Validation Acc 79.60 %\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.37 % AVG Validation Acc 79.60 %\n",
      "Epoch:170/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.51 % AVG Validation Acc 79.60 %\n",
      "Epoch:180/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.28 % AVG Validation Acc 79.60 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.42 % AVG Validation Acc 79.60 %\n",
      "Epoch:200/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.32 % AVG Validation Acc 79.69 %\n",
      "Split 141\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20dabe8ece724eed9d30934967bd4e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.499 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.499 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.38 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.483 AVG Validation Loss:0.501 AVG Training Acc 80.51 % AVG Validation Acc 79.80 %\n",
      "Epoch:50/200 AVG Training Loss:0.480 AVG Validation Loss:0.502 AVG Training Acc 80.62 % AVG Validation Acc 80.25 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.478 AVG Validation Loss:0.504 AVG Training Acc 80.70 % AVG Validation Acc 80.07 %\n",
      "Epoch:70/200 AVG Training Loss:0.476 AVG Validation Loss:0.503 AVG Training Acc 80.83 % AVG Validation Acc 79.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.476 AVG Validation Loss:0.504 AVG Training Acc 80.84 % AVG Validation Acc 79.98 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.477 AVG Validation Loss:0.505 AVG Training Acc 80.79 % AVG Validation Acc 79.89 %\n",
      "Epoch:100/200 AVG Training Loss:0.476 AVG Validation Loss:0.506 AVG Training Acc 80.85 % AVG Validation Acc 79.80 %\n",
      "Epoch:110/200 AVG Training Loss:0.477 AVG Validation Loss:0.505 AVG Training Acc 80.69 % AVG Validation Acc 79.89 %\n",
      "Epoch:120/200 AVG Training Loss:0.476 AVG Validation Loss:0.505 AVG Training Acc 80.69 % AVG Validation Acc 79.89 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.476 AVG Validation Loss:0.506 AVG Training Acc 80.77 % AVG Validation Acc 79.89 %\n",
      "Epoch:140/200 AVG Training Loss:0.477 AVG Validation Loss:0.505 AVG Training Acc 80.81 % AVG Validation Acc 79.80 %\n",
      "Epoch:150/200 AVG Training Loss:0.476 AVG Validation Loss:0.507 AVG Training Acc 80.81 % AVG Validation Acc 79.71 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.475 AVG Validation Loss:0.506 AVG Training Acc 80.88 % AVG Validation Acc 79.80 %\n",
      "Epoch:170/200 AVG Training Loss:0.476 AVG Validation Loss:0.506 AVG Training Acc 80.73 % AVG Validation Acc 79.80 %\n",
      "Epoch:180/200 AVG Training Loss:0.476 AVG Validation Loss:0.505 AVG Training Acc 80.76 % AVG Validation Acc 79.80 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.477 AVG Validation Loss:0.506 AVG Training Acc 80.72 % AVG Validation Acc 79.80 %\n",
      "Epoch:200/200 AVG Training Loss:0.475 AVG Validation Loss:0.506 AVG Training Acc 80.75 % AVG Validation Acc 79.80 %\n",
      "Split 142\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3468e78306432db67e3518daadad47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.21 % AVG Validation Acc 80.07 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.40 % AVG Validation Acc 79.71 %\n",
      "Epoch:50/200 AVG Training Loss:0.483 AVG Validation Loss:0.499 AVG Training Acc 80.56 % AVG Validation Acc 79.80 %\n",
      "Epoch:60/200 AVG Training Loss:0.480 AVG Validation Loss:0.502 AVG Training Acc 80.80 % AVG Validation Acc 79.53 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.478 AVG Validation Loss:0.501 AVG Training Acc 80.92 % AVG Validation Acc 79.71 %\n",
      "Epoch:80/200 AVG Training Loss:0.477 AVG Validation Loss:0.502 AVG Training Acc 81.01 % AVG Validation Acc 79.44 %\n",
      "Epoch:90/200 AVG Training Loss:0.477 AVG Validation Loss:0.504 AVG Training Acc 81.14 % AVG Validation Acc 79.35 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.478 AVG Validation Loss:0.503 AVG Training Acc 80.93 % AVG Validation Acc 79.44 %\n",
      "Epoch:110/200 AVG Training Loss:0.477 AVG Validation Loss:0.504 AVG Training Acc 81.02 % AVG Validation Acc 79.44 %\n",
      "Epoch:120/200 AVG Training Loss:0.477 AVG Validation Loss:0.504 AVG Training Acc 81.04 % AVG Validation Acc 79.44 %\n",
      "Epoch:130/200 AVG Training Loss:0.476 AVG Validation Loss:0.504 AVG Training Acc 81.07 % AVG Validation Acc 79.44 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.476 AVG Validation Loss:0.504 AVG Training Acc 80.96 % AVG Validation Acc 79.44 %\n",
      "Epoch:150/200 AVG Training Loss:0.477 AVG Validation Loss:0.504 AVG Training Acc 81.00 % AVG Validation Acc 79.44 %\n",
      "Epoch:160/200 AVG Training Loss:0.476 AVG Validation Loss:0.504 AVG Training Acc 81.03 % AVG Validation Acc 79.44 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.477 AVG Validation Loss:0.504 AVG Training Acc 80.97 % AVG Validation Acc 79.44 %\n",
      "Epoch:180/200 AVG Training Loss:0.476 AVG Validation Loss:0.504 AVG Training Acc 81.11 % AVG Validation Acc 79.53 %\n",
      "Epoch:190/200 AVG Training Loss:0.476 AVG Validation Loss:0.504 AVG Training Acc 81.03 % AVG Validation Acc 79.53 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.475 AVG Validation Loss:0.504 AVG Training Acc 81.14 % AVG Validation Acc 79.44 %\n",
      "Split 143\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8413cd75f007401b86b1019449d5a5ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.493 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.492 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.489 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.489 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.488 AVG Training Acc 80.16 % AVG Validation Acc 80.25 %\n",
      "Epoch:60/200 AVG Training Loss:0.487 AVG Validation Loss:0.489 AVG Training Acc 80.21 % AVG Validation Acc 80.16 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.487 AVG Validation Loss:0.489 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:80/200 AVG Training Loss:0.487 AVG Validation Loss:0.489 AVG Training Acc 80.23 % AVG Validation Acc 80.16 %\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.490 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.486 AVG Validation Loss:0.489 AVG Training Acc 80.25 % AVG Validation Acc 80.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.26 % AVG Validation Acc 80.16 %\n",
      "Epoch:120/200 AVG Training Loss:0.488 AVG Validation Loss:0.490 AVG Training Acc 80.29 % AVG Validation Acc 80.16 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.30 % AVG Validation Acc 80.16 %\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.32 % AVG Validation Acc 80.16 %\n",
      "Epoch:150/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.27 % AVG Validation Acc 80.16 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.22 % AVG Validation Acc 80.16 %\n",
      "Epoch:170/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.31 % AVG Validation Acc 80.16 %\n",
      "Epoch:180/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.31 % AVG Validation Acc 80.16 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.21 % AVG Validation Acc 80.16 %\n",
      "Epoch:200/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.31 % AVG Validation Acc 80.16 %\n",
      "Split 144\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "019123609b7a4da692703170f051ff58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.498 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.492 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.492 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.23 % AVG Validation Acc 80.16 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.481 AVG Validation Loss:0.502 AVG Training Acc 80.47 % AVG Validation Acc 80.25 %\n",
      "Epoch:60/200 AVG Training Loss:0.478 AVG Validation Loss:0.517 AVG Training Acc 80.86 % AVG Validation Acc 79.89 %\n",
      "Epoch:70/200 AVG Training Loss:0.474 AVG Validation Loss:0.521 AVG Training Acc 81.02 % AVG Validation Acc 79.89 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.470 AVG Validation Loss:0.532 AVG Training Acc 81.19 % AVG Validation Acc 79.71 %\n",
      "Epoch:90/200 AVG Training Loss:0.470 AVG Validation Loss:0.531 AVG Training Acc 81.20 % AVG Validation Acc 79.80 %\n",
      "Epoch:100/200 AVG Training Loss:0.470 AVG Validation Loss:0.534 AVG Training Acc 81.26 % AVG Validation Acc 79.62 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.470 AVG Validation Loss:0.533 AVG Training Acc 81.32 % AVG Validation Acc 79.44 %\n",
      "Epoch:120/200 AVG Training Loss:0.469 AVG Validation Loss:0.532 AVG Training Acc 81.30 % AVG Validation Acc 79.53 %\n",
      "Epoch:130/200 AVG Training Loss:0.470 AVG Validation Loss:0.532 AVG Training Acc 81.22 % AVG Validation Acc 79.80 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.469 AVG Validation Loss:0.533 AVG Training Acc 81.26 % AVG Validation Acc 79.53 %\n",
      "Epoch:150/200 AVG Training Loss:0.470 AVG Validation Loss:0.533 AVG Training Acc 81.11 % AVG Validation Acc 79.62 %\n",
      "Epoch:160/200 AVG Training Loss:0.470 AVG Validation Loss:0.533 AVG Training Acc 81.27 % AVG Validation Acc 79.71 %\n",
      "Epoch:170/200 AVG Training Loss:0.469 AVG Validation Loss:0.531 AVG Training Acc 81.32 % AVG Validation Acc 79.44 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.468 AVG Validation Loss:0.533 AVG Training Acc 81.36 % AVG Validation Acc 79.62 %\n",
      "Epoch:190/200 AVG Training Loss:0.469 AVG Validation Loss:0.534 AVG Training Acc 81.31 % AVG Validation Acc 79.71 %\n",
      "Epoch:200/200 AVG Training Loss:0.469 AVG Validation Loss:0.531 AVG Training Acc 81.14 % AVG Validation Acc 79.53 %\n",
      "Split 145\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b80fcb3b6feb4fcc8cfcf80cfe4101e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.501 AVG Training Acc 80.13 % AVG Validation Acc 80.07 %\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.499 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.499 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.499 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.498 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.499 AVG Training Acc 80.21 % AVG Validation Acc 80.16 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.489 AVG Validation Loss:0.498 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:90/200 AVG Training Loss:0.489 AVG Validation Loss:0.499 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch:100/200 AVG Training Loss:0.489 AVG Validation Loss:0.498 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.489 AVG Validation Loss:0.498 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:120/200 AVG Training Loss:0.489 AVG Validation Loss:0.498 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:130/200 AVG Training Loss:0.489 AVG Validation Loss:0.498 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.489 AVG Validation Loss:0.499 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch:150/200 AVG Training Loss:0.489 AVG Validation Loss:0.498 AVG Training Acc 80.22 % AVG Validation Acc 80.16 %\n",
      "Epoch:160/200 AVG Training Loss:0.489 AVG Validation Loss:0.499 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.489 AVG Validation Loss:0.498 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:180/200 AVG Training Loss:0.489 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:190/200 AVG Training Loss:0.489 AVG Validation Loss:0.498 AVG Training Acc 80.22 % AVG Validation Acc 80.16 %\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.20 % AVG Validation Acc 80.16 %\n",
      "Split 146\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f5559bda2aa406e938ed406933a0d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.501 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.41 % AVG Validation Acc 80.42 %\n",
      "Epoch:80/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.40 % AVG Validation Acc 80.42 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.484 AVG Validation Loss:0.494 AVG Training Acc 80.47 % AVG Validation Acc 80.51 %\n",
      "Epoch:100/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.45 % AVG Validation Acc 80.32 %\n",
      "Epoch:110/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.55 % AVG Validation Acc 80.42 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.483 AVG Validation Loss:0.495 AVG Training Acc 80.54 % AVG Validation Acc 80.42 %\n",
      "Epoch:130/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.58 % AVG Validation Acc 80.42 %\n",
      "Epoch:140/200 AVG Training Loss:0.484 AVG Validation Loss:0.494 AVG Training Acc 80.47 % AVG Validation Acc 80.42 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.483 AVG Validation Loss:0.495 AVG Training Acc 80.51 % AVG Validation Acc 80.42 %\n",
      "Epoch:160/200 AVG Training Loss:0.483 AVG Validation Loss:0.496 AVG Training Acc 80.61 % AVG Validation Acc 80.42 %\n",
      "Epoch:170/200 AVG Training Loss:0.484 AVG Validation Loss:0.494 AVG Training Acc 80.55 % AVG Validation Acc 80.42 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.483 AVG Validation Loss:0.496 AVG Training Acc 80.55 % AVG Validation Acc 80.42 %\n",
      "Epoch:190/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.47 % AVG Validation Acc 80.42 %\n",
      "Epoch:200/200 AVG Training Loss:0.483 AVG Validation Loss:0.494 AVG Training Acc 80.52 % AVG Validation Acc 80.42 %\n",
      "Split 147\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4016df4b875d447090849bed1442bc4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.499 AVG Training Acc 80.10 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.34 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.495 AVG Validation Loss:0.500 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.491 AVG Validation Loss:0.493 AVG Training Acc 80.17 % AVG Validation Acc 80.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.48 % AVG Validation Acc 80.23 %\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:80/200 AVG Training Loss:0.479 AVG Validation Loss:0.496 AVG Training Acc 80.88 % AVG Validation Acc 79.87 %\n",
      "Epoch:90/200 AVG Training Loss:0.475 AVG Validation Loss:0.499 AVG Training Acc 81.04 % AVG Validation Acc 79.87 %\n",
      "Epoch:100/200 AVG Training Loss:0.471 AVG Validation Loss:0.506 AVG Training Acc 81.31 % AVG Validation Acc 79.69 %\n",
      "Epoch   104: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:110/200 AVG Training Loss:0.469 AVG Validation Loss:0.507 AVG Training Acc 81.36 % AVG Validation Acc 79.69 %\n",
      "Epoch:120/200 AVG Training Loss:0.467 AVG Validation Loss:0.507 AVG Training Acc 81.45 % AVG Validation Acc 79.60 %\n",
      "Epoch:130/200 AVG Training Loss:0.467 AVG Validation Loss:0.508 AVG Training Acc 81.40 % AVG Validation Acc 79.69 %\n",
      "Epoch   135: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:140/200 AVG Training Loss:0.467 AVG Validation Loss:0.510 AVG Training Acc 81.39 % AVG Validation Acc 79.69 %\n",
      "Epoch:150/200 AVG Training Loss:0.468 AVG Validation Loss:0.508 AVG Training Acc 81.36 % AVG Validation Acc 79.69 %\n",
      "Epoch:160/200 AVG Training Loss:0.468 AVG Validation Loss:0.510 AVG Training Acc 81.51 % AVG Validation Acc 79.51 %\n",
      "Epoch   166: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:170/200 AVG Training Loss:0.467 AVG Validation Loss:0.510 AVG Training Acc 81.46 % AVG Validation Acc 79.60 %\n",
      "Epoch:180/200 AVG Training Loss:0.467 AVG Validation Loss:0.509 AVG Training Acc 81.48 % AVG Validation Acc 79.69 %\n",
      "Epoch:190/200 AVG Training Loss:0.466 AVG Validation Loss:0.509 AVG Training Acc 81.45 % AVG Validation Acc 79.60 %\n",
      "Epoch   197: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:200/200 AVG Training Loss:0.467 AVG Validation Loss:0.510 AVG Training Acc 81.41 % AVG Validation Acc 79.51 %\n",
      "Split 148\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01433b50b7da444497aec44f5296562b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.09 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:120/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.488 AVG Validation Loss:0.490 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:150/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.09 % AVG Validation Acc 80.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Split 149\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43caa6a5a3d84b1190664364dfc05d3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.493 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.502 AVG Training Acc 80.23 % AVG Validation Acc 80.05 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.485 AVG Validation Loss:0.505 AVG Training Acc 80.51 % AVG Validation Acc 79.87 %\n",
      "Epoch:50/200 AVG Training Loss:0.482 AVG Validation Loss:0.514 AVG Training Acc 80.65 % AVG Validation Acc 79.60 %\n",
      "Epoch:60/200 AVG Training Loss:0.480 AVG Validation Loss:0.520 AVG Training Acc 80.85 % AVG Validation Acc 79.42 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.499 AVG Validation Loss:0.535 AVG Training Acc 80.39 % AVG Validation Acc 79.24 %\n",
      "Epoch:80/200 AVG Training Loss:0.493 AVG Validation Loss:0.523 AVG Training Acc 80.49 % AVG Validation Acc 79.78 %\n",
      "Epoch:90/200 AVG Training Loss:0.487 AVG Validation Loss:0.516 AVG Training Acc 80.78 % AVG Validation Acc 79.78 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.487 AVG Validation Loss:0.523 AVG Training Acc 80.79 % AVG Validation Acc 79.42 %\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.523 AVG Training Acc 80.64 % AVG Validation Acc 79.51 %\n",
      "Epoch:120/200 AVG Training Loss:0.487 AVG Validation Loss:0.520 AVG Training Acc 80.61 % AVG Validation Acc 79.51 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.526 AVG Training Acc 80.70 % AVG Validation Acc 79.51 %\n",
      "Epoch:140/200 AVG Training Loss:0.488 AVG Validation Loss:0.519 AVG Training Acc 80.76 % AVG Validation Acc 79.69 %\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.524 AVG Training Acc 80.72 % AVG Validation Acc 79.51 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.487 AVG Validation Loss:0.516 AVG Training Acc 80.59 % AVG Validation Acc 79.69 %\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.517 AVG Training Acc 80.68 % AVG Validation Acc 79.60 %\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.520 AVG Training Acc 80.69 % AVG Validation Acc 79.69 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.489 AVG Validation Loss:0.522 AVG Training Acc 80.65 % AVG Validation Acc 79.51 %\n",
      "Epoch:200/200 AVG Training Loss:0.487 AVG Validation Loss:0.517 AVG Training Acc 80.57 % AVG Validation Acc 79.78 %\n",
      "Split 150\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "868ab806c44f4787a975ee10c6cc12c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.10 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.25 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.27 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.486 AVG Validation Loss:0.492 AVG Training Acc 80.41 % AVG Validation Acc 80.14 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.485 AVG Validation Loss:0.493 AVG Training Acc 80.49 % AVG Validation Acc 80.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.485 AVG Validation Loss:0.493 AVG Training Acc 80.44 % AVG Validation Acc 80.05 %\n",
      "Epoch:90/200 AVG Training Loss:0.485 AVG Validation Loss:0.492 AVG Training Acc 80.50 % AVG Validation Acc 79.96 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.484 AVG Validation Loss:0.492 AVG Training Acc 80.48 % AVG Validation Acc 80.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.484 AVG Validation Loss:0.492 AVG Training Acc 80.47 % AVG Validation Acc 79.96 %\n",
      "Epoch:120/200 AVG Training Loss:0.484 AVG Validation Loss:0.492 AVG Training Acc 80.53 % AVG Validation Acc 79.96 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.485 AVG Validation Loss:0.492 AVG Training Acc 80.46 % AVG Validation Acc 79.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.484 AVG Validation Loss:0.492 AVG Training Acc 80.47 % AVG Validation Acc 79.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.484 AVG Validation Loss:0.493 AVG Training Acc 80.42 % AVG Validation Acc 79.87 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.493 AVG Training Acc 80.41 % AVG Validation Acc 79.96 %\n",
      "Epoch:170/200 AVG Training Loss:0.485 AVG Validation Loss:0.492 AVG Training Acc 80.42 % AVG Validation Acc 79.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.485 AVG Validation Loss:0.492 AVG Training Acc 80.53 % AVG Validation Acc 79.96 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.484 AVG Validation Loss:0.492 AVG Training Acc 80.48 % AVG Validation Acc 80.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.484 AVG Validation Loss:0.492 AVG Training Acc 80.51 % AVG Validation Acc 79.96 %\n",
      "Split 151\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9879752c4b534b9ab8d895699d068451",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.497 AVG Training Acc 80.21 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.496 AVG Training Acc 80.27 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.500 AVG Training Acc 80.60 % AVG Validation Acc 80.07 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.478 AVG Validation Loss:0.497 AVG Training Acc 80.72 % AVG Validation Acc 80.07 %\n",
      "Epoch:70/200 AVG Training Loss:0.473 AVG Validation Loss:0.501 AVG Training Acc 80.91 % AVG Validation Acc 80.07 %\n",
      "Epoch:80/200 AVG Training Loss:0.471 AVG Validation Loss:0.512 AVG Training Acc 81.08 % AVG Validation Acc 79.62 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.467 AVG Validation Loss:0.517 AVG Training Acc 81.29 % AVG Validation Acc 78.72 %\n",
      "Epoch:100/200 AVG Training Loss:0.467 AVG Validation Loss:0.523 AVG Training Acc 81.33 % AVG Validation Acc 78.99 %\n",
      "Epoch:110/200 AVG Training Loss:0.466 AVG Validation Loss:0.524 AVG Training Acc 81.33 % AVG Validation Acc 79.08 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.467 AVG Validation Loss:0.527 AVG Training Acc 81.34 % AVG Validation Acc 78.81 %\n",
      "Epoch:130/200 AVG Training Loss:0.466 AVG Validation Loss:0.525 AVG Training Acc 81.36 % AVG Validation Acc 78.90 %\n",
      "Epoch:140/200 AVG Training Loss:0.467 AVG Validation Loss:0.525 AVG Training Acc 81.13 % AVG Validation Acc 78.99 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.468 AVG Validation Loss:0.519 AVG Training Acc 81.32 % AVG Validation Acc 78.99 %\n",
      "Epoch:160/200 AVG Training Loss:0.467 AVG Validation Loss:0.532 AVG Training Acc 81.20 % AVG Validation Acc 78.90 %\n",
      "Epoch:170/200 AVG Training Loss:0.466 AVG Validation Loss:0.526 AVG Training Acc 81.07 % AVG Validation Acc 78.81 %\n",
      "Epoch:180/200 AVG Training Loss:0.465 AVG Validation Loss:0.526 AVG Training Acc 81.27 % AVG Validation Acc 78.90 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.466 AVG Validation Loss:0.513 AVG Training Acc 81.11 % AVG Validation Acc 79.17 %\n",
      "Epoch:200/200 AVG Training Loss:0.467 AVG Validation Loss:0.516 AVG Training Acc 81.28 % AVG Validation Acc 78.99 %\n",
      "Split 152\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b60a401122c4ebc99afcaab0779f057",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.24 % AVG Validation Acc 79.80 %\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.502 AVG Training Acc 80.40 % AVG Validation Acc 79.44 %\n",
      "Epoch:50/200 AVG Training Loss:0.484 AVG Validation Loss:0.506 AVG Training Acc 80.56 % AVG Validation Acc 79.44 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.484 AVG Validation Loss:0.509 AVG Training Acc 80.64 % AVG Validation Acc 79.35 %\n",
      "Epoch:70/200 AVG Training Loss:0.483 AVG Validation Loss:0.509 AVG Training Acc 80.53 % AVG Validation Acc 79.35 %\n",
      "Epoch:80/200 AVG Training Loss:0.483 AVG Validation Loss:0.510 AVG Training Acc 80.62 % AVG Validation Acc 79.35 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.483 AVG Validation Loss:0.510 AVG Training Acc 80.51 % AVG Validation Acc 79.44 %\n",
      "Epoch:100/200 AVG Training Loss:0.482 AVG Validation Loss:0.511 AVG Training Acc 80.65 % AVG Validation Acc 79.44 %\n",
      "Epoch:110/200 AVG Training Loss:0.482 AVG Validation Loss:0.511 AVG Training Acc 80.65 % AVG Validation Acc 79.35 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.482 AVG Validation Loss:0.511 AVG Training Acc 80.66 % AVG Validation Acc 79.35 %\n",
      "Epoch:130/200 AVG Training Loss:0.481 AVG Validation Loss:0.511 AVG Training Acc 80.61 % AVG Validation Acc 79.35 %\n",
      "Epoch:140/200 AVG Training Loss:0.482 AVG Validation Loss:0.512 AVG Training Acc 80.64 % AVG Validation Acc 79.26 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.481 AVG Validation Loss:0.511 AVG Training Acc 80.69 % AVG Validation Acc 79.44 %\n",
      "Epoch:160/200 AVG Training Loss:0.483 AVG Validation Loss:0.512 AVG Training Acc 80.55 % AVG Validation Acc 79.35 %\n",
      "Epoch:170/200 AVG Training Loss:0.482 AVG Validation Loss:0.511 AVG Training Acc 80.58 % AVG Validation Acc 79.35 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.482 AVG Validation Loss:0.511 AVG Training Acc 80.62 % AVG Validation Acc 79.35 %\n",
      "Epoch:190/200 AVG Training Loss:0.481 AVG Validation Loss:0.510 AVG Training Acc 80.73 % AVG Validation Acc 79.35 %\n",
      "Epoch:200/200 AVG Training Loss:0.482 AVG Validation Loss:0.511 AVG Training Acc 80.67 % AVG Validation Acc 79.26 %\n",
      "Split 153\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c84cb898f44d6b9bf3bf837e15cb70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.498 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.492 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.493 AVG Validation Loss:0.492 AVG Training Acc 80.08 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.492 AVG Validation Loss:0.489 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.24 % AVG Validation Acc 80.25 %\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.491 AVG Training Acc 80.44 % AVG Validation Acc 80.34 %\n",
      "Epoch:70/200 AVG Training Loss:0.480 AVG Validation Loss:0.493 AVG Training Acc 80.65 % AVG Validation Acc 80.16 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.479 AVG Validation Loss:0.494 AVG Training Acc 80.70 % AVG Validation Acc 80.25 %\n",
      "Epoch:90/200 AVG Training Loss:0.477 AVG Validation Loss:0.495 AVG Training Acc 80.79 % AVG Validation Acc 80.07 %\n",
      "Epoch:100/200 AVG Training Loss:0.476 AVG Validation Loss:0.495 AVG Training Acc 80.82 % AVG Validation Acc 80.16 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.475 AVG Validation Loss:0.496 AVG Training Acc 80.81 % AVG Validation Acc 80.16 %\n",
      "Epoch:120/200 AVG Training Loss:0.477 AVG Validation Loss:0.496 AVG Training Acc 80.81 % AVG Validation Acc 80.16 %\n",
      "Epoch:130/200 AVG Training Loss:0.475 AVG Validation Loss:0.497 AVG Training Acc 81.00 % AVG Validation Acc 80.07 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.476 AVG Validation Loss:0.496 AVG Training Acc 80.85 % AVG Validation Acc 80.16 %\n",
      "Epoch:150/200 AVG Training Loss:0.477 AVG Validation Loss:0.497 AVG Training Acc 80.89 % AVG Validation Acc 80.16 %\n",
      "Epoch:160/200 AVG Training Loss:0.477 AVG Validation Loss:0.497 AVG Training Acc 80.86 % AVG Validation Acc 80.16 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.477 AVG Validation Loss:0.496 AVG Training Acc 80.80 % AVG Validation Acc 80.16 %\n",
      "Epoch:180/200 AVG Training Loss:0.475 AVG Validation Loss:0.495 AVG Training Acc 80.94 % AVG Validation Acc 80.16 %\n",
      "Epoch:190/200 AVG Training Loss:0.475 AVG Validation Loss:0.497 AVG Training Acc 80.82 % AVG Validation Acc 80.16 %\n",
      "Epoch:200/200 AVG Training Loss:0.476 AVG Validation Loss:0.497 AVG Training Acc 80.85 % AVG Validation Acc 80.16 %\n",
      "Epoch   200: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Split 154\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f92732db923c4ad19aac902f34623676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.10 % AVG Validation Acc 80.16 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.30 % AVG Validation Acc 79.89 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.500 AVG Training Acc 80.25 % AVG Validation Acc 79.98 %\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.500 AVG Training Acc 80.31 % AVG Validation Acc 79.89 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.485 AVG Validation Loss:0.502 AVG Training Acc 80.41 % AVG Validation Acc 79.80 %\n",
      "Epoch:70/200 AVG Training Loss:0.484 AVG Validation Loss:0.501 AVG Training Acc 80.48 % AVG Validation Acc 79.89 %\n",
      "Epoch:80/200 AVG Training Loss:0.484 AVG Validation Loss:0.502 AVG Training Acc 80.49 % AVG Validation Acc 79.80 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.484 AVG Validation Loss:0.502 AVG Training Acc 80.52 % AVG Validation Acc 79.80 %\n",
      "Epoch:100/200 AVG Training Loss:0.483 AVG Validation Loss:0.500 AVG Training Acc 80.44 % AVG Validation Acc 79.89 %\n",
      "Epoch:110/200 AVG Training Loss:0.483 AVG Validation Loss:0.501 AVG Training Acc 80.49 % AVG Validation Acc 79.80 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.483 AVG Validation Loss:0.502 AVG Training Acc 80.53 % AVG Validation Acc 79.80 %\n",
      "Epoch:130/200 AVG Training Loss:0.484 AVG Validation Loss:0.500 AVG Training Acc 80.59 % AVG Validation Acc 79.98 %\n",
      "Epoch:140/200 AVG Training Loss:0.484 AVG Validation Loss:0.502 AVG Training Acc 80.51 % AVG Validation Acc 79.89 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.483 AVG Validation Loss:0.501 AVG Training Acc 80.49 % AVG Validation Acc 79.89 %\n",
      "Epoch:160/200 AVG Training Loss:0.483 AVG Validation Loss:0.501 AVG Training Acc 80.54 % AVG Validation Acc 79.89 %\n",
      "Epoch:170/200 AVG Training Loss:0.484 AVG Validation Loss:0.502 AVG Training Acc 80.52 % AVG Validation Acc 79.80 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.483 AVG Validation Loss:0.502 AVG Training Acc 80.45 % AVG Validation Acc 79.80 %\n",
      "Epoch:190/200 AVG Training Loss:0.484 AVG Validation Loss:0.500 AVG Training Acc 80.53 % AVG Validation Acc 79.89 %\n",
      "Epoch:200/200 AVG Training Loss:0.484 AVG Validation Loss:0.500 AVG Training Acc 80.56 % AVG Validation Acc 79.89 %\n",
      "Split 155\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f297093b86b3417b88696a81552ddfea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.16 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.22 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.499 AVG Training Acc 80.24 % AVG Validation Acc 79.98 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.510 AVG Training Acc 80.49 % AVG Validation Acc 79.80 %\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.508 AVG Training Acc 80.55 % AVG Validation Acc 79.71 %\n",
      "Epoch:70/200 AVG Training Loss:0.482 AVG Validation Loss:0.517 AVG Training Acc 80.76 % AVG Validation Acc 79.71 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.481 AVG Validation Loss:0.518 AVG Training Acc 80.71 % AVG Validation Acc 79.71 %\n",
      "Epoch:90/200 AVG Training Loss:0.480 AVG Validation Loss:0.521 AVG Training Acc 80.77 % AVG Validation Acc 79.71 %\n",
      "Epoch:100/200 AVG Training Loss:0.480 AVG Validation Loss:0.527 AVG Training Acc 80.76 % AVG Validation Acc 79.71 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.480 AVG Validation Loss:0.530 AVG Training Acc 80.79 % AVG Validation Acc 79.80 %\n",
      "Epoch:120/200 AVG Training Loss:0.480 AVG Validation Loss:0.528 AVG Training Acc 80.78 % AVG Validation Acc 79.80 %\n",
      "Epoch:130/200 AVG Training Loss:0.480 AVG Validation Loss:0.524 AVG Training Acc 80.74 % AVG Validation Acc 79.80 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.480 AVG Validation Loss:0.528 AVG Training Acc 80.79 % AVG Validation Acc 79.80 %\n",
      "Epoch:150/200 AVG Training Loss:0.480 AVG Validation Loss:0.532 AVG Training Acc 80.83 % AVG Validation Acc 79.80 %\n",
      "Epoch:160/200 AVG Training Loss:0.479 AVG Validation Loss:0.531 AVG Training Acc 80.86 % AVG Validation Acc 79.71 %\n",
      "Epoch:170/200 AVG Training Loss:0.480 AVG Validation Loss:0.529 AVG Training Acc 80.74 % AVG Validation Acc 79.80 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.479 AVG Validation Loss:0.529 AVG Training Acc 80.78 % AVG Validation Acc 79.71 %\n",
      "Epoch:190/200 AVG Training Loss:0.479 AVG Validation Loss:0.528 AVG Training Acc 80.83 % AVG Validation Acc 79.80 %\n",
      "Epoch:200/200 AVG Training Loss:0.480 AVG Validation Loss:0.528 AVG Training Acc 80.71 % AVG Validation Acc 79.80 %\n",
      "Split 156\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1a1eab793af423c9971926029dffe0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.500 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.500 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.498 AVG Training Acc 80.09 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.06 % AVG Validation Acc 80.23 %\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.500 AVG Training Acc 80.19 % AVG Validation Acc 80.05 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.486 AVG Validation Loss:0.501 AVG Training Acc 80.32 % AVG Validation Acc 80.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.486 AVG Validation Loss:0.502 AVG Training Acc 80.30 % AVG Validation Acc 80.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.486 AVG Validation Loss:0.502 AVG Training Acc 80.26 % AVG Validation Acc 79.96 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.486 AVG Validation Loss:0.502 AVG Training Acc 80.27 % AVG Validation Acc 79.87 %\n",
      "Epoch:100/200 AVG Training Loss:0.486 AVG Validation Loss:0.502 AVG Training Acc 80.34 % AVG Validation Acc 79.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.486 AVG Validation Loss:0.502 AVG Training Acc 80.26 % AVG Validation Acc 79.87 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.486 AVG Validation Loss:0.502 AVG Training Acc 80.38 % AVG Validation Acc 79.87 %\n",
      "Epoch:130/200 AVG Training Loss:0.485 AVG Validation Loss:0.501 AVG Training Acc 80.34 % AVG Validation Acc 79.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.486 AVG Validation Loss:0.502 AVG Training Acc 80.23 % AVG Validation Acc 79.87 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.502 AVG Training Acc 80.28 % AVG Validation Acc 79.87 %\n",
      "Epoch:160/200 AVG Training Loss:0.486 AVG Validation Loss:0.502 AVG Training Acc 80.40 % AVG Validation Acc 79.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.486 AVG Validation Loss:0.502 AVG Training Acc 80.25 % AVG Validation Acc 79.87 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.486 AVG Validation Loss:0.502 AVG Training Acc 80.28 % AVG Validation Acc 79.87 %\n",
      "Epoch:190/200 AVG Training Loss:0.486 AVG Validation Loss:0.502 AVG Training Acc 80.27 % AVG Validation Acc 79.96 %\n",
      "Epoch:200/200 AVG Training Loss:0.487 AVG Validation Loss:0.502 AVG Training Acc 80.26 % AVG Validation Acc 79.87 %\n",
      "Split 157\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b997dc9a5dd45bda970dd1e2bcdbd78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.497 AVG Validation Loss:0.497 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.32 % AVG Validation Acc 80.23 %\n",
      "Epoch:60/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.38 % AVG Validation Acc 80.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.485 AVG Validation Loss:0.494 AVG Training Acc 80.45 % AVG Validation Acc 80.05 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.48 % AVG Validation Acc 80.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.45 % AVG Validation Acc 80.05 %\n",
      "Epoch:100/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.37 % AVG Validation Acc 80.05 %\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.53 % AVG Validation Acc 80.05 %\n",
      "Epoch:120/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.45 % AVG Validation Acc 80.05 %\n",
      "Epoch:130/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.40 % AVG Validation Acc 80.05 %\n",
      "Epoch   134: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.44 % AVG Validation Acc 80.05 %\n",
      "Epoch:150/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.47 % AVG Validation Acc 80.05 %\n",
      "Epoch:160/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.48 % AVG Validation Acc 80.05 %\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.40 % AVG Validation Acc 80.05 %\n",
      "Epoch:180/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.40 % AVG Validation Acc 80.05 %\n",
      "Epoch:190/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.51 % AVG Validation Acc 80.05 %\n",
      "Epoch   196: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.48 % AVG Validation Acc 80.05 %\n",
      "Split 158\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d58377815f65460b924b1d1c3d225a4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.497 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.25 % AVG Validation Acc 79.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.33 % AVG Validation Acc 79.87 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.42 % AVG Validation Acc 79.87 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.51 % AVG Validation Acc 79.78 %\n",
      "Epoch:70/200 AVG Training Loss:0.484 AVG Validation Loss:0.498 AVG Training Acc 80.56 % AVG Validation Acc 79.87 %\n",
      "Epoch:80/200 AVG Training Loss:0.484 AVG Validation Loss:0.498 AVG Training Acc 80.38 % AVG Validation Acc 79.69 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.59 % AVG Validation Acc 79.69 %\n",
      "Epoch:100/200 AVG Training Loss:0.484 AVG Validation Loss:0.498 AVG Training Acc 80.61 % AVG Validation Acc 79.69 %\n",
      "Epoch:110/200 AVG Training Loss:0.484 AVG Validation Loss:0.499 AVG Training Acc 80.50 % AVG Validation Acc 79.78 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.484 AVG Validation Loss:0.498 AVG Training Acc 80.58 % AVG Validation Acc 79.69 %\n",
      "Epoch:130/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.55 % AVG Validation Acc 79.69 %\n",
      "Epoch:140/200 AVG Training Loss:0.484 AVG Validation Loss:0.498 AVG Training Acc 80.59 % AVG Validation Acc 79.60 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.55 % AVG Validation Acc 79.60 %\n",
      "Epoch:160/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.62 % AVG Validation Acc 79.60 %\n",
      "Epoch:170/200 AVG Training Loss:0.484 AVG Validation Loss:0.498 AVG Training Acc 80.53 % AVG Validation Acc 79.69 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.52 % AVG Validation Acc 79.60 %\n",
      "Epoch:190/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.51 % AVG Validation Acc 79.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.484 AVG Validation Loss:0.498 AVG Training Acc 80.58 % AVG Validation Acc 79.69 %\n",
      "Split 159\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "750d0eb7d79b4763a4340914a327a22f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.08 % AVG Validation Acc 80.14 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.27 % AVG Validation Acc 80.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.31 % AVG Validation Acc 80.23 %\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.492 AVG Training Acc 80.50 % AVG Validation Acc 80.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.485 AVG Validation Loss:0.494 AVG Training Acc 80.54 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.484 AVG Validation Loss:0.493 AVG Training Acc 80.53 % AVG Validation Acc 80.14 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.481 AVG Validation Loss:0.493 AVG Training Acc 80.66 % AVG Validation Acc 79.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.481 AVG Validation Loss:0.495 AVG Training Acc 80.65 % AVG Validation Acc 80.05 %\n",
      "Epoch:100/200 AVG Training Loss:0.482 AVG Validation Loss:0.495 AVG Training Acc 80.64 % AVG Validation Acc 80.05 %\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.482 AVG Validation Loss:0.495 AVG Training Acc 80.65 % AVG Validation Acc 80.05 %\n",
      "Epoch:120/200 AVG Training Loss:0.481 AVG Validation Loss:0.494 AVG Training Acc 80.64 % AVG Validation Acc 80.05 %\n",
      "Epoch:130/200 AVG Training Loss:0.481 AVG Validation Loss:0.494 AVG Training Acc 80.67 % AVG Validation Acc 80.05 %\n",
      "Epoch   134: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.481 AVG Validation Loss:0.493 AVG Training Acc 80.66 % AVG Validation Acc 80.05 %\n",
      "Epoch:150/200 AVG Training Loss:0.481 AVG Validation Loss:0.493 AVG Training Acc 80.59 % AVG Validation Acc 80.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.481 AVG Validation Loss:0.493 AVG Training Acc 80.60 % AVG Validation Acc 80.23 %\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.481 AVG Validation Loss:0.493 AVG Training Acc 80.63 % AVG Validation Acc 80.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.481 AVG Validation Loss:0.494 AVG Training Acc 80.67 % AVG Validation Acc 80.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.482 AVG Validation Loss:0.494 AVG Training Acc 80.62 % AVG Validation Acc 80.05 %\n",
      "Epoch   196: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.482 AVG Validation Loss:0.493 AVG Training Acc 80.64 % AVG Validation Acc 80.14 %\n",
      "Split 160\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51ecbafef26346598f38fd0bacb50347",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.490 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.490 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.487 AVG Training Acc 80.23 % AVG Validation Acc 80.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.489 AVG Training Acc 80.21 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.23 % AVG Validation Acc 80.05 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.23 % AVG Validation Acc 79.87 %\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.25 % AVG Validation Acc 79.87 %\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.28 % AVG Validation Acc 79.87 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.31 % AVG Validation Acc 79.87 %\n",
      "Epoch:100/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.25 % AVG Validation Acc 79.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.23 % AVG Validation Acc 79.87 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.27 % AVG Validation Acc 79.87 %\n",
      "Epoch:130/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.26 % AVG Validation Acc 79.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.27 % AVG Validation Acc 79.87 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.27 % AVG Validation Acc 79.87 %\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.25 % AVG Validation Acc 79.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.25 % AVG Validation Acc 79.87 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.26 % AVG Validation Acc 79.87 %\n",
      "Epoch:190/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.27 % AVG Validation Acc 79.87 %\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.25 % AVG Validation Acc 79.87 %\n",
      "Split 161\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c609f1442b4b4c980d963dd2a71a5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.25 % AVG Validation Acc 80.25 %\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.61 % AVG Validation Acc 79.80 %\n",
      "Epoch:50/200 AVG Training Loss:0.480 AVG Validation Loss:0.502 AVG Training Acc 80.76 % AVG Validation Acc 79.80 %\n",
      "Epoch:60/200 AVG Training Loss:0.477 AVG Validation Loss:0.507 AVG Training Acc 80.99 % AVG Validation Acc 79.62 %\n",
      "Epoch:70/200 AVG Training Loss:0.474 AVG Validation Loss:0.508 AVG Training Acc 81.14 % AVG Validation Acc 79.98 %\n",
      "Epoch    70: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.474 AVG Validation Loss:0.512 AVG Training Acc 81.05 % AVG Validation Acc 79.62 %\n",
      "Epoch:90/200 AVG Training Loss:0.474 AVG Validation Loss:0.512 AVG Training Acc 81.21 % AVG Validation Acc 79.62 %\n",
      "Epoch:100/200 AVG Training Loss:0.472 AVG Validation Loss:0.512 AVG Training Acc 81.21 % AVG Validation Acc 79.71 %\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.473 AVG Validation Loss:0.513 AVG Training Acc 81.22 % AVG Validation Acc 79.62 %\n",
      "Epoch:120/200 AVG Training Loss:0.474 AVG Validation Loss:0.512 AVG Training Acc 81.17 % AVG Validation Acc 79.53 %\n",
      "Epoch:130/200 AVG Training Loss:0.473 AVG Validation Loss:0.513 AVG Training Acc 81.12 % AVG Validation Acc 79.44 %\n",
      "Epoch   132: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.473 AVG Validation Loss:0.512 AVG Training Acc 81.21 % AVG Validation Acc 79.62 %\n",
      "Epoch:150/200 AVG Training Loss:0.473 AVG Validation Loss:0.513 AVG Training Acc 81.24 % AVG Validation Acc 79.62 %\n",
      "Epoch:160/200 AVG Training Loss:0.472 AVG Validation Loss:0.513 AVG Training Acc 81.19 % AVG Validation Acc 79.53 %\n",
      "Epoch   163: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.472 AVG Validation Loss:0.512 AVG Training Acc 81.24 % AVG Validation Acc 79.62 %\n",
      "Epoch:180/200 AVG Training Loss:0.473 AVG Validation Loss:0.512 AVG Training Acc 81.17 % AVG Validation Acc 79.53 %\n",
      "Epoch:190/200 AVG Training Loss:0.473 AVG Validation Loss:0.513 AVG Training Acc 81.11 % AVG Validation Acc 79.62 %\n",
      "Epoch   194: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.472 AVG Validation Loss:0.513 AVG Training Acc 81.20 % AVG Validation Acc 79.62 %\n",
      "Split 162\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ddad8ef356c4ff2a98582212e9261a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:80/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.26 % AVG Validation Acc 80.16 %\n",
      "Epoch:90/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.26 % AVG Validation Acc 80.16 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.24 % AVG Validation Acc 80.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.20 % AVG Validation Acc 80.16 %\n",
      "Epoch:120/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.20 % AVG Validation Acc 80.16 %\n",
      "Epoch:140/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch:170/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.23 % AVG Validation Acc 80.16 %\n",
      "Epoch:180/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.20 % AVG Validation Acc 80.16 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.27 % AVG Validation Acc 80.16 %\n",
      "Epoch:200/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.30 % AVG Validation Acc 80.16 %\n",
      "Split 163\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f15ed529e1b45448fd47b8d2a67be1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.499 AVG Training Acc 80.18 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.502 AVG Training Acc 80.24 % AVG Validation Acc 79.98 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.502 AVG Training Acc 80.30 % AVG Validation Acc 79.98 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.503 AVG Training Acc 80.38 % AVG Validation Acc 80.16 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.40 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.46 % AVG Validation Acc 80.16 %\n",
      "Epoch:80/200 AVG Training Loss:0.483 AVG Validation Loss:0.504 AVG Training Acc 80.58 % AVG Validation Acc 80.07 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.485 AVG Validation Loss:0.503 AVG Training Acc 80.49 % AVG Validation Acc 80.16 %\n",
      "Epoch:100/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.48 % AVG Validation Acc 80.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.485 AVG Validation Loss:0.503 AVG Training Acc 80.46 % AVG Validation Acc 80.16 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.485 AVG Validation Loss:0.503 AVG Training Acc 80.47 % AVG Validation Acc 80.16 %\n",
      "Epoch:130/200 AVG Training Loss:0.483 AVG Validation Loss:0.503 AVG Training Acc 80.45 % AVG Validation Acc 80.07 %\n",
      "Epoch:140/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.59 % AVG Validation Acc 80.16 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.39 % AVG Validation Acc 80.07 %\n",
      "Epoch:160/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.45 % AVG Validation Acc 80.16 %\n",
      "Epoch:170/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.39 % AVG Validation Acc 80.16 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.57 % AVG Validation Acc 80.07 %\n",
      "Epoch:190/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.45 % AVG Validation Acc 80.07 %\n",
      "Epoch:200/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.52 % AVG Validation Acc 80.16 %\n",
      "Split 164\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48324096b55c4d3abb88512fc4a350f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.22 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.29 % AVG Validation Acc 79.98 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.32 % AVG Validation Acc 79.89 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.42 % AVG Validation Acc 79.89 %\n",
      "Epoch:60/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.49 % AVG Validation Acc 79.98 %\n",
      "Epoch:70/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.47 % AVG Validation Acc 79.98 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.47 % AVG Validation Acc 80.07 %\n",
      "Epoch:90/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.48 % AVG Validation Acc 80.16 %\n",
      "Epoch:100/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.47 % AVG Validation Acc 80.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.44 % AVG Validation Acc 80.16 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.46 % AVG Validation Acc 80.16 %\n",
      "Epoch:130/200 AVG Training Loss:0.485 AVG Validation Loss:0.500 AVG Training Acc 80.49 % AVG Validation Acc 80.07 %\n",
      "Epoch:140/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.45 % AVG Validation Acc 80.16 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.484 AVG Validation Loss:0.498 AVG Training Acc 80.51 % AVG Validation Acc 80.16 %\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.46 % AVG Validation Acc 80.07 %\n",
      "Epoch:170/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.47 % AVG Validation Acc 80.07 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.51 % AVG Validation Acc 80.16 %\n",
      "Epoch:190/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.55 % AVG Validation Acc 80.16 %\n",
      "Epoch:200/200 AVG Training Loss:0.484 AVG Validation Loss:0.499 AVG Training Acc 80.52 % AVG Validation Acc 80.07 %\n",
      "Split 165\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2401922f6a2c439e9af37d8c5267305f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.12 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.23 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.33 % AVG Validation Acc 80.07 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.34 % AVG Validation Acc 79.98 %\n",
      "Epoch:60/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.43 % AVG Validation Acc 79.62 %\n",
      "Epoch:70/200 AVG Training Loss:0.483 AVG Validation Loss:0.499 AVG Training Acc 80.59 % AVG Validation Acc 79.53 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.482 AVG Validation Loss:0.500 AVG Training Acc 80.73 % AVG Validation Acc 79.53 %\n",
      "Epoch:90/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.78 % AVG Validation Acc 79.62 %\n",
      "Epoch:100/200 AVG Training Loss:0.480 AVG Validation Loss:0.500 AVG Training Acc 80.69 % AVG Validation Acc 79.53 %\n",
      "Epoch:110/200 AVG Training Loss:0.480 AVG Validation Loss:0.500 AVG Training Acc 80.80 % AVG Validation Acc 79.53 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.481 AVG Validation Loss:0.500 AVG Training Acc 80.77 % AVG Validation Acc 79.53 %\n",
      "Epoch:130/200 AVG Training Loss:0.481 AVG Validation Loss:0.500 AVG Training Acc 80.83 % AVG Validation Acc 79.44 %\n",
      "Epoch:140/200 AVG Training Loss:0.480 AVG Validation Loss:0.501 AVG Training Acc 80.81 % AVG Validation Acc 79.44 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.481 AVG Validation Loss:0.500 AVG Training Acc 80.82 % AVG Validation Acc 79.53 %\n",
      "Epoch:160/200 AVG Training Loss:0.481 AVG Validation Loss:0.500 AVG Training Acc 80.78 % AVG Validation Acc 79.44 %\n",
      "Epoch:170/200 AVG Training Loss:0.481 AVG Validation Loss:0.500 AVG Training Acc 80.74 % AVG Validation Acc 79.53 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.481 AVG Validation Loss:0.500 AVG Training Acc 80.79 % AVG Validation Acc 79.53 %\n",
      "Epoch:190/200 AVG Training Loss:0.479 AVG Validation Loss:0.500 AVG Training Acc 80.87 % AVG Validation Acc 79.44 %\n",
      "Epoch:200/200 AVG Training Loss:0.481 AVG Validation Loss:0.500 AVG Training Acc 80.79 % AVG Validation Acc 79.53 %\n",
      "Split 166\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "493f6132f0bb43a4a3dd4dc2e37f9948",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.502 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.497 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.498 AVG Training Acc 80.17 % AVG Validation Acc 80.05 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.499 AVG Training Acc 80.17 % AVG Validation Acc 80.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.504 AVG Training Acc 80.23 % AVG Validation Acc 79.96 %\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.504 AVG Training Acc 80.24 % AVG Validation Acc 80.05 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.504 AVG Training Acc 80.22 % AVG Validation Acc 80.05 %\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.505 AVG Training Acc 80.21 % AVG Validation Acc 79.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.488 AVG Validation Loss:0.505 AVG Training Acc 80.23 % AVG Validation Acc 80.05 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.505 AVG Training Acc 80.25 % AVG Validation Acc 80.05 %\n",
      "Epoch:120/200 AVG Training Loss:0.488 AVG Validation Loss:0.505 AVG Training Acc 80.21 % AVG Validation Acc 80.05 %\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.505 AVG Training Acc 80.17 % AVG Validation Acc 80.05 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.489 AVG Validation Loss:0.505 AVG Training Acc 80.22 % AVG Validation Acc 80.05 %\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.505 AVG Training Acc 80.27 % AVG Validation Acc 80.05 %\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.505 AVG Training Acc 80.19 % AVG Validation Acc 80.05 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.505 AVG Training Acc 80.20 % AVG Validation Acc 79.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.505 AVG Training Acc 80.24 % AVG Validation Acc 79.96 %\n",
      "Epoch:190/200 AVG Training Loss:0.488 AVG Validation Loss:0.505 AVG Training Acc 80.23 % AVG Validation Acc 80.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.505 AVG Training Acc 80.18 % AVG Validation Acc 80.05 %\n",
      "Split 167\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ad30ea4cdc14408b42834b39950cbdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.498 AVG Validation Loss:0.499 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.491 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.491 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.491 AVG Validation Loss:0.491 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.15 % AVG Validation Acc 80.23 %\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.17 % AVG Validation Acc 80.23 %\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.490 AVG Training Acc 80.18 % AVG Validation Acc 80.32 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.488 AVG Validation Loss:0.490 AVG Training Acc 80.23 % AVG Validation Acc 80.32 %\n",
      "Epoch:110/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.26 % AVG Validation Acc 80.32 %\n",
      "Epoch:120/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.33 % AVG Validation Acc 80.23 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.487 AVG Validation Loss:0.491 AVG Training Acc 80.30 % AVG Validation Acc 80.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.29 % AVG Validation Acc 80.23 %\n",
      "Epoch:150/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.28 % AVG Validation Acc 80.23 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.30 % AVG Validation Acc 80.23 %\n",
      "Epoch:170/200 AVG Training Loss:0.487 AVG Validation Loss:0.491 AVG Training Acc 80.24 % AVG Validation Acc 80.23 %\n",
      "Epoch:180/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.30 % AVG Validation Acc 80.23 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.27 % AVG Validation Acc 80.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.28 % AVG Validation Acc 80.23 %\n",
      "Split 168\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91a603a92cf546d392be67ca964a848c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.492 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.491 AVG Training Acc 80.29 % AVG Validation Acc 80.23 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.491 AVG Training Acc 80.37 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.484 AVG Validation Loss:0.492 AVG Training Acc 80.39 % AVG Validation Acc 80.14 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.482 AVG Validation Loss:0.493 AVG Training Acc 80.50 % AVG Validation Acc 80.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.483 AVG Validation Loss:0.493 AVG Training Acc 80.54 % AVG Validation Acc 80.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.481 AVG Validation Loss:0.493 AVG Training Acc 80.63 % AVG Validation Acc 80.23 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.482 AVG Validation Loss:0.493 AVG Training Acc 80.54 % AVG Validation Acc 80.23 %\n",
      "Epoch:110/200 AVG Training Loss:0.481 AVG Validation Loss:0.493 AVG Training Acc 80.64 % AVG Validation Acc 80.23 %\n",
      "Epoch:120/200 AVG Training Loss:0.482 AVG Validation Loss:0.493 AVG Training Acc 80.57 % AVG Validation Acc 80.14 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.481 AVG Validation Loss:0.493 AVG Training Acc 80.71 % AVG Validation Acc 80.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.481 AVG Validation Loss:0.493 AVG Training Acc 80.62 % AVG Validation Acc 80.23 %\n",
      "Epoch:150/200 AVG Training Loss:0.481 AVG Validation Loss:0.493 AVG Training Acc 80.65 % AVG Validation Acc 80.23 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.481 AVG Validation Loss:0.493 AVG Training Acc 80.59 % AVG Validation Acc 80.23 %\n",
      "Epoch:170/200 AVG Training Loss:0.481 AVG Validation Loss:0.493 AVG Training Acc 80.69 % AVG Validation Acc 80.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.480 AVG Validation Loss:0.492 AVG Training Acc 80.61 % AVG Validation Acc 80.23 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.482 AVG Validation Loss:0.493 AVG Training Acc 80.59 % AVG Validation Acc 80.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.481 AVG Validation Loss:0.493 AVG Training Acc 80.62 % AVG Validation Acc 80.23 %\n",
      "Split 169\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ba9d3b89a034388836b97ab48186a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.10 % AVG Validation Acc 80.14 %\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.491 AVG Training Acc 80.16 % AVG Validation Acc 80.51 %\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.20 % AVG Validation Acc 80.42 %\n",
      "Epoch:70/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch:120/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch   134: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.10 % AVG Validation Acc 80.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch   196: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Split 170\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f00128761a99421499d2c7b851dcd545",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.492 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.491 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.492 AVG Training Acc 80.15 % AVG Validation Acc 80.05 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.488 AVG Training Acc 80.32 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.489 AVG Training Acc 80.36 % AVG Validation Acc 79.87 %\n",
      "Epoch:60/200 AVG Training Loss:0.484 AVG Validation Loss:0.492 AVG Training Acc 80.48 % AVG Validation Acc 79.78 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.482 AVG Validation Loss:0.492 AVG Training Acc 80.56 % AVG Validation Acc 79.78 %\n",
      "Epoch:80/200 AVG Training Loss:0.482 AVG Validation Loss:0.493 AVG Training Acc 80.62 % AVG Validation Acc 79.78 %\n",
      "Epoch:90/200 AVG Training Loss:0.482 AVG Validation Loss:0.493 AVG Training Acc 80.63 % AVG Validation Acc 79.87 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.482 AVG Validation Loss:0.494 AVG Training Acc 80.65 % AVG Validation Acc 79.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.482 AVG Validation Loss:0.493 AVG Training Acc 80.60 % AVG Validation Acc 79.78 %\n",
      "Epoch:120/200 AVG Training Loss:0.481 AVG Validation Loss:0.494 AVG Training Acc 80.65 % AVG Validation Acc 79.78 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.481 AVG Validation Loss:0.494 AVG Training Acc 80.77 % AVG Validation Acc 79.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.482 AVG Validation Loss:0.493 AVG Training Acc 80.61 % AVG Validation Acc 79.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.482 AVG Validation Loss:0.494 AVG Training Acc 80.59 % AVG Validation Acc 79.78 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.482 AVG Validation Loss:0.494 AVG Training Acc 80.52 % AVG Validation Acc 79.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.481 AVG Validation Loss:0.494 AVG Training Acc 80.71 % AVG Validation Acc 79.78 %\n",
      "Epoch:180/200 AVG Training Loss:0.482 AVG Validation Loss:0.494 AVG Training Acc 80.62 % AVG Validation Acc 79.78 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.481 AVG Validation Loss:0.493 AVG Training Acc 80.74 % AVG Validation Acc 79.78 %\n",
      "Epoch:200/200 AVG Training Loss:0.482 AVG Validation Loss:0.494 AVG Training Acc 80.65 % AVG Validation Acc 79.78 %\n",
      "Split 171\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dafaa5e36be949eeaa977ba35057037e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.503 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.490 AVG Validation Loss:0.502 AVG Training Acc 80.16 % AVG Validation Acc 79.98 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.502 AVG Training Acc 80.20 % AVG Validation Acc 79.98 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.502 AVG Training Acc 80.28 % AVG Validation Acc 80.07 %\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.504 AVG Training Acc 80.28 % AVG Validation Acc 80.07 %\n",
      "Epoch:60/200 AVG Training Loss:0.487 AVG Validation Loss:0.507 AVG Training Acc 80.31 % AVG Validation Acc 80.07 %\n",
      "Epoch:70/200 AVG Training Loss:0.487 AVG Validation Loss:0.507 AVG Training Acc 80.29 % AVG Validation Acc 80.07 %\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.487 AVG Validation Loss:0.507 AVG Training Acc 80.32 % AVG Validation Acc 80.07 %\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.508 AVG Training Acc 80.31 % AVG Validation Acc 80.07 %\n",
      "Epoch:100/200 AVG Training Loss:0.487 AVG Validation Loss:0.506 AVG Training Acc 80.31 % AVG Validation Acc 80.07 %\n",
      "Epoch   106: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.487 AVG Validation Loss:0.509 AVG Training Acc 80.31 % AVG Validation Acc 80.07 %\n",
      "Epoch:120/200 AVG Training Loss:0.487 AVG Validation Loss:0.508 AVG Training Acc 80.34 % AVG Validation Acc 80.07 %\n",
      "Epoch:130/200 AVG Training Loss:0.487 AVG Validation Loss:0.508 AVG Training Acc 80.36 % AVG Validation Acc 80.07 %\n",
      "Epoch   137: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.509 AVG Training Acc 80.25 % AVG Validation Acc 80.07 %\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.506 AVG Training Acc 80.28 % AVG Validation Acc 80.07 %\n",
      "Epoch:160/200 AVG Training Loss:0.487 AVG Validation Loss:0.508 AVG Training Acc 80.32 % AVG Validation Acc 80.07 %\n",
      "Epoch   168: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.487 AVG Validation Loss:0.509 AVG Training Acc 80.31 % AVG Validation Acc 80.07 %\n",
      "Epoch:180/200 AVG Training Loss:0.487 AVG Validation Loss:0.509 AVG Training Acc 80.32 % AVG Validation Acc 80.07 %\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.508 AVG Training Acc 80.34 % AVG Validation Acc 80.07 %\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.507 AVG Training Acc 80.32 % AVG Validation Acc 80.07 %\n",
      "Split 172\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "262aaada17504911a6caacc38aa3343c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.17 % AVG Validation Acc 80.25 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.31 % AVG Validation Acc 80.25 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.43 % AVG Validation Acc 80.34 %\n",
      "Epoch:60/200 AVG Training Loss:0.482 AVG Validation Loss:0.503 AVG Training Acc 80.55 % AVG Validation Acc 80.34 %\n",
      "Epoch:70/200 AVG Training Loss:0.480 AVG Validation Loss:0.504 AVG Training Acc 80.73 % AVG Validation Acc 80.34 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.479 AVG Validation Loss:0.509 AVG Training Acc 80.69 % AVG Validation Acc 80.07 %\n",
      "Epoch:90/200 AVG Training Loss:0.478 AVG Validation Loss:0.510 AVG Training Acc 80.74 % AVG Validation Acc 79.89 %\n",
      "Epoch:100/200 AVG Training Loss:0.479 AVG Validation Loss:0.511 AVG Training Acc 80.78 % AVG Validation Acc 80.16 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.478 AVG Validation Loss:0.511 AVG Training Acc 80.83 % AVG Validation Acc 80.16 %\n",
      "Epoch:120/200 AVG Training Loss:0.477 AVG Validation Loss:0.510 AVG Training Acc 80.82 % AVG Validation Acc 80.16 %\n",
      "Epoch:130/200 AVG Training Loss:0.478 AVG Validation Loss:0.511 AVG Training Acc 80.73 % AVG Validation Acc 80.16 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.479 AVG Validation Loss:0.511 AVG Training Acc 80.72 % AVG Validation Acc 80.16 %\n",
      "Epoch:150/200 AVG Training Loss:0.477 AVG Validation Loss:0.510 AVG Training Acc 80.75 % AVG Validation Acc 80.16 %\n",
      "Epoch:160/200 AVG Training Loss:0.476 AVG Validation Loss:0.506 AVG Training Acc 80.87 % AVG Validation Acc 80.16 %\n",
      "Epoch:170/200 AVG Training Loss:0.477 AVG Validation Loss:0.510 AVG Training Acc 80.88 % AVG Validation Acc 80.07 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.477 AVG Validation Loss:0.512 AVG Training Acc 80.86 % AVG Validation Acc 80.07 %\n",
      "Epoch:190/200 AVG Training Loss:0.478 AVG Validation Loss:0.511 AVG Training Acc 80.85 % AVG Validation Acc 80.16 %\n",
      "Epoch:200/200 AVG Training Loss:0.477 AVG Validation Loss:0.511 AVG Training Acc 80.78 % AVG Validation Acc 80.07 %\n",
      "Split 173\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b63ee5b88534f649fb4d1c1ff40fcf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.495 AVG Validation Loss:0.492 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.494 AVG Validation Loss:0.491 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.493 AVG Validation Loss:0.491 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.492 AVG Validation Loss:0.492 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.491 AVG Validation Loss:0.491 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.492 AVG Validation Loss:0.491 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:80/200 AVG Training Loss:0.492 AVG Validation Loss:0.491 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.491 AVG Validation Loss:0.491 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:100/200 AVG Training Loss:0.491 AVG Validation Loss:0.491 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.492 AVG Validation Loss:0.491 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.491 AVG Validation Loss:0.491 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:130/200 AVG Training Loss:0.491 AVG Validation Loss:0.491 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch:140/200 AVG Training Loss:0.491 AVG Validation Loss:0.491 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.491 AVG Validation Loss:0.491 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:160/200 AVG Training Loss:0.491 AVG Validation Loss:0.491 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:170/200 AVG Training Loss:0.491 AVG Validation Loss:0.491 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.491 AVG Validation Loss:0.491 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:190/200 AVG Training Loss:0.491 AVG Validation Loss:0.491 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:200/200 AVG Training Loss:0.492 AVG Validation Loss:0.491 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Split 174\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96e27d825c3d4a2cb26f3a449f96d7ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.491 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.20 % AVG Validation Acc 80.25 %\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.19 % AVG Validation Acc 80.25 %\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.18 % AVG Validation Acc 80.25 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.488 AVG Training Acc 80.21 % AVG Validation Acc 80.25 %\n",
      "Epoch:80/200 AVG Training Loss:0.489 AVG Validation Loss:0.488 AVG Training Acc 80.23 % AVG Validation Acc 80.25 %\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.22 % AVG Validation Acc 80.25 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.26 % AVG Validation Acc 80.25 %\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.22 % AVG Validation Acc 80.25 %\n",
      "Epoch:120/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.29 % AVG Validation Acc 80.25 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.24 % AVG Validation Acc 80.25 %\n",
      "Epoch:140/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.23 % AVG Validation Acc 80.25 %\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.28 % AVG Validation Acc 80.25 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.488 AVG Training Acc 80.25 % AVG Validation Acc 80.25 %\n",
      "Epoch:170/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.21 % AVG Validation Acc 80.25 %\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.28 % AVG Validation Acc 80.25 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.489 AVG Training Acc 80.18 % AVG Validation Acc 80.25 %\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.28 % AVG Validation Acc 80.25 %\n",
      "Split 175\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f03d50b275493588780a2c094110da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.492 AVG Validation Loss:0.492 AVG Training Acc 80.11 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.24 % AVG Validation Acc 80.07 %\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.490 AVG Training Acc 80.32 % AVG Validation Acc 80.07 %\n",
      "Epoch:70/200 AVG Training Loss:0.493 AVG Validation Loss:0.493 AVG Training Acc 80.12 % AVG Validation Acc 79.98 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:80/200 AVG Training Loss:0.485 AVG Validation Loss:0.486 AVG Training Acc 80.36 % AVG Validation Acc 80.25 %\n",
      "Epoch:90/200 AVG Training Loss:0.482 AVG Validation Loss:0.487 AVG Training Acc 80.49 % AVG Validation Acc 79.98 %\n",
      "Epoch:100/200 AVG Training Loss:0.479 AVG Validation Loss:0.487 AVG Training Acc 80.66 % AVG Validation Acc 80.25 %\n",
      "Epoch:110/200 AVG Training Loss:0.476 AVG Validation Loss:0.491 AVG Training Acc 80.85 % AVG Validation Acc 79.98 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:120/200 AVG Training Loss:0.473 AVG Validation Loss:0.492 AVG Training Acc 81.04 % AVG Validation Acc 79.80 %\n",
      "Epoch:130/200 AVG Training Loss:0.474 AVG Validation Loss:0.490 AVG Training Acc 81.04 % AVG Validation Acc 79.80 %\n",
      "Epoch:140/200 AVG Training Loss:0.474 AVG Validation Loss:0.491 AVG Training Acc 80.87 % AVG Validation Acc 79.80 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.473 AVG Validation Loss:0.490 AVG Training Acc 81.00 % AVG Validation Acc 80.16 %\n",
      "Epoch:160/200 AVG Training Loss:0.474 AVG Validation Loss:0.491 AVG Training Acc 80.88 % AVG Validation Acc 79.98 %\n",
      "Epoch:170/200 AVG Training Loss:0.472 AVG Validation Loss:0.490 AVG Training Acc 81.01 % AVG Validation Acc 79.80 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:180/200 AVG Training Loss:0.472 AVG Validation Loss:0.492 AVG Training Acc 81.14 % AVG Validation Acc 79.80 %\n",
      "Epoch:190/200 AVG Training Loss:0.473 AVG Validation Loss:0.492 AVG Training Acc 81.07 % AVG Validation Acc 79.98 %\n",
      "Epoch:200/200 AVG Training Loss:0.472 AVG Validation Loss:0.492 AVG Training Acc 81.04 % AVG Validation Acc 79.80 %\n",
      "Split 176\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8410ccd5eb94fef82c9f237eae1796c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.493 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.10 % AVG Validation Acc 80.14 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.491 AVG Training Acc 80.49 % AVG Validation Acc 79.87 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.491 AVG Training Acc 80.54 % AVG Validation Acc 79.87 %\n",
      "Epoch:60/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.60 % AVG Validation Acc 79.60 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.480 AVG Validation Loss:0.499 AVG Training Acc 80.70 % AVG Validation Acc 79.78 %\n",
      "Epoch:80/200 AVG Training Loss:0.482 AVG Validation Loss:0.500 AVG Training Acc 80.70 % AVG Validation Acc 79.78 %\n",
      "Epoch:90/200 AVG Training Loss:0.480 AVG Validation Loss:0.501 AVG Training Acc 80.66 % AVG Validation Acc 79.78 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.480 AVG Validation Loss:0.502 AVG Training Acc 80.80 % AVG Validation Acc 79.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.480 AVG Validation Loss:0.502 AVG Training Acc 80.75 % AVG Validation Acc 79.78 %\n",
      "Epoch:120/200 AVG Training Loss:0.480 AVG Validation Loss:0.501 AVG Training Acc 80.77 % AVG Validation Acc 79.78 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.480 AVG Validation Loss:0.501 AVG Training Acc 80.83 % AVG Validation Acc 79.69 %\n",
      "Epoch:140/200 AVG Training Loss:0.479 AVG Validation Loss:0.502 AVG Training Acc 80.79 % AVG Validation Acc 79.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.480 AVG Validation Loss:0.500 AVG Training Acc 80.85 % AVG Validation Acc 79.78 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.480 AVG Validation Loss:0.502 AVG Training Acc 80.81 % AVG Validation Acc 79.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.480 AVG Validation Loss:0.502 AVG Training Acc 80.74 % AVG Validation Acc 79.78 %\n",
      "Epoch:180/200 AVG Training Loss:0.481 AVG Validation Loss:0.502 AVG Training Acc 80.82 % AVG Validation Acc 79.69 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.481 AVG Validation Loss:0.502 AVG Training Acc 80.77 % AVG Validation Acc 79.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.481 AVG Validation Loss:0.501 AVG Training Acc 80.74 % AVG Validation Acc 79.78 %\n",
      "Split 177\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b7e224a3ca348249fb1163537a12c67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.499 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.497 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.497 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.18 % AVG Validation Acc 80.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.24 % AVG Validation Acc 80.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:120/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.10 % AVG Validation Acc 80.14 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.26 % AVG Validation Acc 80.14 %\n",
      "Epoch:150/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Split 178\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "351a1cf663e24666972750ee144bf646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.30 % AVG Validation Acc 80.23 %\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.46 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.483 AVG Validation Loss:0.500 AVG Training Acc 80.63 % AVG Validation Acc 80.14 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.482 AVG Validation Loss:0.504 AVG Training Acc 80.70 % AVG Validation Acc 79.78 %\n",
      "Epoch:70/200 AVG Training Loss:0.480 AVG Validation Loss:0.503 AVG Training Acc 80.87 % AVG Validation Acc 79.69 %\n",
      "Epoch:80/200 AVG Training Loss:0.481 AVG Validation Loss:0.502 AVG Training Acc 80.80 % AVG Validation Acc 79.78 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.480 AVG Validation Loss:0.503 AVG Training Acc 80.81 % AVG Validation Acc 79.78 %\n",
      "Epoch:100/200 AVG Training Loss:0.480 AVG Validation Loss:0.503 AVG Training Acc 80.86 % AVG Validation Acc 79.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.479 AVG Validation Loss:0.503 AVG Training Acc 80.86 % AVG Validation Acc 79.69 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.479 AVG Validation Loss:0.502 AVG Training Acc 80.88 % AVG Validation Acc 79.69 %\n",
      "Epoch:130/200 AVG Training Loss:0.480 AVG Validation Loss:0.502 AVG Training Acc 80.84 % AVG Validation Acc 79.69 %\n",
      "Epoch:140/200 AVG Training Loss:0.479 AVG Validation Loss:0.502 AVG Training Acc 80.87 % AVG Validation Acc 79.78 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.480 AVG Validation Loss:0.501 AVG Training Acc 80.76 % AVG Validation Acc 79.69 %\n",
      "Epoch:160/200 AVG Training Loss:0.480 AVG Validation Loss:0.503 AVG Training Acc 80.71 % AVG Validation Acc 79.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.480 AVG Validation Loss:0.502 AVG Training Acc 80.81 % AVG Validation Acc 79.69 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.480 AVG Validation Loss:0.502 AVG Training Acc 80.75 % AVG Validation Acc 79.78 %\n",
      "Epoch:190/200 AVG Training Loss:0.480 AVG Validation Loss:0.502 AVG Training Acc 80.82 % AVG Validation Acc 79.78 %\n",
      "Epoch:200/200 AVG Training Loss:0.480 AVG Validation Loss:0.503 AVG Training Acc 80.83 % AVG Validation Acc 79.69 %\n",
      "Split 179\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23488379851147dcb8e93b7da1812fe6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.489 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.489 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.485 AVG Validation Loss:0.487 AVG Training Acc 80.35 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.481 AVG Validation Loss:0.488 AVG Training Acc 80.72 % AVG Validation Acc 80.32 %\n",
      "Epoch:60/200 AVG Training Loss:0.479 AVG Validation Loss:0.489 AVG Training Acc 80.84 % AVG Validation Acc 79.96 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.474 AVG Validation Loss:0.491 AVG Training Acc 81.15 % AVG Validation Acc 79.87 %\n",
      "Epoch:80/200 AVG Training Loss:0.473 AVG Validation Loss:0.492 AVG Training Acc 81.21 % AVG Validation Acc 79.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.473 AVG Validation Loss:0.491 AVG Training Acc 81.20 % AVG Validation Acc 80.05 %\n",
      "Epoch:100/200 AVG Training Loss:0.474 AVG Validation Loss:0.492 AVG Training Acc 81.19 % AVG Validation Acc 80.05 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.473 AVG Validation Loss:0.492 AVG Training Acc 81.23 % AVG Validation Acc 80.05 %\n",
      "Epoch:120/200 AVG Training Loss:0.474 AVG Validation Loss:0.492 AVG Training Acc 81.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.472 AVG Validation Loss:0.492 AVG Training Acc 81.21 % AVG Validation Acc 80.05 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.474 AVG Validation Loss:0.491 AVG Training Acc 81.22 % AVG Validation Acc 80.05 %\n",
      "Epoch:150/200 AVG Training Loss:0.474 AVG Validation Loss:0.491 AVG Training Acc 81.10 % AVG Validation Acc 80.05 %\n",
      "Epoch:160/200 AVG Training Loss:0.473 AVG Validation Loss:0.491 AVG Training Acc 81.21 % AVG Validation Acc 80.05 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.472 AVG Validation Loss:0.492 AVG Training Acc 81.32 % AVG Validation Acc 80.05 %\n",
      "Epoch:180/200 AVG Training Loss:0.473 AVG Validation Loss:0.492 AVG Training Acc 81.28 % AVG Validation Acc 80.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.473 AVG Validation Loss:0.491 AVG Training Acc 81.31 % AVG Validation Acc 80.05 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.474 AVG Validation Loss:0.492 AVG Training Acc 81.17 % AVG Validation Acc 80.14 %\n",
      "Split 180\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf59e88a649540ea8afef93127154c48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.500 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.490 AVG Validation Loss:0.502 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.504 AVG Training Acc 80.14 % AVG Validation Acc 80.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.505 AVG Training Acc 80.22 % AVG Validation Acc 80.05 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.507 AVG Training Acc 80.31 % AVG Validation Acc 79.96 %\n",
      "Epoch:60/200 AVG Training Loss:0.485 AVG Validation Loss:0.507 AVG Training Acc 80.30 % AVG Validation Acc 79.96 %\n",
      "Epoch:70/200 AVG Training Loss:0.485 AVG Validation Loss:0.507 AVG Training Acc 80.32 % AVG Validation Acc 80.05 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.486 AVG Validation Loss:0.507 AVG Training Acc 80.37 % AVG Validation Acc 79.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.486 AVG Validation Loss:0.507 AVG Training Acc 80.35 % AVG Validation Acc 80.05 %\n",
      "Epoch:100/200 AVG Training Loss:0.486 AVG Validation Loss:0.508 AVG Training Acc 80.33 % AVG Validation Acc 79.87 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.486 AVG Validation Loss:0.507 AVG Training Acc 80.25 % AVG Validation Acc 79.96 %\n",
      "Epoch:120/200 AVG Training Loss:0.486 AVG Validation Loss:0.507 AVG Training Acc 80.34 % AVG Validation Acc 79.87 %\n",
      "Epoch:130/200 AVG Training Loss:0.485 AVG Validation Loss:0.507 AVG Training Acc 80.35 % AVG Validation Acc 79.96 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.486 AVG Validation Loss:0.508 AVG Training Acc 80.33 % AVG Validation Acc 79.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.508 AVG Training Acc 80.40 % AVG Validation Acc 79.96 %\n",
      "Epoch:160/200 AVG Training Loss:0.486 AVG Validation Loss:0.507 AVG Training Acc 80.30 % AVG Validation Acc 80.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.486 AVG Validation Loss:0.508 AVG Training Acc 80.36 % AVG Validation Acc 79.96 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.486 AVG Validation Loss:0.508 AVG Training Acc 80.35 % AVG Validation Acc 79.96 %\n",
      "Epoch:190/200 AVG Training Loss:0.485 AVG Validation Loss:0.508 AVG Training Acc 80.38 % AVG Validation Acc 79.87 %\n",
      "Epoch:200/200 AVG Training Loss:0.485 AVG Validation Loss:0.508 AVG Training Acc 80.37 % AVG Validation Acc 79.96 %\n",
      "Split 181\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a00cd871e20473fb6e9cc5d86749f14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.20 % AVG Validation Acc 80.07 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.26 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.23 % AVG Validation Acc 80.16 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.498 AVG Training Acc 80.29 % AVG Validation Acc 80.07 %\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.498 AVG Training Acc 80.27 % AVG Validation Acc 80.16 %\n",
      "Epoch:100/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.22 % AVG Validation Acc 80.16 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.35 % AVG Validation Acc 80.07 %\n",
      "Epoch:120/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.27 % AVG Validation Acc 80.07 %\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.498 AVG Training Acc 80.33 % AVG Validation Acc 80.07 %\n",
      "Epoch:140/200 AVG Training Loss:0.488 AVG Validation Loss:0.498 AVG Training Acc 80.26 % AVG Validation Acc 80.07 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.498 AVG Training Acc 80.29 % AVG Validation Acc 80.07 %\n",
      "Epoch:160/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.27 % AVG Validation Acc 80.07 %\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.30 % AVG Validation Acc 80.07 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.498 AVG Training Acc 80.29 % AVG Validation Acc 80.07 %\n",
      "Epoch:190/200 AVG Training Loss:0.488 AVG Validation Loss:0.498 AVG Training Acc 80.24 % AVG Validation Acc 80.07 %\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.498 AVG Training Acc 80.25 % AVG Validation Acc 80.07 %\n",
      "Split 182\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39ca2f69a4394fafb2dde88fc42b3249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.16 % AVG Validation Acc 80.25 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.27 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.34 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.23 % AVG Validation Acc 80.25 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.29 % AVG Validation Acc 80.25 %\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.31 % AVG Validation Acc 80.25 %\n",
      "Epoch:100/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.30 % AVG Validation Acc 80.25 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.26 % AVG Validation Acc 80.25 %\n",
      "Epoch:120/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.25 % AVG Validation Acc 80.25 %\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.29 % AVG Validation Acc 80.25 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.28 % AVG Validation Acc 80.25 %\n",
      "Epoch:150/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.21 % AVG Validation Acc 80.25 %\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.33 % AVG Validation Acc 80.25 %\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.32 % AVG Validation Acc 80.25 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.24 % AVG Validation Acc 80.25 %\n",
      "Epoch:190/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.29 % AVG Validation Acc 80.25 %\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.29 % AVG Validation Acc 80.25 %\n",
      "Split 183\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e140973b92e543e49f1ab53039f111ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.503 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.500 AVG Training Acc 80.18 % AVG Validation Acc 80.16 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.27 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.40 % AVG Validation Acc 79.98 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.494 AVG Training Acc 80.57 % AVG Validation Acc 79.98 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.494 AVG Training Acc 80.52 % AVG Validation Acc 79.80 %\n",
      "Epoch:70/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.60 % AVG Validation Acc 79.62 %\n",
      "Epoch:80/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.52 % AVG Validation Acc 79.62 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.61 % AVG Validation Acc 79.62 %\n",
      "Epoch:100/200 AVG Training Loss:0.483 AVG Validation Loss:0.495 AVG Training Acc 80.64 % AVG Validation Acc 79.71 %\n",
      "Epoch:110/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.63 % AVG Validation Acc 79.62 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.54 % AVG Validation Acc 79.53 %\n",
      "Epoch:130/200 AVG Training Loss:0.483 AVG Validation Loss:0.495 AVG Training Acc 80.67 % AVG Validation Acc 79.71 %\n",
      "Epoch:140/200 AVG Training Loss:0.483 AVG Validation Loss:0.495 AVG Training Acc 80.61 % AVG Validation Acc 79.62 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.483 AVG Validation Loss:0.495 AVG Training Acc 80.62 % AVG Validation Acc 79.71 %\n",
      "Epoch:160/200 AVG Training Loss:0.483 AVG Validation Loss:0.495 AVG Training Acc 80.70 % AVG Validation Acc 79.53 %\n",
      "Epoch:170/200 AVG Training Loss:0.483 AVG Validation Loss:0.496 AVG Training Acc 80.63 % AVG Validation Acc 79.53 %\n",
      "Epoch:180/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.54 % AVG Validation Acc 79.62 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.66 % AVG Validation Acc 79.62 %\n",
      "Epoch:200/200 AVG Training Loss:0.483 AVG Validation Loss:0.494 AVG Training Acc 80.68 % AVG Validation Acc 79.62 %\n",
      "Split 184\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b350386db76a4041803d2cc956fb51b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.498 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.24 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.46 % AVG Validation Acc 80.16 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.491 AVG Training Acc 80.54 % AVG Validation Acc 80.07 %\n",
      "Epoch:60/200 AVG Training Loss:0.478 AVG Validation Loss:0.500 AVG Training Acc 80.86 % AVG Validation Acc 79.62 %\n",
      "Epoch:70/200 AVG Training Loss:0.475 AVG Validation Loss:0.502 AVG Training Acc 81.10 % AVG Validation Acc 79.53 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.471 AVG Validation Loss:0.504 AVG Training Acc 81.31 % AVG Validation Acc 79.44 %\n",
      "Epoch:90/200 AVG Training Loss:0.471 AVG Validation Loss:0.502 AVG Training Acc 81.40 % AVG Validation Acc 79.44 %\n",
      "Epoch:100/200 AVG Training Loss:0.469 AVG Validation Loss:0.504 AVG Training Acc 81.59 % AVG Validation Acc 79.35 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.469 AVG Validation Loss:0.505 AVG Training Acc 81.54 % AVG Validation Acc 79.44 %\n",
      "Epoch:120/200 AVG Training Loss:0.469 AVG Validation Loss:0.505 AVG Training Acc 81.50 % AVG Validation Acc 79.26 %\n",
      "Epoch:130/200 AVG Training Loss:0.469 AVG Validation Loss:0.504 AVG Training Acc 81.53 % AVG Validation Acc 79.26 %\n",
      "Epoch:140/200 AVG Training Loss:0.469 AVG Validation Loss:0.502 AVG Training Acc 81.57 % AVG Validation Acc 79.44 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.469 AVG Validation Loss:0.505 AVG Training Acc 81.54 % AVG Validation Acc 79.44 %\n",
      "Epoch:160/200 AVG Training Loss:0.470 AVG Validation Loss:0.504 AVG Training Acc 81.46 % AVG Validation Acc 79.35 %\n",
      "Epoch:170/200 AVG Training Loss:0.469 AVG Validation Loss:0.504 AVG Training Acc 81.45 % AVG Validation Acc 79.35 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.469 AVG Validation Loss:0.504 AVG Training Acc 81.48 % AVG Validation Acc 79.35 %\n",
      "Epoch:190/200 AVG Training Loss:0.467 AVG Validation Loss:0.506 AVG Training Acc 81.60 % AVG Validation Acc 79.17 %\n",
      "Epoch:200/200 AVG Training Loss:0.468 AVG Validation Loss:0.503 AVG Training Acc 81.52 % AVG Validation Acc 79.44 %\n",
      "Split 185\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f56ffb8a61864aa78d739927d08c5b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.12 % AVG Validation Acc 80.07 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.30 % AVG Validation Acc 79.89 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.44 % AVG Validation Acc 79.89 %\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.48 % AVG Validation Acc 80.07 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.485 AVG Validation Loss:0.499 AVG Training Acc 80.57 % AVG Validation Acc 79.89 %\n",
      "Epoch:70/200 AVG Training Loss:0.486 AVG Validation Loss:0.500 AVG Training Acc 80.36 % AVG Validation Acc 79.80 %\n",
      "Epoch:80/200 AVG Training Loss:0.485 AVG Validation Loss:0.494 AVG Training Acc 80.53 % AVG Validation Acc 79.80 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.55 % AVG Validation Acc 79.80 %\n",
      "Epoch:100/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.49 % AVG Validation Acc 79.71 %\n",
      "Epoch:110/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.55 % AVG Validation Acc 79.89 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.484 AVG Validation Loss:0.502 AVG Training Acc 80.60 % AVG Validation Acc 79.71 %\n",
      "Epoch:130/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.56 % AVG Validation Acc 79.89 %\n",
      "Epoch:140/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.50 % AVG Validation Acc 79.80 %\n",
      "Epoch:150/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.56 % AVG Validation Acc 79.89 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.48 % AVG Validation Acc 79.89 %\n",
      "Epoch:170/200 AVG Training Loss:0.484 AVG Validation Loss:0.502 AVG Training Acc 80.53 % AVG Validation Acc 79.80 %\n",
      "Epoch:180/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.60 % AVG Validation Acc 79.71 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.54 % AVG Validation Acc 79.89 %\n",
      "Epoch:200/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.59 % AVG Validation Acc 79.71 %\n",
      "Split 186\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b8b63e7f29347789f2e8b8d323c0e69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.498 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.34 % AVG Validation Acc 79.78 %\n",
      "Epoch:50/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.56 % AVG Validation Acc 79.69 %\n",
      "Epoch:60/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.58 % AVG Validation Acc 79.60 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.481 AVG Validation Loss:0.498 AVG Training Acc 80.66 % AVG Validation Acc 79.78 %\n",
      "Epoch:80/200 AVG Training Loss:0.480 AVG Validation Loss:0.499 AVG Training Acc 80.55 % AVG Validation Acc 79.60 %\n",
      "Epoch:90/200 AVG Training Loss:0.479 AVG Validation Loss:0.502 AVG Training Acc 80.82 % AVG Validation Acc 79.60 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.479 AVG Validation Loss:0.503 AVG Training Acc 80.57 % AVG Validation Acc 79.51 %\n",
      "Epoch:110/200 AVG Training Loss:0.479 AVG Validation Loss:0.503 AVG Training Acc 80.76 % AVG Validation Acc 79.51 %\n",
      "Epoch:120/200 AVG Training Loss:0.480 AVG Validation Loss:0.504 AVG Training Acc 80.75 % AVG Validation Acc 79.51 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.480 AVG Validation Loss:0.503 AVG Training Acc 80.78 % AVG Validation Acc 79.51 %\n",
      "Epoch:140/200 AVG Training Loss:0.480 AVG Validation Loss:0.504 AVG Training Acc 80.66 % AVG Validation Acc 79.51 %\n",
      "Epoch:150/200 AVG Training Loss:0.479 AVG Validation Loss:0.503 AVG Training Acc 80.81 % AVG Validation Acc 79.51 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.479 AVG Validation Loss:0.504 AVG Training Acc 80.68 % AVG Validation Acc 79.51 %\n",
      "Epoch:170/200 AVG Training Loss:0.480 AVG Validation Loss:0.503 AVG Training Acc 80.60 % AVG Validation Acc 79.51 %\n",
      "Epoch:180/200 AVG Training Loss:0.479 AVG Validation Loss:0.503 AVG Training Acc 80.68 % AVG Validation Acc 79.51 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.480 AVG Validation Loss:0.503 AVG Training Acc 80.73 % AVG Validation Acc 79.51 %\n",
      "Epoch:200/200 AVG Training Loss:0.480 AVG Validation Loss:0.503 AVG Training Acc 80.73 % AVG Validation Acc 79.51 %\n",
      "Split 187\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69e4998c3c624733815d1e4fe1a410e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.493 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.492 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.486 AVG Training Acc 80.39 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.484 AVG Validation Loss:0.487 AVG Training Acc 80.51 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.487 AVG Training Acc 80.55 % AVG Validation Acc 80.23 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.481 AVG Validation Loss:0.488 AVG Training Acc 80.66 % AVG Validation Acc 80.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.481 AVG Validation Loss:0.488 AVG Training Acc 80.68 % AVG Validation Acc 80.05 %\n",
      "Epoch:90/200 AVG Training Loss:0.480 AVG Validation Loss:0.488 AVG Training Acc 80.66 % AVG Validation Acc 80.05 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.480 AVG Validation Loss:0.488 AVG Training Acc 80.73 % AVG Validation Acc 80.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.480 AVG Validation Loss:0.488 AVG Training Acc 80.75 % AVG Validation Acc 80.14 %\n",
      "Epoch:120/200 AVG Training Loss:0.480 AVG Validation Loss:0.488 AVG Training Acc 80.72 % AVG Validation Acc 80.14 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.481 AVG Validation Loss:0.488 AVG Training Acc 80.63 % AVG Validation Acc 80.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.480 AVG Validation Loss:0.488 AVG Training Acc 80.75 % AVG Validation Acc 80.14 %\n",
      "Epoch:150/200 AVG Training Loss:0.479 AVG Validation Loss:0.488 AVG Training Acc 80.71 % AVG Validation Acc 80.05 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.481 AVG Validation Loss:0.488 AVG Training Acc 80.61 % AVG Validation Acc 80.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.479 AVG Validation Loss:0.488 AVG Training Acc 80.67 % AVG Validation Acc 80.05 %\n",
      "Epoch:180/200 AVG Training Loss:0.480 AVG Validation Loss:0.488 AVG Training Acc 80.71 % AVG Validation Acc 80.05 %\n",
      "Epoch:190/200 AVG Training Loss:0.480 AVG Validation Loss:0.488 AVG Training Acc 80.63 % AVG Validation Acc 80.05 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.480 AVG Validation Loss:0.488 AVG Training Acc 80.69 % AVG Validation Acc 80.14 %\n",
      "Split 188\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "447d62b24d834b448219e856f95305b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.22 % AVG Validation Acc 80.23 %\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.32 % AVG Validation Acc 80.32 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.485 AVG Validation Loss:0.490 AVG Training Acc 80.38 % AVG Validation Acc 80.23 %\n",
      "Epoch:70/200 AVG Training Loss:0.481 AVG Validation Loss:0.492 AVG Training Acc 80.49 % AVG Validation Acc 80.23 %\n",
      "Epoch:80/200 AVG Training Loss:0.479 AVG Validation Loss:0.493 AVG Training Acc 80.54 % AVG Validation Acc 80.32 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.478 AVG Validation Loss:0.495 AVG Training Acc 80.69 % AVG Validation Acc 80.32 %\n",
      "Epoch:100/200 AVG Training Loss:0.478 AVG Validation Loss:0.496 AVG Training Acc 80.57 % AVG Validation Acc 80.23 %\n",
      "Epoch:110/200 AVG Training Loss:0.478 AVG Validation Loss:0.495 AVG Training Acc 80.61 % AVG Validation Acc 80.23 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.479 AVG Validation Loss:0.495 AVG Training Acc 80.56 % AVG Validation Acc 80.32 %\n",
      "Epoch:130/200 AVG Training Loss:0.477 AVG Validation Loss:0.496 AVG Training Acc 80.70 % AVG Validation Acc 80.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.478 AVG Validation Loss:0.497 AVG Training Acc 80.65 % AVG Validation Acc 80.14 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.478 AVG Validation Loss:0.495 AVG Training Acc 80.65 % AVG Validation Acc 80.32 %\n",
      "Epoch:160/200 AVG Training Loss:0.478 AVG Validation Loss:0.495 AVG Training Acc 80.68 % AVG Validation Acc 80.32 %\n",
      "Epoch:170/200 AVG Training Loss:0.478 AVG Validation Loss:0.497 AVG Training Acc 80.69 % AVG Validation Acc 80.23 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.477 AVG Validation Loss:0.495 AVG Training Acc 80.66 % AVG Validation Acc 80.23 %\n",
      "Epoch:190/200 AVG Training Loss:0.478 AVG Validation Loss:0.496 AVG Training Acc 80.72 % AVG Validation Acc 80.32 %\n",
      "Epoch:200/200 AVG Training Loss:0.477 AVG Validation Loss:0.494 AVG Training Acc 80.69 % AVG Validation Acc 80.23 %\n",
      "Split 189\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbceabb4cebd41eaa0821a5b00659208",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.25 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.26 % AVG Validation Acc 80.32 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.30 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.32 % AVG Validation Acc 79.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.35 % AVG Validation Acc 79.87 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.31 % AVG Validation Acc 79.87 %\n",
      "Epoch:100/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.30 % AVG Validation Acc 79.96 %\n",
      "Epoch:110/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.35 % AVG Validation Acc 79.96 %\n",
      "Epoch:120/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.32 % AVG Validation Acc 79.87 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.32 % AVG Validation Acc 79.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.26 % AVG Validation Acc 79.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.37 % AVG Validation Acc 79.87 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.37 % AVG Validation Acc 79.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.35 % AVG Validation Acc 79.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.32 % AVG Validation Acc 79.87 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.31 % AVG Validation Acc 79.96 %\n",
      "Epoch:200/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.38 % AVG Validation Acc 79.87 %\n",
      "Split 190\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b445f3f6f424d25b882094b9c45445d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.500 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.501 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.497 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.29 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.40 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.484 AVG Validation Loss:0.499 AVG Training Acc 80.46 % AVG Validation Acc 80.23 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.482 AVG Validation Loss:0.505 AVG Training Acc 80.54 % AVG Validation Acc 80.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.482 AVG Validation Loss:0.504 AVG Training Acc 80.52 % AVG Validation Acc 80.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.481 AVG Validation Loss:0.504 AVG Training Acc 80.64 % AVG Validation Acc 80.14 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.480 AVG Validation Loss:0.504 AVG Training Acc 80.73 % AVG Validation Acc 80.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.480 AVG Validation Loss:0.504 AVG Training Acc 80.63 % AVG Validation Acc 80.05 %\n",
      "Epoch:120/200 AVG Training Loss:0.480 AVG Validation Loss:0.504 AVG Training Acc 80.63 % AVG Validation Acc 80.23 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.480 AVG Validation Loss:0.504 AVG Training Acc 80.60 % AVG Validation Acc 80.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.480 AVG Validation Loss:0.505 AVG Training Acc 80.69 % AVG Validation Acc 79.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.479 AVG Validation Loss:0.504 AVG Training Acc 80.70 % AVG Validation Acc 80.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.480 AVG Validation Loss:0.504 AVG Training Acc 80.71 % AVG Validation Acc 80.05 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.480 AVG Validation Loss:0.504 AVG Training Acc 80.73 % AVG Validation Acc 80.05 %\n",
      "Epoch:180/200 AVG Training Loss:0.479 AVG Validation Loss:0.505 AVG Training Acc 80.72 % AVG Validation Acc 80.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.480 AVG Validation Loss:0.504 AVG Training Acc 80.66 % AVG Validation Acc 80.14 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.480 AVG Validation Loss:0.504 AVG Training Acc 80.70 % AVG Validation Acc 80.14 %\n",
      "Split 191\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59244c4ee8b347db96ed627c8da7ef3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.499 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.16 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.25 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.30 % AVG Validation Acc 80.07 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.38 % AVG Validation Acc 80.34 %\n",
      "Epoch:70/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.41 % AVG Validation Acc 80.25 %\n",
      "Epoch:80/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.40 % AVG Validation Acc 80.25 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.35 % AVG Validation Acc 80.25 %\n",
      "Epoch:100/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.32 % AVG Validation Acc 79.98 %\n",
      "Epoch:110/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.49 % AVG Validation Acc 80.25 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.39 % AVG Validation Acc 80.25 %\n",
      "Epoch:130/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.44 % AVG Validation Acc 80.34 %\n",
      "Epoch:140/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.40 % AVG Validation Acc 80.16 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.41 % AVG Validation Acc 80.16 %\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.48 % AVG Validation Acc 80.16 %\n",
      "Epoch:170/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.37 % AVG Validation Acc 80.07 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.36 % AVG Validation Acc 80.16 %\n",
      "Epoch:190/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.38 % AVG Validation Acc 80.16 %\n",
      "Epoch:200/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.38 % AVG Validation Acc 80.25 %\n",
      "Split 192\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1c294e9b8fc4d4895bd85c9537245c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.499 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 80.07 %\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.18 % AVG Validation Acc 80.07 %\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 80.07 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.18 % AVG Validation Acc 80.07 %\n",
      "Epoch:90/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 80.07 %\n",
      "Epoch:100/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 80.07 %\n",
      "Epoch:120/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.21 % AVG Validation Acc 80.07 %\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.21 % AVG Validation Acc 80.07 %\n",
      "Epoch:140/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.24 % AVG Validation Acc 80.07 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.25 % AVG Validation Acc 80.07 %\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.25 % AVG Validation Acc 80.07 %\n",
      "Epoch:170/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.20 % AVG Validation Acc 80.07 %\n",
      "Epoch:190/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 80.07 %\n",
      "Epoch:200/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.20 % AVG Validation Acc 80.07 %\n",
      "Split 193\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fe75c7259eb4049b4b3a18415e118cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.11 % AVG Validation Acc 80.07 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.33 % AVG Validation Acc 79.98 %\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.39 % AVG Validation Acc 79.89 %\n",
      "Epoch:60/200 AVG Training Loss:0.485 AVG Validation Loss:0.499 AVG Training Acc 80.48 % AVG Validation Acc 79.71 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.484 AVG Validation Loss:0.501 AVG Training Acc 80.49 % AVG Validation Acc 79.35 %\n",
      "Epoch:80/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.48 % AVG Validation Acc 79.35 %\n",
      "Epoch:90/200 AVG Training Loss:0.484 AVG Validation Loss:0.502 AVG Training Acc 80.42 % AVG Validation Acc 79.44 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.483 AVG Validation Loss:0.503 AVG Training Acc 80.48 % AVG Validation Acc 79.35 %\n",
      "Epoch:110/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.48 % AVG Validation Acc 79.35 %\n",
      "Epoch:120/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.39 % AVG Validation Acc 79.35 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.483 AVG Validation Loss:0.503 AVG Training Acc 80.61 % AVG Validation Acc 79.35 %\n",
      "Epoch:140/200 AVG Training Loss:0.483 AVG Validation Loss:0.503 AVG Training Acc 80.56 % AVG Validation Acc 79.44 %\n",
      "Epoch:150/200 AVG Training Loss:0.483 AVG Validation Loss:0.503 AVG Training Acc 80.47 % AVG Validation Acc 79.35 %\n",
      "Epoch:160/200 AVG Training Loss:0.484 AVG Validation Loss:0.502 AVG Training Acc 80.49 % AVG Validation Acc 79.35 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.483 AVG Validation Loss:0.502 AVG Training Acc 80.48 % AVG Validation Acc 79.35 %\n",
      "Epoch:180/200 AVG Training Loss:0.482 AVG Validation Loss:0.503 AVG Training Acc 80.47 % AVG Validation Acc 79.35 %\n",
      "Epoch:190/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.57 % AVG Validation Acc 79.35 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.483 AVG Validation Loss:0.502 AVG Training Acc 80.49 % AVG Validation Acc 79.35 %\n",
      "Split 194\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84d356b4bb994c238fc059ca1bdf8d65",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.22 % AVG Validation Acc 80.25 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.29 % AVG Validation Acc 80.34 %\n",
      "Epoch:50/200 AVG Training Loss:0.492 AVG Validation Loss:0.490 AVG Training Acc 80.23 % AVG Validation Acc 80.43 %\n",
      "Epoch:60/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.57 % AVG Validation Acc 80.16 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:70/200 AVG Training Loss:0.484 AVG Validation Loss:0.492 AVG Training Acc 80.51 % AVG Validation Acc 80.25 %\n",
      "Epoch:80/200 AVG Training Loss:0.481 AVG Validation Loss:0.504 AVG Training Acc 80.74 % AVG Validation Acc 80.16 %\n",
      "Epoch:90/200 AVG Training Loss:0.476 AVG Validation Loss:0.505 AVG Training Acc 80.91 % AVG Validation Acc 80.16 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.476 AVG Validation Loss:0.511 AVG Training Acc 80.82 % AVG Validation Acc 80.07 %\n",
      "Epoch:110/200 AVG Training Loss:0.475 AVG Validation Loss:0.511 AVG Training Acc 81.04 % AVG Validation Acc 80.16 %\n",
      "Epoch:120/200 AVG Training Loss:0.472 AVG Validation Loss:0.510 AVG Training Acc 81.09 % AVG Validation Acc 80.43 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.471 AVG Validation Loss:0.512 AVG Training Acc 81.07 % AVG Validation Acc 80.25 %\n",
      "Epoch:140/200 AVG Training Loss:0.473 AVG Validation Loss:0.514 AVG Training Acc 81.06 % AVG Validation Acc 80.25 %\n",
      "Epoch:150/200 AVG Training Loss:0.472 AVG Validation Loss:0.511 AVG Training Acc 81.08 % AVG Validation Acc 80.25 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.472 AVG Validation Loss:0.515 AVG Training Acc 81.18 % AVG Validation Acc 80.25 %\n",
      "Epoch:170/200 AVG Training Loss:0.471 AVG Validation Loss:0.511 AVG Training Acc 81.20 % AVG Validation Acc 80.25 %\n",
      "Epoch:180/200 AVG Training Loss:0.471 AVG Validation Loss:0.511 AVG Training Acc 81.17 % AVG Validation Acc 80.25 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.472 AVG Validation Loss:0.511 AVG Training Acc 81.21 % AVG Validation Acc 80.34 %\n",
      "Epoch:200/200 AVG Training Loss:0.471 AVG Validation Loss:0.511 AVG Training Acc 81.23 % AVG Validation Acc 80.25 %\n",
      "Split 195\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9885085f60b94863b5aaf1c2f6030764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.493 AVG Training Acc 80.12 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.491 AVG Training Acc 80.16 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.496 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.495 AVG Validation Loss:0.491 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch:60/200 AVG Training Loss:0.493 AVG Validation Loss:0.489 AVG Training Acc 80.18 % AVG Validation Acc 80.07 %\n",
      "Epoch:70/200 AVG Training Loss:0.492 AVG Validation Loss:0.488 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch:80/200 AVG Training Loss:0.491 AVG Validation Loss:0.490 AVG Training Acc 80.22 % AVG Validation Acc 80.07 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.18 % AVG Validation Acc 80.07 %\n",
      "Epoch:100/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.19 % AVG Validation Acc 80.07 %\n",
      "Epoch:110/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.22 % AVG Validation Acc 80.07 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.21 % AVG Validation Acc 80.07 %\n",
      "Epoch:130/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.20 % AVG Validation Acc 80.07 %\n",
      "Epoch:140/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.25 % AVG Validation Acc 80.07 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.490 AVG Validation Loss:0.489 AVG Training Acc 80.20 % AVG Validation Acc 80.07 %\n",
      "Epoch:160/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.19 % AVG Validation Acc 80.07 %\n",
      "Epoch:170/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.23 % AVG Validation Acc 80.07 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch:190/200 AVG Training Loss:0.490 AVG Validation Loss:0.489 AVG Training Acc 80.16 % AVG Validation Acc 80.07 %\n",
      "Epoch:200/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.24 % AVG Validation Acc 80.07 %\n",
      "Split 196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8090cf9467e4c368dbf4c3303c44137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.24 % AVG Validation Acc 80.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.23 % AVG Validation Acc 80.14 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.24 % AVG Validation Acc 80.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.23 % AVG Validation Acc 80.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.23 % AVG Validation Acc 80.14 %\n",
      "Split 197\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adcd80d2d3a844a1a44e8835fd7ffa78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.492 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.491 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.10 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.23 % AVG Validation Acc 80.23 %\n",
      "Epoch:60/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.33 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.485 AVG Validation Loss:0.489 AVG Training Acc 80.45 % AVG Validation Acc 80.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.486 AVG Validation Loss:0.489 AVG Training Acc 80.41 % AVG Validation Acc 80.05 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.485 AVG Validation Loss:0.489 AVG Training Acc 80.46 % AVG Validation Acc 80.05 %\n",
      "Epoch:100/200 AVG Training Loss:0.486 AVG Validation Loss:0.499 AVG Training Acc 80.38 % AVG Validation Acc 79.96 %\n",
      "Epoch:110/200 AVG Training Loss:0.485 AVG Validation Loss:0.489 AVG Training Acc 80.49 % AVG Validation Acc 80.14 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.486 AVG Validation Loss:0.489 AVG Training Acc 80.40 % AVG Validation Acc 80.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.484 AVG Validation Loss:0.489 AVG Training Acc 80.46 % AVG Validation Acc 80.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.486 AVG Validation Loss:0.489 AVG Training Acc 80.40 % AVG Validation Acc 80.05 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.489 AVG Training Acc 80.47 % AVG Validation Acc 80.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.489 AVG Training Acc 80.42 % AVG Validation Acc 80.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.485 AVG Validation Loss:0.489 AVG Training Acc 80.50 % AVG Validation Acc 80.14 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.486 AVG Validation Loss:0.489 AVG Training Acc 80.39 % AVG Validation Acc 80.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.485 AVG Validation Loss:0.489 AVG Training Acc 80.37 % AVG Validation Acc 80.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.485 AVG Validation Loss:0.489 AVG Training Acc 80.44 % AVG Validation Acc 80.14 %\n",
      "Split 198\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a18cfd3479394bb9b002c410444820cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.498 AVG Training Acc 80.08 % AVG Validation Acc 80.14 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.20 % AVG Validation Acc 79.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.27 % AVG Validation Acc 79.96 %\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.35 % AVG Validation Acc 80.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.36 % AVG Validation Acc 79.87 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.40 % AVG Validation Acc 79.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.46 % AVG Validation Acc 79.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.484 AVG Validation Loss:0.498 AVG Training Acc 80.46 % AVG Validation Acc 79.96 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.484 AVG Validation Loss:0.498 AVG Training Acc 80.52 % AVG Validation Acc 79.96 %\n",
      "Epoch:110/200 AVG Training Loss:0.484 AVG Validation Loss:0.498 AVG Training Acc 80.45 % AVG Validation Acc 79.96 %\n",
      "Epoch:120/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.42 % AVG Validation Acc 79.96 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.46 % AVG Validation Acc 79.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.484 AVG Validation Loss:0.498 AVG Training Acc 80.51 % AVG Validation Acc 79.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.484 AVG Validation Loss:0.498 AVG Training Acc 80.42 % AVG Validation Acc 79.96 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.484 AVG Validation Loss:0.498 AVG Training Acc 80.49 % AVG Validation Acc 79.96 %\n",
      "Epoch:170/200 AVG Training Loss:0.484 AVG Validation Loss:0.498 AVG Training Acc 80.45 % AVG Validation Acc 79.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.484 AVG Validation Loss:0.498 AVG Training Acc 80.54 % AVG Validation Acc 79.96 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.484 AVG Validation Loss:0.498 AVG Training Acc 80.42 % AVG Validation Acc 79.96 %\n",
      "Epoch:200/200 AVG Training Loss:0.484 AVG Validation Loss:0.498 AVG Training Acc 80.45 % AVG Validation Acc 79.96 %\n",
      "Split 199\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b79d57a1e24089be74f70c80f13c40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.500 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.500 AVG Training Acc 80.18 % AVG Validation Acc 80.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.505 AVG Training Acc 80.27 % AVG Validation Acc 79.87 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.509 AVG Training Acc 80.31 % AVG Validation Acc 79.96 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.515 AVG Training Acc 80.37 % AVG Validation Acc 79.96 %\n",
      "Epoch:60/200 AVG Training Loss:0.486 AVG Validation Loss:0.515 AVG Training Acc 80.45 % AVG Validation Acc 79.96 %\n",
      "Epoch:70/200 AVG Training Loss:0.486 AVG Validation Loss:0.516 AVG Training Acc 80.44 % AVG Validation Acc 79.96 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.486 AVG Validation Loss:0.514 AVG Training Acc 80.45 % AVG Validation Acc 79.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.486 AVG Validation Loss:0.515 AVG Training Acc 80.36 % AVG Validation Acc 79.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.486 AVG Validation Loss:0.517 AVG Training Acc 80.41 % AVG Validation Acc 79.87 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.486 AVG Validation Loss:0.516 AVG Training Acc 80.53 % AVG Validation Acc 79.96 %\n",
      "Epoch:120/200 AVG Training Loss:0.486 AVG Validation Loss:0.517 AVG Training Acc 80.47 % AVG Validation Acc 79.96 %\n",
      "Epoch:130/200 AVG Training Loss:0.485 AVG Validation Loss:0.516 AVG Training Acc 80.38 % AVG Validation Acc 79.96 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.485 AVG Validation Loss:0.517 AVG Training Acc 80.45 % AVG Validation Acc 79.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.517 AVG Training Acc 80.51 % AVG Validation Acc 79.87 %\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.518 AVG Training Acc 80.47 % AVG Validation Acc 79.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.486 AVG Validation Loss:0.516 AVG Training Acc 80.41 % AVG Validation Acc 79.96 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.486 AVG Validation Loss:0.516 AVG Training Acc 80.42 % AVG Validation Acc 79.96 %\n",
      "Epoch:190/200 AVG Training Loss:0.486 AVG Validation Loss:0.517 AVG Training Acc 80.42 % AVG Validation Acc 79.78 %\n",
      "Epoch:200/200 AVG Training Loss:0.486 AVG Validation Loss:0.516 AVG Training Acc 80.38 % AVG Validation Acc 79.96 %\n",
      "Split 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "76b278eb50254a4db955968907215f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.17 % AVG Validation Acc 79.96 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.25 % AVG Validation Acc 79.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.501 AVG Training Acc 80.40 % AVG Validation Acc 79.87 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.506 AVG Training Acc 80.46 % AVG Validation Acc 79.69 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.509 AVG Training Acc 80.62 % AVG Validation Acc 79.78 %\n",
      "Epoch:70/200 AVG Training Loss:0.482 AVG Validation Loss:0.510 AVG Training Acc 80.63 % AVG Validation Acc 79.60 %\n",
      "Epoch:80/200 AVG Training Loss:0.483 AVG Validation Loss:0.511 AVG Training Acc 80.57 % AVG Validation Acc 79.60 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.482 AVG Validation Loss:0.511 AVG Training Acc 80.65 % AVG Validation Acc 79.60 %\n",
      "Epoch:100/200 AVG Training Loss:0.483 AVG Validation Loss:0.511 AVG Training Acc 80.63 % AVG Validation Acc 79.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.482 AVG Validation Loss:0.511 AVG Training Acc 80.67 % AVG Validation Acc 79.60 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.483 AVG Validation Loss:0.512 AVG Training Acc 80.60 % AVG Validation Acc 79.60 %\n",
      "Epoch:130/200 AVG Training Loss:0.483 AVG Validation Loss:0.512 AVG Training Acc 80.59 % AVG Validation Acc 79.60 %\n",
      "Epoch:140/200 AVG Training Loss:0.482 AVG Validation Loss:0.511 AVG Training Acc 80.68 % AVG Validation Acc 79.60 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.483 AVG Validation Loss:0.512 AVG Training Acc 80.61 % AVG Validation Acc 79.60 %\n",
      "Epoch:160/200 AVG Training Loss:0.482 AVG Validation Loss:0.512 AVG Training Acc 80.65 % AVG Validation Acc 79.60 %\n",
      "Epoch:170/200 AVG Training Loss:0.482 AVG Validation Loss:0.511 AVG Training Acc 80.66 % AVG Validation Acc 79.60 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.482 AVG Validation Loss:0.511 AVG Training Acc 80.65 % AVG Validation Acc 79.60 %\n",
      "Epoch:190/200 AVG Training Loss:0.484 AVG Validation Loss:0.512 AVG Training Acc 80.49 % AVG Validation Acc 79.60 %\n",
      "Epoch:200/200 AVG Training Loss:0.483 AVG Validation Loss:0.512 AVG Training Acc 80.61 % AVG Validation Acc 79.60 %\n",
      "Split 201\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0956d0c0d0df4f66bcb9192ad0fc9173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.10 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.26 % AVG Validation Acc 79.80 %\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.502 AVG Training Acc 80.38 % AVG Validation Acc 79.71 %\n",
      "Epoch:60/200 AVG Training Loss:0.484 AVG Validation Loss:0.504 AVG Training Acc 80.48 % AVG Validation Acc 79.71 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.483 AVG Validation Loss:0.505 AVG Training Acc 80.46 % AVG Validation Acc 79.62 %\n",
      "Epoch:80/200 AVG Training Loss:0.484 AVG Validation Loss:0.506 AVG Training Acc 80.55 % AVG Validation Acc 79.53 %\n",
      "Epoch:90/200 AVG Training Loss:0.482 AVG Validation Loss:0.508 AVG Training Acc 80.49 % AVG Validation Acc 79.53 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.483 AVG Validation Loss:0.507 AVG Training Acc 80.50 % AVG Validation Acc 79.53 %\n",
      "Epoch:110/200 AVG Training Loss:0.482 AVG Validation Loss:0.507 AVG Training Acc 80.55 % AVG Validation Acc 79.53 %\n",
      "Epoch:120/200 AVG Training Loss:0.482 AVG Validation Loss:0.507 AVG Training Acc 80.55 % AVG Validation Acc 79.44 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.482 AVG Validation Loss:0.507 AVG Training Acc 80.52 % AVG Validation Acc 79.44 %\n",
      "Epoch:140/200 AVG Training Loss:0.483 AVG Validation Loss:0.508 AVG Training Acc 80.51 % AVG Validation Acc 79.44 %\n",
      "Epoch:150/200 AVG Training Loss:0.481 AVG Validation Loss:0.508 AVG Training Acc 80.55 % AVG Validation Acc 79.44 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.481 AVG Validation Loss:0.508 AVG Training Acc 80.56 % AVG Validation Acc 79.44 %\n",
      "Epoch:170/200 AVG Training Loss:0.482 AVG Validation Loss:0.508 AVG Training Acc 80.51 % AVG Validation Acc 79.44 %\n",
      "Epoch:180/200 AVG Training Loss:0.482 AVG Validation Loss:0.508 AVG Training Acc 80.55 % AVG Validation Acc 79.44 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.482 AVG Validation Loss:0.508 AVG Training Acc 80.56 % AVG Validation Acc 79.44 %\n",
      "Epoch:200/200 AVG Training Loss:0.482 AVG Validation Loss:0.508 AVG Training Acc 80.49 % AVG Validation Acc 79.44 %\n",
      "Split 202\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89fa517c59c64cb0bcac59a0b808f6d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.12 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.13 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.25 % AVG Validation Acc 80.07 %\n",
      "Epoch:60/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.28 % AVG Validation Acc 79.89 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.486 AVG Validation Loss:0.499 AVG Training Acc 80.42 % AVG Validation Acc 79.80 %\n",
      "Epoch:80/200 AVG Training Loss:0.485 AVG Validation Loss:0.503 AVG Training Acc 80.44 % AVG Validation Acc 79.62 %\n",
      "Epoch:90/200 AVG Training Loss:0.485 AVG Validation Loss:0.500 AVG Training Acc 80.39 % AVG Validation Acc 79.71 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.485 AVG Validation Loss:0.501 AVG Training Acc 80.51 % AVG Validation Acc 79.62 %\n",
      "Epoch:110/200 AVG Training Loss:0.484 AVG Validation Loss:0.502 AVG Training Acc 80.46 % AVG Validation Acc 79.62 %\n",
      "Epoch:120/200 AVG Training Loss:0.485 AVG Validation Loss:0.502 AVG Training Acc 80.42 % AVG Validation Acc 79.62 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.485 AVG Validation Loss:0.503 AVG Training Acc 80.47 % AVG Validation Acc 79.62 %\n",
      "Epoch:140/200 AVG Training Loss:0.485 AVG Validation Loss:0.503 AVG Training Acc 80.36 % AVG Validation Acc 79.62 %\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.502 AVG Training Acc 80.43 % AVG Validation Acc 79.62 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.48 % AVG Validation Acc 79.62 %\n",
      "Epoch:170/200 AVG Training Loss:0.485 AVG Validation Loss:0.503 AVG Training Acc 80.36 % AVG Validation Acc 79.62 %\n",
      "Epoch:180/200 AVG Training Loss:0.485 AVG Validation Loss:0.503 AVG Training Acc 80.41 % AVG Validation Acc 79.62 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.55 % AVG Validation Acc 79.62 %\n",
      "Epoch:200/200 AVG Training Loss:0.485 AVG Validation Loss:0.503 AVG Training Acc 80.41 % AVG Validation Acc 79.62 %\n",
      "Split 203\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9297a84b76d54f8d9c87ed80cd6385ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.499 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.498 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.497 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.21 % AVG Validation Acc 80.25 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.42 % AVG Validation Acc 80.07 %\n",
      "Epoch:60/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.72 % AVG Validation Acc 79.98 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.478 AVG Validation Loss:0.499 AVG Training Acc 80.94 % AVG Validation Acc 79.89 %\n",
      "Epoch:80/200 AVG Training Loss:0.475 AVG Validation Loss:0.500 AVG Training Acc 80.86 % AVG Validation Acc 79.80 %\n",
      "Epoch:90/200 AVG Training Loss:0.475 AVG Validation Loss:0.501 AVG Training Acc 81.00 % AVG Validation Acc 79.71 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.474 AVG Validation Loss:0.501 AVG Training Acc 81.04 % AVG Validation Acc 79.71 %\n",
      "Epoch:110/200 AVG Training Loss:0.476 AVG Validation Loss:0.502 AVG Training Acc 80.90 % AVG Validation Acc 79.71 %\n",
      "Epoch:120/200 AVG Training Loss:0.475 AVG Validation Loss:0.501 AVG Training Acc 80.92 % AVG Validation Acc 79.80 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.476 AVG Validation Loss:0.502 AVG Training Acc 80.94 % AVG Validation Acc 79.71 %\n",
      "Epoch:140/200 AVG Training Loss:0.475 AVG Validation Loss:0.501 AVG Training Acc 81.08 % AVG Validation Acc 79.89 %\n",
      "Epoch:150/200 AVG Training Loss:0.476 AVG Validation Loss:0.501 AVG Training Acc 80.88 % AVG Validation Acc 79.71 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.477 AVG Validation Loss:0.501 AVG Training Acc 80.88 % AVG Validation Acc 79.80 %\n",
      "Epoch:170/200 AVG Training Loss:0.474 AVG Validation Loss:0.502 AVG Training Acc 81.03 % AVG Validation Acc 79.80 %\n",
      "Epoch:180/200 AVG Training Loss:0.476 AVG Validation Loss:0.500 AVG Training Acc 80.91 % AVG Validation Acc 79.89 %\n",
      "Epoch:190/200 AVG Training Loss:0.475 AVG Validation Loss:0.501 AVG Training Acc 80.94 % AVG Validation Acc 79.71 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.475 AVG Validation Loss:0.502 AVG Training Acc 81.05 % AVG Validation Acc 79.80 %\n",
      "Split 204\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79dd7e788b724a79b09baae0d1105ceb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.498 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.26 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.31 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.28 % AVG Validation Acc 80.16 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.36 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.35 % AVG Validation Acc 80.16 %\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.36 % AVG Validation Acc 80.16 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.44 % AVG Validation Acc 80.07 %\n",
      "Epoch:100/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.36 % AVG Validation Acc 80.07 %\n",
      "Epoch:110/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.37 % AVG Validation Acc 80.16 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.45 % AVG Validation Acc 80.07 %\n",
      "Epoch:130/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.38 % AVG Validation Acc 80.07 %\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.41 % AVG Validation Acc 80.16 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.43 % AVG Validation Acc 80.16 %\n",
      "Epoch:160/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.42 % AVG Validation Acc 80.07 %\n",
      "Epoch:170/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.33 % AVG Validation Acc 80.07 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.41 % AVG Validation Acc 80.07 %\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.41 % AVG Validation Acc 80.07 %\n",
      "Epoch:200/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.43 % AVG Validation Acc 80.16 %\n",
      "Split 205\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c28cd1512ea248ef8c3a42e04f0ee10f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.491 AVG Training Acc 80.12 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.486 AVG Training Acc 80.26 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.488 AVG Training Acc 80.36 % AVG Validation Acc 79.89 %\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.489 AVG Training Acc 80.48 % AVG Validation Acc 79.89 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.485 AVG Validation Loss:0.491 AVG Training Acc 80.48 % AVG Validation Acc 79.80 %\n",
      "Epoch:70/200 AVG Training Loss:0.485 AVG Validation Loss:0.492 AVG Training Acc 80.53 % AVG Validation Acc 79.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.485 AVG Validation Loss:0.492 AVG Training Acc 80.53 % AVG Validation Acc 79.98 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.484 AVG Validation Loss:0.492 AVG Training Acc 80.48 % AVG Validation Acc 80.07 %\n",
      "Epoch:100/200 AVG Training Loss:0.484 AVG Validation Loss:0.492 AVG Training Acc 80.50 % AVG Validation Acc 80.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.484 AVG Validation Loss:0.493 AVG Training Acc 80.59 % AVG Validation Acc 80.16 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.484 AVG Validation Loss:0.493 AVG Training Acc 80.53 % AVG Validation Acc 80.07 %\n",
      "Epoch:130/200 AVG Training Loss:0.484 AVG Validation Loss:0.493 AVG Training Acc 80.59 % AVG Validation Acc 80.07 %\n",
      "Epoch:140/200 AVG Training Loss:0.484 AVG Validation Loss:0.493 AVG Training Acc 80.45 % AVG Validation Acc 80.07 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.484 AVG Validation Loss:0.493 AVG Training Acc 80.62 % AVG Validation Acc 80.07 %\n",
      "Epoch:160/200 AVG Training Loss:0.484 AVG Validation Loss:0.493 AVG Training Acc 80.55 % AVG Validation Acc 80.07 %\n",
      "Epoch:170/200 AVG Training Loss:0.484 AVG Validation Loss:0.492 AVG Training Acc 80.60 % AVG Validation Acc 80.07 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.484 AVG Validation Loss:0.492 AVG Training Acc 80.59 % AVG Validation Acc 80.07 %\n",
      "Epoch:190/200 AVG Training Loss:0.484 AVG Validation Loss:0.493 AVG Training Acc 80.61 % AVG Validation Acc 79.98 %\n",
      "Epoch:200/200 AVG Training Loss:0.484 AVG Validation Loss:0.492 AVG Training Acc 80.44 % AVG Validation Acc 79.98 %\n",
      "Split 206\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bc407b081d4426281c0a4ec4cd03ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.23 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.24 % AVG Validation Acc 80.23 %\n",
      "Epoch:70/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.30 % AVG Validation Acc 80.05 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.41 % AVG Validation Acc 79.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.36 % AVG Validation Acc 79.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.40 % AVG Validation Acc 79.96 %\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.41 % AVG Validation Acc 79.96 %\n",
      "Epoch:120/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.34 % AVG Validation Acc 79.96 %\n",
      "Epoch:130/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.34 % AVG Validation Acc 79.96 %\n",
      "Epoch   134: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.47 % AVG Validation Acc 79.87 %\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.41 % AVG Validation Acc 79.87 %\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.47 % AVG Validation Acc 79.87 %\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.48 % AVG Validation Acc 79.87 %\n",
      "Epoch:180/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.47 % AVG Validation Acc 79.87 %\n",
      "Epoch:190/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.44 % AVG Validation Acc 79.87 %\n",
      "Epoch   196: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.38 % AVG Validation Acc 79.87 %\n",
      "Split 207\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb9d0238f35e4555a48d487e8762948e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 80.23 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.21 % AVG Validation Acc 80.23 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.30 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.35 % AVG Validation Acc 80.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.486 AVG Validation Loss:0.491 AVG Training Acc 80.45 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.485 AVG Validation Loss:0.490 AVG Training Acc 80.52 % AVG Validation Acc 80.42 %\n",
      "New Best Accuracy found: 80.78%\n",
      "Epoch: 76\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.482 AVG Validation Loss:0.490 AVG Training Acc 80.66 % AVG Validation Acc 80.69 %\n",
      "Epoch:90/200 AVG Training Loss:0.482 AVG Validation Loss:0.491 AVG Training Acc 80.65 % AVG Validation Acc 80.51 %\n",
      "Epoch:100/200 AVG Training Loss:0.482 AVG Validation Loss:0.490 AVG Training Acc 80.66 % AVG Validation Acc 80.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.481 AVG Validation Loss:0.490 AVG Training Acc 80.77 % AVG Validation Acc 80.51 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.480 AVG Validation Loss:0.490 AVG Training Acc 80.79 % AVG Validation Acc 80.60 %\n",
      "Epoch:130/200 AVG Training Loss:0.479 AVG Validation Loss:0.490 AVG Training Acc 80.74 % AVG Validation Acc 80.69 %\n",
      "Epoch:140/200 AVG Training Loss:0.480 AVG Validation Loss:0.489 AVG Training Acc 80.88 % AVG Validation Acc 80.69 %\n",
      "Epoch:150/200 AVG Training Loss:0.480 AVG Validation Loss:0.489 AVG Training Acc 80.77 % AVG Validation Acc 80.69 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.479 AVG Validation Loss:0.491 AVG Training Acc 80.83 % AVG Validation Acc 80.51 %\n",
      "Epoch:170/200 AVG Training Loss:0.480 AVG Validation Loss:0.490 AVG Training Acc 80.77 % AVG Validation Acc 80.51 %\n",
      "Epoch:180/200 AVG Training Loss:0.481 AVG Validation Loss:0.490 AVG Training Acc 80.82 % AVG Validation Acc 80.60 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.480 AVG Validation Loss:0.489 AVG Training Acc 80.73 % AVG Validation Acc 80.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.480 AVG Validation Loss:0.489 AVG Training Acc 80.75 % AVG Validation Acc 80.69 %\n",
      "Split 208\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "205392eed9284f6f80ba5dc5bb68e202",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.10 % AVG Validation Acc 80.14 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.29 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.28 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.33 % AVG Validation Acc 80.14 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.40 % AVG Validation Acc 80.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.39 % AVG Validation Acc 80.05 %\n",
      "Epoch:90/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.38 % AVG Validation Acc 80.05 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.42 % AVG Validation Acc 80.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.42 % AVG Validation Acc 80.05 %\n",
      "Epoch:120/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.39 % AVG Validation Acc 80.05 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.45 % AVG Validation Acc 80.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.46 % AVG Validation Acc 80.05 %\n",
      "Epoch:150/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.44 % AVG Validation Acc 80.05 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.40 % AVG Validation Acc 80.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.42 % AVG Validation Acc 80.05 %\n",
      "Epoch:180/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.42 % AVG Validation Acc 80.05 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.38 % AVG Validation Acc 80.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.42 % AVG Validation Acc 80.05 %\n",
      "Split 209\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac87964cdc00415cac26b37e71b6e9ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.492 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.30 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.513 AVG Training Acc 80.32 % AVG Validation Acc 79.78 %\n",
      "Epoch:60/200 AVG Training Loss:0.484 AVG Validation Loss:0.515 AVG Training Acc 80.46 % AVG Validation Acc 79.96 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.483 AVG Validation Loss:0.513 AVG Training Acc 80.56 % AVG Validation Acc 79.78 %\n",
      "Epoch:80/200 AVG Training Loss:0.483 AVG Validation Loss:0.512 AVG Training Acc 80.54 % AVG Validation Acc 79.69 %\n",
      "Epoch:90/200 AVG Training Loss:0.483 AVG Validation Loss:0.512 AVG Training Acc 80.60 % AVG Validation Acc 79.69 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.482 AVG Validation Loss:0.513 AVG Training Acc 80.62 % AVG Validation Acc 79.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.482 AVG Validation Loss:0.513 AVG Training Acc 80.62 % AVG Validation Acc 79.69 %\n",
      "Epoch:120/200 AVG Training Loss:0.482 AVG Validation Loss:0.513 AVG Training Acc 80.52 % AVG Validation Acc 79.69 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.483 AVG Validation Loss:0.513 AVG Training Acc 80.55 % AVG Validation Acc 79.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.482 AVG Validation Loss:0.513 AVG Training Acc 80.63 % AVG Validation Acc 79.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.482 AVG Validation Loss:0.513 AVG Training Acc 80.60 % AVG Validation Acc 79.78 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.482 AVG Validation Loss:0.514 AVG Training Acc 80.60 % AVG Validation Acc 79.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.482 AVG Validation Loss:0.514 AVG Training Acc 80.59 % AVG Validation Acc 79.78 %\n",
      "Epoch:180/200 AVG Training Loss:0.482 AVG Validation Loss:0.513 AVG Training Acc 80.52 % AVG Validation Acc 79.69 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.482 AVG Validation Loss:0.513 AVG Training Acc 80.52 % AVG Validation Acc 79.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.482 AVG Validation Loss:0.513 AVG Training Acc 80.58 % AVG Validation Acc 79.78 %\n",
      "Split 210\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c8264955ab943569b2535414272c979",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.497 AVG Training Acc 80.18 % AVG Validation Acc 79.96 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.502 AVG Training Acc 80.27 % AVG Validation Acc 79.78 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.502 AVG Training Acc 80.31 % AVG Validation Acc 79.69 %\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.503 AVG Training Acc 80.38 % AVG Validation Acc 79.87 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.486 AVG Validation Loss:0.502 AVG Training Acc 80.44 % AVG Validation Acc 79.78 %\n",
      "Epoch:70/200 AVG Training Loss:0.485 AVG Validation Loss:0.503 AVG Training Acc 80.44 % AVG Validation Acc 79.87 %\n",
      "Epoch:80/200 AVG Training Loss:0.485 AVG Validation Loss:0.503 AVG Training Acc 80.55 % AVG Validation Acc 79.87 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.484 AVG Validation Loss:0.504 AVG Training Acc 80.45 % AVG Validation Acc 79.87 %\n",
      "Epoch:100/200 AVG Training Loss:0.483 AVG Validation Loss:0.504 AVG Training Acc 80.49 % AVG Validation Acc 79.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.485 AVG Validation Loss:0.504 AVG Training Acc 80.47 % AVG Validation Acc 79.87 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.484 AVG Validation Loss:0.504 AVG Training Acc 80.56 % AVG Validation Acc 79.87 %\n",
      "Epoch:130/200 AVG Training Loss:0.484 AVG Validation Loss:0.504 AVG Training Acc 80.49 % AVG Validation Acc 79.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.484 AVG Validation Loss:0.504 AVG Training Acc 80.52 % AVG Validation Acc 79.87 %\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.504 AVG Training Acc 80.45 % AVG Validation Acc 79.87 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.483 AVG Validation Loss:0.504 AVG Training Acc 80.48 % AVG Validation Acc 79.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.485 AVG Validation Loss:0.504 AVG Training Acc 80.44 % AVG Validation Acc 79.87 %\n",
      "Epoch:180/200 AVG Training Loss:0.483 AVG Validation Loss:0.504 AVG Training Acc 80.50 % AVG Validation Acc 79.87 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.484 AVG Validation Loss:0.504 AVG Training Acc 80.46 % AVG Validation Acc 79.87 %\n",
      "Epoch:200/200 AVG Training Loss:0.484 AVG Validation Loss:0.504 AVG Training Acc 80.45 % AVG Validation Acc 79.87 %\n",
      "Split 211\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6502eebdd4a8465787631110d6bd4e01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.16 % AVG Validation Acc 80.07 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.20 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.21 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.22 % AVG Validation Acc 80.07 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.22 % AVG Validation Acc 80.07 %\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.24 % AVG Validation Acc 80.07 %\n",
      "Epoch:80/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.23 % AVG Validation Acc 79.98 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.19 % AVG Validation Acc 79.98 %\n",
      "Epoch:100/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.23 % AVG Validation Acc 79.98 %\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.25 % AVG Validation Acc 79.98 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.24 % AVG Validation Acc 79.98 %\n",
      "Epoch:130/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.21 % AVG Validation Acc 79.98 %\n",
      "Epoch:140/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.19 % AVG Validation Acc 79.98 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.23 % AVG Validation Acc 79.98 %\n",
      "Epoch:160/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.20 % AVG Validation Acc 79.98 %\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.25 % AVG Validation Acc 79.98 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.24 % AVG Validation Acc 79.98 %\n",
      "Epoch:190/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.20 % AVG Validation Acc 79.98 %\n",
      "Epoch:200/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.23 % AVG Validation Acc 79.98 %\n",
      "Split 212\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64dfb8bfb5a34fd3a182e54645e27bed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.18 % AVG Validation Acc 80.16 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.491 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.491 AVG Validation Loss:0.491 AVG Training Acc 80.16 % AVG Validation Acc 80.07 %\n",
      "Epoch:60/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.24 % AVG Validation Acc 80.07 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.33 % AVG Validation Acc 80.07 %\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.34 % AVG Validation Acc 79.98 %\n",
      "Epoch:90/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.30 % AVG Validation Acc 79.89 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.32 % AVG Validation Acc 79.89 %\n",
      "Epoch:110/200 AVG Training Loss:0.487 AVG Validation Loss:0.491 AVG Training Acc 80.40 % AVG Validation Acc 79.98 %\n",
      "Epoch:120/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.29 % AVG Validation Acc 79.98 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.29 % AVG Validation Acc 79.89 %\n",
      "Epoch:140/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.35 % AVG Validation Acc 79.89 %\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.31 % AVG Validation Acc 79.89 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.36 % AVG Validation Acc 79.89 %\n",
      "Epoch:170/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.30 % AVG Validation Acc 79.89 %\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.31 % AVG Validation Acc 79.89 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.26 % AVG Validation Acc 79.89 %\n",
      "Epoch:200/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.29 % AVG Validation Acc 79.89 %\n",
      "Split 213\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ed40d966c84de1a8aa2a14d8f3e869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.493 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.492 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.19 % AVG Validation Acc 79.98 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.22 % AVG Validation Acc 79.80 %\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.22 % AVG Validation Acc 79.53 %\n",
      "Epoch:80/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.24 % AVG Validation Acc 79.44 %\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.26 % AVG Validation Acc 79.44 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.28 % AVG Validation Acc 79.44 %\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.30 % AVG Validation Acc 79.44 %\n",
      "Epoch:120/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.35 % AVG Validation Acc 79.35 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.26 % AVG Validation Acc 79.35 %\n",
      "Epoch:140/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.30 % AVG Validation Acc 79.44 %\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.32 % AVG Validation Acc 79.35 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.28 % AVG Validation Acc 79.44 %\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.34 % AVG Validation Acc 79.44 %\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.21 % AVG Validation Acc 79.44 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.24 % AVG Validation Acc 79.35 %\n",
      "Epoch:200/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.23 % AVG Validation Acc 79.44 %\n",
      "Split 214\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9336f9c1c86a4cd88b41bee60942d5e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.25 % AVG Validation Acc 80.25 %\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.38 % AVG Validation Acc 80.16 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.25 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.29 % AVG Validation Acc 80.07 %\n",
      "Epoch:80/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.33 % AVG Validation Acc 80.07 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.38 % AVG Validation Acc 80.07 %\n",
      "Epoch:100/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.44 % AVG Validation Acc 80.07 %\n",
      "Epoch:110/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.39 % AVG Validation Acc 80.07 %\n",
      "Epoch:120/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.42 % AVG Validation Acc 80.07 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.38 % AVG Validation Acc 80.07 %\n",
      "Epoch:140/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.35 % AVG Validation Acc 80.07 %\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.40 % AVG Validation Acc 80.07 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.39 % AVG Validation Acc 80.07 %\n",
      "Epoch:170/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.43 % AVG Validation Acc 80.07 %\n",
      "Epoch:180/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.31 % AVG Validation Acc 80.07 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.39 % AVG Validation Acc 80.07 %\n",
      "Epoch:200/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.32 % AVG Validation Acc 80.07 %\n",
      "Split 215\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f51c4fb5bf6e41799865f0c5c9c1c81c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.498 AVG Training Acc 80.19 % AVG Validation Acc 79.98 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.26 % AVG Validation Acc 79.89 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.499 AVG Training Acc 80.20 % AVG Validation Acc 79.80 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.503 AVG Training Acc 80.35 % AVG Validation Acc 79.71 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.485 AVG Validation Loss:0.505 AVG Training Acc 80.37 % AVG Validation Acc 79.62 %\n",
      "Epoch:70/200 AVG Training Loss:0.484 AVG Validation Loss:0.506 AVG Training Acc 80.55 % AVG Validation Acc 79.44 %\n",
      "Epoch:80/200 AVG Training Loss:0.485 AVG Validation Loss:0.506 AVG Training Acc 80.41 % AVG Validation Acc 79.44 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.485 AVG Validation Loss:0.506 AVG Training Acc 80.43 % AVG Validation Acc 79.44 %\n",
      "Epoch:100/200 AVG Training Loss:0.483 AVG Validation Loss:0.507 AVG Training Acc 80.51 % AVG Validation Acc 79.44 %\n",
      "Epoch:110/200 AVG Training Loss:0.485 AVG Validation Loss:0.507 AVG Training Acc 80.44 % AVG Validation Acc 79.44 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.484 AVG Validation Loss:0.507 AVG Training Acc 80.41 % AVG Validation Acc 79.44 %\n",
      "Epoch:130/200 AVG Training Loss:0.484 AVG Validation Loss:0.507 AVG Training Acc 80.42 % AVG Validation Acc 79.44 %\n",
      "Epoch:140/200 AVG Training Loss:0.484 AVG Validation Loss:0.507 AVG Training Acc 80.33 % AVG Validation Acc 79.44 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.484 AVG Validation Loss:0.507 AVG Training Acc 80.45 % AVG Validation Acc 79.44 %\n",
      "Epoch:160/200 AVG Training Loss:0.483 AVG Validation Loss:0.507 AVG Training Acc 80.45 % AVG Validation Acc 79.44 %\n",
      "Epoch:170/200 AVG Training Loss:0.484 AVG Validation Loss:0.507 AVG Training Acc 80.42 % AVG Validation Acc 79.44 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.484 AVG Validation Loss:0.507 AVG Training Acc 80.49 % AVG Validation Acc 79.44 %\n",
      "Epoch:190/200 AVG Training Loss:0.484 AVG Validation Loss:0.507 AVG Training Acc 80.40 % AVG Validation Acc 79.44 %\n",
      "Epoch:200/200 AVG Training Loss:0.484 AVG Validation Loss:0.507 AVG Training Acc 80.35 % AVG Validation Acc 79.44 %\n",
      "Split 216\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5791646ff9154b0a9ca257ace3c3abf6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.497 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.20 % AVG Validation Acc 80.23 %\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.20 % AVG Validation Acc 80.23 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.28 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.35 % AVG Validation Acc 80.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.30 % AVG Validation Acc 80.14 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.37 % AVG Validation Acc 80.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.35 % AVG Validation Acc 80.23 %\n",
      "Epoch:110/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.32 % AVG Validation Acc 80.23 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.30 % AVG Validation Acc 80.23 %\n",
      "Epoch:130/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.30 % AVG Validation Acc 80.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.28 % AVG Validation Acc 80.23 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.30 % AVG Validation Acc 80.23 %\n",
      "Epoch:160/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.35 % AVG Validation Acc 80.23 %\n",
      "Epoch:170/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.33 % AVG Validation Acc 80.23 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.33 % AVG Validation Acc 80.23 %\n",
      "Epoch:190/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.31 % AVG Validation Acc 80.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.33 % AVG Validation Acc 80.23 %\n",
      "Split 217\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e64a55608f8488cb9e8384cb326151a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.498 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.501 AVG Training Acc 80.21 % AVG Validation Acc 79.87 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.504 AVG Training Acc 80.37 % AVG Validation Acc 79.87 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.506 AVG Training Acc 80.49 % AVG Validation Acc 80.05 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.484 AVG Validation Loss:0.506 AVG Training Acc 80.58 % AVG Validation Acc 79.96 %\n",
      "Epoch:70/200 AVG Training Loss:0.483 AVG Validation Loss:0.506 AVG Training Acc 80.62 % AVG Validation Acc 79.78 %\n",
      "Epoch:80/200 AVG Training Loss:0.483 AVG Validation Loss:0.506 AVG Training Acc 80.64 % AVG Validation Acc 79.87 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.482 AVG Validation Loss:0.506 AVG Training Acc 80.60 % AVG Validation Acc 79.87 %\n",
      "Epoch:100/200 AVG Training Loss:0.483 AVG Validation Loss:0.507 AVG Training Acc 80.69 % AVG Validation Acc 79.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.482 AVG Validation Loss:0.506 AVG Training Acc 80.69 % AVG Validation Acc 79.87 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.482 AVG Validation Loss:0.507 AVG Training Acc 80.71 % AVG Validation Acc 79.87 %\n",
      "Epoch:130/200 AVG Training Loss:0.483 AVG Validation Loss:0.506 AVG Training Acc 80.53 % AVG Validation Acc 79.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.483 AVG Validation Loss:0.506 AVG Training Acc 80.61 % AVG Validation Acc 79.87 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.482 AVG Validation Loss:0.506 AVG Training Acc 80.62 % AVG Validation Acc 79.87 %\n",
      "Epoch:160/200 AVG Training Loss:0.483 AVG Validation Loss:0.507 AVG Training Acc 80.68 % AVG Validation Acc 79.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.482 AVG Validation Loss:0.507 AVG Training Acc 80.73 % AVG Validation Acc 79.87 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.483 AVG Validation Loss:0.506 AVG Training Acc 80.58 % AVG Validation Acc 79.87 %\n",
      "Epoch:190/200 AVG Training Loss:0.482 AVG Validation Loss:0.506 AVG Training Acc 80.70 % AVG Validation Acc 79.87 %\n",
      "Epoch:200/200 AVG Training Loss:0.482 AVG Validation Loss:0.506 AVG Training Acc 80.63 % AVG Validation Acc 79.87 %\n",
      "Split 218\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "431be54de3e2465f919f2e55e4e14c33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.498 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.491 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.492 AVG Validation Loss:0.490 AVG Training Acc 80.14 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.491 AVG Validation Loss:0.490 AVG Training Acc 80.16 % AVG Validation Acc 80.05 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.18 % AVG Validation Acc 80.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.23 % AVG Validation Acc 80.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.14 % AVG Validation Acc 80.23 %\n",
      "Epoch:110/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.17 % AVG Validation Acc 80.32 %\n",
      "Epoch:120/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.20 % AVG Validation Acc 80.32 %\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.488 AVG Training Acc 80.14 % AVG Validation Acc 80.32 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:140/200 AVG Training Loss:0.489 AVG Validation Loss:0.488 AVG Training Acc 80.22 % AVG Validation Acc 80.32 %\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.488 AVG Training Acc 80.18 % AVG Validation Acc 80.32 %\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.488 AVG Training Acc 80.21 % AVG Validation Acc 80.32 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:170/200 AVG Training Loss:0.487 AVG Validation Loss:0.488 AVG Training Acc 80.26 % AVG Validation Acc 80.32 %\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.488 AVG Training Acc 80.20 % AVG Validation Acc 80.32 %\n",
      "Epoch:190/200 AVG Training Loss:0.488 AVG Validation Loss:0.488 AVG Training Acc 80.26 % AVG Validation Acc 80.32 %\n",
      "Epoch   198: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.488 AVG Training Acc 80.24 % AVG Validation Acc 80.32 %\n",
      "Split 219\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8cfcf26f70a48d491ac8962b5956b2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.21 % AVG Validation Acc 79.69 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.17 % AVG Validation Acc 79.96 %\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.34 % AVG Validation Acc 79.78 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.44 % AVG Validation Acc 79.51 %\n",
      "Epoch:70/200 AVG Training Loss:0.485 AVG Validation Loss:0.494 AVG Training Acc 80.41 % AVG Validation Acc 79.51 %\n",
      "Epoch:80/200 AVG Training Loss:0.485 AVG Validation Loss:0.494 AVG Training Acc 80.38 % AVG Validation Acc 79.60 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.45 % AVG Validation Acc 79.51 %\n",
      "Epoch:100/200 AVG Training Loss:0.485 AVG Validation Loss:0.494 AVG Training Acc 80.49 % AVG Validation Acc 79.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.485 AVG Validation Loss:0.494 AVG Training Acc 80.45 % AVG Validation Acc 79.51 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.485 AVG Validation Loss:0.494 AVG Training Acc 80.40 % AVG Validation Acc 79.60 %\n",
      "Epoch:130/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.45 % AVG Validation Acc 79.51 %\n",
      "Epoch:140/200 AVG Training Loss:0.484 AVG Validation Loss:0.494 AVG Training Acc 80.40 % AVG Validation Acc 79.60 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.51 % AVG Validation Acc 79.60 %\n",
      "Epoch:160/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.53 % AVG Validation Acc 79.60 %\n",
      "Epoch:170/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.46 % AVG Validation Acc 79.60 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.50 % AVG Validation Acc 79.51 %\n",
      "Epoch:190/200 AVG Training Loss:0.485 AVG Validation Loss:0.494 AVG Training Acc 80.49 % AVG Validation Acc 79.60 %\n",
      "Epoch:200/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.44 % AVG Validation Acc 79.51 %\n",
      "Split 220\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a524881669944a7afb02cd76ebf39a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.491 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.492 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.24 % AVG Validation Acc 80.23 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.37 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.494 AVG Training Acc 80.46 % AVG Validation Acc 80.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.62 % AVG Validation Acc 79.87 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.77 % AVG Validation Acc 79.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.70 % AVG Validation Acc 79.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.72 % AVG Validation Acc 79.87 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.482 AVG Validation Loss:0.500 AVG Training Acc 80.70 % AVG Validation Acc 79.96 %\n",
      "Epoch:110/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.71 % AVG Validation Acc 79.96 %\n",
      "Epoch:120/200 AVG Training Loss:0.480 AVG Validation Loss:0.500 AVG Training Acc 80.74 % AVG Validation Acc 79.96 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.480 AVG Validation Loss:0.499 AVG Training Acc 80.82 % AVG Validation Acc 79.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.481 AVG Validation Loss:0.500 AVG Training Acc 80.77 % AVG Validation Acc 79.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.71 % AVG Validation Acc 79.96 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.480 AVG Validation Loss:0.500 AVG Training Acc 80.74 % AVG Validation Acc 79.96 %\n",
      "Epoch:170/200 AVG Training Loss:0.480 AVG Validation Loss:0.499 AVG Training Acc 80.76 % AVG Validation Acc 79.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.481 AVG Validation Loss:0.500 AVG Training Acc 80.76 % AVG Validation Acc 79.96 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.79 % AVG Validation Acc 79.96 %\n",
      "Epoch:200/200 AVG Training Loss:0.480 AVG Validation Loss:0.499 AVG Training Acc 80.72 % AVG Validation Acc 79.96 %\n",
      "Split 221\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bac354452a04d60a22e5aef7a21782c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.493 AVG Training Acc 80.09 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.20 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.34 % AVG Validation Acc 79.89 %\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.36 % AVG Validation Acc 79.71 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.53 % AVG Validation Acc 79.71 %\n",
      "Epoch:70/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.41 % AVG Validation Acc 79.71 %\n",
      "Epoch:80/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.52 % AVG Validation Acc 79.62 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.43 % AVG Validation Acc 79.71 %\n",
      "Epoch:100/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.53 % AVG Validation Acc 79.62 %\n",
      "Epoch:110/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.57 % AVG Validation Acc 79.53 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.483 AVG Validation Loss:0.503 AVG Training Acc 80.47 % AVG Validation Acc 79.44 %\n",
      "Epoch:130/200 AVG Training Loss:0.484 AVG Validation Loss:0.498 AVG Training Acc 80.53 % AVG Validation Acc 79.53 %\n",
      "Epoch:140/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.51 % AVG Validation Acc 79.71 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.54 % AVG Validation Acc 79.71 %\n",
      "Epoch:160/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.48 % AVG Validation Acc 79.62 %\n",
      "Epoch:170/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.50 % AVG Validation Acc 79.62 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.56 % AVG Validation Acc 79.62 %\n",
      "Epoch:190/200 AVG Training Loss:0.484 AVG Validation Loss:0.498 AVG Training Acc 80.49 % AVG Validation Acc 79.71 %\n",
      "Epoch:200/200 AVG Training Loss:0.482 AVG Validation Loss:0.498 AVG Training Acc 80.61 % AVG Validation Acc 79.53 %\n",
      "Split 222\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a987303ec004949a56591597264ac78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.493 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.489 AVG Training Acc 80.09 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.491 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.18 % AVG Validation Acc 79.98 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.22 % AVG Validation Acc 79.98 %\n",
      "Epoch:70/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.17 % AVG Validation Acc 79.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.16 % AVG Validation Acc 79.98 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.13 % AVG Validation Acc 79.98 %\n",
      "Epoch:100/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.20 % AVG Validation Acc 79.98 %\n",
      "Epoch:110/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.25 % AVG Validation Acc 79.98 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.21 % AVG Validation Acc 79.98 %\n",
      "Epoch:130/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.17 % AVG Validation Acc 79.98 %\n",
      "Epoch:140/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.20 % AVG Validation Acc 79.98 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.10 % AVG Validation Acc 79.98 %\n",
      "Epoch:160/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.21 % AVG Validation Acc 79.98 %\n",
      "Epoch:170/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.19 % AVG Validation Acc 79.98 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.23 % AVG Validation Acc 79.98 %\n",
      "Epoch:190/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.18 % AVG Validation Acc 79.98 %\n",
      "Epoch:200/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.24 % AVG Validation Acc 79.98 %\n",
      "Split 223\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44bbdca453b4f6383d91c44426b6a7c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.10 % AVG Validation Acc 80.16 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.39 % AVG Validation Acc 79.71 %\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.49 % AVG Validation Acc 79.80 %\n",
      "Epoch:50/200 AVG Training Loss:0.484 AVG Validation Loss:0.498 AVG Training Acc 80.58 % AVG Validation Acc 79.89 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.482 AVG Validation Loss:0.507 AVG Training Acc 80.75 % AVG Validation Acc 79.53 %\n",
      "Epoch:70/200 AVG Training Loss:0.480 AVG Validation Loss:0.510 AVG Training Acc 80.72 % AVG Validation Acc 79.53 %\n",
      "Epoch:80/200 AVG Training Loss:0.481 AVG Validation Loss:0.510 AVG Training Acc 80.78 % AVG Validation Acc 79.53 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.480 AVG Validation Loss:0.512 AVG Training Acc 80.87 % AVG Validation Acc 79.35 %\n",
      "Epoch:100/200 AVG Training Loss:0.480 AVG Validation Loss:0.511 AVG Training Acc 80.83 % AVG Validation Acc 79.44 %\n",
      "Epoch:110/200 AVG Training Loss:0.480 AVG Validation Loss:0.512 AVG Training Acc 80.85 % AVG Validation Acc 79.35 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.479 AVG Validation Loss:0.512 AVG Training Acc 80.80 % AVG Validation Acc 79.35 %\n",
      "Epoch:130/200 AVG Training Loss:0.480 AVG Validation Loss:0.512 AVG Training Acc 80.78 % AVG Validation Acc 79.35 %\n",
      "Epoch:140/200 AVG Training Loss:0.480 AVG Validation Loss:0.513 AVG Training Acc 80.73 % AVG Validation Acc 79.35 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.479 AVG Validation Loss:0.511 AVG Training Acc 80.84 % AVG Validation Acc 79.35 %\n",
      "Epoch:160/200 AVG Training Loss:0.479 AVG Validation Loss:0.511 AVG Training Acc 80.87 % AVG Validation Acc 79.35 %\n",
      "Epoch:170/200 AVG Training Loss:0.480 AVG Validation Loss:0.511 AVG Training Acc 80.82 % AVG Validation Acc 79.35 %\n",
      "Epoch:180/200 AVG Training Loss:0.481 AVG Validation Loss:0.512 AVG Training Acc 80.91 % AVG Validation Acc 79.35 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.480 AVG Validation Loss:0.512 AVG Training Acc 80.83 % AVG Validation Acc 79.35 %\n",
      "Epoch:200/200 AVG Training Loss:0.481 AVG Validation Loss:0.511 AVG Training Acc 80.72 % AVG Validation Acc 79.35 %\n",
      "Split 224\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e33180c026cf40418b0b5693dbbaeeca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.497 AVG Training Acc 80.16 % AVG Validation Acc 79.98 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.498 AVG Training Acc 80.15 % AVG Validation Acc 79.98 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.501 AVG Training Acc 80.28 % AVG Validation Acc 79.62 %\n",
      "Epoch:60/200 AVG Training Loss:0.486 AVG Validation Loss:0.502 AVG Training Acc 80.37 % AVG Validation Acc 79.35 %\n",
      "Epoch:70/200 AVG Training Loss:0.486 AVG Validation Loss:0.502 AVG Training Acc 80.36 % AVG Validation Acc 79.71 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.486 AVG Validation Loss:0.503 AVG Training Acc 80.28 % AVG Validation Acc 79.35 %\n",
      "Epoch:90/200 AVG Training Loss:0.486 AVG Validation Loss:0.503 AVG Training Acc 80.30 % AVG Validation Acc 79.44 %\n",
      "Epoch:100/200 AVG Training Loss:0.485 AVG Validation Loss:0.503 AVG Training Acc 80.46 % AVG Validation Acc 79.53 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.486 AVG Validation Loss:0.503 AVG Training Acc 80.36 % AVG Validation Acc 79.44 %\n",
      "Epoch:120/200 AVG Training Loss:0.485 AVG Validation Loss:0.503 AVG Training Acc 80.38 % AVG Validation Acc 79.44 %\n",
      "Epoch:130/200 AVG Training Loss:0.485 AVG Validation Loss:0.503 AVG Training Acc 80.35 % AVG Validation Acc 79.35 %\n",
      "Epoch:140/200 AVG Training Loss:0.486 AVG Validation Loss:0.502 AVG Training Acc 80.33 % AVG Validation Acc 79.26 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.502 AVG Training Acc 80.42 % AVG Validation Acc 79.53 %\n",
      "Epoch:160/200 AVG Training Loss:0.486 AVG Validation Loss:0.502 AVG Training Acc 80.34 % AVG Validation Acc 79.44 %\n",
      "Epoch:170/200 AVG Training Loss:0.486 AVG Validation Loss:0.503 AVG Training Acc 80.34 % AVG Validation Acc 79.44 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.486 AVG Validation Loss:0.503 AVG Training Acc 80.30 % AVG Validation Acc 79.44 %\n",
      "Epoch:190/200 AVG Training Loss:0.486 AVG Validation Loss:0.503 AVG Training Acc 80.33 % AVG Validation Acc 79.62 %\n",
      "Epoch:200/200 AVG Training Loss:0.486 AVG Validation Loss:0.503 AVG Training Acc 80.41 % AVG Validation Acc 79.26 %\n",
      "Split 225\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bdb87e3bb7824b7b828062b32dfc9a87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.493 AVG Validation Loss:0.493 AVG Training Acc 80.18 % AVG Validation Acc 79.98 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.15 % AVG Validation Acc 80.25 %\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.21 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.490 AVG Training Acc 80.32 % AVG Validation Acc 80.07 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.490 AVG Training Acc 80.32 % AVG Validation Acc 80.07 %\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.490 AVG Training Acc 80.35 % AVG Validation Acc 80.07 %\n",
      "Epoch:90/200 AVG Training Loss:0.487 AVG Validation Loss:0.491 AVG Training Acc 80.46 % AVG Validation Acc 80.07 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.34 % AVG Validation Acc 80.07 %\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.490 AVG Training Acc 80.31 % AVG Validation Acc 80.07 %\n",
      "Epoch:120/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.24 % AVG Validation Acc 80.07 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.490 AVG Training Acc 80.25 % AVG Validation Acc 80.07 %\n",
      "Epoch:140/200 AVG Training Loss:0.488 AVG Validation Loss:0.490 AVG Training Acc 80.22 % AVG Validation Acc 80.07 %\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.490 AVG Training Acc 80.28 % AVG Validation Acc 80.07 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.27 % AVG Validation Acc 80.07 %\n",
      "Epoch:170/200 AVG Training Loss:0.487 AVG Validation Loss:0.491 AVG Training Acc 80.33 % AVG Validation Acc 80.07 %\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.26 % AVG Validation Acc 80.07 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.491 AVG Training Acc 80.29 % AVG Validation Acc 80.07 %\n",
      "Epoch:200/200 AVG Training Loss:0.487 AVG Validation Loss:0.491 AVG Training Acc 80.35 % AVG Validation Acc 80.07 %\n",
      "Split 226\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f781d21672a437a871f57d0f8f8a9cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.08 % AVG Validation Acc 80.14 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.25 % AVG Validation Acc 80.14 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.29 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.26 % AVG Validation Acc 80.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.33 % AVG Validation Acc 80.05 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.35 % AVG Validation Acc 79.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.28 % AVG Validation Acc 79.96 %\n",
      "Epoch:110/200 AVG Training Loss:0.485 AVG Validation Loss:0.494 AVG Training Acc 80.31 % AVG Validation Acc 80.05 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.39 % AVG Validation Acc 80.05 %\n",
      "Epoch:130/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.40 % AVG Validation Acc 80.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.35 % AVG Validation Acc 80.05 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.494 AVG Training Acc 80.37 % AVG Validation Acc 80.05 %\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.48 % AVG Validation Acc 80.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.485 AVG Validation Loss:0.494 AVG Training Acc 80.33 % AVG Validation Acc 80.05 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.31 % AVG Validation Acc 80.05 %\n",
      "Epoch:190/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.36 % AVG Validation Acc 80.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.484 AVG Validation Loss:0.494 AVG Training Acc 80.40 % AVG Validation Acc 80.05 %\n",
      "Split 227\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3532a8cffa8d47c4b04d441b51b05560",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.492 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.21 % AVG Validation Acc 80.05 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.33 % AVG Validation Acc 80.23 %\n",
      "Epoch:50/200 AVG Training Loss:0.481 AVG Validation Loss:0.495 AVG Training Acc 80.63 % AVG Validation Acc 80.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.478 AVG Validation Loss:0.498 AVG Training Acc 80.81 % AVG Validation Acc 80.32 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.475 AVG Validation Loss:0.501 AVG Training Acc 81.01 % AVG Validation Acc 80.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.474 AVG Validation Loss:0.499 AVG Training Acc 81.04 % AVG Validation Acc 79.78 %\n",
      "Epoch:90/200 AVG Training Loss:0.474 AVG Validation Loss:0.500 AVG Training Acc 81.05 % AVG Validation Acc 79.96 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.474 AVG Validation Loss:0.500 AVG Training Acc 81.02 % AVG Validation Acc 79.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.473 AVG Validation Loss:0.501 AVG Training Acc 81.16 % AVG Validation Acc 79.87 %\n",
      "Epoch:120/200 AVG Training Loss:0.474 AVG Validation Loss:0.500 AVG Training Acc 81.14 % AVG Validation Acc 79.96 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.474 AVG Validation Loss:0.500 AVG Training Acc 81.10 % AVG Validation Acc 79.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.474 AVG Validation Loss:0.500 AVG Training Acc 81.09 % AVG Validation Acc 79.87 %\n",
      "Epoch:150/200 AVG Training Loss:0.473 AVG Validation Loss:0.501 AVG Training Acc 81.13 % AVG Validation Acc 79.78 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.474 AVG Validation Loss:0.500 AVG Training Acc 81.15 % AVG Validation Acc 80.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.474 AVG Validation Loss:0.500 AVG Training Acc 81.05 % AVG Validation Acc 80.05 %\n",
      "Epoch:180/200 AVG Training Loss:0.474 AVG Validation Loss:0.500 AVG Training Acc 81.06 % AVG Validation Acc 80.05 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.473 AVG Validation Loss:0.500 AVG Training Acc 81.10 % AVG Validation Acc 79.78 %\n",
      "Epoch:200/200 AVG Training Loss:0.473 AVG Validation Loss:0.499 AVG Training Acc 81.15 % AVG Validation Acc 79.96 %\n",
      "Split 228\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea46cace154b49eaa885a6bc614ba2d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.08 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.27 % AVG Validation Acc 80.14 %\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.482 AVG Validation Loss:0.495 AVG Training Acc 80.61 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.480 AVG Validation Loss:0.495 AVG Training Acc 80.63 % AVG Validation Acc 79.96 %\n",
      "Epoch:70/200 AVG Training Loss:0.479 AVG Validation Loss:0.497 AVG Training Acc 80.74 % AVG Validation Acc 79.87 %\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.477 AVG Validation Loss:0.498 AVG Training Acc 80.84 % AVG Validation Acc 79.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.476 AVG Validation Loss:0.498 AVG Training Acc 81.14 % AVG Validation Acc 79.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.475 AVG Validation Loss:0.499 AVG Training Acc 81.08 % AVG Validation Acc 79.96 %\n",
      "Epoch   106: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.475 AVG Validation Loss:0.501 AVG Training Acc 80.97 % AVG Validation Acc 79.87 %\n",
      "Epoch:120/200 AVG Training Loss:0.474 AVG Validation Loss:0.500 AVG Training Acc 81.11 % AVG Validation Acc 79.96 %\n",
      "Epoch:130/200 AVG Training Loss:0.475 AVG Validation Loss:0.500 AVG Training Acc 81.07 % AVG Validation Acc 79.96 %\n",
      "Epoch   137: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.475 AVG Validation Loss:0.500 AVG Training Acc 81.03 % AVG Validation Acc 79.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.476 AVG Validation Loss:0.500 AVG Training Acc 80.96 % AVG Validation Acc 79.96 %\n",
      "Epoch:160/200 AVG Training Loss:0.475 AVG Validation Loss:0.500 AVG Training Acc 81.04 % AVG Validation Acc 79.96 %\n",
      "Epoch   168: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.475 AVG Validation Loss:0.500 AVG Training Acc 81.09 % AVG Validation Acc 79.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.475 AVG Validation Loss:0.500 AVG Training Acc 80.97 % AVG Validation Acc 79.96 %\n",
      "Epoch:190/200 AVG Training Loss:0.475 AVG Validation Loss:0.501 AVG Training Acc 81.01 % AVG Validation Acc 79.87 %\n",
      "Epoch   199: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.475 AVG Validation Loss:0.501 AVG Training Acc 81.07 % AVG Validation Acc 79.96 %\n",
      "Split 229\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "351a8179d93c41d1b671f655651f736f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.497 AVG Training Acc 80.25 % AVG Validation Acc 80.05 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.483 AVG Validation Loss:0.496 AVG Training Acc 80.48 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.59 % AVG Validation Acc 80.23 %\n",
      "Epoch:60/200 AVG Training Loss:0.481 AVG Validation Loss:0.501 AVG Training Acc 80.74 % AVG Validation Acc 80.14 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.478 AVG Validation Loss:0.503 AVG Training Acc 80.68 % AVG Validation Acc 79.87 %\n",
      "Epoch:80/200 AVG Training Loss:0.480 AVG Validation Loss:0.502 AVG Training Acc 80.80 % AVG Validation Acc 80.05 %\n",
      "Epoch:90/200 AVG Training Loss:0.479 AVG Validation Loss:0.505 AVG Training Acc 80.86 % AVG Validation Acc 79.96 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.479 AVG Validation Loss:0.505 AVG Training Acc 80.77 % AVG Validation Acc 79.96 %\n",
      "Epoch:110/200 AVG Training Loss:0.480 AVG Validation Loss:0.506 AVG Training Acc 80.77 % AVG Validation Acc 79.78 %\n",
      "Epoch:120/200 AVG Training Loss:0.479 AVG Validation Loss:0.506 AVG Training Acc 80.82 % AVG Validation Acc 80.14 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.478 AVG Validation Loss:0.505 AVG Training Acc 80.72 % AVG Validation Acc 80.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.478 AVG Validation Loss:0.505 AVG Training Acc 80.85 % AVG Validation Acc 79.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.480 AVG Validation Loss:0.506 AVG Training Acc 80.82 % AVG Validation Acc 79.96 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.479 AVG Validation Loss:0.502 AVG Training Acc 80.82 % AVG Validation Acc 80.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.479 AVG Validation Loss:0.504 AVG Training Acc 80.85 % AVG Validation Acc 80.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.478 AVG Validation Loss:0.506 AVG Training Acc 80.82 % AVG Validation Acc 79.96 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.480 AVG Validation Loss:0.505 AVG Training Acc 80.77 % AVG Validation Acc 80.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.480 AVG Validation Loss:0.506 AVG Training Acc 80.70 % AVG Validation Acc 80.05 %\n",
      "Split 230\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50ff5c8373b740e4ab4dca83579fd93d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.499 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.498 AVG Training Acc 80.09 % AVG Validation Acc 80.14 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.17 % AVG Validation Acc 80.05 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.44 % AVG Validation Acc 79.96 %\n",
      "Epoch:70/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.46 % AVG Validation Acc 79.78 %\n",
      "Epoch:80/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.38 % AVG Validation Acc 79.78 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.39 % AVG Validation Acc 79.69 %\n",
      "Epoch:100/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.58 % AVG Validation Acc 79.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.55 % AVG Validation Acc 79.60 %\n",
      "Epoch:120/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.51 % AVG Validation Acc 79.69 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.51 % AVG Validation Acc 79.60 %\n",
      "Epoch:140/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.50 % AVG Validation Acc 79.60 %\n",
      "Epoch:150/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.35 % AVG Validation Acc 79.60 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.49 % AVG Validation Acc 79.69 %\n",
      "Epoch:170/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.39 % AVG Validation Acc 79.60 %\n",
      "Epoch:180/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.48 % AVG Validation Acc 79.69 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.39 % AVG Validation Acc 79.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.50 % AVG Validation Acc 79.60 %\n",
      "Split 231\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "069f329d05dd4169a0d1e1d3043fb3c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.502 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.499 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.500 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.500 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.500 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.490 AVG Validation Loss:0.500 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.489 AVG Validation Loss:0.500 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:90/200 AVG Training Loss:0.489 AVG Validation Loss:0.500 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch:100/200 AVG Training Loss:0.489 AVG Validation Loss:0.500 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch   106: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.489 AVG Validation Loss:0.500 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:120/200 AVG Training Loss:0.489 AVG Validation Loss:0.500 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch:130/200 AVG Training Loss:0.489 AVG Validation Loss:0.500 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch   137: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.490 AVG Validation Loss:0.500 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:150/200 AVG Training Loss:0.489 AVG Validation Loss:0.500 AVG Training Acc 80.10 % AVG Validation Acc 80.16 %\n",
      "Epoch:160/200 AVG Training Loss:0.489 AVG Validation Loss:0.500 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch   168: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.489 AVG Validation Loss:0.500 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:180/200 AVG Training Loss:0.489 AVG Validation Loss:0.500 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:190/200 AVG Training Loss:0.489 AVG Validation Loss:0.500 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch:200/200 AVG Training Loss:0.489 AVG Validation Loss:0.500 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Split 232\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d759ac913aaa436e85d790b065ea6822",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 79.80 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.497 AVG Training Acc 80.23 % AVG Validation Acc 79.89 %\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.24 % AVG Validation Acc 79.98 %\n",
      "Epoch:60/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.26 % AVG Validation Acc 80.07 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.28 % AVG Validation Acc 80.07 %\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.30 % AVG Validation Acc 80.07 %\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.30 % AVG Validation Acc 80.07 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.32 % AVG Validation Acc 80.07 %\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.30 % AVG Validation Acc 80.07 %\n",
      "Epoch:120/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.34 % AVG Validation Acc 80.07 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.26 % AVG Validation Acc 80.07 %\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.31 % AVG Validation Acc 80.07 %\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.23 % AVG Validation Acc 80.07 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.31 % AVG Validation Acc 80.07 %\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.28 % AVG Validation Acc 80.07 %\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.32 % AVG Validation Acc 80.07 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.31 % AVG Validation Acc 80.07 %\n",
      "Epoch:200/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.37 % AVG Validation Acc 80.07 %\n",
      "Split 233\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53d0f280bbe04938a1953a0cf542982c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.498 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.23 % AVG Validation Acc 80.07 %\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.27 % AVG Validation Acc 80.07 %\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.23 % AVG Validation Acc 80.07 %\n",
      "Epoch:90/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.20 % AVG Validation Acc 80.07 %\n",
      "Epoch:100/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 80.07 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.07 %\n",
      "Epoch:120/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.20 % AVG Validation Acc 80.07 %\n",
      "Epoch:130/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.24 % AVG Validation Acc 80.07 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.25 % AVG Validation Acc 80.07 %\n",
      "Epoch:150/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch:160/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.24 % AVG Validation Acc 80.07 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.25 % AVG Validation Acc 80.07 %\n",
      "Epoch:180/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.25 % AVG Validation Acc 80.07 %\n",
      "Epoch:190/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.32 % AVG Validation Acc 80.07 %\n",
      "Epoch:200/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.22 % AVG Validation Acc 80.07 %\n",
      "Split 234\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5585604e6ba4d57814462cbfd1b2e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.493 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.20 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.22 % AVG Validation Acc 80.25 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.31 % AVG Validation Acc 80.16 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.484 AVG Validation Loss:0.487 AVG Training Acc 80.52 % AVG Validation Acc 79.80 %\n",
      "Epoch:70/200 AVG Training Loss:0.482 AVG Validation Loss:0.490 AVG Training Acc 80.55 % AVG Validation Acc 79.80 %\n",
      "Epoch:80/200 AVG Training Loss:0.481 AVG Validation Loss:0.495 AVG Training Acc 80.79 % AVG Validation Acc 79.53 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.478 AVG Validation Loss:0.499 AVG Training Acc 80.88 % AVG Validation Acc 79.44 %\n",
      "Epoch:100/200 AVG Training Loss:0.477 AVG Validation Loss:0.498 AVG Training Acc 80.89 % AVG Validation Acc 79.62 %\n",
      "Epoch:110/200 AVG Training Loss:0.476 AVG Validation Loss:0.500 AVG Training Acc 80.87 % AVG Validation Acc 79.44 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.475 AVG Validation Loss:0.498 AVG Training Acc 80.96 % AVG Validation Acc 79.53 %\n",
      "Epoch:130/200 AVG Training Loss:0.477 AVG Validation Loss:0.499 AVG Training Acc 80.85 % AVG Validation Acc 79.62 %\n",
      "Epoch:140/200 AVG Training Loss:0.476 AVG Validation Loss:0.501 AVG Training Acc 80.92 % AVG Validation Acc 79.53 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.476 AVG Validation Loss:0.502 AVG Training Acc 80.96 % AVG Validation Acc 79.53 %\n",
      "Epoch:160/200 AVG Training Loss:0.476 AVG Validation Loss:0.500 AVG Training Acc 80.98 % AVG Validation Acc 79.44 %\n",
      "Epoch:170/200 AVG Training Loss:0.476 AVG Validation Loss:0.501 AVG Training Acc 80.94 % AVG Validation Acc 79.53 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.478 AVG Validation Loss:0.498 AVG Training Acc 80.88 % AVG Validation Acc 79.53 %\n",
      "Epoch:190/200 AVG Training Loss:0.477 AVG Validation Loss:0.499 AVG Training Acc 80.89 % AVG Validation Acc 79.53 %\n",
      "Epoch:200/200 AVG Training Loss:0.476 AVG Validation Loss:0.498 AVG Training Acc 80.99 % AVG Validation Acc 79.62 %\n",
      "Split 235\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53bdd1d47b814bcbb894070c6fd75c93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.498 AVG Training Acc 80.13 % AVG Validation Acc 80.07 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.498 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.21 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.497 AVG Training Acc 80.16 % AVG Validation Acc 80.07 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.498 AVG Training Acc 80.12 % AVG Validation Acc 79.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.489 AVG Validation Loss:0.498 AVG Training Acc 80.16 % AVG Validation Acc 79.89 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 79.89 %\n",
      "Epoch:100/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.18 % AVG Validation Acc 79.89 %\n",
      "Epoch:110/200 AVG Training Loss:0.487 AVG Validation Loss:0.499 AVG Training Acc 80.19 % AVG Validation Acc 79.89 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.487 AVG Validation Loss:0.498 AVG Training Acc 80.23 % AVG Validation Acc 79.89 %\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.16 % AVG Validation Acc 79.89 %\n",
      "Epoch:140/200 AVG Training Loss:0.488 AVG Validation Loss:0.498 AVG Training Acc 80.24 % AVG Validation Acc 79.89 %\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.498 AVG Training Acc 80.21 % AVG Validation Acc 79.89 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.498 AVG Training Acc 80.21 % AVG Validation Acc 79.89 %\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.498 AVG Training Acc 80.11 % AVG Validation Acc 79.89 %\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.17 % AVG Validation Acc 79.89 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.498 AVG Training Acc 80.20 % AVG Validation Acc 79.89 %\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.498 AVG Training Acc 80.10 % AVG Validation Acc 79.89 %\n",
      "Split 236\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a20e1e0ae71c4b4aafa64e63601abf5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.493 AVG Training Acc 80.34 % AVG Validation Acc 80.14 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.483 AVG Validation Loss:0.496 AVG Training Acc 80.62 % AVG Validation Acc 79.69 %\n",
      "Epoch:50/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.86 % AVG Validation Acc 79.60 %\n",
      "Epoch:60/200 AVG Training Loss:0.479 AVG Validation Loss:0.504 AVG Training Acc 80.79 % AVG Validation Acc 79.42 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.476 AVG Validation Loss:0.505 AVG Training Acc 81.12 % AVG Validation Acc 79.33 %\n",
      "Epoch:80/200 AVG Training Loss:0.476 AVG Validation Loss:0.507 AVG Training Acc 81.06 % AVG Validation Acc 79.33 %\n",
      "Epoch:90/200 AVG Training Loss:0.476 AVG Validation Loss:0.508 AVG Training Acc 81.16 % AVG Validation Acc 79.33 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.475 AVG Validation Loss:0.513 AVG Training Acc 81.09 % AVG Validation Acc 79.15 %\n",
      "Epoch:110/200 AVG Training Loss:0.475 AVG Validation Loss:0.511 AVG Training Acc 81.12 % AVG Validation Acc 79.24 %\n",
      "Epoch:120/200 AVG Training Loss:0.475 AVG Validation Loss:0.512 AVG Training Acc 81.20 % AVG Validation Acc 79.24 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.475 AVG Validation Loss:0.512 AVG Training Acc 81.19 % AVG Validation Acc 79.24 %\n",
      "Epoch:140/200 AVG Training Loss:0.475 AVG Validation Loss:0.512 AVG Training Acc 81.13 % AVG Validation Acc 79.24 %\n",
      "Epoch:150/200 AVG Training Loss:0.474 AVG Validation Loss:0.512 AVG Training Acc 81.16 % AVG Validation Acc 79.24 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.475 AVG Validation Loss:0.511 AVG Training Acc 81.15 % AVG Validation Acc 79.24 %\n",
      "Epoch:170/200 AVG Training Loss:0.475 AVG Validation Loss:0.512 AVG Training Acc 81.13 % AVG Validation Acc 79.24 %\n",
      "Epoch:180/200 AVG Training Loss:0.476 AVG Validation Loss:0.512 AVG Training Acc 81.05 % AVG Validation Acc 79.24 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.475 AVG Validation Loss:0.511 AVG Training Acc 81.16 % AVG Validation Acc 79.24 %\n",
      "Epoch:200/200 AVG Training Loss:0.475 AVG Validation Loss:0.513 AVG Training Acc 81.16 % AVG Validation Acc 79.24 %\n",
      "Split 237\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87e2143cd1c248cf924a37400f9cd198",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.10 % AVG Validation Acc 80.14 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.33 % AVG Validation Acc 79.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.36 % AVG Validation Acc 79.78 %\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.50 % AVG Validation Acc 79.87 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.503 AVG Training Acc 80.58 % AVG Validation Acc 79.78 %\n",
      "Epoch:70/200 AVG Training Loss:0.482 AVG Validation Loss:0.504 AVG Training Acc 80.71 % AVG Validation Acc 79.60 %\n",
      "Epoch:80/200 AVG Training Loss:0.482 AVG Validation Loss:0.505 AVG Training Acc 80.56 % AVG Validation Acc 79.69 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.481 AVG Validation Loss:0.507 AVG Training Acc 80.71 % AVG Validation Acc 79.69 %\n",
      "Epoch:100/200 AVG Training Loss:0.481 AVG Validation Loss:0.506 AVG Training Acc 80.65 % AVG Validation Acc 79.69 %\n",
      "Epoch:110/200 AVG Training Loss:0.481 AVG Validation Loss:0.506 AVG Training Acc 80.67 % AVG Validation Acc 79.51 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.482 AVG Validation Loss:0.507 AVG Training Acc 80.67 % AVG Validation Acc 79.51 %\n",
      "Epoch:130/200 AVG Training Loss:0.481 AVG Validation Loss:0.507 AVG Training Acc 80.67 % AVG Validation Acc 79.51 %\n",
      "Epoch:140/200 AVG Training Loss:0.481 AVG Validation Loss:0.507 AVG Training Acc 80.64 % AVG Validation Acc 79.51 %\n",
      "Epoch:150/200 AVG Training Loss:0.482 AVG Validation Loss:0.507 AVG Training Acc 80.65 % AVG Validation Acc 79.51 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.481 AVG Validation Loss:0.507 AVG Training Acc 80.69 % AVG Validation Acc 79.51 %\n",
      "Epoch:170/200 AVG Training Loss:0.482 AVG Validation Loss:0.507 AVG Training Acc 80.69 % AVG Validation Acc 79.51 %\n",
      "Epoch:180/200 AVG Training Loss:0.481 AVG Validation Loss:0.507 AVG Training Acc 80.57 % AVG Validation Acc 79.51 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.481 AVG Validation Loss:0.507 AVG Training Acc 80.71 % AVG Validation Acc 79.51 %\n",
      "Epoch:200/200 AVG Training Loss:0.482 AVG Validation Loss:0.507 AVG Training Acc 80.60 % AVG Validation Acc 79.51 %\n",
      "Split 238\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2d727f1e4a413087deb2d960648f1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.05 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.28 % AVG Validation Acc 80.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.39 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.48 % AVG Validation Acc 80.14 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.482 AVG Validation Loss:0.497 AVG Training Acc 80.58 % AVG Validation Acc 80.23 %\n",
      "Epoch:70/200 AVG Training Loss:0.482 AVG Validation Loss:0.497 AVG Training Acc 80.53 % AVG Validation Acc 80.32 %\n",
      "Epoch:80/200 AVG Training Loss:0.482 AVG Validation Loss:0.498 AVG Training Acc 80.55 % AVG Validation Acc 80.32 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.480 AVG Validation Loss:0.498 AVG Training Acc 80.66 % AVG Validation Acc 80.32 %\n",
      "Epoch:100/200 AVG Training Loss:0.481 AVG Validation Loss:0.498 AVG Training Acc 80.63 % AVG Validation Acc 80.32 %\n",
      "Epoch:110/200 AVG Training Loss:0.481 AVG Validation Loss:0.498 AVG Training Acc 80.73 % AVG Validation Acc 80.23 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.480 AVG Validation Loss:0.498 AVG Training Acc 80.52 % AVG Validation Acc 80.23 %\n",
      "Epoch:130/200 AVG Training Loss:0.481 AVG Validation Loss:0.498 AVG Training Acc 80.65 % AVG Validation Acc 80.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.482 AVG Validation Loss:0.498 AVG Training Acc 80.52 % AVG Validation Acc 80.23 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.481 AVG Validation Loss:0.498 AVG Training Acc 80.60 % AVG Validation Acc 80.23 %\n",
      "Epoch:160/200 AVG Training Loss:0.481 AVG Validation Loss:0.498 AVG Training Acc 80.67 % AVG Validation Acc 80.23 %\n",
      "Epoch:170/200 AVG Training Loss:0.481 AVG Validation Loss:0.498 AVG Training Acc 80.61 % AVG Validation Acc 80.23 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.481 AVG Validation Loss:0.498 AVG Training Acc 80.66 % AVG Validation Acc 80.23 %\n",
      "Epoch:190/200 AVG Training Loss:0.481 AVG Validation Loss:0.498 AVG Training Acc 80.67 % AVG Validation Acc 80.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.69 % AVG Validation Acc 80.23 %\n",
      "Split 239\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c76d6a82e83b4e35a7f221e7c77d05ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.499 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.27 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.498 AVG Training Acc 80.37 % AVG Validation Acc 79.60 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.504 AVG Training Acc 80.41 % AVG Validation Acc 79.60 %\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.505 AVG Training Acc 80.50 % AVG Validation Acc 79.60 %\n",
      "Epoch:70/200 AVG Training Loss:0.484 AVG Validation Loss:0.505 AVG Training Acc 80.50 % AVG Validation Acc 79.51 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.483 AVG Validation Loss:0.507 AVG Training Acc 80.50 % AVG Validation Acc 79.60 %\n",
      "Epoch:90/200 AVG Training Loss:0.482 AVG Validation Loss:0.507 AVG Training Acc 80.48 % AVG Validation Acc 79.60 %\n",
      "Epoch:100/200 AVG Training Loss:0.484 AVG Validation Loss:0.507 AVG Training Acc 80.52 % AVG Validation Acc 79.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.483 AVG Validation Loss:0.508 AVG Training Acc 80.58 % AVG Validation Acc 79.60 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.483 AVG Validation Loss:0.508 AVG Training Acc 80.48 % AVG Validation Acc 79.60 %\n",
      "Epoch:130/200 AVG Training Loss:0.483 AVG Validation Loss:0.507 AVG Training Acc 80.50 % AVG Validation Acc 79.60 %\n",
      "Epoch:140/200 AVG Training Loss:0.483 AVG Validation Loss:0.507 AVG Training Acc 80.61 % AVG Validation Acc 79.60 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.484 AVG Validation Loss:0.508 AVG Training Acc 80.44 % AVG Validation Acc 79.60 %\n",
      "Epoch:160/200 AVG Training Loss:0.483 AVG Validation Loss:0.507 AVG Training Acc 80.59 % AVG Validation Acc 79.60 %\n",
      "Epoch:170/200 AVG Training Loss:0.484 AVG Validation Loss:0.508 AVG Training Acc 80.54 % AVG Validation Acc 79.60 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.483 AVG Validation Loss:0.508 AVG Training Acc 80.54 % AVG Validation Acc 79.60 %\n",
      "Epoch:190/200 AVG Training Loss:0.484 AVG Validation Loss:0.508 AVG Training Acc 80.53 % AVG Validation Acc 79.60 %\n",
      "Epoch:200/200 AVG Training Loss:0.483 AVG Validation Loss:0.507 AVG Training Acc 80.50 % AVG Validation Acc 79.60 %\n",
      "Split 240\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fa9dbbe5a0c474ea786faad998b5412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.496 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.35 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.494 AVG Training Acc 80.46 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.68 % AVG Validation Acc 80.14 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.481 AVG Validation Loss:0.496 AVG Training Acc 80.69 % AVG Validation Acc 79.87 %\n",
      "Epoch:80/200 AVG Training Loss:0.482 AVG Validation Loss:0.497 AVG Training Acc 80.68 % AVG Validation Acc 79.78 %\n",
      "Epoch:90/200 AVG Training Loss:0.480 AVG Validation Loss:0.497 AVG Training Acc 80.78 % AVG Validation Acc 80.05 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.480 AVG Validation Loss:0.498 AVG Training Acc 80.72 % AVG Validation Acc 79.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.480 AVG Validation Loss:0.497 AVG Training Acc 80.78 % AVG Validation Acc 79.96 %\n",
      "Epoch:120/200 AVG Training Loss:0.480 AVG Validation Loss:0.497 AVG Training Acc 80.82 % AVG Validation Acc 79.69 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.480 AVG Validation Loss:0.497 AVG Training Acc 80.71 % AVG Validation Acc 79.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.480 AVG Validation Loss:0.498 AVG Training Acc 80.75 % AVG Validation Acc 79.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.480 AVG Validation Loss:0.498 AVG Training Acc 80.71 % AVG Validation Acc 79.78 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.479 AVG Validation Loss:0.499 AVG Training Acc 80.79 % AVG Validation Acc 79.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.479 AVG Validation Loss:0.499 AVG Training Acc 80.75 % AVG Validation Acc 79.78 %\n",
      "Epoch:180/200 AVG Training Loss:0.479 AVG Validation Loss:0.497 AVG Training Acc 80.85 % AVG Validation Acc 79.78 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.479 AVG Validation Loss:0.497 AVG Training Acc 80.80 % AVG Validation Acc 79.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.480 AVG Validation Loss:0.497 AVG Training Acc 80.84 % AVG Validation Acc 79.78 %\n",
      "Split 241\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc8a4ba483bf49cd9a67d39f5208a700",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.12 % AVG Validation Acc 80.25 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.26 % AVG Validation Acc 79.98 %\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.42 % AVG Validation Acc 79.89 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.482 AVG Validation Loss:0.498 AVG Training Acc 80.67 % AVG Validation Acc 79.89 %\n",
      "Epoch:70/200 AVG Training Loss:0.482 AVG Validation Loss:0.497 AVG Training Acc 80.69 % AVG Validation Acc 79.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.481 AVG Validation Loss:0.498 AVG Training Acc 80.65 % AVG Validation Acc 79.98 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.480 AVG Validation Loss:0.499 AVG Training Acc 80.71 % AVG Validation Acc 79.98 %\n",
      "Epoch:100/200 AVG Training Loss:0.480 AVG Validation Loss:0.498 AVG Training Acc 80.77 % AVG Validation Acc 80.07 %\n",
      "Epoch:110/200 AVG Training Loss:0.480 AVG Validation Loss:0.498 AVG Training Acc 80.86 % AVG Validation Acc 80.07 %\n",
      "Epoch:120/200 AVG Training Loss:0.481 AVG Validation Loss:0.498 AVG Training Acc 80.69 % AVG Validation Acc 80.07 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.481 AVG Validation Loss:0.498 AVG Training Acc 80.75 % AVG Validation Acc 80.07 %\n",
      "Epoch:140/200 AVG Training Loss:0.481 AVG Validation Loss:0.498 AVG Training Acc 80.72 % AVG Validation Acc 80.07 %\n",
      "Epoch:150/200 AVG Training Loss:0.480 AVG Validation Loss:0.498 AVG Training Acc 80.80 % AVG Validation Acc 80.16 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.481 AVG Validation Loss:0.498 AVG Training Acc 80.82 % AVG Validation Acc 79.98 %\n",
      "Epoch:170/200 AVG Training Loss:0.480 AVG Validation Loss:0.498 AVG Training Acc 80.72 % AVG Validation Acc 80.07 %\n",
      "Epoch:180/200 AVG Training Loss:0.480 AVG Validation Loss:0.498 AVG Training Acc 80.70 % AVG Validation Acc 80.07 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.481 AVG Validation Loss:0.498 AVG Training Acc 80.80 % AVG Validation Acc 80.07 %\n",
      "Epoch:200/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.75 % AVG Validation Acc 80.07 %\n",
      "Split 242\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d9e90099f7f44e38df9de1fccb98d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.499 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.490 AVG Validation Loss:0.497 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.497 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.19 % AVG Validation Acc 80.07 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.25 % AVG Validation Acc 80.07 %\n",
      "Epoch:100/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.20 % AVG Validation Acc 80.07 %\n",
      "Epoch:110/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.18 % AVG Validation Acc 80.07 %\n",
      "Epoch:140/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.18 % AVG Validation Acc 80.07 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.10 % AVG Validation Acc 80.07 %\n",
      "Epoch:160/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.23 % AVG Validation Acc 80.07 %\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.25 % AVG Validation Acc 80.07 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.25 % AVG Validation Acc 80.07 %\n",
      "Epoch:190/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.19 % AVG Validation Acc 80.07 %\n",
      "Split 243\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a3c7c291cb34bc483dac0f3ad23a77e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.18 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.500 AVG Training Acc 80.30 % AVG Validation Acc 79.89 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.509 AVG Training Acc 80.42 % AVG Validation Acc 79.98 %\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.510 AVG Training Acc 80.49 % AVG Validation Acc 79.98 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.484 AVG Validation Loss:0.509 AVG Training Acc 80.46 % AVG Validation Acc 79.89 %\n",
      "Epoch:70/200 AVG Training Loss:0.484 AVG Validation Loss:0.511 AVG Training Acc 80.50 % AVG Validation Acc 79.80 %\n",
      "Epoch:80/200 AVG Training Loss:0.484 AVG Validation Loss:0.514 AVG Training Acc 80.54 % AVG Validation Acc 79.71 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.483 AVG Validation Loss:0.512 AVG Training Acc 80.58 % AVG Validation Acc 79.80 %\n",
      "Epoch:100/200 AVG Training Loss:0.483 AVG Validation Loss:0.514 AVG Training Acc 80.60 % AVG Validation Acc 79.71 %\n",
      "Epoch:110/200 AVG Training Loss:0.484 AVG Validation Loss:0.514 AVG Training Acc 80.57 % AVG Validation Acc 79.71 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.484 AVG Validation Loss:0.514 AVG Training Acc 80.49 % AVG Validation Acc 79.80 %\n",
      "Epoch:130/200 AVG Training Loss:0.483 AVG Validation Loss:0.514 AVG Training Acc 80.59 % AVG Validation Acc 79.71 %\n",
      "Epoch:140/200 AVG Training Loss:0.483 AVG Validation Loss:0.514 AVG Training Acc 80.51 % AVG Validation Acc 79.80 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.484 AVG Validation Loss:0.514 AVG Training Acc 80.50 % AVG Validation Acc 79.80 %\n",
      "Epoch:160/200 AVG Training Loss:0.483 AVG Validation Loss:0.514 AVG Training Acc 80.56 % AVG Validation Acc 79.80 %\n",
      "Epoch:170/200 AVG Training Loss:0.484 AVG Validation Loss:0.515 AVG Training Acc 80.55 % AVG Validation Acc 79.71 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.484 AVG Validation Loss:0.514 AVG Training Acc 80.56 % AVG Validation Acc 79.80 %\n",
      "Epoch:190/200 AVG Training Loss:0.483 AVG Validation Loss:0.514 AVG Training Acc 80.53 % AVG Validation Acc 79.80 %\n",
      "Epoch:200/200 AVG Training Loss:0.483 AVG Validation Loss:0.515 AVG Training Acc 80.56 % AVG Validation Acc 79.71 %\n",
      "Split 244\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3402c539f8f14c3593a30e2d4ae26d8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.498 AVG Training Acc 80.07 % AVG Validation Acc 80.16 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.20 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.13 % AVG Validation Acc 80.07 %\n",
      "Epoch:60/200 AVG Training Loss:0.486 AVG Validation Loss:0.493 AVG Training Acc 80.29 % AVG Validation Acc 80.25 %\n",
      "Epoch:70/200 AVG Training Loss:0.483 AVG Validation Loss:0.492 AVG Training Acc 80.51 % AVG Validation Acc 80.07 %\n",
      "Epoch:80/200 AVG Training Loss:0.481 AVG Validation Loss:0.492 AVG Training Acc 80.60 % AVG Validation Acc 79.80 %\n",
      "Epoch:90/200 AVG Training Loss:0.480 AVG Validation Loss:0.492 AVG Training Acc 80.71 % AVG Validation Acc 79.98 %\n",
      "Epoch:100/200 AVG Training Loss:0.479 AVG Validation Loss:0.491 AVG Training Acc 80.76 % AVG Validation Acc 79.80 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:110/200 AVG Training Loss:0.476 AVG Validation Loss:0.492 AVG Training Acc 80.91 % AVG Validation Acc 79.44 %\n",
      "Epoch:120/200 AVG Training Loss:0.475 AVG Validation Loss:0.494 AVG Training Acc 81.03 % AVG Validation Acc 79.44 %\n",
      "Epoch:130/200 AVG Training Loss:0.474 AVG Validation Loss:0.493 AVG Training Acc 81.08 % AVG Validation Acc 79.44 %\n",
      "Epoch   133: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:140/200 AVG Training Loss:0.475 AVG Validation Loss:0.494 AVG Training Acc 80.95 % AVG Validation Acc 79.44 %\n",
      "Epoch:150/200 AVG Training Loss:0.476 AVG Validation Loss:0.495 AVG Training Acc 81.10 % AVG Validation Acc 79.44 %\n",
      "Epoch:160/200 AVG Training Loss:0.475 AVG Validation Loss:0.495 AVG Training Acc 81.00 % AVG Validation Acc 79.35 %\n",
      "Epoch   164: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:170/200 AVG Training Loss:0.473 AVG Validation Loss:0.497 AVG Training Acc 81.05 % AVG Validation Acc 79.44 %\n",
      "Epoch:180/200 AVG Training Loss:0.475 AVG Validation Loss:0.495 AVG Training Acc 81.03 % AVG Validation Acc 79.44 %\n",
      "Epoch:190/200 AVG Training Loss:0.475 AVG Validation Loss:0.501 AVG Training Acc 80.96 % AVG Validation Acc 79.35 %\n",
      "Epoch   195: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:200/200 AVG Training Loss:0.474 AVG Validation Loss:0.498 AVG Training Acc 81.15 % AVG Validation Acc 79.35 %\n",
      "Split 245\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "861f7986ba864d5694c2ba02f3515097",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.496 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.21 % AVG Validation Acc 80.07 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.493 AVG Training Acc 80.48 % AVG Validation Acc 79.80 %\n",
      "Epoch:50/200 AVG Training Loss:0.484 AVG Validation Loss:0.493 AVG Training Acc 80.54 % AVG Validation Acc 79.89 %\n",
      "Epoch:60/200 AVG Training Loss:0.481 AVG Validation Loss:0.493 AVG Training Acc 80.66 % AVG Validation Acc 79.98 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.480 AVG Validation Loss:0.495 AVG Training Acc 80.83 % AVG Validation Acc 79.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.479 AVG Validation Loss:0.496 AVG Training Acc 80.75 % AVG Validation Acc 79.89 %\n",
      "Epoch:90/200 AVG Training Loss:0.478 AVG Validation Loss:0.496 AVG Training Acc 80.92 % AVG Validation Acc 79.71 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.478 AVG Validation Loss:0.497 AVG Training Acc 80.92 % AVG Validation Acc 79.80 %\n",
      "Epoch:110/200 AVG Training Loss:0.477 AVG Validation Loss:0.497 AVG Training Acc 81.02 % AVG Validation Acc 79.80 %\n",
      "Epoch:120/200 AVG Training Loss:0.478 AVG Validation Loss:0.496 AVG Training Acc 80.95 % AVG Validation Acc 79.80 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.479 AVG Validation Loss:0.497 AVG Training Acc 80.98 % AVG Validation Acc 79.80 %\n",
      "Epoch:140/200 AVG Training Loss:0.478 AVG Validation Loss:0.498 AVG Training Acc 80.98 % AVG Validation Acc 79.80 %\n",
      "Epoch:150/200 AVG Training Loss:0.476 AVG Validation Loss:0.497 AVG Training Acc 80.94 % AVG Validation Acc 79.89 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.478 AVG Validation Loss:0.498 AVG Training Acc 81.00 % AVG Validation Acc 79.80 %\n",
      "Epoch:170/200 AVG Training Loss:0.478 AVG Validation Loss:0.497 AVG Training Acc 80.87 % AVG Validation Acc 79.80 %\n",
      "Epoch:180/200 AVG Training Loss:0.478 AVG Validation Loss:0.497 AVG Training Acc 80.93 % AVG Validation Acc 79.80 %\n",
      "Epoch:190/200 AVG Training Loss:0.478 AVG Validation Loss:0.498 AVG Training Acc 80.93 % AVG Validation Acc 79.71 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.478 AVG Validation Loss:0.496 AVG Training Acc 80.91 % AVG Validation Acc 79.80 %\n",
      "Split 246\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d16a4c79e9784fac8189d61737b5b537",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.492 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.484 AVG Validation Loss:0.491 AVG Training Acc 80.49 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.480 AVG Validation Loss:0.494 AVG Training Acc 80.63 % AVG Validation Acc 80.32 %\n",
      "Epoch:70/200 AVG Training Loss:0.476 AVG Validation Loss:0.499 AVG Training Acc 80.82 % AVG Validation Acc 79.96 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.474 AVG Validation Loss:0.499 AVG Training Acc 80.90 % AVG Validation Acc 80.32 %\n",
      "Epoch:90/200 AVG Training Loss:0.472 AVG Validation Loss:0.501 AVG Training Acc 81.01 % AVG Validation Acc 80.32 %\n",
      "Epoch:100/200 AVG Training Loss:0.471 AVG Validation Loss:0.500 AVG Training Acc 81.02 % AVG Validation Acc 80.23 %\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.472 AVG Validation Loss:0.500 AVG Training Acc 81.11 % AVG Validation Acc 80.42 %\n",
      "Epoch:120/200 AVG Training Loss:0.472 AVG Validation Loss:0.501 AVG Training Acc 81.06 % AVG Validation Acc 80.42 %\n",
      "Epoch:130/200 AVG Training Loss:0.471 AVG Validation Loss:0.500 AVG Training Acc 81.01 % AVG Validation Acc 80.32 %\n",
      "Epoch   134: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.472 AVG Validation Loss:0.500 AVG Training Acc 80.90 % AVG Validation Acc 80.51 %\n",
      "Epoch:150/200 AVG Training Loss:0.472 AVG Validation Loss:0.500 AVG Training Acc 81.12 % AVG Validation Acc 80.42 %\n",
      "Epoch:160/200 AVG Training Loss:0.471 AVG Validation Loss:0.502 AVG Training Acc 80.94 % AVG Validation Acc 80.42 %\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.473 AVG Validation Loss:0.500 AVG Training Acc 80.98 % AVG Validation Acc 80.42 %\n",
      "Epoch:180/200 AVG Training Loss:0.471 AVG Validation Loss:0.501 AVG Training Acc 81.03 % AVG Validation Acc 80.32 %\n",
      "Epoch:190/200 AVG Training Loss:0.472 AVG Validation Loss:0.501 AVG Training Acc 81.05 % AVG Validation Acc 80.32 %\n",
      "Epoch   196: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.470 AVG Validation Loss:0.501 AVG Training Acc 81.11 % AVG Validation Acc 80.32 %\n",
      "Split 247\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e1e3168636444b8b532aad4c5356348",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.500 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.490 AVG Validation Loss:0.498 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.499 AVG Training Acc 80.21 % AVG Validation Acc 79.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.500 AVG Training Acc 80.21 % AVG Validation Acc 79.78 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.501 AVG Training Acc 80.32 % AVG Validation Acc 79.87 %\n",
      "Epoch:60/200 AVG Training Loss:0.485 AVG Validation Loss:0.501 AVG Training Acc 80.35 % AVG Validation Acc 79.78 %\n",
      "Epoch:70/200 AVG Training Loss:0.486 AVG Validation Loss:0.501 AVG Training Acc 80.37 % AVG Validation Acc 79.78 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.485 AVG Validation Loss:0.502 AVG Training Acc 80.34 % AVG Validation Acc 79.69 %\n",
      "Epoch:90/200 AVG Training Loss:0.484 AVG Validation Loss:0.502 AVG Training Acc 80.42 % AVG Validation Acc 79.69 %\n",
      "Epoch:100/200 AVG Training Loss:0.485 AVG Validation Loss:0.501 AVG Training Acc 80.32 % AVG Validation Acc 79.69 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.484 AVG Validation Loss:0.502 AVG Training Acc 80.40 % AVG Validation Acc 79.69 %\n",
      "Epoch:120/200 AVG Training Loss:0.485 AVG Validation Loss:0.502 AVG Training Acc 80.35 % AVG Validation Acc 79.69 %\n",
      "Epoch:130/200 AVG Training Loss:0.486 AVG Validation Loss:0.502 AVG Training Acc 80.33 % AVG Validation Acc 79.69 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.485 AVG Validation Loss:0.502 AVG Training Acc 80.29 % AVG Validation Acc 79.69 %\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.502 AVG Training Acc 80.36 % AVG Validation Acc 79.69 %\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.502 AVG Training Acc 80.45 % AVG Validation Acc 79.69 %\n",
      "Epoch:170/200 AVG Training Loss:0.484 AVG Validation Loss:0.502 AVG Training Acc 80.42 % AVG Validation Acc 79.69 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.485 AVG Validation Loss:0.502 AVG Training Acc 80.34 % AVG Validation Acc 79.69 %\n",
      "Epoch:190/200 AVG Training Loss:0.485 AVG Validation Loss:0.502 AVG Training Acc 80.31 % AVG Validation Acc 79.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.486 AVG Validation Loss:0.502 AVG Training Acc 80.42 % AVG Validation Acc 79.69 %\n",
      "Split 248\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c474cec39934208a61316239a8a0cf4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.489 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.489 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.491 AVG Validation Loss:0.489 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.490 AVG Validation Loss:0.488 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.487 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.486 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.29 % AVG Validation Acc 80.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.32 % AVG Validation Acc 80.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.486 AVG Validation Loss:0.487 AVG Training Acc 80.27 % AVG Validation Acc 80.14 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.486 AVG Validation Loss:0.491 AVG Training Acc 80.31 % AVG Validation Acc 80.05 %\n",
      "Epoch:130/200 AVG Training Loss:0.485 AVG Validation Loss:0.488 AVG Training Acc 80.24 % AVG Validation Acc 79.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.485 AVG Validation Loss:0.487 AVG Training Acc 80.27 % AVG Validation Acc 79.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.486 AVG Validation Loss:0.487 AVG Training Acc 80.34 % AVG Validation Acc 80.05 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.491 AVG Training Acc 80.38 % AVG Validation Acc 80.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.485 AVG Validation Loss:0.487 AVG Training Acc 80.27 % AVG Validation Acc 79.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.486 AVG Validation Loss:0.487 AVG Training Acc 80.30 % AVG Validation Acc 79.96 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.486 AVG Validation Loss:0.487 AVG Training Acc 80.25 % AVG Validation Acc 80.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.485 AVG Validation Loss:0.488 AVG Training Acc 80.40 % AVG Validation Acc 79.96 %\n",
      "Split 249\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ab5995716cf41fc85ae1e2762fd7477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.18 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.05 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.487 AVG Validation Loss:0.498 AVG Training Acc 80.20 % AVG Validation Acc 80.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.26 % AVG Validation Acc 80.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.487 AVG Validation Loss:0.498 AVG Training Acc 80.26 % AVG Validation Acc 80.05 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.18 % AVG Validation Acc 80.05 %\n",
      "Epoch:100/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.23 % AVG Validation Acc 80.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.498 AVG Training Acc 80.28 % AVG Validation Acc 80.05 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.487 AVG Validation Loss:0.498 AVG Training Acc 80.24 % AVG Validation Acc 80.05 %\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.35 % AVG Validation Acc 80.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.499 AVG Training Acc 80.22 % AVG Validation Acc 80.05 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.28 % AVG Validation Acc 80.05 %\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.23 % AVG Validation Acc 80.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.487 AVG Validation Loss:0.499 AVG Training Acc 80.26 % AVG Validation Acc 80.05 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.487 AVG Validation Loss:0.498 AVG Training Acc 80.25 % AVG Validation Acc 80.05 %\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.498 AVG Training Acc 80.28 % AVG Validation Acc 80.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.487 AVG Validation Loss:0.499 AVG Training Acc 80.24 % AVG Validation Acc 80.05 %\n",
      "Split 250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4eab92103b24e79a5e83ce9b5923e17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.491 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.493 AVG Validation Loss:0.491 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.485 AVG Training Acc 80.20 % AVG Validation Acc 80.23 %\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.485 AVG Training Acc 80.35 % AVG Validation Acc 80.23 %\n",
      "Epoch:60/200 AVG Training Loss:0.487 AVG Validation Loss:0.486 AVG Training Acc 80.38 % AVG Validation Acc 80.14 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.485 AVG Validation Loss:0.487 AVG Training Acc 80.44 % AVG Validation Acc 80.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.486 AVG Validation Loss:0.488 AVG Training Acc 80.52 % AVG Validation Acc 80.05 %\n",
      "Epoch:90/200 AVG Training Loss:0.485 AVG Validation Loss:0.488 AVG Training Acc 80.46 % AVG Validation Acc 80.05 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.485 AVG Validation Loss:0.487 AVG Training Acc 80.50 % AVG Validation Acc 80.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.485 AVG Validation Loss:0.488 AVG Training Acc 80.49 % AVG Validation Acc 80.05 %\n",
      "Epoch:120/200 AVG Training Loss:0.486 AVG Validation Loss:0.487 AVG Training Acc 80.46 % AVG Validation Acc 79.96 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.485 AVG Validation Loss:0.488 AVG Training Acc 80.55 % AVG Validation Acc 79.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.486 AVG Validation Loss:0.488 AVG Training Acc 80.50 % AVG Validation Acc 79.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.488 AVG Training Acc 80.54 % AVG Validation Acc 79.96 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.488 AVG Training Acc 80.47 % AVG Validation Acc 79.96 %\n",
      "Epoch:170/200 AVG Training Loss:0.485 AVG Validation Loss:0.488 AVG Training Acc 80.53 % AVG Validation Acc 79.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.484 AVG Validation Loss:0.488 AVG Training Acc 80.47 % AVG Validation Acc 79.96 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.486 AVG Validation Loss:0.488 AVG Training Acc 80.54 % AVG Validation Acc 79.96 %\n",
      "Epoch:200/200 AVG Training Loss:0.485 AVG Validation Loss:0.488 AVG Training Acc 80.50 % AVG Validation Acc 79.96 %\n",
      "Split 251\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25a784de0b8442fdbc0d1e29c127f3a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.20 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.22 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.23 % AVG Validation Acc 79.98 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.25 % AVG Validation Acc 79.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.31 % AVG Validation Acc 79.89 %\n",
      "Epoch:90/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.23 % AVG Validation Acc 79.98 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.26 % AVG Validation Acc 79.98 %\n",
      "Epoch:110/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.27 % AVG Validation Acc 79.98 %\n",
      "Epoch:120/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.29 % AVG Validation Acc 79.89 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.24 % AVG Validation Acc 79.98 %\n",
      "Epoch:140/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.33 % AVG Validation Acc 79.89 %\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.36 % AVG Validation Acc 79.98 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.28 % AVG Validation Acc 79.98 %\n",
      "Epoch:170/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.28 % AVG Validation Acc 79.89 %\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.27 % AVG Validation Acc 79.98 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.31 % AVG Validation Acc 79.98 %\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.28 % AVG Validation Acc 79.89 %\n",
      "Split 252\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecf843121cbd4f05bbbeb7358a879a88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.498 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.498 AVG Training Acc 80.10 % AVG Validation Acc 80.16 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.502 AVG Training Acc 80.21 % AVG Validation Acc 79.71 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.21 % AVG Validation Acc 79.71 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.503 AVG Training Acc 80.33 % AVG Validation Acc 79.80 %\n",
      "Epoch:60/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.42 % AVG Validation Acc 79.71 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.484 AVG Validation Loss:0.506 AVG Training Acc 80.37 % AVG Validation Acc 79.53 %\n",
      "Epoch:80/200 AVG Training Loss:0.484 AVG Validation Loss:0.506 AVG Training Acc 80.37 % AVG Validation Acc 79.53 %\n",
      "Epoch:90/200 AVG Training Loss:0.484 AVG Validation Loss:0.505 AVG Training Acc 80.32 % AVG Validation Acc 79.62 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.483 AVG Validation Loss:0.505 AVG Training Acc 80.42 % AVG Validation Acc 79.44 %\n",
      "Epoch:110/200 AVG Training Loss:0.484 AVG Validation Loss:0.505 AVG Training Acc 80.47 % AVG Validation Acc 79.35 %\n",
      "Epoch:120/200 AVG Training Loss:0.483 AVG Validation Loss:0.506 AVG Training Acc 80.42 % AVG Validation Acc 79.44 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.483 AVG Validation Loss:0.506 AVG Training Acc 80.48 % AVG Validation Acc 79.53 %\n",
      "Epoch:140/200 AVG Training Loss:0.483 AVG Validation Loss:0.506 AVG Training Acc 80.49 % AVG Validation Acc 79.53 %\n",
      "Epoch:150/200 AVG Training Loss:0.483 AVG Validation Loss:0.506 AVG Training Acc 80.41 % AVG Validation Acc 79.44 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.484 AVG Validation Loss:0.505 AVG Training Acc 80.50 % AVG Validation Acc 79.53 %\n",
      "Epoch:170/200 AVG Training Loss:0.483 AVG Validation Loss:0.507 AVG Training Acc 80.47 % AVG Validation Acc 79.53 %\n",
      "Epoch:180/200 AVG Training Loss:0.484 AVG Validation Loss:0.507 AVG Training Acc 80.46 % AVG Validation Acc 79.44 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.483 AVG Validation Loss:0.505 AVG Training Acc 80.61 % AVG Validation Acc 79.53 %\n",
      "Epoch:200/200 AVG Training Loss:0.482 AVG Validation Loss:0.507 AVG Training Acc 80.41 % AVG Validation Acc 79.35 %\n",
      "Split 253\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef8056c291b0465caa18c523a404892d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.492 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.490 AVG Training Acc 80.23 % AVG Validation Acc 80.25 %\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.27 % AVG Validation Acc 79.98 %\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.55 % AVG Validation Acc 79.98 %\n",
      "Epoch:60/200 AVG Training Loss:0.482 AVG Validation Loss:0.493 AVG Training Acc 80.68 % AVG Validation Acc 79.80 %\n",
      "Epoch:70/200 AVG Training Loss:0.481 AVG Validation Loss:0.495 AVG Training Acc 80.88 % AVG Validation Acc 79.71 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.479 AVG Validation Loss:0.496 AVG Training Acc 80.97 % AVG Validation Acc 79.71 %\n",
      "Epoch:90/200 AVG Training Loss:0.478 AVG Validation Loss:0.498 AVG Training Acc 80.93 % AVG Validation Acc 79.71 %\n",
      "Epoch:100/200 AVG Training Loss:0.479 AVG Validation Loss:0.497 AVG Training Acc 80.93 % AVG Validation Acc 79.71 %\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.480 AVG Validation Loss:0.497 AVG Training Acc 80.85 % AVG Validation Acc 79.80 %\n",
      "Epoch:120/200 AVG Training Loss:0.477 AVG Validation Loss:0.498 AVG Training Acc 80.97 % AVG Validation Acc 79.71 %\n",
      "Epoch:130/200 AVG Training Loss:0.478 AVG Validation Loss:0.497 AVG Training Acc 80.97 % AVG Validation Acc 79.80 %\n",
      "Epoch   134: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.478 AVG Validation Loss:0.498 AVG Training Acc 80.99 % AVG Validation Acc 79.71 %\n",
      "Epoch:150/200 AVG Training Loss:0.477 AVG Validation Loss:0.498 AVG Training Acc 81.10 % AVG Validation Acc 79.80 %\n",
      "Epoch:160/200 AVG Training Loss:0.480 AVG Validation Loss:0.498 AVG Training Acc 80.97 % AVG Validation Acc 79.62 %\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.478 AVG Validation Loss:0.498 AVG Training Acc 80.93 % AVG Validation Acc 79.71 %\n",
      "Epoch:180/200 AVG Training Loss:0.477 AVG Validation Loss:0.498 AVG Training Acc 81.01 % AVG Validation Acc 79.80 %\n",
      "Epoch:190/200 AVG Training Loss:0.478 AVG Validation Loss:0.498 AVG Training Acc 81.06 % AVG Validation Acc 79.71 %\n",
      "Epoch   196: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.477 AVG Validation Loss:0.499 AVG Training Acc 81.09 % AVG Validation Acc 79.71 %\n",
      "Split 254\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e2fd5ea1254fad8edcca240e7068d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.20 % AVG Validation Acc 79.89 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.20 % AVG Validation Acc 79.89 %\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.33 % AVG Validation Acc 79.89 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.31 % AVG Validation Acc 79.89 %\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.25 % AVG Validation Acc 79.89 %\n",
      "Epoch:80/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.30 % AVG Validation Acc 79.89 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.34 % AVG Validation Acc 79.89 %\n",
      "Epoch:100/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.36 % AVG Validation Acc 79.89 %\n",
      "Epoch:110/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.36 % AVG Validation Acc 79.89 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.36 % AVG Validation Acc 79.89 %\n",
      "Epoch:130/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.37 % AVG Validation Acc 79.89 %\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.38 % AVG Validation Acc 79.89 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.38 % AVG Validation Acc 79.89 %\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.36 % AVG Validation Acc 79.89 %\n",
      "Epoch:170/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.39 % AVG Validation Acc 79.89 %\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.33 % AVG Validation Acc 79.89 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.36 % AVG Validation Acc 79.89 %\n",
      "Epoch:200/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.35 % AVG Validation Acc 79.89 %\n",
      "Split 255\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d5af90308df40379624d9a5004622e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.17 % AVG Validation Acc 79.98 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.19 % AVG Validation Acc 79.98 %\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.23 % AVG Validation Acc 79.98 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.26 % AVG Validation Acc 79.98 %\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.32 % AVG Validation Acc 79.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.498 AVG Training Acc 80.27 % AVG Validation Acc 79.98 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.498 AVG Training Acc 80.24 % AVG Validation Acc 79.89 %\n",
      "Epoch:100/200 AVG Training Loss:0.488 AVG Validation Loss:0.498 AVG Training Acc 80.27 % AVG Validation Acc 79.89 %\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.30 % AVG Validation Acc 79.89 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.29 % AVG Validation Acc 79.89 %\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.25 % AVG Validation Acc 79.89 %\n",
      "Epoch:140/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.30 % AVG Validation Acc 79.89 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.32 % AVG Validation Acc 79.89 %\n",
      "Epoch:160/200 AVG Training Loss:0.487 AVG Validation Loss:0.499 AVG Training Acc 80.32 % AVG Validation Acc 79.89 %\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.498 AVG Training Acc 80.29 % AVG Validation Acc 79.89 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.487 AVG Validation Loss:0.499 AVG Training Acc 80.27 % AVG Validation Acc 79.89 %\n",
      "Epoch:190/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.28 % AVG Validation Acc 79.89 %\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.33 % AVG Validation Acc 79.89 %\n",
      "Split 256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f45f7cfdd2c940ba97d285a88702ec0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch   106: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:120/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch   137: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:150/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch   168: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Split 257\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbb5b39bcb5848798baf8280409a384a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.499 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.496 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.24 % AVG Validation Acc 80.14 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.486 AVG Validation Loss:0.499 AVG Training Acc 80.42 % AVG Validation Acc 80.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.485 AVG Validation Loss:0.500 AVG Training Acc 80.48 % AVG Validation Acc 80.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.484 AVG Validation Loss:0.502 AVG Training Acc 80.59 % AVG Validation Acc 79.96 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.484 AVG Validation Loss:0.502 AVG Training Acc 80.61 % AVG Validation Acc 79.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.60 % AVG Validation Acc 79.96 %\n",
      "Epoch:110/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.51 % AVG Validation Acc 79.96 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.58 % AVG Validation Acc 79.96 %\n",
      "Epoch:130/200 AVG Training Loss:0.484 AVG Validation Loss:0.504 AVG Training Acc 80.60 % AVG Validation Acc 79.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.484 AVG Validation Loss:0.504 AVG Training Acc 80.57 % AVG Validation Acc 79.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.483 AVG Validation Loss:0.504 AVG Training Acc 80.62 % AVG Validation Acc 79.96 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.484 AVG Validation Loss:0.504 AVG Training Acc 80.49 % AVG Validation Acc 79.96 %\n",
      "Epoch:170/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.60 % AVG Validation Acc 79.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.484 AVG Validation Loss:0.504 AVG Training Acc 80.50 % AVG Validation Acc 79.96 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.484 AVG Validation Loss:0.504 AVG Training Acc 80.57 % AVG Validation Acc 79.96 %\n",
      "Epoch:200/200 AVG Training Loss:0.484 AVG Validation Loss:0.504 AVG Training Acc 80.53 % AVG Validation Acc 79.96 %\n",
      "Split 258\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2760b49b7ffe4ae59f5466a14156ac6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.492 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.490 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.489 AVG Training Acc 80.22 % AVG Validation Acc 80.23 %\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.24 % AVG Validation Acc 80.23 %\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.27 % AVG Validation Acc 80.32 %\n",
      "Epoch:80/200 AVG Training Loss:0.486 AVG Validation Loss:0.488 AVG Training Acc 80.42 % AVG Validation Acc 80.14 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.484 AVG Validation Loss:0.488 AVG Training Acc 80.47 % AVG Validation Acc 80.32 %\n",
      "Epoch:100/200 AVG Training Loss:0.484 AVG Validation Loss:0.488 AVG Training Acc 80.52 % AVG Validation Acc 80.23 %\n",
      "Epoch:110/200 AVG Training Loss:0.483 AVG Validation Loss:0.488 AVG Training Acc 80.57 % AVG Validation Acc 80.23 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.484 AVG Validation Loss:0.489 AVG Training Acc 80.55 % AVG Validation Acc 80.23 %\n",
      "Epoch:130/200 AVG Training Loss:0.484 AVG Validation Loss:0.489 AVG Training Acc 80.52 % AVG Validation Acc 80.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.484 AVG Validation Loss:0.489 AVG Training Acc 80.49 % AVG Validation Acc 80.23 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.483 AVG Validation Loss:0.489 AVG Training Acc 80.58 % AVG Validation Acc 80.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.483 AVG Validation Loss:0.489 AVG Training Acc 80.46 % AVG Validation Acc 80.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.483 AVG Validation Loss:0.489 AVG Training Acc 80.65 % AVG Validation Acc 80.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.483 AVG Validation Loss:0.489 AVG Training Acc 80.57 % AVG Validation Acc 80.14 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.483 AVG Validation Loss:0.489 AVG Training Acc 80.46 % AVG Validation Acc 80.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.482 AVG Validation Loss:0.489 AVG Training Acc 80.56 % AVG Validation Acc 80.14 %\n",
      "Split 259\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab6be9aa83dd425ba504de9d0580a344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.490 AVG Training Acc 80.16 % AVG Validation Acc 80.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.490 AVG Training Acc 80.15 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.491 AVG Validation Loss:0.489 AVG Training Acc 80.20 % AVG Validation Acc 80.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.19 % AVG Validation Acc 80.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.490 AVG Validation Loss:0.488 AVG Training Acc 80.21 % AVG Validation Acc 80.05 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.21 % AVG Validation Acc 80.23 %\n",
      "Epoch:90/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.36 % AVG Validation Acc 80.23 %\n",
      "Epoch:100/200 AVG Training Loss:0.487 AVG Validation Loss:0.491 AVG Training Acc 80.33 % AVG Validation Acc 80.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.26 % AVG Validation Acc 80.14 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.29 % AVG Validation Acc 80.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.28 % AVG Validation Acc 80.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.28 % AVG Validation Acc 80.14 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.27 % AVG Validation Acc 80.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.28 % AVG Validation Acc 80.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.25 % AVG Validation Acc 80.14 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.34 % AVG Validation Acc 80.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.32 % AVG Validation Acc 80.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.32 % AVG Validation Acc 80.14 %\n",
      "Split 260\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1e2a510298e43c7a328ea1aa7116a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.05 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.491 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.22 % AVG Validation Acc 80.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.23 % AVG Validation Acc 80.05 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.29 % AVG Validation Acc 80.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.29 % AVG Validation Acc 79.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.31 % AVG Validation Acc 80.05 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.36 % AVG Validation Acc 80.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.36 % AVG Validation Acc 80.05 %\n",
      "Epoch:120/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.34 % AVG Validation Acc 80.05 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.31 % AVG Validation Acc 80.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.30 % AVG Validation Acc 80.05 %\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.31 % AVG Validation Acc 80.05 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.29 % AVG Validation Acc 80.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.31 % AVG Validation Acc 80.05 %\n",
      "Epoch:180/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.34 % AVG Validation Acc 80.05 %\n",
      "Epoch:190/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.33 % AVG Validation Acc 80.05 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.31 % AVG Validation Acc 80.05 %\n",
      "Split 261\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e7d39021cf64998aa27386724cc79d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.500 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.499 AVG Validation Loss:0.499 AVG Training Acc 80.05 % AVG Validation Acc 80.16 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.18 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:80/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:100/200 AVG Training Loss:0.492 AVG Validation Loss:0.497 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.18 % AVG Validation Acc 80.16 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:130/200 AVG Training Loss:0.491 AVG Validation Loss:0.497 AVG Training Acc 80.20 % AVG Validation Acc 80.16 %\n",
      "Epoch:140/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:160/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.21 % AVG Validation Acc 80.16 %\n",
      "Epoch:170/200 AVG Training Loss:0.492 AVG Validation Loss:0.497 AVG Training Acc 80.20 % AVG Validation Acc 80.16 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.492 AVG Validation Loss:0.497 AVG Training Acc 80.21 % AVG Validation Acc 80.16 %\n",
      "Epoch:190/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:200/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Split 262\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f850c44f3374cf7bd68847aa44bbfb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.489 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.488 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.488 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.491 AVG Validation Loss:0.488 AVG Training Acc 80.16 % AVG Validation Acc 80.25 %\n",
      "Epoch:60/200 AVG Training Loss:0.490 AVG Validation Loss:0.487 AVG Training Acc 80.23 % AVG Validation Acc 80.25 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.487 AVG Training Acc 80.33 % AVG Validation Acc 80.25 %\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.487 AVG Training Acc 80.31 % AVG Validation Acc 80.25 %\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.487 AVG Training Acc 80.29 % AVG Validation Acc 80.25 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.488 AVG Validation Loss:0.487 AVG Training Acc 80.30 % AVG Validation Acc 80.25 %\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.487 AVG Training Acc 80.35 % AVG Validation Acc 80.25 %\n",
      "Epoch:120/200 AVG Training Loss:0.488 AVG Validation Loss:0.487 AVG Training Acc 80.32 % AVG Validation Acc 80.16 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.487 AVG Validation Loss:0.487 AVG Training Acc 80.39 % AVG Validation Acc 80.16 %\n",
      "Epoch:140/200 AVG Training Loss:0.488 AVG Validation Loss:0.487 AVG Training Acc 80.38 % AVG Validation Acc 80.16 %\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.487 AVG Training Acc 80.34 % AVG Validation Acc 80.34 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.486 AVG Training Acc 80.28 % AVG Validation Acc 80.25 %\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.487 AVG Training Acc 80.34 % AVG Validation Acc 80.16 %\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.488 AVG Training Acc 80.36 % AVG Validation Acc 80.16 %\n",
      "Epoch:190/200 AVG Training Loss:0.488 AVG Validation Loss:0.487 AVG Training Acc 80.27 % AVG Validation Acc 80.16 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.487 AVG Training Acc 80.35 % AVG Validation Acc 80.34 %\n",
      "Split 263\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10c5a4c531d74c0fb27a0b6440300592",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.491 AVG Training Acc 80.18 % AVG Validation Acc 80.25 %\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.491 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.492 AVG Validation Loss:0.491 AVG Training Acc 80.19 % AVG Validation Acc 80.25 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.20 % AVG Validation Acc 80.25 %\n",
      "Epoch:70/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.20 % AVG Validation Acc 80.25 %\n",
      "Epoch:80/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.20 % AVG Validation Acc 80.25 %\n",
      "Epoch:90/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.21 % AVG Validation Acc 80.25 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.23 % AVG Validation Acc 80.34 %\n",
      "Epoch:110/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.23 % AVG Validation Acc 80.34 %\n",
      "Epoch:120/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.20 % AVG Validation Acc 80.34 %\n",
      "Epoch:130/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.22 % AVG Validation Acc 80.34 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.17 % AVG Validation Acc 80.34 %\n",
      "Epoch:150/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.23 % AVG Validation Acc 80.34 %\n",
      "Epoch:160/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.21 % AVG Validation Acc 80.34 %\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.19 % AVG Validation Acc 80.34 %\n",
      "Epoch:180/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.22 % AVG Validation Acc 80.34 %\n",
      "Epoch:190/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.20 % AVG Validation Acc 80.25 %\n",
      "Epoch   196: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.22 % AVG Validation Acc 80.25 %\n",
      "Split 264\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f12198c6163340e4bea0767f57f0d57a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.18 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.499 AVG Training Acc 80.32 % AVG Validation Acc 80.07 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.59 % AVG Validation Acc 79.80 %\n",
      "Epoch:50/200 AVG Training Loss:0.479 AVG Validation Loss:0.506 AVG Training Acc 80.72 % AVG Validation Acc 79.71 %\n",
      "Epoch:60/200 AVG Training Loss:0.477 AVG Validation Loss:0.512 AVG Training Acc 80.92 % AVG Validation Acc 79.62 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.475 AVG Validation Loss:0.514 AVG Training Acc 80.97 % AVG Validation Acc 79.71 %\n",
      "Epoch:80/200 AVG Training Loss:0.473 AVG Validation Loss:0.517 AVG Training Acc 81.14 % AVG Validation Acc 79.62 %\n",
      "Epoch:90/200 AVG Training Loss:0.473 AVG Validation Loss:0.517 AVG Training Acc 81.18 % AVG Validation Acc 79.62 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.472 AVG Validation Loss:0.514 AVG Training Acc 81.09 % AVG Validation Acc 79.71 %\n",
      "Epoch:110/200 AVG Training Loss:0.472 AVG Validation Loss:0.518 AVG Training Acc 81.21 % AVG Validation Acc 79.80 %\n",
      "Epoch:120/200 AVG Training Loss:0.473 AVG Validation Loss:0.515 AVG Training Acc 81.16 % AVG Validation Acc 79.71 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.473 AVG Validation Loss:0.515 AVG Training Acc 81.03 % AVG Validation Acc 79.71 %\n",
      "Epoch:140/200 AVG Training Loss:0.474 AVG Validation Loss:0.517 AVG Training Acc 81.07 % AVG Validation Acc 79.80 %\n",
      "Epoch:150/200 AVG Training Loss:0.472 AVG Validation Loss:0.518 AVG Training Acc 81.19 % AVG Validation Acc 79.71 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.473 AVG Validation Loss:0.517 AVG Training Acc 81.16 % AVG Validation Acc 79.62 %\n",
      "Epoch:170/200 AVG Training Loss:0.473 AVG Validation Loss:0.518 AVG Training Acc 81.21 % AVG Validation Acc 79.71 %\n",
      "Epoch:180/200 AVG Training Loss:0.473 AVG Validation Loss:0.516 AVG Training Acc 81.10 % AVG Validation Acc 79.71 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.472 AVG Validation Loss:0.518 AVG Training Acc 81.16 % AVG Validation Acc 79.80 %\n",
      "Epoch:200/200 AVG Training Loss:0.472 AVG Validation Loss:0.517 AVG Training Acc 81.22 % AVG Validation Acc 79.71 %\n",
      "Split 265\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad2ad597e6704760ab92eac95ed0a5bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.16 % AVG Validation Acc 80.07 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.18 % AVG Validation Acc 79.89 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.37 % AVG Validation Acc 79.89 %\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.41 % AVG Validation Acc 79.80 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.502 AVG Training Acc 80.43 % AVG Validation Acc 79.35 %\n",
      "Epoch:70/200 AVG Training Loss:0.483 AVG Validation Loss:0.503 AVG Training Acc 80.56 % AVG Validation Acc 79.17 %\n",
      "Epoch:80/200 AVG Training Loss:0.482 AVG Validation Loss:0.503 AVG Training Acc 80.56 % AVG Validation Acc 79.17 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.482 AVG Validation Loss:0.504 AVG Training Acc 80.61 % AVG Validation Acc 79.08 %\n",
      "Epoch:100/200 AVG Training Loss:0.483 AVG Validation Loss:0.504 AVG Training Acc 80.66 % AVG Validation Acc 79.08 %\n",
      "Epoch:110/200 AVG Training Loss:0.482 AVG Validation Loss:0.504 AVG Training Acc 80.59 % AVG Validation Acc 79.08 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.483 AVG Validation Loss:0.504 AVG Training Acc 80.62 % AVG Validation Acc 79.08 %\n",
      "Epoch:130/200 AVG Training Loss:0.482 AVG Validation Loss:0.504 AVG Training Acc 80.57 % AVG Validation Acc 79.08 %\n",
      "Epoch:140/200 AVG Training Loss:0.482 AVG Validation Loss:0.504 AVG Training Acc 80.52 % AVG Validation Acc 79.08 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.483 AVG Validation Loss:0.504 AVG Training Acc 80.64 % AVG Validation Acc 79.08 %\n",
      "Epoch:160/200 AVG Training Loss:0.483 AVG Validation Loss:0.504 AVG Training Acc 80.57 % AVG Validation Acc 79.08 %\n",
      "Epoch:170/200 AVG Training Loss:0.482 AVG Validation Loss:0.504 AVG Training Acc 80.54 % AVG Validation Acc 79.08 %\n",
      "Epoch:180/200 AVG Training Loss:0.484 AVG Validation Loss:0.504 AVG Training Acc 80.55 % AVG Validation Acc 79.08 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.484 AVG Validation Loss:0.504 AVG Training Acc 80.59 % AVG Validation Acc 79.08 %\n",
      "Epoch:200/200 AVG Training Loss:0.482 AVG Validation Loss:0.504 AVG Training Acc 80.57 % AVG Validation Acc 79.08 %\n",
      "Split 266\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0871e8cd89744b689e0d8879a28ee28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.28 % AVG Validation Acc 79.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.32 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.489 AVG Training Acc 80.34 % AVG Validation Acc 80.05 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.485 AVG Validation Loss:0.490 AVG Training Acc 80.38 % AVG Validation Acc 79.96 %\n",
      "Epoch:70/200 AVG Training Loss:0.485 AVG Validation Loss:0.490 AVG Training Acc 80.48 % AVG Validation Acc 79.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.485 AVG Validation Loss:0.491 AVG Training Acc 80.47 % AVG Validation Acc 79.96 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.485 AVG Validation Loss:0.491 AVG Training Acc 80.50 % AVG Validation Acc 79.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.485 AVG Validation Loss:0.489 AVG Training Acc 80.49 % AVG Validation Acc 79.96 %\n",
      "Epoch:110/200 AVG Training Loss:0.484 AVG Validation Loss:0.491 AVG Training Acc 80.51 % AVG Validation Acc 79.96 %\n",
      "Epoch:120/200 AVG Training Loss:0.485 AVG Validation Loss:0.491 AVG Training Acc 80.37 % AVG Validation Acc 79.96 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.484 AVG Validation Loss:0.490 AVG Training Acc 80.39 % AVG Validation Acc 79.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.485 AVG Validation Loss:0.490 AVG Training Acc 80.41 % AVG Validation Acc 79.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.490 AVG Training Acc 80.46 % AVG Validation Acc 79.96 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.490 AVG Training Acc 80.46 % AVG Validation Acc 79.96 %\n",
      "Epoch:170/200 AVG Training Loss:0.485 AVG Validation Loss:0.491 AVG Training Acc 80.40 % AVG Validation Acc 79.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.485 AVG Validation Loss:0.490 AVG Training Acc 80.40 % AVG Validation Acc 79.96 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.485 AVG Validation Loss:0.491 AVG Training Acc 80.44 % AVG Validation Acc 79.96 %\n",
      "Epoch:200/200 AVG Training Loss:0.485 AVG Validation Loss:0.491 AVG Training Acc 80.45 % AVG Validation Acc 79.96 %\n",
      "Split 267\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "369ebc136e0b423eaf4e746836a5f4d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 80.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 80.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.497 AVG Training Acc 80.23 % AVG Validation Acc 79.96 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.498 AVG Training Acc 80.24 % AVG Validation Acc 79.96 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.498 AVG Training Acc 80.25 % AVG Validation Acc 79.96 %\n",
      "Epoch:70/200 AVG Training Loss:0.490 AVG Validation Loss:0.498 AVG Training Acc 80.23 % AVG Validation Acc 79.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.490 AVG Validation Loss:0.499 AVG Training Acc 80.21 % AVG Validation Acc 79.96 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.489 AVG Validation Loss:0.499 AVG Training Acc 80.23 % AVG Validation Acc 79.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.489 AVG Validation Loss:0.499 AVG Training Acc 80.25 % AVG Validation Acc 79.96 %\n",
      "Epoch:110/200 AVG Training Loss:0.490 AVG Validation Loss:0.499 AVG Training Acc 80.24 % AVG Validation Acc 79.96 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.490 AVG Validation Loss:0.499 AVG Training Acc 80.21 % AVG Validation Acc 79.96 %\n",
      "Epoch:130/200 AVG Training Loss:0.489 AVG Validation Loss:0.499 AVG Training Acc 80.23 % AVG Validation Acc 79.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.489 AVG Validation Loss:0.499 AVG Training Acc 80.27 % AVG Validation Acc 79.96 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.489 AVG Validation Loss:0.499 AVG Training Acc 80.24 % AVG Validation Acc 79.96 %\n",
      "Epoch:160/200 AVG Training Loss:0.490 AVG Validation Loss:0.499 AVG Training Acc 80.21 % AVG Validation Acc 79.96 %\n",
      "Epoch:170/200 AVG Training Loss:0.489 AVG Validation Loss:0.499 AVG Training Acc 80.23 % AVG Validation Acc 79.96 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.489 AVG Validation Loss:0.499 AVG Training Acc 80.26 % AVG Validation Acc 79.96 %\n",
      "Epoch:190/200 AVG Training Loss:0.489 AVG Validation Loss:0.499 AVG Training Acc 80.26 % AVG Validation Acc 79.96 %\n",
      "Epoch:200/200 AVG Training Loss:0.489 AVG Validation Loss:0.499 AVG Training Acc 80.25 % AVG Validation Acc 79.96 %\n",
      "Split 268\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fec0a17addf4590b03f79353e8afaa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.20 % AVG Validation Acc 80.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.24 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.25 % AVG Validation Acc 80.05 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.501 AVG Training Acc 80.25 % AVG Validation Acc 79.96 %\n",
      "Epoch:70/200 AVG Training Loss:0.487 AVG Validation Loss:0.502 AVG Training Acc 80.23 % AVG Validation Acc 79.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.487 AVG Validation Loss:0.506 AVG Training Acc 80.24 % AVG Validation Acc 79.96 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.487 AVG Validation Loss:0.505 AVG Training Acc 80.27 % AVG Validation Acc 79.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.488 AVG Validation Loss:0.505 AVG Training Acc 80.24 % AVG Validation Acc 79.96 %\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.505 AVG Training Acc 80.24 % AVG Validation Acc 79.96 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.487 AVG Validation Loss:0.505 AVG Training Acc 80.26 % AVG Validation Acc 79.96 %\n",
      "Epoch:130/200 AVG Training Loss:0.487 AVG Validation Loss:0.505 AVG Training Acc 80.27 % AVG Validation Acc 79.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.505 AVG Training Acc 80.26 % AVG Validation Acc 79.96 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.505 AVG Training Acc 80.29 % AVG Validation Acc 79.96 %\n",
      "Epoch:160/200 AVG Training Loss:0.487 AVG Validation Loss:0.505 AVG Training Acc 80.30 % AVG Validation Acc 79.96 %\n",
      "Epoch:170/200 AVG Training Loss:0.487 AVG Validation Loss:0.505 AVG Training Acc 80.30 % AVG Validation Acc 79.96 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.487 AVG Validation Loss:0.505 AVG Training Acc 80.26 % AVG Validation Acc 79.96 %\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.505 AVG Training Acc 80.28 % AVG Validation Acc 79.96 %\n",
      "Epoch:200/200 AVG Training Loss:0.487 AVG Validation Loss:0.505 AVG Training Acc 80.29 % AVG Validation Acc 79.96 %\n",
      "Split 269\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cec7f82f9c2f4ec6b4245bfea4df2e19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.498 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.493 AVG Training Acc 80.10 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.493 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.16 % AVG Validation Acc 80.23 %\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.16 % AVG Validation Acc 80.23 %\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.22 % AVG Validation Acc 80.23 %\n",
      "Epoch    70: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.25 % AVG Validation Acc 80.32 %\n",
      "Epoch:90/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.30 % AVG Validation Acc 80.32 %\n",
      "Epoch:100/200 AVG Training Loss:0.486 AVG Validation Loss:0.493 AVG Training Acc 80.30 % AVG Validation Acc 80.23 %\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.28 % AVG Validation Acc 80.23 %\n",
      "Epoch:120/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.32 % AVG Validation Acc 80.23 %\n",
      "Epoch:130/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.30 % AVG Validation Acc 80.23 %\n",
      "Epoch   132: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.486 AVG Validation Loss:0.493 AVG Training Acc 80.26 % AVG Validation Acc 80.23 %\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.493 AVG Training Acc 80.38 % AVG Validation Acc 80.23 %\n",
      "Epoch:160/200 AVG Training Loss:0.486 AVG Validation Loss:0.493 AVG Training Acc 80.27 % AVG Validation Acc 80.23 %\n",
      "Epoch   163: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.486 AVG Validation Loss:0.493 AVG Training Acc 80.29 % AVG Validation Acc 80.23 %\n",
      "Epoch:180/200 AVG Training Loss:0.486 AVG Validation Loss:0.493 AVG Training Acc 80.36 % AVG Validation Acc 80.23 %\n",
      "Epoch:190/200 AVG Training Loss:0.486 AVG Validation Loss:0.493 AVG Training Acc 80.39 % AVG Validation Acc 80.23 %\n",
      "Epoch   194: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.29 % AVG Validation Acc 80.23 %\n",
      "Split 270\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4cc3419e86a64a65a5c7ecb948f20763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.498 AVG Training Acc 80.11 % AVG Validation Acc 80.05 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.501 AVG Training Acc 80.23 % AVG Validation Acc 79.69 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.505 AVG Training Acc 80.31 % AVG Validation Acc 79.42 %\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.507 AVG Training Acc 80.36 % AVG Validation Acc 79.42 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.485 AVG Validation Loss:0.508 AVG Training Acc 80.42 % AVG Validation Acc 79.51 %\n",
      "Epoch:70/200 AVG Training Loss:0.485 AVG Validation Loss:0.507 AVG Training Acc 80.41 % AVG Validation Acc 79.51 %\n",
      "Epoch:80/200 AVG Training Loss:0.484 AVG Validation Loss:0.509 AVG Training Acc 80.49 % AVG Validation Acc 79.51 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.485 AVG Validation Loss:0.508 AVG Training Acc 80.44 % AVG Validation Acc 79.51 %\n",
      "Epoch:100/200 AVG Training Loss:0.484 AVG Validation Loss:0.509 AVG Training Acc 80.44 % AVG Validation Acc 79.51 %\n",
      "Epoch:110/200 AVG Training Loss:0.485 AVG Validation Loss:0.508 AVG Training Acc 80.49 % AVG Validation Acc 79.51 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.485 AVG Validation Loss:0.508 AVG Training Acc 80.44 % AVG Validation Acc 79.51 %\n",
      "Epoch:130/200 AVG Training Loss:0.484 AVG Validation Loss:0.509 AVG Training Acc 80.46 % AVG Validation Acc 79.51 %\n",
      "Epoch:140/200 AVG Training Loss:0.484 AVG Validation Loss:0.509 AVG Training Acc 80.45 % AVG Validation Acc 79.51 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.508 AVG Training Acc 80.45 % AVG Validation Acc 79.51 %\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.508 AVG Training Acc 80.57 % AVG Validation Acc 79.51 %\n",
      "Epoch:170/200 AVG Training Loss:0.485 AVG Validation Loss:0.508 AVG Training Acc 80.46 % AVG Validation Acc 79.51 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.485 AVG Validation Loss:0.508 AVG Training Acc 80.53 % AVG Validation Acc 79.60 %\n",
      "Epoch:190/200 AVG Training Loss:0.484 AVG Validation Loss:0.508 AVG Training Acc 80.46 % AVG Validation Acc 79.51 %\n",
      "Epoch:200/200 AVG Training Loss:0.484 AVG Validation Loss:0.508 AVG Training Acc 80.49 % AVG Validation Acc 79.51 %\n",
      "Split 271\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3c4e61c19b425d92261a0746a7a89b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.20 % AVG Validation Acc 80.25 %\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.32 % AVG Validation Acc 79.98 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.33 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.27 % AVG Validation Acc 80.07 %\n",
      "Epoch:80/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.30 % AVG Validation Acc 79.89 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.34 % AVG Validation Acc 79.89 %\n",
      "Epoch:100/200 AVG Training Loss:0.486 AVG Validation Loss:0.493 AVG Training Acc 80.35 % AVG Validation Acc 79.98 %\n",
      "Epoch:110/200 AVG Training Loss:0.485 AVG Validation Loss:0.493 AVG Training Acc 80.36 % AVG Validation Acc 79.89 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.45 % AVG Validation Acc 79.80 %\n",
      "Epoch:130/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.40 % AVG Validation Acc 79.89 %\n",
      "Epoch:140/200 AVG Training Loss:0.486 AVG Validation Loss:0.493 AVG Training Acc 80.39 % AVG Validation Acc 79.98 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.486 AVG Validation Loss:0.493 AVG Training Acc 80.43 % AVG Validation Acc 79.89 %\n",
      "Epoch:160/200 AVG Training Loss:0.486 AVG Validation Loss:0.493 AVG Training Acc 80.41 % AVG Validation Acc 79.80 %\n",
      "Epoch:170/200 AVG Training Loss:0.486 AVG Validation Loss:0.493 AVG Training Acc 80.38 % AVG Validation Acc 79.89 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.39 % AVG Validation Acc 79.98 %\n",
      "Epoch:190/200 AVG Training Loss:0.486 AVG Validation Loss:0.493 AVG Training Acc 80.40 % AVG Validation Acc 79.98 %\n",
      "Epoch:200/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.31 % AVG Validation Acc 79.98 %\n",
      "Split 272\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e51062de9f464f12a26c99489faf7b9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.21 % AVG Validation Acc 79.98 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.500 AVG Training Acc 80.40 % AVG Validation Acc 79.80 %\n",
      "Epoch:50/200 AVG Training Loss:0.482 AVG Validation Loss:0.506 AVG Training Acc 80.55 % AVG Validation Acc 79.71 %\n",
      "Epoch:60/200 AVG Training Loss:0.480 AVG Validation Loss:0.509 AVG Training Acc 80.59 % AVG Validation Acc 79.71 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.477 AVG Validation Loss:0.513 AVG Training Acc 80.79 % AVG Validation Acc 79.62 %\n",
      "Epoch:80/200 AVG Training Loss:0.477 AVG Validation Loss:0.513 AVG Training Acc 80.82 % AVG Validation Acc 79.53 %\n",
      "Epoch:90/200 AVG Training Loss:0.477 AVG Validation Loss:0.513 AVG Training Acc 80.84 % AVG Validation Acc 79.53 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.477 AVG Validation Loss:0.513 AVG Training Acc 80.74 % AVG Validation Acc 79.53 %\n",
      "Epoch:110/200 AVG Training Loss:0.477 AVG Validation Loss:0.511 AVG Training Acc 80.85 % AVG Validation Acc 79.62 %\n",
      "Epoch:120/200 AVG Training Loss:0.477 AVG Validation Loss:0.511 AVG Training Acc 80.85 % AVG Validation Acc 79.62 %\n",
      "Epoch:130/200 AVG Training Loss:0.476 AVG Validation Loss:0.511 AVG Training Acc 80.90 % AVG Validation Acc 79.62 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.477 AVG Validation Loss:0.512 AVG Training Acc 80.75 % AVG Validation Acc 79.53 %\n",
      "Epoch:150/200 AVG Training Loss:0.476 AVG Validation Loss:0.512 AVG Training Acc 80.79 % AVG Validation Acc 79.53 %\n",
      "Epoch:160/200 AVG Training Loss:0.475 AVG Validation Loss:0.511 AVG Training Acc 80.89 % AVG Validation Acc 79.53 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.476 AVG Validation Loss:0.511 AVG Training Acc 80.91 % AVG Validation Acc 79.44 %\n",
      "Epoch:180/200 AVG Training Loss:0.476 AVG Validation Loss:0.512 AVG Training Acc 80.74 % AVG Validation Acc 79.53 %\n",
      "Epoch:190/200 AVG Training Loss:0.477 AVG Validation Loss:0.511 AVG Training Acc 80.82 % AVG Validation Acc 79.53 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.476 AVG Validation Loss:0.513 AVG Training Acc 80.89 % AVG Validation Acc 79.44 %\n",
      "Split 273\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ce2a5cbb6974155a8fa3d599f0ee6cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.19 % AVG Validation Acc 79.98 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.29 % AVG Validation Acc 79.98 %\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.28 % AVG Validation Acc 79.98 %\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.34 % AVG Validation Acc 79.98 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.33 % AVG Validation Acc 79.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.31 % AVG Validation Acc 79.98 %\n",
      "Epoch:90/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.36 % AVG Validation Acc 79.98 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.28 % AVG Validation Acc 79.98 %\n",
      "Epoch:110/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.30 % AVG Validation Acc 79.98 %\n",
      "Epoch:120/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.38 % AVG Validation Acc 79.98 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.38 % AVG Validation Acc 79.98 %\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.41 % AVG Validation Acc 79.98 %\n",
      "Epoch:150/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.35 % AVG Validation Acc 79.98 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.39 % AVG Validation Acc 79.98 %\n",
      "Epoch:170/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.36 % AVG Validation Acc 79.98 %\n",
      "Epoch:180/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.39 % AVG Validation Acc 79.98 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.42 % AVG Validation Acc 79.98 %\n",
      "Epoch:200/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.38 % AVG Validation Acc 79.98 %\n",
      "Split 274\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f6b125821645998caf16f84a4c48da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.492 AVG Training Acc 80.09 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.24 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.25 % AVG Validation Acc 80.34 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.481 AVG Validation Loss:0.501 AVG Training Acc 80.56 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.476 AVG Validation Loss:0.514 AVG Training Acc 80.81 % AVG Validation Acc 79.89 %\n",
      "Epoch:80/200 AVG Training Loss:0.475 AVG Validation Loss:0.512 AVG Training Acc 80.77 % AVG Validation Acc 79.89 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.472 AVG Validation Loss:0.514 AVG Training Acc 80.91 % AVG Validation Acc 80.07 %\n",
      "Epoch:100/200 AVG Training Loss:0.471 AVG Validation Loss:0.524 AVG Training Acc 81.03 % AVG Validation Acc 79.89 %\n",
      "Epoch:110/200 AVG Training Loss:0.470 AVG Validation Loss:0.519 AVG Training Acc 81.06 % AVG Validation Acc 79.98 %\n",
      "Epoch:120/200 AVG Training Loss:0.469 AVG Validation Loss:0.519 AVG Training Acc 81.13 % AVG Validation Acc 80.25 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.469 AVG Validation Loss:0.517 AVG Training Acc 81.16 % AVG Validation Acc 80.25 %\n",
      "Epoch:140/200 AVG Training Loss:0.469 AVG Validation Loss:0.521 AVG Training Acc 81.07 % AVG Validation Acc 79.89 %\n",
      "Epoch:150/200 AVG Training Loss:0.470 AVG Validation Loss:0.519 AVG Training Acc 81.01 % AVG Validation Acc 80.07 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.470 AVG Validation Loss:0.521 AVG Training Acc 81.03 % AVG Validation Acc 79.98 %\n",
      "Epoch:170/200 AVG Training Loss:0.469 AVG Validation Loss:0.521 AVG Training Acc 81.21 % AVG Validation Acc 79.89 %\n",
      "Epoch:180/200 AVG Training Loss:0.470 AVG Validation Loss:0.519 AVG Training Acc 81.16 % AVG Validation Acc 80.16 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.469 AVG Validation Loss:0.520 AVG Training Acc 81.16 % AVG Validation Acc 79.98 %\n",
      "Epoch:200/200 AVG Training Loss:0.469 AVG Validation Loss:0.514 AVG Training Acc 81.05 % AVG Validation Acc 80.16 %\n",
      "Split 275\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8e219c89aae46288b8d5275409d02ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.498 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.497 AVG Training Acc 80.16 % AVG Validation Acc 79.98 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.499 AVG Training Acc 80.15 % AVG Validation Acc 79.98 %\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.501 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.500 AVG Training Acc 80.22 % AVG Validation Acc 80.07 %\n",
      "Epoch:70/200 AVG Training Loss:0.487 AVG Validation Loss:0.502 AVG Training Acc 80.23 % AVG Validation Acc 79.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.502 AVG Training Acc 80.24 % AVG Validation Acc 79.89 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.487 AVG Validation Loss:0.502 AVG Training Acc 80.26 % AVG Validation Acc 79.89 %\n",
      "Epoch:100/200 AVG Training Loss:0.488 AVG Validation Loss:0.502 AVG Training Acc 80.22 % AVG Validation Acc 79.98 %\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.503 AVG Training Acc 80.25 % AVG Validation Acc 79.80 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.487 AVG Validation Loss:0.503 AVG Training Acc 80.27 % AVG Validation Acc 79.98 %\n",
      "Epoch:130/200 AVG Training Loss:0.487 AVG Validation Loss:0.502 AVG Training Acc 80.29 % AVG Validation Acc 79.98 %\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.503 AVG Training Acc 80.28 % AVG Validation Acc 79.98 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.487 AVG Validation Loss:0.502 AVG Training Acc 80.26 % AVG Validation Acc 79.89 %\n",
      "Epoch:160/200 AVG Training Loss:0.487 AVG Validation Loss:0.502 AVG Training Acc 80.25 % AVG Validation Acc 79.89 %\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.502 AVG Training Acc 80.27 % AVG Validation Acc 79.98 %\n",
      "Epoch:180/200 AVG Training Loss:0.487 AVG Validation Loss:0.503 AVG Training Acc 80.15 % AVG Validation Acc 79.89 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.503 AVG Training Acc 80.23 % AVG Validation Acc 79.98 %\n",
      "Epoch:200/200 AVG Training Loss:0.487 AVG Validation Loss:0.502 AVG Training Acc 80.23 % AVG Validation Acc 79.89 %\n",
      "Split 276\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8be7f12d36cd4b7fac37a36f10347aa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.498 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.21 % AVG Validation Acc 79.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.31 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.29 % AVG Validation Acc 79.96 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.486 AVG Validation Loss:0.493 AVG Training Acc 80.28 % AVG Validation Acc 79.96 %\n",
      "Epoch:70/200 AVG Training Loss:0.485 AVG Validation Loss:0.493 AVG Training Acc 80.30 % AVG Validation Acc 79.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.484 AVG Validation Loss:0.493 AVG Training Acc 80.28 % AVG Validation Acc 79.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.485 AVG Validation Loss:0.493 AVG Training Acc 80.44 % AVG Validation Acc 79.96 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.484 AVG Validation Loss:0.493 AVG Training Acc 80.41 % AVG Validation Acc 79.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.485 AVG Validation Loss:0.493 AVG Training Acc 80.36 % AVG Validation Acc 79.87 %\n",
      "Epoch:120/200 AVG Training Loss:0.484 AVG Validation Loss:0.493 AVG Training Acc 80.34 % AVG Validation Acc 79.87 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.484 AVG Validation Loss:0.493 AVG Training Acc 80.38 % AVG Validation Acc 79.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.484 AVG Validation Loss:0.493 AVG Training Acc 80.32 % AVG Validation Acc 79.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.484 AVG Validation Loss:0.493 AVG Training Acc 80.35 % AVG Validation Acc 79.87 %\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.493 AVG Training Acc 80.35 % AVG Validation Acc 79.96 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.484 AVG Validation Loss:0.493 AVG Training Acc 80.42 % AVG Validation Acc 79.78 %\n",
      "Epoch:180/200 AVG Training Loss:0.485 AVG Validation Loss:0.493 AVG Training Acc 80.25 % AVG Validation Acc 79.78 %\n",
      "Epoch:190/200 AVG Training Loss:0.484 AVG Validation Loss:0.493 AVG Training Acc 80.32 % AVG Validation Acc 79.87 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.485 AVG Validation Loss:0.493 AVG Training Acc 80.35 % AVG Validation Acc 79.87 %\n",
      "Split 277\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97bfb6775ab5424ebb42134012e1e95c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.18 % AVG Validation Acc 80.23 %\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.13 % AVG Validation Acc 80.23 %\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.22 % AVG Validation Acc 80.23 %\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.18 % AVG Validation Acc 80.23 %\n",
      "Epoch:100/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.19 % AVG Validation Acc 80.23 %\n",
      "Epoch   104: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.18 % AVG Validation Acc 80.23 %\n",
      "Epoch:120/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.18 % AVG Validation Acc 80.23 %\n",
      "Epoch:130/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.18 % AVG Validation Acc 80.23 %\n",
      "Epoch   135: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.18 % AVG Validation Acc 80.23 %\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.19 % AVG Validation Acc 80.23 %\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.16 % AVG Validation Acc 80.23 %\n",
      "Epoch   166: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.18 % AVG Validation Acc 80.23 %\n",
      "Epoch:180/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.17 % AVG Validation Acc 80.23 %\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.20 % AVG Validation Acc 80.23 %\n",
      "Epoch   197: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.16 % AVG Validation Acc 80.23 %\n",
      "Split 278\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b327942571142d2b954e2ac12edfe56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.27 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.490 AVG Training Acc 80.34 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.36 % AVG Validation Acc 79.96 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.32 % AVG Validation Acc 79.96 %\n",
      "Epoch:70/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.49 % AVG Validation Acc 79.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.485 AVG Validation Loss:0.491 AVG Training Acc 80.40 % AVG Validation Acc 79.96 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.485 AVG Validation Loss:0.490 AVG Training Acc 80.51 % AVG Validation Acc 79.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.486 AVG Validation Loss:0.491 AVG Training Acc 80.41 % AVG Validation Acc 79.96 %\n",
      "Epoch:110/200 AVG Training Loss:0.485 AVG Validation Loss:0.490 AVG Training Acc 80.47 % AVG Validation Acc 79.96 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.44 % AVG Validation Acc 79.96 %\n",
      "Epoch:130/200 AVG Training Loss:0.485 AVG Validation Loss:0.490 AVG Training Acc 80.47 % AVG Validation Acc 80.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.486 AVG Validation Loss:0.491 AVG Training Acc 80.36 % AVG Validation Acc 79.96 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.486 AVG Validation Loss:0.491 AVG Training Acc 80.38 % AVG Validation Acc 79.96 %\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.491 AVG Training Acc 80.39 % AVG Validation Acc 79.96 %\n",
      "Epoch:170/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.46 % AVG Validation Acc 79.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.486 AVG Validation Loss:0.491 AVG Training Acc 80.39 % AVG Validation Acc 79.96 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.486 AVG Validation Loss:0.491 AVG Training Acc 80.44 % AVG Validation Acc 80.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.34 % AVG Validation Acc 79.96 %\n",
      "Split 279\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada0d33ffb3040ad93c15b8d79e419bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.24 % AVG Validation Acc 80.14 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Split 280\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a596ff85a5a4cf7b73a4cd257af5e4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.29 % AVG Validation Acc 79.69 %\n",
      "Epoch:40/200 AVG Training Loss:0.485 AVG Validation Loss:0.499 AVG Training Acc 80.61 % AVG Validation Acc 79.69 %\n",
      "Epoch:50/200 AVG Training Loss:0.484 AVG Validation Loss:0.498 AVG Training Acc 80.50 % AVG Validation Acc 79.69 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.480 AVG Validation Loss:0.503 AVG Training Acc 80.78 % AVG Validation Acc 79.42 %\n",
      "Epoch:70/200 AVG Training Loss:0.478 AVG Validation Loss:0.503 AVG Training Acc 80.92 % AVG Validation Acc 79.42 %\n",
      "Epoch:80/200 AVG Training Loss:0.478 AVG Validation Loss:0.505 AVG Training Acc 80.75 % AVG Validation Acc 79.33 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.478 AVG Validation Loss:0.506 AVG Training Acc 80.92 % AVG Validation Acc 79.42 %\n",
      "Epoch:100/200 AVG Training Loss:0.477 AVG Validation Loss:0.506 AVG Training Acc 80.80 % AVG Validation Acc 79.33 %\n",
      "Epoch:110/200 AVG Training Loss:0.477 AVG Validation Loss:0.506 AVG Training Acc 80.89 % AVG Validation Acc 79.42 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.477 AVG Validation Loss:0.507 AVG Training Acc 80.95 % AVG Validation Acc 79.33 %\n",
      "Epoch:130/200 AVG Training Loss:0.477 AVG Validation Loss:0.507 AVG Training Acc 80.99 % AVG Validation Acc 79.33 %\n",
      "Epoch:140/200 AVG Training Loss:0.478 AVG Validation Loss:0.507 AVG Training Acc 80.85 % AVG Validation Acc 79.33 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.478 AVG Validation Loss:0.508 AVG Training Acc 80.85 % AVG Validation Acc 79.33 %\n",
      "Epoch:160/200 AVG Training Loss:0.478 AVG Validation Loss:0.507 AVG Training Acc 80.91 % AVG Validation Acc 79.33 %\n",
      "Epoch:170/200 AVG Training Loss:0.478 AVG Validation Loss:0.507 AVG Training Acc 80.85 % AVG Validation Acc 79.33 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.477 AVG Validation Loss:0.506 AVG Training Acc 80.94 % AVG Validation Acc 79.33 %\n",
      "Epoch:190/200 AVG Training Loss:0.478 AVG Validation Loss:0.507 AVG Training Acc 80.88 % AVG Validation Acc 79.33 %\n",
      "Epoch:200/200 AVG Training Loss:0.478 AVG Validation Loss:0.507 AVG Training Acc 80.96 % AVG Validation Acc 79.33 %\n",
      "Split 281\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f05fd2990ea3412390109d917f25f609",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.499 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.493 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 79.89 %\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.16 % AVG Validation Acc 79.89 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.22 % AVG Validation Acc 79.62 %\n",
      "Epoch:70/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.32 % AVG Validation Acc 79.62 %\n",
      "Epoch:80/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.26 % AVG Validation Acc 79.62 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.22 % AVG Validation Acc 79.53 %\n",
      "Epoch:100/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.32 % AVG Validation Acc 79.53 %\n",
      "Epoch:110/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.25 % AVG Validation Acc 79.62 %\n",
      "Epoch:120/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.28 % AVG Validation Acc 79.71 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.26 % AVG Validation Acc 79.53 %\n",
      "Epoch:140/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.25 % AVG Validation Acc 79.62 %\n",
      "Epoch:150/200 AVG Training Loss:0.487 AVG Validation Loss:0.498 AVG Training Acc 80.29 % AVG Validation Acc 79.62 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.31 % AVG Validation Acc 79.62 %\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.21 % AVG Validation Acc 79.62 %\n",
      "Epoch:180/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.38 % AVG Validation Acc 79.62 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.27 % AVG Validation Acc 79.62 %\n",
      "Epoch:200/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.24 % AVG Validation Acc 79.62 %\n",
      "Split 282\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58ac4f0a067541b68a170dcb81d2f4e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.500 AVG Validation Loss:0.500 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.497 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.13 % AVG Validation Acc 80.25 %\n",
      "Epoch:80/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.25 %\n",
      "Epoch:90/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.15 % AVG Validation Acc 80.25 %\n",
      "Epoch:100/200 AVG Training Loss:0.491 AVG Validation Loss:0.493 AVG Training Acc 80.20 % AVG Validation Acc 80.25 %\n",
      "Epoch:110/200 AVG Training Loss:0.491 AVG Validation Loss:0.493 AVG Training Acc 80.19 % AVG Validation Acc 80.25 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.18 % AVG Validation Acc 80.25 %\n",
      "Epoch:130/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.17 % AVG Validation Acc 80.25 %\n",
      "Epoch:140/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.15 % AVG Validation Acc 80.25 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.17 % AVG Validation Acc 80.25 %\n",
      "Epoch:160/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 80.25 %\n",
      "Epoch:170/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.17 % AVG Validation Acc 80.25 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.25 %\n",
      "Epoch:190/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.25 %\n",
      "Epoch:200/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.25 %\n",
      "Split 283\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c1b880bf53b4e19859507da5d31c8f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.492 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.16 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.13 % AVG Validation Acc 79.80 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.09 % AVG Validation Acc 79.80 %\n",
      "Epoch:80/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.07 % AVG Validation Acc 79.89 %\n",
      "Epoch:90/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.15 % AVG Validation Acc 79.98 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.18 % AVG Validation Acc 79.80 %\n",
      "Epoch:110/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.22 % AVG Validation Acc 79.80 %\n",
      "Epoch:120/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.17 % AVG Validation Acc 79.80 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.12 % AVG Validation Acc 79.80 %\n",
      "Epoch:140/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.20 % AVG Validation Acc 79.80 %\n",
      "Epoch:150/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.15 % AVG Validation Acc 79.80 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.16 % AVG Validation Acc 79.80 %\n",
      "Epoch:170/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.17 % AVG Validation Acc 79.80 %\n",
      "Epoch:180/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.18 % AVG Validation Acc 79.80 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.20 % AVG Validation Acc 79.80 %\n",
      "Epoch:200/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.18 % AVG Validation Acc 79.80 %\n",
      "Split 284\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75c950ae87084161b51421d32970aef6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.498 AVG Validation Loss:0.499 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.489 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.490 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.22 % AVG Validation Acc 80.16 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.27 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.23 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.28 % AVG Validation Acc 80.16 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.27 % AVG Validation Acc 80.16 %\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.24 % AVG Validation Acc 80.16 %\n",
      "Epoch:100/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.24 % AVG Validation Acc 80.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.21 % AVG Validation Acc 80.16 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.30 % AVG Validation Acc 80.16 %\n",
      "Epoch:130/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.33 % AVG Validation Acc 80.16 %\n",
      "Epoch:140/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.24 % AVG Validation Acc 80.16 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.26 % AVG Validation Acc 80.16 %\n",
      "Epoch:160/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.23 % AVG Validation Acc 80.16 %\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.28 % AVG Validation Acc 80.16 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.27 % AVG Validation Acc 80.16 %\n",
      "Epoch:190/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.25 % AVG Validation Acc 80.16 %\n",
      "Epoch:200/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.30 % AVG Validation Acc 80.16 %\n",
      "Split 285\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ff85a50b274cdebb7edefc16d468f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.07 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.493 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:60/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.16 % AVG Validation Acc 80.07 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.19 % AVG Validation Acc 80.07 %\n",
      "Epoch:80/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.20 % AVG Validation Acc 80.16 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:120/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.18 % AVG Validation Acc 80.16 %\n",
      "Epoch:140/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:150/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:170/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:180/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:200/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.20 % AVG Validation Acc 80.16 %\n",
      "Split 286\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b1fbb3a8b30441e88dfcd3fa22acf1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.498 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.498 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.25 % AVG Validation Acc 79.87 %\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.36 % AVG Validation Acc 79.96 %\n",
      "Epoch:50/200 AVG Training Loss:0.484 AVG Validation Loss:0.500 AVG Training Acc 80.54 % AVG Validation Acc 79.78 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.482 AVG Validation Loss:0.502 AVG Training Acc 80.60 % AVG Validation Acc 79.60 %\n",
      "Epoch:70/200 AVG Training Loss:0.482 AVG Validation Loss:0.502 AVG Training Acc 80.65 % AVG Validation Acc 79.51 %\n",
      "Epoch:80/200 AVG Training Loss:0.479 AVG Validation Loss:0.504 AVG Training Acc 80.73 % AVG Validation Acc 79.42 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.480 AVG Validation Loss:0.502 AVG Training Acc 80.74 % AVG Validation Acc 79.60 %\n",
      "Epoch:100/200 AVG Training Loss:0.480 AVG Validation Loss:0.503 AVG Training Acc 80.83 % AVG Validation Acc 79.51 %\n",
      "Epoch:110/200 AVG Training Loss:0.481 AVG Validation Loss:0.502 AVG Training Acc 80.77 % AVG Validation Acc 79.51 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.479 AVG Validation Loss:0.502 AVG Training Acc 80.71 % AVG Validation Acc 79.60 %\n",
      "Epoch:130/200 AVG Training Loss:0.480 AVG Validation Loss:0.502 AVG Training Acc 80.71 % AVG Validation Acc 79.60 %\n",
      "Epoch:140/200 AVG Training Loss:0.479 AVG Validation Loss:0.504 AVG Training Acc 80.80 % AVG Validation Acc 79.51 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.480 AVG Validation Loss:0.504 AVG Training Acc 80.70 % AVG Validation Acc 79.51 %\n",
      "Epoch:160/200 AVG Training Loss:0.479 AVG Validation Loss:0.504 AVG Training Acc 80.82 % AVG Validation Acc 79.51 %\n",
      "Epoch:170/200 AVG Training Loss:0.479 AVG Validation Loss:0.502 AVG Training Acc 80.84 % AVG Validation Acc 79.60 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.479 AVG Validation Loss:0.504 AVG Training Acc 80.74 % AVG Validation Acc 79.51 %\n",
      "Epoch:190/200 AVG Training Loss:0.479 AVG Validation Loss:0.504 AVG Training Acc 80.80 % AVG Validation Acc 79.51 %\n",
      "Epoch:200/200 AVG Training Loss:0.478 AVG Validation Loss:0.503 AVG Training Acc 80.81 % AVG Validation Acc 79.60 %\n",
      "Split 287\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca3d1ec2cc94eb395f905e749002742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.500 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.497 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.17 % AVG Validation Acc 80.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.22 % AVG Validation Acc 80.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.26 % AVG Validation Acc 80.05 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.22 % AVG Validation Acc 80.05 %\n",
      "Epoch:90/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.26 % AVG Validation Acc 80.05 %\n",
      "Epoch:100/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.23 % AVG Validation Acc 80.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.20 % AVG Validation Acc 80.05 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.25 % AVG Validation Acc 80.05 %\n",
      "Epoch:130/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.26 % AVG Validation Acc 80.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.23 % AVG Validation Acc 80.05 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.27 % AVG Validation Acc 80.05 %\n",
      "Epoch:160/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.27 % AVG Validation Acc 80.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.23 % AVG Validation Acc 80.05 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.21 % AVG Validation Acc 80.05 %\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.29 % AVG Validation Acc 80.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.29 % AVG Validation Acc 80.05 %\n",
      "Split 288\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67f508bb3d7f4f80b9da906d65a6f98c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.499 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.500 AVG Training Acc 80.06 % AVG Validation Acc 80.14 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.19 % AVG Validation Acc 80.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.35 % AVG Validation Acc 79.87 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.42 % AVG Validation Acc 80.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.35 % AVG Validation Acc 80.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.49 % AVG Validation Acc 80.05 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.42 % AVG Validation Acc 80.05 %\n",
      "Epoch:100/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.39 % AVG Validation Acc 80.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.32 % AVG Validation Acc 80.05 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.36 % AVG Validation Acc 80.05 %\n",
      "Epoch:130/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.37 % AVG Validation Acc 80.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.39 % AVG Validation Acc 80.05 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.37 % AVG Validation Acc 80.05 %\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.41 % AVG Validation Acc 80.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.47 % AVG Validation Acc 80.05 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.42 % AVG Validation Acc 80.05 %\n",
      "Epoch:190/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.49 % AVG Validation Acc 80.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.50 % AVG Validation Acc 80.05 %\n",
      "Split 289\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4079fb37d2664b5b8c3c857e718d5328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.485 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.485 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.486 AVG Training Acc 80.23 % AVG Validation Acc 80.14 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.37 % AVG Validation Acc 80.32 %\n",
      "Epoch:70/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.31 % AVG Validation Acc 80.23 %\n",
      "Epoch:80/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.34 % AVG Validation Acc 80.23 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.486 AVG Validation Loss:0.491 AVG Training Acc 80.48 % AVG Validation Acc 80.23 %\n",
      "Epoch:100/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.38 % AVG Validation Acc 80.23 %\n",
      "Epoch:110/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.47 % AVG Validation Acc 80.23 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.486 AVG Validation Loss:0.491 AVG Training Acc 80.35 % AVG Validation Acc 80.23 %\n",
      "Epoch:130/200 AVG Training Loss:0.486 AVG Validation Loss:0.491 AVG Training Acc 80.34 % AVG Validation Acc 80.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.485 AVG Validation Loss:0.491 AVG Training Acc 80.38 % AVG Validation Acc 80.23 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.32 % AVG Validation Acc 80.23 %\n",
      "Epoch:160/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.44 % AVG Validation Acc 80.23 %\n",
      "Epoch:170/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.40 % AVG Validation Acc 80.23 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.485 AVG Validation Loss:0.491 AVG Training Acc 80.39 % AVG Validation Acc 80.23 %\n",
      "Epoch:190/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.38 % AVG Validation Acc 80.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.33 % AVG Validation Acc 80.23 %\n",
      "Split 290\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a288128ae8a74e4381503455c405bf43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.38 % AVG Validation Acc 80.32 %\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.29 % AVG Validation Acc 80.05 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.484 AVG Validation Loss:0.504 AVG Training Acc 80.44 % AVG Validation Acc 79.96 %\n",
      "Epoch:70/200 AVG Training Loss:0.476 AVG Validation Loss:0.511 AVG Training Acc 80.72 % AVG Validation Acc 79.78 %\n",
      "Epoch:80/200 AVG Training Loss:0.473 AVG Validation Loss:0.518 AVG Training Acc 80.94 % AVG Validation Acc 79.60 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.468 AVG Validation Loss:0.521 AVG Training Acc 81.34 % AVG Validation Acc 79.51 %\n",
      "Epoch:100/200 AVG Training Loss:0.468 AVG Validation Loss:0.524 AVG Training Acc 81.28 % AVG Validation Acc 79.33 %\n",
      "Epoch:110/200 AVG Training Loss:0.466 AVG Validation Loss:0.524 AVG Training Acc 81.34 % AVG Validation Acc 79.60 %\n",
      "Epoch:120/200 AVG Training Loss:0.466 AVG Validation Loss:0.527 AVG Training Acc 81.37 % AVG Validation Acc 79.51 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.466 AVG Validation Loss:0.525 AVG Training Acc 81.34 % AVG Validation Acc 79.60 %\n",
      "Epoch:140/200 AVG Training Loss:0.466 AVG Validation Loss:0.528 AVG Training Acc 81.39 % AVG Validation Acc 79.51 %\n",
      "Epoch:150/200 AVG Training Loss:0.467 AVG Validation Loss:0.525 AVG Training Acc 81.27 % AVG Validation Acc 79.51 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.467 AVG Validation Loss:0.528 AVG Training Acc 81.42 % AVG Validation Acc 79.51 %\n",
      "Epoch:170/200 AVG Training Loss:0.466 AVG Validation Loss:0.527 AVG Training Acc 81.49 % AVG Validation Acc 79.60 %\n",
      "Epoch:180/200 AVG Training Loss:0.464 AVG Validation Loss:0.528 AVG Training Acc 81.63 % AVG Validation Acc 79.60 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.465 AVG Validation Loss:0.527 AVG Training Acc 81.32 % AVG Validation Acc 79.51 %\n",
      "Epoch:200/200 AVG Training Loss:0.465 AVG Validation Loss:0.528 AVG Training Acc 81.48 % AVG Validation Acc 79.51 %\n",
      "Split 291\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66f5532e50e644108d5f1fe0a37fa978",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.497 AVG Training Acc 80.18 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.24 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.493 AVG Training Acc 80.26 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.500 AVG Training Acc 80.55 % AVG Validation Acc 79.80 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:70/200 AVG Training Loss:0.472 AVG Validation Loss:0.512 AVG Training Acc 81.00 % AVG Validation Acc 79.53 %\n",
      "Epoch:80/200 AVG Training Loss:0.466 AVG Validation Loss:0.522 AVG Training Acc 81.43 % AVG Validation Acc 79.17 %\n",
      "Epoch:90/200 AVG Training Loss:0.462 AVG Validation Loss:0.527 AVG Training Acc 81.66 % AVG Validation Acc 78.45 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.463 AVG Validation Loss:0.535 AVG Training Acc 81.57 % AVG Validation Acc 78.63 %\n",
      "Epoch:110/200 AVG Training Loss:0.461 AVG Validation Loss:0.542 AVG Training Acc 81.69 % AVG Validation Acc 78.45 %\n",
      "Epoch:120/200 AVG Training Loss:0.461 AVG Validation Loss:0.543 AVG Training Acc 81.80 % AVG Validation Acc 78.45 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.461 AVG Validation Loss:0.540 AVG Training Acc 81.65 % AVG Validation Acc 78.72 %\n",
      "Epoch:140/200 AVG Training Loss:0.461 AVG Validation Loss:0.542 AVG Training Acc 81.78 % AVG Validation Acc 78.54 %\n",
      "Epoch:150/200 AVG Training Loss:0.461 AVG Validation Loss:0.541 AVG Training Acc 81.63 % AVG Validation Acc 78.36 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.462 AVG Validation Loss:0.531 AVG Training Acc 81.57 % AVG Validation Acc 78.63 %\n",
      "Epoch:170/200 AVG Training Loss:0.461 AVG Validation Loss:0.529 AVG Training Acc 81.74 % AVG Validation Acc 78.72 %\n",
      "Epoch:180/200 AVG Training Loss:0.462 AVG Validation Loss:0.550 AVG Training Acc 81.62 % AVG Validation Acc 78.18 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.461 AVG Validation Loss:0.541 AVG Training Acc 81.71 % AVG Validation Acc 78.36 %\n",
      "Epoch:200/200 AVG Training Loss:0.462 AVG Validation Loss:0.541 AVG Training Acc 81.64 % AVG Validation Acc 78.27 %\n",
      "Split 292\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52ad632276d64afb80f46b1a85f049fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.501 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.503 AVG Training Acc 80.13 % AVG Validation Acc 80.07 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.500 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.501 AVG Training Acc 80.27 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.502 AVG Training Acc 80.37 % AVG Validation Acc 80.16 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.487 AVG Validation Loss:0.499 AVG Training Acc 80.35 % AVG Validation Acc 80.25 %\n",
      "Epoch:70/200 AVG Training Loss:0.486 AVG Validation Loss:0.503 AVG Training Acc 80.34 % AVG Validation Acc 80.16 %\n",
      "Epoch:80/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.42 % AVG Validation Acc 80.16 %\n",
      "Epoch:90/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.38 % AVG Validation Acc 80.16 %\n",
      "Epoch:100/200 AVG Training Loss:0.485 AVG Validation Loss:0.494 AVG Training Acc 80.44 % AVG Validation Acc 80.34 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.44 % AVG Validation Acc 80.25 %\n",
      "Epoch:120/200 AVG Training Loss:0.485 AVG Validation Loss:0.499 AVG Training Acc 80.48 % AVG Validation Acc 80.25 %\n",
      "Epoch:130/200 AVG Training Loss:0.485 AVG Validation Loss:0.494 AVG Training Acc 80.52 % AVG Validation Acc 80.25 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.46 % AVG Validation Acc 80.25 %\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.494 AVG Training Acc 80.47 % AVG Validation Acc 80.25 %\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.499 AVG Training Acc 80.53 % AVG Validation Acc 80.25 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.46 % AVG Validation Acc 80.25 %\n",
      "Epoch:180/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.43 % AVG Validation Acc 80.25 %\n",
      "Epoch:190/200 AVG Training Loss:0.486 AVG Validation Loss:0.499 AVG Training Acc 80.48 % AVG Validation Acc 80.25 %\n",
      "Epoch   198: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.45 % AVG Validation Acc 80.25 %\n",
      "Split 293\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f05f3dfe24f14488b0d0ae7919239fe8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.493 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.489 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.490 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:80/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.22 % AVG Validation Acc 80.07 %\n",
      "Epoch:100/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.16 % AVG Validation Acc 80.07 %\n",
      "Epoch:110/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.25 % AVG Validation Acc 80.07 %\n",
      "Epoch:130/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch:140/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.13 % AVG Validation Acc 80.07 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.11 % AVG Validation Acc 80.07 %\n",
      "Epoch:160/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.20 % AVG Validation Acc 80.07 %\n",
      "Epoch:170/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.18 % AVG Validation Acc 80.07 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.13 % AVG Validation Acc 80.07 %\n",
      "Epoch:190/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.18 % AVG Validation Acc 80.07 %\n",
      "Epoch:200/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.09 % AVG Validation Acc 80.07 %\n",
      "Split 294\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1df35b490274aa2b4240e9c6ba17ec9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.487 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.492 AVG Validation Loss:0.488 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.488 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.490 AVG Validation Loss:0.487 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.490 AVG Validation Loss:0.487 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:80/200 AVG Training Loss:0.490 AVG Validation Loss:0.488 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.490 AVG Validation Loss:0.488 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:100/200 AVG Training Loss:0.490 AVG Validation Loss:0.488 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.490 AVG Validation Loss:0.488 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.490 AVG Validation Loss:0.488 AVG Training Acc 80.22 % AVG Validation Acc 80.16 %\n",
      "Epoch:130/200 AVG Training Loss:0.490 AVG Validation Loss:0.488 AVG Training Acc 80.18 % AVG Validation Acc 80.16 %\n",
      "Epoch:140/200 AVG Training Loss:0.489 AVG Validation Loss:0.488 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.490 AVG Validation Loss:0.488 AVG Training Acc 80.21 % AVG Validation Acc 80.16 %\n",
      "Epoch:160/200 AVG Training Loss:0.490 AVG Validation Loss:0.488 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:170/200 AVG Training Loss:0.490 AVG Validation Loss:0.487 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.489 AVG Validation Loss:0.488 AVG Training Acc 80.20 % AVG Validation Acc 80.16 %\n",
      "Epoch:190/200 AVG Training Loss:0.489 AVG Validation Loss:0.488 AVG Training Acc 80.20 % AVG Validation Acc 80.16 %\n",
      "Epoch:200/200 AVG Training Loss:0.489 AVG Validation Loss:0.488 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Split 295\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85a9e534837f4f3d8362008daf8cbe99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.499 AVG Training Acc 80.13 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.499 AVG Training Acc 80.11 % AVG Validation Acc 80.07 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.23 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.498 AVG Training Acc 80.23 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.498 AVG Training Acc 80.31 % AVG Validation Acc 80.16 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.486 AVG Validation Loss:0.500 AVG Training Acc 80.47 % AVG Validation Acc 79.71 %\n",
      "Epoch:70/200 AVG Training Loss:0.485 AVG Validation Loss:0.499 AVG Training Acc 80.45 % AVG Validation Acc 79.71 %\n",
      "Epoch:80/200 AVG Training Loss:0.485 AVG Validation Loss:0.499 AVG Training Acc 80.44 % AVG Validation Acc 79.71 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.485 AVG Validation Loss:0.499 AVG Training Acc 80.41 % AVG Validation Acc 79.71 %\n",
      "Epoch:100/200 AVG Training Loss:0.485 AVG Validation Loss:0.500 AVG Training Acc 80.43 % AVG Validation Acc 79.71 %\n",
      "Epoch:110/200 AVG Training Loss:0.485 AVG Validation Loss:0.500 AVG Training Acc 80.35 % AVG Validation Acc 79.80 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.485 AVG Validation Loss:0.500 AVG Training Acc 80.49 % AVG Validation Acc 79.71 %\n",
      "Epoch:130/200 AVG Training Loss:0.485 AVG Validation Loss:0.499 AVG Training Acc 80.51 % AVG Validation Acc 79.80 %\n",
      "Epoch:140/200 AVG Training Loss:0.485 AVG Validation Loss:0.499 AVG Training Acc 80.49 % AVG Validation Acc 79.80 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.499 AVG Training Acc 80.53 % AVG Validation Acc 79.80 %\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.500 AVG Training Acc 80.45 % AVG Validation Acc 79.71 %\n",
      "Epoch:170/200 AVG Training Loss:0.486 AVG Validation Loss:0.499 AVG Training Acc 80.42 % AVG Validation Acc 79.80 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.486 AVG Validation Loss:0.500 AVG Training Acc 80.37 % AVG Validation Acc 79.71 %\n",
      "Epoch:190/200 AVG Training Loss:0.485 AVG Validation Loss:0.500 AVG Training Acc 80.44 % AVG Validation Acc 79.80 %\n",
      "Epoch:200/200 AVG Training Loss:0.485 AVG Validation Loss:0.500 AVG Training Acc 80.39 % AVG Validation Acc 79.71 %\n",
      "Split 296\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc7c55f3f284c0f9ff17777e05ad689",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.492 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.34 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.493 AVG Training Acc 80.41 % AVG Validation Acc 80.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.482 AVG Validation Loss:0.496 AVG Training Acc 80.58 % AVG Validation Acc 79.87 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.480 AVG Validation Loss:0.498 AVG Training Acc 80.58 % AVG Validation Acc 80.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.478 AVG Validation Loss:0.500 AVG Training Acc 80.76 % AVG Validation Acc 79.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.478 AVG Validation Loss:0.501 AVG Training Acc 80.69 % AVG Validation Acc 79.96 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.478 AVG Validation Loss:0.502 AVG Training Acc 80.66 % AVG Validation Acc 79.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.478 AVG Validation Loss:0.502 AVG Training Acc 80.74 % AVG Validation Acc 79.87 %\n",
      "Epoch:120/200 AVG Training Loss:0.478 AVG Validation Loss:0.503 AVG Training Acc 80.73 % AVG Validation Acc 79.96 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.479 AVG Validation Loss:0.503 AVG Training Acc 80.80 % AVG Validation Acc 79.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.479 AVG Validation Loss:0.502 AVG Training Acc 80.75 % AVG Validation Acc 79.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.478 AVG Validation Loss:0.503 AVG Training Acc 80.67 % AVG Validation Acc 79.96 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.478 AVG Validation Loss:0.503 AVG Training Acc 80.60 % AVG Validation Acc 79.96 %\n",
      "Epoch:170/200 AVG Training Loss:0.479 AVG Validation Loss:0.502 AVG Training Acc 80.78 % AVG Validation Acc 80.05 %\n",
      "Epoch:180/200 AVG Training Loss:0.479 AVG Validation Loss:0.503 AVG Training Acc 80.71 % AVG Validation Acc 79.78 %\n",
      "Epoch:190/200 AVG Training Loss:0.479 AVG Validation Loss:0.502 AVG Training Acc 80.70 % AVG Validation Acc 79.87 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.478 AVG Validation Loss:0.502 AVG Training Acc 80.61 % AVG Validation Acc 79.96 %\n",
      "Split 297\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cba7a8af153449795e7018c57919318",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.21 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.32 % AVG Validation Acc 80.14 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.45 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.42 % AVG Validation Acc 79.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.37 % AVG Validation Acc 80.14 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.482 AVG Validation Loss:0.496 AVG Training Acc 80.64 % AVG Validation Acc 80.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.482 AVG Validation Loss:0.497 AVG Training Acc 80.65 % AVG Validation Acc 80.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.482 AVG Validation Loss:0.497 AVG Training Acc 80.53 % AVG Validation Acc 79.96 %\n",
      "Epoch:120/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.49 % AVG Validation Acc 79.96 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.482 AVG Validation Loss:0.497 AVG Training Acc 80.52 % AVG Validation Acc 79.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.50 % AVG Validation Acc 79.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.54 % AVG Validation Acc 79.96 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.483 AVG Validation Loss:0.496 AVG Training Acc 80.61 % AVG Validation Acc 80.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.53 % AVG Validation Acc 80.05 %\n",
      "Epoch:180/200 AVG Training Loss:0.483 AVG Validation Loss:0.496 AVG Training Acc 80.51 % AVG Validation Acc 80.05 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.483 AVG Validation Loss:0.496 AVG Training Acc 80.47 % AVG Validation Acc 80.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.483 AVG Validation Loss:0.499 AVG Training Acc 80.45 % AVG Validation Acc 79.87 %\n",
      "Split 298\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5424040ccc714d71adc9e907e5ffed46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.09 % AVG Validation Acc 80.14 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.486 AVG Validation Loss:0.499 AVG Training Acc 80.45 % AVG Validation Acc 79.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.483 AVG Validation Loss:0.503 AVG Training Acc 80.56 % AVG Validation Acc 79.60 %\n",
      "Epoch:50/200 AVG Training Loss:0.480 AVG Validation Loss:0.506 AVG Training Acc 80.82 % AVG Validation Acc 79.51 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.478 AVG Validation Loss:0.509 AVG Training Acc 80.81 % AVG Validation Acc 79.42 %\n",
      "Epoch:70/200 AVG Training Loss:0.476 AVG Validation Loss:0.509 AVG Training Acc 80.96 % AVG Validation Acc 79.42 %\n",
      "Epoch:80/200 AVG Training Loss:0.476 AVG Validation Loss:0.511 AVG Training Acc 81.00 % AVG Validation Acc 79.33 %\n",
      "Epoch:90/200 AVG Training Loss:0.476 AVG Validation Loss:0.513 AVG Training Acc 80.99 % AVG Validation Acc 79.15 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.476 AVG Validation Loss:0.512 AVG Training Acc 81.04 % AVG Validation Acc 79.06 %\n",
      "Epoch:110/200 AVG Training Loss:0.475 AVG Validation Loss:0.513 AVG Training Acc 81.02 % AVG Validation Acc 79.06 %\n",
      "Epoch:120/200 AVG Training Loss:0.475 AVG Validation Loss:0.512 AVG Training Acc 81.06 % AVG Validation Acc 79.24 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.475 AVG Validation Loss:0.512 AVG Training Acc 81.08 % AVG Validation Acc 79.15 %\n",
      "Epoch:140/200 AVG Training Loss:0.474 AVG Validation Loss:0.513 AVG Training Acc 81.12 % AVG Validation Acc 79.24 %\n",
      "Epoch:150/200 AVG Training Loss:0.474 AVG Validation Loss:0.513 AVG Training Acc 81.06 % AVG Validation Acc 79.06 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.476 AVG Validation Loss:0.512 AVG Training Acc 81.00 % AVG Validation Acc 79.33 %\n",
      "Epoch:170/200 AVG Training Loss:0.474 AVG Validation Loss:0.512 AVG Training Acc 81.18 % AVG Validation Acc 79.15 %\n",
      "Epoch:180/200 AVG Training Loss:0.475 AVG Validation Loss:0.513 AVG Training Acc 81.07 % AVG Validation Acc 79.06 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.475 AVG Validation Loss:0.512 AVG Training Acc 81.05 % AVG Validation Acc 79.24 %\n",
      "Epoch:200/200 AVG Training Loss:0.474 AVG Validation Loss:0.513 AVG Training Acc 81.13 % AVG Validation Acc 79.06 %\n",
      "Split 299\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8292bea18ab34be3b00d1bd7db011cc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.30 % AVG Validation Acc 79.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.46 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.42 % AVG Validation Acc 80.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.495 AVG Training Acc 80.55 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.481 AVG Validation Loss:0.494 AVG Training Acc 80.70 % AVG Validation Acc 80.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.481 AVG Validation Loss:0.496 AVG Training Acc 80.71 % AVG Validation Acc 79.96 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.477 AVG Validation Loss:0.497 AVG Training Acc 80.92 % AVG Validation Acc 79.87 %\n",
      "Epoch:100/200 AVG Training Loss:0.477 AVG Validation Loss:0.497 AVG Training Acc 81.00 % AVG Validation Acc 79.96 %\n",
      "Epoch:110/200 AVG Training Loss:0.477 AVG Validation Loss:0.499 AVG Training Acc 81.02 % AVG Validation Acc 79.69 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.476 AVG Validation Loss:0.500 AVG Training Acc 81.03 % AVG Validation Acc 79.69 %\n",
      "Epoch:130/200 AVG Training Loss:0.476 AVG Validation Loss:0.500 AVG Training Acc 80.96 % AVG Validation Acc 79.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.476 AVG Validation Loss:0.499 AVG Training Acc 81.01 % AVG Validation Acc 79.78 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.476 AVG Validation Loss:0.501 AVG Training Acc 81.04 % AVG Validation Acc 79.69 %\n",
      "Epoch:160/200 AVG Training Loss:0.475 AVG Validation Loss:0.499 AVG Training Acc 81.05 % AVG Validation Acc 79.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.475 AVG Validation Loss:0.499 AVG Training Acc 80.95 % AVG Validation Acc 79.78 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.476 AVG Validation Loss:0.499 AVG Training Acc 80.97 % AVG Validation Acc 79.78 %\n",
      "Epoch:190/200 AVG Training Loss:0.475 AVG Validation Loss:0.501 AVG Training Acc 80.99 % AVG Validation Acc 79.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.477 AVG Validation Loss:0.499 AVG Training Acc 80.91 % AVG Validation Acc 79.69 %\n",
      "Split 300\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0cc46623bd84e458e771f26d9672da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.10 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.23 %\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.31 % AVG Validation Acc 80.32 %\n",
      "Epoch:60/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.45 % AVG Validation Acc 80.42 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.482 AVG Validation Loss:0.495 AVG Training Acc 80.51 % AVG Validation Acc 80.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.481 AVG Validation Loss:0.496 AVG Training Acc 80.62 % AVG Validation Acc 80.05 %\n",
      "Epoch:90/200 AVG Training Loss:0.481 AVG Validation Loss:0.496 AVG Training Acc 80.61 % AVG Validation Acc 80.05 %\n",
      "Epoch:100/200 AVG Training Loss:0.480 AVG Validation Loss:0.496 AVG Training Acc 80.73 % AVG Validation Acc 80.14 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.480 AVG Validation Loss:0.497 AVG Training Acc 80.77 % AVG Validation Acc 80.05 %\n",
      "Epoch:120/200 AVG Training Loss:0.481 AVG Validation Loss:0.497 AVG Training Acc 80.62 % AVG Validation Acc 80.05 %\n",
      "Epoch:130/200 AVG Training Loss:0.479 AVG Validation Loss:0.497 AVG Training Acc 80.73 % AVG Validation Acc 79.96 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.481 AVG Validation Loss:0.497 AVG Training Acc 80.68 % AVG Validation Acc 79.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.481 AVG Validation Loss:0.496 AVG Training Acc 80.57 % AVG Validation Acc 79.96 %\n",
      "Epoch:160/200 AVG Training Loss:0.480 AVG Validation Loss:0.497 AVG Training Acc 80.64 % AVG Validation Acc 79.96 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.480 AVG Validation Loss:0.496 AVG Training Acc 80.71 % AVG Validation Acc 79.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.480 AVG Validation Loss:0.498 AVG Training Acc 80.75 % AVG Validation Acc 79.96 %\n",
      "Epoch:190/200 AVG Training Loss:0.481 AVG Validation Loss:0.497 AVG Training Acc 80.56 % AVG Validation Acc 80.05 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.480 AVG Validation Loss:0.497 AVG Training Acc 80.63 % AVG Validation Acc 79.96 %\n",
      "Date_threshold_100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c75086965afb409085924c5d655aeed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final_fail\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bae56ea71074d21851ec97db9904644",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef5d0e44c44d4077970cfb1b04ff51b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best Accuracy found: 61.95%\n",
      "Epoch: 1\n",
      "Epoch:10/200 AVG Training Loss:0.657 AVG Validation Loss:0.659 AVG Training Acc 61.96 % AVG Validation Acc 61.86 %\n",
      "New Best Accuracy found: 62.04%\n",
      "Epoch: 11\n",
      "New Best Accuracy found: 62.22%\n",
      "Epoch: 19\n",
      "Epoch:20/200 AVG Training Loss:0.650 AVG Validation Loss:0.663 AVG Training Acc 62.07 % AVG Validation Acc 61.68 %\n",
      "New Best Accuracy found: 62.67%\n",
      "Epoch: 25\n",
      "Epoch:30/200 AVG Training Loss:0.640 AVG Validation Loss:0.669 AVG Training Acc 62.66 % AVG Validation Acc 61.95 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.662 AVG Validation Loss:0.662 AVG Training Acc 61.86 % AVG Validation Acc 61.95 %\n",
      "Epoch:50/200 AVG Training Loss:0.661 AVG Validation Loss:0.662 AVG Training Acc 61.87 % AVG Validation Acc 62.04 %\n",
      "Epoch:60/200 AVG Training Loss:0.661 AVG Validation Loss:0.661 AVG Training Acc 61.93 % AVG Validation Acc 61.95 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.659 AVG Validation Loss:0.661 AVG Training Acc 61.99 % AVG Validation Acc 61.86 %\n",
      "Epoch:80/200 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 62.11 % AVG Validation Acc 61.86 %\n",
      "Epoch:90/200 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 61.99 % AVG Validation Acc 61.77 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.660 AVG Validation Loss:0.661 AVG Training Acc 61.98 % AVG Validation Acc 61.77 %\n",
      "Epoch:110/200 AVG Training Loss:0.659 AVG Validation Loss:0.662 AVG Training Acc 62.00 % AVG Validation Acc 61.77 %\n",
      "Epoch:120/200 AVG Training Loss:0.659 AVG Validation Loss:0.662 AVG Training Acc 61.98 % AVG Validation Acc 61.77 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.661 AVG Validation Loss:0.661 AVG Training Acc 62.05 % AVG Validation Acc 61.77 %\n",
      "Epoch:140/200 AVG Training Loss:0.660 AVG Validation Loss:0.661 AVG Training Acc 61.94 % AVG Validation Acc 61.77 %\n",
      "Epoch:150/200 AVG Training Loss:0.659 AVG Validation Loss:0.661 AVG Training Acc 61.97 % AVG Validation Acc 61.86 %\n",
      "Epoch:160/200 AVG Training Loss:0.660 AVG Validation Loss:0.661 AVG Training Acc 62.03 % AVG Validation Acc 61.77 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 62.02 % AVG Validation Acc 61.77 %\n",
      "Epoch:180/200 AVG Training Loss:0.659 AVG Validation Loss:0.662 AVG Training Acc 62.03 % AVG Validation Acc 61.77 %\n",
      "Epoch:190/200 AVG Training Loss:0.661 AVG Validation Loss:0.661 AVG Training Acc 62.07 % AVG Validation Acc 61.77 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 62.07 % AVG Validation Acc 61.77 %\n",
      "Split 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "857b2b41af1f40438e1228891ea4fb36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.660 AVG Training Acc 61.98 % AVG Validation Acc 62.04 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.658 AVG Training Acc 62.06 % AVG Validation Acc 62.31 %\n",
      "Epoch:30/200 AVG Training Loss:0.642 AVG Validation Loss:0.660 AVG Training Acc 62.49 % AVG Validation Acc 61.95 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.625 AVG Validation Loss:0.667 AVG Training Acc 63.85 % AVG Validation Acc 61.95 %\n",
      "Epoch:50/200 AVG Training Loss:0.615 AVG Validation Loss:0.677 AVG Training Acc 64.69 % AVG Validation Acc 61.50 %\n",
      "Epoch:60/200 AVG Training Loss:0.602 AVG Validation Loss:0.699 AVG Training Acc 65.62 % AVG Validation Acc 60.23 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.595 AVG Validation Loss:0.711 AVG Training Acc 65.99 % AVG Validation Acc 61.41 %\n",
      "Epoch:80/200 AVG Training Loss:0.596 AVG Validation Loss:0.708 AVG Training Acc 65.57 % AVG Validation Acc 61.32 %\n",
      "Epoch:90/200 AVG Training Loss:0.592 AVG Validation Loss:0.707 AVG Training Acc 65.95 % AVG Validation Acc 60.96 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.589 AVG Validation Loss:0.717 AVG Training Acc 66.06 % AVG Validation Acc 60.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.590 AVG Validation Loss:0.713 AVG Training Acc 66.17 % AVG Validation Acc 61.05 %\n",
      "Epoch:120/200 AVG Training Loss:0.591 AVG Validation Loss:0.709 AVG Training Acc 66.05 % AVG Validation Acc 62.04 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.590 AVG Validation Loss:0.719 AVG Training Acc 66.51 % AVG Validation Acc 61.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.590 AVG Validation Loss:0.715 AVG Training Acc 66.68 % AVG Validation Acc 61.32 %\n",
      "Epoch:150/200 AVG Training Loss:0.590 AVG Validation Loss:0.713 AVG Training Acc 66.42 % AVG Validation Acc 60.87 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.591 AVG Validation Loss:0.711 AVG Training Acc 66.42 % AVG Validation Acc 61.23 %\n",
      "Epoch:170/200 AVG Training Loss:0.589 AVG Validation Loss:0.715 AVG Training Acc 66.62 % AVG Validation Acc 61.05 %\n",
      "Epoch:180/200 AVG Training Loss:0.590 AVG Validation Loss:0.717 AVG Training Acc 66.51 % AVG Validation Acc 61.41 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.590 AVG Validation Loss:0.719 AVG Training Acc 66.25 % AVG Validation Acc 61.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.591 AVG Validation Loss:0.709 AVG Training Acc 66.13 % AVG Validation Acc 61.14 %\n",
      "Split 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da697a98069c46b7ae566bcf6af2afee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.656 AVG Training Acc 61.87 % AVG Validation Acc 62.13 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.656 AVG Training Acc 62.14 % AVG Validation Acc 62.04 %\n",
      "Epoch:30/200 AVG Training Loss:0.645 AVG Validation Loss:0.651 AVG Training Acc 62.16 % AVG Validation Acc 60.87 %\n",
      "New Best Accuracy found: 62.85%\n",
      "Epoch: 31\n",
      "Epoch:40/200 AVG Training Loss:0.669 AVG Validation Loss:0.670 AVG Training Acc 61.50 % AVG Validation Acc 61.86 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.664 AVG Validation Loss:0.662 AVG Training Acc 61.92 % AVG Validation Acc 61.86 %\n",
      "Epoch:60/200 AVG Training Loss:0.663 AVG Validation Loss:0.663 AVG Training Acc 61.93 % AVG Validation Acc 61.86 %\n",
      "Epoch:70/200 AVG Training Loss:0.663 AVG Validation Loss:0.662 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.662 AVG Validation Loss:0.662 AVG Training Acc 61.95 % AVG Validation Acc 61.86 %\n",
      "Epoch:90/200 AVG Training Loss:0.661 AVG Validation Loss:0.662 AVG Training Acc 61.95 % AVG Validation Acc 61.86 %\n",
      "Epoch:100/200 AVG Training Loss:0.662 AVG Validation Loss:0.663 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.662 AVG Validation Loss:0.663 AVG Training Acc 61.93 % AVG Validation Acc 61.86 %\n",
      "Epoch:120/200 AVG Training Loss:0.663 AVG Validation Loss:0.662 AVG Training Acc 61.93 % AVG Validation Acc 61.86 %\n",
      "Epoch:130/200 AVG Training Loss:0.662 AVG Validation Loss:0.662 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.663 AVG Validation Loss:0.662 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:150/200 AVG Training Loss:0.662 AVG Validation Loss:0.663 AVG Training Acc 61.88 % AVG Validation Acc 61.86 %\n",
      "Epoch:160/200 AVG Training Loss:0.661 AVG Validation Loss:0.663 AVG Training Acc 61.97 % AVG Validation Acc 61.86 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.662 AVG Validation Loss:0.662 AVG Training Acc 61.96 % AVG Validation Acc 61.86 %\n",
      "Epoch:180/200 AVG Training Loss:0.662 AVG Validation Loss:0.662 AVG Training Acc 61.93 % AVG Validation Acc 61.86 %\n",
      "Epoch:190/200 AVG Training Loss:0.662 AVG Validation Loss:0.662 AVG Training Acc 61.93 % AVG Validation Acc 61.86 %\n",
      "Epoch   198: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.662 AVG Validation Loss:0.663 AVG Training Acc 61.94 % AVG Validation Acc 61.86 %\n",
      "Split 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a44f692c9a4e83b546967db37b8eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.659 AVG Training Acc 61.87 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.668 AVG Validation Loss:0.692 AVG Training Acc 60.55 % AVG Validation Acc 61.86 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.661 AVG Validation Loss:0.665 AVG Training Acc 61.92 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.663 AVG Validation Loss:0.666 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:50/200 AVG Training Loss:0.662 AVG Validation Loss:0.664 AVG Training Acc 61.93 % AVG Validation Acc 61.86 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.660 AVG Validation Loss:0.663 AVG Training Acc 61.92 % AVG Validation Acc 61.86 %\n",
      "Epoch:70/200 AVG Training Loss:0.659 AVG Validation Loss:0.662 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:80/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 61.93 % AVG Validation Acc 61.86 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.657 AVG Validation Loss:0.662 AVG Training Acc 61.93 % AVG Validation Acc 61.86 %\n",
      "Epoch:100/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 61.96 % AVG Validation Acc 61.86 %\n",
      "Epoch:110/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 61.92 % AVG Validation Acc 61.86 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.658 AVG Validation Loss:0.663 AVG Training Acc 61.92 % AVG Validation Acc 61.86 %\n",
      "Epoch:130/200 AVG Training Loss:0.659 AVG Validation Loss:0.663 AVG Training Acc 61.96 % AVG Validation Acc 61.86 %\n",
      "Epoch:140/200 AVG Training Loss:0.657 AVG Validation Loss:0.662 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:150/200 AVG Training Loss:0.659 AVG Validation Loss:0.663 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.659 AVG Validation Loss:0.662 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:170/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 61.93 % AVG Validation Acc 61.86 %\n",
      "Epoch:180/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 61.92 % AVG Validation Acc 61.86 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 61.94 % AVG Validation Acc 61.86 %\n",
      "Epoch:200/200 AVG Training Loss:0.657 AVG Validation Loss:0.662 AVG Training Acc 61.96 % AVG Validation Acc 61.86 %\n",
      "Split 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31c6f7b293eb4657be30ce4b6ebb82ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.661 AVG Training Acc 61.74 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.650 AVG Validation Loss:0.668 AVG Training Acc 62.08 % AVG Validation Acc 61.68 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.635 AVG Validation Loss:0.664 AVG Training Acc 62.92 % AVG Validation Acc 61.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.629 AVG Validation Loss:0.668 AVG Training Acc 63.69 % AVG Validation Acc 61.68 %\n",
      "Epoch:50/200 AVG Training Loss:0.622 AVG Validation Loss:0.674 AVG Training Acc 63.74 % AVG Validation Acc 61.32 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.614 AVG Validation Loss:0.676 AVG Training Acc 64.52 % AVG Validation Acc 60.41 %\n",
      "Epoch:70/200 AVG Training Loss:0.614 AVG Validation Loss:0.673 AVG Training Acc 65.05 % AVG Validation Acc 61.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.614 AVG Validation Loss:0.678 AVG Training Acc 64.71 % AVG Validation Acc 61.05 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.612 AVG Validation Loss:0.677 AVG Training Acc 64.75 % AVG Validation Acc 60.87 %\n",
      "Epoch:100/200 AVG Training Loss:0.613 AVG Validation Loss:0.678 AVG Training Acc 65.01 % AVG Validation Acc 61.23 %\n",
      "Epoch:110/200 AVG Training Loss:0.612 AVG Validation Loss:0.681 AVG Training Acc 64.72 % AVG Validation Acc 60.96 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.613 AVG Validation Loss:0.679 AVG Training Acc 64.71 % AVG Validation Acc 60.69 %\n",
      "Epoch:130/200 AVG Training Loss:0.615 AVG Validation Loss:0.679 AVG Training Acc 64.39 % AVG Validation Acc 60.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.612 AVG Validation Loss:0.678 AVG Training Acc 64.72 % AVG Validation Acc 61.50 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.613 AVG Validation Loss:0.678 AVG Training Acc 64.24 % AVG Validation Acc 61.23 %\n",
      "Epoch:160/200 AVG Training Loss:0.613 AVG Validation Loss:0.679 AVG Training Acc 64.64 % AVG Validation Acc 61.23 %\n",
      "Epoch:170/200 AVG Training Loss:0.613 AVG Validation Loss:0.680 AVG Training Acc 64.71 % AVG Validation Acc 60.96 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.615 AVG Validation Loss:0.678 AVG Training Acc 64.39 % AVG Validation Acc 61.41 %\n",
      "Epoch:190/200 AVG Training Loss:0.613 AVG Validation Loss:0.678 AVG Training Acc 64.55 % AVG Validation Acc 61.32 %\n",
      "Epoch:200/200 AVG Training Loss:0.614 AVG Validation Loss:0.677 AVG Training Acc 65.07 % AVG Validation Acc 60.96 %\n",
      "Split 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "440cb5b885a64e4c81358f9065cf4ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.660 AVG Training Acc 61.77 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.662 AVG Training Acc 62.08 % AVG Validation Acc 62.18 %\n",
      "Epoch:30/200 AVG Training Loss:0.666 AVG Validation Loss:0.670 AVG Training Acc 61.56 % AVG Validation Acc 61.91 %\n",
      "Epoch:40/200 AVG Training Loss:0.639 AVG Validation Loss:0.671 AVG Training Acc 62.39 % AVG Validation Acc 62.73 %\n",
      "New Best Accuracy found: 63.00%\n",
      "Epoch: 43\n",
      "New Best Accuracy found: 63.09%\n",
      "Epoch: 44\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.615 AVG Validation Loss:0.689 AVG Training Acc 64.18 % AVG Validation Acc 61.01 %\n",
      "Epoch:60/200 AVG Training Loss:0.604 AVG Validation Loss:0.708 AVG Training Acc 64.91 % AVG Validation Acc 61.01 %\n",
      "Epoch:70/200 AVG Training Loss:0.593 AVG Validation Loss:0.722 AVG Training Acc 65.69 % AVG Validation Acc 59.75 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.586 AVG Validation Loss:0.735 AVG Training Acc 66.08 % AVG Validation Acc 59.48 %\n",
      "Epoch:90/200 AVG Training Loss:0.583 AVG Validation Loss:0.732 AVG Training Acc 66.53 % AVG Validation Acc 58.94 %\n",
      "Epoch:100/200 AVG Training Loss:0.582 AVG Validation Loss:0.743 AVG Training Acc 66.44 % AVG Validation Acc 58.39 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.579 AVG Validation Loss:0.746 AVG Training Acc 66.51 % AVG Validation Acc 58.30 %\n",
      "Epoch:120/200 AVG Training Loss:0.582 AVG Validation Loss:0.742 AVG Training Acc 66.44 % AVG Validation Acc 59.30 %\n",
      "Epoch:130/200 AVG Training Loss:0.581 AVG Validation Loss:0.744 AVG Training Acc 66.49 % AVG Validation Acc 58.39 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.581 AVG Validation Loss:0.742 AVG Training Acc 66.48 % AVG Validation Acc 59.03 %\n",
      "Epoch:150/200 AVG Training Loss:0.581 AVG Validation Loss:0.756 AVG Training Acc 66.47 % AVG Validation Acc 58.66 %\n",
      "Epoch:160/200 AVG Training Loss:0.578 AVG Validation Loss:0.740 AVG Training Acc 66.61 % AVG Validation Acc 58.94 %\n",
      "Epoch:170/200 AVG Training Loss:0.581 AVG Validation Loss:0.750 AVG Training Acc 66.69 % AVG Validation Acc 58.21 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.584 AVG Validation Loss:0.736 AVG Training Acc 66.16 % AVG Validation Acc 59.03 %\n",
      "Epoch:190/200 AVG Training Loss:0.581 AVG Validation Loss:0.744 AVG Training Acc 66.73 % AVG Validation Acc 58.39 %\n",
      "Epoch:200/200 AVG Training Loss:0.581 AVG Validation Loss:0.748 AVG Training Acc 66.41 % AVG Validation Acc 58.48 %\n",
      "Split 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1ea6812ded743f88978dc480ca8c56e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.654 AVG Training Acc 61.81 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.649 AVG Training Acc 62.11 % AVG Validation Acc 62.27 %\n",
      "Epoch:30/200 AVG Training Loss:0.643 AVG Validation Loss:0.654 AVG Training Acc 62.56 % AVG Validation Acc 61.82 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.622 AVG Validation Loss:0.660 AVG Training Acc 63.62 % AVG Validation Acc 63.00 %\n",
      "New Best Accuracy found: 63.54%\n",
      "Epoch: 43\n",
      "New Best Accuracy found: 63.63%\n",
      "Epoch: 49\n",
      "Epoch:50/200 AVG Training Loss:0.614 AVG Validation Loss:0.684 AVG Training Acc 64.41 % AVG Validation Acc 62.91 %\n",
      "Epoch:60/200 AVG Training Loss:0.608 AVG Validation Loss:0.678 AVG Training Acc 64.95 % AVG Validation Acc 63.36 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "New Best Accuracy found: 63.99%\n",
      "Epoch: 63\n",
      "Epoch:70/200 AVG Training Loss:0.603 AVG Validation Loss:0.695 AVG Training Acc 64.97 % AVG Validation Acc 63.00 %\n",
      "Epoch:80/200 AVG Training Loss:0.605 AVG Validation Loss:0.703 AVG Training Acc 65.16 % AVG Validation Acc 63.18 %\n",
      "Epoch:90/200 AVG Training Loss:0.601 AVG Validation Loss:0.705 AVG Training Acc 65.42 % AVG Validation Acc 62.45 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.600 AVG Validation Loss:0.701 AVG Training Acc 65.70 % AVG Validation Acc 62.36 %\n",
      "Epoch:110/200 AVG Training Loss:0.600 AVG Validation Loss:0.694 AVG Training Acc 65.80 % AVG Validation Acc 62.45 %\n",
      "Epoch:120/200 AVG Training Loss:0.600 AVG Validation Loss:0.706 AVG Training Acc 65.61 % AVG Validation Acc 62.27 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.599 AVG Validation Loss:0.709 AVG Training Acc 65.92 % AVG Validation Acc 62.73 %\n",
      "Epoch:140/200 AVG Training Loss:0.603 AVG Validation Loss:0.704 AVG Training Acc 65.52 % AVG Validation Acc 62.82 %\n",
      "Epoch:150/200 AVG Training Loss:0.600 AVG Validation Loss:0.706 AVG Training Acc 65.82 % AVG Validation Acc 62.18 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.601 AVG Validation Loss:0.702 AVG Training Acc 65.10 % AVG Validation Acc 62.91 %\n",
      "Epoch:170/200 AVG Training Loss:0.600 AVG Validation Loss:0.700 AVG Training Acc 65.59 % AVG Validation Acc 62.55 %\n",
      "Epoch:180/200 AVG Training Loss:0.601 AVG Validation Loss:0.695 AVG Training Acc 65.44 % AVG Validation Acc 62.45 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.599 AVG Validation Loss:0.694 AVG Training Acc 65.12 % AVG Validation Acc 62.45 %\n",
      "Epoch:200/200 AVG Training Loss:0.601 AVG Validation Loss:0.692 AVG Training Acc 65.37 % AVG Validation Acc 62.45 %\n",
      "Split 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4be5383c8a8f462f90b4d403c287fc32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.652 AVG Training Acc 61.72 % AVG Validation Acc 62.00 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.650 AVG Training Acc 61.44 % AVG Validation Acc 62.18 %\n",
      "Epoch:30/200 AVG Training Loss:0.643 AVG Validation Loss:0.645 AVG Training Acc 61.80 % AVG Validation Acc 62.00 %\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.627 AVG Validation Loss:0.658 AVG Training Acc 63.21 % AVG Validation Acc 63.18 %\n",
      "Epoch:50/200 AVG Training Loss:0.607 AVG Validation Loss:0.675 AVG Training Acc 64.60 % AVG Validation Acc 61.91 %\n",
      "Epoch:60/200 AVG Training Loss:0.601 AVG Validation Loss:0.685 AVG Training Acc 63.80 % AVG Validation Acc 61.37 %\n",
      "Epoch:70/200 AVG Training Loss:0.589 AVG Validation Loss:0.714 AVG Training Acc 65.59 % AVG Validation Acc 61.01 %\n",
      "Epoch    70: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.585 AVG Validation Loss:0.713 AVG Training Acc 65.71 % AVG Validation Acc 60.38 %\n",
      "Epoch:90/200 AVG Training Loss:0.582 AVG Validation Loss:0.713 AVG Training Acc 65.57 % AVG Validation Acc 60.20 %\n",
      "Epoch:100/200 AVG Training Loss:0.583 AVG Validation Loss:0.722 AVG Training Acc 65.97 % AVG Validation Acc 60.20 %\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.582 AVG Validation Loss:0.714 AVG Training Acc 66.15 % AVG Validation Acc 60.65 %\n",
      "Epoch:120/200 AVG Training Loss:0.579 AVG Validation Loss:0.718 AVG Training Acc 65.83 % AVG Validation Acc 60.56 %\n",
      "Epoch:130/200 AVG Training Loss:0.583 AVG Validation Loss:0.722 AVG Training Acc 65.41 % AVG Validation Acc 60.47 %\n",
      "Epoch   132: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.581 AVG Validation Loss:0.717 AVG Training Acc 65.77 % AVG Validation Acc 60.38 %\n",
      "Epoch:150/200 AVG Training Loss:0.580 AVG Validation Loss:0.719 AVG Training Acc 65.98 % AVG Validation Acc 60.38 %\n",
      "Epoch:160/200 AVG Training Loss:0.580 AVG Validation Loss:0.719 AVG Training Acc 65.73 % AVG Validation Acc 61.01 %\n",
      "Epoch   163: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.580 AVG Validation Loss:0.719 AVG Training Acc 65.71 % AVG Validation Acc 60.11 %\n",
      "Epoch:180/200 AVG Training Loss:0.582 AVG Validation Loss:0.723 AVG Training Acc 66.17 % AVG Validation Acc 60.74 %\n",
      "Epoch:190/200 AVG Training Loss:0.579 AVG Validation Loss:0.717 AVG Training Acc 65.54 % AVG Validation Acc 60.29 %\n",
      "Epoch   194: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.580 AVG Validation Loss:0.720 AVG Training Acc 65.88 % AVG Validation Acc 60.29 %\n",
      "Split 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e2fe23554f94850af1b810ef4bffddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.669 AVG Training Acc 61.77 % AVG Validation Acc 61.73 %\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.646 AVG Validation Loss:0.670 AVG Training Acc 62.56 % AVG Validation Acc 59.48 %\n",
      "Epoch:30/200 AVG Training Loss:0.642 AVG Validation Loss:0.672 AVG Training Acc 62.48 % AVG Validation Acc 58.84 %\n",
      "Epoch:40/200 AVG Training Loss:0.636 AVG Validation Loss:0.679 AVG Training Acc 62.75 % AVG Validation Acc 57.85 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.630 AVG Validation Loss:0.683 AVG Training Acc 63.15 % AVG Validation Acc 57.49 %\n",
      "Epoch:60/200 AVG Training Loss:0.630 AVG Validation Loss:0.686 AVG Training Acc 63.38 % AVG Validation Acc 57.13 %\n",
      "Epoch:70/200 AVG Training Loss:0.627 AVG Validation Loss:0.687 AVG Training Acc 63.84 % AVG Validation Acc 57.04 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.626 AVG Validation Loss:0.687 AVG Training Acc 63.90 % AVG Validation Acc 57.22 %\n",
      "Epoch:90/200 AVG Training Loss:0.626 AVG Validation Loss:0.687 AVG Training Acc 63.58 % AVG Validation Acc 57.22 %\n",
      "Epoch:100/200 AVG Training Loss:0.627 AVG Validation Loss:0.687 AVG Training Acc 63.37 % AVG Validation Acc 57.40 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.626 AVG Validation Loss:0.686 AVG Training Acc 63.93 % AVG Validation Acc 57.49 %\n",
      "Epoch:120/200 AVG Training Loss:0.626 AVG Validation Loss:0.686 AVG Training Acc 64.14 % AVG Validation Acc 57.04 %\n",
      "Epoch:130/200 AVG Training Loss:0.627 AVG Validation Loss:0.687 AVG Training Acc 63.50 % AVG Validation Acc 57.40 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.625 AVG Validation Loss:0.686 AVG Training Acc 63.77 % AVG Validation Acc 57.49 %\n",
      "Epoch:150/200 AVG Training Loss:0.627 AVG Validation Loss:0.686 AVG Training Acc 63.52 % AVG Validation Acc 57.22 %\n",
      "Epoch:160/200 AVG Training Loss:0.626 AVG Validation Loss:0.686 AVG Training Acc 64.17 % AVG Validation Acc 57.40 %\n",
      "Epoch:170/200 AVG Training Loss:0.626 AVG Validation Loss:0.687 AVG Training Acc 63.60 % AVG Validation Acc 56.86 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.627 AVG Validation Loss:0.686 AVG Training Acc 63.74 % AVG Validation Acc 57.31 %\n",
      "Epoch:190/200 AVG Training Loss:0.626 AVG Validation Loss:0.688 AVG Training Acc 63.94 % AVG Validation Acc 57.22 %\n",
      "Epoch:200/200 AVG Training Loss:0.627 AVG Validation Loss:0.687 AVG Training Acc 63.65 % AVG Validation Acc 57.58 %\n",
      "Split 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f42bb318231447cbaa463729ffc7f05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.655 AVG Training Acc 61.75 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.655 AVG Training Acc 62.03 % AVG Validation Acc 61.91 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.638 AVG Validation Loss:0.661 AVG Training Acc 63.20 % AVG Validation Acc 61.28 %\n",
      "Epoch:40/200 AVG Training Loss:0.624 AVG Validation Loss:0.676 AVG Training Acc 63.82 % AVG Validation Acc 61.19 %\n",
      "Epoch:50/200 AVG Training Loss:0.615 AVG Validation Loss:0.684 AVG Training Acc 64.28 % AVG Validation Acc 59.93 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.605 AVG Validation Loss:0.691 AVG Training Acc 65.00 % AVG Validation Acc 59.57 %\n",
      "Epoch:70/200 AVG Training Loss:0.602 AVG Validation Loss:0.691 AVG Training Acc 65.35 % AVG Validation Acc 58.57 %\n",
      "Epoch:80/200 AVG Training Loss:0.600 AVG Validation Loss:0.691 AVG Training Acc 65.37 % AVG Validation Acc 58.48 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.599 AVG Validation Loss:0.694 AVG Training Acc 65.32 % AVG Validation Acc 59.30 %\n",
      "Epoch:100/200 AVG Training Loss:0.601 AVG Validation Loss:0.695 AVG Training Acc 65.13 % AVG Validation Acc 58.48 %\n",
      "Epoch:110/200 AVG Training Loss:0.601 AVG Validation Loss:0.699 AVG Training Acc 65.65 % AVG Validation Acc 58.30 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.599 AVG Validation Loss:0.697 AVG Training Acc 65.41 % AVG Validation Acc 58.48 %\n",
      "Epoch:130/200 AVG Training Loss:0.601 AVG Validation Loss:0.694 AVG Training Acc 65.77 % AVG Validation Acc 58.84 %\n",
      "Epoch:140/200 AVG Training Loss:0.601 AVG Validation Loss:0.697 AVG Training Acc 65.65 % AVG Validation Acc 58.30 %\n",
      "Epoch:150/200 AVG Training Loss:0.598 AVG Validation Loss:0.696 AVG Training Acc 65.26 % AVG Validation Acc 58.48 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.599 AVG Validation Loss:0.697 AVG Training Acc 65.24 % AVG Validation Acc 58.39 %\n",
      "Epoch:170/200 AVG Training Loss:0.598 AVG Validation Loss:0.695 AVG Training Acc 65.49 % AVG Validation Acc 58.03 %\n",
      "Epoch:180/200 AVG Training Loss:0.599 AVG Validation Loss:0.696 AVG Training Acc 65.48 % AVG Validation Acc 58.84 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.599 AVG Validation Loss:0.696 AVG Training Acc 65.28 % AVG Validation Acc 58.21 %\n",
      "Epoch:200/200 AVG Training Loss:0.601 AVG Validation Loss:0.694 AVG Training Acc 64.91 % AVG Validation Acc 58.30 %\n",
      "Split 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e9131ab9f644be4aaab225b7fbe5adb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 61.91 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.663 AVG Training Acc 62.05 % AVG Validation Acc 60.60 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.633 AVG Validation Loss:0.671 AVG Training Acc 63.11 % AVG Validation Acc 59.78 %\n",
      "Epoch:40/200 AVG Training Loss:0.621 AVG Validation Loss:0.681 AVG Training Acc 63.91 % AVG Validation Acc 61.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.614 AVG Validation Loss:0.690 AVG Training Acc 64.73 % AVG Validation Acc 61.68 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.606 AVG Validation Loss:0.699 AVG Training Acc 65.40 % AVG Validation Acc 60.32 %\n",
      "Epoch:70/200 AVG Training Loss:0.606 AVG Validation Loss:0.702 AVG Training Acc 65.07 % AVG Validation Acc 60.78 %\n",
      "Epoch:80/200 AVG Training Loss:0.604 AVG Validation Loss:0.704 AVG Training Acc 65.23 % AVG Validation Acc 60.69 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.599 AVG Validation Loss:0.703 AVG Training Acc 65.79 % AVG Validation Acc 60.60 %\n",
      "Epoch:100/200 AVG Training Loss:0.602 AVG Validation Loss:0.703 AVG Training Acc 65.67 % AVG Validation Acc 60.69 %\n",
      "Epoch:110/200 AVG Training Loss:0.601 AVG Validation Loss:0.704 AVG Training Acc 65.33 % AVG Validation Acc 60.60 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.602 AVG Validation Loss:0.705 AVG Training Acc 65.79 % AVG Validation Acc 60.96 %\n",
      "Epoch:130/200 AVG Training Loss:0.601 AVG Validation Loss:0.702 AVG Training Acc 65.72 % AVG Validation Acc 61.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.601 AVG Validation Loss:0.703 AVG Training Acc 65.48 % AVG Validation Acc 61.14 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.601 AVG Validation Loss:0.702 AVG Training Acc 65.35 % AVG Validation Acc 61.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.601 AVG Validation Loss:0.699 AVG Training Acc 65.79 % AVG Validation Acc 60.60 %\n",
      "Epoch:170/200 AVG Training Loss:0.602 AVG Validation Loss:0.704 AVG Training Acc 65.71 % AVG Validation Acc 60.69 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.603 AVG Validation Loss:0.702 AVG Training Acc 65.28 % AVG Validation Acc 60.96 %\n",
      "Epoch:190/200 AVG Training Loss:0.599 AVG Validation Loss:0.703 AVG Training Acc 65.92 % AVG Validation Acc 60.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.600 AVG Validation Loss:0.703 AVG Training Acc 66.06 % AVG Validation Acc 61.32 %\n",
      "Split 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2116d0043b2d42f0b2eddfb4f9ccdb64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.656 AVG Training Acc 61.82 % AVG Validation Acc 61.77 %\n",
      "Epoch:30/200 AVG Training Loss:0.651 AVG Validation Loss:0.653 AVG Training Acc 61.99 % AVG Validation Acc 61.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.646 AVG Validation Loss:0.654 AVG Training Acc 62.42 % AVG Validation Acc 61.95 %\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.623 AVG Validation Loss:0.669 AVG Training Acc 63.49 % AVG Validation Acc 62.13 %\n",
      "Epoch:60/200 AVG Training Loss:0.617 AVG Validation Loss:0.686 AVG Training Acc 63.77 % AVG Validation Acc 60.96 %\n",
      "Epoch:70/200 AVG Training Loss:0.608 AVG Validation Loss:0.698 AVG Training Acc 64.11 % AVG Validation Acc 60.96 %\n",
      "Epoch    71: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.603 AVG Validation Loss:0.700 AVG Training Acc 64.48 % AVG Validation Acc 60.69 %\n",
      "Epoch:90/200 AVG Training Loss:0.602 AVG Validation Loss:0.700 AVG Training Acc 65.00 % AVG Validation Acc 59.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.601 AVG Validation Loss:0.706 AVG Training Acc 65.23 % AVG Validation Acc 59.42 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.601 AVG Validation Loss:0.707 AVG Training Acc 65.30 % AVG Validation Acc 59.78 %\n",
      "Epoch:120/200 AVG Training Loss:0.600 AVG Validation Loss:0.709 AVG Training Acc 65.04 % AVG Validation Acc 59.51 %\n",
      "Epoch:130/200 AVG Training Loss:0.604 AVG Validation Loss:0.711 AVG Training Acc 64.63 % AVG Validation Acc 59.42 %\n",
      "Epoch   133: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.601 AVG Validation Loss:0.713 AVG Training Acc 64.63 % AVG Validation Acc 59.69 %\n",
      "Epoch:150/200 AVG Training Loss:0.598 AVG Validation Loss:0.702 AVG Training Acc 65.48 % AVG Validation Acc 59.78 %\n",
      "Epoch:160/200 AVG Training Loss:0.603 AVG Validation Loss:0.705 AVG Training Acc 64.32 % AVG Validation Acc 60.32 %\n",
      "Epoch   164: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.601 AVG Validation Loss:0.708 AVG Training Acc 64.52 % AVG Validation Acc 59.60 %\n",
      "Epoch:180/200 AVG Training Loss:0.602 AVG Validation Loss:0.711 AVG Training Acc 64.97 % AVG Validation Acc 59.51 %\n",
      "Epoch:190/200 AVG Training Loss:0.601 AVG Validation Loss:0.710 AVG Training Acc 64.54 % AVG Validation Acc 59.78 %\n",
      "Epoch   195: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.599 AVG Validation Loss:0.707 AVG Training Acc 64.86 % AVG Validation Acc 59.51 %\n",
      "Split 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17bcde168f0f40f3b8fd5b19b60cc9b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.659 AVG Training Acc 61.92 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.650 AVG Validation Loss:0.659 AVG Training Acc 61.92 % AVG Validation Acc 61.77 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.633 AVG Validation Loss:0.666 AVG Training Acc 63.12 % AVG Validation Acc 61.50 %\n",
      "Epoch:40/200 AVG Training Loss:0.626 AVG Validation Loss:0.664 AVG Training Acc 63.70 % AVG Validation Acc 61.23 %\n",
      "Epoch:50/200 AVG Training Loss:0.620 AVG Validation Loss:0.671 AVG Training Acc 64.18 % AVG Validation Acc 61.14 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.612 AVG Validation Loss:0.676 AVG Training Acc 64.56 % AVG Validation Acc 60.60 %\n",
      "Epoch:70/200 AVG Training Loss:0.610 AVG Validation Loss:0.677 AVG Training Acc 65.22 % AVG Validation Acc 60.87 %\n",
      "Epoch:80/200 AVG Training Loss:0.609 AVG Validation Loss:0.679 AVG Training Acc 64.75 % AVG Validation Acc 60.96 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.609 AVG Validation Loss:0.677 AVG Training Acc 64.80 % AVG Validation Acc 61.23 %\n",
      "Epoch:100/200 AVG Training Loss:0.608 AVG Validation Loss:0.680 AVG Training Acc 65.09 % AVG Validation Acc 60.96 %\n",
      "Epoch:110/200 AVG Training Loss:0.606 AVG Validation Loss:0.678 AVG Training Acc 65.05 % AVG Validation Acc 60.96 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.608 AVG Validation Loss:0.679 AVG Training Acc 65.06 % AVG Validation Acc 60.78 %\n",
      "Epoch:130/200 AVG Training Loss:0.606 AVG Validation Loss:0.679 AVG Training Acc 65.27 % AVG Validation Acc 61.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.607 AVG Validation Loss:0.682 AVG Training Acc 65.32 % AVG Validation Acc 60.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.608 AVG Validation Loss:0.677 AVG Training Acc 64.45 % AVG Validation Acc 61.41 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.608 AVG Validation Loss:0.683 AVG Training Acc 65.27 % AVG Validation Acc 61.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.608 AVG Validation Loss:0.679 AVG Training Acc 64.76 % AVG Validation Acc 60.41 %\n",
      "Epoch:180/200 AVG Training Loss:0.606 AVG Validation Loss:0.676 AVG Training Acc 65.10 % AVG Validation Acc 61.05 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.608 AVG Validation Loss:0.681 AVG Training Acc 64.62 % AVG Validation Acc 60.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.607 AVG Validation Loss:0.678 AVG Training Acc 65.08 % AVG Validation Acc 61.14 %\n",
      "Split 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3faa2d2cd904f22a9330838f821a2dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.657 AVG Training Acc 61.72 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.653 AVG Training Acc 62.05 % AVG Validation Acc 62.04 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.656 AVG Training Acc 61.33 % AVG Validation Acc 61.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.642 AVG Validation Loss:0.657 AVG Training Acc 62.39 % AVG Validation Acc 61.59 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.640 AVG Validation Loss:0.664 AVG Training Acc 62.44 % AVG Validation Acc 61.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.630 AVG Validation Loss:0.668 AVG Training Acc 62.81 % AVG Validation Acc 61.23 %\n",
      "Epoch:70/200 AVG Training Loss:0.620 AVG Validation Loss:0.678 AVG Training Acc 63.26 % AVG Validation Acc 59.87 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.614 AVG Validation Loss:0.677 AVG Training Acc 64.07 % AVG Validation Acc 59.06 %\n",
      "Epoch:90/200 AVG Training Loss:0.613 AVG Validation Loss:0.680 AVG Training Acc 63.88 % AVG Validation Acc 58.34 %\n",
      "Epoch:100/200 AVG Training Loss:0.612 AVG Validation Loss:0.681 AVG Training Acc 64.17 % AVG Validation Acc 59.15 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.610 AVG Validation Loss:0.680 AVG Training Acc 64.18 % AVG Validation Acc 58.97 %\n",
      "Epoch:120/200 AVG Training Loss:0.611 AVG Validation Loss:0.682 AVG Training Acc 64.13 % AVG Validation Acc 58.52 %\n",
      "Epoch:130/200 AVG Training Loss:0.611 AVG Validation Loss:0.683 AVG Training Acc 64.13 % AVG Validation Acc 58.79 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.610 AVG Validation Loss:0.678 AVG Training Acc 63.96 % AVG Validation Acc 58.43 %\n",
      "Epoch:150/200 AVG Training Loss:0.611 AVG Validation Loss:0.683 AVG Training Acc 64.06 % AVG Validation Acc 58.79 %\n",
      "Epoch:160/200 AVG Training Loss:0.610 AVG Validation Loss:0.685 AVG Training Acc 64.28 % AVG Validation Acc 58.70 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.611 AVG Validation Loss:0.683 AVG Training Acc 64.21 % AVG Validation Acc 58.70 %\n",
      "Epoch:180/200 AVG Training Loss:0.610 AVG Validation Loss:0.685 AVG Training Acc 63.97 % AVG Validation Acc 58.61 %\n",
      "Epoch:190/200 AVG Training Loss:0.607 AVG Validation Loss:0.683 AVG Training Acc 64.38 % AVG Validation Acc 58.34 %\n",
      "Epoch   198: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.611 AVG Validation Loss:0.682 AVG Training Acc 64.60 % AVG Validation Acc 58.61 %\n",
      "Split 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd58f757a7e942fdab4b5587c11e8357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.657 AVG Validation Loss:0.662 AVG Training Acc 62.08 % AVG Validation Acc 61.77 %\n",
      "Epoch:20/200 AVG Training Loss:0.649 AVG Validation Loss:0.665 AVG Training Acc 62.12 % AVG Validation Acc 61.23 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.638 AVG Validation Loss:0.660 AVG Training Acc 63.28 % AVG Validation Acc 61.23 %\n",
      "Epoch:40/200 AVG Training Loss:0.630 AVG Validation Loss:0.665 AVG Training Acc 63.70 % AVG Validation Acc 60.87 %\n",
      "Epoch:50/200 AVG Training Loss:0.624 AVG Validation Loss:0.675 AVG Training Acc 63.61 % AVG Validation Acc 60.05 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.615 AVG Validation Loss:0.675 AVG Training Acc 64.61 % AVG Validation Acc 59.42 %\n",
      "Epoch:70/200 AVG Training Loss:0.613 AVG Validation Loss:0.678 AVG Training Acc 64.40 % AVG Validation Acc 58.70 %\n",
      "Epoch:80/200 AVG Training Loss:0.614 AVG Validation Loss:0.684 AVG Training Acc 64.48 % AVG Validation Acc 58.52 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.613 AVG Validation Loss:0.683 AVG Training Acc 64.19 % AVG Validation Acc 58.70 %\n",
      "Epoch:100/200 AVG Training Loss:0.611 AVG Validation Loss:0.681 AVG Training Acc 64.88 % AVG Validation Acc 58.34 %\n",
      "Epoch:110/200 AVG Training Loss:0.611 AVG Validation Loss:0.678 AVG Training Acc 64.68 % AVG Validation Acc 58.61 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.613 AVG Validation Loss:0.680 AVG Training Acc 64.32 % AVG Validation Acc 58.88 %\n",
      "Epoch:130/200 AVG Training Loss:0.613 AVG Validation Loss:0.685 AVG Training Acc 64.44 % AVG Validation Acc 58.70 %\n",
      "Epoch:140/200 AVG Training Loss:0.612 AVG Validation Loss:0.687 AVG Training Acc 64.60 % AVG Validation Acc 58.61 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.612 AVG Validation Loss:0.683 AVG Training Acc 64.60 % AVG Validation Acc 58.79 %\n",
      "Epoch:160/200 AVG Training Loss:0.612 AVG Validation Loss:0.680 AVG Training Acc 64.44 % AVG Validation Acc 58.34 %\n",
      "Epoch:170/200 AVG Training Loss:0.612 AVG Validation Loss:0.686 AVG Training Acc 64.84 % AVG Validation Acc 58.43 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.614 AVG Validation Loss:0.684 AVG Training Acc 64.66 % AVG Validation Acc 57.71 %\n",
      "Epoch:190/200 AVG Training Loss:0.612 AVG Validation Loss:0.686 AVG Training Acc 64.52 % AVG Validation Acc 58.61 %\n",
      "Epoch:200/200 AVG Training Loss:0.616 AVG Validation Loss:0.683 AVG Training Acc 64.18 % AVG Validation Acc 58.43 %\n",
      "Split 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9122299d6ccf483a83db03b1ed8f0b64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.656 AVG Training Acc 61.78 % AVG Validation Acc 62.00 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.655 AVG Training Acc 61.81 % AVG Validation Acc 62.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.644 AVG Validation Loss:0.658 AVG Training Acc 62.28 % AVG Validation Acc 61.73 %\n",
      "Epoch:40/200 AVG Training Loss:0.675 AVG Validation Loss:0.684 AVG Training Acc 60.27 % AVG Validation Acc 61.91 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.665 AVG Validation Loss:0.665 AVG Training Acc 61.91 % AVG Validation Acc 61.91 %\n",
      "Epoch:60/200 AVG Training Loss:0.663 AVG Validation Loss:0.663 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch:70/200 AVG Training Loss:0.663 AVG Validation Loss:0.663 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.664 AVG Validation Loss:0.663 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch:90/200 AVG Training Loss:0.664 AVG Validation Loss:0.663 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch:100/200 AVG Training Loss:0.663 AVG Validation Loss:0.663 AVG Training Acc 61.92 % AVG Validation Acc 61.91 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.663 AVG Validation Loss:0.662 AVG Training Acc 61.91 % AVG Validation Acc 61.91 %\n",
      "Epoch:120/200 AVG Training Loss:0.663 AVG Validation Loss:0.663 AVG Training Acc 61.91 % AVG Validation Acc 61.91 %\n",
      "Epoch:130/200 AVG Training Loss:0.663 AVG Validation Loss:0.663 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.663 AVG Validation Loss:0.663 AVG Training Acc 61.91 % AVG Validation Acc 61.91 %\n",
      "Epoch:150/200 AVG Training Loss:0.663 AVG Validation Loss:0.663 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch:160/200 AVG Training Loss:0.663 AVG Validation Loss:0.663 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.663 AVG Validation Loss:0.662 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch:180/200 AVG Training Loss:0.664 AVG Validation Loss:0.663 AVG Training Acc 61.85 % AVG Validation Acc 61.91 %\n",
      "Epoch:190/200 AVG Training Loss:0.663 AVG Validation Loss:0.663 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch:200/200 AVG Training Loss:0.664 AVG Validation Loss:0.663 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch   200: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Split 17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2760a94559b747ff9f888dc9edf43a92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 61.83 % AVG Validation Acc 62.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:0.656 AVG Training Acc 61.60 % AVG Validation Acc 62.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.645 AVG Validation Loss:0.650 AVG Training Acc 62.30 % AVG Validation Acc 61.91 %\n",
      "Epoch:40/200 AVG Training Loss:0.637 AVG Validation Loss:0.641 AVG Training Acc 62.97 % AVG Validation Acc 62.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.628 AVG Validation Loss:0.664 AVG Training Acc 63.20 % AVG Validation Acc 61.91 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.603 AVG Validation Loss:0.651 AVG Training Acc 65.28 % AVG Validation Acc 63.27 %\n",
      "Epoch:70/200 AVG Training Loss:0.586 AVG Validation Loss:0.669 AVG Training Acc 65.94 % AVG Validation Acc 61.64 %\n",
      "Epoch:80/200 AVG Training Loss:0.575 AVG Validation Loss:0.677 AVG Training Acc 66.82 % AVG Validation Acc 60.38 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.569 AVG Validation Loss:0.684 AVG Training Acc 67.52 % AVG Validation Acc 61.82 %\n",
      "Epoch:100/200 AVG Training Loss:0.569 AVG Validation Loss:0.683 AVG Training Acc 67.45 % AVG Validation Acc 61.37 %\n",
      "Epoch:110/200 AVG Training Loss:0.568 AVG Validation Loss:0.684 AVG Training Acc 67.27 % AVG Validation Acc 60.92 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.566 AVG Validation Loss:0.679 AVG Training Acc 67.18 % AVG Validation Acc 60.83 %\n",
      "Epoch:130/200 AVG Training Loss:0.565 AVG Validation Loss:0.676 AVG Training Acc 67.83 % AVG Validation Acc 61.19 %\n",
      "Epoch:140/200 AVG Training Loss:0.565 AVG Validation Loss:0.683 AVG Training Acc 67.27 % AVG Validation Acc 61.01 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.564 AVG Validation Loss:0.681 AVG Training Acc 67.54 % AVG Validation Acc 60.83 %\n",
      "Epoch:160/200 AVG Training Loss:0.564 AVG Validation Loss:0.687 AVG Training Acc 67.26 % AVG Validation Acc 60.56 %\n",
      "Epoch:170/200 AVG Training Loss:0.565 AVG Validation Loss:0.687 AVG Training Acc 67.29 % AVG Validation Acc 61.19 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.564 AVG Validation Loss:0.681 AVG Training Acc 67.46 % AVG Validation Acc 60.56 %\n",
      "Epoch:190/200 AVG Training Loss:0.565 AVG Validation Loss:0.685 AVG Training Acc 67.38 % AVG Validation Acc 60.92 %\n",
      "Epoch:200/200 AVG Training Loss:0.565 AVG Validation Loss:0.687 AVG Training Acc 67.36 % AVG Validation Acc 61.10 %\n",
      "Split 18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f58f8a6d614b96ae430f740a5e7655",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.661 AVG Training Acc 61.96 % AVG Validation Acc 62.00 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.663 AVG Training Acc 61.87 % AVG Validation Acc 61.37 %\n",
      "Epoch:30/200 AVG Training Loss:0.647 AVG Validation Loss:0.664 AVG Training Acc 62.29 % AVG Validation Acc 61.19 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.633 AVG Validation Loss:0.669 AVG Training Acc 63.34 % AVG Validation Acc 59.84 %\n",
      "Epoch:50/200 AVG Training Loss:0.620 AVG Validation Loss:0.680 AVG Training Acc 64.20 % AVG Validation Acc 60.47 %\n",
      "Epoch:60/200 AVG Training Loss:0.611 AVG Validation Loss:0.686 AVG Training Acc 64.79 % AVG Validation Acc 60.56 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.608 AVG Validation Loss:0.685 AVG Training Acc 65.55 % AVG Validation Acc 60.38 %\n",
      "Epoch:80/200 AVG Training Loss:0.607 AVG Validation Loss:0.691 AVG Training Acc 65.36 % AVG Validation Acc 59.84 %\n",
      "Epoch:90/200 AVG Training Loss:0.603 AVG Validation Loss:0.696 AVG Training Acc 65.69 % AVG Validation Acc 60.47 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.604 AVG Validation Loss:0.689 AVG Training Acc 65.93 % AVG Validation Acc 60.65 %\n",
      "Epoch:110/200 AVG Training Loss:0.602 AVG Validation Loss:0.696 AVG Training Acc 65.79 % AVG Validation Acc 60.29 %\n",
      "Epoch:120/200 AVG Training Loss:0.602 AVG Validation Loss:0.694 AVG Training Acc 65.70 % AVG Validation Acc 60.65 %\n",
      "Epoch:130/200 AVG Training Loss:0.603 AVG Validation Loss:0.692 AVG Training Acc 65.53 % AVG Validation Acc 60.47 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.603 AVG Validation Loss:0.693 AVG Training Acc 65.66 % AVG Validation Acc 60.65 %\n",
      "Epoch:150/200 AVG Training Loss:0.601 AVG Validation Loss:0.690 AVG Training Acc 66.18 % AVG Validation Acc 60.83 %\n",
      "Epoch:160/200 AVG Training Loss:0.602 AVG Validation Loss:0.695 AVG Training Acc 65.87 % AVG Validation Acc 60.11 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.601 AVG Validation Loss:0.694 AVG Training Acc 65.63 % AVG Validation Acc 60.38 %\n",
      "Epoch:180/200 AVG Training Loss:0.601 AVG Validation Loss:0.693 AVG Training Acc 65.76 % AVG Validation Acc 60.47 %\n",
      "Epoch:190/200 AVG Training Loss:0.599 AVG Validation Loss:0.699 AVG Training Acc 65.79 % AVG Validation Acc 60.02 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.603 AVG Validation Loss:0.690 AVG Training Acc 65.92 % AVG Validation Acc 60.47 %\n",
      "Split 19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f4116f7822444f8f0515e0662da499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.655 AVG Training Acc 61.83 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.656 AVG Validation Loss:0.653 AVG Training Acc 62.04 % AVG Validation Acc 61.82 %\n",
      "Epoch:30/200 AVG Training Loss:0.645 AVG Validation Loss:0.657 AVG Training Acc 62.47 % AVG Validation Acc 61.55 %\n",
      "Epoch:40/200 AVG Training Loss:0.637 AVG Validation Loss:0.646 AVG Training Acc 62.28 % AVG Validation Acc 63.18 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.603 AVG Validation Loss:0.660 AVG Training Acc 65.03 % AVG Validation Acc 62.45 %\n",
      "Epoch:60/200 AVG Training Loss:0.588 AVG Validation Loss:0.676 AVG Training Acc 66.45 % AVG Validation Acc 61.91 %\n",
      "Epoch:70/200 AVG Training Loss:0.577 AVG Validation Loss:0.703 AVG Training Acc 66.86 % AVG Validation Acc 60.47 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.568 AVG Validation Loss:0.711 AVG Training Acc 67.34 % AVG Validation Acc 60.83 %\n",
      "Epoch:90/200 AVG Training Loss:0.568 AVG Validation Loss:0.717 AVG Training Acc 67.47 % AVG Validation Acc 60.29 %\n",
      "Epoch:100/200 AVG Training Loss:0.566 AVG Validation Loss:0.717 AVG Training Acc 67.40 % AVG Validation Acc 61.55 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.565 AVG Validation Loss:0.721 AVG Training Acc 67.48 % AVG Validation Acc 60.74 %\n",
      "Epoch:120/200 AVG Training Loss:0.565 AVG Validation Loss:0.718 AVG Training Acc 67.76 % AVG Validation Acc 60.83 %\n",
      "Epoch:130/200 AVG Training Loss:0.563 AVG Validation Loss:0.721 AVG Training Acc 67.64 % AVG Validation Acc 61.01 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.562 AVG Validation Loss:0.718 AVG Training Acc 67.70 % AVG Validation Acc 60.65 %\n",
      "Epoch:150/200 AVG Training Loss:0.563 AVG Validation Loss:0.726 AVG Training Acc 67.82 % AVG Validation Acc 60.56 %\n",
      "Epoch:160/200 AVG Training Loss:0.566 AVG Validation Loss:0.717 AVG Training Acc 67.79 % AVG Validation Acc 60.65 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.563 AVG Validation Loss:0.717 AVG Training Acc 68.24 % AVG Validation Acc 60.83 %\n",
      "Epoch:180/200 AVG Training Loss:0.563 AVG Validation Loss:0.717 AVG Training Acc 67.62 % AVG Validation Acc 61.73 %\n",
      "Epoch:190/200 AVG Training Loss:0.564 AVG Validation Loss:0.715 AVG Training Acc 67.62 % AVG Validation Acc 60.92 %\n",
      "Epoch:200/200 AVG Training Loss:0.562 AVG Validation Loss:0.720 AVG Training Acc 68.14 % AVG Validation Acc 60.56 %\n",
      "Epoch   200: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Split 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f70927b7414454a28b6bd0108e190a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.654 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.651 AVG Training Acc 61.73 % AVG Validation Acc 62.00 %\n",
      "Epoch:30/200 AVG Training Loss:0.645 AVG Validation Loss:0.656 AVG Training Acc 62.07 % AVG Validation Acc 61.73 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.626 AVG Validation Loss:0.665 AVG Training Acc 63.57 % AVG Validation Acc 61.73 %\n",
      "Epoch:50/200 AVG Training Loss:0.620 AVG Validation Loss:0.676 AVG Training Acc 63.65 % AVG Validation Acc 60.92 %\n",
      "Epoch:60/200 AVG Training Loss:0.610 AVG Validation Loss:0.681 AVG Training Acc 64.99 % AVG Validation Acc 61.28 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.608 AVG Validation Loss:0.685 AVG Training Acc 64.79 % AVG Validation Acc 60.47 %\n",
      "Epoch:80/200 AVG Training Loss:0.605 AVG Validation Loss:0.690 AVG Training Acc 64.63 % AVG Validation Acc 60.65 %\n",
      "Epoch:90/200 AVG Training Loss:0.608 AVG Validation Loss:0.694 AVG Training Acc 64.93 % AVG Validation Acc 60.47 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.605 AVG Validation Loss:0.691 AVG Training Acc 64.61 % AVG Validation Acc 61.01 %\n",
      "Epoch:110/200 AVG Training Loss:0.605 AVG Validation Loss:0.695 AVG Training Acc 65.17 % AVG Validation Acc 60.56 %\n",
      "Epoch:120/200 AVG Training Loss:0.604 AVG Validation Loss:0.689 AVG Training Acc 65.38 % AVG Validation Acc 60.47 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.604 AVG Validation Loss:0.696 AVG Training Acc 65.01 % AVG Validation Acc 60.29 %\n",
      "Epoch:140/200 AVG Training Loss:0.602 AVG Validation Loss:0.689 AVG Training Acc 65.05 % AVG Validation Acc 60.74 %\n",
      "Epoch:150/200 AVG Training Loss:0.602 AVG Validation Loss:0.694 AVG Training Acc 65.18 % AVG Validation Acc 60.29 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.605 AVG Validation Loss:0.689 AVG Training Acc 64.78 % AVG Validation Acc 61.28 %\n",
      "Epoch:170/200 AVG Training Loss:0.603 AVG Validation Loss:0.698 AVG Training Acc 65.27 % AVG Validation Acc 60.65 %\n",
      "Epoch:180/200 AVG Training Loss:0.603 AVG Validation Loss:0.696 AVG Training Acc 65.65 % AVG Validation Acc 60.74 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.605 AVG Validation Loss:0.697 AVG Training Acc 65.23 % AVG Validation Acc 60.56 %\n",
      "Epoch:200/200 AVG Training Loss:0.602 AVG Validation Loss:0.689 AVG Training Acc 64.81 % AVG Validation Acc 60.38 %\n",
      "Split 21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0322f7efdad2436da41a8357197ad3c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.665 AVG Training Acc 61.83 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.647 AVG Validation Loss:0.666 AVG Training Acc 62.13 % AVG Validation Acc 62.85 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.628 AVG Validation Loss:0.672 AVG Training Acc 63.74 % AVG Validation Acc 60.32 %\n",
      "Epoch:40/200 AVG Training Loss:0.614 AVG Validation Loss:0.688 AVG Training Acc 64.23 % AVG Validation Acc 61.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.607 AVG Validation Loss:0.697 AVG Training Acc 64.72 % AVG Validation Acc 61.05 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.598 AVG Validation Loss:0.708 AVG Training Acc 66.11 % AVG Validation Acc 59.96 %\n",
      "Epoch:70/200 AVG Training Loss:0.594 AVG Validation Loss:0.706 AVG Training Acc 66.21 % AVG Validation Acc 59.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.594 AVG Validation Loss:0.711 AVG Training Acc 65.89 % AVG Validation Acc 59.87 %\n",
      "Epoch:90/200 AVG Training Loss:0.593 AVG Validation Loss:0.714 AVG Training Acc 66.15 % AVG Validation Acc 59.87 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.593 AVG Validation Loss:0.711 AVG Training Acc 65.78 % AVG Validation Acc 60.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.592 AVG Validation Loss:0.710 AVG Training Acc 66.11 % AVG Validation Acc 59.78 %\n",
      "Epoch:120/200 AVG Training Loss:0.593 AVG Validation Loss:0.710 AVG Training Acc 66.44 % AVG Validation Acc 59.69 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.591 AVG Validation Loss:0.712 AVG Training Acc 66.46 % AVG Validation Acc 59.51 %\n",
      "Epoch:140/200 AVG Training Loss:0.593 AVG Validation Loss:0.712 AVG Training Acc 66.23 % AVG Validation Acc 59.69 %\n",
      "Epoch:150/200 AVG Training Loss:0.592 AVG Validation Loss:0.712 AVG Training Acc 66.12 % AVG Validation Acc 59.51 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.591 AVG Validation Loss:0.710 AVG Training Acc 65.96 % AVG Validation Acc 59.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.591 AVG Validation Loss:0.711 AVG Training Acc 66.34 % AVG Validation Acc 59.15 %\n",
      "Epoch:180/200 AVG Training Loss:0.593 AVG Validation Loss:0.710 AVG Training Acc 65.83 % AVG Validation Acc 60.05 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.591 AVG Validation Loss:0.711 AVG Training Acc 66.44 % AVG Validation Acc 60.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.592 AVG Validation Loss:0.715 AVG Training Acc 66.39 % AVG Validation Acc 59.42 %\n",
      "Split 22\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07871db82d9f4f5d8eb831a595532219",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.657 AVG Validation Loss:0.659 AVG Training Acc 61.94 % AVG Validation Acc 61.86 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.647 AVG Validation Loss:0.662 AVG Training Acc 62.48 % AVG Validation Acc 60.69 %\n",
      "Epoch:30/200 AVG Training Loss:0.632 AVG Validation Loss:0.673 AVG Training Acc 63.13 % AVG Validation Acc 59.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.620 AVG Validation Loss:0.688 AVG Training Acc 63.52 % AVG Validation Acc 59.42 %\n",
      "Epoch:50/200 AVG Training Loss:0.611 AVG Validation Loss:0.696 AVG Training Acc 63.96 % AVG Validation Acc 58.79 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.601 AVG Validation Loss:0.706 AVG Training Acc 65.25 % AVG Validation Acc 57.98 %\n",
      "Epoch:70/200 AVG Training Loss:0.599 AVG Validation Loss:0.706 AVG Training Acc 64.83 % AVG Validation Acc 57.17 %\n",
      "Epoch:80/200 AVG Training Loss:0.597 AVG Validation Loss:0.713 AVG Training Acc 65.77 % AVG Validation Acc 57.35 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.599 AVG Validation Loss:0.711 AVG Training Acc 65.38 % AVG Validation Acc 57.53 %\n",
      "Epoch:100/200 AVG Training Loss:0.598 AVG Validation Loss:0.715 AVG Training Acc 65.68 % AVG Validation Acc 56.90 %\n",
      "Epoch:110/200 AVG Training Loss:0.596 AVG Validation Loss:0.710 AVG Training Acc 65.27 % AVG Validation Acc 58.70 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.598 AVG Validation Loss:0.710 AVG Training Acc 65.24 % AVG Validation Acc 56.99 %\n",
      "Epoch:130/200 AVG Training Loss:0.599 AVG Validation Loss:0.711 AVG Training Acc 65.29 % AVG Validation Acc 57.53 %\n",
      "Epoch:140/200 AVG Training Loss:0.597 AVG Validation Loss:0.713 AVG Training Acc 65.57 % AVG Validation Acc 57.89 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.598 AVG Validation Loss:0.713 AVG Training Acc 65.23 % AVG Validation Acc 57.35 %\n",
      "Epoch:160/200 AVG Training Loss:0.596 AVG Validation Loss:0.709 AVG Training Acc 65.21 % AVG Validation Acc 57.62 %\n",
      "Epoch:170/200 AVG Training Loss:0.596 AVG Validation Loss:0.708 AVG Training Acc 65.66 % AVG Validation Acc 57.53 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.595 AVG Validation Loss:0.710 AVG Training Acc 65.21 % AVG Validation Acc 57.53 %\n",
      "Epoch:190/200 AVG Training Loss:0.597 AVG Validation Loss:0.713 AVG Training Acc 65.29 % AVG Validation Acc 57.26 %\n",
      "Epoch:200/200 AVG Training Loss:0.596 AVG Validation Loss:0.708 AVG Training Acc 65.84 % AVG Validation Acc 57.80 %\n",
      "Split 23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "506c6d22214f459191c88b9cc96da2d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.653 AVG Training Acc 61.77 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.648 AVG Training Acc 62.02 % AVG Validation Acc 61.68 %\n",
      "Epoch:30/200 AVG Training Loss:0.644 AVG Validation Loss:0.653 AVG Training Acc 62.15 % AVG Validation Acc 60.41 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.626 AVG Validation Loss:0.663 AVG Training Acc 63.69 % AVG Validation Acc 61.50 %\n",
      "Epoch:50/200 AVG Training Loss:0.608 AVG Validation Loss:0.684 AVG Training Acc 65.23 % AVG Validation Acc 60.96 %\n",
      "Epoch:60/200 AVG Training Loss:0.598 AVG Validation Loss:0.702 AVG Training Acc 65.59 % AVG Validation Acc 59.87 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.592 AVG Validation Loss:0.686 AVG Training Acc 66.07 % AVG Validation Acc 61.68 %\n",
      "Epoch:80/200 AVG Training Loss:0.589 AVG Validation Loss:0.691 AVG Training Acc 66.13 % AVG Validation Acc 61.23 %\n",
      "Epoch:90/200 AVG Training Loss:0.587 AVG Validation Loss:0.695 AVG Training Acc 66.29 % AVG Validation Acc 61.32 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.587 AVG Validation Loss:0.695 AVG Training Acc 66.54 % AVG Validation Acc 61.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.586 AVG Validation Loss:0.693 AVG Training Acc 66.19 % AVG Validation Acc 61.05 %\n",
      "Epoch:120/200 AVG Training Loss:0.585 AVG Validation Loss:0.695 AVG Training Acc 66.41 % AVG Validation Acc 60.69 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.586 AVG Validation Loss:0.693 AVG Training Acc 66.08 % AVG Validation Acc 61.32 %\n",
      "Epoch:140/200 AVG Training Loss:0.584 AVG Validation Loss:0.696 AVG Training Acc 66.27 % AVG Validation Acc 61.41 %\n",
      "Epoch:150/200 AVG Training Loss:0.583 AVG Validation Loss:0.698 AVG Training Acc 66.73 % AVG Validation Acc 61.14 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.586 AVG Validation Loss:0.696 AVG Training Acc 66.45 % AVG Validation Acc 60.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.586 AVG Validation Loss:0.697 AVG Training Acc 66.48 % AVG Validation Acc 61.32 %\n",
      "Epoch:180/200 AVG Training Loss:0.585 AVG Validation Loss:0.694 AVG Training Acc 66.28 % AVG Validation Acc 61.32 %\n",
      "Epoch:190/200 AVG Training Loss:0.584 AVG Validation Loss:0.699 AVG Training Acc 66.96 % AVG Validation Acc 60.69 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.586 AVG Validation Loss:0.696 AVG Training Acc 67.09 % AVG Validation Acc 60.69 %\n",
      "Split 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40e71a583825446bb8ff70b686811fe2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.664 AVG Validation Loss:0.663 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.661 AVG Training Acc 62.14 % AVG Validation Acc 61.68 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.637 AVG Validation Loss:0.659 AVG Training Acc 63.03 % AVG Validation Acc 60.32 %\n",
      "Epoch:40/200 AVG Training Loss:0.629 AVG Validation Loss:0.661 AVG Training Acc 63.38 % AVG Validation Acc 61.59 %\n",
      "Epoch:50/200 AVG Training Loss:0.625 AVG Validation Loss:0.668 AVG Training Acc 63.45 % AVG Validation Acc 61.32 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.618 AVG Validation Loss:0.669 AVG Training Acc 64.82 % AVG Validation Acc 62.22 %\n",
      "Epoch:70/200 AVG Training Loss:0.617 AVG Validation Loss:0.669 AVG Training Acc 64.47 % AVG Validation Acc 62.04 %\n",
      "Epoch:80/200 AVG Training Loss:0.614 AVG Validation Loss:0.670 AVG Training Acc 65.42 % AVG Validation Acc 61.41 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.613 AVG Validation Loss:0.672 AVG Training Acc 64.65 % AVG Validation Acc 61.41 %\n",
      "Epoch:100/200 AVG Training Loss:0.615 AVG Validation Loss:0.675 AVG Training Acc 64.64 % AVG Validation Acc 61.86 %\n",
      "Epoch:110/200 AVG Training Loss:0.614 AVG Validation Loss:0.669 AVG Training Acc 64.88 % AVG Validation Acc 62.04 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.614 AVG Validation Loss:0.670 AVG Training Acc 64.80 % AVG Validation Acc 61.68 %\n",
      "Epoch:130/200 AVG Training Loss:0.613 AVG Validation Loss:0.670 AVG Training Acc 65.10 % AVG Validation Acc 61.68 %\n",
      "Epoch:140/200 AVG Training Loss:0.612 AVG Validation Loss:0.666 AVG Training Acc 65.43 % AVG Validation Acc 61.86 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.613 AVG Validation Loss:0.670 AVG Training Acc 64.86 % AVG Validation Acc 62.31 %\n",
      "Epoch:160/200 AVG Training Loss:0.614 AVG Validation Loss:0.673 AVG Training Acc 64.99 % AVG Validation Acc 61.23 %\n",
      "Epoch:170/200 AVG Training Loss:0.612 AVG Validation Loss:0.670 AVG Training Acc 64.46 % AVG Validation Acc 61.86 %\n",
      "Epoch:180/200 AVG Training Loss:0.614 AVG Validation Loss:0.669 AVG Training Acc 64.63 % AVG Validation Acc 62.40 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.615 AVG Validation Loss:0.670 AVG Training Acc 64.43 % AVG Validation Acc 61.77 %\n",
      "Epoch:200/200 AVG Training Loss:0.611 AVG Validation Loss:0.670 AVG Training Acc 65.18 % AVG Validation Acc 61.23 %\n",
      "Split 25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d80ba973aa6946d7984c1801c1c707c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.662 AVG Validation Loss:0.659 AVG Training Acc 61.71 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.659 AVG Training Acc 61.74 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.645 AVG Validation Loss:0.659 AVG Training Acc 61.95 % AVG Validation Acc 62.04 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.629 AVG Validation Loss:0.660 AVG Training Acc 62.54 % AVG Validation Acc 60.96 %\n",
      "Epoch:50/200 AVG Training Loss:0.614 AVG Validation Loss:0.681 AVG Training Acc 64.22 % AVG Validation Acc 60.96 %\n",
      "Epoch:60/200 AVG Training Loss:0.605 AVG Validation Loss:0.696 AVG Training Acc 65.27 % AVG Validation Acc 61.32 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.596 AVG Validation Loss:0.704 AVG Training Acc 65.79 % AVG Validation Acc 60.78 %\n",
      "Epoch:80/200 AVG Training Loss:0.591 AVG Validation Loss:0.697 AVG Training Acc 66.54 % AVG Validation Acc 60.50 %\n",
      "Epoch:90/200 AVG Training Loss:0.589 AVG Validation Loss:0.702 AVG Training Acc 66.27 % AVG Validation Acc 60.60 %\n",
      "Epoch:100/200 AVG Training Loss:0.588 AVG Validation Loss:0.702 AVG Training Acc 66.53 % AVG Validation Acc 60.60 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.588 AVG Validation Loss:0.703 AVG Training Acc 66.60 % AVG Validation Acc 60.50 %\n",
      "Epoch:120/200 AVG Training Loss:0.590 AVG Validation Loss:0.706 AVG Training Acc 66.30 % AVG Validation Acc 60.32 %\n",
      "Epoch:130/200 AVG Training Loss:0.589 AVG Validation Loss:0.702 AVG Training Acc 66.39 % AVG Validation Acc 60.60 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.590 AVG Validation Loss:0.705 AVG Training Acc 66.15 % AVG Validation Acc 60.23 %\n",
      "Epoch:150/200 AVG Training Loss:0.588 AVG Validation Loss:0.702 AVG Training Acc 66.61 % AVG Validation Acc 60.60 %\n",
      "Epoch:160/200 AVG Training Loss:0.589 AVG Validation Loss:0.702 AVG Training Acc 66.32 % AVG Validation Acc 60.41 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.588 AVG Validation Loss:0.703 AVG Training Acc 66.47 % AVG Validation Acc 60.32 %\n",
      "Epoch:180/200 AVG Training Loss:0.588 AVG Validation Loss:0.701 AVG Training Acc 66.69 % AVG Validation Acc 60.78 %\n",
      "Epoch:190/200 AVG Training Loss:0.587 AVG Validation Loss:0.700 AVG Training Acc 66.66 % AVG Validation Acc 60.50 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.588 AVG Validation Loss:0.700 AVG Training Acc 66.44 % AVG Validation Acc 60.05 %\n",
      "Split 26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "532d4586c23341ac98b54fd2149f98db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.651 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:0.650 AVG Training Acc 61.87 % AVG Validation Acc 61.46 %\n",
      "Epoch:30/200 AVG Training Loss:0.651 AVG Validation Loss:0.647 AVG Training Acc 61.90 % AVG Validation Acc 61.82 %\n",
      "Epoch:40/200 AVG Training Loss:0.647 AVG Validation Loss:0.649 AVG Training Acc 62.43 % AVG Validation Acc 61.10 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.634 AVG Validation Loss:0.650 AVG Training Acc 63.21 % AVG Validation Acc 62.00 %\n",
      "Epoch:60/200 AVG Training Loss:0.621 AVG Validation Loss:0.655 AVG Training Acc 63.52 % AVG Validation Acc 61.64 %\n",
      "Epoch:70/200 AVG Training Loss:0.612 AVG Validation Loss:0.659 AVG Training Acc 64.81 % AVG Validation Acc 62.09 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.609 AVG Validation Loss:0.658 AVG Training Acc 64.72 % AVG Validation Acc 62.55 %\n",
      "Epoch:90/200 AVG Training Loss:0.609 AVG Validation Loss:0.657 AVG Training Acc 65.17 % AVG Validation Acc 62.00 %\n",
      "Epoch:100/200 AVG Training Loss:0.608 AVG Validation Loss:0.654 AVG Training Acc 64.92 % AVG Validation Acc 62.00 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.605 AVG Validation Loss:0.658 AVG Training Acc 65.08 % AVG Validation Acc 61.64 %\n",
      "Epoch:120/200 AVG Training Loss:0.605 AVG Validation Loss:0.655 AVG Training Acc 65.16 % AVG Validation Acc 62.18 %\n",
      "Epoch:130/200 AVG Training Loss:0.604 AVG Validation Loss:0.659 AVG Training Acc 65.26 % AVG Validation Acc 62.36 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.605 AVG Validation Loss:0.658 AVG Training Acc 65.10 % AVG Validation Acc 61.73 %\n",
      "Epoch:150/200 AVG Training Loss:0.605 AVG Validation Loss:0.657 AVG Training Acc 65.24 % AVG Validation Acc 61.91 %\n",
      "Epoch:160/200 AVG Training Loss:0.603 AVG Validation Loss:0.659 AVG Training Acc 65.64 % AVG Validation Acc 62.36 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.603 AVG Validation Loss:0.658 AVG Training Acc 65.58 % AVG Validation Acc 62.27 %\n",
      "Epoch:180/200 AVG Training Loss:0.604 AVG Validation Loss:0.655 AVG Training Acc 65.49 % AVG Validation Acc 61.91 %\n",
      "Epoch:190/200 AVG Training Loss:0.604 AVG Validation Loss:0.660 AVG Training Acc 65.03 % AVG Validation Acc 62.09 %\n",
      "Epoch:200/200 AVG Training Loss:0.605 AVG Validation Loss:0.658 AVG Training Acc 64.60 % AVG Validation Acc 61.37 %\n",
      "Epoch   200: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Split 27\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13067cbc5c3749b1beb8f8d0fe8cdbdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.657 AVG Validation Loss:0.664 AVG Training Acc 62.02 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.649 AVG Validation Loss:0.670 AVG Training Acc 61.88 % AVG Validation Acc 62.09 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.630 AVG Validation Loss:0.668 AVG Training Acc 63.12 % AVG Validation Acc 60.47 %\n",
      "Epoch:40/200 AVG Training Loss:0.624 AVG Validation Loss:0.677 AVG Training Acc 63.77 % AVG Validation Acc 59.93 %\n",
      "Epoch:50/200 AVG Training Loss:0.613 AVG Validation Loss:0.682 AVG Training Acc 64.20 % AVG Validation Acc 59.39 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.609 AVG Validation Loss:0.685 AVG Training Acc 64.52 % AVG Validation Acc 59.30 %\n",
      "Epoch:70/200 AVG Training Loss:0.609 AVG Validation Loss:0.690 AVG Training Acc 64.45 % AVG Validation Acc 59.48 %\n",
      "Epoch:80/200 AVG Training Loss:0.607 AVG Validation Loss:0.692 AVG Training Acc 64.15 % AVG Validation Acc 59.57 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.608 AVG Validation Loss:0.687 AVG Training Acc 65.14 % AVG Validation Acc 59.21 %\n",
      "Epoch:100/200 AVG Training Loss:0.605 AVG Validation Loss:0.690 AVG Training Acc 64.71 % AVG Validation Acc 59.30 %\n",
      "Epoch:110/200 AVG Training Loss:0.606 AVG Validation Loss:0.692 AVG Training Acc 64.99 % AVG Validation Acc 59.21 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.608 AVG Validation Loss:0.693 AVG Training Acc 64.93 % AVG Validation Acc 58.94 %\n",
      "Epoch:130/200 AVG Training Loss:0.606 AVG Validation Loss:0.689 AVG Training Acc 65.16 % AVG Validation Acc 59.30 %\n",
      "Epoch:140/200 AVG Training Loss:0.609 AVG Validation Loss:0.694 AVG Training Acc 64.66 % AVG Validation Acc 59.12 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.606 AVG Validation Loss:0.690 AVG Training Acc 65.01 % AVG Validation Acc 59.03 %\n",
      "Epoch:160/200 AVG Training Loss:0.606 AVG Validation Loss:0.692 AVG Training Acc 65.24 % AVG Validation Acc 59.57 %\n",
      "Epoch:170/200 AVG Training Loss:0.606 AVG Validation Loss:0.696 AVG Training Acc 64.26 % AVG Validation Acc 59.30 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.605 AVG Validation Loss:0.691 AVG Training Acc 64.44 % AVG Validation Acc 60.02 %\n",
      "Epoch:190/200 AVG Training Loss:0.606 AVG Validation Loss:0.686 AVG Training Acc 64.73 % AVG Validation Acc 58.75 %\n",
      "Epoch:200/200 AVG Training Loss:0.605 AVG Validation Loss:0.691 AVG Training Acc 64.92 % AVG Validation Acc 59.03 %\n",
      "Split 28\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f845244283b4f8b9f866c1dabc5841b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.656 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.646 AVG Training Acc 61.94 % AVG Validation Acc 62.27 %\n",
      "Epoch:30/200 AVG Training Loss:0.659 AVG Validation Loss:0.655 AVG Training Acc 61.83 % AVG Validation Acc 62.18 %\n",
      "Epoch:40/200 AVG Training Loss:0.655 AVG Validation Loss:0.661 AVG Training Acc 61.74 % AVG Validation Acc 62.82 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.635 AVG Validation Loss:0.655 AVG Training Acc 62.89 % AVG Validation Acc 63.00 %\n",
      "Epoch:60/200 AVG Training Loss:0.627 AVG Validation Loss:0.662 AVG Training Acc 63.71 % AVG Validation Acc 62.45 %\n",
      "Epoch:70/200 AVG Training Loss:0.618 AVG Validation Loss:0.668 AVG Training Acc 63.94 % AVG Validation Acc 62.09 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.611 AVG Validation Loss:0.672 AVG Training Acc 64.52 % AVG Validation Acc 61.64 %\n",
      "Epoch:90/200 AVG Training Loss:0.607 AVG Validation Loss:0.676 AVG Training Acc 64.59 % AVG Validation Acc 61.55 %\n",
      "Epoch:100/200 AVG Training Loss:0.606 AVG Validation Loss:0.674 AVG Training Acc 64.86 % AVG Validation Acc 61.64 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.606 AVG Validation Loss:0.680 AVG Training Acc 64.46 % AVG Validation Acc 61.55 %\n",
      "Epoch:120/200 AVG Training Loss:0.607 AVG Validation Loss:0.674 AVG Training Acc 64.54 % AVG Validation Acc 61.28 %\n",
      "Epoch:130/200 AVG Training Loss:0.607 AVG Validation Loss:0.677 AVG Training Acc 64.85 % AVG Validation Acc 61.64 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.607 AVG Validation Loss:0.676 AVG Training Acc 64.76 % AVG Validation Acc 61.55 %\n",
      "Epoch:150/200 AVG Training Loss:0.606 AVG Validation Loss:0.676 AVG Training Acc 64.69 % AVG Validation Acc 61.64 %\n",
      "Epoch:160/200 AVG Training Loss:0.605 AVG Validation Loss:0.675 AVG Training Acc 65.05 % AVG Validation Acc 61.28 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.606 AVG Validation Loss:0.677 AVG Training Acc 65.05 % AVG Validation Acc 61.28 %\n",
      "Epoch:180/200 AVG Training Loss:0.604 AVG Validation Loss:0.676 AVG Training Acc 65.51 % AVG Validation Acc 61.37 %\n",
      "Epoch:190/200 AVG Training Loss:0.606 AVG Validation Loss:0.675 AVG Training Acc 65.18 % AVG Validation Acc 61.55 %\n",
      "Epoch:200/200 AVG Training Loss:0.605 AVG Validation Loss:0.678 AVG Training Acc 65.21 % AVG Validation Acc 61.28 %\n",
      "Epoch   200: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Split 29\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffcded3376e2401288e37fa10a91402d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.664 AVG Training Acc 61.96 % AVG Validation Acc 61.91 %\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.657 AVG Training Acc 62.12 % AVG Validation Acc 61.46 %\n",
      "Epoch:30/200 AVG Training Loss:0.645 AVG Validation Loss:0.657 AVG Training Acc 62.47 % AVG Validation Acc 62.18 %\n",
      "Epoch:40/200 AVG Training Loss:0.638 AVG Validation Loss:0.659 AVG Training Acc 63.47 % AVG Validation Acc 61.46 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.631 AVG Validation Loss:0.664 AVG Training Acc 64.04 % AVG Validation Acc 60.92 %\n",
      "Epoch:60/200 AVG Training Loss:0.629 AVG Validation Loss:0.665 AVG Training Acc 64.38 % AVG Validation Acc 61.37 %\n",
      "Epoch:70/200 AVG Training Loss:0.626 AVG Validation Loss:0.667 AVG Training Acc 64.25 % AVG Validation Acc 61.28 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.626 AVG Validation Loss:0.666 AVG Training Acc 64.56 % AVG Validation Acc 61.73 %\n",
      "Epoch:90/200 AVG Training Loss:0.627 AVG Validation Loss:0.667 AVG Training Acc 64.28 % AVG Validation Acc 61.46 %\n",
      "Epoch:100/200 AVG Training Loss:0.626 AVG Validation Loss:0.666 AVG Training Acc 64.68 % AVG Validation Acc 61.82 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.625 AVG Validation Loss:0.667 AVG Training Acc 64.40 % AVG Validation Acc 61.28 %\n",
      "Epoch:120/200 AVG Training Loss:0.626 AVG Validation Loss:0.667 AVG Training Acc 64.39 % AVG Validation Acc 61.55 %\n",
      "Epoch:130/200 AVG Training Loss:0.626 AVG Validation Loss:0.667 AVG Training Acc 64.76 % AVG Validation Acc 61.64 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.627 AVG Validation Loss:0.668 AVG Training Acc 64.65 % AVG Validation Acc 62.09 %\n",
      "Epoch:150/200 AVG Training Loss:0.623 AVG Validation Loss:0.667 AVG Training Acc 64.85 % AVG Validation Acc 61.64 %\n",
      "Epoch:160/200 AVG Training Loss:0.626 AVG Validation Loss:0.667 AVG Training Acc 64.38 % AVG Validation Acc 61.28 %\n",
      "Epoch:170/200 AVG Training Loss:0.625 AVG Validation Loss:0.668 AVG Training Acc 64.47 % AVG Validation Acc 61.64 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.626 AVG Validation Loss:0.667 AVG Training Acc 64.46 % AVG Validation Acc 61.46 %\n",
      "Epoch:190/200 AVG Training Loss:0.625 AVG Validation Loss:0.668 AVG Training Acc 64.49 % AVG Validation Acc 61.55 %\n",
      "Epoch:200/200 AVG Training Loss:0.627 AVG Validation Loss:0.668 AVG Training Acc 64.08 % AVG Validation Acc 61.64 %\n",
      "Split 30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa7db919f5bc43c3bb4d14ed5bc450a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 61.76 % AVG Validation Acc 61.91 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.647 AVG Validation Loss:0.656 AVG Training Acc 62.16 % AVG Validation Acc 61.82 %\n",
      "Epoch:30/200 AVG Training Loss:0.639 AVG Validation Loss:0.664 AVG Training Acc 62.56 % AVG Validation Acc 60.20 %\n",
      "Epoch:40/200 AVG Training Loss:0.635 AVG Validation Loss:0.671 AVG Training Acc 62.66 % AVG Validation Acc 60.20 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.627 AVG Validation Loss:0.675 AVG Training Acc 63.64 % AVG Validation Acc 59.48 %\n",
      "Epoch:60/200 AVG Training Loss:0.626 AVG Validation Loss:0.681 AVG Training Acc 63.73 % AVG Validation Acc 58.94 %\n",
      "Epoch:70/200 AVG Training Loss:0.625 AVG Validation Loss:0.687 AVG Training Acc 63.72 % AVG Validation Acc 58.66 %\n",
      "Epoch:80/200 AVG Training Loss:0.624 AVG Validation Loss:0.686 AVG Training Acc 63.70 % AVG Validation Acc 59.03 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.623 AVG Validation Loss:0.690 AVG Training Acc 63.70 % AVG Validation Acc 58.57 %\n",
      "Epoch:100/200 AVG Training Loss:0.623 AVG Validation Loss:0.691 AVG Training Acc 63.78 % AVG Validation Acc 58.66 %\n",
      "Epoch:110/200 AVG Training Loss:0.623 AVG Validation Loss:0.692 AVG Training Acc 63.71 % AVG Validation Acc 58.84 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.623 AVG Validation Loss:0.690 AVG Training Acc 63.46 % AVG Validation Acc 58.94 %\n",
      "Epoch:130/200 AVG Training Loss:0.621 AVG Validation Loss:0.693 AVG Training Acc 63.52 % AVG Validation Acc 58.57 %\n",
      "Epoch:140/200 AVG Training Loss:0.622 AVG Validation Loss:0.695 AVG Training Acc 63.79 % AVG Validation Acc 58.66 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.624 AVG Validation Loss:0.692 AVG Training Acc 63.58 % AVG Validation Acc 58.66 %\n",
      "Epoch:160/200 AVG Training Loss:0.623 AVG Validation Loss:0.689 AVG Training Acc 63.79 % AVG Validation Acc 58.84 %\n",
      "Epoch:170/200 AVG Training Loss:0.624 AVG Validation Loss:0.691 AVG Training Acc 63.59 % AVG Validation Acc 58.57 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.622 AVG Validation Loss:0.689 AVG Training Acc 63.97 % AVG Validation Acc 58.75 %\n",
      "Epoch:190/200 AVG Training Loss:0.623 AVG Validation Loss:0.690 AVG Training Acc 63.69 % AVG Validation Acc 58.84 %\n",
      "Epoch:200/200 AVG Training Loss:0.624 AVG Validation Loss:0.692 AVG Training Acc 63.75 % AVG Validation Acc 58.57 %\n",
      "Split 31\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6eb1a3313555460ab59d97c20674b31d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.661 AVG Training Acc 61.71 % AVG Validation Acc 61.77 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.663 AVG Training Acc 62.39 % AVG Validation Acc 61.32 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.640 AVG Validation Loss:0.662 AVG Training Acc 63.25 % AVG Validation Acc 60.87 %\n",
      "Epoch:40/200 AVG Training Loss:0.625 AVG Validation Loss:0.674 AVG Training Acc 64.15 % AVG Validation Acc 59.96 %\n",
      "Epoch:50/200 AVG Training Loss:0.615 AVG Validation Loss:0.684 AVG Training Acc 64.52 % AVG Validation Acc 58.97 %\n",
      "Epoch:60/200 AVG Training Loss:0.607 AVG Validation Loss:0.691 AVG Training Acc 65.65 % AVG Validation Acc 59.51 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.602 AVG Validation Loss:0.693 AVG Training Acc 65.80 % AVG Validation Acc 59.33 %\n",
      "Epoch:80/200 AVG Training Loss:0.600 AVG Validation Loss:0.694 AVG Training Acc 66.15 % AVG Validation Acc 58.70 %\n",
      "Epoch:90/200 AVG Training Loss:0.597 AVG Validation Loss:0.703 AVG Training Acc 66.63 % AVG Validation Acc 58.52 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.598 AVG Validation Loss:0.700 AVG Training Acc 66.51 % AVG Validation Acc 58.70 %\n",
      "Epoch:110/200 AVG Training Loss:0.597 AVG Validation Loss:0.693 AVG Training Acc 66.58 % AVG Validation Acc 58.97 %\n",
      "Epoch:120/200 AVG Training Loss:0.598 AVG Validation Loss:0.696 AVG Training Acc 66.21 % AVG Validation Acc 59.33 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.596 AVG Validation Loss:0.696 AVG Training Acc 66.12 % AVG Validation Acc 59.24 %\n",
      "Epoch:140/200 AVG Training Loss:0.598 AVG Validation Loss:0.699 AVG Training Acc 66.71 % AVG Validation Acc 58.43 %\n",
      "Epoch:150/200 AVG Training Loss:0.597 AVG Validation Loss:0.699 AVG Training Acc 66.46 % AVG Validation Acc 58.88 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.599 AVG Validation Loss:0.693 AVG Training Acc 66.30 % AVG Validation Acc 59.69 %\n",
      "Epoch:170/200 AVG Training Loss:0.597 AVG Validation Loss:0.696 AVG Training Acc 66.43 % AVG Validation Acc 59.06 %\n",
      "Epoch:180/200 AVG Training Loss:0.598 AVG Validation Loss:0.697 AVG Training Acc 66.41 % AVG Validation Acc 59.33 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.599 AVG Validation Loss:0.701 AVG Training Acc 66.28 % AVG Validation Acc 58.79 %\n",
      "Epoch:200/200 AVG Training Loss:0.597 AVG Validation Loss:0.697 AVG Training Acc 66.46 % AVG Validation Acc 58.79 %\n",
      "Split 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c607cef8a6842928a7e09bc121a0ca4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.655 AVG Training Acc 61.77 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.646 AVG Training Acc 61.90 % AVG Validation Acc 61.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.643 AVG Validation Loss:0.647 AVG Training Acc 62.44 % AVG Validation Acc 61.95 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.622 AVG Validation Loss:0.659 AVG Training Acc 63.83 % AVG Validation Acc 62.13 %\n",
      "Epoch:50/200 AVG Training Loss:0.611 AVG Validation Loss:0.673 AVG Training Acc 64.57 % AVG Validation Acc 61.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.603 AVG Validation Loss:0.689 AVG Training Acc 64.16 % AVG Validation Acc 60.78 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.598 AVG Validation Loss:0.688 AVG Training Acc 64.90 % AVG Validation Acc 60.23 %\n",
      "Epoch:80/200 AVG Training Loss:0.599 AVG Validation Loss:0.690 AVG Training Acc 65.01 % AVG Validation Acc 60.41 %\n",
      "Epoch:90/200 AVG Training Loss:0.594 AVG Validation Loss:0.689 AVG Training Acc 65.22 % AVG Validation Acc 60.69 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.594 AVG Validation Loss:0.693 AVG Training Acc 65.39 % AVG Validation Acc 60.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.597 AVG Validation Loss:0.694 AVG Training Acc 65.17 % AVG Validation Acc 60.32 %\n",
      "Epoch:120/200 AVG Training Loss:0.595 AVG Validation Loss:0.693 AVG Training Acc 65.07 % AVG Validation Acc 60.41 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.593 AVG Validation Loss:0.697 AVG Training Acc 65.51 % AVG Validation Acc 60.41 %\n",
      "Epoch:140/200 AVG Training Loss:0.594 AVG Validation Loss:0.695 AVG Training Acc 65.00 % AVG Validation Acc 60.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.593 AVG Validation Loss:0.691 AVG Training Acc 65.36 % AVG Validation Acc 61.23 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.597 AVG Validation Loss:0.693 AVG Training Acc 64.91 % AVG Validation Acc 60.60 %\n",
      "Epoch:170/200 AVG Training Loss:0.596 AVG Validation Loss:0.696 AVG Training Acc 64.95 % AVG Validation Acc 60.50 %\n",
      "Epoch:180/200 AVG Training Loss:0.595 AVG Validation Loss:0.693 AVG Training Acc 65.63 % AVG Validation Acc 60.87 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.595 AVG Validation Loss:0.688 AVG Training Acc 64.99 % AVG Validation Acc 61.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.595 AVG Validation Loss:0.695 AVG Training Acc 65.52 % AVG Validation Acc 60.78 %\n",
      "Split 33\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8f548ba5ab24eb395a6010ef86ffe47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.657 AVG Training Acc 61.87 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.656 AVG Training Acc 62.04 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.640 AVG Validation Loss:0.650 AVG Training Acc 62.32 % AVG Validation Acc 62.13 %\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.627 AVG Validation Loss:0.652 AVG Training Acc 63.04 % AVG Validation Acc 63.12 %\n",
      "Epoch:50/200 AVG Training Loss:0.601 AVG Validation Loss:0.677 AVG Training Acc 65.60 % AVG Validation Acc 61.77 %\n",
      "Epoch:60/200 AVG Training Loss:0.585 AVG Validation Loss:0.682 AVG Training Acc 66.93 % AVG Validation Acc 61.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.582 AVG Validation Loss:0.691 AVG Training Acc 66.53 % AVG Validation Acc 61.14 %\n",
      "Epoch    70: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.577 AVG Validation Loss:0.691 AVG Training Acc 66.58 % AVG Validation Acc 60.69 %\n",
      "Epoch:90/200 AVG Training Loss:0.576 AVG Validation Loss:0.694 AVG Training Acc 67.57 % AVG Validation Acc 60.69 %\n",
      "Epoch:100/200 AVG Training Loss:0.573 AVG Validation Loss:0.696 AVG Training Acc 67.35 % AVG Validation Acc 59.96 %\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.573 AVG Validation Loss:0.698 AVG Training Acc 67.54 % AVG Validation Acc 60.60 %\n",
      "Epoch:120/200 AVG Training Loss:0.572 AVG Validation Loss:0.696 AVG Training Acc 67.61 % AVG Validation Acc 60.60 %\n",
      "Epoch:130/200 AVG Training Loss:0.571 AVG Validation Loss:0.694 AVG Training Acc 67.45 % AVG Validation Acc 61.05 %\n",
      "Epoch   132: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.572 AVG Validation Loss:0.697 AVG Training Acc 67.70 % AVG Validation Acc 60.14 %\n",
      "Epoch:150/200 AVG Training Loss:0.571 AVG Validation Loss:0.700 AVG Training Acc 67.56 % AVG Validation Acc 60.41 %\n",
      "Epoch:160/200 AVG Training Loss:0.570 AVG Validation Loss:0.703 AVG Training Acc 67.57 % AVG Validation Acc 60.32 %\n",
      "Epoch   163: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.571 AVG Validation Loss:0.697 AVG Training Acc 67.79 % AVG Validation Acc 61.23 %\n",
      "Epoch:180/200 AVG Training Loss:0.571 AVG Validation Loss:0.697 AVG Training Acc 67.24 % AVG Validation Acc 60.69 %\n",
      "Epoch:190/200 AVG Training Loss:0.572 AVG Validation Loss:0.698 AVG Training Acc 67.36 % AVG Validation Acc 60.96 %\n",
      "Epoch   194: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.570 AVG Validation Loss:0.695 AVG Training Acc 67.67 % AVG Validation Acc 61.23 %\n",
      "Split 34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c23151abad54497097550435441050b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.663 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.661 AVG Training Acc 62.05 % AVG Validation Acc 62.22 %\n",
      "Epoch:30/200 AVG Training Loss:0.646 AVG Validation Loss:0.657 AVG Training Acc 62.59 % AVG Validation Acc 61.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.643 AVG Validation Loss:0.653 AVG Training Acc 62.93 % AVG Validation Acc 62.40 %\n",
      "Epoch:50/200 AVG Training Loss:0.661 AVG Validation Loss:0.664 AVG Training Acc 61.99 % AVG Validation Acc 61.59 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.653 AVG Validation Loss:0.663 AVG Training Acc 62.15 % AVG Validation Acc 61.50 %\n",
      "Epoch:70/200 AVG Training Loss:0.649 AVG Validation Loss:0.662 AVG Training Acc 62.39 % AVG Validation Acc 61.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.647 AVG Validation Loss:0.660 AVG Training Acc 62.45 % AVG Validation Acc 61.68 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.646 AVG Validation Loss:0.660 AVG Training Acc 62.83 % AVG Validation Acc 61.95 %\n",
      "Epoch:100/200 AVG Training Loss:0.644 AVG Validation Loss:0.661 AVG Training Acc 62.62 % AVG Validation Acc 61.23 %\n",
      "Epoch:110/200 AVG Training Loss:0.643 AVG Validation Loss:0.657 AVG Training Acc 62.79 % AVG Validation Acc 61.59 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.643 AVG Validation Loss:0.660 AVG Training Acc 62.89 % AVG Validation Acc 62.22 %\n",
      "Epoch:130/200 AVG Training Loss:0.642 AVG Validation Loss:0.658 AVG Training Acc 62.90 % AVG Validation Acc 62.04 %\n",
      "Epoch:140/200 AVG Training Loss:0.644 AVG Validation Loss:0.659 AVG Training Acc 62.88 % AVG Validation Acc 61.86 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.643 AVG Validation Loss:0.661 AVG Training Acc 62.72 % AVG Validation Acc 61.95 %\n",
      "Epoch:160/200 AVG Training Loss:0.642 AVG Validation Loss:0.659 AVG Training Acc 62.68 % AVG Validation Acc 60.96 %\n",
      "Epoch:170/200 AVG Training Loss:0.643 AVG Validation Loss:0.659 AVG Training Acc 62.88 % AVG Validation Acc 61.77 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.644 AVG Validation Loss:0.660 AVG Training Acc 62.59 % AVG Validation Acc 61.50 %\n",
      "Epoch:190/200 AVG Training Loss:0.642 AVG Validation Loss:0.660 AVG Training Acc 62.89 % AVG Validation Acc 62.04 %\n",
      "Epoch:200/200 AVG Training Loss:0.643 AVG Validation Loss:0.659 AVG Training Acc 62.75 % AVG Validation Acc 61.68 %\n",
      "Split 35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0468403e98274f3dae16bac115f6f585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.658 AVG Training Acc 61.76 % AVG Validation Acc 62.31 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.661 AVG Training Acc 62.23 % AVG Validation Acc 61.77 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.635 AVG Validation Loss:0.665 AVG Training Acc 62.69 % AVG Validation Acc 60.78 %\n",
      "Epoch:40/200 AVG Training Loss:0.627 AVG Validation Loss:0.673 AVG Training Acc 63.62 % AVG Validation Acc 60.96 %\n",
      "Epoch:50/200 AVG Training Loss:0.618 AVG Validation Loss:0.678 AVG Training Acc 64.56 % AVG Validation Acc 60.05 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.612 AVG Validation Loss:0.691 AVG Training Acc 64.77 % AVG Validation Acc 60.69 %\n",
      "Epoch:70/200 AVG Training Loss:0.612 AVG Validation Loss:0.696 AVG Training Acc 64.86 % AVG Validation Acc 60.87 %\n",
      "Epoch:80/200 AVG Training Loss:0.611 AVG Validation Loss:0.697 AVG Training Acc 64.56 % AVG Validation Acc 60.14 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.609 AVG Validation Loss:0.697 AVG Training Acc 65.19 % AVG Validation Acc 60.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.609 AVG Validation Loss:0.698 AVG Training Acc 65.12 % AVG Validation Acc 60.69 %\n",
      "Epoch:110/200 AVG Training Loss:0.610 AVG Validation Loss:0.694 AVG Training Acc 65.04 % AVG Validation Acc 60.41 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.609 AVG Validation Loss:0.696 AVG Training Acc 65.20 % AVG Validation Acc 60.60 %\n",
      "Epoch:130/200 AVG Training Loss:0.608 AVG Validation Loss:0.694 AVG Training Acc 65.33 % AVG Validation Acc 60.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.608 AVG Validation Loss:0.700 AVG Training Acc 65.19 % AVG Validation Acc 60.32 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.609 AVG Validation Loss:0.700 AVG Training Acc 64.95 % AVG Validation Acc 60.23 %\n",
      "Epoch:160/200 AVG Training Loss:0.608 AVG Validation Loss:0.696 AVG Training Acc 65.26 % AVG Validation Acc 60.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.610 AVG Validation Loss:0.698 AVG Training Acc 65.36 % AVG Validation Acc 60.50 %\n",
      "Epoch:180/200 AVG Training Loss:0.609 AVG Validation Loss:0.695 AVG Training Acc 65.29 % AVG Validation Acc 60.50 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.610 AVG Validation Loss:0.696 AVG Training Acc 65.00 % AVG Validation Acc 60.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.609 AVG Validation Loss:0.696 AVG Training Acc 64.95 % AVG Validation Acc 60.78 %\n",
      "Split 36\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "185847d63dc145b4ab7bc7454d72e926",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.655 AVG Training Acc 61.74 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.649 AVG Validation Loss:0.652 AVG Training Acc 62.07 % AVG Validation Acc 61.73 %\n",
      "Epoch:30/200 AVG Training Loss:0.644 AVG Validation Loss:0.646 AVG Training Acc 62.44 % AVG Validation Acc 62.18 %\n",
      "Epoch:40/200 AVG Training Loss:0.689 AVG Validation Loss:0.687 AVG Training Acc 58.96 % AVG Validation Acc 61.82 %\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.663 AVG Validation Loss:0.661 AVG Training Acc 61.92 % AVG Validation Acc 61.91 %\n",
      "Epoch:60/200 AVG Training Loss:0.663 AVG Validation Loss:0.661 AVG Training Acc 61.95 % AVG Validation Acc 61.91 %\n",
      "Epoch:70/200 AVG Training Loss:0.661 AVG Validation Loss:0.659 AVG Training Acc 61.99 % AVG Validation Acc 61.82 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.659 AVG Validation Loss:0.659 AVG Training Acc 62.11 % AVG Validation Acc 62.00 %\n",
      "Epoch:90/200 AVG Training Loss:0.659 AVG Validation Loss:0.659 AVG Training Acc 61.95 % AVG Validation Acc 62.09 %\n",
      "Epoch:100/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 61.87 % AVG Validation Acc 62.09 %\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.658 AVG Validation Loss:0.658 AVG Training Acc 62.09 % AVG Validation Acc 62.09 %\n",
      "Epoch:120/200 AVG Training Loss:0.658 AVG Validation Loss:0.658 AVG Training Acc 62.07 % AVG Validation Acc 61.91 %\n",
      "Epoch:130/200 AVG Training Loss:0.659 AVG Validation Loss:0.657 AVG Training Acc 62.06 % AVG Validation Acc 62.09 %\n",
      "Epoch   134: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.659 AVG Validation Loss:0.659 AVG Training Acc 61.95 % AVG Validation Acc 62.00 %\n",
      "Epoch:150/200 AVG Training Loss:0.659 AVG Validation Loss:0.659 AVG Training Acc 61.96 % AVG Validation Acc 62.09 %\n",
      "Epoch:160/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 62.03 % AVG Validation Acc 62.00 %\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 62.07 % AVG Validation Acc 62.00 %\n",
      "Epoch:180/200 AVG Training Loss:0.659 AVG Validation Loss:0.659 AVG Training Acc 62.09 % AVG Validation Acc 62.00 %\n",
      "Epoch:190/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 62.03 % AVG Validation Acc 62.00 %\n",
      "Epoch   196: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.658 AVG Validation Loss:0.658 AVG Training Acc 62.08 % AVG Validation Acc 61.82 %\n",
      "Split 37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2c42215418a4c04801c8beb4a4a94e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.658 AVG Training Acc 61.69 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.658 AVG Training Acc 61.84 % AVG Validation Acc 61.19 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.639 AVG Validation Loss:0.659 AVG Training Acc 62.75 % AVG Validation Acc 61.82 %\n",
      "Epoch:40/200 AVG Training Loss:0.631 AVG Validation Loss:0.662 AVG Training Acc 63.90 % AVG Validation Acc 61.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.621 AVG Validation Loss:0.665 AVG Training Acc 64.30 % AVG Validation Acc 61.19 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.613 AVG Validation Loss:0.673 AVG Training Acc 65.37 % AVG Validation Acc 60.29 %\n",
      "Epoch:70/200 AVG Training Loss:0.609 AVG Validation Loss:0.676 AVG Training Acc 65.41 % AVG Validation Acc 60.11 %\n",
      "Epoch:80/200 AVG Training Loss:0.606 AVG Validation Loss:0.675 AVG Training Acc 65.82 % AVG Validation Acc 60.65 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.610 AVG Validation Loss:0.677 AVG Training Acc 65.56 % AVG Validation Acc 60.56 %\n",
      "Epoch:100/200 AVG Training Loss:0.607 AVG Validation Loss:0.678 AVG Training Acc 65.77 % AVG Validation Acc 60.74 %\n",
      "Epoch:110/200 AVG Training Loss:0.609 AVG Validation Loss:0.681 AVG Training Acc 65.75 % AVG Validation Acc 60.02 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.607 AVG Validation Loss:0.678 AVG Training Acc 65.60 % AVG Validation Acc 60.74 %\n",
      "Epoch:130/200 AVG Training Loss:0.607 AVG Validation Loss:0.677 AVG Training Acc 65.44 % AVG Validation Acc 60.38 %\n",
      "Epoch:140/200 AVG Training Loss:0.606 AVG Validation Loss:0.677 AVG Training Acc 65.47 % AVG Validation Acc 60.83 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.606 AVG Validation Loss:0.677 AVG Training Acc 65.47 % AVG Validation Acc 60.83 %\n",
      "Epoch:160/200 AVG Training Loss:0.607 AVG Validation Loss:0.677 AVG Training Acc 65.60 % AVG Validation Acc 60.47 %\n",
      "Epoch:170/200 AVG Training Loss:0.609 AVG Validation Loss:0.678 AVG Training Acc 64.90 % AVG Validation Acc 60.47 %\n",
      "Epoch:180/200 AVG Training Loss:0.607 AVG Validation Loss:0.677 AVG Training Acc 65.55 % AVG Validation Acc 60.38 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.606 AVG Validation Loss:0.674 AVG Training Acc 65.50 % AVG Validation Acc 60.29 %\n",
      "Epoch:200/200 AVG Training Loss:0.606 AVG Validation Loss:0.677 AVG Training Acc 65.78 % AVG Validation Acc 60.92 %\n",
      "Split 38\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d4f178a5ce44857b7f3ad3e9c366dec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.659 AVG Training Acc 61.84 % AVG Validation Acc 61.82 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.655 AVG Training Acc 62.20 % AVG Validation Acc 62.45 %\n",
      "Epoch:30/200 AVG Training Loss:0.651 AVG Validation Loss:0.652 AVG Training Acc 61.80 % AVG Validation Acc 62.18 %\n",
      "Epoch:40/200 AVG Training Loss:0.648 AVG Validation Loss:0.654 AVG Training Acc 61.95 % AVG Validation Acc 62.09 %\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.630 AVG Validation Loss:0.657 AVG Training Acc 62.97 % AVG Validation Acc 62.18 %\n",
      "Epoch:60/200 AVG Training Loss:0.623 AVG Validation Loss:0.661 AVG Training Acc 64.19 % AVG Validation Acc 60.65 %\n",
      "Epoch:70/200 AVG Training Loss:0.615 AVG Validation Loss:0.666 AVG Training Acc 64.20 % AVG Validation Acc 59.84 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.612 AVG Validation Loss:0.666 AVG Training Acc 65.24 % AVG Validation Acc 60.38 %\n",
      "Epoch:90/200 AVG Training Loss:0.611 AVG Validation Loss:0.664 AVG Training Acc 65.00 % AVG Validation Acc 60.29 %\n",
      "Epoch:100/200 AVG Training Loss:0.609 AVG Validation Loss:0.664 AVG Training Acc 65.30 % AVG Validation Acc 59.93 %\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.608 AVG Validation Loss:0.667 AVG Training Acc 65.65 % AVG Validation Acc 59.93 %\n",
      "Epoch:120/200 AVG Training Loss:0.608 AVG Validation Loss:0.665 AVG Training Acc 65.19 % AVG Validation Acc 59.93 %\n",
      "Epoch:130/200 AVG Training Loss:0.609 AVG Validation Loss:0.668 AVG Training Acc 65.36 % AVG Validation Acc 59.48 %\n",
      "Epoch   134: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.610 AVG Validation Loss:0.667 AVG Training Acc 65.06 % AVG Validation Acc 60.29 %\n",
      "Epoch:150/200 AVG Training Loss:0.608 AVG Validation Loss:0.664 AVG Training Acc 65.32 % AVG Validation Acc 60.38 %\n",
      "Epoch:160/200 AVG Training Loss:0.610 AVG Validation Loss:0.666 AVG Training Acc 65.11 % AVG Validation Acc 60.20 %\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.610 AVG Validation Loss:0.666 AVG Training Acc 64.58 % AVG Validation Acc 59.84 %\n",
      "Epoch:180/200 AVG Training Loss:0.608 AVG Validation Loss:0.666 AVG Training Acc 65.13 % AVG Validation Acc 60.11 %\n",
      "Epoch:190/200 AVG Training Loss:0.608 AVG Validation Loss:0.667 AVG Training Acc 65.49 % AVG Validation Acc 60.02 %\n",
      "Epoch   196: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.609 AVG Validation Loss:0.666 AVG Training Acc 65.32 % AVG Validation Acc 60.29 %\n",
      "Split 39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0363a71e0cf64a848604df04077507b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.659 AVG Training Acc 61.76 % AVG Validation Acc 61.82 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.662 AVG Training Acc 61.93 % AVG Validation Acc 62.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.649 AVG Validation Loss:0.649 AVG Training Acc 61.98 % AVG Validation Acc 63.27 %\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.637 AVG Validation Loss:0.663 AVG Training Acc 62.68 % AVG Validation Acc 63.09 %\n",
      "Epoch:50/200 AVG Training Loss:0.618 AVG Validation Loss:0.675 AVG Training Acc 63.95 % AVG Validation Acc 63.36 %\n",
      "Epoch:60/200 AVG Training Loss:0.609 AVG Validation Loss:0.685 AVG Training Acc 64.16 % AVG Validation Acc 62.27 %\n",
      "Epoch:70/200 AVG Training Loss:0.602 AVG Validation Loss:0.688 AVG Training Acc 65.10 % AVG Validation Acc 63.27 %\n",
      "Epoch    70: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.599 AVG Validation Loss:0.696 AVG Training Acc 65.24 % AVG Validation Acc 63.09 %\n",
      "Epoch:90/200 AVG Training Loss:0.598 AVG Validation Loss:0.698 AVG Training Acc 65.09 % AVG Validation Acc 62.55 %\n",
      "Epoch:100/200 AVG Training Loss:0.597 AVG Validation Loss:0.697 AVG Training Acc 65.26 % AVG Validation Acc 63.18 %\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.593 AVG Validation Loss:0.702 AVG Training Acc 65.34 % AVG Validation Acc 62.09 %\n",
      "Epoch:120/200 AVG Training Loss:0.596 AVG Validation Loss:0.709 AVG Training Acc 65.07 % AVG Validation Acc 62.64 %\n",
      "Epoch:130/200 AVG Training Loss:0.594 AVG Validation Loss:0.703 AVG Training Acc 65.57 % AVG Validation Acc 62.91 %\n",
      "Epoch   132: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.595 AVG Validation Loss:0.700 AVG Training Acc 65.71 % AVG Validation Acc 62.73 %\n",
      "Epoch:150/200 AVG Training Loss:0.595 AVG Validation Loss:0.703 AVG Training Acc 65.44 % AVG Validation Acc 62.55 %\n",
      "Epoch:160/200 AVG Training Loss:0.593 AVG Validation Loss:0.701 AVG Training Acc 66.15 % AVG Validation Acc 63.18 %\n",
      "Epoch   163: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.594 AVG Validation Loss:0.698 AVG Training Acc 65.72 % AVG Validation Acc 62.64 %\n",
      "Epoch:180/200 AVG Training Loss:0.593 AVG Validation Loss:0.707 AVG Training Acc 65.30 % AVG Validation Acc 62.73 %\n",
      "Epoch:190/200 AVG Training Loss:0.591 AVG Validation Loss:0.699 AVG Training Acc 65.71 % AVG Validation Acc 62.36 %\n",
      "Epoch   194: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.594 AVG Validation Loss:0.707 AVG Training Acc 65.70 % AVG Validation Acc 62.36 %\n",
      "Split 40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11b5b2bb723c410e9da3e530c8d0359f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.659 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.658 AVG Training Acc 61.79 % AVG Validation Acc 61.82 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.638 AVG Validation Loss:0.665 AVG Training Acc 62.55 % AVG Validation Acc 61.28 %\n",
      "Epoch:40/200 AVG Training Loss:0.621 AVG Validation Loss:0.673 AVG Training Acc 64.43 % AVG Validation Acc 61.19 %\n",
      "Epoch:50/200 AVG Training Loss:0.612 AVG Validation Loss:0.687 AVG Training Acc 64.95 % AVG Validation Acc 59.48 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.602 AVG Validation Loss:0.692 AVG Training Acc 66.04 % AVG Validation Acc 61.37 %\n",
      "Epoch:70/200 AVG Training Loss:0.597 AVG Validation Loss:0.695 AVG Training Acc 66.40 % AVG Validation Acc 60.47 %\n",
      "Epoch:80/200 AVG Training Loss:0.594 AVG Validation Loss:0.697 AVG Training Acc 65.98 % AVG Validation Acc 60.83 %\n",
      "Epoch:90/200 AVG Training Loss:0.595 AVG Validation Loss:0.699 AVG Training Acc 65.95 % AVG Validation Acc 60.38 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.594 AVG Validation Loss:0.694 AVG Training Acc 66.14 % AVG Validation Acc 59.75 %\n",
      "Epoch:110/200 AVG Training Loss:0.594 AVG Validation Loss:0.703 AVG Training Acc 66.80 % AVG Validation Acc 59.66 %\n",
      "Epoch:120/200 AVG Training Loss:0.596 AVG Validation Loss:0.698 AVG Training Acc 66.18 % AVG Validation Acc 60.47 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.594 AVG Validation Loss:0.698 AVG Training Acc 66.46 % AVG Validation Acc 60.02 %\n",
      "Epoch:140/200 AVG Training Loss:0.593 AVG Validation Loss:0.697 AVG Training Acc 66.48 % AVG Validation Acc 60.74 %\n",
      "Epoch:150/200 AVG Training Loss:0.593 AVG Validation Loss:0.690 AVG Training Acc 66.58 % AVG Validation Acc 60.47 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.594 AVG Validation Loss:0.705 AVG Training Acc 66.49 % AVG Validation Acc 59.21 %\n",
      "Epoch:170/200 AVG Training Loss:0.595 AVG Validation Loss:0.703 AVG Training Acc 66.41 % AVG Validation Acc 60.83 %\n",
      "Epoch:180/200 AVG Training Loss:0.593 AVG Validation Loss:0.694 AVG Training Acc 66.64 % AVG Validation Acc 60.02 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.592 AVG Validation Loss:0.700 AVG Training Acc 66.67 % AVG Validation Acc 59.66 %\n",
      "Epoch:200/200 AVG Training Loss:0.593 AVG Validation Loss:0.694 AVG Training Acc 66.22 % AVG Validation Acc 60.56 %\n",
      "Split 41\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "41c2fbccf9f24850b0ee9d8ae5fd5697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.658 AVG Training Acc 61.92 % AVG Validation Acc 62.04 %\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:0.659 AVG Training Acc 61.90 % AVG Validation Acc 62.04 %\n",
      "Epoch:30/200 AVG Training Loss:0.650 AVG Validation Loss:0.657 AVG Training Acc 62.16 % AVG Validation Acc 61.95 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.634 AVG Validation Loss:0.658 AVG Training Acc 62.98 % AVG Validation Acc 62.04 %\n",
      "Epoch:50/200 AVG Training Loss:0.630 AVG Validation Loss:0.657 AVG Training Acc 63.14 % AVG Validation Acc 62.31 %\n",
      "Epoch:60/200 AVG Training Loss:0.624 AVG Validation Loss:0.657 AVG Training Acc 63.60 % AVG Validation Acc 62.94 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.618 AVG Validation Loss:0.665 AVG Training Acc 64.05 % AVG Validation Acc 62.31 %\n",
      "Epoch:80/200 AVG Training Loss:0.616 AVG Validation Loss:0.664 AVG Training Acc 64.34 % AVG Validation Acc 62.04 %\n",
      "Epoch:90/200 AVG Training Loss:0.616 AVG Validation Loss:0.670 AVG Training Acc 64.36 % AVG Validation Acc 61.50 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.617 AVG Validation Loss:0.669 AVG Training Acc 64.36 % AVG Validation Acc 62.13 %\n",
      "Epoch:110/200 AVG Training Loss:0.614 AVG Validation Loss:0.669 AVG Training Acc 65.00 % AVG Validation Acc 61.77 %\n",
      "Epoch:120/200 AVG Training Loss:0.613 AVG Validation Loss:0.675 AVG Training Acc 65.01 % AVG Validation Acc 61.59 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.613 AVG Validation Loss:0.668 AVG Training Acc 64.61 % AVG Validation Acc 61.86 %\n",
      "Epoch:140/200 AVG Training Loss:0.614 AVG Validation Loss:0.665 AVG Training Acc 64.09 % AVG Validation Acc 62.13 %\n",
      "Epoch:150/200 AVG Training Loss:0.613 AVG Validation Loss:0.668 AVG Training Acc 64.33 % AVG Validation Acc 62.13 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.612 AVG Validation Loss:0.670 AVG Training Acc 64.41 % AVG Validation Acc 62.31 %\n",
      "Epoch:170/200 AVG Training Loss:0.614 AVG Validation Loss:0.669 AVG Training Acc 64.64 % AVG Validation Acc 61.59 %\n",
      "Epoch:180/200 AVG Training Loss:0.615 AVG Validation Loss:0.672 AVG Training Acc 64.30 % AVG Validation Acc 62.22 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.615 AVG Validation Loss:0.668 AVG Training Acc 64.03 % AVG Validation Acc 61.50 %\n",
      "Epoch:200/200 AVG Training Loss:0.614 AVG Validation Loss:0.667 AVG Training Acc 64.94 % AVG Validation Acc 62.13 %\n",
      "Split 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00cf01b3ecde4263a1debc7c83d7603a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.655 AVG Training Acc 61.76 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.657 AVG Training Acc 61.96 % AVG Validation Acc 61.77 %\n",
      "Epoch:30/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 61.80 % AVG Validation Acc 62.13 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.627 AVG Validation Loss:0.662 AVG Training Acc 63.37 % AVG Validation Acc 62.58 %\n",
      "Epoch:50/200 AVG Training Loss:0.616 AVG Validation Loss:0.679 AVG Training Acc 63.67 % AVG Validation Acc 63.30 %\n",
      "Epoch:60/200 AVG Training Loss:0.608 AVG Validation Loss:0.700 AVG Training Acc 64.19 % AVG Validation Acc 63.03 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.603 AVG Validation Loss:0.705 AVG Training Acc 64.42 % AVG Validation Acc 62.22 %\n",
      "Epoch:80/200 AVG Training Loss:0.603 AVG Validation Loss:0.704 AVG Training Acc 63.90 % AVG Validation Acc 62.49 %\n",
      "Epoch:90/200 AVG Training Loss:0.601 AVG Validation Loss:0.693 AVG Training Acc 64.78 % AVG Validation Acc 62.40 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.600 AVG Validation Loss:0.717 AVG Training Acc 64.24 % AVG Validation Acc 62.13 %\n",
      "Epoch:110/200 AVG Training Loss:0.597 AVG Validation Loss:0.717 AVG Training Acc 64.44 % AVG Validation Acc 62.13 %\n",
      "Epoch:120/200 AVG Training Loss:0.599 AVG Validation Loss:0.702 AVG Training Acc 64.37 % AVG Validation Acc 62.40 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.599 AVG Validation Loss:0.717 AVG Training Acc 64.52 % AVG Validation Acc 62.04 %\n",
      "Epoch:140/200 AVG Training Loss:0.598 AVG Validation Loss:0.719 AVG Training Acc 64.74 % AVG Validation Acc 62.22 %\n",
      "Epoch:150/200 AVG Training Loss:0.601 AVG Validation Loss:0.714 AVG Training Acc 64.50 % AVG Validation Acc 62.76 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.599 AVG Validation Loss:0.705 AVG Training Acc 64.76 % AVG Validation Acc 62.31 %\n",
      "Epoch:170/200 AVG Training Loss:0.597 AVG Validation Loss:0.700 AVG Training Acc 64.85 % AVG Validation Acc 62.67 %\n",
      "Epoch:180/200 AVG Training Loss:0.599 AVG Validation Loss:0.714 AVG Training Acc 64.82 % AVG Validation Acc 62.13 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.599 AVG Validation Loss:0.713 AVG Training Acc 64.48 % AVG Validation Acc 62.67 %\n",
      "Epoch:200/200 AVG Training Loss:0.599 AVG Validation Loss:0.707 AVG Training Acc 64.35 % AVG Validation Acc 62.40 %\n",
      "Split 43\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c9bfcfb2edc4d499d00b369aa7551d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 61.92 % AVG Validation Acc 61.32 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.661 AVG Training Acc 61.99 % AVG Validation Acc 60.69 %\n",
      "Epoch:30/200 AVG Training Loss:0.648 AVG Validation Loss:0.661 AVG Training Acc 62.06 % AVG Validation Acc 61.23 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.625 AVG Validation Loss:0.671 AVG Training Acc 63.26 % AVG Validation Acc 61.23 %\n",
      "Epoch:50/200 AVG Training Loss:0.615 AVG Validation Loss:0.676 AVG Training Acc 64.43 % AVG Validation Acc 60.50 %\n",
      "Epoch:60/200 AVG Training Loss:0.605 AVG Validation Loss:0.681 AVG Training Acc 65.00 % AVG Validation Acc 59.60 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.597 AVG Validation Loss:0.693 AVG Training Acc 65.65 % AVG Validation Acc 59.78 %\n",
      "Epoch:80/200 AVG Training Loss:0.595 AVG Validation Loss:0.694 AVG Training Acc 65.24 % AVG Validation Acc 60.05 %\n",
      "Epoch:90/200 AVG Training Loss:0.594 AVG Validation Loss:0.698 AVG Training Acc 65.94 % AVG Validation Acc 60.41 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.594 AVG Validation Loss:0.699 AVG Training Acc 65.74 % AVG Validation Acc 60.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.593 AVG Validation Loss:0.696 AVG Training Acc 65.95 % AVG Validation Acc 60.41 %\n",
      "Epoch:120/200 AVG Training Loss:0.594 AVG Validation Loss:0.699 AVG Training Acc 66.09 % AVG Validation Acc 59.87 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.592 AVG Validation Loss:0.690 AVG Training Acc 66.17 % AVG Validation Acc 60.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.593 AVG Validation Loss:0.699 AVG Training Acc 65.67 % AVG Validation Acc 60.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.594 AVG Validation Loss:0.696 AVG Training Acc 66.19 % AVG Validation Acc 60.50 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.592 AVG Validation Loss:0.695 AVG Training Acc 65.91 % AVG Validation Acc 60.60 %\n",
      "Epoch:170/200 AVG Training Loss:0.593 AVG Validation Loss:0.690 AVG Training Acc 65.47 % AVG Validation Acc 60.87 %\n",
      "Epoch:180/200 AVG Training Loss:0.592 AVG Validation Loss:0.698 AVG Training Acc 65.74 % AVG Validation Acc 60.23 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.592 AVG Validation Loss:0.697 AVG Training Acc 66.18 % AVG Validation Acc 61.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.593 AVG Validation Loss:0.702 AVG Training Acc 65.99 % AVG Validation Acc 60.05 %\n",
      "Split 44\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e0fb5b930a7482ca9d5daf0533079d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.656 AVG Training Acc 61.86 % AVG Validation Acc 61.68 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.646 AVG Validation Loss:0.660 AVG Training Acc 62.58 % AVG Validation Acc 60.78 %\n",
      "Epoch:30/200 AVG Training Loss:0.637 AVG Validation Loss:0.661 AVG Training Acc 62.63 % AVG Validation Acc 61.32 %\n",
      "Epoch:40/200 AVG Training Loss:0.628 AVG Validation Loss:0.668 AVG Training Acc 63.18 % AVG Validation Acc 60.87 %\n",
      "Epoch:50/200 AVG Training Loss:0.622 AVG Validation Loss:0.676 AVG Training Acc 63.69 % AVG Validation Acc 59.78 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.617 AVG Validation Loss:0.684 AVG Training Acc 64.23 % AVG Validation Acc 60.32 %\n",
      "Epoch:70/200 AVG Training Loss:0.617 AVG Validation Loss:0.680 AVG Training Acc 64.34 % AVG Validation Acc 60.69 %\n",
      "Epoch:80/200 AVG Training Loss:0.615 AVG Validation Loss:0.678 AVG Training Acc 63.87 % AVG Validation Acc 60.32 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.616 AVG Validation Loss:0.684 AVG Training Acc 64.05 % AVG Validation Acc 60.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.615 AVG Validation Loss:0.681 AVG Training Acc 64.09 % AVG Validation Acc 60.32 %\n",
      "Epoch:110/200 AVG Training Loss:0.616 AVG Validation Loss:0.681 AVG Training Acc 64.11 % AVG Validation Acc 60.05 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.615 AVG Validation Loss:0.684 AVG Training Acc 64.49 % AVG Validation Acc 60.23 %\n",
      "Epoch:130/200 AVG Training Loss:0.616 AVG Validation Loss:0.685 AVG Training Acc 63.80 % AVG Validation Acc 60.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.615 AVG Validation Loss:0.682 AVG Training Acc 64.64 % AVG Validation Acc 60.23 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.615 AVG Validation Loss:0.679 AVG Training Acc 64.23 % AVG Validation Acc 60.69 %\n",
      "Epoch:160/200 AVG Training Loss:0.615 AVG Validation Loss:0.684 AVG Training Acc 64.00 % AVG Validation Acc 60.41 %\n",
      "Epoch:170/200 AVG Training Loss:0.615 AVG Validation Loss:0.684 AVG Training Acc 63.75 % AVG Validation Acc 60.41 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.616 AVG Validation Loss:0.681 AVG Training Acc 64.33 % AVG Validation Acc 60.32 %\n",
      "Epoch:190/200 AVG Training Loss:0.614 AVG Validation Loss:0.684 AVG Training Acc 64.37 % AVG Validation Acc 60.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.615 AVG Validation Loss:0.682 AVG Training Acc 64.48 % AVG Validation Acc 60.41 %\n",
      "Split 45\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "322bb22555144eb49bf200c7aabfb4fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.656 AVG Training Acc 61.82 % AVG Validation Acc 61.68 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.658 AVG Training Acc 61.84 % AVG Validation Acc 61.50 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.645 AVG Validation Loss:0.661 AVG Training Acc 62.48 % AVG Validation Acc 60.69 %\n",
      "Epoch:40/200 AVG Training Loss:0.641 AVG Validation Loss:0.661 AVG Training Acc 62.57 % AVG Validation Acc 60.96 %\n",
      "Epoch:50/200 AVG Training Loss:0.638 AVG Validation Loss:0.663 AVG Training Acc 63.29 % AVG Validation Acc 60.87 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.634 AVG Validation Loss:0.664 AVG Training Acc 63.40 % AVG Validation Acc 61.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.632 AVG Validation Loss:0.666 AVG Training Acc 63.67 % AVG Validation Acc 60.69 %\n",
      "Epoch:80/200 AVG Training Loss:0.632 AVG Validation Loss:0.667 AVG Training Acc 63.37 % AVG Validation Acc 60.69 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.630 AVG Validation Loss:0.668 AVG Training Acc 63.26 % AVG Validation Acc 60.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.630 AVG Validation Loss:0.669 AVG Training Acc 63.83 % AVG Validation Acc 60.96 %\n",
      "Epoch:110/200 AVG Training Loss:0.632 AVG Validation Loss:0.668 AVG Training Acc 63.68 % AVG Validation Acc 61.14 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.630 AVG Validation Loss:0.669 AVG Training Acc 64.20 % AVG Validation Acc 60.60 %\n",
      "Epoch:130/200 AVG Training Loss:0.630 AVG Validation Loss:0.668 AVG Training Acc 64.06 % AVG Validation Acc 60.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.630 AVG Validation Loss:0.669 AVG Training Acc 63.97 % AVG Validation Acc 60.69 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.630 AVG Validation Loss:0.668 AVG Training Acc 63.83 % AVG Validation Acc 60.50 %\n",
      "Epoch:160/200 AVG Training Loss:0.631 AVG Validation Loss:0.666 AVG Training Acc 63.49 % AVG Validation Acc 60.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.632 AVG Validation Loss:0.668 AVG Training Acc 63.53 % AVG Validation Acc 60.87 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.631 AVG Validation Loss:0.669 AVG Training Acc 63.89 % AVG Validation Acc 60.50 %\n",
      "Epoch:190/200 AVG Training Loss:0.630 AVG Validation Loss:0.668 AVG Training Acc 64.07 % AVG Validation Acc 60.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.629 AVG Validation Loss:0.669 AVG Training Acc 63.82 % AVG Validation Acc 60.50 %\n",
      "Split 46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d822cf0d50bb4b3e8ad92e1d336b3f88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 62.01 % AVG Validation Acc 62.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.650 AVG Validation Loss:0.658 AVG Training Acc 61.77 % AVG Validation Acc 62.00 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.623 AVG Validation Loss:0.670 AVG Training Acc 63.64 % AVG Validation Acc 62.09 %\n",
      "Epoch:40/200 AVG Training Loss:0.605 AVG Validation Loss:0.678 AVG Training Acc 65.23 % AVG Validation Acc 62.82 %\n",
      "Epoch:50/200 AVG Training Loss:0.594 AVG Validation Loss:0.689 AVG Training Acc 65.69 % AVG Validation Acc 61.46 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.585 AVG Validation Loss:0.715 AVG Training Acc 66.56 % AVG Validation Acc 61.64 %\n",
      "Epoch:70/200 AVG Training Loss:0.579 AVG Validation Loss:0.708 AVG Training Acc 67.07 % AVG Validation Acc 61.19 %\n",
      "Epoch:80/200 AVG Training Loss:0.577 AVG Validation Loss:0.718 AVG Training Acc 66.80 % AVG Validation Acc 61.37 %\n",
      "Epoch:90/200 AVG Training Loss:0.576 AVG Validation Loss:0.725 AVG Training Acc 67.26 % AVG Validation Acc 61.73 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.577 AVG Validation Loss:0.716 AVG Training Acc 66.90 % AVG Validation Acc 61.10 %\n",
      "Epoch:110/200 AVG Training Loss:0.574 AVG Validation Loss:0.725 AVG Training Acc 67.11 % AVG Validation Acc 61.01 %\n",
      "Epoch:120/200 AVG Training Loss:0.576 AVG Validation Loss:0.720 AVG Training Acc 66.85 % AVG Validation Acc 60.92 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.574 AVG Validation Loss:0.718 AVG Training Acc 67.19 % AVG Validation Acc 61.28 %\n",
      "Epoch:140/200 AVG Training Loss:0.575 AVG Validation Loss:0.713 AVG Training Acc 67.08 % AVG Validation Acc 61.82 %\n",
      "Epoch:150/200 AVG Training Loss:0.572 AVG Validation Loss:0.717 AVG Training Acc 67.35 % AVG Validation Acc 61.10 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.573 AVG Validation Loss:0.721 AVG Training Acc 67.33 % AVG Validation Acc 61.01 %\n",
      "Epoch:170/200 AVG Training Loss:0.576 AVG Validation Loss:0.722 AVG Training Acc 66.93 % AVG Validation Acc 60.92 %\n",
      "Epoch:180/200 AVG Training Loss:0.576 AVG Validation Loss:0.720 AVG Training Acc 67.10 % AVG Validation Acc 60.74 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.575 AVG Validation Loss:0.724 AVG Training Acc 67.30 % AVG Validation Acc 61.64 %\n",
      "Epoch:200/200 AVG Training Loss:0.574 AVG Validation Loss:0.722 AVG Training Acc 67.17 % AVG Validation Acc 61.19 %\n",
      "Split 47\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384319d05a174c71bb764c1450220b27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.656 AVG Training Acc 61.68 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.650 AVG Validation Loss:0.651 AVG Training Acc 62.05 % AVG Validation Acc 62.00 %\n",
      "Epoch:30/200 AVG Training Loss:0.639 AVG Validation Loss:0.648 AVG Training Acc 62.82 % AVG Validation Acc 61.73 %\n",
      "Epoch:40/200 AVG Training Loss:0.637 AVG Validation Loss:0.654 AVG Training Acc 63.03 % AVG Validation Acc 61.55 %\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.612 AVG Validation Loss:0.664 AVG Training Acc 66.06 % AVG Validation Acc 61.19 %\n",
      "Epoch:60/200 AVG Training Loss:0.598 AVG Validation Loss:0.672 AVG Training Acc 66.72 % AVG Validation Acc 60.74 %\n",
      "Epoch:70/200 AVG Training Loss:0.584 AVG Validation Loss:0.682 AVG Training Acc 67.93 % AVG Validation Acc 61.10 %\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.577 AVG Validation Loss:0.689 AVG Training Acc 68.72 % AVG Validation Acc 60.02 %\n",
      "Epoch:90/200 AVG Training Loss:0.576 AVG Validation Loss:0.691 AVG Training Acc 68.34 % AVG Validation Acc 60.56 %\n",
      "Epoch:100/200 AVG Training Loss:0.571 AVG Validation Loss:0.701 AVG Training Acc 68.48 % AVG Validation Acc 59.57 %\n",
      "Epoch   106: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.570 AVG Validation Loss:0.694 AVG Training Acc 68.51 % AVG Validation Acc 59.66 %\n",
      "Epoch:120/200 AVG Training Loss:0.572 AVG Validation Loss:0.690 AVG Training Acc 68.32 % AVG Validation Acc 60.56 %\n",
      "Epoch:130/200 AVG Training Loss:0.573 AVG Validation Loss:0.701 AVG Training Acc 68.45 % AVG Validation Acc 61.19 %\n",
      "Epoch   137: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.570 AVG Validation Loss:0.699 AVG Training Acc 68.74 % AVG Validation Acc 59.75 %\n",
      "Epoch:150/200 AVG Training Loss:0.571 AVG Validation Loss:0.698 AVG Training Acc 68.69 % AVG Validation Acc 59.93 %\n",
      "Epoch:160/200 AVG Training Loss:0.571 AVG Validation Loss:0.693 AVG Training Acc 68.57 % AVG Validation Acc 59.66 %\n",
      "Epoch   168: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.573 AVG Validation Loss:0.695 AVG Training Acc 68.01 % AVG Validation Acc 60.02 %\n",
      "Epoch:180/200 AVG Training Loss:0.571 AVG Validation Loss:0.695 AVG Training Acc 68.40 % AVG Validation Acc 59.93 %\n",
      "Epoch:190/200 AVG Training Loss:0.569 AVG Validation Loss:0.697 AVG Training Acc 68.46 % AVG Validation Acc 59.75 %\n",
      "Epoch   199: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.570 AVG Validation Loss:0.697 AVG Training Acc 68.74 % AVG Validation Acc 60.47 %\n",
      "Split 48\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "789e3f8d26fd4c59bfe09af5c67d65e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.657 AVG Training Acc 61.85 % AVG Validation Acc 61.73 %\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.656 AVG Training Acc 61.89 % AVG Validation Acc 62.09 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.638 AVG Validation Loss:0.659 AVG Training Acc 63.06 % AVG Validation Acc 61.19 %\n",
      "Epoch:40/200 AVG Training Loss:0.632 AVG Validation Loss:0.667 AVG Training Acc 63.00 % AVG Validation Acc 60.47 %\n",
      "Epoch:50/200 AVG Training Loss:0.623 AVG Validation Loss:0.676 AVG Training Acc 63.86 % AVG Validation Acc 59.57 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.620 AVG Validation Loss:0.682 AVG Training Acc 64.06 % AVG Validation Acc 60.47 %\n",
      "Epoch:70/200 AVG Training Loss:0.617 AVG Validation Loss:0.683 AVG Training Acc 64.15 % AVG Validation Acc 60.20 %\n",
      "Epoch:80/200 AVG Training Loss:0.616 AVG Validation Loss:0.683 AVG Training Acc 64.57 % AVG Validation Acc 60.20 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.615 AVG Validation Loss:0.685 AVG Training Acc 64.40 % AVG Validation Acc 60.29 %\n",
      "Epoch:100/200 AVG Training Loss:0.615 AVG Validation Loss:0.687 AVG Training Acc 64.54 % AVG Validation Acc 60.11 %\n",
      "Epoch:110/200 AVG Training Loss:0.614 AVG Validation Loss:0.686 AVG Training Acc 64.59 % AVG Validation Acc 60.65 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.614 AVG Validation Loss:0.686 AVG Training Acc 64.64 % AVG Validation Acc 60.47 %\n",
      "Epoch:130/200 AVG Training Loss:0.616 AVG Validation Loss:0.685 AVG Training Acc 64.69 % AVG Validation Acc 60.02 %\n",
      "Epoch:140/200 AVG Training Loss:0.614 AVG Validation Loss:0.682 AVG Training Acc 64.72 % AVG Validation Acc 60.38 %\n",
      "Epoch:150/200 AVG Training Loss:0.616 AVG Validation Loss:0.684 AVG Training Acc 64.29 % AVG Validation Acc 60.38 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.614 AVG Validation Loss:0.686 AVG Training Acc 64.64 % AVG Validation Acc 60.11 %\n",
      "Epoch:170/200 AVG Training Loss:0.612 AVG Validation Loss:0.686 AVG Training Acc 65.01 % AVG Validation Acc 60.47 %\n",
      "Epoch:180/200 AVG Training Loss:0.613 AVG Validation Loss:0.685 AVG Training Acc 64.55 % AVG Validation Acc 60.29 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.614 AVG Validation Loss:0.685 AVG Training Acc 64.51 % AVG Validation Acc 60.47 %\n",
      "Epoch:200/200 AVG Training Loss:0.615 AVG Validation Loss:0.686 AVG Training Acc 64.58 % AVG Validation Acc 60.29 %\n",
      "Split 49\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13f0b8172164bd7a1bcd4daf27fb4ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.660 AVG Training Acc 61.84 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.657 AVG Training Acc 61.71 % AVG Validation Acc 62.55 %\n",
      "Epoch:30/200 AVG Training Loss:0.645 AVG Validation Loss:0.659 AVG Training Acc 61.98 % AVG Validation Acc 62.45 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.618 AVG Validation Loss:0.678 AVG Training Acc 64.27 % AVG Validation Acc 62.55 %\n",
      "Epoch:50/200 AVG Training Loss:0.605 AVG Validation Loss:0.699 AVG Training Acc 64.36 % AVG Validation Acc 60.74 %\n",
      "Epoch:60/200 AVG Training Loss:0.595 AVG Validation Loss:0.713 AVG Training Acc 65.47 % AVG Validation Acc 60.29 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.586 AVG Validation Loss:0.714 AVG Training Acc 66.04 % AVG Validation Acc 60.38 %\n",
      "Epoch:80/200 AVG Training Loss:0.585 AVG Validation Loss:0.725 AVG Training Acc 66.30 % AVG Validation Acc 60.38 %\n",
      "Epoch:90/200 AVG Training Loss:0.583 AVG Validation Loss:0.730 AVG Training Acc 65.89 % AVG Validation Acc 60.11 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.583 AVG Validation Loss:0.731 AVG Training Acc 66.26 % AVG Validation Acc 60.20 %\n",
      "Epoch:110/200 AVG Training Loss:0.584 AVG Validation Loss:0.723 AVG Training Acc 66.20 % AVG Validation Acc 60.65 %\n",
      "Epoch:120/200 AVG Training Loss:0.583 AVG Validation Loss:0.725 AVG Training Acc 65.84 % AVG Validation Acc 60.20 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.582 AVG Validation Loss:0.731 AVG Training Acc 66.77 % AVG Validation Acc 59.57 %\n",
      "Epoch:140/200 AVG Training Loss:0.582 AVG Validation Loss:0.721 AVG Training Acc 66.49 % AVG Validation Acc 60.29 %\n",
      "Epoch:150/200 AVG Training Loss:0.584 AVG Validation Loss:0.731 AVG Training Acc 66.13 % AVG Validation Acc 59.12 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.582 AVG Validation Loss:0.728 AVG Training Acc 66.33 % AVG Validation Acc 60.29 %\n",
      "Epoch:170/200 AVG Training Loss:0.583 AVG Validation Loss:0.727 AVG Training Acc 65.83 % AVG Validation Acc 60.74 %\n",
      "Epoch:180/200 AVG Training Loss:0.583 AVG Validation Loss:0.731 AVG Training Acc 66.07 % AVG Validation Acc 60.29 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.582 AVG Validation Loss:0.726 AVG Training Acc 66.11 % AVG Validation Acc 60.29 %\n",
      "Epoch:200/200 AVG Training Loss:0.579 AVG Validation Loss:0.731 AVG Training Acc 66.26 % AVG Validation Acc 60.74 %\n",
      "Split 50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc40a8378a0e4b3ab224c3a1caaaccb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.657 AVG Validation Loss:0.658 AVG Training Acc 61.86 % AVG Validation Acc 61.82 %\n",
      "Epoch:20/200 AVG Training Loss:0.646 AVG Validation Loss:0.658 AVG Training Acc 62.22 % AVG Validation Acc 60.11 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.623 AVG Validation Loss:0.671 AVG Training Acc 63.55 % AVG Validation Acc 58.03 %\n",
      "Epoch:40/200 AVG Training Loss:0.608 AVG Validation Loss:0.692 AVG Training Acc 64.22 % AVG Validation Acc 56.77 %\n",
      "Epoch:50/200 AVG Training Loss:0.598 AVG Validation Loss:0.699 AVG Training Acc 65.16 % AVG Validation Acc 56.77 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.590 AVG Validation Loss:0.703 AVG Training Acc 65.36 % AVG Validation Acc 56.77 %\n",
      "Epoch:70/200 AVG Training Loss:0.587 AVG Validation Loss:0.707 AVG Training Acc 65.24 % AVG Validation Acc 56.68 %\n",
      "Epoch:80/200 AVG Training Loss:0.589 AVG Validation Loss:0.706 AVG Training Acc 65.33 % AVG Validation Acc 57.67 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.583 AVG Validation Loss:0.706 AVG Training Acc 65.50 % AVG Validation Acc 57.40 %\n",
      "Epoch:100/200 AVG Training Loss:0.583 AVG Validation Loss:0.708 AVG Training Acc 66.18 % AVG Validation Acc 56.86 %\n",
      "Epoch:110/200 AVG Training Loss:0.585 AVG Validation Loss:0.708 AVG Training Acc 65.95 % AVG Validation Acc 57.22 %\n",
      "Epoch:120/200 AVG Training Loss:0.584 AVG Validation Loss:0.707 AVG Training Acc 65.94 % AVG Validation Acc 57.22 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.582 AVG Validation Loss:0.709 AVG Training Acc 65.57 % AVG Validation Acc 56.77 %\n",
      "Epoch:140/200 AVG Training Loss:0.584 AVG Validation Loss:0.707 AVG Training Acc 65.66 % AVG Validation Acc 57.49 %\n",
      "Epoch:150/200 AVG Training Loss:0.582 AVG Validation Loss:0.709 AVG Training Acc 66.02 % AVG Validation Acc 57.04 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.582 AVG Validation Loss:0.707 AVG Training Acc 65.70 % AVG Validation Acc 57.58 %\n",
      "Epoch:170/200 AVG Training Loss:0.583 AVG Validation Loss:0.703 AVG Training Acc 65.78 % AVG Validation Acc 57.85 %\n",
      "Epoch:180/200 AVG Training Loss:0.583 AVG Validation Loss:0.710 AVG Training Acc 65.24 % AVG Validation Acc 57.13 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.583 AVG Validation Loss:0.710 AVG Training Acc 65.70 % AVG Validation Acc 57.67 %\n",
      "Epoch:200/200 AVG Training Loss:0.582 AVG Validation Loss:0.713 AVG Training Acc 65.77 % AVG Validation Acc 57.58 %\n",
      "Split 51\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43275694587f4d208705b623a6f51154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.660 AVG Training Acc 61.90 % AVG Validation Acc 61.59 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.661 AVG Training Acc 61.73 % AVG Validation Acc 61.50 %\n",
      "Epoch:30/200 AVG Training Loss:0.641 AVG Validation Loss:0.659 AVG Training Acc 62.35 % AVG Validation Acc 61.14 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.630 AVG Validation Loss:0.662 AVG Training Acc 63.11 % AVG Validation Acc 62.04 %\n",
      "Epoch:50/200 AVG Training Loss:0.613 AVG Validation Loss:0.677 AVG Training Acc 63.48 % AVG Validation Acc 61.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.598 AVG Validation Loss:0.695 AVG Training Acc 64.40 % AVG Validation Acc 60.78 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.593 AVG Validation Loss:0.696 AVG Training Acc 65.25 % AVG Validation Acc 60.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.591 AVG Validation Loss:0.707 AVG Training Acc 65.67 % AVG Validation Acc 60.60 %\n",
      "Epoch:90/200 AVG Training Loss:0.588 AVG Validation Loss:0.706 AVG Training Acc 65.36 % AVG Validation Acc 60.78 %\n",
      "Epoch:100/200 AVG Training Loss:0.587 AVG Validation Loss:0.708 AVG Training Acc 65.48 % AVG Validation Acc 60.60 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.586 AVG Validation Loss:0.709 AVG Training Acc 65.41 % AVG Validation Acc 60.50 %\n",
      "Epoch:120/200 AVG Training Loss:0.588 AVG Validation Loss:0.704 AVG Training Acc 65.64 % AVG Validation Acc 60.78 %\n",
      "Epoch:130/200 AVG Training Loss:0.586 AVG Validation Loss:0.708 AVG Training Acc 65.57 % AVG Validation Acc 60.60 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.585 AVG Validation Loss:0.709 AVG Training Acc 65.61 % AVG Validation Acc 60.87 %\n",
      "Epoch:150/200 AVG Training Loss:0.589 AVG Validation Loss:0.710 AVG Training Acc 65.19 % AVG Validation Acc 60.78 %\n",
      "Epoch:160/200 AVG Training Loss:0.584 AVG Validation Loss:0.712 AVG Training Acc 66.43 % AVG Validation Acc 60.32 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.586 AVG Validation Loss:0.708 AVG Training Acc 65.58 % AVG Validation Acc 60.50 %\n",
      "Epoch:180/200 AVG Training Loss:0.587 AVG Validation Loss:0.708 AVG Training Acc 65.05 % AVG Validation Acc 60.41 %\n",
      "Epoch:190/200 AVG Training Loss:0.586 AVG Validation Loss:0.713 AVG Training Acc 65.99 % AVG Validation Acc 60.69 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.586 AVG Validation Loss:0.708 AVG Training Acc 65.32 % AVG Validation Acc 60.69 %\n",
      "Split 52\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "641e378fee3344cfbd7f51e283862768",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.660 AVG Training Acc 61.77 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.660 AVG Training Acc 61.80 % AVG Validation Acc 61.86 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.646 AVG Validation Loss:0.659 AVG Training Acc 62.29 % AVG Validation Acc 60.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.634 AVG Validation Loss:0.664 AVG Training Acc 62.40 % AVG Validation Acc 62.04 %\n",
      "Epoch:50/200 AVG Training Loss:0.623 AVG Validation Loss:0.666 AVG Training Acc 63.92 % AVG Validation Acc 61.05 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.614 AVG Validation Loss:0.672 AVG Training Acc 64.87 % AVG Validation Acc 61.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.609 AVG Validation Loss:0.677 AVG Training Acc 65.49 % AVG Validation Acc 60.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.608 AVG Validation Loss:0.673 AVG Training Acc 65.28 % AVG Validation Acc 60.87 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.608 AVG Validation Loss:0.677 AVG Training Acc 65.45 % AVG Validation Acc 60.60 %\n",
      "Epoch:100/200 AVG Training Loss:0.607 AVG Validation Loss:0.676 AVG Training Acc 65.12 % AVG Validation Acc 61.68 %\n",
      "Epoch:110/200 AVG Training Loss:0.605 AVG Validation Loss:0.676 AVG Training Acc 65.62 % AVG Validation Acc 60.41 %\n",
      "Epoch:120/200 AVG Training Loss:0.605 AVG Validation Loss:0.676 AVG Training Acc 65.58 % AVG Validation Acc 60.96 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.605 AVG Validation Loss:0.677 AVG Training Acc 65.63 % AVG Validation Acc 60.69 %\n",
      "Epoch:140/200 AVG Training Loss:0.608 AVG Validation Loss:0.675 AVG Training Acc 65.33 % AVG Validation Acc 61.41 %\n",
      "Epoch:150/200 AVG Training Loss:0.605 AVG Validation Loss:0.674 AVG Training Acc 65.93 % AVG Validation Acc 60.60 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.607 AVG Validation Loss:0.678 AVG Training Acc 65.38 % AVG Validation Acc 60.41 %\n",
      "Epoch:170/200 AVG Training Loss:0.606 AVG Validation Loss:0.674 AVG Training Acc 65.44 % AVG Validation Acc 60.60 %\n",
      "Epoch:180/200 AVG Training Loss:0.606 AVG Validation Loss:0.677 AVG Training Acc 65.37 % AVG Validation Acc 60.69 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.607 AVG Validation Loss:0.676 AVG Training Acc 65.20 % AVG Validation Acc 60.78 %\n",
      "Epoch:200/200 AVG Training Loss:0.605 AVG Validation Loss:0.676 AVG Training Acc 65.36 % AVG Validation Acc 61.14 %\n",
      "Split 53\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1f0704c14b54c7cb2adf5750097a552",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.657 AVG Validation Loss:0.654 AVG Training Acc 62.02 % AVG Validation Acc 61.59 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.654 AVG Training Acc 61.76 % AVG Validation Acc 61.77 %\n",
      "Epoch:30/200 AVG Training Loss:0.648 AVG Validation Loss:0.653 AVG Training Acc 62.18 % AVG Validation Acc 61.59 %\n",
      "Epoch:40/200 AVG Training Loss:0.640 AVG Validation Loss:0.659 AVG Training Acc 62.45 % AVG Validation Acc 59.51 %\n",
      "Epoch:50/200 AVG Training Loss:0.645 AVG Validation Loss:0.653 AVG Training Acc 62.10 % AVG Validation Acc 61.86 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.658 AVG Validation Loss:0.655 AVG Training Acc 61.98 % AVG Validation Acc 61.59 %\n",
      "Epoch:70/200 AVG Training Loss:0.654 AVG Validation Loss:0.654 AVG Training Acc 61.94 % AVG Validation Acc 61.77 %\n",
      "Epoch:80/200 AVG Training Loss:0.652 AVG Validation Loss:0.653 AVG Training Acc 62.12 % AVG Validation Acc 62.13 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.650 AVG Validation Loss:0.657 AVG Training Acc 62.32 % AVG Validation Acc 61.41 %\n",
      "Epoch:100/200 AVG Training Loss:0.650 AVG Validation Loss:0.656 AVG Training Acc 62.61 % AVG Validation Acc 61.41 %\n",
      "Epoch:110/200 AVG Training Loss:0.649 AVG Validation Loss:0.654 AVG Training Acc 62.14 % AVG Validation Acc 61.14 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.646 AVG Validation Loss:0.651 AVG Training Acc 62.59 % AVG Validation Acc 61.50 %\n",
      "Epoch:130/200 AVG Training Loss:0.648 AVG Validation Loss:0.654 AVG Training Acc 62.48 % AVG Validation Acc 61.41 %\n",
      "Epoch:140/200 AVG Training Loss:0.648 AVG Validation Loss:0.653 AVG Training Acc 61.98 % AVG Validation Acc 61.59 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.648 AVG Validation Loss:0.654 AVG Training Acc 62.24 % AVG Validation Acc 61.95 %\n",
      "Epoch:160/200 AVG Training Loss:0.647 AVG Validation Loss:0.657 AVG Training Acc 62.52 % AVG Validation Acc 61.59 %\n",
      "Epoch:170/200 AVG Training Loss:0.647 AVG Validation Loss:0.657 AVG Training Acc 62.45 % AVG Validation Acc 60.87 %\n",
      "Epoch:180/200 AVG Training Loss:0.649 AVG Validation Loss:0.656 AVG Training Acc 62.34 % AVG Validation Acc 61.14 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.648 AVG Validation Loss:0.655 AVG Training Acc 62.37 % AVG Validation Acc 61.86 %\n",
      "Epoch:200/200 AVG Training Loss:0.648 AVG Validation Loss:0.652 AVG Training Acc 62.45 % AVG Validation Acc 61.86 %\n",
      "Split 54\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a3edbf79244745afca3e3e094f5f7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.660 AVG Training Acc 61.73 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.662 AVG Training Acc 61.79 % AVG Validation Acc 62.31 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.663 AVG Validation Loss:0.663 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.659 AVG Validation Loss:0.663 AVG Training Acc 61.93 % AVG Validation Acc 61.50 %\n",
      "Epoch:50/200 AVG Training Loss:0.656 AVG Validation Loss:0.667 AVG Training Acc 62.00 % AVG Validation Acc 62.22 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.656 AVG Validation Loss:0.664 AVG Training Acc 62.18 % AVG Validation Acc 62.13 %\n",
      "Epoch:70/200 AVG Training Loss:0.656 AVG Validation Loss:0.665 AVG Training Acc 62.15 % AVG Validation Acc 61.59 %\n",
      "Epoch:80/200 AVG Training Loss:0.654 AVG Validation Loss:0.666 AVG Training Acc 62.53 % AVG Validation Acc 61.86 %\n",
      "Epoch:90/200 AVG Training Loss:0.653 AVG Validation Loss:0.665 AVG Training Acc 62.33 % AVG Validation Acc 61.68 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.653 AVG Validation Loss:0.665 AVG Training Acc 62.44 % AVG Validation Acc 61.95 %\n",
      "Epoch:110/200 AVG Training Loss:0.652 AVG Validation Loss:0.666 AVG Training Acc 62.54 % AVG Validation Acc 61.86 %\n",
      "Epoch:120/200 AVG Training Loss:0.654 AVG Validation Loss:0.667 AVG Training Acc 62.35 % AVG Validation Acc 61.68 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.653 AVG Validation Loss:0.665 AVG Training Acc 62.14 % AVG Validation Acc 61.59 %\n",
      "Epoch:140/200 AVG Training Loss:0.653 AVG Validation Loss:0.666 AVG Training Acc 62.73 % AVG Validation Acc 61.59 %\n",
      "Epoch:150/200 AVG Training Loss:0.654 AVG Validation Loss:0.665 AVG Training Acc 62.41 % AVG Validation Acc 61.68 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.653 AVG Validation Loss:0.664 AVG Training Acc 62.49 % AVG Validation Acc 61.68 %\n",
      "Epoch:170/200 AVG Training Loss:0.653 AVG Validation Loss:0.664 AVG Training Acc 62.44 % AVG Validation Acc 61.77 %\n",
      "Epoch:180/200 AVG Training Loss:0.654 AVG Validation Loss:0.664 AVG Training Acc 62.46 % AVG Validation Acc 61.77 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.653 AVG Validation Loss:0.664 AVG Training Acc 62.40 % AVG Validation Acc 61.77 %\n",
      "Epoch:200/200 AVG Training Loss:0.653 AVG Validation Loss:0.664 AVG Training Acc 62.35 % AVG Validation Acc 62.04 %\n",
      "Split 55\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92b5820d06504a12ad3ee9b1b643158a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.659 AVG Training Acc 61.85 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.665 AVG Training Acc 61.85 % AVG Validation Acc 61.41 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.634 AVG Validation Loss:0.669 AVG Training Acc 63.19 % AVG Validation Acc 61.41 %\n",
      "Epoch:40/200 AVG Training Loss:0.620 AVG Validation Loss:0.686 AVG Training Acc 64.21 % AVG Validation Acc 60.60 %\n",
      "Epoch:50/200 AVG Training Loss:0.615 AVG Validation Loss:0.694 AVG Training Acc 64.67 % AVG Validation Acc 60.14 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.609 AVG Validation Loss:0.714 AVG Training Acc 64.90 % AVG Validation Acc 59.51 %\n",
      "Epoch:70/200 AVG Training Loss:0.604 AVG Validation Loss:0.719 AVG Training Acc 65.69 % AVG Validation Acc 59.60 %\n",
      "Epoch:80/200 AVG Training Loss:0.602 AVG Validation Loss:0.721 AVG Training Acc 65.56 % AVG Validation Acc 59.87 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.601 AVG Validation Loss:0.723 AVG Training Acc 65.85 % AVG Validation Acc 59.15 %\n",
      "Epoch:100/200 AVG Training Loss:0.601 AVG Validation Loss:0.723 AVG Training Acc 65.42 % AVG Validation Acc 58.88 %\n",
      "Epoch:110/200 AVG Training Loss:0.601 AVG Validation Loss:0.724 AVG Training Acc 65.57 % AVG Validation Acc 58.70 %\n",
      "Epoch:120/200 AVG Training Loss:0.602 AVG Validation Loss:0.723 AVG Training Acc 65.61 % AVG Validation Acc 59.42 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.602 AVG Validation Loss:0.722 AVG Training Acc 65.54 % AVG Validation Acc 59.33 %\n",
      "Epoch:140/200 AVG Training Loss:0.601 AVG Validation Loss:0.724 AVG Training Acc 65.83 % AVG Validation Acc 59.15 %\n",
      "Epoch:150/200 AVG Training Loss:0.603 AVG Validation Loss:0.725 AVG Training Acc 65.94 % AVG Validation Acc 59.24 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.601 AVG Validation Loss:0.724 AVG Training Acc 65.83 % AVG Validation Acc 59.06 %\n",
      "Epoch:170/200 AVG Training Loss:0.600 AVG Validation Loss:0.727 AVG Training Acc 65.41 % AVG Validation Acc 59.33 %\n",
      "Epoch:180/200 AVG Training Loss:0.601 AVG Validation Loss:0.726 AVG Training Acc 65.46 % AVG Validation Acc 59.06 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.602 AVG Validation Loss:0.724 AVG Training Acc 65.95 % AVG Validation Acc 59.24 %\n",
      "Epoch:200/200 AVG Training Loss:0.602 AVG Validation Loss:0.725 AVG Training Acc 65.52 % AVG Validation Acc 58.88 %\n",
      "Split 56\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58dc08297ff745c884a129f503167bfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.660 AVG Training Acc 61.73 % AVG Validation Acc 62.00 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.664 AVG Training Acc 62.13 % AVG Validation Acc 61.82 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.642 AVG Validation Loss:0.662 AVG Training Acc 62.29 % AVG Validation Acc 61.10 %\n",
      "Epoch:40/200 AVG Training Loss:0.636 AVG Validation Loss:0.667 AVG Training Acc 63.22 % AVG Validation Acc 61.73 %\n",
      "Epoch:50/200 AVG Training Loss:0.627 AVG Validation Loss:0.673 AVG Training Acc 63.89 % AVG Validation Acc 60.29 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.621 AVG Validation Loss:0.682 AVG Training Acc 63.83 % AVG Validation Acc 60.11 %\n",
      "Epoch:70/200 AVG Training Loss:0.620 AVG Validation Loss:0.682 AVG Training Acc 64.34 % AVG Validation Acc 60.74 %\n",
      "Epoch:80/200 AVG Training Loss:0.619 AVG Validation Loss:0.686 AVG Training Acc 63.75 % AVG Validation Acc 60.83 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.618 AVG Validation Loss:0.686 AVG Training Acc 64.33 % AVG Validation Acc 61.01 %\n",
      "Epoch:100/200 AVG Training Loss:0.619 AVG Validation Loss:0.687 AVG Training Acc 64.07 % AVG Validation Acc 61.28 %\n",
      "Epoch:110/200 AVG Training Loss:0.619 AVG Validation Loss:0.686 AVG Training Acc 63.99 % AVG Validation Acc 60.74 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.620 AVG Validation Loss:0.685 AVG Training Acc 64.05 % AVG Validation Acc 61.19 %\n",
      "Epoch:130/200 AVG Training Loss:0.617 AVG Validation Loss:0.683 AVG Training Acc 64.72 % AVG Validation Acc 61.01 %\n",
      "Epoch:140/200 AVG Training Loss:0.618 AVG Validation Loss:0.683 AVG Training Acc 64.54 % AVG Validation Acc 61.01 %\n",
      "Epoch:150/200 AVG Training Loss:0.617 AVG Validation Loss:0.689 AVG Training Acc 64.21 % AVG Validation Acc 60.92 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.618 AVG Validation Loss:0.689 AVG Training Acc 64.34 % AVG Validation Acc 61.01 %\n",
      "Epoch:170/200 AVG Training Loss:0.618 AVG Validation Loss:0.686 AVG Training Acc 64.43 % AVG Validation Acc 61.55 %\n",
      "Epoch:180/200 AVG Training Loss:0.617 AVG Validation Loss:0.683 AVG Training Acc 64.34 % AVG Validation Acc 61.19 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.618 AVG Validation Loss:0.686 AVG Training Acc 64.33 % AVG Validation Acc 61.28 %\n",
      "Epoch:200/200 AVG Training Loss:0.617 AVG Validation Loss:0.686 AVG Training Acc 64.26 % AVG Validation Acc 60.83 %\n",
      "Split 57\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9460b782d754a088ed82eafbcc1d460",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.662 AVG Validation Loss:0.652 AVG Training Acc 61.87 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:0.651 AVG Training Acc 62.01 % AVG Validation Acc 61.46 %\n",
      "Epoch:30/200 AVG Training Loss:0.652 AVG Validation Loss:0.650 AVG Training Acc 61.95 % AVG Validation Acc 61.64 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.629 AVG Validation Loss:0.659 AVG Training Acc 62.87 % AVG Validation Acc 60.29 %\n",
      "Epoch:50/200 AVG Training Loss:0.618 AVG Validation Loss:0.668 AVG Training Acc 63.52 % AVG Validation Acc 60.56 %\n",
      "Epoch:60/200 AVG Training Loss:0.611 AVG Validation Loss:0.680 AVG Training Acc 64.34 % AVG Validation Acc 60.20 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.606 AVG Validation Loss:0.687 AVG Training Acc 64.21 % AVG Validation Acc 61.01 %\n",
      "Epoch:80/200 AVG Training Loss:0.606 AVG Validation Loss:0.690 AVG Training Acc 64.62 % AVG Validation Acc 60.92 %\n",
      "Epoch:90/200 AVG Training Loss:0.603 AVG Validation Loss:0.691 AVG Training Acc 64.92 % AVG Validation Acc 60.47 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.603 AVG Validation Loss:0.691 AVG Training Acc 65.07 % AVG Validation Acc 60.92 %\n",
      "Epoch:110/200 AVG Training Loss:0.603 AVG Validation Loss:0.692 AVG Training Acc 64.49 % AVG Validation Acc 59.93 %\n",
      "Epoch:120/200 AVG Training Loss:0.602 AVG Validation Loss:0.694 AVG Training Acc 65.07 % AVG Validation Acc 60.65 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.602 AVG Validation Loss:0.692 AVG Training Acc 64.70 % AVG Validation Acc 60.47 %\n",
      "Epoch:140/200 AVG Training Loss:0.600 AVG Validation Loss:0.692 AVG Training Acc 65.05 % AVG Validation Acc 60.83 %\n",
      "Epoch:150/200 AVG Training Loss:0.601 AVG Validation Loss:0.695 AVG Training Acc 64.73 % AVG Validation Acc 61.01 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.601 AVG Validation Loss:0.693 AVG Training Acc 65.17 % AVG Validation Acc 60.83 %\n",
      "Epoch:170/200 AVG Training Loss:0.602 AVG Validation Loss:0.694 AVG Training Acc 64.66 % AVG Validation Acc 60.38 %\n",
      "Epoch:180/200 AVG Training Loss:0.601 AVG Validation Loss:0.699 AVG Training Acc 64.73 % AVG Validation Acc 60.20 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.602 AVG Validation Loss:0.692 AVG Training Acc 64.54 % AVG Validation Acc 60.83 %\n",
      "Epoch:200/200 AVG Training Loss:0.600 AVG Validation Loss:0.694 AVG Training Acc 64.80 % AVG Validation Acc 60.56 %\n",
      "Split 58\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dddd7d6607314aeb8acc2cc4fc070ab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.657 AVG Validation Loss:0.659 AVG Training Acc 61.67 % AVG Validation Acc 62.00 %\n",
      "Epoch:20/200 AVG Training Loss:0.650 AVG Validation Loss:0.660 AVG Training Acc 61.72 % AVG Validation Acc 61.55 %\n",
      "Epoch:30/200 AVG Training Loss:0.640 AVG Validation Loss:0.667 AVG Training Acc 61.75 % AVG Validation Acc 62.18 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.615 AVG Validation Loss:0.692 AVG Training Acc 63.90 % AVG Validation Acc 59.66 %\n",
      "Epoch:50/200 AVG Training Loss:0.602 AVG Validation Loss:0.698 AVG Training Acc 65.11 % AVG Validation Acc 60.47 %\n",
      "Epoch:60/200 AVG Training Loss:0.592 AVG Validation Loss:0.700 AVG Training Acc 65.99 % AVG Validation Acc 60.11 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.585 AVG Validation Loss:0.712 AVG Training Acc 66.22 % AVG Validation Acc 59.39 %\n",
      "Epoch:80/200 AVG Training Loss:0.583 AVG Validation Loss:0.718 AVG Training Acc 66.60 % AVG Validation Acc 59.39 %\n",
      "Epoch:90/200 AVG Training Loss:0.582 AVG Validation Loss:0.718 AVG Training Acc 66.53 % AVG Validation Acc 58.21 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.582 AVG Validation Loss:0.712 AVG Training Acc 66.32 % AVG Validation Acc 58.66 %\n",
      "Epoch:110/200 AVG Training Loss:0.579 AVG Validation Loss:0.727 AVG Training Acc 66.92 % AVG Validation Acc 58.48 %\n",
      "Epoch:120/200 AVG Training Loss:0.579 AVG Validation Loss:0.724 AVG Training Acc 66.77 % AVG Validation Acc 58.94 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.583 AVG Validation Loss:0.716 AVG Training Acc 66.22 % AVG Validation Acc 58.75 %\n",
      "Epoch:140/200 AVG Training Loss:0.579 AVG Validation Loss:0.713 AVG Training Acc 66.30 % AVG Validation Acc 58.48 %\n",
      "Epoch:150/200 AVG Training Loss:0.580 AVG Validation Loss:0.715 AVG Training Acc 66.96 % AVG Validation Acc 58.30 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.580 AVG Validation Loss:0.723 AVG Training Acc 66.53 % AVG Validation Acc 58.39 %\n",
      "Epoch:170/200 AVG Training Loss:0.578 AVG Validation Loss:0.717 AVG Training Acc 66.73 % AVG Validation Acc 58.66 %\n",
      "Epoch:180/200 AVG Training Loss:0.584 AVG Validation Loss:0.717 AVG Training Acc 66.62 % AVG Validation Acc 59.30 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.580 AVG Validation Loss:0.712 AVG Training Acc 66.87 % AVG Validation Acc 58.21 %\n",
      "Epoch:200/200 AVG Training Loss:0.580 AVG Validation Loss:0.720 AVG Training Acc 66.35 % AVG Validation Acc 58.84 %\n",
      "Split 59\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a50a6f2343a545fbbf498d54ec3da57d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.662 AVG Training Acc 61.74 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.662 AVG Training Acc 61.85 % AVG Validation Acc 61.64 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.638 AVG Validation Loss:0.668 AVG Training Acc 63.22 % AVG Validation Acc 60.74 %\n",
      "Epoch:40/200 AVG Training Loss:0.632 AVG Validation Loss:0.672 AVG Training Acc 63.19 % AVG Validation Acc 61.46 %\n",
      "Epoch:50/200 AVG Training Loss:0.625 AVG Validation Loss:0.675 AVG Training Acc 64.30 % AVG Validation Acc 61.10 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.621 AVG Validation Loss:0.677 AVG Training Acc 64.11 % AVG Validation Acc 61.91 %\n",
      "Epoch:70/200 AVG Training Loss:0.620 AVG Validation Loss:0.677 AVG Training Acc 64.34 % AVG Validation Acc 61.73 %\n",
      "Epoch:80/200 AVG Training Loss:0.619 AVG Validation Loss:0.679 AVG Training Acc 64.49 % AVG Validation Acc 62.18 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.619 AVG Validation Loss:0.673 AVG Training Acc 64.74 % AVG Validation Acc 62.18 %\n",
      "Epoch:100/200 AVG Training Loss:0.618 AVG Validation Loss:0.674 AVG Training Acc 64.72 % AVG Validation Acc 62.27 %\n",
      "Epoch:110/200 AVG Training Loss:0.618 AVG Validation Loss:0.676 AVG Training Acc 64.39 % AVG Validation Acc 61.19 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.617 AVG Validation Loss:0.675 AVG Training Acc 65.23 % AVG Validation Acc 61.55 %\n",
      "Epoch:130/200 AVG Training Loss:0.616 AVG Validation Loss:0.673 AVG Training Acc 64.58 % AVG Validation Acc 61.46 %\n",
      "Epoch:140/200 AVG Training Loss:0.618 AVG Validation Loss:0.677 AVG Training Acc 64.60 % AVG Validation Acc 61.82 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.619 AVG Validation Loss:0.677 AVG Training Acc 64.64 % AVG Validation Acc 61.10 %\n",
      "Epoch:160/200 AVG Training Loss:0.619 AVG Validation Loss:0.678 AVG Training Acc 64.79 % AVG Validation Acc 61.91 %\n",
      "Epoch:170/200 AVG Training Loss:0.618 AVG Validation Loss:0.675 AVG Training Acc 64.35 % AVG Validation Acc 61.73 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.619 AVG Validation Loss:0.678 AVG Training Acc 64.17 % AVG Validation Acc 61.91 %\n",
      "Epoch:190/200 AVG Training Loss:0.618 AVG Validation Loss:0.677 AVG Training Acc 64.84 % AVG Validation Acc 61.46 %\n",
      "Epoch:200/200 AVG Training Loss:0.618 AVG Validation Loss:0.675 AVG Training Acc 64.73 % AVG Validation Acc 62.00 %\n",
      "Split 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e30be2f70664d7c8fb706a167ffa19a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.657 AVG Training Acc 61.83 % AVG Validation Acc 61.82 %\n",
      "Epoch:20/200 AVG Training Loss:0.649 AVG Validation Loss:0.673 AVG Training Acc 61.96 % AVG Validation Acc 62.45 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.628 AVG Validation Loss:0.663 AVG Training Acc 63.30 % AVG Validation Acc 61.73 %\n",
      "Epoch:40/200 AVG Training Loss:0.618 AVG Validation Loss:0.672 AVG Training Acc 63.16 % AVG Validation Acc 60.56 %\n",
      "Epoch:50/200 AVG Training Loss:0.611 AVG Validation Loss:0.680 AVG Training Acc 64.23 % AVG Validation Acc 60.65 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.602 AVG Validation Loss:0.685 AVG Training Acc 64.80 % AVG Validation Acc 61.73 %\n",
      "Epoch:70/200 AVG Training Loss:0.602 AVG Validation Loss:0.682 AVG Training Acc 64.74 % AVG Validation Acc 61.55 %\n",
      "Epoch:80/200 AVG Training Loss:0.598 AVG Validation Loss:0.688 AVG Training Acc 64.86 % AVG Validation Acc 61.37 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.599 AVG Validation Loss:0.689 AVG Training Acc 64.66 % AVG Validation Acc 61.73 %\n",
      "Epoch:100/200 AVG Training Loss:0.597 AVG Validation Loss:0.691 AVG Training Acc 65.22 % AVG Validation Acc 61.19 %\n",
      "Epoch:110/200 AVG Training Loss:0.598 AVG Validation Loss:0.689 AVG Training Acc 64.59 % AVG Validation Acc 61.55 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.598 AVG Validation Loss:0.695 AVG Training Acc 64.98 % AVG Validation Acc 61.55 %\n",
      "Epoch:130/200 AVG Training Loss:0.599 AVG Validation Loss:0.690 AVG Training Acc 64.94 % AVG Validation Acc 61.82 %\n",
      "Epoch:140/200 AVG Training Loss:0.597 AVG Validation Loss:0.692 AVG Training Acc 64.89 % AVG Validation Acc 61.37 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.597 AVG Validation Loss:0.686 AVG Training Acc 65.22 % AVG Validation Acc 60.83 %\n",
      "Epoch:160/200 AVG Training Loss:0.598 AVG Validation Loss:0.690 AVG Training Acc 64.97 % AVG Validation Acc 61.82 %\n",
      "Epoch:170/200 AVG Training Loss:0.600 AVG Validation Loss:0.690 AVG Training Acc 65.04 % AVG Validation Acc 61.55 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.596 AVG Validation Loss:0.692 AVG Training Acc 65.86 % AVG Validation Acc 61.55 %\n",
      "Epoch:190/200 AVG Training Loss:0.598 AVG Validation Loss:0.691 AVG Training Acc 64.88 % AVG Validation Acc 61.10 %\n",
      "Epoch:200/200 AVG Training Loss:0.596 AVG Validation Loss:0.691 AVG Training Acc 65.22 % AVG Validation Acc 61.28 %\n",
      "Split 61\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9265528b74484621b5b233a64318b30d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.657 AVG Training Acc 61.95 % AVG Validation Acc 62.04 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.659 AVG Training Acc 62.08 % AVG Validation Acc 61.59 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.633 AVG Validation Loss:0.662 AVG Training Acc 63.34 % AVG Validation Acc 60.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.625 AVG Validation Loss:0.667 AVG Training Acc 63.97 % AVG Validation Acc 61.50 %\n",
      "Epoch:50/200 AVG Training Loss:0.615 AVG Validation Loss:0.672 AVG Training Acc 64.43 % AVG Validation Acc 60.60 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.610 AVG Validation Loss:0.680 AVG Training Acc 65.15 % AVG Validation Acc 61.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.607 AVG Validation Loss:0.681 AVG Training Acc 65.35 % AVG Validation Acc 61.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.608 AVG Validation Loss:0.687 AVG Training Acc 64.76 % AVG Validation Acc 61.68 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.606 AVG Validation Loss:0.685 AVG Training Acc 65.06 % AVG Validation Acc 60.87 %\n",
      "Epoch:100/200 AVG Training Loss:0.606 AVG Validation Loss:0.689 AVG Training Acc 64.82 % AVG Validation Acc 61.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.607 AVG Validation Loss:0.691 AVG Training Acc 64.93 % AVG Validation Acc 61.14 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.605 AVG Validation Loss:0.685 AVG Training Acc 65.25 % AVG Validation Acc 61.77 %\n",
      "Epoch:130/200 AVG Training Loss:0.608 AVG Validation Loss:0.685 AVG Training Acc 65.32 % AVG Validation Acc 61.41 %\n",
      "Epoch:140/200 AVG Training Loss:0.605 AVG Validation Loss:0.686 AVG Training Acc 65.23 % AVG Validation Acc 61.05 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.605 AVG Validation Loss:0.687 AVG Training Acc 65.01 % AVG Validation Acc 61.41 %\n",
      "Epoch:160/200 AVG Training Loss:0.606 AVG Validation Loss:0.684 AVG Training Acc 65.36 % AVG Validation Acc 61.41 %\n",
      "Epoch:170/200 AVG Training Loss:0.607 AVG Validation Loss:0.689 AVG Training Acc 65.16 % AVG Validation Acc 60.96 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.606 AVG Validation Loss:0.688 AVG Training Acc 65.45 % AVG Validation Acc 61.23 %\n",
      "Epoch:190/200 AVG Training Loss:0.606 AVG Validation Loss:0.690 AVG Training Acc 65.10 % AVG Validation Acc 60.50 %\n",
      "Epoch:200/200 AVG Training Loss:0.607 AVG Validation Loss:0.688 AVG Training Acc 65.15 % AVG Validation Acc 61.32 %\n",
      "Split 62\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a1f9eed9e534b47800cab279359f0d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.663 AVG Training Acc 62.00 % AVG Validation Acc 61.32 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.665 AVG Training Acc 62.17 % AVG Validation Acc 61.77 %\n",
      "Epoch:30/200 AVG Training Loss:0.647 AVG Validation Loss:0.665 AVG Training Acc 62.46 % AVG Validation Acc 60.60 %\n",
      "Epoch:40/200 AVG Training Loss:0.644 AVG Validation Loss:0.668 AVG Training Acc 62.20 % AVG Validation Acc 60.50 %\n",
      "Epoch:50/200 AVG Training Loss:0.640 AVG Validation Loss:0.674 AVG Training Acc 62.72 % AVG Validation Acc 60.50 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.639 AVG Validation Loss:0.673 AVG Training Acc 63.13 % AVG Validation Acc 60.78 %\n",
      "Epoch:70/200 AVG Training Loss:0.637 AVG Validation Loss:0.674 AVG Training Acc 62.84 % AVG Validation Acc 60.87 %\n",
      "Epoch:80/200 AVG Training Loss:0.637 AVG Validation Loss:0.675 AVG Training Acc 63.01 % AVG Validation Acc 60.69 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.636 AVG Validation Loss:0.674 AVG Training Acc 63.23 % AVG Validation Acc 60.41 %\n",
      "Epoch:100/200 AVG Training Loss:0.636 AVG Validation Loss:0.674 AVG Training Acc 63.08 % AVG Validation Acc 60.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.636 AVG Validation Loss:0.676 AVG Training Acc 63.26 % AVG Validation Acc 60.60 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.637 AVG Validation Loss:0.675 AVG Training Acc 62.98 % AVG Validation Acc 60.60 %\n",
      "Epoch:130/200 AVG Training Loss:0.636 AVG Validation Loss:0.675 AVG Training Acc 62.87 % AVG Validation Acc 60.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.636 AVG Validation Loss:0.675 AVG Training Acc 63.22 % AVG Validation Acc 60.69 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.635 AVG Validation Loss:0.675 AVG Training Acc 63.32 % AVG Validation Acc 60.41 %\n",
      "Epoch:160/200 AVG Training Loss:0.636 AVG Validation Loss:0.675 AVG Training Acc 62.80 % AVG Validation Acc 60.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.636 AVG Validation Loss:0.676 AVG Training Acc 63.12 % AVG Validation Acc 60.41 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.636 AVG Validation Loss:0.675 AVG Training Acc 63.11 % AVG Validation Acc 60.50 %\n",
      "Epoch:190/200 AVG Training Loss:0.636 AVG Validation Loss:0.675 AVG Training Acc 63.14 % AVG Validation Acc 60.78 %\n",
      "Epoch:200/200 AVG Training Loss:0.637 AVG Validation Loss:0.675 AVG Training Acc 62.87 % AVG Validation Acc 60.41 %\n",
      "Split 63\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8e41ae0c14e49f0babfc3242c4d4412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.665 AVG Training Acc 61.84 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.661 AVG Training Acc 61.74 % AVG Validation Acc 61.86 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.642 AVG Validation Loss:0.664 AVG Training Acc 62.73 % AVG Validation Acc 60.41 %\n",
      "Epoch:40/200 AVG Training Loss:0.633 AVG Validation Loss:0.669 AVG Training Acc 63.31 % AVG Validation Acc 60.32 %\n",
      "Epoch:50/200 AVG Training Loss:0.625 AVG Validation Loss:0.674 AVG Training Acc 63.72 % AVG Validation Acc 60.32 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.617 AVG Validation Loss:0.685 AVG Training Acc 63.99 % AVG Validation Acc 60.41 %\n",
      "Epoch:70/200 AVG Training Loss:0.616 AVG Validation Loss:0.688 AVG Training Acc 63.97 % AVG Validation Acc 60.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.614 AVG Validation Loss:0.689 AVG Training Acc 64.33 % AVG Validation Acc 59.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.612 AVG Validation Loss:0.691 AVG Training Acc 64.82 % AVG Validation Acc 59.78 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.612 AVG Validation Loss:0.690 AVG Training Acc 64.83 % AVG Validation Acc 60.41 %\n",
      "Epoch:110/200 AVG Training Loss:0.613 AVG Validation Loss:0.691 AVG Training Acc 64.64 % AVG Validation Acc 59.78 %\n",
      "Epoch:120/200 AVG Training Loss:0.611 AVG Validation Loss:0.691 AVG Training Acc 64.79 % AVG Validation Acc 59.87 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.612 AVG Validation Loss:0.693 AVG Training Acc 64.61 % AVG Validation Acc 59.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.611 AVG Validation Loss:0.689 AVG Training Acc 64.27 % AVG Validation Acc 59.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.612 AVG Validation Loss:0.691 AVG Training Acc 64.54 % AVG Validation Acc 60.14 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.612 AVG Validation Loss:0.692 AVG Training Acc 64.73 % AVG Validation Acc 59.96 %\n",
      "Epoch:170/200 AVG Training Loss:0.610 AVG Validation Loss:0.690 AVG Training Acc 64.40 % AVG Validation Acc 60.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.613 AVG Validation Loss:0.691 AVG Training Acc 64.50 % AVG Validation Acc 59.87 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.609 AVG Validation Loss:0.691 AVG Training Acc 64.64 % AVG Validation Acc 59.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.611 AVG Validation Loss:0.689 AVG Training Acc 64.46 % AVG Validation Acc 60.05 %\n",
      "Split 64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad6d0969a0404ccb8424cb8d404b343d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.655 AVG Training Acc 61.73 % AVG Validation Acc 61.68 %\n",
      "Epoch:20/200 AVG Training Loss:0.661 AVG Validation Loss:0.656 AVG Training Acc 61.88 % AVG Validation Acc 61.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.651 AVG Validation Loss:0.660 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.644 AVG Validation Loss:0.659 AVG Training Acc 61.98 % AVG Validation Acc 61.59 %\n",
      "Epoch:50/200 AVG Training Loss:0.647 AVG Validation Loss:0.654 AVG Training Acc 62.21 % AVG Validation Acc 62.04 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.618 AVG Validation Loss:0.648 AVG Training Acc 63.10 % AVG Validation Acc 62.49 %\n",
      "Epoch:70/200 AVG Training Loss:0.608 AVG Validation Loss:0.662 AVG Training Acc 63.74 % AVG Validation Acc 62.40 %\n",
      "Epoch:80/200 AVG Training Loss:0.601 AVG Validation Loss:0.677 AVG Training Acc 64.53 % AVG Validation Acc 62.40 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.596 AVG Validation Loss:0.685 AVG Training Acc 64.18 % AVG Validation Acc 62.13 %\n",
      "Epoch:100/200 AVG Training Loss:0.595 AVG Validation Loss:0.692 AVG Training Acc 64.32 % AVG Validation Acc 62.13 %\n",
      "Epoch:110/200 AVG Training Loss:0.594 AVG Validation Loss:0.696 AVG Training Acc 64.25 % AVG Validation Acc 61.77 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.596 AVG Validation Loss:0.688 AVG Training Acc 64.91 % AVG Validation Acc 61.59 %\n",
      "Epoch:130/200 AVG Training Loss:0.593 AVG Validation Loss:0.694 AVG Training Acc 64.46 % AVG Validation Acc 62.22 %\n",
      "Epoch:140/200 AVG Training Loss:0.591 AVG Validation Loss:0.694 AVG Training Acc 65.08 % AVG Validation Acc 61.86 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.591 AVG Validation Loss:0.689 AVG Training Acc 65.14 % AVG Validation Acc 61.59 %\n",
      "Epoch:160/200 AVG Training Loss:0.594 AVG Validation Loss:0.691 AVG Training Acc 64.94 % AVG Validation Acc 62.22 %\n",
      "Epoch:170/200 AVG Training Loss:0.593 AVG Validation Loss:0.687 AVG Training Acc 64.60 % AVG Validation Acc 61.77 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.593 AVG Validation Loss:0.685 AVG Training Acc 64.75 % AVG Validation Acc 62.40 %\n",
      "Epoch:190/200 AVG Training Loss:0.591 AVG Validation Loss:0.690 AVG Training Acc 64.85 % AVG Validation Acc 62.49 %\n",
      "Epoch:200/200 AVG Training Loss:0.592 AVG Validation Loss:0.690 AVG Training Acc 64.85 % AVG Validation Acc 62.22 %\n",
      "Split 65\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79d633f3020f4fd997f63a34da779e4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.656 AVG Training Acc 61.90 % AVG Validation Acc 62.04 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.650 AVG Training Acc 61.74 % AVG Validation Acc 61.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.644 AVG Validation Loss:0.657 AVG Training Acc 62.37 % AVG Validation Acc 62.76 %\n",
      "Epoch:40/200 AVG Training Loss:0.663 AVG Validation Loss:0.666 AVG Training Acc 61.72 % AVG Validation Acc 61.86 %\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.657 AVG Validation Loss:0.663 AVG Training Acc 61.93 % AVG Validation Acc 62.04 %\n",
      "Epoch:60/200 AVG Training Loss:0.651 AVG Validation Loss:0.663 AVG Training Acc 62.05 % AVG Validation Acc 61.77 %\n",
      "Epoch:70/200 AVG Training Loss:0.644 AVG Validation Loss:0.667 AVG Training Acc 62.21 % AVG Validation Acc 61.86 %\n",
      "Epoch    71: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.641 AVG Validation Loss:0.668 AVG Training Acc 62.27 % AVG Validation Acc 61.59 %\n",
      "Epoch:90/200 AVG Training Loss:0.640 AVG Validation Loss:0.668 AVG Training Acc 62.48 % AVG Validation Acc 61.77 %\n",
      "Epoch:100/200 AVG Training Loss:0.638 AVG Validation Loss:0.670 AVG Training Acc 62.19 % AVG Validation Acc 61.68 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.638 AVG Validation Loss:0.670 AVG Training Acc 62.28 % AVG Validation Acc 61.86 %\n",
      "Epoch:120/200 AVG Training Loss:0.639 AVG Validation Loss:0.669 AVG Training Acc 62.27 % AVG Validation Acc 61.59 %\n",
      "Epoch:130/200 AVG Training Loss:0.639 AVG Validation Loss:0.669 AVG Training Acc 62.32 % AVG Validation Acc 61.68 %\n",
      "Epoch   133: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.639 AVG Validation Loss:0.668 AVG Training Acc 62.32 % AVG Validation Acc 61.77 %\n",
      "Epoch:150/200 AVG Training Loss:0.639 AVG Validation Loss:0.669 AVG Training Acc 62.52 % AVG Validation Acc 61.68 %\n",
      "Epoch:160/200 AVG Training Loss:0.639 AVG Validation Loss:0.669 AVG Training Acc 62.40 % AVG Validation Acc 61.50 %\n",
      "Epoch   164: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.640 AVG Validation Loss:0.667 AVG Training Acc 62.19 % AVG Validation Acc 61.77 %\n",
      "Epoch:180/200 AVG Training Loss:0.639 AVG Validation Loss:0.668 AVG Training Acc 62.29 % AVG Validation Acc 61.59 %\n",
      "Epoch:190/200 AVG Training Loss:0.639 AVG Validation Loss:0.668 AVG Training Acc 62.31 % AVG Validation Acc 61.68 %\n",
      "Epoch   195: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.639 AVG Validation Loss:0.670 AVG Training Acc 62.08 % AVG Validation Acc 61.77 %\n",
      "Split 66\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f63b18fc95074bb4ac1d0abc4725a845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.661 AVG Training Acc 61.79 % AVG Validation Acc 61.82 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.660 AVG Training Acc 61.78 % AVG Validation Acc 61.46 %\n",
      "Epoch:30/200 AVG Training Loss:0.648 AVG Validation Loss:0.657 AVG Training Acc 62.37 % AVG Validation Acc 61.46 %\n",
      "Epoch:40/200 AVG Training Loss:0.638 AVG Validation Loss:0.661 AVG Training Acc 63.15 % AVG Validation Acc 61.64 %\n",
      "Epoch:50/200 AVG Training Loss:0.646 AVG Validation Loss:0.668 AVG Training Acc 62.27 % AVG Validation Acc 60.83 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.618 AVG Validation Loss:0.669 AVG Training Acc 64.64 % AVG Validation Acc 60.47 %\n",
      "Epoch:70/200 AVG Training Loss:0.603 AVG Validation Loss:0.682 AVG Training Acc 66.16 % AVG Validation Acc 60.74 %\n",
      "Epoch:80/200 AVG Training Loss:0.596 AVG Validation Loss:0.697 AVG Training Acc 66.33 % AVG Validation Acc 60.20 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.589 AVG Validation Loss:0.707 AVG Training Acc 67.51 % AVG Validation Acc 60.02 %\n",
      "Epoch:100/200 AVG Training Loss:0.586 AVG Validation Loss:0.703 AVG Training Acc 67.27 % AVG Validation Acc 60.38 %\n",
      "Epoch:110/200 AVG Training Loss:0.583 AVG Validation Loss:0.706 AVG Training Acc 67.24 % AVG Validation Acc 60.20 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.581 AVG Validation Loss:0.708 AVG Training Acc 67.79 % AVG Validation Acc 59.39 %\n",
      "Epoch:130/200 AVG Training Loss:0.585 AVG Validation Loss:0.709 AVG Training Acc 67.07 % AVG Validation Acc 59.57 %\n",
      "Epoch:140/200 AVG Training Loss:0.583 AVG Validation Loss:0.708 AVG Training Acc 67.17 % AVG Validation Acc 59.66 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.583 AVG Validation Loss:0.713 AVG Training Acc 67.20 % AVG Validation Acc 59.66 %\n",
      "Epoch:160/200 AVG Training Loss:0.584 AVG Validation Loss:0.711 AVG Training Acc 66.78 % AVG Validation Acc 59.21 %\n",
      "Epoch:170/200 AVG Training Loss:0.583 AVG Validation Loss:0.713 AVG Training Acc 67.56 % AVG Validation Acc 60.38 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.581 AVG Validation Loss:0.700 AVG Training Acc 67.58 % AVG Validation Acc 59.48 %\n",
      "Epoch:190/200 AVG Training Loss:0.582 AVG Validation Loss:0.708 AVG Training Acc 67.44 % AVG Validation Acc 59.21 %\n",
      "Epoch:200/200 AVG Training Loss:0.582 AVG Validation Loss:0.711 AVG Training Acc 67.69 % AVG Validation Acc 59.57 %\n",
      "Split 67\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bef6e68ba0b4066942650731aa1503d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.663 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.663 AVG Training Acc 62.08 % AVG Validation Acc 62.18 %\n",
      "Epoch:30/200 AVG Training Loss:0.645 AVG Validation Loss:0.664 AVG Training Acc 62.15 % AVG Validation Acc 61.82 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.618 AVG Validation Loss:0.683 AVG Training Acc 64.29 % AVG Validation Acc 62.55 %\n",
      "Epoch:50/200 AVG Training Loss:0.606 AVG Validation Loss:0.698 AVG Training Acc 64.65 % AVG Validation Acc 60.74 %\n",
      "Epoch:60/200 AVG Training Loss:0.596 AVG Validation Loss:0.713 AVG Training Acc 65.69 % AVG Validation Acc 60.20 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.589 AVG Validation Loss:0.716 AVG Training Acc 66.36 % AVG Validation Acc 59.66 %\n",
      "Epoch:80/200 AVG Training Loss:0.589 AVG Validation Loss:0.720 AVG Training Acc 65.94 % AVG Validation Acc 59.93 %\n",
      "Epoch:90/200 AVG Training Loss:0.586 AVG Validation Loss:0.713 AVG Training Acc 66.27 % AVG Validation Acc 59.66 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.588 AVG Validation Loss:0.712 AVG Training Acc 66.17 % AVG Validation Acc 59.84 %\n",
      "Epoch:110/200 AVG Training Loss:0.586 AVG Validation Loss:0.717 AVG Training Acc 66.62 % AVG Validation Acc 59.84 %\n",
      "Epoch:120/200 AVG Training Loss:0.584 AVG Validation Loss:0.723 AVG Training Acc 66.67 % AVG Validation Acc 60.02 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.585 AVG Validation Loss:0.724 AVG Training Acc 66.39 % AVG Validation Acc 59.48 %\n",
      "Epoch:140/200 AVG Training Loss:0.584 AVG Validation Loss:0.720 AVG Training Acc 66.40 % AVG Validation Acc 60.02 %\n",
      "Epoch:150/200 AVG Training Loss:0.587 AVG Validation Loss:0.720 AVG Training Acc 66.34 % AVG Validation Acc 59.30 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.586 AVG Validation Loss:0.720 AVG Training Acc 66.77 % AVG Validation Acc 59.75 %\n",
      "Epoch:170/200 AVG Training Loss:0.586 AVG Validation Loss:0.717 AVG Training Acc 66.70 % AVG Validation Acc 60.47 %\n",
      "Epoch:180/200 AVG Training Loss:0.588 AVG Validation Loss:0.715 AVG Training Acc 66.71 % AVG Validation Acc 59.93 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.585 AVG Validation Loss:0.723 AVG Training Acc 66.08 % AVG Validation Acc 59.75 %\n",
      "Epoch:200/200 AVG Training Loss:0.584 AVG Validation Loss:0.717 AVG Training Acc 66.50 % AVG Validation Acc 59.84 %\n",
      "Split 68\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f9b76d94d6c421fabe2ffdfc2ec10f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.660 AVG Training Acc 61.98 % AVG Validation Acc 61.73 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.657 AVG Training Acc 62.03 % AVG Validation Acc 61.82 %\n",
      "Epoch:30/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 61.65 % AVG Validation Acc 61.73 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.636 AVG Validation Loss:0.660 AVG Training Acc 63.29 % AVG Validation Acc 61.28 %\n",
      "Epoch:50/200 AVG Training Loss:0.630 AVG Validation Loss:0.668 AVG Training Acc 64.06 % AVG Validation Acc 61.46 %\n",
      "Epoch:60/200 AVG Training Loss:0.621 AVG Validation Loss:0.672 AVG Training Acc 64.78 % AVG Validation Acc 60.74 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.615 AVG Validation Loss:0.673 AVG Training Acc 65.76 % AVG Validation Acc 60.56 %\n",
      "Epoch:80/200 AVG Training Loss:0.612 AVG Validation Loss:0.681 AVG Training Acc 66.07 % AVG Validation Acc 59.75 %\n",
      "Epoch:90/200 AVG Training Loss:0.612 AVG Validation Loss:0.678 AVG Training Acc 66.06 % AVG Validation Acc 60.29 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.611 AVG Validation Loss:0.680 AVG Training Acc 65.94 % AVG Validation Acc 60.29 %\n",
      "Epoch:110/200 AVG Training Loss:0.612 AVG Validation Loss:0.680 AVG Training Acc 66.62 % AVG Validation Acc 59.93 %\n",
      "Epoch:120/200 AVG Training Loss:0.610 AVG Validation Loss:0.681 AVG Training Acc 66.64 % AVG Validation Acc 59.93 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.612 AVG Validation Loss:0.678 AVG Training Acc 66.00 % AVG Validation Acc 60.02 %\n",
      "Epoch:140/200 AVG Training Loss:0.610 AVG Validation Loss:0.681 AVG Training Acc 65.97 % AVG Validation Acc 60.11 %\n",
      "Epoch:150/200 AVG Training Loss:0.611 AVG Validation Loss:0.680 AVG Training Acc 66.12 % AVG Validation Acc 60.29 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.610 AVG Validation Loss:0.681 AVG Training Acc 66.24 % AVG Validation Acc 60.38 %\n",
      "Epoch:170/200 AVG Training Loss:0.611 AVG Validation Loss:0.679 AVG Training Acc 65.82 % AVG Validation Acc 60.11 %\n",
      "Epoch:180/200 AVG Training Loss:0.612 AVG Validation Loss:0.680 AVG Training Acc 65.80 % AVG Validation Acc 60.29 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.613 AVG Validation Loss:0.678 AVG Training Acc 65.82 % AVG Validation Acc 59.93 %\n",
      "Epoch:200/200 AVG Training Loss:0.612 AVG Validation Loss:0.681 AVG Training Acc 66.21 % AVG Validation Acc 59.75 %\n",
      "Split 69\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46740e2ff0e44685aaf9205e4eabd586",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.657 AVG Training Acc 61.75 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.652 AVG Training Acc 61.73 % AVG Validation Acc 62.00 %\n",
      "Epoch:30/200 AVG Training Loss:0.643 AVG Validation Loss:0.655 AVG Training Acc 62.62 % AVG Validation Acc 62.64 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.623 AVG Validation Loss:0.654 AVG Training Acc 64.06 % AVG Validation Acc 62.55 %\n",
      "Epoch:50/200 AVG Training Loss:0.608 AVG Validation Loss:0.670 AVG Training Acc 64.91 % AVG Validation Acc 61.55 %\n",
      "Epoch:60/200 AVG Training Loss:0.598 AVG Validation Loss:0.678 AVG Training Acc 66.05 % AVG Validation Acc 62.18 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.593 AVG Validation Loss:0.687 AVG Training Acc 66.43 % AVG Validation Acc 61.37 %\n",
      "Epoch:80/200 AVG Training Loss:0.587 AVG Validation Loss:0.695 AVG Training Acc 66.34 % AVG Validation Acc 61.37 %\n",
      "Epoch:90/200 AVG Training Loss:0.586 AVG Validation Loss:0.696 AVG Training Acc 66.80 % AVG Validation Acc 61.37 %\n",
      "Epoch:100/200 AVG Training Loss:0.585 AVG Validation Loss:0.695 AVG Training Acc 66.76 % AVG Validation Acc 61.10 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.586 AVG Validation Loss:0.701 AVG Training Acc 66.88 % AVG Validation Acc 62.18 %\n",
      "Epoch:120/200 AVG Training Loss:0.587 AVG Validation Loss:0.702 AVG Training Acc 66.74 % AVG Validation Acc 61.37 %\n",
      "Epoch:130/200 AVG Training Loss:0.586 AVG Validation Loss:0.694 AVG Training Acc 66.47 % AVG Validation Acc 61.73 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.583 AVG Validation Loss:0.693 AVG Training Acc 66.65 % AVG Validation Acc 61.46 %\n",
      "Epoch:150/200 AVG Training Loss:0.585 AVG Validation Loss:0.696 AVG Training Acc 66.92 % AVG Validation Acc 61.37 %\n",
      "Epoch:160/200 AVG Training Loss:0.583 AVG Validation Loss:0.699 AVG Training Acc 67.19 % AVG Validation Acc 61.37 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.587 AVG Validation Loss:0.700 AVG Training Acc 66.60 % AVG Validation Acc 60.92 %\n",
      "Epoch:180/200 AVG Training Loss:0.585 AVG Validation Loss:0.692 AVG Training Acc 66.85 % AVG Validation Acc 61.01 %\n",
      "Epoch:190/200 AVG Training Loss:0.585 AVG Validation Loss:0.699 AVG Training Acc 66.43 % AVG Validation Acc 61.10 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.587 AVG Validation Loss:0.699 AVG Training Acc 66.38 % AVG Validation Acc 61.46 %\n",
      "Split 70\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c3c156cdd934ac6b27d7857206aee63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.658 AVG Training Acc 61.82 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.660 AVG Training Acc 62.09 % AVG Validation Acc 62.27 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.640 AVG Validation Loss:0.660 AVG Training Acc 62.68 % AVG Validation Acc 61.46 %\n",
      "Epoch:40/200 AVG Training Loss:0.624 AVG Validation Loss:0.676 AVG Training Acc 64.22 % AVG Validation Acc 61.28 %\n",
      "Epoch:50/200 AVG Training Loss:0.614 AVG Validation Loss:0.690 AVG Training Acc 64.66 % AVG Validation Acc 60.65 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.607 AVG Validation Loss:0.700 AVG Training Acc 65.31 % AVG Validation Acc 60.92 %\n",
      "Epoch:70/200 AVG Training Loss:0.603 AVG Validation Loss:0.701 AVG Training Acc 65.56 % AVG Validation Acc 59.84 %\n",
      "Epoch:80/200 AVG Training Loss:0.602 AVG Validation Loss:0.706 AVG Training Acc 65.69 % AVG Validation Acc 60.02 %\n",
      "Epoch:90/200 AVG Training Loss:0.601 AVG Validation Loss:0.704 AVG Training Acc 66.03 % AVG Validation Acc 60.29 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.599 AVG Validation Loss:0.703 AVG Training Acc 65.91 % AVG Validation Acc 60.47 %\n",
      "Epoch:110/200 AVG Training Loss:0.600 AVG Validation Loss:0.703 AVG Training Acc 65.72 % AVG Validation Acc 60.29 %\n",
      "Epoch:120/200 AVG Training Loss:0.597 AVG Validation Loss:0.704 AVG Training Acc 66.12 % AVG Validation Acc 60.65 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.599 AVG Validation Loss:0.707 AVG Training Acc 65.86 % AVG Validation Acc 59.84 %\n",
      "Epoch:140/200 AVG Training Loss:0.599 AVG Validation Loss:0.706 AVG Training Acc 66.27 % AVG Validation Acc 60.29 %\n",
      "Epoch:150/200 AVG Training Loss:0.599 AVG Validation Loss:0.705 AVG Training Acc 65.78 % AVG Validation Acc 60.56 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.602 AVG Validation Loss:0.705 AVG Training Acc 65.10 % AVG Validation Acc 60.38 %\n",
      "Epoch:170/200 AVG Training Loss:0.598 AVG Validation Loss:0.708 AVG Training Acc 65.80 % AVG Validation Acc 60.56 %\n",
      "Epoch:180/200 AVG Training Loss:0.600 AVG Validation Loss:0.707 AVG Training Acc 66.02 % AVG Validation Acc 60.65 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.599 AVG Validation Loss:0.706 AVG Training Acc 65.87 % AVG Validation Acc 60.20 %\n",
      "Epoch:200/200 AVG Training Loss:0.599 AVG Validation Loss:0.710 AVG Training Acc 66.29 % AVG Validation Acc 60.20 %\n",
      "Split 71\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c060f6789c1f4d35a3e2f3af292a8155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.663 AVG Validation Loss:0.655 AVG Training Acc 61.85 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.647 AVG Training Acc 61.77 % AVG Validation Acc 61.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.644 AVG Validation Loss:0.642 AVG Training Acc 62.23 % AVG Validation Acc 61.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.645 AVG Training Acc 62.17 % AVG Validation Acc 61.59 %\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.612 AVG Validation Loss:0.656 AVG Training Acc 63.53 % AVG Validation Acc 62.22 %\n",
      "Epoch:60/200 AVG Training Loss:0.602 AVG Validation Loss:0.655 AVG Training Acc 64.31 % AVG Validation Acc 62.22 %\n",
      "Epoch:70/200 AVG Training Loss:0.590 AVG Validation Loss:0.662 AVG Training Acc 65.37 % AVG Validation Acc 62.94 %\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.588 AVG Validation Loss:0.672 AVG Training Acc 65.70 % AVG Validation Acc 62.04 %\n",
      "Epoch:90/200 AVG Training Loss:0.585 AVG Validation Loss:0.665 AVG Training Acc 65.62 % AVG Validation Acc 62.40 %\n",
      "Epoch:100/200 AVG Training Loss:0.581 AVG Validation Loss:0.671 AVG Training Acc 65.73 % AVG Validation Acc 62.13 %\n",
      "Epoch   106: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.582 AVG Validation Loss:0.669 AVG Training Acc 66.08 % AVG Validation Acc 62.58 %\n",
      "Epoch:120/200 AVG Training Loss:0.583 AVG Validation Loss:0.672 AVG Training Acc 65.69 % AVG Validation Acc 62.22 %\n",
      "Epoch:130/200 AVG Training Loss:0.582 AVG Validation Loss:0.678 AVG Training Acc 66.14 % AVG Validation Acc 62.22 %\n",
      "Epoch   137: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.583 AVG Validation Loss:0.673 AVG Training Acc 66.15 % AVG Validation Acc 62.13 %\n",
      "Epoch:150/200 AVG Training Loss:0.583 AVG Validation Loss:0.674 AVG Training Acc 66.11 % AVG Validation Acc 61.86 %\n",
      "Epoch:160/200 AVG Training Loss:0.584 AVG Validation Loss:0.674 AVG Training Acc 65.68 % AVG Validation Acc 62.67 %\n",
      "Epoch   168: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.581 AVG Validation Loss:0.677 AVG Training Acc 66.09 % AVG Validation Acc 63.21 %\n",
      "Epoch:180/200 AVG Training Loss:0.582 AVG Validation Loss:0.679 AVG Training Acc 66.04 % AVG Validation Acc 62.58 %\n",
      "Epoch:190/200 AVG Training Loss:0.583 AVG Validation Loss:0.671 AVG Training Acc 65.49 % AVG Validation Acc 62.04 %\n",
      "Epoch   199: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.582 AVG Validation Loss:0.677 AVG Training Acc 65.89 % AVG Validation Acc 62.13 %\n",
      "Split 72\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b5a72c840404546bb2552f6d8df92b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.660 AVG Training Acc 61.73 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.650 AVG Validation Loss:0.651 AVG Training Acc 62.20 % AVG Validation Acc 62.94 %\n",
      "Epoch:30/200 AVG Training Loss:0.640 AVG Validation Loss:0.662 AVG Training Acc 62.68 % AVG Validation Acc 62.31 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.614 AVG Validation Loss:0.678 AVG Training Acc 64.85 % AVG Validation Acc 61.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.605 AVG Validation Loss:0.687 AVG Training Acc 65.57 % AVG Validation Acc 61.86 %\n",
      "Epoch:60/200 AVG Training Loss:0.598 AVG Validation Loss:0.688 AVG Training Acc 65.82 % AVG Validation Acc 60.78 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.590 AVG Validation Loss:0.689 AVG Training Acc 66.54 % AVG Validation Acc 62.04 %\n",
      "Epoch:80/200 AVG Training Loss:0.590 AVG Validation Loss:0.693 AVG Training Acc 66.75 % AVG Validation Acc 61.41 %\n",
      "Epoch:90/200 AVG Training Loss:0.587 AVG Validation Loss:0.691 AVG Training Acc 66.53 % AVG Validation Acc 61.77 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.589 AVG Validation Loss:0.697 AVG Training Acc 67.06 % AVG Validation Acc 60.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.590 AVG Validation Loss:0.696 AVG Training Acc 66.36 % AVG Validation Acc 61.59 %\n",
      "Epoch:120/200 AVG Training Loss:0.586 AVG Validation Loss:0.694 AVG Training Acc 66.94 % AVG Validation Acc 61.68 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.587 AVG Validation Loss:0.696 AVG Training Acc 66.82 % AVG Validation Acc 61.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.587 AVG Validation Loss:0.698 AVG Training Acc 66.67 % AVG Validation Acc 61.59 %\n",
      "Epoch:150/200 AVG Training Loss:0.589 AVG Validation Loss:0.696 AVG Training Acc 66.25 % AVG Validation Acc 60.78 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.589 AVG Validation Loss:0.694 AVG Training Acc 66.70 % AVG Validation Acc 61.23 %\n",
      "Epoch:170/200 AVG Training Loss:0.587 AVG Validation Loss:0.699 AVG Training Acc 66.65 % AVG Validation Acc 61.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.588 AVG Validation Loss:0.695 AVG Training Acc 66.72 % AVG Validation Acc 61.50 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.589 AVG Validation Loss:0.691 AVG Training Acc 66.71 % AVG Validation Acc 61.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.588 AVG Validation Loss:0.698 AVG Training Acc 67.27 % AVG Validation Acc 61.59 %\n",
      "Split 73\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c40b35fb172241a5942faf2b06262e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.660 AVG Training Acc 61.72 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.656 AVG Training Acc 62.07 % AVG Validation Acc 62.13 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 61.91 % AVG Validation Acc 61.77 %\n",
      "Epoch:40/200 AVG Training Loss:0.655 AVG Validation Loss:0.660 AVG Training Acc 61.99 % AVG Validation Acc 61.59 %\n",
      "Epoch:50/200 AVG Training Loss:0.647 AVG Validation Loss:0.662 AVG Training Acc 63.13 % AVG Validation Acc 62.22 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.642 AVG Validation Loss:0.663 AVG Training Acc 63.13 % AVG Validation Acc 62.13 %\n",
      "Epoch:70/200 AVG Training Loss:0.640 AVG Validation Loss:0.666 AVG Training Acc 63.31 % AVG Validation Acc 62.31 %\n",
      "Epoch:80/200 AVG Training Loss:0.638 AVG Validation Loss:0.667 AVG Training Acc 63.98 % AVG Validation Acc 62.58 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.637 AVG Validation Loss:0.667 AVG Training Acc 63.89 % AVG Validation Acc 62.22 %\n",
      "Epoch:100/200 AVG Training Loss:0.639 AVG Validation Loss:0.668 AVG Training Acc 63.76 % AVG Validation Acc 62.31 %\n",
      "Epoch:110/200 AVG Training Loss:0.636 AVG Validation Loss:0.667 AVG Training Acc 64.05 % AVG Validation Acc 62.31 %\n",
      "Epoch:120/200 AVG Training Loss:0.639 AVG Validation Loss:0.668 AVG Training Acc 63.75 % AVG Validation Acc 62.49 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.639 AVG Validation Loss:0.668 AVG Training Acc 63.57 % AVG Validation Acc 62.58 %\n",
      "Epoch:140/200 AVG Training Loss:0.636 AVG Validation Loss:0.668 AVG Training Acc 63.87 % AVG Validation Acc 62.13 %\n",
      "Epoch:150/200 AVG Training Loss:0.637 AVG Validation Loss:0.668 AVG Training Acc 64.07 % AVG Validation Acc 62.40 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.637 AVG Validation Loss:0.668 AVG Training Acc 63.85 % AVG Validation Acc 62.22 %\n",
      "Epoch:170/200 AVG Training Loss:0.638 AVG Validation Loss:0.668 AVG Training Acc 63.99 % AVG Validation Acc 62.40 %\n",
      "Epoch:180/200 AVG Training Loss:0.636 AVG Validation Loss:0.668 AVG Training Acc 64.01 % AVG Validation Acc 62.13 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.637 AVG Validation Loss:0.668 AVG Training Acc 63.76 % AVG Validation Acc 62.22 %\n",
      "Epoch:200/200 AVG Training Loss:0.637 AVG Validation Loss:0.667 AVG Training Acc 63.78 % AVG Validation Acc 62.31 %\n",
      "Split 74\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c49c8b60bccb49bda45417408f2c006a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.657 AVG Training Acc 61.84 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.650 AVG Validation Loss:0.656 AVG Training Acc 62.04 % AVG Validation Acc 61.77 %\n",
      "Epoch:30/200 AVG Training Loss:0.644 AVG Validation Loss:0.664 AVG Training Acc 61.91 % AVG Validation Acc 61.05 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.615 AVG Validation Loss:0.679 AVG Training Acc 64.13 % AVG Validation Acc 60.87 %\n",
      "Epoch:50/200 AVG Training Loss:0.604 AVG Validation Loss:0.686 AVG Training Acc 65.55 % AVG Validation Acc 59.87 %\n",
      "Epoch:60/200 AVG Training Loss:0.592 AVG Validation Loss:0.706 AVG Training Acc 65.92 % AVG Validation Acc 59.87 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.584 AVG Validation Loss:0.709 AVG Training Acc 66.35 % AVG Validation Acc 57.80 %\n",
      "Epoch:80/200 AVG Training Loss:0.580 AVG Validation Loss:0.717 AVG Training Acc 67.26 % AVG Validation Acc 57.35 %\n",
      "Epoch:90/200 AVG Training Loss:0.581 AVG Validation Loss:0.720 AVG Training Acc 67.35 % AVG Validation Acc 56.63 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.582 AVG Validation Loss:0.720 AVG Training Acc 66.99 % AVG Validation Acc 56.63 %\n",
      "Epoch:110/200 AVG Training Loss:0.579 AVG Validation Loss:0.718 AVG Training Acc 67.21 % AVG Validation Acc 56.63 %\n",
      "Epoch:120/200 AVG Training Loss:0.583 AVG Validation Loss:0.719 AVG Training Acc 67.14 % AVG Validation Acc 56.90 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.581 AVG Validation Loss:0.710 AVG Training Acc 66.79 % AVG Validation Acc 57.08 %\n",
      "Epoch:140/200 AVG Training Loss:0.580 AVG Validation Loss:0.712 AVG Training Acc 67.25 % AVG Validation Acc 58.07 %\n",
      "Epoch:150/200 AVG Training Loss:0.581 AVG Validation Loss:0.715 AVG Training Acc 66.58 % AVG Validation Acc 56.99 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.580 AVG Validation Loss:0.719 AVG Training Acc 67.14 % AVG Validation Acc 58.25 %\n",
      "Epoch:170/200 AVG Training Loss:0.579 AVG Validation Loss:0.719 AVG Training Acc 67.38 % AVG Validation Acc 56.90 %\n",
      "Epoch:180/200 AVG Training Loss:0.581 AVG Validation Loss:0.720 AVG Training Acc 67.34 % AVG Validation Acc 56.99 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.580 AVG Validation Loss:0.712 AVG Training Acc 67.31 % AVG Validation Acc 56.90 %\n",
      "Epoch:200/200 AVG Training Loss:0.581 AVG Validation Loss:0.722 AVG Training Acc 67.02 % AVG Validation Acc 56.54 %\n",
      "Split 75\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d05537915fb4eeb9084e92348fdb569",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.654 AVG Training Acc 61.89 % AVG Validation Acc 61.77 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.653 AVG Training Acc 61.72 % AVG Validation Acc 61.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.650 AVG Validation Loss:0.656 AVG Training Acc 62.00 % AVG Validation Acc 60.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.640 AVG Validation Loss:0.657 AVG Training Acc 63.06 % AVG Validation Acc 61.68 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.617 AVG Validation Loss:0.667 AVG Training Acc 64.79 % AVG Validation Acc 63.21 %\n",
      "Epoch:60/200 AVG Training Loss:0.607 AVG Validation Loss:0.672 AVG Training Acc 65.65 % AVG Validation Acc 61.59 %\n",
      "Epoch:70/200 AVG Training Loss:0.602 AVG Validation Loss:0.677 AVG Training Acc 65.87 % AVG Validation Acc 60.69 %\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.594 AVG Validation Loss:0.680 AVG Training Acc 66.44 % AVG Validation Acc 60.87 %\n",
      "Epoch:90/200 AVG Training Loss:0.593 AVG Validation Loss:0.680 AVG Training Acc 67.02 % AVG Validation Acc 60.23 %\n",
      "Epoch:100/200 AVG Training Loss:0.594 AVG Validation Loss:0.683 AVG Training Acc 66.60 % AVG Validation Acc 60.60 %\n",
      "Epoch   104: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.593 AVG Validation Loss:0.675 AVG Training Acc 67.05 % AVG Validation Acc 61.14 %\n",
      "Epoch:120/200 AVG Training Loss:0.592 AVG Validation Loss:0.681 AVG Training Acc 66.77 % AVG Validation Acc 61.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.594 AVG Validation Loss:0.679 AVG Training Acc 66.12 % AVG Validation Acc 60.96 %\n",
      "Epoch   135: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.592 AVG Validation Loss:0.679 AVG Training Acc 66.78 % AVG Validation Acc 61.32 %\n",
      "Epoch:150/200 AVG Training Loss:0.593 AVG Validation Loss:0.678 AVG Training Acc 66.51 % AVG Validation Acc 60.96 %\n",
      "Epoch:160/200 AVG Training Loss:0.591 AVG Validation Loss:0.677 AVG Training Acc 67.12 % AVG Validation Acc 61.50 %\n",
      "Epoch   166: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.593 AVG Validation Loss:0.681 AVG Training Acc 66.39 % AVG Validation Acc 60.69 %\n",
      "Epoch:180/200 AVG Training Loss:0.593 AVG Validation Loss:0.680 AVG Training Acc 66.62 % AVG Validation Acc 61.50 %\n",
      "Epoch:190/200 AVG Training Loss:0.591 AVG Validation Loss:0.677 AVG Training Acc 66.90 % AVG Validation Acc 60.69 %\n",
      "Epoch   197: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.592 AVG Validation Loss:0.679 AVG Training Acc 66.54 % AVG Validation Acc 60.41 %\n",
      "Split 76\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "960388d7104d44c594bec34b59e948ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.657 AVG Validation Loss:0.662 AVG Training Acc 61.91 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.646 AVG Validation Loss:0.662 AVG Training Acc 61.82 % AVG Validation Acc 61.28 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.616 AVG Validation Loss:0.687 AVG Training Acc 64.62 % AVG Validation Acc 58.75 %\n",
      "Epoch:40/200 AVG Training Loss:0.599 AVG Validation Loss:0.707 AVG Training Acc 65.75 % AVG Validation Acc 58.84 %\n",
      "Epoch:50/200 AVG Training Loss:0.589 AVG Validation Loss:0.706 AVG Training Acc 66.74 % AVG Validation Acc 59.48 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.576 AVG Validation Loss:0.723 AVG Training Acc 67.08 % AVG Validation Acc 59.03 %\n",
      "Epoch:70/200 AVG Training Loss:0.572 AVG Validation Loss:0.732 AVG Training Acc 67.54 % AVG Validation Acc 58.94 %\n",
      "Epoch:80/200 AVG Training Loss:0.571 AVG Validation Loss:0.729 AVG Training Acc 67.91 % AVG Validation Acc 59.39 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.568 AVG Validation Loss:0.735 AVG Training Acc 68.11 % AVG Validation Acc 58.94 %\n",
      "Epoch:100/200 AVG Training Loss:0.568 AVG Validation Loss:0.738 AVG Training Acc 67.76 % AVG Validation Acc 58.39 %\n",
      "Epoch:110/200 AVG Training Loss:0.567 AVG Validation Loss:0.736 AVG Training Acc 67.72 % AVG Validation Acc 58.30 %\n",
      "Epoch:120/200 AVG Training Loss:0.569 AVG Validation Loss:0.732 AVG Training Acc 67.98 % AVG Validation Acc 59.21 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.568 AVG Validation Loss:0.736 AVG Training Acc 67.97 % AVG Validation Acc 59.75 %\n",
      "Epoch:140/200 AVG Training Loss:0.571 AVG Validation Loss:0.731 AVG Training Acc 67.58 % AVG Validation Acc 58.84 %\n",
      "Epoch:150/200 AVG Training Loss:0.568 AVG Validation Loss:0.730 AVG Training Acc 68.12 % AVG Validation Acc 58.75 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.568 AVG Validation Loss:0.731 AVG Training Acc 67.88 % AVG Validation Acc 58.75 %\n",
      "Epoch:170/200 AVG Training Loss:0.571 AVG Validation Loss:0.736 AVG Training Acc 68.03 % AVG Validation Acc 59.57 %\n",
      "Epoch:180/200 AVG Training Loss:0.568 AVG Validation Loss:0.736 AVG Training Acc 67.79 % AVG Validation Acc 59.12 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.569 AVG Validation Loss:0.729 AVG Training Acc 67.73 % AVG Validation Acc 58.30 %\n",
      "Epoch:200/200 AVG Training Loss:0.567 AVG Validation Loss:0.733 AVG Training Acc 67.96 % AVG Validation Acc 58.66 %\n",
      "Split 77\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "483da5a1d8a14746bddde506a5d24741",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.661 AVG Training Acc 61.63 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.658 AVG Training Acc 61.79 % AVG Validation Acc 62.64 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.638 AVG Validation Loss:0.662 AVG Training Acc 62.30 % AVG Validation Acc 63.18 %\n",
      "Epoch:40/200 AVG Training Loss:0.628 AVG Validation Loss:0.668 AVG Training Acc 63.45 % AVG Validation Acc 63.09 %\n",
      "Epoch:50/200 AVG Training Loss:0.620 AVG Validation Loss:0.672 AVG Training Acc 63.64 % AVG Validation Acc 63.18 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.609 AVG Validation Loss:0.675 AVG Training Acc 65.05 % AVG Validation Acc 62.09 %\n",
      "Epoch:70/200 AVG Training Loss:0.610 AVG Validation Loss:0.673 AVG Training Acc 64.91 % AVG Validation Acc 62.45 %\n",
      "Epoch:80/200 AVG Training Loss:0.606 AVG Validation Loss:0.678 AVG Training Acc 64.91 % AVG Validation Acc 63.18 %\n",
      "Epoch:90/200 AVG Training Loss:0.606 AVG Validation Loss:0.676 AVG Training Acc 64.90 % AVG Validation Acc 62.64 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.607 AVG Validation Loss:0.678 AVG Training Acc 64.96 % AVG Validation Acc 62.91 %\n",
      "Epoch:110/200 AVG Training Loss:0.606 AVG Validation Loss:0.677 AVG Training Acc 64.76 % AVG Validation Acc 63.00 %\n",
      "Epoch:120/200 AVG Training Loss:0.605 AVG Validation Loss:0.674 AVG Training Acc 64.94 % AVG Validation Acc 63.27 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.605 AVG Validation Loss:0.673 AVG Training Acc 65.23 % AVG Validation Acc 63.09 %\n",
      "Epoch:140/200 AVG Training Loss:0.606 AVG Validation Loss:0.677 AVG Training Acc 64.69 % AVG Validation Acc 63.09 %\n",
      "Epoch:150/200 AVG Training Loss:0.607 AVG Validation Loss:0.679 AVG Training Acc 65.15 % AVG Validation Acc 62.27 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.606 AVG Validation Loss:0.677 AVG Training Acc 65.00 % AVG Validation Acc 62.73 %\n",
      "Epoch:170/200 AVG Training Loss:0.608 AVG Validation Loss:0.679 AVG Training Acc 64.92 % AVG Validation Acc 62.91 %\n",
      "Epoch:180/200 AVG Training Loss:0.605 AVG Validation Loss:0.676 AVG Training Acc 64.84 % AVG Validation Acc 63.00 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.605 AVG Validation Loss:0.682 AVG Training Acc 65.14 % AVG Validation Acc 62.82 %\n",
      "Epoch:200/200 AVG Training Loss:0.606 AVG Validation Loss:0.676 AVG Training Acc 64.82 % AVG Validation Acc 62.73 %\n",
      "Split 78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4763ae91c27d44f19932a7d4e106e6b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 61.81 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.653 AVG Training Acc 61.92 % AVG Validation Acc 62.82 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.639 AVG Validation Loss:0.658 AVG Training Acc 62.81 % AVG Validation Acc 61.10 %\n",
      "Epoch:40/200 AVG Training Loss:0.626 AVG Validation Loss:0.668 AVG Training Acc 64.07 % AVG Validation Acc 60.92 %\n",
      "Epoch:50/200 AVG Training Loss:0.618 AVG Validation Loss:0.676 AVG Training Acc 64.55 % AVG Validation Acc 61.55 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.611 AVG Validation Loss:0.686 AVG Training Acc 65.38 % AVG Validation Acc 60.74 %\n",
      "Epoch:70/200 AVG Training Loss:0.608 AVG Validation Loss:0.690 AVG Training Acc 65.51 % AVG Validation Acc 61.28 %\n",
      "Epoch:80/200 AVG Training Loss:0.605 AVG Validation Loss:0.689 AVG Training Acc 65.87 % AVG Validation Acc 61.01 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.606 AVG Validation Loss:0.690 AVG Training Acc 65.88 % AVG Validation Acc 61.10 %\n",
      "Epoch:100/200 AVG Training Loss:0.605 AVG Validation Loss:0.691 AVG Training Acc 65.62 % AVG Validation Acc 61.19 %\n",
      "Epoch:110/200 AVG Training Loss:0.604 AVG Validation Loss:0.691 AVG Training Acc 66.30 % AVG Validation Acc 60.83 %\n",
      "Epoch:120/200 AVG Training Loss:0.604 AVG Validation Loss:0.690 AVG Training Acc 65.93 % AVG Validation Acc 61.55 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.605 AVG Validation Loss:0.692 AVG Training Acc 65.87 % AVG Validation Acc 61.46 %\n",
      "Epoch:140/200 AVG Training Loss:0.604 AVG Validation Loss:0.689 AVG Training Acc 65.66 % AVG Validation Acc 61.19 %\n",
      "Epoch:150/200 AVG Training Loss:0.605 AVG Validation Loss:0.691 AVG Training Acc 65.78 % AVG Validation Acc 61.91 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.606 AVG Validation Loss:0.690 AVG Training Acc 65.71 % AVG Validation Acc 61.19 %\n",
      "Epoch:170/200 AVG Training Loss:0.605 AVG Validation Loss:0.693 AVG Training Acc 65.74 % AVG Validation Acc 61.46 %\n",
      "Epoch:180/200 AVG Training Loss:0.605 AVG Validation Loss:0.690 AVG Training Acc 65.49 % AVG Validation Acc 61.64 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.607 AVG Validation Loss:0.692 AVG Training Acc 65.22 % AVG Validation Acc 61.19 %\n",
      "Epoch:200/200 AVG Training Loss:0.605 AVG Validation Loss:0.688 AVG Training Acc 65.83 % AVG Validation Acc 61.28 %\n",
      "Split 79\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a3035de67d74648819697666491bed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.663 AVG Training Acc 62.01 % AVG Validation Acc 61.82 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.660 AVG Training Acc 61.54 % AVG Validation Acc 61.73 %\n",
      "Epoch:30/200 AVG Training Loss:0.639 AVG Validation Loss:0.666 AVG Training Acc 62.85 % AVG Validation Acc 58.94 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.617 AVG Validation Loss:0.690 AVG Training Acc 64.10 % AVG Validation Acc 58.21 %\n",
      "Epoch:50/200 AVG Training Loss:0.603 AVG Validation Loss:0.709 AVG Training Acc 65.27 % AVG Validation Acc 58.84 %\n",
      "Epoch:60/200 AVG Training Loss:0.593 AVG Validation Loss:0.717 AVG Training Acc 65.94 % AVG Validation Acc 59.39 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.588 AVG Validation Loss:0.717 AVG Training Acc 66.35 % AVG Validation Acc 58.12 %\n",
      "Epoch:80/200 AVG Training Loss:0.584 AVG Validation Loss:0.736 AVG Training Acc 66.55 % AVG Validation Acc 58.21 %\n",
      "Epoch:90/200 AVG Training Loss:0.586 AVG Validation Loss:0.755 AVG Training Acc 65.93 % AVG Validation Acc 58.12 %\n",
      "Epoch:100/200 AVG Training Loss:0.582 AVG Validation Loss:0.740 AVG Training Acc 66.34 % AVG Validation Acc 56.95 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.581 AVG Validation Loss:0.742 AVG Training Acc 66.95 % AVG Validation Acc 58.21 %\n",
      "Epoch:120/200 AVG Training Loss:0.581 AVG Validation Loss:0.744 AVG Training Acc 66.62 % AVG Validation Acc 58.12 %\n",
      "Epoch:130/200 AVG Training Loss:0.583 AVG Validation Loss:0.742 AVG Training Acc 66.51 % AVG Validation Acc 58.57 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.583 AVG Validation Loss:0.747 AVG Training Acc 66.75 % AVG Validation Acc 58.21 %\n",
      "Epoch:150/200 AVG Training Loss:0.581 AVG Validation Loss:0.736 AVG Training Acc 66.90 % AVG Validation Acc 57.85 %\n",
      "Epoch:160/200 AVG Training Loss:0.581 AVG Validation Loss:0.748 AVG Training Acc 67.01 % AVG Validation Acc 57.49 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.580 AVG Validation Loss:0.749 AVG Training Acc 66.59 % AVG Validation Acc 58.12 %\n",
      "Epoch:180/200 AVG Training Loss:0.582 AVG Validation Loss:0.747 AVG Training Acc 66.28 % AVG Validation Acc 57.49 %\n",
      "Epoch:190/200 AVG Training Loss:0.582 AVG Validation Loss:0.750 AVG Training Acc 66.72 % AVG Validation Acc 57.85 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.583 AVG Validation Loss:0.743 AVG Training Acc 66.72 % AVG Validation Acc 58.30 %\n",
      "Split 80\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59252ffaca9447f8a3cc23ded853da03",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.660 AVG Training Acc 61.73 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.655 AVG Training Acc 61.87 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.644 AVG Validation Loss:0.656 AVG Training Acc 61.64 % AVG Validation Acc 61.37 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.621 AVG Validation Loss:0.660 AVG Training Acc 63.80 % AVG Validation Acc 61.37 %\n",
      "Epoch:50/200 AVG Training Loss:0.604 AVG Validation Loss:0.669 AVG Training Acc 64.87 % AVG Validation Acc 62.82 %\n",
      "Epoch:60/200 AVG Training Loss:0.594 AVG Validation Loss:0.674 AVG Training Acc 65.69 % AVG Validation Acc 63.27 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.586 AVG Validation Loss:0.686 AVG Training Acc 65.56 % AVG Validation Acc 63.36 %\n",
      "Epoch:80/200 AVG Training Loss:0.585 AVG Validation Loss:0.691 AVG Training Acc 66.28 % AVG Validation Acc 63.90 %\n",
      "Epoch:90/200 AVG Training Loss:0.583 AVG Validation Loss:0.699 AVG Training Acc 65.94 % AVG Validation Acc 63.72 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.582 AVG Validation Loss:0.700 AVG Training Acc 66.32 % AVG Validation Acc 63.18 %\n",
      "New Best Accuracy found: 64.08%\n",
      "Epoch: 104\n",
      "Epoch:110/200 AVG Training Loss:0.582 AVG Validation Loss:0.696 AVG Training Acc 65.92 % AVG Validation Acc 63.27 %\n",
      "New Best Accuracy found: 64.26%\n",
      "Epoch: 113\n",
      "Epoch:120/200 AVG Training Loss:0.582 AVG Validation Loss:0.697 AVG Training Acc 66.40 % AVG Validation Acc 63.09 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.580 AVG Validation Loss:0.698 AVG Training Acc 66.56 % AVG Validation Acc 63.36 %\n",
      "Epoch:140/200 AVG Training Loss:0.583 AVG Validation Loss:0.693 AVG Training Acc 65.84 % AVG Validation Acc 63.18 %\n",
      "New Best Accuracy found: 64.35%\n",
      "Epoch: 141\n",
      "Epoch:150/200 AVG Training Loss:0.583 AVG Validation Loss:0.699 AVG Training Acc 66.14 % AVG Validation Acc 63.54 %\n",
      "Epoch:160/200 AVG Training Loss:0.580 AVG Validation Loss:0.694 AVG Training Acc 66.14 % AVG Validation Acc 63.54 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.581 AVG Validation Loss:0.699 AVG Training Acc 66.30 % AVG Validation Acc 63.27 %\n",
      "Epoch:180/200 AVG Training Loss:0.581 AVG Validation Loss:0.700 AVG Training Acc 66.25 % AVG Validation Acc 63.63 %\n",
      "Epoch:190/200 AVG Training Loss:0.579 AVG Validation Loss:0.695 AVG Training Acc 66.16 % AVG Validation Acc 63.09 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.582 AVG Validation Loss:0.698 AVG Training Acc 66.39 % AVG Validation Acc 63.90 %\n",
      "Split 81\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "768e40bc25c54469832e18dd5d1c2dee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.656 AVG Training Acc 61.83 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.648 AVG Training Acc 61.84 % AVG Validation Acc 62.31 %\n",
      "Epoch:30/200 AVG Training Loss:0.641 AVG Validation Loss:0.645 AVG Training Acc 61.97 % AVG Validation Acc 62.67 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.613 AVG Validation Loss:0.660 AVG Training Acc 64.32 % AVG Validation Acc 62.22 %\n",
      "Epoch:50/200 AVG Training Loss:0.602 AVG Validation Loss:0.675 AVG Training Acc 65.17 % AVG Validation Acc 61.59 %\n",
      "Epoch:60/200 AVG Training Loss:0.590 AVG Validation Loss:0.682 AVG Training Acc 66.50 % AVG Validation Acc 61.68 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.581 AVG Validation Loss:0.691 AVG Training Acc 66.85 % AVG Validation Acc 61.41 %\n",
      "Epoch:80/200 AVG Training Loss:0.579 AVG Validation Loss:0.699 AVG Training Acc 67.17 % AVG Validation Acc 61.32 %\n",
      "Epoch:90/200 AVG Training Loss:0.579 AVG Validation Loss:0.700 AVG Training Acc 66.78 % AVG Validation Acc 61.32 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.577 AVG Validation Loss:0.701 AVG Training Acc 67.09 % AVG Validation Acc 60.96 %\n",
      "Epoch:110/200 AVG Training Loss:0.574 AVG Validation Loss:0.694 AVG Training Acc 67.11 % AVG Validation Acc 60.96 %\n",
      "Epoch:120/200 AVG Training Loss:0.577 AVG Validation Loss:0.700 AVG Training Acc 67.09 % AVG Validation Acc 61.77 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.575 AVG Validation Loss:0.698 AVG Training Acc 67.14 % AVG Validation Acc 60.69 %\n",
      "Epoch:140/200 AVG Training Loss:0.576 AVG Validation Loss:0.698 AVG Training Acc 67.11 % AVG Validation Acc 61.68 %\n",
      "Epoch:150/200 AVG Training Loss:0.575 AVG Validation Loss:0.701 AVG Training Acc 66.70 % AVG Validation Acc 61.23 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.577 AVG Validation Loss:0.701 AVG Training Acc 66.72 % AVG Validation Acc 60.69 %\n",
      "Epoch:170/200 AVG Training Loss:0.578 AVG Validation Loss:0.700 AVG Training Acc 66.60 % AVG Validation Acc 60.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.575 AVG Validation Loss:0.694 AVG Training Acc 67.20 % AVG Validation Acc 60.87 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.573 AVG Validation Loss:0.700 AVG Training Acc 66.98 % AVG Validation Acc 61.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.575 AVG Validation Loss:0.697 AVG Training Acc 67.15 % AVG Validation Acc 61.50 %\n",
      "Split 82\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fda7fcd96e374d56983478f015b2e734",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.661 AVG Training Acc 61.73 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.661 AVG Training Acc 62.09 % AVG Validation Acc 61.41 %\n",
      "Epoch:30/200 AVG Training Loss:0.645 AVG Validation Loss:0.668 AVG Training Acc 62.34 % AVG Validation Acc 61.86 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.629 AVG Validation Loss:0.668 AVG Training Acc 62.68 % AVG Validation Acc 61.59 %\n",
      "Epoch:50/200 AVG Training Loss:0.620 AVG Validation Loss:0.678 AVG Training Acc 63.17 % AVG Validation Acc 62.49 %\n",
      "Epoch:60/200 AVG Training Loss:0.610 AVG Validation Loss:0.685 AVG Training Acc 64.12 % AVG Validation Acc 62.31 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.603 AVG Validation Loss:0.692 AVG Training Acc 64.37 % AVG Validation Acc 61.50 %\n",
      "Epoch:80/200 AVG Training Loss:0.602 AVG Validation Loss:0.698 AVG Training Acc 64.88 % AVG Validation Acc 61.05 %\n",
      "Epoch:90/200 AVG Training Loss:0.600 AVG Validation Loss:0.701 AVG Training Acc 64.74 % AVG Validation Acc 61.77 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.598 AVG Validation Loss:0.700 AVG Training Acc 64.93 % AVG Validation Acc 61.23 %\n",
      "Epoch:110/200 AVG Training Loss:0.600 AVG Validation Loss:0.702 AVG Training Acc 64.53 % AVG Validation Acc 61.32 %\n",
      "Epoch:120/200 AVG Training Loss:0.599 AVG Validation Loss:0.701 AVG Training Acc 64.26 % AVG Validation Acc 61.41 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.601 AVG Validation Loss:0.702 AVG Training Acc 64.30 % AVG Validation Acc 61.68 %\n",
      "Epoch:140/200 AVG Training Loss:0.600 AVG Validation Loss:0.702 AVG Training Acc 64.90 % AVG Validation Acc 61.41 %\n",
      "Epoch:150/200 AVG Training Loss:0.599 AVG Validation Loss:0.696 AVG Training Acc 64.40 % AVG Validation Acc 60.96 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.598 AVG Validation Loss:0.701 AVG Training Acc 64.10 % AVG Validation Acc 61.41 %\n",
      "Epoch:170/200 AVG Training Loss:0.598 AVG Validation Loss:0.701 AVG Training Acc 64.31 % AVG Validation Acc 61.59 %\n",
      "Epoch:180/200 AVG Training Loss:0.600 AVG Validation Loss:0.703 AVG Training Acc 64.04 % AVG Validation Acc 61.41 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.599 AVG Validation Loss:0.699 AVG Training Acc 63.84 % AVG Validation Acc 61.68 %\n",
      "Epoch:200/200 AVG Training Loss:0.600 AVG Validation Loss:0.703 AVG Training Acc 64.34 % AVG Validation Acc 61.41 %\n",
      "Split 83\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8371d3b49f2a4240b271ecbf6c1c0154",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.665 AVG Training Acc 61.86 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.666 AVG Training Acc 61.94 % AVG Validation Acc 61.86 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.636 AVG Validation Loss:0.658 AVG Training Acc 62.49 % AVG Validation Acc 61.23 %\n",
      "Epoch:40/200 AVG Training Loss:0.628 AVG Validation Loss:0.659 AVG Training Acc 63.33 % AVG Validation Acc 61.23 %\n",
      "Epoch:50/200 AVG Training Loss:0.622 AVG Validation Loss:0.666 AVG Training Acc 63.48 % AVG Validation Acc 60.87 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.617 AVG Validation Loss:0.668 AVG Training Acc 64.23 % AVG Validation Acc 60.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.615 AVG Validation Loss:0.668 AVG Training Acc 64.25 % AVG Validation Acc 60.69 %\n",
      "Epoch:80/200 AVG Training Loss:0.615 AVG Validation Loss:0.671 AVG Training Acc 64.63 % AVG Validation Acc 60.69 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.613 AVG Validation Loss:0.671 AVG Training Acc 64.55 % AVG Validation Acc 60.69 %\n",
      "Epoch:100/200 AVG Training Loss:0.613 AVG Validation Loss:0.666 AVG Training Acc 64.42 % AVG Validation Acc 61.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.612 AVG Validation Loss:0.671 AVG Training Acc 64.30 % AVG Validation Acc 60.60 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.612 AVG Validation Loss:0.673 AVG Training Acc 64.52 % AVG Validation Acc 60.69 %\n",
      "Epoch:130/200 AVG Training Loss:0.613 AVG Validation Loss:0.669 AVG Training Acc 64.49 % AVG Validation Acc 60.69 %\n",
      "Epoch:140/200 AVG Training Loss:0.612 AVG Validation Loss:0.671 AVG Training Acc 64.72 % AVG Validation Acc 60.41 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.613 AVG Validation Loss:0.671 AVG Training Acc 64.30 % AVG Validation Acc 60.05 %\n",
      "Epoch:160/200 AVG Training Loss:0.615 AVG Validation Loss:0.672 AVG Training Acc 64.33 % AVG Validation Acc 60.69 %\n",
      "Epoch:170/200 AVG Training Loss:0.616 AVG Validation Loss:0.670 AVG Training Acc 64.24 % AVG Validation Acc 61.32 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.614 AVG Validation Loss:0.669 AVG Training Acc 64.30 % AVG Validation Acc 60.32 %\n",
      "Epoch:190/200 AVG Training Loss:0.613 AVG Validation Loss:0.670 AVG Training Acc 64.41 % AVG Validation Acc 60.41 %\n",
      "Epoch:200/200 AVG Training Loss:0.615 AVG Validation Loss:0.670 AVG Training Acc 64.45 % AVG Validation Acc 60.23 %\n",
      "Split 84\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f652d1fb051041ae803a7191efb2d2e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.653 AVG Training Acc 61.89 % AVG Validation Acc 62.04 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.653 AVG Training Acc 62.01 % AVG Validation Acc 61.68 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.636 AVG Validation Loss:0.663 AVG Training Acc 62.98 % AVG Validation Acc 61.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.625 AVG Validation Loss:0.673 AVG Training Acc 64.34 % AVG Validation Acc 62.13 %\n",
      "Epoch:50/200 AVG Training Loss:0.613 AVG Validation Loss:0.685 AVG Training Acc 65.59 % AVG Validation Acc 60.14 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.603 AVG Validation Loss:0.692 AVG Training Acc 66.34 % AVG Validation Acc 60.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.602 AVG Validation Loss:0.698 AVG Training Acc 66.52 % AVG Validation Acc 59.69 %\n",
      "Epoch:80/200 AVG Training Loss:0.600 AVG Validation Loss:0.702 AVG Training Acc 66.67 % AVG Validation Acc 59.87 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.598 AVG Validation Loss:0.700 AVG Training Acc 67.15 % AVG Validation Acc 59.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.600 AVG Validation Loss:0.701 AVG Training Acc 66.72 % AVG Validation Acc 60.23 %\n",
      "Epoch:110/200 AVG Training Loss:0.600 AVG Validation Loss:0.704 AVG Training Acc 66.72 % AVG Validation Acc 59.33 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.598 AVG Validation Loss:0.702 AVG Training Acc 66.66 % AVG Validation Acc 59.87 %\n",
      "Epoch:130/200 AVG Training Loss:0.599 AVG Validation Loss:0.701 AVG Training Acc 66.54 % AVG Validation Acc 59.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.599 AVG Validation Loss:0.705 AVG Training Acc 66.63 % AVG Validation Acc 59.24 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.600 AVG Validation Loss:0.703 AVG Training Acc 66.67 % AVG Validation Acc 59.78 %\n",
      "Epoch:160/200 AVG Training Loss:0.599 AVG Validation Loss:0.704 AVG Training Acc 66.79 % AVG Validation Acc 60.23 %\n",
      "Epoch:170/200 AVG Training Loss:0.600 AVG Validation Loss:0.701 AVG Training Acc 66.46 % AVG Validation Acc 60.14 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.599 AVG Validation Loss:0.705 AVG Training Acc 66.70 % AVG Validation Acc 59.33 %\n",
      "Epoch:190/200 AVG Training Loss:0.598 AVG Validation Loss:0.700 AVG Training Acc 66.70 % AVG Validation Acc 60.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.599 AVG Validation Loss:0.699 AVG Training Acc 66.74 % AVG Validation Acc 59.96 %\n",
      "Split 85\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac72fad5ff7d4b3c954f2d805d511d83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.657 AVG Validation Loss:0.663 AVG Training Acc 61.93 % AVG Validation Acc 61.77 %\n",
      "Epoch:20/200 AVG Training Loss:0.650 AVG Validation Loss:0.663 AVG Training Acc 62.16 % AVG Validation Acc 61.41 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.635 AVG Validation Loss:0.667 AVG Training Acc 62.67 % AVG Validation Acc 60.50 %\n",
      "Epoch:40/200 AVG Training Loss:0.625 AVG Validation Loss:0.679 AVG Training Acc 63.86 % AVG Validation Acc 60.78 %\n",
      "Epoch:50/200 AVG Training Loss:0.616 AVG Validation Loss:0.686 AVG Training Acc 64.43 % AVG Validation Acc 60.50 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.608 AVG Validation Loss:0.693 AVG Training Acc 64.99 % AVG Validation Acc 60.60 %\n",
      "Epoch:70/200 AVG Training Loss:0.605 AVG Validation Loss:0.690 AVG Training Acc 65.09 % AVG Validation Acc 60.32 %\n",
      "Epoch:80/200 AVG Training Loss:0.604 AVG Validation Loss:0.693 AVG Training Acc 64.86 % AVG Validation Acc 60.50 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.603 AVG Validation Loss:0.693 AVG Training Acc 64.90 % AVG Validation Acc 61.05 %\n",
      "Epoch:100/200 AVG Training Loss:0.602 AVG Validation Loss:0.693 AVG Training Acc 65.16 % AVG Validation Acc 60.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.603 AVG Validation Loss:0.693 AVG Training Acc 64.83 % AVG Validation Acc 59.87 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.602 AVG Validation Loss:0.700 AVG Training Acc 65.56 % AVG Validation Acc 60.05 %\n",
      "Epoch:130/200 AVG Training Loss:0.602 AVG Validation Loss:0.700 AVG Training Acc 64.96 % AVG Validation Acc 61.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.602 AVG Validation Loss:0.697 AVG Training Acc 64.87 % AVG Validation Acc 60.78 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.603 AVG Validation Loss:0.700 AVG Training Acc 64.94 % AVG Validation Acc 60.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.604 AVG Validation Loss:0.694 AVG Training Acc 65.24 % AVG Validation Acc 60.60 %\n",
      "Epoch:170/200 AVG Training Loss:0.602 AVG Validation Loss:0.702 AVG Training Acc 65.44 % AVG Validation Acc 60.69 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.601 AVG Validation Loss:0.697 AVG Training Acc 65.47 % AVG Validation Acc 60.87 %\n",
      "Epoch:190/200 AVG Training Loss:0.603 AVG Validation Loss:0.699 AVG Training Acc 65.34 % AVG Validation Acc 60.96 %\n",
      "Epoch:200/200 AVG Training Loss:0.603 AVG Validation Loss:0.698 AVG Training Acc 65.16 % AVG Validation Acc 60.23 %\n",
      "Split 86\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea01ba104ab54f3a914fbeea0c57b24b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.659 AVG Training Acc 61.84 % AVG Validation Acc 61.73 %\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:0.650 AVG Training Acc 61.89 % AVG Validation Acc 61.55 %\n",
      "Epoch:30/200 AVG Training Loss:0.650 AVG Validation Loss:0.652 AVG Training Acc 61.89 % AVG Validation Acc 61.73 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.625 AVG Validation Loss:0.659 AVG Training Acc 63.57 % AVG Validation Acc 60.56 %\n",
      "Epoch:50/200 AVG Training Loss:0.618 AVG Validation Loss:0.660 AVG Training Acc 64.24 % AVG Validation Acc 59.93 %\n",
      "Epoch:60/200 AVG Training Loss:0.607 AVG Validation Loss:0.662 AVG Training Acc 64.52 % AVG Validation Acc 62.18 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.601 AVG Validation Loss:0.671 AVG Training Acc 65.62 % AVG Validation Acc 60.83 %\n",
      "Epoch:80/200 AVG Training Loss:0.601 AVG Validation Loss:0.667 AVG Training Acc 65.56 % AVG Validation Acc 60.47 %\n",
      "Epoch:90/200 AVG Training Loss:0.599 AVG Validation Loss:0.666 AVG Training Acc 65.43 % AVG Validation Acc 60.74 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.597 AVG Validation Loss:0.671 AVG Training Acc 65.41 % AVG Validation Acc 60.56 %\n",
      "Epoch:110/200 AVG Training Loss:0.598 AVG Validation Loss:0.672 AVG Training Acc 65.58 % AVG Validation Acc 60.92 %\n",
      "Epoch:120/200 AVG Training Loss:0.596 AVG Validation Loss:0.674 AVG Training Acc 65.81 % AVG Validation Acc 60.74 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.597 AVG Validation Loss:0.668 AVG Training Acc 65.81 % AVG Validation Acc 61.01 %\n",
      "Epoch:140/200 AVG Training Loss:0.598 AVG Validation Loss:0.674 AVG Training Acc 65.46 % AVG Validation Acc 60.92 %\n",
      "Epoch:150/200 AVG Training Loss:0.598 AVG Validation Loss:0.668 AVG Training Acc 66.14 % AVG Validation Acc 60.83 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.596 AVG Validation Loss:0.676 AVG Training Acc 66.27 % AVG Validation Acc 60.92 %\n",
      "Epoch:170/200 AVG Training Loss:0.598 AVG Validation Loss:0.674 AVG Training Acc 65.61 % AVG Validation Acc 61.10 %\n",
      "Epoch:180/200 AVG Training Loss:0.599 AVG Validation Loss:0.669 AVG Training Acc 65.54 % AVG Validation Acc 60.29 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.598 AVG Validation Loss:0.673 AVG Training Acc 65.58 % AVG Validation Acc 60.20 %\n",
      "Epoch:200/200 AVG Training Loss:0.599 AVG Validation Loss:0.677 AVG Training Acc 65.78 % AVG Validation Acc 61.01 %\n",
      "Split 87\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1393d5d7508436a8ca6d378b550df25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.661 AVG Training Acc 61.87 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.657 AVG Training Acc 61.94 % AVG Validation Acc 61.91 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.638 AVG Validation Loss:0.660 AVG Training Acc 63.16 % AVG Validation Acc 62.00 %\n",
      "Epoch:40/200 AVG Training Loss:0.631 AVG Validation Loss:0.669 AVG Training Acc 63.68 % AVG Validation Acc 61.46 %\n",
      "Epoch:50/200 AVG Training Loss:0.626 AVG Validation Loss:0.677 AVG Training Acc 64.15 % AVG Validation Acc 61.73 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.617 AVG Validation Loss:0.681 AVG Training Acc 64.70 % AVG Validation Acc 61.10 %\n",
      "Epoch:70/200 AVG Training Loss:0.616 AVG Validation Loss:0.689 AVG Training Acc 65.07 % AVG Validation Acc 61.01 %\n",
      "Epoch:80/200 AVG Training Loss:0.613 AVG Validation Loss:0.694 AVG Training Acc 64.84 % AVG Validation Acc 60.38 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.614 AVG Validation Loss:0.693 AVG Training Acc 65.03 % AVG Validation Acc 61.01 %\n",
      "Epoch:100/200 AVG Training Loss:0.612 AVG Validation Loss:0.693 AVG Training Acc 65.15 % AVG Validation Acc 60.47 %\n",
      "Epoch:110/200 AVG Training Loss:0.614 AVG Validation Loss:0.697 AVG Training Acc 65.02 % AVG Validation Acc 60.11 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.612 AVG Validation Loss:0.696 AVG Training Acc 65.46 % AVG Validation Acc 60.47 %\n",
      "Epoch:130/200 AVG Training Loss:0.614 AVG Validation Loss:0.693 AVG Training Acc 64.89 % AVG Validation Acc 60.56 %\n",
      "Epoch:140/200 AVG Training Loss:0.611 AVG Validation Loss:0.698 AVG Training Acc 65.34 % AVG Validation Acc 60.65 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.613 AVG Validation Loss:0.696 AVG Training Acc 65.01 % AVG Validation Acc 60.65 %\n",
      "Epoch:160/200 AVG Training Loss:0.613 AVG Validation Loss:0.701 AVG Training Acc 65.23 % AVG Validation Acc 60.29 %\n",
      "Epoch:170/200 AVG Training Loss:0.612 AVG Validation Loss:0.696 AVG Training Acc 65.28 % AVG Validation Acc 60.29 %\n",
      "Epoch:180/200 AVG Training Loss:0.614 AVG Validation Loss:0.697 AVG Training Acc 65.04 % AVG Validation Acc 60.20 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.613 AVG Validation Loss:0.696 AVG Training Acc 65.20 % AVG Validation Acc 60.20 %\n",
      "Epoch:200/200 AVG Training Loss:0.614 AVG Validation Loss:0.697 AVG Training Acc 65.18 % AVG Validation Acc 60.47 %\n",
      "Split 88\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e20fb7834f4804b06b1b7b352faedd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.662 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.21 % AVG Validation Acc 61.73 %\n",
      "Epoch:30/200 AVG Training Loss:0.637 AVG Validation Loss:0.668 AVG Training Acc 62.90 % AVG Validation Acc 59.75 %\n",
      "Epoch:40/200 AVG Training Loss:0.625 AVG Validation Loss:0.668 AVG Training Acc 64.08 % AVG Validation Acc 61.28 %\n",
      "Epoch:50/200 AVG Training Loss:0.617 AVG Validation Loss:0.676 AVG Training Acc 64.49 % AVG Validation Acc 60.56 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.612 AVG Validation Loss:0.675 AVG Training Acc 65.02 % AVG Validation Acc 61.64 %\n",
      "Epoch:70/200 AVG Training Loss:0.610 AVG Validation Loss:0.680 AVG Training Acc 64.93 % AVG Validation Acc 61.37 %\n",
      "Epoch:80/200 AVG Training Loss:0.609 AVG Validation Loss:0.685 AVG Training Acc 65.34 % AVG Validation Acc 60.92 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.610 AVG Validation Loss:0.682 AVG Training Acc 64.98 % AVG Validation Acc 60.92 %\n",
      "Epoch:100/200 AVG Training Loss:0.610 AVG Validation Loss:0.685 AVG Training Acc 65.54 % AVG Validation Acc 61.19 %\n",
      "Epoch:110/200 AVG Training Loss:0.608 AVG Validation Loss:0.684 AVG Training Acc 65.02 % AVG Validation Acc 61.55 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.608 AVG Validation Loss:0.686 AVG Training Acc 65.72 % AVG Validation Acc 61.01 %\n",
      "Epoch:130/200 AVG Training Loss:0.608 AVG Validation Loss:0.683 AVG Training Acc 65.01 % AVG Validation Acc 60.83 %\n",
      "Epoch:140/200 AVG Training Loss:0.610 AVG Validation Loss:0.682 AVG Training Acc 65.34 % AVG Validation Acc 60.83 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.609 AVG Validation Loss:0.686 AVG Training Acc 64.89 % AVG Validation Acc 61.37 %\n",
      "Epoch:160/200 AVG Training Loss:0.611 AVG Validation Loss:0.687 AVG Training Acc 64.84 % AVG Validation Acc 61.01 %\n",
      "Epoch:170/200 AVG Training Loss:0.609 AVG Validation Loss:0.688 AVG Training Acc 65.13 % AVG Validation Acc 60.92 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.609 AVG Validation Loss:0.686 AVG Training Acc 65.19 % AVG Validation Acc 60.83 %\n",
      "Epoch:190/200 AVG Training Loss:0.610 AVG Validation Loss:0.684 AVG Training Acc 65.07 % AVG Validation Acc 60.65 %\n",
      "Epoch:200/200 AVG Training Loss:0.608 AVG Validation Loss:0.684 AVG Training Acc 65.46 % AVG Validation Acc 61.28 %\n",
      "Split 89\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b438cb19d5fd42a491dc209cb7953bd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.663 AVG Training Acc 61.91 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.666 AVG Training Acc 62.03 % AVG Validation Acc 61.55 %\n",
      "Epoch:30/200 AVG Training Loss:0.645 AVG Validation Loss:0.661 AVG Training Acc 62.28 % AVG Validation Acc 61.73 %\n",
      "Epoch:40/200 AVG Training Loss:0.666 AVG Validation Loss:0.665 AVG Training Acc 61.50 % AVG Validation Acc 61.82 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.658 AVG Validation Loss:0.661 AVG Training Acc 61.93 % AVG Validation Acc 61.91 %\n",
      "Epoch:60/200 AVG Training Loss:0.656 AVG Validation Loss:0.661 AVG Training Acc 62.00 % AVG Validation Acc 61.91 %\n",
      "Epoch:70/200 AVG Training Loss:0.656 AVG Validation Loss:0.660 AVG Training Acc 62.20 % AVG Validation Acc 61.91 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.655 AVG Validation Loss:0.659 AVG Training Acc 61.94 % AVG Validation Acc 61.82 %\n",
      "Epoch:90/200 AVG Training Loss:0.655 AVG Validation Loss:0.660 AVG Training Acc 62.29 % AVG Validation Acc 61.73 %\n",
      "Epoch:100/200 AVG Training Loss:0.656 AVG Validation Loss:0.659 AVG Training Acc 61.91 % AVG Validation Acc 61.91 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.656 AVG Validation Loss:0.659 AVG Training Acc 61.93 % AVG Validation Acc 61.73 %\n",
      "Epoch:120/200 AVG Training Loss:0.656 AVG Validation Loss:0.659 AVG Training Acc 61.71 % AVG Validation Acc 61.91 %\n",
      "Epoch:130/200 AVG Training Loss:0.657 AVG Validation Loss:0.659 AVG Training Acc 61.78 % AVG Validation Acc 61.82 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.657 AVG Validation Loss:0.660 AVG Training Acc 61.80 % AVG Validation Acc 61.82 %\n",
      "Epoch:150/200 AVG Training Loss:0.657 AVG Validation Loss:0.660 AVG Training Acc 61.77 % AVG Validation Acc 61.91 %\n",
      "Epoch:160/200 AVG Training Loss:0.657 AVG Validation Loss:0.660 AVG Training Acc 61.94 % AVG Validation Acc 61.82 %\n",
      "Epoch:170/200 AVG Training Loss:0.656 AVG Validation Loss:0.659 AVG Training Acc 61.91 % AVG Validation Acc 61.91 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.655 AVG Validation Loss:0.661 AVG Training Acc 62.19 % AVG Validation Acc 62.09 %\n",
      "Epoch:190/200 AVG Training Loss:0.657 AVG Validation Loss:0.660 AVG Training Acc 61.55 % AVG Validation Acc 61.73 %\n",
      "Epoch:200/200 AVG Training Loss:0.656 AVG Validation Loss:0.659 AVG Training Acc 61.94 % AVG Validation Acc 62.00 %\n",
      "Split 90\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ca757f4d7f4c52bb4c8f0a4828849e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.653 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.655 AVG Training Acc 61.95 % AVG Validation Acc 62.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.648 AVG Validation Loss:0.650 AVG Training Acc 61.92 % AVG Validation Acc 62.18 %\n",
      "Epoch:40/200 AVG Training Loss:0.642 AVG Validation Loss:0.651 AVG Training Acc 62.22 % AVG Validation Acc 63.18 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.634 AVG Validation Loss:0.661 AVG Training Acc 62.98 % AVG Validation Acc 60.83 %\n",
      "Epoch:60/200 AVG Training Loss:0.615 AVG Validation Loss:0.677 AVG Training Acc 63.92 % AVG Validation Acc 61.64 %\n",
      "Epoch:70/200 AVG Training Loss:0.603 AVG Validation Loss:0.700 AVG Training Acc 64.59 % AVG Validation Acc 60.47 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.591 AVG Validation Loss:0.720 AVG Training Acc 65.08 % AVG Validation Acc 60.29 %\n",
      "Epoch:90/200 AVG Training Loss:0.588 AVG Validation Loss:0.718 AVG Training Acc 65.82 % AVG Validation Acc 60.38 %\n",
      "Epoch:100/200 AVG Training Loss:0.589 AVG Validation Loss:0.722 AVG Training Acc 65.34 % AVG Validation Acc 59.93 %\n",
      "Epoch:110/200 AVG Training Loss:0.587 AVG Validation Loss:0.722 AVG Training Acc 65.26 % AVG Validation Acc 59.84 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.584 AVG Validation Loss:0.725 AVG Training Acc 66.13 % AVG Validation Acc 60.29 %\n",
      "Epoch:130/200 AVG Training Loss:0.588 AVG Validation Loss:0.718 AVG Training Acc 65.52 % AVG Validation Acc 60.11 %\n",
      "Epoch:140/200 AVG Training Loss:0.585 AVG Validation Loss:0.726 AVG Training Acc 65.65 % AVG Validation Acc 59.75 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.588 AVG Validation Loss:0.718 AVG Training Acc 65.76 % AVG Validation Acc 60.20 %\n",
      "Epoch:160/200 AVG Training Loss:0.583 AVG Validation Loss:0.720 AVG Training Acc 66.06 % AVG Validation Acc 60.38 %\n",
      "Epoch:170/200 AVG Training Loss:0.586 AVG Validation Loss:0.732 AVG Training Acc 65.75 % AVG Validation Acc 59.21 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.584 AVG Validation Loss:0.721 AVG Training Acc 65.98 % AVG Validation Acc 60.11 %\n",
      "Epoch:190/200 AVG Training Loss:0.585 AVG Validation Loss:0.723 AVG Training Acc 65.75 % AVG Validation Acc 59.84 %\n",
      "Epoch:200/200 AVG Training Loss:0.588 AVG Validation Loss:0.721 AVG Training Acc 65.24 % AVG Validation Acc 59.93 %\n",
      "Split 91\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66090da37c0c4c23874b6c220b24d081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.655 AVG Training Acc 61.83 % AVG Validation Acc 62.04 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.660 AVG Training Acc 61.73 % AVG Validation Acc 61.50 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.633 AVG Validation Loss:0.664 AVG Training Acc 63.69 % AVG Validation Acc 61.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.623 AVG Validation Loss:0.669 AVG Training Acc 64.59 % AVG Validation Acc 60.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.615 AVG Validation Loss:0.675 AVG Training Acc 65.21 % AVG Validation Acc 59.69 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.605 AVG Validation Loss:0.684 AVG Training Acc 65.92 % AVG Validation Acc 60.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.606 AVG Validation Loss:0.686 AVG Training Acc 65.66 % AVG Validation Acc 60.41 %\n",
      "Epoch:80/200 AVG Training Loss:0.603 AVG Validation Loss:0.687 AVG Training Acc 66.65 % AVG Validation Acc 60.23 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.601 AVG Validation Loss:0.689 AVG Training Acc 66.49 % AVG Validation Acc 59.78 %\n",
      "Epoch:100/200 AVG Training Loss:0.603 AVG Validation Loss:0.692 AVG Training Acc 66.27 % AVG Validation Acc 59.24 %\n",
      "Epoch:110/200 AVG Training Loss:0.603 AVG Validation Loss:0.690 AVG Training Acc 66.08 % AVG Validation Acc 59.96 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.600 AVG Validation Loss:0.685 AVG Training Acc 66.56 % AVG Validation Acc 60.32 %\n",
      "Epoch:130/200 AVG Training Loss:0.604 AVG Validation Loss:0.688 AVG Training Acc 66.16 % AVG Validation Acc 59.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.601 AVG Validation Loss:0.691 AVG Training Acc 65.87 % AVG Validation Acc 59.42 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.601 AVG Validation Loss:0.687 AVG Training Acc 66.75 % AVG Validation Acc 59.78 %\n",
      "Epoch:160/200 AVG Training Loss:0.601 AVG Validation Loss:0.696 AVG Training Acc 66.13 % AVG Validation Acc 59.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.603 AVG Validation Loss:0.691 AVG Training Acc 66.02 % AVG Validation Acc 59.87 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.603 AVG Validation Loss:0.690 AVG Training Acc 66.45 % AVG Validation Acc 59.87 %\n",
      "Epoch:190/200 AVG Training Loss:0.603 AVG Validation Loss:0.687 AVG Training Acc 65.98 % AVG Validation Acc 60.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.601 AVG Validation Loss:0.689 AVG Training Acc 66.43 % AVG Validation Acc 59.69 %\n",
      "Split 92\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4f73496d81e4c9095b0aed617461f64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.659 AVG Training Acc 61.92 % AVG Validation Acc 61.77 %\n",
      "Epoch:20/200 AVG Training Loss:0.650 AVG Validation Loss:0.661 AVG Training Acc 61.76 % AVG Validation Acc 61.77 %\n",
      "Epoch:30/200 AVG Training Loss:0.636 AVG Validation Loss:0.660 AVG Training Acc 62.63 % AVG Validation Acc 61.95 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.605 AVG Validation Loss:0.681 AVG Training Acc 65.60 % AVG Validation Acc 60.78 %\n",
      "Epoch:50/200 AVG Training Loss:0.589 AVG Validation Loss:0.696 AVG Training Acc 66.78 % AVG Validation Acc 60.41 %\n",
      "Epoch:60/200 AVG Training Loss:0.581 AVG Validation Loss:0.709 AVG Training Acc 67.45 % AVG Validation Acc 60.87 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.573 AVG Validation Loss:0.718 AVG Training Acc 68.27 % AVG Validation Acc 60.32 %\n",
      "Epoch:80/200 AVG Training Loss:0.571 AVG Validation Loss:0.715 AVG Training Acc 68.08 % AVG Validation Acc 59.87 %\n",
      "Epoch:90/200 AVG Training Loss:0.569 AVG Validation Loss:0.718 AVG Training Acc 68.38 % AVG Validation Acc 59.60 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.569 AVG Validation Loss:0.724 AVG Training Acc 68.28 % AVG Validation Acc 59.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.567 AVG Validation Loss:0.713 AVG Training Acc 68.54 % AVG Validation Acc 60.23 %\n",
      "Epoch:120/200 AVG Training Loss:0.569 AVG Validation Loss:0.715 AVG Training Acc 68.78 % AVG Validation Acc 59.87 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.569 AVG Validation Loss:0.717 AVG Training Acc 68.14 % AVG Validation Acc 60.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.568 AVG Validation Loss:0.721 AVG Training Acc 68.67 % AVG Validation Acc 60.32 %\n",
      "Epoch:150/200 AVG Training Loss:0.566 AVG Validation Loss:0.716 AVG Training Acc 68.66 % AVG Validation Acc 59.33 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.568 AVG Validation Loss:0.712 AVG Training Acc 68.79 % AVG Validation Acc 60.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.569 AVG Validation Loss:0.721 AVG Training Acc 68.66 % AVG Validation Acc 60.32 %\n",
      "Epoch:180/200 AVG Training Loss:0.566 AVG Validation Loss:0.714 AVG Training Acc 68.72 % AVG Validation Acc 59.69 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.569 AVG Validation Loss:0.717 AVG Training Acc 68.30 % AVG Validation Acc 59.96 %\n",
      "Epoch:200/200 AVG Training Loss:0.569 AVG Validation Loss:0.718 AVG Training Acc 68.62 % AVG Validation Acc 60.50 %\n",
      "Split 93\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d70a2fb9a1bb48e895c4afad174672ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.660 AVG Training Acc 61.64 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.649 AVG Validation Loss:0.662 AVG Training Acc 61.79 % AVG Validation Acc 60.87 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.631 AVG Validation Loss:0.662 AVG Training Acc 63.06 % AVG Validation Acc 62.04 %\n",
      "Epoch:40/200 AVG Training Loss:0.619 AVG Validation Loss:0.672 AVG Training Acc 63.90 % AVG Validation Acc 62.94 %\n",
      "Epoch:50/200 AVG Training Loss:0.607 AVG Validation Loss:0.680 AVG Training Acc 64.66 % AVG Validation Acc 62.04 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.597 AVG Validation Loss:0.690 AVG Training Acc 65.60 % AVG Validation Acc 60.78 %\n",
      "Epoch:70/200 AVG Training Loss:0.597 AVG Validation Loss:0.692 AVG Training Acc 65.61 % AVG Validation Acc 61.50 %\n",
      "Epoch:80/200 AVG Training Loss:0.594 AVG Validation Loss:0.690 AVG Training Acc 65.26 % AVG Validation Acc 61.23 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.593 AVG Validation Loss:0.697 AVG Training Acc 65.76 % AVG Validation Acc 61.50 %\n",
      "Epoch:100/200 AVG Training Loss:0.592 AVG Validation Loss:0.699 AVG Training Acc 65.77 % AVG Validation Acc 61.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.593 AVG Validation Loss:0.697 AVG Training Acc 65.98 % AVG Validation Acc 61.32 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.592 AVG Validation Loss:0.698 AVG Training Acc 65.59 % AVG Validation Acc 61.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.595 AVG Validation Loss:0.698 AVG Training Acc 65.46 % AVG Validation Acc 61.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.591 AVG Validation Loss:0.698 AVG Training Acc 65.94 % AVG Validation Acc 61.23 %\n",
      "Epoch:150/200 AVG Training Loss:0.591 AVG Validation Loss:0.695 AVG Training Acc 65.71 % AVG Validation Acc 61.14 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.591 AVG Validation Loss:0.697 AVG Training Acc 65.74 % AVG Validation Acc 61.77 %\n",
      "Epoch:170/200 AVG Training Loss:0.592 AVG Validation Loss:0.700 AVG Training Acc 66.02 % AVG Validation Acc 61.23 %\n",
      "Epoch:180/200 AVG Training Loss:0.592 AVG Validation Loss:0.700 AVG Training Acc 65.93 % AVG Validation Acc 61.14 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.592 AVG Validation Loss:0.702 AVG Training Acc 65.34 % AVG Validation Acc 61.50 %\n",
      "Epoch:200/200 AVG Training Loss:0.593 AVG Validation Loss:0.694 AVG Training Acc 65.86 % AVG Validation Acc 61.50 %\n",
      "Split 94\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c22788f5f364712bda6f5fd26da1216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.657 AVG Validation Loss:0.663 AVG Training Acc 61.90 % AVG Validation Acc 62.22 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.662 AVG Training Acc 61.96 % AVG Validation Acc 62.22 %\n",
      "Epoch:30/200 AVG Training Loss:0.644 AVG Validation Loss:0.666 AVG Training Acc 62.45 % AVG Validation Acc 62.40 %\n",
      "Epoch:40/200 AVG Training Loss:0.666 AVG Validation Loss:0.664 AVG Training Acc 61.59 % AVG Validation Acc 61.86 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.658 AVG Validation Loss:0.664 AVG Training Acc 61.90 % AVG Validation Acc 61.95 %\n",
      "Epoch:60/200 AVG Training Loss:0.656 AVG Validation Loss:0.664 AVG Training Acc 62.03 % AVG Validation Acc 62.04 %\n",
      "Epoch:70/200 AVG Training Loss:0.653 AVG Validation Loss:0.668 AVG Training Acc 62.22 % AVG Validation Acc 61.95 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.650 AVG Validation Loss:0.673 AVG Training Acc 62.29 % AVG Validation Acc 61.77 %\n",
      "Epoch:90/200 AVG Training Loss:0.646 AVG Validation Loss:0.672 AVG Training Acc 62.40 % AVG Validation Acc 61.68 %\n",
      "Epoch:100/200 AVG Training Loss:0.647 AVG Validation Loss:0.676 AVG Training Acc 62.43 % AVG Validation Acc 61.41 %\n",
      "Epoch:110/200 AVG Training Loss:0.648 AVG Validation Loss:0.673 AVG Training Acc 62.50 % AVG Validation Acc 61.50 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.647 AVG Validation Loss:0.672 AVG Training Acc 62.78 % AVG Validation Acc 61.68 %\n",
      "Epoch:130/200 AVG Training Loss:0.647 AVG Validation Loss:0.677 AVG Training Acc 62.54 % AVG Validation Acc 61.50 %\n",
      "Epoch:140/200 AVG Training Loss:0.647 AVG Validation Loss:0.677 AVG Training Acc 62.30 % AVG Validation Acc 61.68 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.648 AVG Validation Loss:0.673 AVG Training Acc 62.53 % AVG Validation Acc 61.41 %\n",
      "Epoch:160/200 AVG Training Loss:0.645 AVG Validation Loss:0.674 AVG Training Acc 62.49 % AVG Validation Acc 61.59 %\n",
      "Epoch:170/200 AVG Training Loss:0.645 AVG Validation Loss:0.669 AVG Training Acc 62.61 % AVG Validation Acc 61.86 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.644 AVG Validation Loss:0.680 AVG Training Acc 62.70 % AVG Validation Acc 61.77 %\n",
      "Epoch:190/200 AVG Training Loss:0.646 AVG Validation Loss:0.672 AVG Training Acc 62.56 % AVG Validation Acc 61.68 %\n",
      "Epoch:200/200 AVG Training Loss:0.646 AVG Validation Loss:0.672 AVG Training Acc 62.78 % AVG Validation Acc 61.86 %\n",
      "Split 95\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bf08a7ef2214fec9ebc9e6d7cf71fbe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.663 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.663 AVG Training Acc 62.31 % AVG Validation Acc 60.96 %\n",
      "Epoch:30/200 AVG Training Loss:0.644 AVG Validation Loss:0.659 AVG Training Acc 62.50 % AVG Validation Acc 61.59 %\n",
      "Epoch:40/200 AVG Training Loss:0.634 AVG Validation Loss:0.660 AVG Training Acc 63.13 % AVG Validation Acc 61.68 %\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.612 AVG Validation Loss:0.666 AVG Training Acc 64.12 % AVG Validation Acc 61.77 %\n",
      "Epoch:60/200 AVG Training Loss:0.598 AVG Validation Loss:0.683 AVG Training Acc 65.20 % AVG Validation Acc 61.59 %\n",
      "Epoch:70/200 AVG Training Loss:0.588 AVG Validation Loss:0.695 AVG Training Acc 65.59 % AVG Validation Acc 62.04 %\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.577 AVG Validation Loss:0.705 AVG Training Acc 66.59 % AVG Validation Acc 60.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.577 AVG Validation Loss:0.701 AVG Training Acc 66.76 % AVG Validation Acc 61.68 %\n",
      "Epoch:100/200 AVG Training Loss:0.578 AVG Validation Loss:0.705 AVG Training Acc 66.62 % AVG Validation Acc 60.32 %\n",
      "Epoch   106: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.577 AVG Validation Loss:0.710 AVG Training Acc 66.71 % AVG Validation Acc 60.69 %\n",
      "Epoch:120/200 AVG Training Loss:0.574 AVG Validation Loss:0.716 AVG Training Acc 66.27 % AVG Validation Acc 61.41 %\n",
      "Epoch:130/200 AVG Training Loss:0.578 AVG Validation Loss:0.704 AVG Training Acc 66.49 % AVG Validation Acc 61.05 %\n",
      "Epoch   137: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.577 AVG Validation Loss:0.719 AVG Training Acc 66.20 % AVG Validation Acc 59.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.577 AVG Validation Loss:0.712 AVG Training Acc 66.46 % AVG Validation Acc 60.87 %\n",
      "Epoch:160/200 AVG Training Loss:0.576 AVG Validation Loss:0.716 AVG Training Acc 66.75 % AVG Validation Acc 60.69 %\n",
      "Epoch   168: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.573 AVG Validation Loss:0.716 AVG Training Acc 66.92 % AVG Validation Acc 60.69 %\n",
      "Epoch:180/200 AVG Training Loss:0.574 AVG Validation Loss:0.713 AVG Training Acc 66.26 % AVG Validation Acc 60.50 %\n",
      "Epoch:190/200 AVG Training Loss:0.575 AVG Validation Loss:0.714 AVG Training Acc 66.86 % AVG Validation Acc 60.87 %\n",
      "Epoch   199: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.577 AVG Validation Loss:0.714 AVG Training Acc 66.05 % AVG Validation Acc 60.14 %\n",
      "Split 96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b944f77cc93244e3aac0a22338647905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.662 AVG Training Acc 61.79 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.665 AVG Training Acc 61.94 % AVG Validation Acc 61.46 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.637 AVG Validation Loss:0.670 AVG Training Acc 62.49 % AVG Validation Acc 60.74 %\n",
      "Epoch:40/200 AVG Training Loss:0.624 AVG Validation Loss:0.687 AVG Training Acc 63.45 % AVG Validation Acc 60.56 %\n",
      "Epoch:50/200 AVG Training Loss:0.612 AVG Validation Loss:0.704 AVG Training Acc 64.49 % AVG Validation Acc 60.11 %\n",
      "Epoch:60/200 AVG Training Loss:0.606 AVG Validation Loss:0.716 AVG Training Acc 65.20 % AVG Validation Acc 59.48 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.604 AVG Validation Loss:0.724 AVG Training Acc 64.86 % AVG Validation Acc 58.57 %\n",
      "Epoch:80/200 AVG Training Loss:0.602 AVG Validation Loss:0.718 AVG Training Acc 65.34 % AVG Validation Acc 59.12 %\n",
      "Epoch:90/200 AVG Training Loss:0.601 AVG Validation Loss:0.723 AVG Training Acc 65.70 % AVG Validation Acc 58.12 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.600 AVG Validation Loss:0.727 AVG Training Acc 65.33 % AVG Validation Acc 58.66 %\n",
      "Epoch:110/200 AVG Training Loss:0.597 AVG Validation Loss:0.726 AVG Training Acc 65.70 % AVG Validation Acc 58.66 %\n",
      "Epoch:120/200 AVG Training Loss:0.599 AVG Validation Loss:0.724 AVG Training Acc 65.18 % AVG Validation Acc 58.57 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.600 AVG Validation Loss:0.727 AVG Training Acc 65.71 % AVG Validation Acc 58.66 %\n",
      "Epoch:140/200 AVG Training Loss:0.599 AVG Validation Loss:0.726 AVG Training Acc 65.84 % AVG Validation Acc 58.57 %\n",
      "Epoch:150/200 AVG Training Loss:0.599 AVG Validation Loss:0.720 AVG Training Acc 65.90 % AVG Validation Acc 59.12 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.599 AVG Validation Loss:0.720 AVG Training Acc 65.70 % AVG Validation Acc 58.12 %\n",
      "Epoch:170/200 AVG Training Loss:0.598 AVG Validation Loss:0.726 AVG Training Acc 65.88 % AVG Validation Acc 59.21 %\n",
      "Epoch:180/200 AVG Training Loss:0.595 AVG Validation Loss:0.724 AVG Training Acc 65.82 % AVG Validation Acc 59.21 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.599 AVG Validation Loss:0.723 AVG Training Acc 65.54 % AVG Validation Acc 58.75 %\n",
      "Epoch:200/200 AVG Training Loss:0.599 AVG Validation Loss:0.725 AVG Training Acc 65.35 % AVG Validation Acc 58.48 %\n",
      "Split 97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d53a52d972464ec5b1d062c5ea46224c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.652 AVG Training Acc 61.79 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.650 AVG Training Acc 62.12 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.646 AVG Validation Loss:0.648 AVG Training Acc 62.49 % AVG Validation Acc 61.46 %\n",
      "Epoch:40/200 AVG Training Loss:0.637 AVG Validation Loss:0.657 AVG Training Acc 63.26 % AVG Validation Acc 61.82 %\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.621 AVG Validation Loss:0.650 AVG Training Acc 64.79 % AVG Validation Acc 61.37 %\n",
      "Epoch:60/200 AVG Training Loss:0.611 AVG Validation Loss:0.659 AVG Training Acc 65.90 % AVG Validation Acc 62.09 %\n",
      "Epoch:70/200 AVG Training Loss:0.600 AVG Validation Loss:0.657 AVG Training Acc 66.86 % AVG Validation Acc 62.18 %\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.593 AVG Validation Loss:0.660 AVG Training Acc 67.38 % AVG Validation Acc 62.64 %\n",
      "Epoch:90/200 AVG Training Loss:0.592 AVG Validation Loss:0.654 AVG Training Acc 67.56 % AVG Validation Acc 63.00 %\n",
      "Epoch:100/200 AVG Training Loss:0.591 AVG Validation Loss:0.658 AVG Training Acc 67.31 % AVG Validation Acc 62.18 %\n",
      "Epoch   106: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.589 AVG Validation Loss:0.659 AVG Training Acc 67.60 % AVG Validation Acc 63.27 %\n",
      "Epoch:120/200 AVG Training Loss:0.587 AVG Validation Loss:0.664 AVG Training Acc 67.57 % AVG Validation Acc 62.73 %\n",
      "Epoch:130/200 AVG Training Loss:0.585 AVG Validation Loss:0.658 AVG Training Acc 68.09 % AVG Validation Acc 63.18 %\n",
      "Epoch   137: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.588 AVG Validation Loss:0.664 AVG Training Acc 67.46 % AVG Validation Acc 62.55 %\n",
      "Epoch:150/200 AVG Training Loss:0.589 AVG Validation Loss:0.654 AVG Training Acc 68.27 % AVG Validation Acc 63.09 %\n",
      "Epoch:160/200 AVG Training Loss:0.590 AVG Validation Loss:0.654 AVG Training Acc 67.82 % AVG Validation Acc 63.63 %\n",
      "Epoch   168: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.587 AVG Validation Loss:0.658 AVG Training Acc 67.74 % AVG Validation Acc 62.36 %\n",
      "Epoch:180/200 AVG Training Loss:0.588 AVG Validation Loss:0.661 AVG Training Acc 68.01 % AVG Validation Acc 62.82 %\n",
      "Epoch:190/200 AVG Training Loss:0.589 AVG Validation Loss:0.655 AVG Training Acc 67.66 % AVG Validation Acc 63.00 %\n",
      "Epoch   199: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.592 AVG Validation Loss:0.657 AVG Training Acc 67.89 % AVG Validation Acc 62.55 %\n",
      "Split 98\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "680f3ef54f4a4f138027a1e9bf482ddc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.655 AVG Training Acc 61.79 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.653 AVG Training Acc 61.69 % AVG Validation Acc 61.55 %\n",
      "Epoch:30/200 AVG Training Loss:0.650 AVG Validation Loss:0.652 AVG Training Acc 61.95 % AVG Validation Acc 62.00 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.629 AVG Validation Loss:0.657 AVG Training Acc 63.50 % AVG Validation Acc 61.37 %\n",
      "Epoch:50/200 AVG Training Loss:0.622 AVG Validation Loss:0.654 AVG Training Acc 64.41 % AVG Validation Acc 61.28 %\n",
      "Epoch:60/200 AVG Training Loss:0.613 AVG Validation Loss:0.665 AVG Training Acc 65.27 % AVG Validation Acc 60.56 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.608 AVG Validation Loss:0.666 AVG Training Acc 65.56 % AVG Validation Acc 61.46 %\n",
      "Epoch:80/200 AVG Training Loss:0.609 AVG Validation Loss:0.669 AVG Training Acc 65.14 % AVG Validation Acc 60.56 %\n",
      "Epoch:90/200 AVG Training Loss:0.607 AVG Validation Loss:0.661 AVG Training Acc 65.50 % AVG Validation Acc 60.47 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.606 AVG Validation Loss:0.672 AVG Training Acc 65.64 % AVG Validation Acc 60.29 %\n",
      "Epoch:110/200 AVG Training Loss:0.606 AVG Validation Loss:0.669 AVG Training Acc 65.55 % AVG Validation Acc 60.38 %\n",
      "Epoch:120/200 AVG Training Loss:0.605 AVG Validation Loss:0.673 AVG Training Acc 65.65 % AVG Validation Acc 60.47 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.605 AVG Validation Loss:0.667 AVG Training Acc 65.97 % AVG Validation Acc 60.29 %\n",
      "Epoch:140/200 AVG Training Loss:0.604 AVG Validation Loss:0.668 AVG Training Acc 65.82 % AVG Validation Acc 60.38 %\n",
      "Epoch:150/200 AVG Training Loss:0.605 AVG Validation Loss:0.670 AVG Training Acc 66.28 % AVG Validation Acc 60.74 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.606 AVG Validation Loss:0.663 AVG Training Acc 65.20 % AVG Validation Acc 60.47 %\n",
      "Epoch:170/200 AVG Training Loss:0.606 AVG Validation Loss:0.673 AVG Training Acc 65.39 % AVG Validation Acc 60.29 %\n",
      "Epoch:180/200 AVG Training Loss:0.605 AVG Validation Loss:0.669 AVG Training Acc 66.05 % AVG Validation Acc 60.65 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.605 AVG Validation Loss:0.669 AVG Training Acc 65.78 % AVG Validation Acc 60.92 %\n",
      "Epoch:200/200 AVG Training Loss:0.604 AVG Validation Loss:0.669 AVG Training Acc 65.30 % AVG Validation Acc 60.47 %\n",
      "Split 99\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19a4b9f0080a4734871d7435a3474f12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.656 AVG Training Acc 61.92 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:0.655 AVG Training Acc 61.72 % AVG Validation Acc 61.73 %\n",
      "Epoch:30/200 AVG Training Loss:0.648 AVG Validation Loss:0.653 AVG Training Acc 62.11 % AVG Validation Acc 61.55 %\n",
      "Epoch:40/200 AVG Training Loss:0.636 AVG Validation Loss:0.660 AVG Training Acc 62.65 % AVG Validation Acc 60.56 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.628 AVG Validation Loss:0.659 AVG Training Acc 63.29 % AVG Validation Acc 60.56 %\n",
      "Epoch:60/200 AVG Training Loss:0.605 AVG Validation Loss:0.679 AVG Training Acc 64.57 % AVG Validation Acc 61.28 %\n",
      "Epoch:70/200 AVG Training Loss:0.593 AVG Validation Loss:0.687 AVG Training Acc 65.65 % AVG Validation Acc 61.19 %\n",
      "Epoch:80/200 AVG Training Loss:0.583 AVG Validation Loss:0.703 AVG Training Acc 66.43 % AVG Validation Acc 59.84 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.579 AVG Validation Loss:0.709 AVG Training Acc 66.45 % AVG Validation Acc 59.39 %\n",
      "Epoch:100/200 AVG Training Loss:0.578 AVG Validation Loss:0.710 AVG Training Acc 66.98 % AVG Validation Acc 59.93 %\n",
      "Epoch:110/200 AVG Training Loss:0.576 AVG Validation Loss:0.719 AVG Training Acc 66.63 % AVG Validation Acc 59.21 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.576 AVG Validation Loss:0.716 AVG Training Acc 67.12 % AVG Validation Acc 59.75 %\n",
      "Epoch:130/200 AVG Training Loss:0.574 AVG Validation Loss:0.719 AVG Training Acc 66.90 % AVG Validation Acc 60.20 %\n",
      "Epoch:140/200 AVG Training Loss:0.578 AVG Validation Loss:0.717 AVG Training Acc 66.96 % AVG Validation Acc 59.66 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.574 AVG Validation Loss:0.714 AVG Training Acc 67.17 % AVG Validation Acc 59.75 %\n",
      "Epoch:160/200 AVG Training Loss:0.573 AVG Validation Loss:0.716 AVG Training Acc 67.36 % AVG Validation Acc 59.03 %\n",
      "Epoch:170/200 AVG Training Loss:0.575 AVG Validation Loss:0.716 AVG Training Acc 67.13 % AVG Validation Acc 59.21 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.576 AVG Validation Loss:0.711 AVG Training Acc 66.66 % AVG Validation Acc 58.84 %\n",
      "Epoch:190/200 AVG Training Loss:0.576 AVG Validation Loss:0.720 AVG Training Acc 66.95 % AVG Validation Acc 59.57 %\n",
      "Epoch:200/200 AVG Training Loss:0.577 AVG Validation Loss:0.720 AVG Training Acc 67.02 % AVG Validation Acc 59.57 %\n",
      "Split 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6539a8734144c348a7a4a23dea37dd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.661 AVG Training Acc 61.86 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.658 AVG Training Acc 61.82 % AVG Validation Acc 62.73 %\n",
      "Epoch:30/200 AVG Training Loss:0.648 AVG Validation Loss:0.653 AVG Training Acc 62.36 % AVG Validation Acc 62.09 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.633 AVG Validation Loss:0.650 AVG Training Acc 63.65 % AVG Validation Acc 62.55 %\n",
      "Epoch:50/200 AVG Training Loss:0.623 AVG Validation Loss:0.655 AVG Training Acc 64.42 % AVG Validation Acc 61.82 %\n",
      "Epoch:60/200 AVG Training Loss:0.617 AVG Validation Loss:0.651 AVG Training Acc 65.37 % AVG Validation Acc 61.82 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.606 AVG Validation Loss:0.657 AVG Training Acc 66.17 % AVG Validation Acc 61.37 %\n",
      "Epoch:80/200 AVG Training Loss:0.608 AVG Validation Loss:0.655 AVG Training Acc 65.61 % AVG Validation Acc 61.55 %\n",
      "Epoch:90/200 AVG Training Loss:0.606 AVG Validation Loss:0.658 AVG Training Acc 66.06 % AVG Validation Acc 61.19 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.604 AVG Validation Loss:0.661 AVG Training Acc 66.18 % AVG Validation Acc 61.55 %\n",
      "Epoch:110/200 AVG Training Loss:0.606 AVG Validation Loss:0.661 AVG Training Acc 66.20 % AVG Validation Acc 61.37 %\n",
      "Epoch:120/200 AVG Training Loss:0.605 AVG Validation Loss:0.663 AVG Training Acc 65.87 % AVG Validation Acc 61.64 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.605 AVG Validation Loss:0.659 AVG Training Acc 65.96 % AVG Validation Acc 62.18 %\n",
      "Epoch:140/200 AVG Training Loss:0.608 AVG Validation Loss:0.660 AVG Training Acc 65.89 % AVG Validation Acc 61.19 %\n",
      "Epoch:150/200 AVG Training Loss:0.604 AVG Validation Loss:0.660 AVG Training Acc 66.15 % AVG Validation Acc 61.82 %\n",
      "Epoch:160/200 AVG Training Loss:0.605 AVG Validation Loss:0.661 AVG Training Acc 65.93 % AVG Validation Acc 61.37 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.604 AVG Validation Loss:0.660 AVG Training Acc 66.12 % AVG Validation Acc 61.64 %\n",
      "Epoch:180/200 AVG Training Loss:0.604 AVG Validation Loss:0.660 AVG Training Acc 65.82 % AVG Validation Acc 61.19 %\n",
      "Epoch:190/200 AVG Training Loss:0.604 AVG Validation Loss:0.666 AVG Training Acc 66.09 % AVG Validation Acc 60.74 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.605 AVG Validation Loss:0.663 AVG Training Acc 66.37 % AVG Validation Acc 62.00 %\n",
      "Split 101\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eb39b9aa4a44bbb8383cb65d899ae1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.657 AVG Training Acc 61.81 % AVG Validation Acc 62.04 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.655 AVG Training Acc 61.87 % AVG Validation Acc 61.77 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.628 AVG Validation Loss:0.675 AVG Training Acc 63.49 % AVG Validation Acc 58.88 %\n",
      "Epoch:40/200 AVG Training Loss:0.618 AVG Validation Loss:0.685 AVG Training Acc 64.32 % AVG Validation Acc 59.24 %\n",
      "Epoch:50/200 AVG Training Loss:0.608 AVG Validation Loss:0.693 AVG Training Acc 64.87 % AVG Validation Acc 59.87 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.598 AVG Validation Loss:0.702 AVG Training Acc 65.23 % AVG Validation Acc 59.60 %\n",
      "Epoch:70/200 AVG Training Loss:0.596 AVG Validation Loss:0.705 AVG Training Acc 65.52 % AVG Validation Acc 60.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.593 AVG Validation Loss:0.707 AVG Training Acc 66.23 % AVG Validation Acc 60.60 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.592 AVG Validation Loss:0.707 AVG Training Acc 66.10 % AVG Validation Acc 60.69 %\n",
      "Epoch:100/200 AVG Training Loss:0.592 AVG Validation Loss:0.708 AVG Training Acc 66.01 % AVG Validation Acc 60.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.590 AVG Validation Loss:0.708 AVG Training Acc 66.40 % AVG Validation Acc 59.78 %\n",
      "Epoch:120/200 AVG Training Loss:0.591 AVG Validation Loss:0.710 AVG Training Acc 66.50 % AVG Validation Acc 60.78 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.590 AVG Validation Loss:0.711 AVG Training Acc 66.33 % AVG Validation Acc 60.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.592 AVG Validation Loss:0.711 AVG Training Acc 66.01 % AVG Validation Acc 59.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.589 AVG Validation Loss:0.710 AVG Training Acc 66.13 % AVG Validation Acc 59.60 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.591 AVG Validation Loss:0.708 AVG Training Acc 66.22 % AVG Validation Acc 59.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.590 AVG Validation Loss:0.706 AVG Training Acc 65.70 % AVG Validation Acc 60.23 %\n",
      "Epoch:180/200 AVG Training Loss:0.589 AVG Validation Loss:0.709 AVG Training Acc 66.50 % AVG Validation Acc 60.05 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.590 AVG Validation Loss:0.707 AVG Training Acc 66.89 % AVG Validation Acc 60.50 %\n",
      "Epoch:200/200 AVG Training Loss:0.588 AVG Validation Loss:0.702 AVG Training Acc 66.40 % AVG Validation Acc 61.50 %\n",
      "Split 102\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca4f382e0234108bd0433e707fedaef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.665 AVG Training Acc 62.03 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.657 AVG Training Acc 61.65 % AVG Validation Acc 62.04 %\n",
      "Epoch:30/200 AVG Training Loss:0.647 AVG Validation Loss:0.662 AVG Training Acc 62.08 % AVG Validation Acc 61.50 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.637 AVG Validation Loss:0.661 AVG Training Acc 62.77 % AVG Validation Acc 61.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.628 AVG Validation Loss:0.670 AVG Training Acc 63.60 % AVG Validation Acc 60.41 %\n",
      "Epoch:60/200 AVG Training Loss:0.619 AVG Validation Loss:0.679 AVG Training Acc 63.38 % AVG Validation Acc 59.42 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.611 AVG Validation Loss:0.690 AVG Training Acc 64.01 % AVG Validation Acc 59.51 %\n",
      "Epoch:80/200 AVG Training Loss:0.609 AVG Validation Loss:0.694 AVG Training Acc 64.37 % AVG Validation Acc 58.34 %\n",
      "Epoch:90/200 AVG Training Loss:0.607 AVG Validation Loss:0.693 AVG Training Acc 64.38 % AVG Validation Acc 59.06 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.605 AVG Validation Loss:0.696 AVG Training Acc 64.34 % AVG Validation Acc 58.97 %\n",
      "Epoch:110/200 AVG Training Loss:0.605 AVG Validation Loss:0.691 AVG Training Acc 64.57 % AVG Validation Acc 58.70 %\n",
      "Epoch:120/200 AVG Training Loss:0.606 AVG Validation Loss:0.694 AVG Training Acc 64.72 % AVG Validation Acc 57.98 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.607 AVG Validation Loss:0.698 AVG Training Acc 64.32 % AVG Validation Acc 58.25 %\n",
      "Epoch:140/200 AVG Training Loss:0.605 AVG Validation Loss:0.692 AVG Training Acc 64.43 % AVG Validation Acc 58.88 %\n",
      "Epoch:150/200 AVG Training Loss:0.603 AVG Validation Loss:0.693 AVG Training Acc 64.83 % AVG Validation Acc 58.34 %\n",
      "Epoch:160/200 AVG Training Loss:0.605 AVG Validation Loss:0.695 AVG Training Acc 64.59 % AVG Validation Acc 57.80 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.607 AVG Validation Loss:0.693 AVG Training Acc 63.56 % AVG Validation Acc 58.70 %\n",
      "Epoch:180/200 AVG Training Loss:0.605 AVG Validation Loss:0.696 AVG Training Acc 64.31 % AVG Validation Acc 58.34 %\n",
      "Epoch:190/200 AVG Training Loss:0.607 AVG Validation Loss:0.696 AVG Training Acc 64.12 % AVG Validation Acc 58.43 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.606 AVG Validation Loss:0.699 AVG Training Acc 64.17 % AVG Validation Acc 57.80 %\n",
      "Split 103\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7612d2131a8c45dba80960ab9491df6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.663 AVG Training Acc 61.69 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.660 AVG Training Acc 61.89 % AVG Validation Acc 61.59 %\n",
      "Epoch:30/200 AVG Training Loss:0.642 AVG Validation Loss:0.673 AVG Training Acc 62.38 % AVG Validation Acc 62.22 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.620 AVG Validation Loss:0.674 AVG Training Acc 64.38 % AVG Validation Acc 62.22 %\n",
      "Epoch:50/200 AVG Training Loss:0.609 AVG Validation Loss:0.681 AVG Training Acc 65.03 % AVG Validation Acc 61.95 %\n",
      "Epoch:60/200 AVG Training Loss:0.601 AVG Validation Loss:0.680 AVG Training Acc 65.23 % AVG Validation Acc 61.23 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.594 AVG Validation Loss:0.682 AVG Training Acc 66.64 % AVG Validation Acc 61.86 %\n",
      "Epoch:80/200 AVG Training Loss:0.593 AVG Validation Loss:0.690 AVG Training Acc 66.28 % AVG Validation Acc 61.23 %\n",
      "Epoch:90/200 AVG Training Loss:0.589 AVG Validation Loss:0.693 AVG Training Acc 66.85 % AVG Validation Acc 61.41 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.592 AVG Validation Loss:0.683 AVG Training Acc 66.03 % AVG Validation Acc 61.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.589 AVG Validation Loss:0.688 AVG Training Acc 66.20 % AVG Validation Acc 61.68 %\n",
      "Epoch:120/200 AVG Training Loss:0.591 AVG Validation Loss:0.684 AVG Training Acc 66.18 % AVG Validation Acc 61.50 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.589 AVG Validation Loss:0.688 AVG Training Acc 66.96 % AVG Validation Acc 60.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.589 AVG Validation Loss:0.691 AVG Training Acc 66.49 % AVG Validation Acc 61.59 %\n",
      "Epoch:150/200 AVG Training Loss:0.590 AVG Validation Loss:0.688 AVG Training Acc 66.36 % AVG Validation Acc 61.41 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.591 AVG Validation Loss:0.690 AVG Training Acc 66.50 % AVG Validation Acc 61.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.592 AVG Validation Loss:0.687 AVG Training Acc 66.36 % AVG Validation Acc 61.50 %\n",
      "Epoch:180/200 AVG Training Loss:0.591 AVG Validation Loss:0.686 AVG Training Acc 66.21 % AVG Validation Acc 60.87 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.593 AVG Validation Loss:0.692 AVG Training Acc 66.33 % AVG Validation Acc 60.41 %\n",
      "Epoch:200/200 AVG Training Loss:0.588 AVG Validation Loss:0.684 AVG Training Acc 66.81 % AVG Validation Acc 61.23 %\n",
      "Split 104\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbfdd53c3f4e4c8faa4ad7a8b8c4c308",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.655 AVG Training Acc 61.70 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.652 AVG Training Acc 62.44 % AVG Validation Acc 61.68 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.643 AVG Validation Loss:0.655 AVG Training Acc 62.60 % AVG Validation Acc 59.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.628 AVG Validation Loss:0.662 AVG Training Acc 64.25 % AVG Validation Acc 60.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.621 AVG Validation Loss:0.668 AVG Training Acc 65.22 % AVG Validation Acc 60.50 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.611 AVG Validation Loss:0.674 AVG Training Acc 65.98 % AVG Validation Acc 60.41 %\n",
      "Epoch:70/200 AVG Training Loss:0.609 AVG Validation Loss:0.675 AVG Training Acc 66.24 % AVG Validation Acc 60.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.610 AVG Validation Loss:0.678 AVG Training Acc 65.57 % AVG Validation Acc 59.42 %\n",
      "Epoch:90/200 AVG Training Loss:0.609 AVG Validation Loss:0.676 AVG Training Acc 65.71 % AVG Validation Acc 60.05 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.608 AVG Validation Loss:0.678 AVG Training Acc 66.02 % AVG Validation Acc 59.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.609 AVG Validation Loss:0.678 AVG Training Acc 66.19 % AVG Validation Acc 59.96 %\n",
      "Epoch:120/200 AVG Training Loss:0.608 AVG Validation Loss:0.677 AVG Training Acc 65.73 % AVG Validation Acc 60.14 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.609 AVG Validation Loss:0.679 AVG Training Acc 65.59 % AVG Validation Acc 59.60 %\n",
      "Epoch:140/200 AVG Training Loss:0.607 AVG Validation Loss:0.679 AVG Training Acc 65.56 % AVG Validation Acc 59.42 %\n",
      "Epoch:150/200 AVG Training Loss:0.609 AVG Validation Loss:0.677 AVG Training Acc 65.57 % AVG Validation Acc 59.96 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.608 AVG Validation Loss:0.676 AVG Training Acc 66.25 % AVG Validation Acc 59.69 %\n",
      "Epoch:170/200 AVG Training Loss:0.608 AVG Validation Loss:0.675 AVG Training Acc 65.94 % AVG Validation Acc 59.69 %\n",
      "Epoch:180/200 AVG Training Loss:0.607 AVG Validation Loss:0.677 AVG Training Acc 65.80 % AVG Validation Acc 59.78 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.608 AVG Validation Loss:0.678 AVG Training Acc 65.98 % AVG Validation Acc 59.51 %\n",
      "Epoch:200/200 AVG Training Loss:0.608 AVG Validation Loss:0.679 AVG Training Acc 66.02 % AVG Validation Acc 60.32 %\n",
      "Split 105\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e73cc53b7024d318a836796a3b204d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.664 AVG Training Acc 62.03 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:0.661 AVG Training Acc 62.03 % AVG Validation Acc 61.77 %\n",
      "Epoch:30/200 AVG Training Loss:0.648 AVG Validation Loss:0.663 AVG Training Acc 62.26 % AVG Validation Acc 60.78 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.658 AVG Validation Loss:0.663 AVG Training Acc 61.83 % AVG Validation Acc 61.86 %\n",
      "Epoch:50/200 AVG Training Loss:0.656 AVG Validation Loss:0.664 AVG Training Acc 61.97 % AVG Validation Acc 61.77 %\n",
      "Epoch:60/200 AVG Training Loss:0.655 AVG Validation Loss:0.663 AVG Training Acc 61.90 % AVG Validation Acc 61.77 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.652 AVG Validation Loss:0.663 AVG Training Acc 61.80 % AVG Validation Acc 61.86 %\n",
      "Epoch:80/200 AVG Training Loss:0.652 AVG Validation Loss:0.663 AVG Training Acc 62.29 % AVG Validation Acc 61.41 %\n",
      "Epoch:90/200 AVG Training Loss:0.652 AVG Validation Loss:0.665 AVG Training Acc 62.12 % AVG Validation Acc 61.59 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.652 AVG Validation Loss:0.665 AVG Training Acc 61.91 % AVG Validation Acc 61.50 %\n",
      "Epoch:110/200 AVG Training Loss:0.651 AVG Validation Loss:0.665 AVG Training Acc 62.20 % AVG Validation Acc 61.77 %\n",
      "Epoch:120/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.28 % AVG Validation Acc 61.23 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.651 AVG Validation Loss:0.665 AVG Training Acc 62.13 % AVG Validation Acc 61.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.652 AVG Validation Loss:0.665 AVG Training Acc 61.94 % AVG Validation Acc 61.05 %\n",
      "Epoch:150/200 AVG Training Loss:0.651 AVG Validation Loss:0.665 AVG Training Acc 62.32 % AVG Validation Acc 61.05 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.651 AVG Validation Loss:0.665 AVG Training Acc 62.35 % AVG Validation Acc 61.50 %\n",
      "Epoch:170/200 AVG Training Loss:0.650 AVG Validation Loss:0.665 AVG Training Acc 62.02 % AVG Validation Acc 61.41 %\n",
      "Epoch:180/200 AVG Training Loss:0.651 AVG Validation Loss:0.665 AVG Training Acc 62.10 % AVG Validation Acc 61.14 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.651 AVG Validation Loss:0.665 AVG Training Acc 62.05 % AVG Validation Acc 61.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.651 AVG Validation Loss:0.664 AVG Training Acc 62.10 % AVG Validation Acc 61.41 %\n",
      "Split 106\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34661991dc444a07a039cacd8a0b089e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.655 AVG Training Acc 61.59 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.656 AVG Training Acc 61.93 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.648 AVG Validation Loss:0.655 AVG Training Acc 62.27 % AVG Validation Acc 61.91 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.629 AVG Validation Loss:0.662 AVG Training Acc 63.64 % AVG Validation Acc 61.37 %\n",
      "Epoch:50/200 AVG Training Loss:0.618 AVG Validation Loss:0.675 AVG Training Acc 64.15 % AVG Validation Acc 61.82 %\n",
      "Epoch:60/200 AVG Training Loss:0.607 AVG Validation Loss:0.686 AVG Training Acc 64.68 % AVG Validation Acc 62.64 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.598 AVG Validation Loss:0.692 AVG Training Acc 65.43 % AVG Validation Acc 61.82 %\n",
      "Epoch:80/200 AVG Training Loss:0.599 AVG Validation Loss:0.700 AVG Training Acc 65.54 % AVG Validation Acc 61.28 %\n",
      "Epoch:90/200 AVG Training Loss:0.596 AVG Validation Loss:0.699 AVG Training Acc 66.12 % AVG Validation Acc 61.73 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.596 AVG Validation Loss:0.699 AVG Training Acc 65.59 % AVG Validation Acc 61.46 %\n",
      "Epoch:110/200 AVG Training Loss:0.593 AVG Validation Loss:0.700 AVG Training Acc 65.88 % AVG Validation Acc 61.01 %\n",
      "Epoch:120/200 AVG Training Loss:0.596 AVG Validation Loss:0.704 AVG Training Acc 65.72 % AVG Validation Acc 61.37 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.595 AVG Validation Loss:0.699 AVG Training Acc 65.49 % AVG Validation Acc 61.64 %\n",
      "Epoch:140/200 AVG Training Loss:0.592 AVG Validation Loss:0.699 AVG Training Acc 65.97 % AVG Validation Acc 61.10 %\n",
      "Epoch:150/200 AVG Training Loss:0.595 AVG Validation Loss:0.698 AVG Training Acc 65.81 % AVG Validation Acc 61.01 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.595 AVG Validation Loss:0.699 AVG Training Acc 65.59 % AVG Validation Acc 61.73 %\n",
      "Epoch:170/200 AVG Training Loss:0.595 AVG Validation Loss:0.698 AVG Training Acc 65.59 % AVG Validation Acc 61.37 %\n",
      "Epoch:180/200 AVG Training Loss:0.595 AVG Validation Loss:0.694 AVG Training Acc 65.74 % AVG Validation Acc 61.55 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.594 AVG Validation Loss:0.697 AVG Training Acc 65.73 % AVG Validation Acc 61.64 %\n",
      "Epoch:200/200 AVG Training Loss:0.596 AVG Validation Loss:0.701 AVG Training Acc 65.63 % AVG Validation Acc 61.64 %\n",
      "Split 107\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f80bda48424777832bc4abb8730075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.657 AVG Training Acc 61.87 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.659 AVG Training Acc 61.96 % AVG Validation Acc 61.73 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.633 AVG Validation Loss:0.656 AVG Training Acc 63.27 % AVG Validation Acc 61.19 %\n",
      "Epoch:40/200 AVG Training Loss:0.622 AVG Validation Loss:0.662 AVG Training Acc 64.24 % AVG Validation Acc 61.10 %\n",
      "Epoch:50/200 AVG Training Loss:0.612 AVG Validation Loss:0.673 AVG Training Acc 65.23 % AVG Validation Acc 60.92 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.605 AVG Validation Loss:0.679 AVG Training Acc 65.14 % AVG Validation Acc 61.01 %\n",
      "Epoch:70/200 AVG Training Loss:0.601 AVG Validation Loss:0.684 AVG Training Acc 65.70 % AVG Validation Acc 60.83 %\n",
      "Epoch:80/200 AVG Training Loss:0.601 AVG Validation Loss:0.683 AVG Training Acc 65.39 % AVG Validation Acc 60.92 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.599 AVG Validation Loss:0.686 AVG Training Acc 65.94 % AVG Validation Acc 61.19 %\n",
      "Epoch:100/200 AVG Training Loss:0.598 AVG Validation Loss:0.688 AVG Training Acc 65.72 % AVG Validation Acc 60.92 %\n",
      "Epoch:110/200 AVG Training Loss:0.598 AVG Validation Loss:0.690 AVG Training Acc 66.03 % AVG Validation Acc 60.65 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.598 AVG Validation Loss:0.688 AVG Training Acc 65.66 % AVG Validation Acc 60.92 %\n",
      "Epoch:130/200 AVG Training Loss:0.597 AVG Validation Loss:0.687 AVG Training Acc 65.85 % AVG Validation Acc 61.19 %\n",
      "Epoch:140/200 AVG Training Loss:0.597 AVG Validation Loss:0.684 AVG Training Acc 66.23 % AVG Validation Acc 61.01 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.599 AVG Validation Loss:0.686 AVG Training Acc 65.86 % AVG Validation Acc 60.92 %\n",
      "Epoch:160/200 AVG Training Loss:0.599 AVG Validation Loss:0.686 AVG Training Acc 66.06 % AVG Validation Acc 61.46 %\n",
      "Epoch:170/200 AVG Training Loss:0.599 AVG Validation Loss:0.688 AVG Training Acc 65.52 % AVG Validation Acc 61.10 %\n",
      "Epoch:180/200 AVG Training Loss:0.598 AVG Validation Loss:0.687 AVG Training Acc 65.79 % AVG Validation Acc 61.28 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.600 AVG Validation Loss:0.688 AVG Training Acc 65.89 % AVG Validation Acc 61.19 %\n",
      "Epoch:200/200 AVG Training Loss:0.598 AVG Validation Loss:0.690 AVG Training Acc 66.02 % AVG Validation Acc 60.56 %\n",
      "Split 108\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ae20069c68e4678b715138707c8f0c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.657 AVG Validation Loss:0.657 AVG Training Acc 61.86 % AVG Validation Acc 62.00 %\n",
      "Epoch:20/200 AVG Training Loss:0.650 AVG Validation Loss:0.656 AVG Training Acc 61.95 % AVG Validation Acc 61.10 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.640 AVG Validation Loss:0.654 AVG Training Acc 62.12 % AVG Validation Acc 61.28 %\n",
      "Epoch:40/200 AVG Training Loss:0.626 AVG Validation Loss:0.662 AVG Training Acc 63.85 % AVG Validation Acc 60.83 %\n",
      "Epoch:50/200 AVG Training Loss:0.618 AVG Validation Loss:0.660 AVG Training Acc 64.87 % AVG Validation Acc 61.10 %\n",
      "Epoch:60/200 AVG Training Loss:0.610 AVG Validation Loss:0.672 AVG Training Acc 64.98 % AVG Validation Acc 60.74 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.607 AVG Validation Loss:0.662 AVG Training Acc 65.05 % AVG Validation Acc 60.83 %\n",
      "Epoch:80/200 AVG Training Loss:0.604 AVG Validation Loss:0.668 AVG Training Acc 66.02 % AVG Validation Acc 60.74 %\n",
      "Epoch:90/200 AVG Training Loss:0.603 AVG Validation Loss:0.668 AVG Training Acc 65.65 % AVG Validation Acc 60.29 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.602 AVG Validation Loss:0.671 AVG Training Acc 65.71 % AVG Validation Acc 60.83 %\n",
      "Epoch:110/200 AVG Training Loss:0.602 AVG Validation Loss:0.674 AVG Training Acc 65.65 % AVG Validation Acc 60.83 %\n",
      "Epoch:120/200 AVG Training Loss:0.602 AVG Validation Loss:0.672 AVG Training Acc 65.67 % AVG Validation Acc 60.56 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.602 AVG Validation Loss:0.674 AVG Training Acc 65.62 % AVG Validation Acc 60.47 %\n",
      "Epoch:140/200 AVG Training Loss:0.602 AVG Validation Loss:0.673 AVG Training Acc 65.91 % AVG Validation Acc 59.93 %\n",
      "Epoch:150/200 AVG Training Loss:0.602 AVG Validation Loss:0.674 AVG Training Acc 65.32 % AVG Validation Acc 60.02 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.604 AVG Validation Loss:0.674 AVG Training Acc 65.68 % AVG Validation Acc 60.02 %\n",
      "Epoch:170/200 AVG Training Loss:0.603 AVG Validation Loss:0.673 AVG Training Acc 65.84 % AVG Validation Acc 60.11 %\n",
      "Epoch:180/200 AVG Training Loss:0.604 AVG Validation Loss:0.671 AVG Training Acc 65.75 % AVG Validation Acc 60.29 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.603 AVG Validation Loss:0.675 AVG Training Acc 65.91 % AVG Validation Acc 59.84 %\n",
      "Epoch:200/200 AVG Training Loss:0.604 AVG Validation Loss:0.675 AVG Training Acc 65.11 % AVG Validation Acc 60.47 %\n",
      "Split 109\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81cdaab3ef084a3083ffb363aa0b8371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.657 AVG Training Acc 61.93 % AVG Validation Acc 61.82 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.654 AVG Training Acc 61.95 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.648 AVG Validation Loss:0.657 AVG Training Acc 62.10 % AVG Validation Acc 62.18 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.621 AVG Validation Loss:0.668 AVG Training Acc 62.94 % AVG Validation Acc 61.55 %\n",
      "Epoch:50/200 AVG Training Loss:0.608 AVG Validation Loss:0.678 AVG Training Acc 64.36 % AVG Validation Acc 61.73 %\n",
      "Epoch:60/200 AVG Training Loss:0.600 AVG Validation Loss:0.685 AVG Training Acc 64.24 % AVG Validation Acc 59.57 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.592 AVG Validation Loss:0.702 AVG Training Acc 64.91 % AVG Validation Acc 59.93 %\n",
      "Epoch:80/200 AVG Training Loss:0.588 AVG Validation Loss:0.706 AVG Training Acc 64.97 % AVG Validation Acc 60.92 %\n",
      "Epoch:90/200 AVG Training Loss:0.585 AVG Validation Loss:0.713 AVG Training Acc 64.78 % AVG Validation Acc 60.20 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.586 AVG Validation Loss:0.711 AVG Training Acc 65.44 % AVG Validation Acc 60.56 %\n",
      "Epoch:110/200 AVG Training Loss:0.586 AVG Validation Loss:0.704 AVG Training Acc 64.91 % AVG Validation Acc 60.92 %\n",
      "Epoch:120/200 AVG Training Loss:0.586 AVG Validation Loss:0.714 AVG Training Acc 65.14 % AVG Validation Acc 59.75 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.587 AVG Validation Loss:0.708 AVG Training Acc 65.29 % AVG Validation Acc 60.47 %\n",
      "Epoch:140/200 AVG Training Loss:0.586 AVG Validation Loss:0.715 AVG Training Acc 64.51 % AVG Validation Acc 61.01 %\n",
      "Epoch:150/200 AVG Training Loss:0.587 AVG Validation Loss:0.714 AVG Training Acc 65.27 % AVG Validation Acc 60.38 %\n",
      "Epoch:160/200 AVG Training Loss:0.585 AVG Validation Loss:0.708 AVG Training Acc 65.04 % AVG Validation Acc 60.83 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.589 AVG Validation Loss:0.707 AVG Training Acc 65.16 % AVG Validation Acc 60.20 %\n",
      "Epoch:180/200 AVG Training Loss:0.586 AVG Validation Loss:0.714 AVG Training Acc 65.09 % AVG Validation Acc 60.56 %\n",
      "Epoch:190/200 AVG Training Loss:0.586 AVG Validation Loss:0.712 AVG Training Acc 65.54 % AVG Validation Acc 60.02 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.586 AVG Validation Loss:0.712 AVG Training Acc 65.16 % AVG Validation Acc 60.74 %\n",
      "Split 110\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68f94222edf84077b224e510a56f7bce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 61.67 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.658 AVG Training Acc 61.83 % AVG Validation Acc 62.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.648 AVG Validation Loss:0.662 AVG Training Acc 62.28 % AVG Validation Acc 61.82 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.626 AVG Validation Loss:0.667 AVG Training Acc 63.49 % AVG Validation Acc 60.83 %\n",
      "Epoch:50/200 AVG Training Loss:0.619 AVG Validation Loss:0.669 AVG Training Acc 63.95 % AVG Validation Acc 60.83 %\n",
      "Epoch:60/200 AVG Training Loss:0.614 AVG Validation Loss:0.672 AVG Training Acc 64.09 % AVG Validation Acc 59.84 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.609 AVG Validation Loss:0.673 AVG Training Acc 64.83 % AVG Validation Acc 59.12 %\n",
      "Epoch:80/200 AVG Training Loss:0.608 AVG Validation Loss:0.680 AVG Training Acc 64.90 % AVG Validation Acc 59.12 %\n",
      "Epoch:90/200 AVG Training Loss:0.608 AVG Validation Loss:0.679 AVG Training Acc 64.67 % AVG Validation Acc 59.30 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.608 AVG Validation Loss:0.683 AVG Training Acc 64.96 % AVG Validation Acc 58.48 %\n",
      "Epoch:110/200 AVG Training Loss:0.607 AVG Validation Loss:0.677 AVG Training Acc 64.80 % AVG Validation Acc 59.30 %\n",
      "Epoch:120/200 AVG Training Loss:0.608 AVG Validation Loss:0.675 AVG Training Acc 64.72 % AVG Validation Acc 59.21 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.608 AVG Validation Loss:0.676 AVG Training Acc 65.07 % AVG Validation Acc 59.30 %\n",
      "Epoch:140/200 AVG Training Loss:0.607 AVG Validation Loss:0.677 AVG Training Acc 65.20 % AVG Validation Acc 59.21 %\n",
      "Epoch:150/200 AVG Training Loss:0.607 AVG Validation Loss:0.673 AVG Training Acc 64.50 % AVG Validation Acc 59.39 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.610 AVG Validation Loss:0.674 AVG Training Acc 64.73 % AVG Validation Acc 59.03 %\n",
      "Epoch:170/200 AVG Training Loss:0.609 AVG Validation Loss:0.677 AVG Training Acc 64.75 % AVG Validation Acc 59.48 %\n",
      "Epoch:180/200 AVG Training Loss:0.608 AVG Validation Loss:0.679 AVG Training Acc 64.95 % AVG Validation Acc 59.03 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.606 AVG Validation Loss:0.676 AVG Training Acc 65.06 % AVG Validation Acc 59.39 %\n",
      "Epoch:200/200 AVG Training Loss:0.608 AVG Validation Loss:0.671 AVG Training Acc 64.79 % AVG Validation Acc 59.39 %\n",
      "Split 111\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc3d03fbffbb4b529c9a1be28e16df93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.663 AVG Training Acc 61.83 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.656 AVG Training Acc 61.91 % AVG Validation Acc 62.31 %\n",
      "Epoch:30/200 AVG Training Loss:0.646 AVG Validation Loss:0.660 AVG Training Acc 62.24 % AVG Validation Acc 62.49 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.630 AVG Validation Loss:0.667 AVG Training Acc 63.13 % AVG Validation Acc 61.95 %\n",
      "Epoch:50/200 AVG Training Loss:0.622 AVG Validation Loss:0.675 AVG Training Acc 63.60 % AVG Validation Acc 61.68 %\n",
      "Epoch:60/200 AVG Training Loss:0.614 AVG Validation Loss:0.683 AVG Training Acc 63.86 % AVG Validation Acc 61.86 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.605 AVG Validation Loss:0.692 AVG Training Acc 64.69 % AVG Validation Acc 61.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.605 AVG Validation Loss:0.692 AVG Training Acc 64.66 % AVG Validation Acc 61.05 %\n",
      "Epoch:90/200 AVG Training Loss:0.602 AVG Validation Loss:0.695 AVG Training Acc 64.59 % AVG Validation Acc 60.78 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.604 AVG Validation Loss:0.693 AVG Training Acc 64.34 % AVG Validation Acc 60.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.603 AVG Validation Loss:0.693 AVG Training Acc 64.13 % AVG Validation Acc 61.32 %\n",
      "Epoch:120/200 AVG Training Loss:0.603 AVG Validation Loss:0.694 AVG Training Acc 64.63 % AVG Validation Acc 60.69 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.604 AVG Validation Loss:0.694 AVG Training Acc 64.31 % AVG Validation Acc 61.59 %\n",
      "Epoch:140/200 AVG Training Loss:0.605 AVG Validation Loss:0.693 AVG Training Acc 64.42 % AVG Validation Acc 61.41 %\n",
      "Epoch:150/200 AVG Training Loss:0.602 AVG Validation Loss:0.697 AVG Training Acc 64.37 % AVG Validation Acc 61.05 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.602 AVG Validation Loss:0.692 AVG Training Acc 64.92 % AVG Validation Acc 61.68 %\n",
      "Epoch:170/200 AVG Training Loss:0.602 AVG Validation Loss:0.694 AVG Training Acc 64.30 % AVG Validation Acc 60.23 %\n",
      "Epoch:180/200 AVG Training Loss:0.605 AVG Validation Loss:0.696 AVG Training Acc 63.99 % AVG Validation Acc 60.69 %\n",
      "Epoch:190/200 AVG Training Loss:0.604 AVG Validation Loss:0.696 AVG Training Acc 64.49 % AVG Validation Acc 61.50 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.603 AVG Validation Loss:0.698 AVG Training Acc 64.79 % AVG Validation Acc 61.05 %\n",
      "Split 112\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "beddc5f171ec4c7bb5232afdae08c74d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.661 AVG Training Acc 61.82 % AVG Validation Acc 61.41 %\n",
      "Epoch:20/200 AVG Training Loss:0.649 AVG Validation Loss:0.665 AVG Training Acc 61.94 % AVG Validation Acc 61.50 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.629 AVG Validation Loss:0.665 AVG Training Acc 63.36 % AVG Validation Acc 60.50 %\n",
      "Epoch:40/200 AVG Training Loss:0.618 AVG Validation Loss:0.679 AVG Training Acc 64.41 % AVG Validation Acc 59.60 %\n",
      "Epoch:50/200 AVG Training Loss:0.609 AVG Validation Loss:0.686 AVG Training Acc 65.16 % AVG Validation Acc 60.32 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.598 AVG Validation Loss:0.698 AVG Training Acc 65.30 % AVG Validation Acc 58.61 %\n",
      "Epoch:70/200 AVG Training Loss:0.597 AVG Validation Loss:0.701 AVG Training Acc 65.20 % AVG Validation Acc 58.52 %\n",
      "Epoch:80/200 AVG Training Loss:0.594 AVG Validation Loss:0.703 AVG Training Acc 65.34 % AVG Validation Acc 58.16 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.592 AVG Validation Loss:0.700 AVG Training Acc 65.90 % AVG Validation Acc 58.07 %\n",
      "Epoch:100/200 AVG Training Loss:0.592 AVG Validation Loss:0.703 AVG Training Acc 65.59 % AVG Validation Acc 57.53 %\n",
      "Epoch:110/200 AVG Training Loss:0.594 AVG Validation Loss:0.707 AVG Training Acc 65.86 % AVG Validation Acc 57.53 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.595 AVG Validation Loss:0.703 AVG Training Acc 65.37 % AVG Validation Acc 58.07 %\n",
      "Epoch:130/200 AVG Training Loss:0.594 AVG Validation Loss:0.706 AVG Training Acc 65.68 % AVG Validation Acc 58.34 %\n",
      "Epoch:140/200 AVG Training Loss:0.595 AVG Validation Loss:0.707 AVG Training Acc 65.62 % AVG Validation Acc 57.80 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.593 AVG Validation Loss:0.702 AVG Training Acc 65.64 % AVG Validation Acc 58.61 %\n",
      "Epoch:160/200 AVG Training Loss:0.591 AVG Validation Loss:0.701 AVG Training Acc 66.26 % AVG Validation Acc 58.07 %\n",
      "Epoch:170/200 AVG Training Loss:0.594 AVG Validation Loss:0.702 AVG Training Acc 66.10 % AVG Validation Acc 57.44 %\n",
      "Epoch:180/200 AVG Training Loss:0.594 AVG Validation Loss:0.703 AVG Training Acc 65.61 % AVG Validation Acc 58.07 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.595 AVG Validation Loss:0.706 AVG Training Acc 65.63 % AVG Validation Acc 57.62 %\n",
      "Epoch:200/200 AVG Training Loss:0.594 AVG Validation Loss:0.709 AVG Training Acc 65.71 % AVG Validation Acc 57.35 %\n",
      "Split 113\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5aedecc03c04b9b8ec251d7bdc44726",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.650 AVG Training Acc 61.85 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.649 AVG Training Acc 62.30 % AVG Validation Acc 61.50 %\n",
      "Epoch:30/200 AVG Training Loss:0.651 AVG Validation Loss:0.647 AVG Training Acc 62.34 % AVG Validation Acc 61.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.656 AVG Validation Loss:0.654 AVG Training Acc 61.56 % AVG Validation Acc 61.68 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.635 AVG Validation Loss:0.652 AVG Training Acc 63.06 % AVG Validation Acc 63.48 %\n",
      "Epoch:60/200 AVG Training Loss:0.627 AVG Validation Loss:0.657 AVG Training Acc 63.19 % AVG Validation Acc 63.48 %\n",
      "Epoch:70/200 AVG Training Loss:0.615 AVG Validation Loss:0.672 AVG Training Acc 64.57 % AVG Validation Acc 62.58 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.611 AVG Validation Loss:0.672 AVG Training Acc 64.51 % AVG Validation Acc 62.22 %\n",
      "Epoch:90/200 AVG Training Loss:0.608 AVG Validation Loss:0.679 AVG Training Acc 64.87 % AVG Validation Acc 61.86 %\n",
      "Epoch:100/200 AVG Training Loss:0.606 AVG Validation Loss:0.672 AVG Training Acc 64.88 % AVG Validation Acc 61.86 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.605 AVG Validation Loss:0.677 AVG Training Acc 64.87 % AVG Validation Acc 62.76 %\n",
      "Epoch:120/200 AVG Training Loss:0.607 AVG Validation Loss:0.678 AVG Training Acc 64.52 % AVG Validation Acc 62.13 %\n",
      "Epoch:130/200 AVG Training Loss:0.607 AVG Validation Loss:0.674 AVG Training Acc 64.96 % AVG Validation Acc 62.49 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.604 AVG Validation Loss:0.676 AVG Training Acc 65.03 % AVG Validation Acc 62.49 %\n",
      "Epoch:150/200 AVG Training Loss:0.604 AVG Validation Loss:0.673 AVG Training Acc 64.38 % AVG Validation Acc 62.04 %\n",
      "Epoch:160/200 AVG Training Loss:0.606 AVG Validation Loss:0.679 AVG Training Acc 64.23 % AVG Validation Acc 62.58 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.606 AVG Validation Loss:0.674 AVG Training Acc 64.29 % AVG Validation Acc 62.31 %\n",
      "Epoch:180/200 AVG Training Loss:0.605 AVG Validation Loss:0.674 AVG Training Acc 65.01 % AVG Validation Acc 62.76 %\n",
      "Epoch:190/200 AVG Training Loss:0.605 AVG Validation Loss:0.668 AVG Training Acc 65.01 % AVG Validation Acc 61.86 %\n",
      "Epoch:200/200 AVG Training Loss:0.606 AVG Validation Loss:0.677 AVG Training Acc 64.66 % AVG Validation Acc 62.04 %\n",
      "Epoch   200: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Split 114\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5332f2c7cac3412aaa9f982ac6847153",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.658 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.674 AVG Validation Loss:0.669 AVG Training Acc 60.53 % AVG Validation Acc 61.86 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.662 AVG Validation Loss:0.662 AVG Training Acc 61.76 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.659 AVG Validation Loss:0.663 AVG Training Acc 61.97 % AVG Validation Acc 61.68 %\n",
      "Epoch:50/200 AVG Training Loss:0.657 AVG Validation Loss:0.662 AVG Training Acc 62.00 % AVG Validation Acc 61.32 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.655 AVG Validation Loss:0.664 AVG Training Acc 62.10 % AVG Validation Acc 61.32 %\n",
      "Epoch:70/200 AVG Training Loss:0.653 AVG Validation Loss:0.665 AVG Training Acc 62.12 % AVG Validation Acc 61.23 %\n",
      "Epoch:80/200 AVG Training Loss:0.652 AVG Validation Loss:0.664 AVG Training Acc 62.48 % AVG Validation Acc 61.32 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.652 AVG Validation Loss:0.666 AVG Training Acc 62.41 % AVG Validation Acc 61.32 %\n",
      "Epoch:100/200 AVG Training Loss:0.652 AVG Validation Loss:0.665 AVG Training Acc 62.41 % AVG Validation Acc 61.23 %\n",
      "Epoch:110/200 AVG Training Loss:0.653 AVG Validation Loss:0.664 AVG Training Acc 62.29 % AVG Validation Acc 61.23 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.652 AVG Validation Loss:0.665 AVG Training Acc 62.59 % AVG Validation Acc 61.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.653 AVG Validation Loss:0.664 AVG Training Acc 62.48 % AVG Validation Acc 61.32 %\n",
      "Epoch:140/200 AVG Training Loss:0.650 AVG Validation Loss:0.664 AVG Training Acc 62.38 % AVG Validation Acc 61.14 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.652 AVG Validation Loss:0.665 AVG Training Acc 62.52 % AVG Validation Acc 61.23 %\n",
      "Epoch:160/200 AVG Training Loss:0.652 AVG Validation Loss:0.665 AVG Training Acc 62.26 % AVG Validation Acc 61.23 %\n",
      "Epoch:170/200 AVG Training Loss:0.652 AVG Validation Loss:0.664 AVG Training Acc 62.24 % AVG Validation Acc 61.23 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.652 AVG Validation Loss:0.665 AVG Training Acc 62.32 % AVG Validation Acc 61.23 %\n",
      "Epoch:190/200 AVG Training Loss:0.652 AVG Validation Loss:0.665 AVG Training Acc 62.17 % AVG Validation Acc 61.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.651 AVG Validation Loss:0.665 AVG Training Acc 62.52 % AVG Validation Acc 61.23 %\n",
      "Split 115\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12599089983b49e99d4577f456d92de5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.659 AVG Training Acc 61.88 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.656 AVG Training Acc 61.61 % AVG Validation Acc 62.67 %\n",
      "Epoch:30/200 AVG Training Loss:0.642 AVG Validation Loss:0.665 AVG Training Acc 62.37 % AVG Validation Acc 63.30 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.626 AVG Validation Loss:0.666 AVG Training Acc 63.76 % AVG Validation Acc 62.04 %\n",
      "Epoch:50/200 AVG Training Loss:0.610 AVG Validation Loss:0.678 AVG Training Acc 65.36 % AVG Validation Acc 61.86 %\n",
      "Epoch:60/200 AVG Training Loss:0.601 AVG Validation Loss:0.695 AVG Training Acc 65.90 % AVG Validation Acc 61.77 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.593 AVG Validation Loss:0.701 AVG Training Acc 66.77 % AVG Validation Acc 60.78 %\n",
      "Epoch:80/200 AVG Training Loss:0.587 AVG Validation Loss:0.704 AVG Training Acc 67.43 % AVG Validation Acc 60.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.585 AVG Validation Loss:0.710 AVG Training Acc 67.09 % AVG Validation Acc 60.87 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.588 AVG Validation Loss:0.707 AVG Training Acc 66.91 % AVG Validation Acc 60.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.589 AVG Validation Loss:0.710 AVG Training Acc 67.25 % AVG Validation Acc 60.32 %\n",
      "Epoch:120/200 AVG Training Loss:0.586 AVG Validation Loss:0.708 AVG Training Acc 67.82 % AVG Validation Acc 60.69 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.585 AVG Validation Loss:0.708 AVG Training Acc 67.28 % AVG Validation Acc 60.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.588 AVG Validation Loss:0.709 AVG Training Acc 66.94 % AVG Validation Acc 60.69 %\n",
      "Epoch:150/200 AVG Training Loss:0.585 AVG Validation Loss:0.709 AVG Training Acc 67.18 % AVG Validation Acc 60.78 %\n",
      "Epoch:160/200 AVG Training Loss:0.586 AVG Validation Loss:0.706 AVG Training Acc 67.42 % AVG Validation Acc 60.14 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.586 AVG Validation Loss:0.708 AVG Training Acc 67.42 % AVG Validation Acc 60.50 %\n",
      "Epoch:180/200 AVG Training Loss:0.585 AVG Validation Loss:0.713 AVG Training Acc 67.81 % AVG Validation Acc 60.78 %\n",
      "Epoch:190/200 AVG Training Loss:0.585 AVG Validation Loss:0.709 AVG Training Acc 67.18 % AVG Validation Acc 60.96 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.586 AVG Validation Loss:0.705 AVG Training Acc 67.66 % AVG Validation Acc 61.14 %\n",
      "Split 116\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6d29dda7621481a909b9b4c688ede9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.660 AVG Training Acc 61.77 % AVG Validation Acc 61.82 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.659 AVG Training Acc 62.22 % AVG Validation Acc 62.45 %\n",
      "Epoch:30/200 AVG Training Loss:0.644 AVG Validation Loss:0.661 AVG Training Acc 62.51 % AVG Validation Acc 61.28 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.623 AVG Validation Loss:0.671 AVG Training Acc 64.16 % AVG Validation Acc 58.94 %\n",
      "Epoch:50/200 AVG Training Loss:0.613 AVG Validation Loss:0.682 AVG Training Acc 64.88 % AVG Validation Acc 59.48 %\n",
      "Epoch:60/200 AVG Training Loss:0.602 AVG Validation Loss:0.689 AVG Training Acc 65.64 % AVG Validation Acc 59.93 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.603 AVG Validation Loss:0.689 AVG Training Acc 65.57 % AVG Validation Acc 59.30 %\n",
      "Epoch:80/200 AVG Training Loss:0.598 AVG Validation Loss:0.688 AVG Training Acc 65.87 % AVG Validation Acc 59.12 %\n",
      "Epoch:90/200 AVG Training Loss:0.597 AVG Validation Loss:0.689 AVG Training Acc 66.03 % AVG Validation Acc 58.66 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.595 AVG Validation Loss:0.692 AVG Training Acc 66.04 % AVG Validation Acc 59.12 %\n",
      "Epoch:110/200 AVG Training Loss:0.595 AVG Validation Loss:0.690 AVG Training Acc 66.19 % AVG Validation Acc 58.57 %\n",
      "Epoch:120/200 AVG Training Loss:0.597 AVG Validation Loss:0.697 AVG Training Acc 65.62 % AVG Validation Acc 58.94 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.594 AVG Validation Loss:0.693 AVG Training Acc 66.04 % AVG Validation Acc 58.48 %\n",
      "Epoch:140/200 AVG Training Loss:0.594 AVG Validation Loss:0.691 AVG Training Acc 65.59 % AVG Validation Acc 58.39 %\n",
      "Epoch:150/200 AVG Training Loss:0.596 AVG Validation Loss:0.695 AVG Training Acc 65.78 % AVG Validation Acc 59.30 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.594 AVG Validation Loss:0.693 AVG Training Acc 66.19 % AVG Validation Acc 58.84 %\n",
      "Epoch:170/200 AVG Training Loss:0.594 AVG Validation Loss:0.688 AVG Training Acc 66.10 % AVG Validation Acc 58.94 %\n",
      "Epoch:180/200 AVG Training Loss:0.594 AVG Validation Loss:0.692 AVG Training Acc 66.21 % AVG Validation Acc 58.39 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.594 AVG Validation Loss:0.691 AVG Training Acc 66.31 % AVG Validation Acc 58.57 %\n",
      "Epoch:200/200 AVG Training Loss:0.594 AVG Validation Loss:0.694 AVG Training Acc 65.83 % AVG Validation Acc 58.75 %\n",
      "Split 117\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4146985d2aa64deea241abdd13ec8c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.665 AVG Training Acc 61.89 % AVG Validation Acc 61.82 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.663 AVG Training Acc 61.80 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.640 AVG Validation Loss:0.663 AVG Training Acc 62.59 % AVG Validation Acc 61.64 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.615 AVG Validation Loss:0.688 AVG Training Acc 65.04 % AVG Validation Acc 59.12 %\n",
      "Epoch:50/200 AVG Training Loss:0.603 AVG Validation Loss:0.702 AVG Training Acc 65.73 % AVG Validation Acc 60.02 %\n",
      "Epoch:60/200 AVG Training Loss:0.592 AVG Validation Loss:0.716 AVG Training Acc 66.83 % AVG Validation Acc 57.94 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.583 AVG Validation Loss:0.725 AVG Training Acc 67.13 % AVG Validation Acc 58.30 %\n",
      "Epoch:80/200 AVG Training Loss:0.579 AVG Validation Loss:0.731 AVG Training Acc 67.44 % AVG Validation Acc 58.57 %\n",
      "Epoch:90/200 AVG Training Loss:0.579 AVG Validation Loss:0.736 AVG Training Acc 68.08 % AVG Validation Acc 59.12 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.577 AVG Validation Loss:0.739 AVG Training Acc 68.01 % AVG Validation Acc 58.39 %\n",
      "Epoch:110/200 AVG Training Loss:0.577 AVG Validation Loss:0.735 AVG Training Acc 67.91 % AVG Validation Acc 58.48 %\n",
      "Epoch:120/200 AVG Training Loss:0.579 AVG Validation Loss:0.733 AVG Training Acc 68.13 % AVG Validation Acc 59.39 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.576 AVG Validation Loss:0.733 AVG Training Acc 67.75 % AVG Validation Acc 58.57 %\n",
      "Epoch:140/200 AVG Training Loss:0.578 AVG Validation Loss:0.736 AVG Training Acc 67.70 % AVG Validation Acc 58.84 %\n",
      "Epoch:150/200 AVG Training Loss:0.578 AVG Validation Loss:0.735 AVG Training Acc 68.40 % AVG Validation Acc 58.57 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.578 AVG Validation Loss:0.737 AVG Training Acc 67.95 % AVG Validation Acc 58.12 %\n",
      "Epoch:170/200 AVG Training Loss:0.579 AVG Validation Loss:0.736 AVG Training Acc 67.99 % AVG Validation Acc 58.84 %\n",
      "Epoch:180/200 AVG Training Loss:0.580 AVG Validation Loss:0.745 AVG Training Acc 67.83 % AVG Validation Acc 58.57 %\n",
      "Epoch:190/200 AVG Training Loss:0.580 AVG Validation Loss:0.735 AVG Training Acc 67.68 % AVG Validation Acc 58.48 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.577 AVG Validation Loss:0.732 AVG Training Acc 67.49 % AVG Validation Acc 58.48 %\n",
      "Split 118\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2bc4ea0f6c84dc584978a0603eae0a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.654 AVG Training Acc 61.94 % AVG Validation Acc 61.82 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.654 AVG Training Acc 61.88 % AVG Validation Acc 62.36 %\n",
      "Epoch:30/200 AVG Training Loss:0.643 AVG Validation Loss:0.656 AVG Training Acc 62.20 % AVG Validation Acc 62.27 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.628 AVG Validation Loss:0.661 AVG Training Acc 63.21 % AVG Validation Acc 61.55 %\n",
      "Epoch:50/200 AVG Training Loss:0.618 AVG Validation Loss:0.671 AVG Training Acc 63.87 % AVG Validation Acc 61.46 %\n",
      "Epoch:60/200 AVG Training Loss:0.610 AVG Validation Loss:0.679 AVG Training Acc 64.48 % AVG Validation Acc 61.91 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.606 AVG Validation Loss:0.686 AVG Training Acc 64.73 % AVG Validation Acc 61.82 %\n",
      "Epoch:80/200 AVG Training Loss:0.603 AVG Validation Loss:0.690 AVG Training Acc 65.27 % AVG Validation Acc 62.00 %\n",
      "Epoch:90/200 AVG Training Loss:0.604 AVG Validation Loss:0.691 AVG Training Acc 64.70 % AVG Validation Acc 61.73 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.600 AVG Validation Loss:0.690 AVG Training Acc 64.61 % AVG Validation Acc 61.82 %\n",
      "Epoch:110/200 AVG Training Loss:0.601 AVG Validation Loss:0.688 AVG Training Acc 64.86 % AVG Validation Acc 61.73 %\n",
      "Epoch:120/200 AVG Training Loss:0.601 AVG Validation Loss:0.688 AVG Training Acc 65.06 % AVG Validation Acc 62.18 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.601 AVG Validation Loss:0.692 AVG Training Acc 64.91 % AVG Validation Acc 61.37 %\n",
      "Epoch:140/200 AVG Training Loss:0.602 AVG Validation Loss:0.691 AVG Training Acc 64.54 % AVG Validation Acc 61.37 %\n",
      "Epoch:150/200 AVG Training Loss:0.602 AVG Validation Loss:0.691 AVG Training Acc 64.82 % AVG Validation Acc 61.19 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.598 AVG Validation Loss:0.692 AVG Training Acc 65.18 % AVG Validation Acc 61.55 %\n",
      "Epoch:170/200 AVG Training Loss:0.600 AVG Validation Loss:0.690 AVG Training Acc 65.41 % AVG Validation Acc 61.55 %\n",
      "Epoch:180/200 AVG Training Loss:0.602 AVG Validation Loss:0.691 AVG Training Acc 64.62 % AVG Validation Acc 61.91 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.600 AVG Validation Loss:0.689 AVG Training Acc 65.32 % AVG Validation Acc 61.91 %\n",
      "Epoch:200/200 AVG Training Loss:0.600 AVG Validation Loss:0.689 AVG Training Acc 65.25 % AVG Validation Acc 61.28 %\n",
      "Split 119\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b7e323e71f246ff97842050bd5e2a66",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.655 AVG Training Acc 61.80 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:0.654 AVG Training Acc 62.02 % AVG Validation Acc 61.64 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.648 AVG Validation Loss:0.654 AVG Training Acc 62.20 % AVG Validation Acc 61.28 %\n",
      "Epoch:40/200 AVG Training Loss:0.640 AVG Validation Loss:0.655 AVG Training Acc 62.78 % AVG Validation Acc 60.92 %\n",
      "Epoch:50/200 AVG Training Loss:0.633 AVG Validation Loss:0.660 AVG Training Acc 63.19 % AVG Validation Acc 60.83 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.630 AVG Validation Loss:0.663 AVG Training Acc 63.43 % AVG Validation Acc 60.74 %\n",
      "Epoch:70/200 AVG Training Loss:0.628 AVG Validation Loss:0.662 AVG Training Acc 63.51 % AVG Validation Acc 61.01 %\n",
      "Epoch:80/200 AVG Training Loss:0.627 AVG Validation Loss:0.661 AVG Training Acc 63.89 % AVG Validation Acc 60.74 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.626 AVG Validation Loss:0.664 AVG Training Acc 63.64 % AVG Validation Acc 61.01 %\n",
      "Epoch:100/200 AVG Training Loss:0.627 AVG Validation Loss:0.665 AVG Training Acc 63.62 % AVG Validation Acc 60.74 %\n",
      "Epoch:110/200 AVG Training Loss:0.625 AVG Validation Loss:0.664 AVG Training Acc 64.09 % AVG Validation Acc 60.92 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.626 AVG Validation Loss:0.665 AVG Training Acc 63.78 % AVG Validation Acc 60.83 %\n",
      "Epoch:130/200 AVG Training Loss:0.627 AVG Validation Loss:0.665 AVG Training Acc 63.97 % AVG Validation Acc 60.65 %\n",
      "Epoch:140/200 AVG Training Loss:0.626 AVG Validation Loss:0.663 AVG Training Acc 63.75 % AVG Validation Acc 60.74 %\n",
      "Epoch:150/200 AVG Training Loss:0.624 AVG Validation Loss:0.664 AVG Training Acc 64.12 % AVG Validation Acc 60.92 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.625 AVG Validation Loss:0.664 AVG Training Acc 63.93 % AVG Validation Acc 61.01 %\n",
      "Epoch:170/200 AVG Training Loss:0.625 AVG Validation Loss:0.665 AVG Training Acc 63.84 % AVG Validation Acc 60.92 %\n",
      "Epoch:180/200 AVG Training Loss:0.625 AVG Validation Loss:0.665 AVG Training Acc 64.10 % AVG Validation Acc 61.10 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.625 AVG Validation Loss:0.665 AVG Training Acc 64.03 % AVG Validation Acc 61.01 %\n",
      "Epoch:200/200 AVG Training Loss:0.625 AVG Validation Loss:0.663 AVG Training Acc 64.17 % AVG Validation Acc 61.01 %\n",
      "Split 120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e01dacc80f604e9ab553f2947ecba065",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.658 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:0.654 AVG Training Acc 61.95 % AVG Validation Acc 62.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.646 AVG Validation Loss:0.661 AVG Training Acc 62.55 % AVG Validation Acc 62.00 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.632 AVG Validation Loss:0.657 AVG Training Acc 62.79 % AVG Validation Acc 61.19 %\n",
      "Epoch:50/200 AVG Training Loss:0.622 AVG Validation Loss:0.668 AVG Training Acc 63.67 % AVG Validation Acc 61.64 %\n",
      "Epoch:60/200 AVG Training Loss:0.612 AVG Validation Loss:0.676 AVG Training Acc 64.80 % AVG Validation Acc 60.65 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.607 AVG Validation Loss:0.678 AVG Training Acc 64.97 % AVG Validation Acc 62.00 %\n",
      "Epoch:80/200 AVG Training Loss:0.605 AVG Validation Loss:0.685 AVG Training Acc 65.18 % AVG Validation Acc 61.19 %\n",
      "Epoch:90/200 AVG Training Loss:0.602 AVG Validation Loss:0.684 AVG Training Acc 65.01 % AVG Validation Acc 61.01 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.602 AVG Validation Loss:0.689 AVG Training Acc 65.33 % AVG Validation Acc 61.19 %\n",
      "Epoch:110/200 AVG Training Loss:0.603 AVG Validation Loss:0.688 AVG Training Acc 65.44 % AVG Validation Acc 61.64 %\n",
      "Epoch:120/200 AVG Training Loss:0.603 AVG Validation Loss:0.684 AVG Training Acc 65.38 % AVG Validation Acc 61.91 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.603 AVG Validation Loss:0.684 AVG Training Acc 65.36 % AVG Validation Acc 61.91 %\n",
      "Epoch:140/200 AVG Training Loss:0.603 AVG Validation Loss:0.690 AVG Training Acc 65.64 % AVG Validation Acc 61.91 %\n",
      "Epoch:150/200 AVG Training Loss:0.600 AVG Validation Loss:0.685 AVG Training Acc 65.67 % AVG Validation Acc 62.00 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.603 AVG Validation Loss:0.688 AVG Training Acc 65.49 % AVG Validation Acc 62.00 %\n",
      "Epoch:170/200 AVG Training Loss:0.601 AVG Validation Loss:0.685 AVG Training Acc 65.65 % AVG Validation Acc 61.37 %\n",
      "Epoch:180/200 AVG Training Loss:0.603 AVG Validation Loss:0.685 AVG Training Acc 65.29 % AVG Validation Acc 61.82 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.602 AVG Validation Loss:0.685 AVG Training Acc 65.15 % AVG Validation Acc 61.91 %\n",
      "Epoch:200/200 AVG Training Loss:0.601 AVG Validation Loss:0.688 AVG Training Acc 65.64 % AVG Validation Acc 61.37 %\n",
      "Split 121\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb5d537d8bf496eb81f77414a499878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.657 AVG Training Acc 61.77 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.648 AVG Validation Loss:0.666 AVG Training Acc 61.91 % AVG Validation Acc 61.77 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.630 AVG Validation Loss:0.656 AVG Training Acc 63.37 % AVG Validation Acc 61.77 %\n",
      "Epoch:40/200 AVG Training Loss:0.620 AVG Validation Loss:0.665 AVG Training Acc 63.48 % AVG Validation Acc 62.31 %\n",
      "Epoch:50/200 AVG Training Loss:0.612 AVG Validation Loss:0.676 AVG Training Acc 64.28 % AVG Validation Acc 62.58 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.605 AVG Validation Loss:0.671 AVG Training Acc 65.15 % AVG Validation Acc 62.67 %\n",
      "Epoch:70/200 AVG Training Loss:0.602 AVG Validation Loss:0.679 AVG Training Acc 65.48 % AVG Validation Acc 63.12 %\n",
      "Epoch:80/200 AVG Training Loss:0.599 AVG Validation Loss:0.681 AVG Training Acc 65.29 % AVG Validation Acc 62.22 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.599 AVG Validation Loss:0.679 AVG Training Acc 65.51 % AVG Validation Acc 62.67 %\n",
      "Epoch:100/200 AVG Training Loss:0.599 AVG Validation Loss:0.679 AVG Training Acc 65.24 % AVG Validation Acc 61.86 %\n",
      "Epoch:110/200 AVG Training Loss:0.601 AVG Validation Loss:0.678 AVG Training Acc 65.50 % AVG Validation Acc 62.67 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.600 AVG Validation Loss:0.678 AVG Training Acc 65.54 % AVG Validation Acc 62.13 %\n",
      "Epoch:130/200 AVG Training Loss:0.600 AVG Validation Loss:0.672 AVG Training Acc 65.43 % AVG Validation Acc 62.85 %\n",
      "Epoch:140/200 AVG Training Loss:0.600 AVG Validation Loss:0.677 AVG Training Acc 65.64 % AVG Validation Acc 62.04 %\n",
      "Epoch:150/200 AVG Training Loss:0.601 AVG Validation Loss:0.681 AVG Training Acc 65.57 % AVG Validation Acc 61.86 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.600 AVG Validation Loss:0.679 AVG Training Acc 65.48 % AVG Validation Acc 62.49 %\n",
      "Epoch:170/200 AVG Training Loss:0.598 AVG Validation Loss:0.680 AVG Training Acc 65.90 % AVG Validation Acc 62.67 %\n",
      "Epoch:180/200 AVG Training Loss:0.601 AVG Validation Loss:0.681 AVG Training Acc 65.57 % AVG Validation Acc 62.22 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.598 AVG Validation Loss:0.683 AVG Training Acc 65.69 % AVG Validation Acc 62.76 %\n",
      "Epoch:200/200 AVG Training Loss:0.599 AVG Validation Loss:0.671 AVG Training Acc 65.67 % AVG Validation Acc 62.13 %\n",
      "Split 122\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a9ea316ffb9b4d56bbc531836f6e2ec7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.657 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.654 AVG Training Acc 62.20 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.645 AVG Validation Loss:0.656 AVG Training Acc 62.01 % AVG Validation Acc 61.14 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.634 AVG Validation Loss:0.654 AVG Training Acc 63.15 % AVG Validation Acc 61.41 %\n",
      "Epoch:50/200 AVG Training Loss:0.620 AVG Validation Loss:0.657 AVG Training Acc 63.96 % AVG Validation Acc 61.23 %\n",
      "Epoch:60/200 AVG Training Loss:0.608 AVG Validation Loss:0.664 AVG Training Acc 64.65 % AVG Validation Acc 60.78 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.598 AVG Validation Loss:0.669 AVG Training Acc 65.93 % AVG Validation Acc 60.69 %\n",
      "Epoch:80/200 AVG Training Loss:0.594 AVG Validation Loss:0.677 AVG Training Acc 65.64 % AVG Validation Acc 60.60 %\n",
      "Epoch:90/200 AVG Training Loss:0.593 AVG Validation Loss:0.679 AVG Training Acc 65.99 % AVG Validation Acc 60.69 %\n",
      "Epoch:100/200 AVG Training Loss:0.591 AVG Validation Loss:0.684 AVG Training Acc 65.74 % AVG Validation Acc 60.69 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.589 AVG Validation Loss:0.685 AVG Training Acc 66.27 % AVG Validation Acc 60.32 %\n",
      "Epoch:120/200 AVG Training Loss:0.593 AVG Validation Loss:0.678 AVG Training Acc 66.02 % AVG Validation Acc 60.41 %\n",
      "Epoch:130/200 AVG Training Loss:0.592 AVG Validation Loss:0.678 AVG Training Acc 65.87 % AVG Validation Acc 60.78 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.590 AVG Validation Loss:0.683 AVG Training Acc 66.23 % AVG Validation Acc 60.32 %\n",
      "Epoch:150/200 AVG Training Loss:0.590 AVG Validation Loss:0.682 AVG Training Acc 66.38 % AVG Validation Acc 60.23 %\n",
      "Epoch:160/200 AVG Training Loss:0.592 AVG Validation Loss:0.682 AVG Training Acc 65.47 % AVG Validation Acc 60.41 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.592 AVG Validation Loss:0.681 AVG Training Acc 66.05 % AVG Validation Acc 60.87 %\n",
      "Epoch:180/200 AVG Training Loss:0.593 AVG Validation Loss:0.684 AVG Training Acc 66.01 % AVG Validation Acc 60.60 %\n",
      "Epoch:190/200 AVG Training Loss:0.594 AVG Validation Loss:0.683 AVG Training Acc 65.88 % AVG Validation Acc 60.14 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.590 AVG Validation Loss:0.680 AVG Training Acc 66.49 % AVG Validation Acc 61.05 %\n",
      "Split 123\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be316b1ba27457db37cb45c9230a25d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.661 AVG Training Acc 61.87 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.654 AVG Training Acc 61.63 % AVG Validation Acc 61.77 %\n",
      "Epoch:30/200 AVG Training Loss:0.639 AVG Validation Loss:0.659 AVG Training Acc 62.79 % AVG Validation Acc 61.50 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.625 AVG Validation Loss:0.670 AVG Training Acc 63.50 % AVG Validation Acc 60.60 %\n",
      "Epoch:50/200 AVG Training Loss:0.608 AVG Validation Loss:0.683 AVG Training Acc 65.29 % AVG Validation Acc 60.32 %\n",
      "Epoch:60/200 AVG Training Loss:0.595 AVG Validation Loss:0.696 AVG Training Acc 66.36 % AVG Validation Acc 59.96 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.584 AVG Validation Loss:0.699 AVG Training Acc 67.01 % AVG Validation Acc 59.51 %\n",
      "Epoch:80/200 AVG Training Loss:0.586 AVG Validation Loss:0.702 AVG Training Acc 67.00 % AVG Validation Acc 59.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.581 AVG Validation Loss:0.705 AVG Training Acc 67.66 % AVG Validation Acc 59.69 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.580 AVG Validation Loss:0.709 AVG Training Acc 67.56 % AVG Validation Acc 59.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.585 AVG Validation Loss:0.705 AVG Training Acc 67.36 % AVG Validation Acc 59.60 %\n",
      "Epoch:120/200 AVG Training Loss:0.581 AVG Validation Loss:0.704 AVG Training Acc 67.55 % AVG Validation Acc 60.50 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.579 AVG Validation Loss:0.709 AVG Training Acc 67.82 % AVG Validation Acc 59.60 %\n",
      "Epoch:140/200 AVG Training Loss:0.583 AVG Validation Loss:0.705 AVG Training Acc 67.21 % AVG Validation Acc 59.87 %\n",
      "Epoch:150/200 AVG Training Loss:0.580 AVG Validation Loss:0.705 AVG Training Acc 67.73 % AVG Validation Acc 60.05 %\n",
      "Epoch:160/200 AVG Training Loss:0.582 AVG Validation Loss:0.704 AVG Training Acc 67.57 % AVG Validation Acc 60.14 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.579 AVG Validation Loss:0.704 AVG Training Acc 68.22 % AVG Validation Acc 60.05 %\n",
      "Epoch:180/200 AVG Training Loss:0.581 AVG Validation Loss:0.705 AVG Training Acc 67.60 % AVG Validation Acc 59.69 %\n",
      "Epoch:190/200 AVG Training Loss:0.584 AVG Validation Loss:0.706 AVG Training Acc 67.27 % AVG Validation Acc 59.69 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.581 AVG Validation Loss:0.703 AVG Training Acc 67.77 % AVG Validation Acc 60.41 %\n",
      "Split 124\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6649550f9d74338bc8bdb22f1a8346e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.655 AVG Training Acc 61.83 % AVG Validation Acc 61.77 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.650 AVG Training Acc 61.66 % AVG Validation Acc 61.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.664 AVG Validation Loss:0.663 AVG Training Acc 61.57 % AVG Validation Acc 61.86 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.655 AVG Validation Loss:0.660 AVG Training Acc 61.77 % AVG Validation Acc 61.50 %\n",
      "Epoch:50/200 AVG Training Loss:0.650 AVG Validation Loss:0.662 AVG Training Acc 62.54 % AVG Validation Acc 61.41 %\n",
      "Epoch:60/200 AVG Training Loss:0.648 AVG Validation Loss:0.661 AVG Training Acc 63.17 % AVG Validation Acc 61.68 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.644 AVG Validation Loss:0.661 AVG Training Acc 62.98 % AVG Validation Acc 60.87 %\n",
      "Epoch:80/200 AVG Training Loss:0.641 AVG Validation Loss:0.660 AVG Training Acc 63.57 % AVG Validation Acc 61.32 %\n",
      "Epoch:90/200 AVG Training Loss:0.641 AVG Validation Loss:0.663 AVG Training Acc 63.98 % AVG Validation Acc 60.87 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.641 AVG Validation Loss:0.662 AVG Training Acc 63.49 % AVG Validation Acc 60.69 %\n",
      "Epoch:110/200 AVG Training Loss:0.641 AVG Validation Loss:0.661 AVG Training Acc 63.77 % AVG Validation Acc 61.50 %\n",
      "Epoch:120/200 AVG Training Loss:0.641 AVG Validation Loss:0.663 AVG Training Acc 63.35 % AVG Validation Acc 60.05 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.642 AVG Validation Loss:0.664 AVG Training Acc 63.90 % AVG Validation Acc 60.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.640 AVG Validation Loss:0.663 AVG Training Acc 64.32 % AVG Validation Acc 60.23 %\n",
      "Epoch:150/200 AVG Training Loss:0.639 AVG Validation Loss:0.661 AVG Training Acc 63.96 % AVG Validation Acc 60.96 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.641 AVG Validation Loss:0.663 AVG Training Acc 63.74 % AVG Validation Acc 60.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.640 AVG Validation Loss:0.664 AVG Training Acc 64.02 % AVG Validation Acc 60.41 %\n",
      "Epoch:180/200 AVG Training Loss:0.642 AVG Validation Loss:0.662 AVG Training Acc 63.69 % AVG Validation Acc 60.87 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.641 AVG Validation Loss:0.664 AVG Training Acc 63.53 % AVG Validation Acc 61.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.641 AVG Validation Loss:0.660 AVG Training Acc 63.77 % AVG Validation Acc 61.14 %\n",
      "Split 125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "663e4ebb0832451ba3cdfc25b62ad47c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 62.04 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.657 AVG Training Acc 61.86 % AVG Validation Acc 61.77 %\n",
      "Epoch:30/200 AVG Training Loss:0.637 AVG Validation Loss:0.665 AVG Training Acc 62.56 % AVG Validation Acc 61.32 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.617 AVG Validation Loss:0.672 AVG Training Acc 63.75 % AVG Validation Acc 62.85 %\n",
      "Epoch:50/200 AVG Training Loss:0.610 AVG Validation Loss:0.683 AVG Training Acc 63.86 % AVG Validation Acc 61.86 %\n",
      "Epoch:60/200 AVG Training Loss:0.603 AVG Validation Loss:0.705 AVG Training Acc 64.83 % AVG Validation Acc 61.05 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.595 AVG Validation Loss:0.714 AVG Training Acc 65.26 % AVG Validation Acc 62.22 %\n",
      "Epoch:80/200 AVG Training Loss:0.592 AVG Validation Loss:0.718 AVG Training Acc 65.34 % AVG Validation Acc 61.32 %\n",
      "Epoch:90/200 AVG Training Loss:0.593 AVG Validation Loss:0.710 AVG Training Acc 65.31 % AVG Validation Acc 61.50 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.592 AVG Validation Loss:0.720 AVG Training Acc 65.06 % AVG Validation Acc 61.68 %\n",
      "Epoch:110/200 AVG Training Loss:0.591 AVG Validation Loss:0.730 AVG Training Acc 65.23 % AVG Validation Acc 61.77 %\n",
      "Epoch:120/200 AVG Training Loss:0.592 AVG Validation Loss:0.720 AVG Training Acc 65.36 % AVG Validation Acc 61.14 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.592 AVG Validation Loss:0.729 AVG Training Acc 65.51 % AVG Validation Acc 60.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.592 AVG Validation Loss:0.721 AVG Training Acc 64.52 % AVG Validation Acc 60.69 %\n",
      "Epoch:150/200 AVG Training Loss:0.593 AVG Validation Loss:0.724 AVG Training Acc 65.53 % AVG Validation Acc 61.32 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.594 AVG Validation Loss:0.714 AVG Training Acc 64.85 % AVG Validation Acc 60.60 %\n",
      "Epoch:170/200 AVG Training Loss:0.592 AVG Validation Loss:0.729 AVG Training Acc 64.75 % AVG Validation Acc 61.59 %\n",
      "Epoch:180/200 AVG Training Loss:0.591 AVG Validation Loss:0.727 AVG Training Acc 65.34 % AVG Validation Acc 61.05 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.591 AVG Validation Loss:0.734 AVG Training Acc 65.54 % AVG Validation Acc 60.41 %\n",
      "Epoch:200/200 AVG Training Loss:0.591 AVG Validation Loss:0.725 AVG Training Acc 65.29 % AVG Validation Acc 61.14 %\n",
      "Split 126\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0fbb582abc242e08d818cf80ee4b706",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.656 AVG Training Acc 61.68 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.664 AVG Training Acc 62.08 % AVG Validation Acc 61.73 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.631 AVG Validation Loss:0.669 AVG Training Acc 63.96 % AVG Validation Acc 60.47 %\n",
      "Epoch:40/200 AVG Training Loss:0.623 AVG Validation Loss:0.673 AVG Training Acc 64.51 % AVG Validation Acc 60.20 %\n",
      "Epoch:50/200 AVG Training Loss:0.614 AVG Validation Loss:0.683 AVG Training Acc 64.96 % AVG Validation Acc 60.38 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.609 AVG Validation Loss:0.685 AVG Training Acc 65.88 % AVG Validation Acc 59.75 %\n",
      "Epoch:70/200 AVG Training Loss:0.608 AVG Validation Loss:0.682 AVG Training Acc 65.85 % AVG Validation Acc 59.03 %\n",
      "Epoch:80/200 AVG Training Loss:0.605 AVG Validation Loss:0.688 AVG Training Acc 66.22 % AVG Validation Acc 58.66 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.604 AVG Validation Loss:0.684 AVG Training Acc 66.45 % AVG Validation Acc 58.75 %\n",
      "Epoch:100/200 AVG Training Loss:0.604 AVG Validation Loss:0.686 AVG Training Acc 66.44 % AVG Validation Acc 59.48 %\n",
      "Epoch:110/200 AVG Training Loss:0.605 AVG Validation Loss:0.688 AVG Training Acc 66.39 % AVG Validation Acc 59.21 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.607 AVG Validation Loss:0.687 AVG Training Acc 65.75 % AVG Validation Acc 59.03 %\n",
      "Epoch:130/200 AVG Training Loss:0.605 AVG Validation Loss:0.687 AVG Training Acc 65.94 % AVG Validation Acc 59.12 %\n",
      "Epoch:140/200 AVG Training Loss:0.605 AVG Validation Loss:0.692 AVG Training Acc 66.10 % AVG Validation Acc 58.94 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.604 AVG Validation Loss:0.689 AVG Training Acc 66.48 % AVG Validation Acc 59.21 %\n",
      "Epoch:160/200 AVG Training Loss:0.603 AVG Validation Loss:0.690 AVG Training Acc 66.32 % AVG Validation Acc 58.94 %\n",
      "Epoch:170/200 AVG Training Loss:0.605 AVG Validation Loss:0.686 AVG Training Acc 66.04 % AVG Validation Acc 59.57 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.605 AVG Validation Loss:0.688 AVG Training Acc 66.65 % AVG Validation Acc 58.94 %\n",
      "Epoch:190/200 AVG Training Loss:0.604 AVG Validation Loss:0.684 AVG Training Acc 66.23 % AVG Validation Acc 58.57 %\n",
      "Epoch:200/200 AVG Training Loss:0.604 AVG Validation Loss:0.684 AVG Training Acc 66.23 % AVG Validation Acc 59.30 %\n",
      "Split 127\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f6f7b7de564ae8853f5f18f8eb2957",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.666 AVG Training Acc 61.76 % AVG Validation Acc 61.91 %\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.649 AVG Validation Loss:0.669 AVG Training Acc 62.23 % AVG Validation Acc 60.38 %\n",
      "Epoch:30/200 AVG Training Loss:0.640 AVG Validation Loss:0.675 AVG Training Acc 63.10 % AVG Validation Acc 61.37 %\n",
      "Epoch:40/200 AVG Training Loss:0.631 AVG Validation Loss:0.681 AVG Training Acc 62.71 % AVG Validation Acc 61.82 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.622 AVG Validation Loss:0.685 AVG Training Acc 63.41 % AVG Validation Acc 61.46 %\n",
      "Epoch:60/200 AVG Training Loss:0.622 AVG Validation Loss:0.688 AVG Training Acc 63.53 % AVG Validation Acc 61.10 %\n",
      "Epoch:70/200 AVG Training Loss:0.617 AVG Validation Loss:0.693 AVG Training Acc 64.15 % AVG Validation Acc 61.46 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.619 AVG Validation Loss:0.692 AVG Training Acc 63.53 % AVG Validation Acc 61.28 %\n",
      "Epoch:90/200 AVG Training Loss:0.618 AVG Validation Loss:0.693 AVG Training Acc 63.77 % AVG Validation Acc 61.19 %\n",
      "Epoch:100/200 AVG Training Loss:0.618 AVG Validation Loss:0.692 AVG Training Acc 63.64 % AVG Validation Acc 61.91 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.618 AVG Validation Loss:0.691 AVG Training Acc 63.69 % AVG Validation Acc 61.19 %\n",
      "Epoch:120/200 AVG Training Loss:0.618 AVG Validation Loss:0.692 AVG Training Acc 64.00 % AVG Validation Acc 61.64 %\n",
      "Epoch:130/200 AVG Training Loss:0.618 AVG Validation Loss:0.693 AVG Training Acc 63.60 % AVG Validation Acc 61.37 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.619 AVG Validation Loss:0.692 AVG Training Acc 63.84 % AVG Validation Acc 61.37 %\n",
      "Epoch:150/200 AVG Training Loss:0.618 AVG Validation Loss:0.693 AVG Training Acc 64.20 % AVG Validation Acc 61.19 %\n",
      "Epoch:160/200 AVG Training Loss:0.618 AVG Validation Loss:0.693 AVG Training Acc 63.80 % AVG Validation Acc 61.19 %\n",
      "Epoch:170/200 AVG Training Loss:0.617 AVG Validation Loss:0.695 AVG Training Acc 63.59 % AVG Validation Acc 61.01 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.619 AVG Validation Loss:0.693 AVG Training Acc 63.62 % AVG Validation Acc 61.37 %\n",
      "Epoch:190/200 AVG Training Loss:0.618 AVG Validation Loss:0.692 AVG Training Acc 63.96 % AVG Validation Acc 61.64 %\n",
      "Epoch:200/200 AVG Training Loss:0.619 AVG Validation Loss:0.692 AVG Training Acc 63.78 % AVG Validation Acc 61.55 %\n",
      "Split 128\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8171ba57a9a647f695d8a3ccc7acc397",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.665 AVG Training Acc 61.84 % AVG Validation Acc 61.91 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.645 AVG Validation Loss:0.665 AVG Training Acc 62.05 % AVG Validation Acc 62.00 %\n",
      "Epoch:30/200 AVG Training Loss:0.637 AVG Validation Loss:0.669 AVG Training Acc 63.06 % AVG Validation Acc 60.47 %\n",
      "Epoch:40/200 AVG Training Loss:0.630 AVG Validation Loss:0.679 AVG Training Acc 63.98 % AVG Validation Acc 60.74 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.619 AVG Validation Loss:0.685 AVG Training Acc 64.43 % AVG Validation Acc 61.01 %\n",
      "Epoch:60/200 AVG Training Loss:0.617 AVG Validation Loss:0.688 AVG Training Acc 64.69 % AVG Validation Acc 60.65 %\n",
      "Epoch:70/200 AVG Training Loss:0.613 AVG Validation Loss:0.688 AVG Training Acc 64.83 % AVG Validation Acc 60.74 %\n",
      "Epoch:80/200 AVG Training Loss:0.613 AVG Validation Loss:0.687 AVG Training Acc 64.93 % AVG Validation Acc 61.01 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.612 AVG Validation Loss:0.688 AVG Training Acc 64.86 % AVG Validation Acc 61.10 %\n",
      "Epoch:100/200 AVG Training Loss:0.613 AVG Validation Loss:0.688 AVG Training Acc 64.39 % AVG Validation Acc 61.37 %\n",
      "Epoch:110/200 AVG Training Loss:0.612 AVG Validation Loss:0.689 AVG Training Acc 64.86 % AVG Validation Acc 61.37 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.611 AVG Validation Loss:0.687 AVG Training Acc 65.17 % AVG Validation Acc 61.55 %\n",
      "Epoch:130/200 AVG Training Loss:0.612 AVG Validation Loss:0.689 AVG Training Acc 64.93 % AVG Validation Acc 61.01 %\n",
      "Epoch:140/200 AVG Training Loss:0.610 AVG Validation Loss:0.690 AVG Training Acc 64.98 % AVG Validation Acc 61.37 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.611 AVG Validation Loss:0.692 AVG Training Acc 64.50 % AVG Validation Acc 60.83 %\n",
      "Epoch:160/200 AVG Training Loss:0.612 AVG Validation Loss:0.690 AVG Training Acc 64.78 % AVG Validation Acc 60.56 %\n",
      "Epoch:170/200 AVG Training Loss:0.612 AVG Validation Loss:0.690 AVG Training Acc 65.02 % AVG Validation Acc 61.82 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.613 AVG Validation Loss:0.691 AVG Training Acc 64.79 % AVG Validation Acc 61.10 %\n",
      "Epoch:190/200 AVG Training Loss:0.611 AVG Validation Loss:0.689 AVG Training Acc 65.53 % AVG Validation Acc 61.19 %\n",
      "Epoch:200/200 AVG Training Loss:0.612 AVG Validation Loss:0.687 AVG Training Acc 64.47 % AVG Validation Acc 62.36 %\n",
      "Split 129\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "131f8544bc5846a2a3d23f7cf6a1d0ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.657 AVG Validation Loss:0.658 AVG Training Acc 61.68 % AVG Validation Acc 62.18 %\n",
      "Epoch:20/200 AVG Training Loss:0.649 AVG Validation Loss:0.654 AVG Training Acc 61.88 % AVG Validation Acc 62.18 %\n",
      "Epoch:30/200 AVG Training Loss:0.645 AVG Validation Loss:0.655 AVG Training Acc 61.92 % AVG Validation Acc 61.64 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.623 AVG Validation Loss:0.661 AVG Training Acc 63.41 % AVG Validation Acc 60.74 %\n",
      "Epoch:50/200 AVG Training Loss:0.609 AVG Validation Loss:0.674 AVG Training Acc 63.72 % AVG Validation Acc 62.55 %\n",
      "Epoch:60/200 AVG Training Loss:0.600 AVG Validation Loss:0.691 AVG Training Acc 64.33 % AVG Validation Acc 61.55 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.587 AVG Validation Loss:0.706 AVG Training Acc 64.93 % AVG Validation Acc 62.09 %\n",
      "Epoch:80/200 AVG Training Loss:0.589 AVG Validation Loss:0.704 AVG Training Acc 65.55 % AVG Validation Acc 62.09 %\n",
      "Epoch:90/200 AVG Training Loss:0.585 AVG Validation Loss:0.704 AVG Training Acc 65.35 % AVG Validation Acc 62.18 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.583 AVG Validation Loss:0.703 AVG Training Acc 65.48 % AVG Validation Acc 62.18 %\n",
      "Epoch:110/200 AVG Training Loss:0.584 AVG Validation Loss:0.702 AVG Training Acc 65.65 % AVG Validation Acc 62.18 %\n",
      "Epoch:120/200 AVG Training Loss:0.585 AVG Validation Loss:0.701 AVG Training Acc 65.40 % AVG Validation Acc 62.18 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.581 AVG Validation Loss:0.701 AVG Training Acc 65.79 % AVG Validation Acc 62.36 %\n",
      "Epoch:140/200 AVG Training Loss:0.586 AVG Validation Loss:0.701 AVG Training Acc 65.37 % AVG Validation Acc 61.82 %\n",
      "Epoch:150/200 AVG Training Loss:0.583 AVG Validation Loss:0.700 AVG Training Acc 65.70 % AVG Validation Acc 62.36 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.585 AVG Validation Loss:0.710 AVG Training Acc 65.00 % AVG Validation Acc 62.27 %\n",
      "Epoch:170/200 AVG Training Loss:0.583 AVG Validation Loss:0.697 AVG Training Acc 64.91 % AVG Validation Acc 62.09 %\n",
      "Epoch:180/200 AVG Training Loss:0.585 AVG Validation Loss:0.706 AVG Training Acc 65.16 % AVG Validation Acc 62.18 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.584 AVG Validation Loss:0.700 AVG Training Acc 65.63 % AVG Validation Acc 61.73 %\n",
      "Epoch:200/200 AVG Training Loss:0.583 AVG Validation Loss:0.696 AVG Training Acc 65.44 % AVG Validation Acc 62.27 %\n",
      "Split 130\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddea07a57cda4192a4e0c50a1ffa5d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.659 AVG Training Acc 61.80 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.649 AVG Validation Loss:0.659 AVG Training Acc 61.74 % AVG Validation Acc 63.45 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.631 AVG Validation Loss:0.654 AVG Training Acc 63.19 % AVG Validation Acc 62.45 %\n",
      "Epoch:40/200 AVG Training Loss:0.616 AVG Validation Loss:0.668 AVG Training Acc 64.21 % AVG Validation Acc 61.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.606 AVG Validation Loss:0.679 AVG Training Acc 64.69 % AVG Validation Acc 61.82 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.596 AVG Validation Loss:0.690 AVG Training Acc 65.58 % AVG Validation Acc 61.55 %\n",
      "Epoch:70/200 AVG Training Loss:0.594 AVG Validation Loss:0.698 AVG Training Acc 65.78 % AVG Validation Acc 60.92 %\n",
      "Epoch:80/200 AVG Training Loss:0.594 AVG Validation Loss:0.703 AVG Training Acc 65.74 % AVG Validation Acc 61.10 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.591 AVG Validation Loss:0.706 AVG Training Acc 66.09 % AVG Validation Acc 61.55 %\n",
      "Epoch:100/200 AVG Training Loss:0.590 AVG Validation Loss:0.705 AVG Training Acc 66.21 % AVG Validation Acc 61.19 %\n",
      "Epoch:110/200 AVG Training Loss:0.591 AVG Validation Loss:0.708 AVG Training Acc 66.16 % AVG Validation Acc 61.01 %\n",
      "Epoch:120/200 AVG Training Loss:0.589 AVG Validation Loss:0.700 AVG Training Acc 66.68 % AVG Validation Acc 60.65 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.590 AVG Validation Loss:0.711 AVG Training Acc 66.02 % AVG Validation Acc 60.56 %\n",
      "Epoch:140/200 AVG Training Loss:0.592 AVG Validation Loss:0.706 AVG Training Acc 65.60 % AVG Validation Acc 60.83 %\n",
      "Epoch:150/200 AVG Training Loss:0.591 AVG Validation Loss:0.702 AVG Training Acc 66.10 % AVG Validation Acc 61.19 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.591 AVG Validation Loss:0.708 AVG Training Acc 66.03 % AVG Validation Acc 60.92 %\n",
      "Epoch:170/200 AVG Training Loss:0.589 AVG Validation Loss:0.709 AVG Training Acc 66.16 % AVG Validation Acc 60.20 %\n",
      "Epoch:180/200 AVG Training Loss:0.590 AVG Validation Loss:0.704 AVG Training Acc 66.15 % AVG Validation Acc 61.19 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.588 AVG Validation Loss:0.701 AVG Training Acc 66.30 % AVG Validation Acc 60.65 %\n",
      "Epoch:200/200 AVG Training Loss:0.592 AVG Validation Loss:0.705 AVG Training Acc 66.35 % AVG Validation Acc 61.01 %\n",
      "Split 131\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4085a341e329494284fef1879f5be6ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.655 AVG Training Acc 61.94 % AVG Validation Acc 61.77 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.656 AVG Training Acc 62.31 % AVG Validation Acc 61.50 %\n",
      "Epoch:30/200 AVG Training Loss:0.644 AVG Validation Loss:0.653 AVG Training Acc 62.58 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.640 AVG Validation Loss:0.655 AVG Training Acc 62.61 % AVG Validation Acc 60.23 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.623 AVG Validation Loss:0.663 AVG Training Acc 64.59 % AVG Validation Acc 61.23 %\n",
      "Epoch:60/200 AVG Training Loss:0.607 AVG Validation Loss:0.664 AVG Training Acc 65.83 % AVG Validation Acc 61.68 %\n",
      "Epoch:70/200 AVG Training Loss:0.596 AVG Validation Loss:0.668 AVG Training Acc 66.74 % AVG Validation Acc 62.67 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.587 AVG Validation Loss:0.670 AVG Training Acc 67.38 % AVG Validation Acc 61.95 %\n",
      "Epoch:90/200 AVG Training Loss:0.586 AVG Validation Loss:0.673 AVG Training Acc 67.26 % AVG Validation Acc 61.59 %\n",
      "Epoch:100/200 AVG Training Loss:0.583 AVG Validation Loss:0.677 AVG Training Acc 67.24 % AVG Validation Acc 61.14 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.582 AVG Validation Loss:0.670 AVG Training Acc 67.49 % AVG Validation Acc 61.50 %\n",
      "Epoch:120/200 AVG Training Loss:0.584 AVG Validation Loss:0.672 AVG Training Acc 67.15 % AVG Validation Acc 61.59 %\n",
      "Epoch:130/200 AVG Training Loss:0.583 AVG Validation Loss:0.668 AVG Training Acc 67.39 % AVG Validation Acc 61.95 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.584 AVG Validation Loss:0.679 AVG Training Acc 67.31 % AVG Validation Acc 61.68 %\n",
      "Epoch:150/200 AVG Training Loss:0.583 AVG Validation Loss:0.670 AVG Training Acc 67.47 % AVG Validation Acc 61.32 %\n",
      "Epoch:160/200 AVG Training Loss:0.583 AVG Validation Loss:0.676 AVG Training Acc 67.43 % AVG Validation Acc 61.23 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.583 AVG Validation Loss:0.678 AVG Training Acc 67.81 % AVG Validation Acc 61.05 %\n",
      "Epoch:180/200 AVG Training Loss:0.580 AVG Validation Loss:0.675 AVG Training Acc 67.83 % AVG Validation Acc 61.32 %\n",
      "Epoch:190/200 AVG Training Loss:0.582 AVG Validation Loss:0.673 AVG Training Acc 67.86 % AVG Validation Acc 61.32 %\n",
      "Epoch:200/200 AVG Training Loss:0.582 AVG Validation Loss:0.680 AVG Training Acc 67.61 % AVG Validation Acc 61.14 %\n",
      "Epoch   200: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Split 132\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab3bb6fbbfe5431d9b793be3a7c08d70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.655 AVG Training Acc 61.82 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.652 AVG Training Acc 62.32 % AVG Validation Acc 61.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.645 AVG Validation Loss:0.652 AVG Training Acc 62.33 % AVG Validation Acc 61.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.637 AVG Validation Loss:0.653 AVG Training Acc 62.61 % AVG Validation Acc 61.77 %\n",
      "Epoch:50/200 AVG Training Loss:0.633 AVG Validation Loss:0.654 AVG Training Acc 63.10 % AVG Validation Acc 61.86 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.599 AVG Validation Loss:0.673 AVG Training Acc 66.14 % AVG Validation Acc 60.69 %\n",
      "Epoch:70/200 AVG Training Loss:0.587 AVG Validation Loss:0.688 AVG Training Acc 67.08 % AVG Validation Acc 60.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.581 AVG Validation Loss:0.687 AVG Training Acc 67.44 % AVG Validation Acc 60.60 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.571 AVG Validation Loss:0.698 AVG Training Acc 67.45 % AVG Validation Acc 59.33 %\n",
      "Epoch:100/200 AVG Training Loss:0.567 AVG Validation Loss:0.710 AVG Training Acc 68.28 % AVG Validation Acc 59.51 %\n",
      "Epoch:110/200 AVG Training Loss:0.567 AVG Validation Loss:0.701 AVG Training Acc 68.56 % AVG Validation Acc 59.24 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.567 AVG Validation Loss:0.707 AVG Training Acc 68.53 % AVG Validation Acc 58.61 %\n",
      "Epoch:130/200 AVG Training Loss:0.564 AVG Validation Loss:0.697 AVG Training Acc 68.40 % AVG Validation Acc 60.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.561 AVG Validation Loss:0.696 AVG Training Acc 68.72 % AVG Validation Acc 58.88 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.563 AVG Validation Loss:0.699 AVG Training Acc 68.68 % AVG Validation Acc 59.60 %\n",
      "Epoch:160/200 AVG Training Loss:0.567 AVG Validation Loss:0.702 AVG Training Acc 68.27 % AVG Validation Acc 59.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.565 AVG Validation Loss:0.708 AVG Training Acc 68.16 % AVG Validation Acc 59.24 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.564 AVG Validation Loss:0.705 AVG Training Acc 68.83 % AVG Validation Acc 59.15 %\n",
      "Epoch:190/200 AVG Training Loss:0.564 AVG Validation Loss:0.700 AVG Training Acc 68.00 % AVG Validation Acc 59.51 %\n",
      "Epoch:200/200 AVG Training Loss:0.567 AVG Validation Loss:0.697 AVG Training Acc 67.92 % AVG Validation Acc 60.05 %\n",
      "Split 133\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7218be7c0f1e4628bf65fc92f955e164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.661 AVG Training Acc 61.73 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.667 AVG Training Acc 61.77 % AVG Validation Acc 59.69 %\n",
      "Epoch:30/200 AVG Training Loss:0.647 AVG Validation Loss:0.655 AVG Training Acc 62.01 % AVG Validation Acc 61.86 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.628 AVG Validation Loss:0.656 AVG Training Acc 63.41 % AVG Validation Acc 61.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.616 AVG Validation Loss:0.663 AVG Training Acc 64.20 % AVG Validation Acc 60.96 %\n",
      "Epoch:60/200 AVG Training Loss:0.607 AVG Validation Loss:0.664 AVG Training Acc 64.55 % AVG Validation Acc 61.32 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.600 AVG Validation Loss:0.668 AVG Training Acc 65.20 % AVG Validation Acc 62.04 %\n",
      "Epoch:80/200 AVG Training Loss:0.598 AVG Validation Loss:0.673 AVG Training Acc 65.50 % AVG Validation Acc 61.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.598 AVG Validation Loss:0.673 AVG Training Acc 65.79 % AVG Validation Acc 61.41 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.598 AVG Validation Loss:0.669 AVG Training Acc 65.56 % AVG Validation Acc 61.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.598 AVG Validation Loss:0.669 AVG Training Acc 64.99 % AVG Validation Acc 61.14 %\n",
      "Epoch:120/200 AVG Training Loss:0.597 AVG Validation Loss:0.671 AVG Training Acc 65.16 % AVG Validation Acc 61.05 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.596 AVG Validation Loss:0.671 AVG Training Acc 64.99 % AVG Validation Acc 60.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.594 AVG Validation Loss:0.673 AVG Training Acc 65.43 % AVG Validation Acc 61.32 %\n",
      "Epoch:150/200 AVG Training Loss:0.597 AVG Validation Loss:0.673 AVG Training Acc 64.99 % AVG Validation Acc 60.96 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.597 AVG Validation Loss:0.671 AVG Training Acc 65.39 % AVG Validation Acc 61.86 %\n",
      "Epoch:170/200 AVG Training Loss:0.599 AVG Validation Loss:0.676 AVG Training Acc 65.51 % AVG Validation Acc 61.23 %\n",
      "Epoch:180/200 AVG Training Loss:0.597 AVG Validation Loss:0.680 AVG Training Acc 65.36 % AVG Validation Acc 60.87 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.596 AVG Validation Loss:0.673 AVG Training Acc 65.70 % AVG Validation Acc 60.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.596 AVG Validation Loss:0.672 AVG Training Acc 65.27 % AVG Validation Acc 61.05 %\n",
      "Split 134\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a56c7b7e4d94492a206e0cb46a26a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.665 AVG Training Acc 61.85 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.648 AVG Validation Loss:0.665 AVG Training Acc 61.86 % AVG Validation Acc 62.31 %\n",
      "Epoch:30/200 AVG Training Loss:0.636 AVG Validation Loss:0.665 AVG Training Acc 63.15 % AVG Validation Acc 61.32 %\n",
      "Epoch:40/200 AVG Training Loss:0.664 AVG Validation Loss:0.660 AVG Training Acc 61.64 % AVG Validation Acc 61.59 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.657 AVG Validation Loss:0.663 AVG Training Acc 61.90 % AVG Validation Acc 62.04 %\n",
      "Epoch:60/200 AVG Training Loss:0.654 AVG Validation Loss:0.663 AVG Training Acc 61.95 % AVG Validation Acc 61.95 %\n",
      "Epoch:70/200 AVG Training Loss:0.653 AVG Validation Loss:0.669 AVG Training Acc 62.15 % AVG Validation Acc 61.68 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.651 AVG Validation Loss:0.666 AVG Training Acc 62.15 % AVG Validation Acc 61.41 %\n",
      "Epoch:90/200 AVG Training Loss:0.651 AVG Validation Loss:0.665 AVG Training Acc 62.24 % AVG Validation Acc 61.68 %\n",
      "Epoch:100/200 AVG Training Loss:0.649 AVG Validation Loss:0.667 AVG Training Acc 61.93 % AVG Validation Acc 61.86 %\n",
      "Epoch:110/200 AVG Training Loss:0.650 AVG Validation Loss:0.668 AVG Training Acc 62.06 % AVG Validation Acc 61.86 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.651 AVG Validation Loss:0.669 AVG Training Acc 62.01 % AVG Validation Acc 61.59 %\n",
      "Epoch:130/200 AVG Training Loss:0.650 AVG Validation Loss:0.668 AVG Training Acc 61.95 % AVG Validation Acc 61.95 %\n",
      "Epoch:140/200 AVG Training Loss:0.648 AVG Validation Loss:0.668 AVG Training Acc 62.09 % AVG Validation Acc 61.86 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 62.19 % AVG Validation Acc 61.86 %\n",
      "Epoch:160/200 AVG Training Loss:0.650 AVG Validation Loss:0.666 AVG Training Acc 62.03 % AVG Validation Acc 61.86 %\n",
      "Epoch:170/200 AVG Training Loss:0.648 AVG Validation Loss:0.665 AVG Training Acc 62.29 % AVG Validation Acc 62.13 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.651 AVG Validation Loss:0.666 AVG Training Acc 62.00 % AVG Validation Acc 61.86 %\n",
      "Epoch:190/200 AVG Training Loss:0.649 AVG Validation Loss:0.667 AVG Training Acc 62.02 % AVG Validation Acc 62.04 %\n",
      "Epoch:200/200 AVG Training Loss:0.650 AVG Validation Loss:0.668 AVG Training Acc 62.30 % AVG Validation Acc 61.95 %\n",
      "Split 135\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588154b3ae4d4c7c8b44dfb86d39fb9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.664 AVG Training Acc 62.04 % AVG Validation Acc 61.77 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.668 AVG Training Acc 61.73 % AVG Validation Acc 61.77 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.639 AVG Validation Loss:0.669 AVG Training Acc 62.35 % AVG Validation Acc 61.59 %\n",
      "Epoch:40/200 AVG Training Loss:0.623 AVG Validation Loss:0.677 AVG Training Acc 63.38 % AVG Validation Acc 59.96 %\n",
      "Epoch:50/200 AVG Training Loss:0.610 AVG Validation Loss:0.689 AVG Training Acc 64.55 % AVG Validation Acc 59.60 %\n",
      "Epoch:60/200 AVG Training Loss:0.604 AVG Validation Loss:0.705 AVG Training Acc 65.67 % AVG Validation Acc 59.15 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.601 AVG Validation Loss:0.704 AVG Training Acc 65.46 % AVG Validation Acc 58.70 %\n",
      "Epoch:80/200 AVG Training Loss:0.597 AVG Validation Loss:0.709 AVG Training Acc 66.03 % AVG Validation Acc 59.06 %\n",
      "Epoch:90/200 AVG Training Loss:0.595 AVG Validation Loss:0.704 AVG Training Acc 66.29 % AVG Validation Acc 59.15 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.595 AVG Validation Loss:0.703 AVG Training Acc 65.89 % AVG Validation Acc 59.42 %\n",
      "Epoch:110/200 AVG Training Loss:0.594 AVG Validation Loss:0.710 AVG Training Acc 66.41 % AVG Validation Acc 59.15 %\n",
      "Epoch:120/200 AVG Training Loss:0.593 AVG Validation Loss:0.710 AVG Training Acc 66.13 % AVG Validation Acc 59.15 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.594 AVG Validation Loss:0.706 AVG Training Acc 66.20 % AVG Validation Acc 59.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.592 AVG Validation Loss:0.708 AVG Training Acc 66.47 % AVG Validation Acc 59.15 %\n",
      "Epoch:150/200 AVG Training Loss:0.593 AVG Validation Loss:0.712 AVG Training Acc 65.63 % AVG Validation Acc 59.06 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.594 AVG Validation Loss:0.710 AVG Training Acc 66.55 % AVG Validation Acc 59.69 %\n",
      "Epoch:170/200 AVG Training Loss:0.595 AVG Validation Loss:0.709 AVG Training Acc 65.70 % AVG Validation Acc 58.70 %\n",
      "Epoch:180/200 AVG Training Loss:0.596 AVG Validation Loss:0.711 AVG Training Acc 66.52 % AVG Validation Acc 59.24 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.592 AVG Validation Loss:0.713 AVG Training Acc 66.29 % AVG Validation Acc 58.88 %\n",
      "Epoch:200/200 AVG Training Loss:0.593 AVG Validation Loss:0.708 AVG Training Acc 66.46 % AVG Validation Acc 59.06 %\n",
      "Split 136\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd000b14d165495e86ad65b69ac6ac35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.655 AVG Training Acc 61.87 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.657 AVG Training Acc 62.08 % AVG Validation Acc 60.92 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.639 AVG Validation Loss:0.658 AVG Training Acc 62.78 % AVG Validation Acc 60.38 %\n",
      "Epoch:40/200 AVG Training Loss:0.633 AVG Validation Loss:0.659 AVG Training Acc 63.64 % AVG Validation Acc 60.29 %\n",
      "Epoch:50/200 AVG Training Loss:0.627 AVG Validation Loss:0.667 AVG Training Acc 64.10 % AVG Validation Acc 59.66 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.619 AVG Validation Loss:0.672 AVG Training Acc 64.11 % AVG Validation Acc 60.47 %\n",
      "Epoch:70/200 AVG Training Loss:0.618 AVG Validation Loss:0.673 AVG Training Acc 65.05 % AVG Validation Acc 61.01 %\n",
      "Epoch:80/200 AVG Training Loss:0.617 AVG Validation Loss:0.673 AVG Training Acc 64.71 % AVG Validation Acc 60.56 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.616 AVG Validation Loss:0.674 AVG Training Acc 64.76 % AVG Validation Acc 60.20 %\n",
      "Epoch:100/200 AVG Training Loss:0.616 AVG Validation Loss:0.675 AVG Training Acc 64.89 % AVG Validation Acc 60.29 %\n",
      "Epoch:110/200 AVG Training Loss:0.616 AVG Validation Loss:0.674 AVG Training Acc 64.97 % AVG Validation Acc 60.47 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.616 AVG Validation Loss:0.673 AVG Training Acc 64.73 % AVG Validation Acc 60.20 %\n",
      "Epoch:130/200 AVG Training Loss:0.614 AVG Validation Loss:0.675 AVG Training Acc 64.97 % AVG Validation Acc 60.20 %\n",
      "Epoch:140/200 AVG Training Loss:0.616 AVG Validation Loss:0.673 AVG Training Acc 64.93 % AVG Validation Acc 60.11 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.615 AVG Validation Loss:0.675 AVG Training Acc 64.99 % AVG Validation Acc 60.29 %\n",
      "Epoch:160/200 AVG Training Loss:0.616 AVG Validation Loss:0.673 AVG Training Acc 64.81 % AVG Validation Acc 60.56 %\n",
      "Epoch:170/200 AVG Training Loss:0.616 AVG Validation Loss:0.673 AVG Training Acc 64.47 % AVG Validation Acc 60.38 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.617 AVG Validation Loss:0.676 AVG Training Acc 64.59 % AVG Validation Acc 60.47 %\n",
      "Epoch:190/200 AVG Training Loss:0.617 AVG Validation Loss:0.674 AVG Training Acc 64.52 % AVG Validation Acc 60.38 %\n",
      "Epoch:200/200 AVG Training Loss:0.615 AVG Validation Loss:0.671 AVG Training Acc 64.97 % AVG Validation Acc 60.11 %\n",
      "Split 137\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00a28c57d9864d9e8140a6e364aa6584",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.666 AVG Training Acc 61.91 % AVG Validation Acc 62.00 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.672 AVG Training Acc 61.96 % AVG Validation Acc 61.64 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.648 AVG Validation Loss:0.666 AVG Training Acc 62.47 % AVG Validation Acc 61.28 %\n",
      "Epoch:40/200 AVG Training Loss:0.643 AVG Validation Loss:0.668 AVG Training Acc 62.24 % AVG Validation Acc 61.28 %\n",
      "Epoch:50/200 AVG Training Loss:0.636 AVG Validation Loss:0.672 AVG Training Acc 62.83 % AVG Validation Acc 62.36 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.630 AVG Validation Loss:0.675 AVG Training Acc 62.85 % AVG Validation Acc 61.01 %\n",
      "Epoch:70/200 AVG Training Loss:0.627 AVG Validation Loss:0.676 AVG Training Acc 63.22 % AVG Validation Acc 61.01 %\n",
      "Epoch:80/200 AVG Training Loss:0.626 AVG Validation Loss:0.680 AVG Training Acc 63.56 % AVG Validation Acc 60.74 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.626 AVG Validation Loss:0.679 AVG Training Acc 63.77 % AVG Validation Acc 60.92 %\n",
      "Epoch:100/200 AVG Training Loss:0.626 AVG Validation Loss:0.679 AVG Training Acc 63.96 % AVG Validation Acc 61.28 %\n",
      "Epoch:110/200 AVG Training Loss:0.626 AVG Validation Loss:0.681 AVG Training Acc 63.41 % AVG Validation Acc 61.01 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.626 AVG Validation Loss:0.678 AVG Training Acc 63.31 % AVG Validation Acc 61.10 %\n",
      "Epoch:130/200 AVG Training Loss:0.625 AVG Validation Loss:0.680 AVG Training Acc 63.43 % AVG Validation Acc 61.01 %\n",
      "Epoch:140/200 AVG Training Loss:0.625 AVG Validation Loss:0.680 AVG Training Acc 63.45 % AVG Validation Acc 60.92 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.625 AVG Validation Loss:0.680 AVG Training Acc 63.83 % AVG Validation Acc 60.74 %\n",
      "Epoch:160/200 AVG Training Loss:0.627 AVG Validation Loss:0.677 AVG Training Acc 62.86 % AVG Validation Acc 61.01 %\n",
      "Epoch:170/200 AVG Training Loss:0.625 AVG Validation Loss:0.678 AVG Training Acc 63.71 % AVG Validation Acc 60.83 %\n",
      "Epoch:180/200 AVG Training Loss:0.625 AVG Validation Loss:0.680 AVG Training Acc 63.28 % AVG Validation Acc 61.01 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.626 AVG Validation Loss:0.681 AVG Training Acc 63.02 % AVG Validation Acc 60.83 %\n",
      "Epoch:200/200 AVG Training Loss:0.625 AVG Validation Loss:0.680 AVG Training Acc 63.32 % AVG Validation Acc 61.28 %\n",
      "Split 138\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0bbec5a23c04e65896e367d4583e7b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.658 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.650 AVG Validation Loss:0.658 AVG Training Acc 61.87 % AVG Validation Acc 62.27 %\n",
      "Epoch:30/200 AVG Training Loss:0.638 AVG Validation Loss:0.683 AVG Training Acc 63.37 % AVG Validation Acc 61.19 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.614 AVG Validation Loss:0.680 AVG Training Acc 65.48 % AVG Validation Acc 59.84 %\n",
      "Epoch:50/200 AVG Training Loss:0.605 AVG Validation Loss:0.684 AVG Training Acc 66.06 % AVG Validation Acc 60.02 %\n",
      "Epoch:60/200 AVG Training Loss:0.599 AVG Validation Loss:0.689 AVG Training Acc 66.39 % AVG Validation Acc 60.02 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.593 AVG Validation Loss:0.688 AVG Training Acc 66.97 % AVG Validation Acc 59.66 %\n",
      "Epoch:80/200 AVG Training Loss:0.592 AVG Validation Loss:0.690 AVG Training Acc 66.68 % AVG Validation Acc 58.94 %\n",
      "Epoch:90/200 AVG Training Loss:0.589 AVG Validation Loss:0.697 AVG Training Acc 67.16 % AVG Validation Acc 58.21 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.591 AVG Validation Loss:0.695 AVG Training Acc 67.02 % AVG Validation Acc 58.30 %\n",
      "Epoch:110/200 AVG Training Loss:0.591 AVG Validation Loss:0.698 AVG Training Acc 67.11 % AVG Validation Acc 58.84 %\n",
      "Epoch:120/200 AVG Training Loss:0.591 AVG Validation Loss:0.694 AVG Training Acc 67.19 % AVG Validation Acc 58.66 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.590 AVG Validation Loss:0.693 AVG Training Acc 66.93 % AVG Validation Acc 58.66 %\n",
      "Epoch:140/200 AVG Training Loss:0.591 AVG Validation Loss:0.694 AVG Training Acc 67.33 % AVG Validation Acc 58.03 %\n",
      "Epoch:150/200 AVG Training Loss:0.590 AVG Validation Loss:0.690 AVG Training Acc 67.11 % AVG Validation Acc 58.84 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.589 AVG Validation Loss:0.694 AVG Training Acc 67.18 % AVG Validation Acc 58.84 %\n",
      "Epoch:170/200 AVG Training Loss:0.589 AVG Validation Loss:0.695 AVG Training Acc 67.18 % AVG Validation Acc 59.12 %\n",
      "Epoch:180/200 AVG Training Loss:0.591 AVG Validation Loss:0.694 AVG Training Acc 67.10 % AVG Validation Acc 59.03 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.589 AVG Validation Loss:0.695 AVG Training Acc 67.67 % AVG Validation Acc 58.39 %\n",
      "Epoch:200/200 AVG Training Loss:0.589 AVG Validation Loss:0.691 AVG Training Acc 67.02 % AVG Validation Acc 58.75 %\n",
      "Split 139\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b70b918a9c84fa7a78c0e1de6f4ce23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.652 AVG Training Acc 61.64 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.646 AVG Validation Loss:0.651 AVG Training Acc 62.30 % AVG Validation Acc 61.82 %\n",
      "Epoch:30/200 AVG Training Loss:0.642 AVG Validation Loss:0.647 AVG Training Acc 62.24 % AVG Validation Acc 62.27 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.617 AVG Validation Loss:0.659 AVG Training Acc 63.75 % AVG Validation Acc 62.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.603 AVG Validation Loss:0.671 AVG Training Acc 64.80 % AVG Validation Acc 60.74 %\n",
      "Epoch:60/200 AVG Training Loss:0.596 AVG Validation Loss:0.683 AVG Training Acc 65.04 % AVG Validation Acc 61.64 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.588 AVG Validation Loss:0.691 AVG Training Acc 65.82 % AVG Validation Acc 60.92 %\n",
      "Epoch:80/200 AVG Training Loss:0.585 AVG Validation Loss:0.693 AVG Training Acc 66.03 % AVG Validation Acc 61.10 %\n",
      "Epoch:90/200 AVG Training Loss:0.585 AVG Validation Loss:0.688 AVG Training Acc 65.84 % AVG Validation Acc 61.73 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.582 AVG Validation Loss:0.697 AVG Training Acc 66.06 % AVG Validation Acc 61.46 %\n",
      "Epoch:110/200 AVG Training Loss:0.583 AVG Validation Loss:0.695 AVG Training Acc 66.22 % AVG Validation Acc 60.92 %\n",
      "Epoch:120/200 AVG Training Loss:0.584 AVG Validation Loss:0.691 AVG Training Acc 65.89 % AVG Validation Acc 61.46 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.582 AVG Validation Loss:0.694 AVG Training Acc 66.51 % AVG Validation Acc 61.01 %\n",
      "Epoch:140/200 AVG Training Loss:0.582 AVG Validation Loss:0.691 AVG Training Acc 66.33 % AVG Validation Acc 61.28 %\n",
      "Epoch:150/200 AVG Training Loss:0.583 AVG Validation Loss:0.692 AVG Training Acc 66.05 % AVG Validation Acc 61.19 %\n",
      "Epoch:160/200 AVG Training Loss:0.582 AVG Validation Loss:0.696 AVG Training Acc 66.69 % AVG Validation Acc 61.55 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.583 AVG Validation Loss:0.690 AVG Training Acc 66.14 % AVG Validation Acc 62.36 %\n",
      "Epoch:180/200 AVG Training Loss:0.584 AVG Validation Loss:0.695 AVG Training Acc 66.15 % AVG Validation Acc 61.46 %\n",
      "Epoch:190/200 AVG Training Loss:0.583 AVG Validation Loss:0.699 AVG Training Acc 66.08 % AVG Validation Acc 61.19 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.583 AVG Validation Loss:0.700 AVG Training Acc 66.04 % AVG Validation Acc 61.37 %\n",
      "Split 140\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "981a70c9ec41425a98151270ffce99d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.668 AVG Training Acc 61.70 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.650 AVG Validation Loss:0.654 AVG Training Acc 61.82 % AVG Validation Acc 62.82 %\n",
      "Epoch:30/200 AVG Training Loss:0.644 AVG Validation Loss:0.648 AVG Training Acc 62.21 % AVG Validation Acc 61.73 %\n",
      "Epoch:40/200 AVG Training Loss:0.630 AVG Validation Loss:0.660 AVG Training Acc 63.18 % AVG Validation Acc 61.01 %\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.604 AVG Validation Loss:0.681 AVG Training Acc 65.37 % AVG Validation Acc 60.38 %\n",
      "Epoch:60/200 AVG Training Loss:0.588 AVG Validation Loss:0.702 AVG Training Acc 65.97 % AVG Validation Acc 58.84 %\n",
      "Epoch:70/200 AVG Training Loss:0.577 AVG Validation Loss:0.713 AVG Training Acc 66.76 % AVG Validation Acc 58.57 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.573 AVG Validation Loss:0.714 AVG Training Acc 67.29 % AVG Validation Acc 57.58 %\n",
      "Epoch:90/200 AVG Training Loss:0.566 AVG Validation Loss:0.716 AVG Training Acc 67.59 % AVG Validation Acc 58.75 %\n",
      "Epoch:100/200 AVG Training Loss:0.572 AVG Validation Loss:0.711 AVG Training Acc 67.09 % AVG Validation Acc 58.39 %\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.570 AVG Validation Loss:0.718 AVG Training Acc 67.65 % AVG Validation Acc 59.03 %\n",
      "Epoch:120/200 AVG Training Loss:0.568 AVG Validation Loss:0.714 AVG Training Acc 67.60 % AVG Validation Acc 58.94 %\n",
      "Epoch:130/200 AVG Training Loss:0.567 AVG Validation Loss:0.713 AVG Training Acc 67.46 % AVG Validation Acc 58.57 %\n",
      "Epoch   134: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.567 AVG Validation Loss:0.715 AVG Training Acc 67.06 % AVG Validation Acc 58.39 %\n",
      "Epoch:150/200 AVG Training Loss:0.568 AVG Validation Loss:0.718 AVG Training Acc 67.30 % AVG Validation Acc 57.40 %\n",
      "Epoch:160/200 AVG Training Loss:0.569 AVG Validation Loss:0.718 AVG Training Acc 67.74 % AVG Validation Acc 58.21 %\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.565 AVG Validation Loss:0.714 AVG Training Acc 67.80 % AVG Validation Acc 58.75 %\n",
      "Epoch:180/200 AVG Training Loss:0.568 AVG Validation Loss:0.717 AVG Training Acc 67.62 % AVG Validation Acc 58.30 %\n",
      "Epoch:190/200 AVG Training Loss:0.565 AVG Validation Loss:0.717 AVG Training Acc 67.71 % AVG Validation Acc 58.66 %\n",
      "Epoch   196: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.568 AVG Validation Loss:0.720 AVG Training Acc 67.33 % AVG Validation Acc 58.84 %\n",
      "Split 141\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c68cba8e582460aba7d19e1e95a1f87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.655 AVG Training Acc 61.77 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.657 AVG Training Acc 61.95 % AVG Validation Acc 62.49 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.634 AVG Validation Loss:0.663 AVG Training Acc 62.62 % AVG Validation Acc 59.51 %\n",
      "Epoch:40/200 AVG Training Loss:0.621 AVG Validation Loss:0.672 AVG Training Acc 63.54 % AVG Validation Acc 59.78 %\n",
      "Epoch:50/200 AVG Training Loss:0.611 AVG Validation Loss:0.681 AVG Training Acc 64.47 % AVG Validation Acc 60.32 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.601 AVG Validation Loss:0.688 AVG Training Acc 64.99 % AVG Validation Acc 60.50 %\n",
      "Epoch:70/200 AVG Training Loss:0.598 AVG Validation Loss:0.686 AVG Training Acc 65.35 % AVG Validation Acc 60.78 %\n",
      "Epoch:80/200 AVG Training Loss:0.597 AVG Validation Loss:0.688 AVG Training Acc 65.21 % AVG Validation Acc 60.69 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.596 AVG Validation Loss:0.692 AVG Training Acc 65.03 % AVG Validation Acc 60.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.596 AVG Validation Loss:0.687 AVG Training Acc 65.57 % AVG Validation Acc 60.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.595 AVG Validation Loss:0.686 AVG Training Acc 65.65 % AVG Validation Acc 60.78 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.593 AVG Validation Loss:0.690 AVG Training Acc 65.75 % AVG Validation Acc 60.96 %\n",
      "Epoch:130/200 AVG Training Loss:0.597 AVG Validation Loss:0.690 AVG Training Acc 65.30 % AVG Validation Acc 60.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.594 AVG Validation Loss:0.684 AVG Training Acc 65.74 % AVG Validation Acc 60.05 %\n",
      "Epoch:150/200 AVG Training Loss:0.595 AVG Validation Loss:0.691 AVG Training Acc 66.04 % AVG Validation Acc 60.41 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.594 AVG Validation Loss:0.689 AVG Training Acc 65.40 % AVG Validation Acc 60.50 %\n",
      "Epoch:170/200 AVG Training Loss:0.594 AVG Validation Loss:0.689 AVG Training Acc 65.87 % AVG Validation Acc 60.50 %\n",
      "Epoch:180/200 AVG Training Loss:0.595 AVG Validation Loss:0.692 AVG Training Acc 65.55 % AVG Validation Acc 60.14 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.594 AVG Validation Loss:0.688 AVG Training Acc 65.63 % AVG Validation Acc 60.60 %\n",
      "Epoch:200/200 AVG Training Loss:0.594 AVG Validation Loss:0.695 AVG Training Acc 65.83 % AVG Validation Acc 60.23 %\n",
      "Split 142\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae4f122d271c4fe8816362c39ef30a19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.654 AVG Training Acc 61.80 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.650 AVG Training Acc 61.88 % AVG Validation Acc 61.86 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.661 AVG Validation Loss:0.658 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.657 AVG Validation Loss:0.655 AVG Training Acc 61.87 % AVG Validation Acc 61.68 %\n",
      "Epoch:50/200 AVG Training Loss:0.654 AVG Validation Loss:0.653 AVG Training Acc 62.12 % AVG Validation Acc 61.68 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.648 AVG Validation Loss:0.652 AVG Training Acc 62.41 % AVG Validation Acc 61.86 %\n",
      "Epoch:70/200 AVG Training Loss:0.648 AVG Validation Loss:0.651 AVG Training Acc 62.25 % AVG Validation Acc 62.22 %\n",
      "Epoch:80/200 AVG Training Loss:0.648 AVG Validation Loss:0.652 AVG Training Acc 62.42 % AVG Validation Acc 62.22 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.646 AVG Validation Loss:0.652 AVG Training Acc 62.48 % AVG Validation Acc 62.13 %\n",
      "Epoch:100/200 AVG Training Loss:0.647 AVG Validation Loss:0.652 AVG Training Acc 62.30 % AVG Validation Acc 62.22 %\n",
      "Epoch:110/200 AVG Training Loss:0.648 AVG Validation Loss:0.652 AVG Training Acc 62.02 % AVG Validation Acc 62.40 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.647 AVG Validation Loss:0.651 AVG Training Acc 62.16 % AVG Validation Acc 62.04 %\n",
      "Epoch:130/200 AVG Training Loss:0.647 AVG Validation Loss:0.652 AVG Training Acc 62.28 % AVG Validation Acc 62.22 %\n",
      "Epoch:140/200 AVG Training Loss:0.647 AVG Validation Loss:0.652 AVG Training Acc 62.31 % AVG Validation Acc 62.13 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.646 AVG Validation Loss:0.652 AVG Training Acc 62.24 % AVG Validation Acc 62.31 %\n",
      "Epoch:160/200 AVG Training Loss:0.646 AVG Validation Loss:0.653 AVG Training Acc 62.31 % AVG Validation Acc 62.31 %\n",
      "Epoch:170/200 AVG Training Loss:0.648 AVG Validation Loss:0.652 AVG Training Acc 62.04 % AVG Validation Acc 62.13 %\n",
      "Epoch:180/200 AVG Training Loss:0.647 AVG Validation Loss:0.652 AVG Training Acc 62.07 % AVG Validation Acc 62.13 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.645 AVG Validation Loss:0.651 AVG Training Acc 62.32 % AVG Validation Acc 62.22 %\n",
      "Epoch:200/200 AVG Training Loss:0.647 AVG Validation Loss:0.652 AVG Training Acc 62.25 % AVG Validation Acc 62.22 %\n",
      "Split 143\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89b2c9111b4440688309e3b3825642b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.655 AVG Training Acc 62.00 % AVG Validation Acc 62.76 %\n",
      "Epoch:30/200 AVG Training Loss:0.647 AVG Validation Loss:0.662 AVG Training Acc 62.31 % AVG Validation Acc 61.95 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.622 AVG Validation Loss:0.674 AVG Training Acc 64.13 % AVG Validation Acc 60.96 %\n",
      "Epoch:50/200 AVG Training Loss:0.613 AVG Validation Loss:0.684 AVG Training Acc 64.42 % AVG Validation Acc 60.69 %\n",
      "Epoch:60/200 AVG Training Loss:0.602 AVG Validation Loss:0.694 AVG Training Acc 65.76 % AVG Validation Acc 59.24 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.598 AVG Validation Loss:0.698 AVG Training Acc 65.90 % AVG Validation Acc 59.51 %\n",
      "Epoch:80/200 AVG Training Loss:0.597 AVG Validation Loss:0.697 AVG Training Acc 65.74 % AVG Validation Acc 59.06 %\n",
      "Epoch:90/200 AVG Training Loss:0.595 AVG Validation Loss:0.697 AVG Training Acc 65.52 % AVG Validation Acc 58.70 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.594 AVG Validation Loss:0.704 AVG Training Acc 66.35 % AVG Validation Acc 58.61 %\n",
      "Epoch:110/200 AVG Training Loss:0.593 AVG Validation Loss:0.706 AVG Training Acc 66.08 % AVG Validation Acc 59.15 %\n",
      "Epoch:120/200 AVG Training Loss:0.597 AVG Validation Loss:0.703 AVG Training Acc 65.86 % AVG Validation Acc 59.51 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.593 AVG Validation Loss:0.709 AVG Training Acc 66.17 % AVG Validation Acc 60.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.594 AVG Validation Loss:0.704 AVG Training Acc 65.83 % AVG Validation Acc 59.33 %\n",
      "Epoch:150/200 AVG Training Loss:0.595 AVG Validation Loss:0.697 AVG Training Acc 65.41 % AVG Validation Acc 59.78 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.594 AVG Validation Loss:0.704 AVG Training Acc 65.99 % AVG Validation Acc 59.24 %\n",
      "Epoch:170/200 AVG Training Loss:0.592 AVG Validation Loss:0.701 AVG Training Acc 66.34 % AVG Validation Acc 59.33 %\n",
      "Epoch:180/200 AVG Training Loss:0.594 AVG Validation Loss:0.704 AVG Training Acc 65.93 % AVG Validation Acc 58.88 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.592 AVG Validation Loss:0.707 AVG Training Acc 66.41 % AVG Validation Acc 59.06 %\n",
      "Epoch:200/200 AVG Training Loss:0.594 AVG Validation Loss:0.701 AVG Training Acc 65.90 % AVG Validation Acc 59.51 %\n",
      "Split 144\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0a0dc1709204611b2517d60a623e1ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.659 AVG Training Acc 61.88 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.658 AVG Training Acc 62.10 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.647 AVG Validation Loss:0.657 AVG Training Acc 62.55 % AVG Validation Acc 61.86 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.625 AVG Validation Loss:0.672 AVG Training Acc 63.65 % AVG Validation Acc 60.23 %\n",
      "Epoch:50/200 AVG Training Loss:0.613 AVG Validation Loss:0.687 AVG Training Acc 64.73 % AVG Validation Acc 60.78 %\n",
      "Epoch:60/200 AVG Training Loss:0.606 AVG Validation Loss:0.703 AVG Training Acc 64.96 % AVG Validation Acc 60.96 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.598 AVG Validation Loss:0.702 AVG Training Acc 65.24 % AVG Validation Acc 61.32 %\n",
      "Epoch:80/200 AVG Training Loss:0.598 AVG Validation Loss:0.711 AVG Training Acc 65.45 % AVG Validation Acc 60.69 %\n",
      "Epoch:90/200 AVG Training Loss:0.595 AVG Validation Loss:0.717 AVG Training Acc 65.45 % AVG Validation Acc 61.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.593 AVG Validation Loss:0.716 AVG Training Acc 65.91 % AVG Validation Acc 61.23 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.593 AVG Validation Loss:0.713 AVG Training Acc 65.92 % AVG Validation Acc 61.41 %\n",
      "Epoch:120/200 AVG Training Loss:0.592 AVG Validation Loss:0.714 AVG Training Acc 65.99 % AVG Validation Acc 61.32 %\n",
      "Epoch:130/200 AVG Training Loss:0.592 AVG Validation Loss:0.707 AVG Training Acc 66.00 % AVG Validation Acc 61.05 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.595 AVG Validation Loss:0.716 AVG Training Acc 65.73 % AVG Validation Acc 60.41 %\n",
      "Epoch:150/200 AVG Training Loss:0.593 AVG Validation Loss:0.712 AVG Training Acc 66.27 % AVG Validation Acc 61.95 %\n",
      "Epoch:160/200 AVG Training Loss:0.593 AVG Validation Loss:0.713 AVG Training Acc 65.59 % AVG Validation Acc 60.96 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.593 AVG Validation Loss:0.718 AVG Training Acc 66.16 % AVG Validation Acc 61.59 %\n",
      "Epoch:180/200 AVG Training Loss:0.591 AVG Validation Loss:0.716 AVG Training Acc 65.97 % AVG Validation Acc 60.60 %\n",
      "Epoch:190/200 AVG Training Loss:0.592 AVG Validation Loss:0.713 AVG Training Acc 65.71 % AVG Validation Acc 61.05 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.594 AVG Validation Loss:0.713 AVG Training Acc 65.68 % AVG Validation Acc 60.78 %\n",
      "Split 145\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2feffbfbc494db785e16a555d112c01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.655 AVG Training Acc 61.90 % AVG Validation Acc 62.04 %\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.660 AVG Training Acc 61.77 % AVG Validation Acc 61.68 %\n",
      "Epoch:30/200 AVG Training Loss:0.647 AVG Validation Loss:0.657 AVG Training Acc 62.37 % AVG Validation Acc 62.31 %\n",
      "Epoch:40/200 AVG Training Loss:0.638 AVG Validation Loss:0.648 AVG Training Acc 62.53 % AVG Validation Acc 62.31 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.620 AVG Validation Loss:0.654 AVG Training Acc 63.96 % AVG Validation Acc 62.58 %\n",
      "Epoch:60/200 AVG Training Loss:0.603 AVG Validation Loss:0.671 AVG Training Acc 64.73 % AVG Validation Acc 62.22 %\n",
      "Epoch:70/200 AVG Training Loss:0.599 AVG Validation Loss:0.674 AVG Training Acc 65.21 % AVG Validation Acc 62.85 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.586 AVG Validation Loss:0.686 AVG Training Acc 66.01 % AVG Validation Acc 61.50 %\n",
      "Epoch:90/200 AVG Training Loss:0.585 AVG Validation Loss:0.682 AVG Training Acc 66.21 % AVG Validation Acc 61.23 %\n",
      "Epoch:100/200 AVG Training Loss:0.583 AVG Validation Loss:0.687 AVG Training Acc 66.12 % AVG Validation Acc 61.41 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.583 AVG Validation Loss:0.690 AVG Training Acc 66.47 % AVG Validation Acc 60.96 %\n",
      "Epoch:120/200 AVG Training Loss:0.583 AVG Validation Loss:0.692 AVG Training Acc 66.10 % AVG Validation Acc 61.59 %\n",
      "Epoch:130/200 AVG Training Loss:0.580 AVG Validation Loss:0.694 AVG Training Acc 66.50 % AVG Validation Acc 60.87 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.584 AVG Validation Loss:0.694 AVG Training Acc 65.41 % AVG Validation Acc 60.60 %\n",
      "Epoch:150/200 AVG Training Loss:0.583 AVG Validation Loss:0.689 AVG Training Acc 65.58 % AVG Validation Acc 61.77 %\n",
      "Epoch:160/200 AVG Training Loss:0.580 AVG Validation Loss:0.686 AVG Training Acc 66.06 % AVG Validation Acc 60.87 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.582 AVG Validation Loss:0.688 AVG Training Acc 66.36 % AVG Validation Acc 61.68 %\n",
      "Epoch:180/200 AVG Training Loss:0.584 AVG Validation Loss:0.694 AVG Training Acc 65.83 % AVG Validation Acc 61.32 %\n",
      "Epoch:190/200 AVG Training Loss:0.581 AVG Validation Loss:0.690 AVG Training Acc 66.04 % AVG Validation Acc 60.96 %\n",
      "Epoch:200/200 AVG Training Loss:0.578 AVG Validation Loss:0.696 AVG Training Acc 66.07 % AVG Validation Acc 60.50 %\n",
      "Epoch   200: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Split 146\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e53b7d08b4346a4a2cf5229720f59fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.661 AVG Training Acc 61.82 % AVG Validation Acc 62.00 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.661 AVG Training Acc 62.00 % AVG Validation Acc 61.91 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.642 AVG Validation Loss:0.663 AVG Training Acc 62.77 % AVG Validation Acc 61.37 %\n",
      "Epoch:40/200 AVG Training Loss:0.627 AVG Validation Loss:0.671 AVG Training Acc 63.82 % AVG Validation Acc 60.29 %\n",
      "Epoch:50/200 AVG Training Loss:0.616 AVG Validation Loss:0.678 AVG Training Acc 64.58 % AVG Validation Acc 59.93 %\n",
      "Epoch:60/200 AVG Training Loss:0.607 AVG Validation Loss:0.683 AVG Training Acc 64.78 % AVG Validation Acc 59.39 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.607 AVG Validation Loss:0.685 AVG Training Acc 64.64 % AVG Validation Acc 59.12 %\n",
      "Epoch:80/200 AVG Training Loss:0.602 AVG Validation Loss:0.689 AVG Training Acc 65.05 % AVG Validation Acc 59.39 %\n",
      "Epoch:90/200 AVG Training Loss:0.602 AVG Validation Loss:0.688 AVG Training Acc 65.46 % AVG Validation Acc 59.12 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.604 AVG Validation Loss:0.694 AVG Training Acc 64.57 % AVG Validation Acc 58.57 %\n",
      "Epoch:110/200 AVG Training Loss:0.602 AVG Validation Loss:0.691 AVG Training Acc 65.03 % AVG Validation Acc 59.03 %\n",
      "Epoch:120/200 AVG Training Loss:0.602 AVG Validation Loss:0.687 AVG Training Acc 64.97 % AVG Validation Acc 59.30 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.599 AVG Validation Loss:0.688 AVG Training Acc 65.41 % AVG Validation Acc 59.03 %\n",
      "Epoch:140/200 AVG Training Loss:0.601 AVG Validation Loss:0.690 AVG Training Acc 64.89 % AVG Validation Acc 59.03 %\n",
      "Epoch:150/200 AVG Training Loss:0.600 AVG Validation Loss:0.688 AVG Training Acc 65.68 % AVG Validation Acc 58.84 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.604 AVG Validation Loss:0.692 AVG Training Acc 64.99 % AVG Validation Acc 58.39 %\n",
      "Epoch:170/200 AVG Training Loss:0.601 AVG Validation Loss:0.692 AVG Training Acc 65.10 % AVG Validation Acc 58.84 %\n",
      "Epoch:180/200 AVG Training Loss:0.601 AVG Validation Loss:0.693 AVG Training Acc 65.01 % AVG Validation Acc 59.39 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.603 AVG Validation Loss:0.690 AVG Training Acc 64.70 % AVG Validation Acc 59.48 %\n",
      "Epoch:200/200 AVG Training Loss:0.602 AVG Validation Loss:0.694 AVG Training Acc 65.02 % AVG Validation Acc 58.75 %\n",
      "Split 147\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62e744bd47f4432ea5a1fb3dee8ef6a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.660 AVG Training Acc 61.86 % AVG Validation Acc 61.73 %\n",
      "Epoch:20/200 AVG Training Loss:0.650 AVG Validation Loss:0.661 AVG Training Acc 62.27 % AVG Validation Acc 61.55 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.640 AVG Validation Loss:0.666 AVG Training Acc 62.83 % AVG Validation Acc 60.47 %\n",
      "Epoch:40/200 AVG Training Loss:0.633 AVG Validation Loss:0.673 AVG Training Acc 63.37 % AVG Validation Acc 60.38 %\n",
      "Epoch:50/200 AVG Training Loss:0.629 AVG Validation Loss:0.677 AVG Training Acc 63.80 % AVG Validation Acc 60.56 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.625 AVG Validation Loss:0.678 AVG Training Acc 63.79 % AVG Validation Acc 59.57 %\n",
      "Epoch:70/200 AVG Training Loss:0.626 AVG Validation Loss:0.678 AVG Training Acc 63.91 % AVG Validation Acc 59.84 %\n",
      "Epoch:80/200 AVG Training Loss:0.624 AVG Validation Loss:0.682 AVG Training Acc 64.49 % AVG Validation Acc 59.48 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.623 AVG Validation Loss:0.681 AVG Training Acc 63.95 % AVG Validation Acc 59.84 %\n",
      "Epoch:100/200 AVG Training Loss:0.624 AVG Validation Loss:0.683 AVG Training Acc 64.23 % AVG Validation Acc 59.84 %\n",
      "Epoch:110/200 AVG Training Loss:0.622 AVG Validation Loss:0.682 AVG Training Acc 64.63 % AVG Validation Acc 60.02 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.621 AVG Validation Loss:0.685 AVG Training Acc 64.67 % AVG Validation Acc 59.30 %\n",
      "Epoch:130/200 AVG Training Loss:0.621 AVG Validation Loss:0.681 AVG Training Acc 64.64 % AVG Validation Acc 60.02 %\n",
      "Epoch:140/200 AVG Training Loss:0.621 AVG Validation Loss:0.681 AVG Training Acc 64.30 % AVG Validation Acc 59.93 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.623 AVG Validation Loss:0.680 AVG Training Acc 64.82 % AVG Validation Acc 60.74 %\n",
      "Epoch:160/200 AVG Training Loss:0.621 AVG Validation Loss:0.682 AVG Training Acc 64.67 % AVG Validation Acc 59.93 %\n",
      "Epoch:170/200 AVG Training Loss:0.622 AVG Validation Loss:0.685 AVG Training Acc 64.40 % AVG Validation Acc 59.66 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.622 AVG Validation Loss:0.681 AVG Training Acc 64.52 % AVG Validation Acc 60.02 %\n",
      "Epoch:190/200 AVG Training Loss:0.624 AVG Validation Loss:0.680 AVG Training Acc 64.31 % AVG Validation Acc 60.29 %\n",
      "Epoch:200/200 AVG Training Loss:0.622 AVG Validation Loss:0.681 AVG Training Acc 64.57 % AVG Validation Acc 59.57 %\n",
      "Split 148\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8aaba8abc394408bb5c34677d1242ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.663 AVG Training Acc 61.98 % AVG Validation Acc 62.00 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.646 AVG Validation Loss:0.665 AVG Training Acc 62.37 % AVG Validation Acc 61.01 %\n",
      "Epoch:30/200 AVG Training Loss:0.641 AVG Validation Loss:0.669 AVG Training Acc 63.03 % AVG Validation Acc 60.29 %\n",
      "Epoch:40/200 AVG Training Loss:0.634 AVG Validation Loss:0.676 AVG Training Acc 63.47 % AVG Validation Acc 60.47 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.623 AVG Validation Loss:0.693 AVG Training Acc 64.25 % AVG Validation Acc 60.38 %\n",
      "Epoch:60/200 AVG Training Loss:0.620 AVG Validation Loss:0.697 AVG Training Acc 64.32 % AVG Validation Acc 60.02 %\n",
      "Epoch:70/200 AVG Training Loss:0.616 AVG Validation Loss:0.699 AVG Training Acc 64.69 % AVG Validation Acc 59.84 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.616 AVG Validation Loss:0.701 AVG Training Acc 64.94 % AVG Validation Acc 59.75 %\n",
      "Epoch:90/200 AVG Training Loss:0.616 AVG Validation Loss:0.701 AVG Training Acc 64.66 % AVG Validation Acc 59.30 %\n",
      "Epoch:100/200 AVG Training Loss:0.616 AVG Validation Loss:0.701 AVG Training Acc 64.86 % AVG Validation Acc 59.12 %\n",
      "Epoch:110/200 AVG Training Loss:0.616 AVG Validation Loss:0.702 AVG Training Acc 65.15 % AVG Validation Acc 59.30 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.614 AVG Validation Loss:0.703 AVG Training Acc 64.91 % AVG Validation Acc 59.21 %\n",
      "Epoch:130/200 AVG Training Loss:0.615 AVG Validation Loss:0.702 AVG Training Acc 64.81 % AVG Validation Acc 59.39 %\n",
      "Epoch:140/200 AVG Training Loss:0.615 AVG Validation Loss:0.702 AVG Training Acc 65.12 % AVG Validation Acc 59.21 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.614 AVG Validation Loss:0.702 AVG Training Acc 65.03 % AVG Validation Acc 59.21 %\n",
      "Epoch:160/200 AVG Training Loss:0.616 AVG Validation Loss:0.703 AVG Training Acc 65.08 % AVG Validation Acc 59.21 %\n",
      "Epoch:170/200 AVG Training Loss:0.615 AVG Validation Loss:0.703 AVG Training Acc 64.97 % AVG Validation Acc 59.30 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.616 AVG Validation Loss:0.703 AVG Training Acc 64.70 % AVG Validation Acc 59.48 %\n",
      "Epoch:190/200 AVG Training Loss:0.615 AVG Validation Loss:0.702 AVG Training Acc 64.84 % AVG Validation Acc 59.57 %\n",
      "Epoch:200/200 AVG Training Loss:0.614 AVG Validation Loss:0.701 AVG Training Acc 64.99 % AVG Validation Acc 59.75 %\n",
      "Split 149\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4890420012774bbfb666fb081388f0b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.663 AVG Training Acc 61.77 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.658 AVG Training Acc 61.48 % AVG Validation Acc 61.37 %\n",
      "Epoch:30/200 AVG Training Loss:0.639 AVG Validation Loss:0.660 AVG Training Acc 62.60 % AVG Validation Acc 59.75 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.618 AVG Validation Loss:0.671 AVG Training Acc 63.71 % AVG Validation Acc 59.75 %\n",
      "Epoch:50/200 AVG Training Loss:0.606 AVG Validation Loss:0.686 AVG Training Acc 64.14 % AVG Validation Acc 59.03 %\n",
      "Epoch:60/200 AVG Training Loss:0.598 AVG Validation Loss:0.691 AVG Training Acc 65.03 % AVG Validation Acc 58.48 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.591 AVG Validation Loss:0.695 AVG Training Acc 65.61 % AVG Validation Acc 57.67 %\n",
      "Epoch:80/200 AVG Training Loss:0.591 AVG Validation Loss:0.702 AVG Training Acc 65.84 % AVG Validation Acc 58.39 %\n",
      "Epoch:90/200 AVG Training Loss:0.591 AVG Validation Loss:0.691 AVG Training Acc 65.50 % AVG Validation Acc 58.12 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.589 AVG Validation Loss:0.702 AVG Training Acc 65.61 % AVG Validation Acc 57.40 %\n",
      "Epoch:110/200 AVG Training Loss:0.591 AVG Validation Loss:0.697 AVG Training Acc 65.23 % AVG Validation Acc 58.12 %\n",
      "Epoch:120/200 AVG Training Loss:0.588 AVG Validation Loss:0.706 AVG Training Acc 65.63 % AVG Validation Acc 57.94 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.592 AVG Validation Loss:0.690 AVG Training Acc 65.10 % AVG Validation Acc 57.40 %\n",
      "Epoch:140/200 AVG Training Loss:0.590 AVG Validation Loss:0.695 AVG Training Acc 65.59 % AVG Validation Acc 58.12 %\n",
      "Epoch:150/200 AVG Training Loss:0.589 AVG Validation Loss:0.703 AVG Training Acc 65.63 % AVG Validation Acc 57.76 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.587 AVG Validation Loss:0.695 AVG Training Acc 65.56 % AVG Validation Acc 57.76 %\n",
      "Epoch:170/200 AVG Training Loss:0.589 AVG Validation Loss:0.703 AVG Training Acc 65.57 % AVG Validation Acc 57.85 %\n",
      "Epoch:180/200 AVG Training Loss:0.588 AVG Validation Loss:0.689 AVG Training Acc 65.46 % AVG Validation Acc 58.21 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.589 AVG Validation Loss:0.692 AVG Training Acc 65.75 % AVG Validation Acc 57.85 %\n",
      "Epoch:200/200 AVG Training Loss:0.592 AVG Validation Loss:0.699 AVG Training Acc 65.31 % AVG Validation Acc 57.94 %\n",
      "Split 150\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20eb8f8d6b2f470dbb838b1c2cbff081",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.664 AVG Training Acc 61.82 % AVG Validation Acc 62.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.657 AVG Training Acc 61.73 % AVG Validation Acc 62.45 %\n",
      "Epoch:30/200 AVG Training Loss:0.645 AVG Validation Loss:0.668 AVG Training Acc 62.02 % AVG Validation Acc 60.56 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.626 AVG Validation Loss:0.673 AVG Training Acc 63.06 % AVG Validation Acc 60.92 %\n",
      "Epoch:50/200 AVG Training Loss:0.613 AVG Validation Loss:0.676 AVG Training Acc 64.11 % AVG Validation Acc 60.02 %\n",
      "Epoch:60/200 AVG Training Loss:0.605 AVG Validation Loss:0.682 AVG Training Acc 63.91 % AVG Validation Acc 58.66 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.599 AVG Validation Loss:0.692 AVG Training Acc 64.65 % AVG Validation Acc 58.03 %\n",
      "Epoch:80/200 AVG Training Loss:0.598 AVG Validation Loss:0.696 AVG Training Acc 64.73 % AVG Validation Acc 58.12 %\n",
      "Epoch:90/200 AVG Training Loss:0.595 AVG Validation Loss:0.698 AVG Training Acc 65.15 % AVG Validation Acc 57.13 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.593 AVG Validation Loss:0.699 AVG Training Acc 65.33 % AVG Validation Acc 57.13 %\n",
      "Epoch:110/200 AVG Training Loss:0.593 AVG Validation Loss:0.700 AVG Training Acc 64.61 % AVG Validation Acc 57.49 %\n",
      "Epoch:120/200 AVG Training Loss:0.595 AVG Validation Loss:0.702 AVG Training Acc 64.80 % AVG Validation Acc 57.49 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.592 AVG Validation Loss:0.698 AVG Training Acc 65.37 % AVG Validation Acc 57.94 %\n",
      "Epoch:140/200 AVG Training Loss:0.592 AVG Validation Loss:0.699 AVG Training Acc 64.85 % AVG Validation Acc 57.49 %\n",
      "Epoch:150/200 AVG Training Loss:0.592 AVG Validation Loss:0.699 AVG Training Acc 64.94 % AVG Validation Acc 57.58 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.594 AVG Validation Loss:0.698 AVG Training Acc 65.00 % AVG Validation Acc 57.85 %\n",
      "Epoch:170/200 AVG Training Loss:0.593 AVG Validation Loss:0.705 AVG Training Acc 64.62 % AVG Validation Acc 57.31 %\n",
      "Epoch:180/200 AVG Training Loss:0.592 AVG Validation Loss:0.705 AVG Training Acc 65.02 % AVG Validation Acc 57.58 %\n",
      "Epoch:190/200 AVG Training Loss:0.595 AVG Validation Loss:0.707 AVG Training Acc 64.63 % AVG Validation Acc 58.03 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.592 AVG Validation Loss:0.698 AVG Training Acc 65.28 % AVG Validation Acc 57.49 %\n",
      "Split 151\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ff421987cd46d19908ddb1fa4a6c39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.657 AVG Training Acc 61.88 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.654 AVG Training Acc 61.95 % AVG Validation Acc 62.13 %\n",
      "Epoch:30/200 AVG Training Loss:0.649 AVG Validation Loss:0.652 AVG Training Acc 61.76 % AVG Validation Acc 62.13 %\n",
      "Epoch:40/200 AVG Training Loss:0.649 AVG Validation Loss:0.657 AVG Training Acc 61.74 % AVG Validation Acc 63.12 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.637 AVG Validation Loss:0.652 AVG Training Acc 62.39 % AVG Validation Acc 62.31 %\n",
      "Epoch:60/200 AVG Training Loss:0.622 AVG Validation Loss:0.660 AVG Training Acc 63.67 % AVG Validation Acc 62.76 %\n",
      "Epoch:70/200 AVG Training Loss:0.613 AVG Validation Loss:0.669 AVG Training Acc 63.54 % AVG Validation Acc 61.05 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.603 AVG Validation Loss:0.678 AVG Training Acc 65.08 % AVG Validation Acc 60.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.603 AVG Validation Loss:0.682 AVG Training Acc 65.13 % AVG Validation Acc 59.69 %\n",
      "Epoch:100/200 AVG Training Loss:0.600 AVG Validation Loss:0.682 AVG Training Acc 65.59 % AVG Validation Acc 60.78 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.600 AVG Validation Loss:0.683 AVG Training Acc 65.62 % AVG Validation Acc 60.41 %\n",
      "Epoch:120/200 AVG Training Loss:0.599 AVG Validation Loss:0.680 AVG Training Acc 65.31 % AVG Validation Acc 60.41 %\n",
      "Epoch:130/200 AVG Training Loss:0.598 AVG Validation Loss:0.681 AVG Training Acc 65.75 % AVG Validation Acc 60.05 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.599 AVG Validation Loss:0.685 AVG Training Acc 65.67 % AVG Validation Acc 60.23 %\n",
      "Epoch:150/200 AVG Training Loss:0.598 AVG Validation Loss:0.686 AVG Training Acc 65.72 % AVG Validation Acc 60.78 %\n",
      "Epoch:160/200 AVG Training Loss:0.600 AVG Validation Loss:0.685 AVG Training Acc 65.31 % AVG Validation Acc 59.96 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.598 AVG Validation Loss:0.683 AVG Training Acc 65.51 % AVG Validation Acc 60.32 %\n",
      "Epoch:180/200 AVG Training Loss:0.599 AVG Validation Loss:0.684 AVG Training Acc 66.00 % AVG Validation Acc 60.69 %\n",
      "Epoch:190/200 AVG Training Loss:0.601 AVG Validation Loss:0.681 AVG Training Acc 65.41 % AVG Validation Acc 60.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.600 AVG Validation Loss:0.683 AVG Training Acc 65.12 % AVG Validation Acc 60.96 %\n",
      "Epoch   200: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Split 152\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f978a3dd1714ea6b2c77b19eb8f7054",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.660 AVG Training Acc 61.97 % AVG Validation Acc 61.50 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.660 AVG Training Acc 62.01 % AVG Validation Acc 60.78 %\n",
      "Epoch:30/200 AVG Training Loss:0.639 AVG Validation Loss:0.671 AVG Training Acc 62.34 % AVG Validation Acc 60.05 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.648 AVG Validation Loss:0.662 AVG Training Acc 62.09 % AVG Validation Acc 60.78 %\n",
      "Epoch:50/200 AVG Training Loss:0.640 AVG Validation Loss:0.662 AVG Training Acc 62.56 % AVG Validation Acc 61.50 %\n",
      "Epoch:60/200 AVG Training Loss:0.634 AVG Validation Loss:0.659 AVG Training Acc 63.13 % AVG Validation Acc 61.14 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.629 AVG Validation Loss:0.661 AVG Training Acc 63.13 % AVG Validation Acc 60.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.626 AVG Validation Loss:0.663 AVG Training Acc 63.66 % AVG Validation Acc 60.41 %\n",
      "Epoch:90/200 AVG Training Loss:0.625 AVG Validation Loss:0.665 AVG Training Acc 63.79 % AVG Validation Acc 61.23 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.624 AVG Validation Loss:0.669 AVG Training Acc 64.52 % AVG Validation Acc 61.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.624 AVG Validation Loss:0.668 AVG Training Acc 63.88 % AVG Validation Acc 60.87 %\n",
      "Epoch:120/200 AVG Training Loss:0.624 AVG Validation Loss:0.667 AVG Training Acc 64.06 % AVG Validation Acc 61.14 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.625 AVG Validation Loss:0.663 AVG Training Acc 63.79 % AVG Validation Acc 61.50 %\n",
      "Epoch:140/200 AVG Training Loss:0.624 AVG Validation Loss:0.666 AVG Training Acc 63.85 % AVG Validation Acc 61.23 %\n",
      "Epoch:150/200 AVG Training Loss:0.626 AVG Validation Loss:0.664 AVG Training Acc 63.92 % AVG Validation Acc 61.14 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.623 AVG Validation Loss:0.666 AVG Training Acc 63.50 % AVG Validation Acc 60.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.626 AVG Validation Loss:0.667 AVG Training Acc 63.74 % AVG Validation Acc 61.05 %\n",
      "Epoch:180/200 AVG Training Loss:0.626 AVG Validation Loss:0.665 AVG Training Acc 63.58 % AVG Validation Acc 61.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.624 AVG Validation Loss:0.663 AVG Training Acc 64.15 % AVG Validation Acc 60.96 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.624 AVG Validation Loss:0.664 AVG Training Acc 64.03 % AVG Validation Acc 60.60 %\n",
      "Split 153\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b44ee0153dc748d4bb6201dc5913a52c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.664 AVG Training Acc 61.79 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.662 AVG Training Acc 62.09 % AVG Validation Acc 62.04 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.639 AVG Validation Loss:0.665 AVG Training Acc 62.87 % AVG Validation Acc 61.68 %\n",
      "Epoch:40/200 AVG Training Loss:0.632 AVG Validation Loss:0.669 AVG Training Acc 63.32 % AVG Validation Acc 62.04 %\n",
      "Epoch:50/200 AVG Training Loss:0.627 AVG Validation Loss:0.672 AVG Training Acc 63.65 % AVG Validation Acc 61.41 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.621 AVG Validation Loss:0.675 AVG Training Acc 64.32 % AVG Validation Acc 62.04 %\n",
      "Epoch:70/200 AVG Training Loss:0.619 AVG Validation Loss:0.678 AVG Training Acc 64.37 % AVG Validation Acc 61.59 %\n",
      "Epoch:80/200 AVG Training Loss:0.620 AVG Validation Loss:0.678 AVG Training Acc 64.41 % AVG Validation Acc 61.59 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.619 AVG Validation Loss:0.681 AVG Training Acc 64.43 % AVG Validation Acc 60.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.619 AVG Validation Loss:0.678 AVG Training Acc 64.44 % AVG Validation Acc 61.41 %\n",
      "Epoch:110/200 AVG Training Loss:0.618 AVG Validation Loss:0.682 AVG Training Acc 64.52 % AVG Validation Acc 61.23 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.619 AVG Validation Loss:0.682 AVG Training Acc 64.29 % AVG Validation Acc 61.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.618 AVG Validation Loss:0.682 AVG Training Acc 64.53 % AVG Validation Acc 60.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.617 AVG Validation Loss:0.681 AVG Training Acc 64.81 % AVG Validation Acc 61.14 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.617 AVG Validation Loss:0.680 AVG Training Acc 64.40 % AVG Validation Acc 61.41 %\n",
      "Epoch:160/200 AVG Training Loss:0.619 AVG Validation Loss:0.679 AVG Training Acc 64.74 % AVG Validation Acc 60.96 %\n",
      "Epoch:170/200 AVG Training Loss:0.618 AVG Validation Loss:0.678 AVG Training Acc 64.32 % AVG Validation Acc 61.05 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.618 AVG Validation Loss:0.679 AVG Training Acc 64.54 % AVG Validation Acc 61.05 %\n",
      "Epoch:190/200 AVG Training Loss:0.621 AVG Validation Loss:0.680 AVG Training Acc 64.33 % AVG Validation Acc 61.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.619 AVG Validation Loss:0.683 AVG Training Acc 64.36 % AVG Validation Acc 61.14 %\n",
      "Split 154\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e33acc0de2c488a9399745b4e5c6002",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.663 AVG Training Acc 61.96 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.650 AVG Validation Loss:0.657 AVG Training Acc 61.93 % AVG Validation Acc 61.86 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.638 AVG Validation Loss:0.664 AVG Training Acc 62.94 % AVG Validation Acc 61.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.619 AVG Validation Loss:0.683 AVG Training Acc 63.90 % AVG Validation Acc 60.41 %\n",
      "Epoch:50/200 AVG Training Loss:0.610 AVG Validation Loss:0.699 AVG Training Acc 64.05 % AVG Validation Acc 60.96 %\n",
      "Epoch:60/200 AVG Training Loss:0.599 AVG Validation Loss:0.703 AVG Training Acc 65.32 % AVG Validation Acc 61.23 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.595 AVG Validation Loss:0.698 AVG Training Acc 65.69 % AVG Validation Acc 59.87 %\n",
      "Epoch:80/200 AVG Training Loss:0.595 AVG Validation Loss:0.702 AVG Training Acc 65.46 % AVG Validation Acc 59.69 %\n",
      "Epoch:90/200 AVG Training Loss:0.594 AVG Validation Loss:0.704 AVG Training Acc 65.37 % AVG Validation Acc 60.14 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.593 AVG Validation Loss:0.702 AVG Training Acc 65.87 % AVG Validation Acc 60.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.594 AVG Validation Loss:0.711 AVG Training Acc 65.63 % AVG Validation Acc 59.60 %\n",
      "Epoch:120/200 AVG Training Loss:0.593 AVG Validation Loss:0.710 AVG Training Acc 65.43 % AVG Validation Acc 59.60 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.592 AVG Validation Loss:0.710 AVG Training Acc 65.75 % AVG Validation Acc 58.70 %\n",
      "Epoch:140/200 AVG Training Loss:0.593 AVG Validation Loss:0.706 AVG Training Acc 65.35 % AVG Validation Acc 59.24 %\n",
      "Epoch:150/200 AVG Training Loss:0.592 AVG Validation Loss:0.705 AVG Training Acc 65.52 % AVG Validation Acc 59.60 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.591 AVG Validation Loss:0.708 AVG Training Acc 65.38 % AVG Validation Acc 59.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.592 AVG Validation Loss:0.705 AVG Training Acc 65.49 % AVG Validation Acc 59.42 %\n",
      "Epoch:180/200 AVG Training Loss:0.594 AVG Validation Loss:0.713 AVG Training Acc 64.85 % AVG Validation Acc 59.87 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.593 AVG Validation Loss:0.712 AVG Training Acc 65.38 % AVG Validation Acc 59.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.591 AVG Validation Loss:0.706 AVG Training Acc 65.63 % AVG Validation Acc 59.78 %\n",
      "Split 155\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4c666734e1644c3aa73d5daca8302a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.659 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:0.659 AVG Training Acc 61.87 % AVG Validation Acc 62.13 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.638 AVG Validation Loss:0.663 AVG Training Acc 62.64 % AVG Validation Acc 61.32 %\n",
      "Epoch:40/200 AVG Training Loss:0.630 AVG Validation Loss:0.667 AVG Training Acc 62.90 % AVG Validation Acc 60.23 %\n",
      "Epoch:50/200 AVG Training Loss:0.619 AVG Validation Loss:0.677 AVG Training Acc 64.04 % AVG Validation Acc 59.15 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.609 AVG Validation Loss:0.680 AVG Training Acc 64.53 % AVG Validation Acc 58.70 %\n",
      "Epoch:70/200 AVG Training Loss:0.613 AVG Validation Loss:0.681 AVG Training Acc 64.28 % AVG Validation Acc 59.60 %\n",
      "Epoch:80/200 AVG Training Loss:0.609 AVG Validation Loss:0.683 AVG Training Acc 65.15 % AVG Validation Acc 58.97 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.610 AVG Validation Loss:0.685 AVG Training Acc 64.59 % AVG Validation Acc 58.61 %\n",
      "Epoch:100/200 AVG Training Loss:0.607 AVG Validation Loss:0.684 AVG Training Acc 64.84 % AVG Validation Acc 58.88 %\n",
      "Epoch:110/200 AVG Training Loss:0.607 AVG Validation Loss:0.686 AVG Training Acc 64.50 % AVG Validation Acc 58.61 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.605 AVG Validation Loss:0.683 AVG Training Acc 64.99 % AVG Validation Acc 58.43 %\n",
      "Epoch:130/200 AVG Training Loss:0.609 AVG Validation Loss:0.685 AVG Training Acc 64.75 % AVG Validation Acc 58.88 %\n",
      "Epoch:140/200 AVG Training Loss:0.606 AVG Validation Loss:0.685 AVG Training Acc 64.77 % AVG Validation Acc 59.24 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.605 AVG Validation Loss:0.684 AVG Training Acc 64.71 % AVG Validation Acc 59.15 %\n",
      "Epoch:160/200 AVG Training Loss:0.606 AVG Validation Loss:0.683 AVG Training Acc 64.90 % AVG Validation Acc 58.52 %\n",
      "Epoch:170/200 AVG Training Loss:0.607 AVG Validation Loss:0.687 AVG Training Acc 65.09 % AVG Validation Acc 58.97 %\n",
      "Epoch:180/200 AVG Training Loss:0.606 AVG Validation Loss:0.683 AVG Training Acc 65.08 % AVG Validation Acc 58.52 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.609 AVG Validation Loss:0.686 AVG Training Acc 65.07 % AVG Validation Acc 58.52 %\n",
      "Epoch:200/200 AVG Training Loss:0.607 AVG Validation Loss:0.685 AVG Training Acc 64.65 % AVG Validation Acc 58.88 %\n",
      "Split 156\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd93e631c48e4ad0961445800559a4e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.660 AVG Training Acc 61.82 % AVG Validation Acc 62.00 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.661 AVG Training Acc 61.96 % AVG Validation Acc 62.18 %\n",
      "Epoch:30/200 AVG Training Loss:0.640 AVG Validation Loss:0.661 AVG Training Acc 62.62 % AVG Validation Acc 61.37 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.618 AVG Validation Loss:0.674 AVG Training Acc 64.31 % AVG Validation Acc 60.74 %\n",
      "Epoch:50/200 AVG Training Loss:0.603 AVG Validation Loss:0.687 AVG Training Acc 65.32 % AVG Validation Acc 60.92 %\n",
      "Epoch:60/200 AVG Training Loss:0.592 AVG Validation Loss:0.690 AVG Training Acc 66.62 % AVG Validation Acc 60.74 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.584 AVG Validation Loss:0.699 AVG Training Acc 67.27 % AVG Validation Acc 60.56 %\n",
      "Epoch:80/200 AVG Training Loss:0.579 AVG Validation Loss:0.702 AVG Training Acc 67.36 % AVG Validation Acc 59.93 %\n",
      "Epoch:90/200 AVG Training Loss:0.579 AVG Validation Loss:0.700 AVG Training Acc 67.26 % AVG Validation Acc 61.01 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.577 AVG Validation Loss:0.699 AVG Training Acc 68.03 % AVG Validation Acc 60.65 %\n",
      "Epoch:110/200 AVG Training Loss:0.578 AVG Validation Loss:0.702 AVG Training Acc 67.72 % AVG Validation Acc 60.38 %\n",
      "Epoch:120/200 AVG Training Loss:0.580 AVG Validation Loss:0.694 AVG Training Acc 67.54 % AVG Validation Acc 60.65 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.577 AVG Validation Loss:0.705 AVG Training Acc 67.77 % AVG Validation Acc 59.57 %\n",
      "Epoch:140/200 AVG Training Loss:0.579 AVG Validation Loss:0.700 AVG Training Acc 67.81 % AVG Validation Acc 60.38 %\n",
      "Epoch:150/200 AVG Training Loss:0.576 AVG Validation Loss:0.697 AVG Training Acc 67.42 % AVG Validation Acc 60.65 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.577 AVG Validation Loss:0.697 AVG Training Acc 67.77 % AVG Validation Acc 60.56 %\n",
      "Epoch:170/200 AVG Training Loss:0.581 AVG Validation Loss:0.701 AVG Training Acc 67.12 % AVG Validation Acc 60.20 %\n",
      "Epoch:180/200 AVG Training Loss:0.577 AVG Validation Loss:0.702 AVG Training Acc 67.90 % AVG Validation Acc 60.47 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.578 AVG Validation Loss:0.697 AVG Training Acc 67.52 % AVG Validation Acc 61.01 %\n",
      "Epoch:200/200 AVG Training Loss:0.578 AVG Validation Loss:0.698 AVG Training Acc 67.70 % AVG Validation Acc 60.92 %\n",
      "Split 157\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "710398a24a69486ea03151ecd37082d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.660 AVG Training Acc 61.99 % AVG Validation Acc 61.82 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.658 AVG Training Acc 62.07 % AVG Validation Acc 62.00 %\n",
      "Epoch:30/200 AVG Training Loss:0.639 AVG Validation Loss:0.658 AVG Training Acc 62.93 % AVG Validation Acc 62.91 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.615 AVG Validation Loss:0.671 AVG Training Acc 64.13 % AVG Validation Acc 61.73 %\n",
      "Epoch:50/200 AVG Training Loss:0.603 AVG Validation Loss:0.679 AVG Training Acc 64.82 % AVG Validation Acc 61.82 %\n",
      "Epoch:60/200 AVG Training Loss:0.596 AVG Validation Loss:0.689 AVG Training Acc 65.65 % AVG Validation Acc 60.92 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.589 AVG Validation Loss:0.701 AVG Training Acc 66.22 % AVG Validation Acc 61.19 %\n",
      "Epoch:80/200 AVG Training Loss:0.586 AVG Validation Loss:0.708 AVG Training Acc 66.14 % AVG Validation Acc 61.28 %\n",
      "Epoch:90/200 AVG Training Loss:0.585 AVG Validation Loss:0.711 AVG Training Acc 66.10 % AVG Validation Acc 61.10 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.582 AVG Validation Loss:0.714 AVG Training Acc 66.17 % AVG Validation Acc 61.19 %\n",
      "Epoch:110/200 AVG Training Loss:0.583 AVG Validation Loss:0.711 AVG Training Acc 66.58 % AVG Validation Acc 60.92 %\n",
      "Epoch:120/200 AVG Training Loss:0.581 AVG Validation Loss:0.709 AVG Training Acc 66.70 % AVG Validation Acc 61.37 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.581 AVG Validation Loss:0.713 AVG Training Acc 66.67 % AVG Validation Acc 61.19 %\n",
      "Epoch:140/200 AVG Training Loss:0.581 AVG Validation Loss:0.711 AVG Training Acc 66.62 % AVG Validation Acc 61.01 %\n",
      "Epoch:150/200 AVG Training Loss:0.586 AVG Validation Loss:0.711 AVG Training Acc 66.29 % AVG Validation Acc 61.64 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.584 AVG Validation Loss:0.711 AVG Training Acc 66.06 % AVG Validation Acc 60.92 %\n",
      "Epoch:170/200 AVG Training Loss:0.586 AVG Validation Loss:0.717 AVG Training Acc 66.38 % AVG Validation Acc 61.37 %\n",
      "Epoch:180/200 AVG Training Loss:0.583 AVG Validation Loss:0.707 AVG Training Acc 66.49 % AVG Validation Acc 61.55 %\n",
      "Epoch:190/200 AVG Training Loss:0.585 AVG Validation Loss:0.710 AVG Training Acc 66.05 % AVG Validation Acc 60.47 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.585 AVG Validation Loss:0.718 AVG Training Acc 65.73 % AVG Validation Acc 60.65 %\n",
      "Split 158\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db62738658f4ec594fcc6113fbbbf19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.648 AVG Training Acc 61.68 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.648 AVG Validation Loss:0.642 AVG Training Acc 62.05 % AVG Validation Acc 63.27 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.628 AVG Validation Loss:0.661 AVG Training Acc 63.26 % AVG Validation Acc 60.38 %\n",
      "Epoch:40/200 AVG Training Loss:0.612 AVG Validation Loss:0.672 AVG Training Acc 64.66 % AVG Validation Acc 60.92 %\n",
      "Epoch:50/200 AVG Training Loss:0.601 AVG Validation Loss:0.681 AVG Training Acc 65.19 % AVG Validation Acc 60.65 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.593 AVG Validation Loss:0.683 AVG Training Acc 65.20 % AVG Validation Acc 59.48 %\n",
      "Epoch:70/200 AVG Training Loss:0.590 AVG Validation Loss:0.682 AVG Training Acc 65.40 % AVG Validation Acc 60.29 %\n",
      "Epoch:80/200 AVG Training Loss:0.588 AVG Validation Loss:0.687 AVG Training Acc 65.65 % AVG Validation Acc 60.02 %\n",
      "Epoch:90/200 AVG Training Loss:0.587 AVG Validation Loss:0.685 AVG Training Acc 65.79 % AVG Validation Acc 59.48 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.585 AVG Validation Loss:0.682 AVG Training Acc 65.94 % AVG Validation Acc 60.02 %\n",
      "Epoch:110/200 AVG Training Loss:0.584 AVG Validation Loss:0.688 AVG Training Acc 65.74 % AVG Validation Acc 59.21 %\n",
      "Epoch:120/200 AVG Training Loss:0.585 AVG Validation Loss:0.689 AVG Training Acc 65.82 % AVG Validation Acc 59.84 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.587 AVG Validation Loss:0.682 AVG Training Acc 65.50 % AVG Validation Acc 59.48 %\n",
      "Epoch:140/200 AVG Training Loss:0.588 AVG Validation Loss:0.686 AVG Training Acc 65.53 % AVG Validation Acc 59.03 %\n",
      "Epoch:150/200 AVG Training Loss:0.585 AVG Validation Loss:0.687 AVG Training Acc 66.13 % AVG Validation Acc 59.66 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.587 AVG Validation Loss:0.687 AVG Training Acc 65.76 % AVG Validation Acc 59.75 %\n",
      "Epoch:170/200 AVG Training Loss:0.586 AVG Validation Loss:0.686 AVG Training Acc 65.87 % AVG Validation Acc 59.66 %\n",
      "Epoch:180/200 AVG Training Loss:0.586 AVG Validation Loss:0.689 AVG Training Acc 65.69 % AVG Validation Acc 59.30 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.585 AVG Validation Loss:0.688 AVG Training Acc 66.32 % AVG Validation Acc 59.84 %\n",
      "Epoch:200/200 AVG Training Loss:0.586 AVG Validation Loss:0.687 AVG Training Acc 66.02 % AVG Validation Acc 60.11 %\n",
      "Split 159\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee59db35ada745b78c5ebaf292340c6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.660 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.656 AVG Validation Loss:0.659 AVG Training Acc 61.86 % AVG Validation Acc 62.09 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.649 AVG Validation Loss:0.661 AVG Training Acc 62.15 % AVG Validation Acc 61.82 %\n",
      "Epoch:40/200 AVG Training Loss:0.636 AVG Validation Loss:0.670 AVG Training Acc 62.87 % AVG Validation Acc 61.64 %\n",
      "Epoch:50/200 AVG Training Loss:0.628 AVG Validation Loss:0.683 AVG Training Acc 62.85 % AVG Validation Acc 61.82 %\n",
      "Epoch:60/200 AVG Training Loss:0.621 AVG Validation Loss:0.686 AVG Training Acc 63.59 % AVG Validation Acc 61.19 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.617 AVG Validation Loss:0.686 AVG Training Acc 63.71 % AVG Validation Acc 61.46 %\n",
      "Epoch:80/200 AVG Training Loss:0.617 AVG Validation Loss:0.690 AVG Training Acc 63.97 % AVG Validation Acc 61.28 %\n",
      "Epoch:90/200 AVG Training Loss:0.615 AVG Validation Loss:0.691 AVG Training Acc 64.31 % AVG Validation Acc 61.10 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.615 AVG Validation Loss:0.688 AVG Training Acc 63.61 % AVG Validation Acc 60.92 %\n",
      "Epoch:110/200 AVG Training Loss:0.614 AVG Validation Loss:0.692 AVG Training Acc 64.28 % AVG Validation Acc 60.83 %\n",
      "Epoch:120/200 AVG Training Loss:0.615 AVG Validation Loss:0.688 AVG Training Acc 64.19 % AVG Validation Acc 61.19 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.613 AVG Validation Loss:0.689 AVG Training Acc 63.81 % AVG Validation Acc 60.83 %\n",
      "Epoch:140/200 AVG Training Loss:0.614 AVG Validation Loss:0.689 AVG Training Acc 64.17 % AVG Validation Acc 60.74 %\n",
      "Epoch:150/200 AVG Training Loss:0.612 AVG Validation Loss:0.689 AVG Training Acc 64.35 % AVG Validation Acc 61.10 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.613 AVG Validation Loss:0.691 AVG Training Acc 64.37 % AVG Validation Acc 60.38 %\n",
      "Epoch:170/200 AVG Training Loss:0.616 AVG Validation Loss:0.689 AVG Training Acc 64.33 % AVG Validation Acc 60.74 %\n",
      "Epoch:180/200 AVG Training Loss:0.613 AVG Validation Loss:0.692 AVG Training Acc 64.42 % AVG Validation Acc 60.29 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.614 AVG Validation Loss:0.691 AVG Training Acc 64.31 % AVG Validation Acc 60.92 %\n",
      "Epoch:200/200 AVG Training Loss:0.615 AVG Validation Loss:0.690 AVG Training Acc 64.38 % AVG Validation Acc 61.01 %\n",
      "Split 160\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ddfc35f2c364406bf171475b73c35a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.654 AVG Training Acc 61.77 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.655 AVG Training Acc 62.20 % AVG Validation Acc 61.55 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.640 AVG Validation Loss:0.663 AVG Training Acc 62.57 % AVG Validation Acc 59.30 %\n",
      "Epoch:40/200 AVG Training Loss:0.627 AVG Validation Loss:0.677 AVG Training Acc 63.77 % AVG Validation Acc 58.75 %\n",
      "Epoch:50/200 AVG Training Loss:0.618 AVG Validation Loss:0.691 AVG Training Acc 64.30 % AVG Validation Acc 57.67 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.613 AVG Validation Loss:0.694 AVG Training Acc 64.24 % AVG Validation Acc 58.39 %\n",
      "Epoch:70/200 AVG Training Loss:0.613 AVG Validation Loss:0.694 AVG Training Acc 64.90 % AVG Validation Acc 58.57 %\n",
      "Epoch:80/200 AVG Training Loss:0.610 AVG Validation Loss:0.694 AVG Training Acc 65.32 % AVG Validation Acc 58.21 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.608 AVG Validation Loss:0.693 AVG Training Acc 65.45 % AVG Validation Acc 58.21 %\n",
      "Epoch:100/200 AVG Training Loss:0.607 AVG Validation Loss:0.695 AVG Training Acc 65.92 % AVG Validation Acc 58.21 %\n",
      "Epoch:110/200 AVG Training Loss:0.608 AVG Validation Loss:0.696 AVG Training Acc 65.41 % AVG Validation Acc 58.03 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.607 AVG Validation Loss:0.696 AVG Training Acc 65.17 % AVG Validation Acc 58.21 %\n",
      "Epoch:130/200 AVG Training Loss:0.608 AVG Validation Loss:0.697 AVG Training Acc 65.61 % AVG Validation Acc 58.03 %\n",
      "Epoch:140/200 AVG Training Loss:0.609 AVG Validation Loss:0.697 AVG Training Acc 65.47 % AVG Validation Acc 57.94 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.609 AVG Validation Loss:0.699 AVG Training Acc 65.14 % AVG Validation Acc 58.12 %\n",
      "Epoch:160/200 AVG Training Loss:0.610 AVG Validation Loss:0.695 AVG Training Acc 64.96 % AVG Validation Acc 57.85 %\n",
      "Epoch:170/200 AVG Training Loss:0.609 AVG Validation Loss:0.697 AVG Training Acc 65.69 % AVG Validation Acc 58.12 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.607 AVG Validation Loss:0.696 AVG Training Acc 65.24 % AVG Validation Acc 58.12 %\n",
      "Epoch:190/200 AVG Training Loss:0.610 AVG Validation Loss:0.695 AVG Training Acc 65.07 % AVG Validation Acc 58.48 %\n",
      "Epoch:200/200 AVG Training Loss:0.608 AVG Validation Loss:0.698 AVG Training Acc 65.36 % AVG Validation Acc 57.94 %\n",
      "Split 161\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73be8ec9a2524ff29f27162b3f852778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.657 AVG Validation Loss:0.661 AVG Training Acc 62.03 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.663 AVG Training Acc 62.06 % AVG Validation Acc 61.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.649 AVG Validation Loss:0.655 AVG Training Acc 62.23 % AVG Validation Acc 61.59 %\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.662 AVG Validation Loss:0.660 AVG Training Acc 61.96 % AVG Validation Acc 61.77 %\n",
      "Epoch:50/200 AVG Training Loss:0.659 AVG Validation Loss:0.659 AVG Training Acc 62.02 % AVG Validation Acc 61.59 %\n",
      "Epoch:60/200 AVG Training Loss:0.656 AVG Validation Loss:0.657 AVG Training Acc 61.96 % AVG Validation Acc 61.50 %\n",
      "Epoch:70/200 AVG Training Loss:0.649 AVG Validation Loss:0.655 AVG Training Acc 62.63 % AVG Validation Acc 61.32 %\n",
      "Epoch    70: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.649 AVG Validation Loss:0.653 AVG Training Acc 62.64 % AVG Validation Acc 61.32 %\n",
      "Epoch:90/200 AVG Training Loss:0.646 AVG Validation Loss:0.654 AVG Training Acc 62.43 % AVG Validation Acc 61.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.646 AVG Validation Loss:0.654 AVG Training Acc 63.04 % AVG Validation Acc 61.50 %\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.648 AVG Validation Loss:0.655 AVG Training Acc 62.42 % AVG Validation Acc 61.32 %\n",
      "Epoch:120/200 AVG Training Loss:0.647 AVG Validation Loss:0.656 AVG Training Acc 62.43 % AVG Validation Acc 61.05 %\n",
      "Epoch:130/200 AVG Training Loss:0.645 AVG Validation Loss:0.655 AVG Training Acc 63.00 % AVG Validation Acc 61.32 %\n",
      "Epoch   132: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.646 AVG Validation Loss:0.655 AVG Training Acc 62.61 % AVG Validation Acc 61.32 %\n",
      "Epoch:150/200 AVG Training Loss:0.647 AVG Validation Loss:0.655 AVG Training Acc 62.44 % AVG Validation Acc 60.87 %\n",
      "Epoch:160/200 AVG Training Loss:0.647 AVG Validation Loss:0.655 AVG Training Acc 62.45 % AVG Validation Acc 60.69 %\n",
      "Epoch   163: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.645 AVG Validation Loss:0.656 AVG Training Acc 62.51 % AVG Validation Acc 60.69 %\n",
      "Epoch:180/200 AVG Training Loss:0.645 AVG Validation Loss:0.654 AVG Training Acc 62.84 % AVG Validation Acc 61.50 %\n",
      "Epoch:190/200 AVG Training Loss:0.644 AVG Validation Loss:0.655 AVG Training Acc 62.47 % AVG Validation Acc 61.41 %\n",
      "Epoch   194: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.645 AVG Validation Loss:0.655 AVG Training Acc 62.70 % AVG Validation Acc 61.05 %\n",
      "Split 162\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61886702107347a78ee5a743c99be411",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.659 AVG Training Acc 61.99 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.661 AVG Training Acc 62.15 % AVG Validation Acc 61.50 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.644 AVG Validation Loss:0.664 AVG Training Acc 62.34 % AVG Validation Acc 62.22 %\n",
      "Epoch:40/200 AVG Training Loss:0.639 AVG Validation Loss:0.666 AVG Training Acc 62.87 % AVG Validation Acc 62.13 %\n",
      "Epoch:50/200 AVG Training Loss:0.632 AVG Validation Loss:0.672 AVG Training Acc 63.23 % AVG Validation Acc 62.31 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.627 AVG Validation Loss:0.671 AVG Training Acc 63.51 % AVG Validation Acc 61.41 %\n",
      "Epoch:70/200 AVG Training Loss:0.627 AVG Validation Loss:0.671 AVG Training Acc 63.69 % AVG Validation Acc 61.86 %\n",
      "Epoch:80/200 AVG Training Loss:0.625 AVG Validation Loss:0.671 AVG Training Acc 63.76 % AVG Validation Acc 62.04 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.625 AVG Validation Loss:0.671 AVG Training Acc 63.83 % AVG Validation Acc 61.41 %\n",
      "Epoch:100/200 AVG Training Loss:0.624 AVG Validation Loss:0.672 AVG Training Acc 63.94 % AVG Validation Acc 62.22 %\n",
      "Epoch:110/200 AVG Training Loss:0.625 AVG Validation Loss:0.673 AVG Training Acc 64.17 % AVG Validation Acc 61.95 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.624 AVG Validation Loss:0.672 AVG Training Acc 64.17 % AVG Validation Acc 61.86 %\n",
      "Epoch:130/200 AVG Training Loss:0.625 AVG Validation Loss:0.673 AVG Training Acc 64.11 % AVG Validation Acc 61.59 %\n",
      "Epoch:140/200 AVG Training Loss:0.625 AVG Validation Loss:0.672 AVG Training Acc 64.00 % AVG Validation Acc 61.86 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.624 AVG Validation Loss:0.673 AVG Training Acc 63.95 % AVG Validation Acc 61.68 %\n",
      "Epoch:160/200 AVG Training Loss:0.625 AVG Validation Loss:0.672 AVG Training Acc 63.58 % AVG Validation Acc 61.59 %\n",
      "Epoch:170/200 AVG Training Loss:0.625 AVG Validation Loss:0.672 AVG Training Acc 63.77 % AVG Validation Acc 61.77 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.626 AVG Validation Loss:0.673 AVG Training Acc 63.55 % AVG Validation Acc 61.77 %\n",
      "Epoch:190/200 AVG Training Loss:0.625 AVG Validation Loss:0.672 AVG Training Acc 63.80 % AVG Validation Acc 61.77 %\n",
      "Epoch:200/200 AVG Training Loss:0.626 AVG Validation Loss:0.672 AVG Training Acc 63.67 % AVG Validation Acc 61.95 %\n",
      "Split 163\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945aeaf5d81243ccb2b490ef9ec5d44b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.662 AVG Training Acc 61.86 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.663 AVG Training Acc 61.91 % AVG Validation Acc 62.67 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.638 AVG Validation Loss:0.667 AVG Training Acc 63.05 % AVG Validation Acc 61.68 %\n",
      "Epoch:40/200 AVG Training Loss:0.629 AVG Validation Loss:0.677 AVG Training Acc 63.80 % AVG Validation Acc 61.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.617 AVG Validation Loss:0.692 AVG Training Acc 64.66 % AVG Validation Acc 60.50 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.606 AVG Validation Loss:0.701 AVG Training Acc 65.95 % AVG Validation Acc 58.07 %\n",
      "Epoch:70/200 AVG Training Loss:0.606 AVG Validation Loss:0.702 AVG Training Acc 66.08 % AVG Validation Acc 58.79 %\n",
      "Epoch:80/200 AVG Training Loss:0.604 AVG Validation Loss:0.706 AVG Training Acc 66.14 % AVG Validation Acc 58.70 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.603 AVG Validation Loss:0.710 AVG Training Acc 66.25 % AVG Validation Acc 57.80 %\n",
      "Epoch:100/200 AVG Training Loss:0.602 AVG Validation Loss:0.708 AVG Training Acc 66.39 % AVG Validation Acc 58.34 %\n",
      "Epoch:110/200 AVG Training Loss:0.601 AVG Validation Loss:0.706 AVG Training Acc 66.47 % AVG Validation Acc 58.34 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.601 AVG Validation Loss:0.706 AVG Training Acc 66.23 % AVG Validation Acc 58.79 %\n",
      "Epoch:130/200 AVG Training Loss:0.602 AVG Validation Loss:0.707 AVG Training Acc 66.37 % AVG Validation Acc 58.52 %\n",
      "Epoch:140/200 AVG Training Loss:0.602 AVG Validation Loss:0.707 AVG Training Acc 66.28 % AVG Validation Acc 58.52 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.603 AVG Validation Loss:0.711 AVG Training Acc 65.96 % AVG Validation Acc 57.89 %\n",
      "Epoch:160/200 AVG Training Loss:0.601 AVG Validation Loss:0.709 AVG Training Acc 66.51 % AVG Validation Acc 58.43 %\n",
      "Epoch:170/200 AVG Training Loss:0.601 AVG Validation Loss:0.709 AVG Training Acc 65.91 % AVG Validation Acc 58.52 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.602 AVG Validation Loss:0.709 AVG Training Acc 66.24 % AVG Validation Acc 58.70 %\n",
      "Epoch:190/200 AVG Training Loss:0.603 AVG Validation Loss:0.709 AVG Training Acc 66.17 % AVG Validation Acc 58.70 %\n",
      "Epoch:200/200 AVG Training Loss:0.606 AVG Validation Loss:0.704 AVG Training Acc 66.20 % AVG Validation Acc 58.88 %\n",
      "Split 164\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa28667ca6bf46f0b1200877c7bb8238",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.659 AVG Training Acc 62.01 % AVG Validation Acc 61.59 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.656 AVG Training Acc 62.00 % AVG Validation Acc 62.22 %\n",
      "Epoch:30/200 AVG Training Loss:0.644 AVG Validation Loss:0.658 AVG Training Acc 62.19 % AVG Validation Acc 61.05 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.616 AVG Validation Loss:0.681 AVG Training Acc 64.04 % AVG Validation Acc 60.60 %\n",
      "Epoch:50/200 AVG Training Loss:0.602 AVG Validation Loss:0.697 AVG Training Acc 65.47 % AVG Validation Acc 60.23 %\n",
      "Epoch:60/200 AVG Training Loss:0.595 AVG Validation Loss:0.701 AVG Training Acc 65.89 % AVG Validation Acc 60.14 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.586 AVG Validation Loss:0.708 AVG Training Acc 66.74 % AVG Validation Acc 60.60 %\n",
      "Epoch:80/200 AVG Training Loss:0.584 AVG Validation Loss:0.711 AVG Training Acc 67.08 % AVG Validation Acc 60.87 %\n",
      "Epoch:90/200 AVG Training Loss:0.585 AVG Validation Loss:0.716 AVG Training Acc 66.85 % AVG Validation Acc 60.69 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.581 AVG Validation Loss:0.716 AVG Training Acc 67.32 % AVG Validation Acc 60.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.578 AVG Validation Loss:0.716 AVG Training Acc 66.99 % AVG Validation Acc 60.69 %\n",
      "Epoch:120/200 AVG Training Loss:0.580 AVG Validation Loss:0.707 AVG Training Acc 67.49 % AVG Validation Acc 61.32 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.582 AVG Validation Loss:0.719 AVG Training Acc 66.96 % AVG Validation Acc 60.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.579 AVG Validation Loss:0.711 AVG Training Acc 66.88 % AVG Validation Acc 61.14 %\n",
      "Epoch:150/200 AVG Training Loss:0.583 AVG Validation Loss:0.711 AVG Training Acc 66.93 % AVG Validation Acc 60.41 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.579 AVG Validation Loss:0.713 AVG Training Acc 67.14 % AVG Validation Acc 60.60 %\n",
      "Epoch:170/200 AVG Training Loss:0.582 AVG Validation Loss:0.709 AVG Training Acc 67.26 % AVG Validation Acc 60.87 %\n",
      "Epoch:180/200 AVG Training Loss:0.582 AVG Validation Loss:0.711 AVG Training Acc 66.89 % AVG Validation Acc 60.23 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.582 AVG Validation Loss:0.714 AVG Training Acc 67.11 % AVG Validation Acc 61.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.581 AVG Validation Loss:0.710 AVG Training Acc 67.26 % AVG Validation Acc 60.60 %\n",
      "Split 165\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea09cbb261214799bbffbe8f07af32a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.659 AVG Training Acc 61.78 % AVG Validation Acc 61.68 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.660 AVG Training Acc 62.06 % AVG Validation Acc 61.50 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.638 AVG Validation Loss:0.664 AVG Training Acc 62.80 % AVG Validation Acc 60.87 %\n",
      "Epoch:40/200 AVG Training Loss:0.628 AVG Validation Loss:0.665 AVG Training Acc 63.00 % AVG Validation Acc 61.23 %\n",
      "Epoch:50/200 AVG Training Loss:0.620 AVG Validation Loss:0.671 AVG Training Acc 63.98 % AVG Validation Acc 59.96 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.609 AVG Validation Loss:0.677 AVG Training Acc 65.50 % AVG Validation Acc 60.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.610 AVG Validation Loss:0.678 AVG Training Acc 65.06 % AVG Validation Acc 60.78 %\n",
      "Epoch:80/200 AVG Training Loss:0.606 AVG Validation Loss:0.679 AVG Training Acc 65.17 % AVG Validation Acc 61.05 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.607 AVG Validation Loss:0.678 AVG Training Acc 65.30 % AVG Validation Acc 61.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.605 AVG Validation Loss:0.673 AVG Training Acc 65.49 % AVG Validation Acc 60.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.607 AVG Validation Loss:0.679 AVG Training Acc 65.86 % AVG Validation Acc 60.41 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.606 AVG Validation Loss:0.679 AVG Training Acc 65.35 % AVG Validation Acc 60.69 %\n",
      "Epoch:130/200 AVG Training Loss:0.607 AVG Validation Loss:0.676 AVG Training Acc 65.33 % AVG Validation Acc 60.50 %\n",
      "Epoch:140/200 AVG Training Loss:0.607 AVG Validation Loss:0.675 AVG Training Acc 65.06 % AVG Validation Acc 60.23 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.607 AVG Validation Loss:0.679 AVG Training Acc 65.47 % AVG Validation Acc 60.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.606 AVG Validation Loss:0.676 AVG Training Acc 65.01 % AVG Validation Acc 60.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.606 AVG Validation Loss:0.679 AVG Training Acc 65.49 % AVG Validation Acc 60.50 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.604 AVG Validation Loss:0.677 AVG Training Acc 65.56 % AVG Validation Acc 60.50 %\n",
      "Epoch:190/200 AVG Training Loss:0.604 AVG Validation Loss:0.679 AVG Training Acc 65.63 % AVG Validation Acc 61.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.605 AVG Validation Loss:0.679 AVG Training Acc 65.72 % AVG Validation Acc 60.69 %\n",
      "Split 166\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a6389969074f490497699e6361d6a301",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.661 AVG Training Acc 61.81 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.660 AVG Training Acc 62.03 % AVG Validation Acc 62.27 %\n",
      "Epoch:30/200 AVG Training Loss:0.642 AVG Validation Loss:0.664 AVG Training Acc 62.73 % AVG Validation Acc 62.55 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.628 AVG Validation Loss:0.666 AVG Training Acc 62.74 % AVG Validation Acc 62.09 %\n",
      "Epoch:50/200 AVG Training Loss:0.617 AVG Validation Loss:0.685 AVG Training Acc 63.64 % AVG Validation Acc 62.73 %\n",
      "Epoch:60/200 AVG Training Loss:0.604 AVG Validation Loss:0.722 AVG Training Acc 64.86 % AVG Validation Acc 62.73 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.597 AVG Validation Loss:0.719 AVG Training Acc 64.71 % AVG Validation Acc 61.55 %\n",
      "Epoch:80/200 AVG Training Loss:0.593 AVG Validation Loss:0.724 AVG Training Acc 65.19 % AVG Validation Acc 61.82 %\n",
      "Epoch:90/200 AVG Training Loss:0.593 AVG Validation Loss:0.730 AVG Training Acc 65.40 % AVG Validation Acc 61.37 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.592 AVG Validation Loss:0.724 AVG Training Acc 65.25 % AVG Validation Acc 61.28 %\n",
      "Epoch:110/200 AVG Training Loss:0.592 AVG Validation Loss:0.722 AVG Training Acc 65.40 % AVG Validation Acc 61.19 %\n",
      "Epoch:120/200 AVG Training Loss:0.591 AVG Validation Loss:0.725 AVG Training Acc 65.24 % AVG Validation Acc 61.28 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.592 AVG Validation Loss:0.727 AVG Training Acc 65.42 % AVG Validation Acc 61.82 %\n",
      "Epoch:140/200 AVG Training Loss:0.594 AVG Validation Loss:0.736 AVG Training Acc 65.02 % AVG Validation Acc 61.10 %\n",
      "Epoch:150/200 AVG Training Loss:0.591 AVG Validation Loss:0.726 AVG Training Acc 64.94 % AVG Validation Acc 61.46 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.593 AVG Validation Loss:0.726 AVG Training Acc 64.98 % AVG Validation Acc 60.92 %\n",
      "Epoch:170/200 AVG Training Loss:0.592 AVG Validation Loss:0.727 AVG Training Acc 65.23 % AVG Validation Acc 61.55 %\n",
      "Epoch:180/200 AVG Training Loss:0.592 AVG Validation Loss:0.728 AVG Training Acc 65.14 % AVG Validation Acc 61.28 %\n",
      "Epoch:190/200 AVG Training Loss:0.592 AVG Validation Loss:0.724 AVG Training Acc 65.17 % AVG Validation Acc 61.37 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.591 AVG Validation Loss:0.725 AVG Training Acc 65.50 % AVG Validation Acc 61.28 %\n",
      "Split 167\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf2792f2296b4841ad95e7439d1e8896",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.657 AVG Training Acc 61.88 % AVG Validation Acc 61.73 %\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:0.651 AVG Training Acc 62.00 % AVG Validation Acc 62.18 %\n",
      "Epoch:30/200 AVG Training Loss:0.659 AVG Validation Loss:0.650 AVG Training Acc 61.74 % AVG Validation Acc 61.82 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.631 AVG Validation Loss:0.657 AVG Training Acc 63.21 % AVG Validation Acc 62.18 %\n",
      "Epoch:50/200 AVG Training Loss:0.618 AVG Validation Loss:0.667 AVG Training Acc 64.90 % AVG Validation Acc 62.82 %\n",
      "Epoch:60/200 AVG Training Loss:0.608 AVG Validation Loss:0.676 AVG Training Acc 65.43 % AVG Validation Acc 62.09 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.600 AVG Validation Loss:0.689 AVG Training Acc 66.23 % AVG Validation Acc 62.00 %\n",
      "Epoch:80/200 AVG Training Loss:0.597 AVG Validation Loss:0.686 AVG Training Acc 66.08 % AVG Validation Acc 61.91 %\n",
      "Epoch:90/200 AVG Training Loss:0.597 AVG Validation Loss:0.690 AVG Training Acc 66.44 % AVG Validation Acc 61.82 %\n",
      "Epoch:100/200 AVG Training Loss:0.594 AVG Validation Loss:0.690 AVG Training Acc 66.59 % AVG Validation Acc 61.10 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.596 AVG Validation Loss:0.692 AVG Training Acc 66.45 % AVG Validation Acc 60.74 %\n",
      "Epoch:120/200 AVG Training Loss:0.595 AVG Validation Loss:0.694 AVG Training Acc 66.75 % AVG Validation Acc 61.37 %\n",
      "Epoch:130/200 AVG Training Loss:0.594 AVG Validation Loss:0.694 AVG Training Acc 66.24 % AVG Validation Acc 61.10 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.594 AVG Validation Loss:0.698 AVG Training Acc 66.30 % AVG Validation Acc 61.73 %\n",
      "Epoch:150/200 AVG Training Loss:0.596 AVG Validation Loss:0.691 AVG Training Acc 66.14 % AVG Validation Acc 61.28 %\n",
      "Epoch:160/200 AVG Training Loss:0.593 AVG Validation Loss:0.694 AVG Training Acc 66.98 % AVG Validation Acc 61.10 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.597 AVG Validation Loss:0.689 AVG Training Acc 65.89 % AVG Validation Acc 61.82 %\n",
      "Epoch:180/200 AVG Training Loss:0.592 AVG Validation Loss:0.690 AVG Training Acc 66.46 % AVG Validation Acc 61.64 %\n",
      "Epoch:190/200 AVG Training Loss:0.593 AVG Validation Loss:0.689 AVG Training Acc 66.14 % AVG Validation Acc 61.73 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.596 AVG Validation Loss:0.693 AVG Training Acc 66.41 % AVG Validation Acc 61.55 %\n",
      "Split 168\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74b830fc62554fba88eab5385c294386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.658 AVG Training Acc 61.84 % AVG Validation Acc 61.73 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.658 AVG Training Acc 61.83 % AVG Validation Acc 61.55 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.642 AVG Validation Loss:0.653 AVG Training Acc 62.47 % AVG Validation Acc 60.56 %\n",
      "Epoch:40/200 AVG Training Loss:0.637 AVG Validation Loss:0.658 AVG Training Acc 62.99 % AVG Validation Acc 61.28 %\n",
      "Epoch:50/200 AVG Training Loss:0.625 AVG Validation Loss:0.667 AVG Training Acc 63.93 % AVG Validation Acc 61.01 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.616 AVG Validation Loss:0.675 AVG Training Acc 64.96 % AVG Validation Acc 61.10 %\n",
      "Epoch:70/200 AVG Training Loss:0.614 AVG Validation Loss:0.674 AVG Training Acc 64.93 % AVG Validation Acc 61.64 %\n",
      "Epoch:80/200 AVG Training Loss:0.613 AVG Validation Loss:0.678 AVG Training Acc 64.78 % AVG Validation Acc 60.74 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.613 AVG Validation Loss:0.677 AVG Training Acc 64.71 % AVG Validation Acc 61.28 %\n",
      "Epoch:100/200 AVG Training Loss:0.612 AVG Validation Loss:0.680 AVG Training Acc 65.28 % AVG Validation Acc 60.74 %\n",
      "Epoch:110/200 AVG Training Loss:0.610 AVG Validation Loss:0.676 AVG Training Acc 65.05 % AVG Validation Acc 61.19 %\n",
      "Epoch:120/200 AVG Training Loss:0.612 AVG Validation Loss:0.677 AVG Training Acc 65.19 % AVG Validation Acc 61.37 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.613 AVG Validation Loss:0.680 AVG Training Acc 65.39 % AVG Validation Acc 61.01 %\n",
      "Epoch:140/200 AVG Training Loss:0.613 AVG Validation Loss:0.678 AVG Training Acc 64.85 % AVG Validation Acc 61.10 %\n",
      "Epoch:150/200 AVG Training Loss:0.612 AVG Validation Loss:0.677 AVG Training Acc 64.75 % AVG Validation Acc 61.46 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.612 AVG Validation Loss:0.679 AVG Training Acc 65.09 % AVG Validation Acc 61.28 %\n",
      "Epoch:170/200 AVG Training Loss:0.611 AVG Validation Loss:0.679 AVG Training Acc 65.04 % AVG Validation Acc 61.46 %\n",
      "Epoch:180/200 AVG Training Loss:0.612 AVG Validation Loss:0.678 AVG Training Acc 64.86 % AVG Validation Acc 61.10 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.610 AVG Validation Loss:0.678 AVG Training Acc 65.15 % AVG Validation Acc 61.10 %\n",
      "Epoch:200/200 AVG Training Loss:0.611 AVG Validation Loss:0.676 AVG Training Acc 65.09 % AVG Validation Acc 61.10 %\n",
      "Split 169\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31226e3c55344e9fa41cc0a9b063d3e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.657 AVG Validation Loss:0.667 AVG Training Acc 61.85 % AVG Validation Acc 61.73 %\n",
      "Epoch:20/200 AVG Training Loss:0.649 AVG Validation Loss:0.658 AVG Training Acc 62.52 % AVG Validation Acc 61.46 %\n",
      "Epoch:30/200 AVG Training Loss:0.645 AVG Validation Loss:0.654 AVG Training Acc 62.32 % AVG Validation Acc 61.73 %\n",
      "Epoch:40/200 AVG Training Loss:0.635 AVG Validation Loss:0.646 AVG Training Acc 63.56 % AVG Validation Acc 62.82 %\n",
      "Epoch:50/200 AVG Training Loss:0.647 AVG Validation Loss:0.652 AVG Training Acc 62.04 % AVG Validation Acc 61.28 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.621 AVG Validation Loss:0.663 AVG Training Acc 63.78 % AVG Validation Acc 61.10 %\n",
      "Epoch:70/200 AVG Training Loss:0.610 AVG Validation Loss:0.676 AVG Training Acc 64.61 % AVG Validation Acc 60.83 %\n",
      "Epoch:80/200 AVG Training Loss:0.604 AVG Validation Loss:0.679 AVG Training Acc 65.18 % AVG Validation Acc 60.65 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.597 AVG Validation Loss:0.684 AVG Training Acc 65.38 % AVG Validation Acc 60.56 %\n",
      "Epoch:100/200 AVG Training Loss:0.595 AVG Validation Loss:0.677 AVG Training Acc 65.62 % AVG Validation Acc 61.01 %\n",
      "Epoch:110/200 AVG Training Loss:0.595 AVG Validation Loss:0.687 AVG Training Acc 65.84 % AVG Validation Acc 60.65 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.592 AVG Validation Loss:0.673 AVG Training Acc 66.17 % AVG Validation Acc 60.11 %\n",
      "Epoch:130/200 AVG Training Loss:0.592 AVG Validation Loss:0.683 AVG Training Acc 66.35 % AVG Validation Acc 60.11 %\n",
      "Epoch:140/200 AVG Training Loss:0.592 AVG Validation Loss:0.687 AVG Training Acc 65.83 % AVG Validation Acc 60.83 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.592 AVG Validation Loss:0.675 AVG Training Acc 65.94 % AVG Validation Acc 60.56 %\n",
      "Epoch:160/200 AVG Training Loss:0.592 AVG Validation Loss:0.679 AVG Training Acc 66.22 % AVG Validation Acc 59.84 %\n",
      "Epoch:170/200 AVG Training Loss:0.593 AVG Validation Loss:0.680 AVG Training Acc 65.85 % AVG Validation Acc 60.20 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.594 AVG Validation Loss:0.683 AVG Training Acc 65.93 % AVG Validation Acc 60.29 %\n",
      "Epoch:190/200 AVG Training Loss:0.590 AVG Validation Loss:0.686 AVG Training Acc 66.47 % AVG Validation Acc 60.74 %\n",
      "Epoch:200/200 AVG Training Loss:0.593 AVG Validation Loss:0.684 AVG Training Acc 65.81 % AVG Validation Acc 60.02 %\n",
      "Split 170\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce7d003595b944a7bf8888f0d7c40d0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.662 AVG Validation Loss:0.657 AVG Training Acc 61.73 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.657 AVG Training Acc 61.69 % AVG Validation Acc 61.64 %\n",
      "Epoch:30/200 AVG Training Loss:0.639 AVG Validation Loss:0.667 AVG Training Acc 62.43 % AVG Validation Acc 60.92 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.617 AVG Validation Loss:0.675 AVG Training Acc 64.66 % AVG Validation Acc 59.75 %\n",
      "Epoch:50/200 AVG Training Loss:0.598 AVG Validation Loss:0.692 AVG Training Acc 65.96 % AVG Validation Acc 59.48 %\n",
      "Epoch:60/200 AVG Training Loss:0.588 AVG Validation Loss:0.703 AVG Training Acc 66.95 % AVG Validation Acc 59.57 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.579 AVG Validation Loss:0.710 AVG Training Acc 67.64 % AVG Validation Acc 60.65 %\n",
      "Epoch:80/200 AVG Training Loss:0.574 AVG Validation Loss:0.719 AVG Training Acc 68.45 % AVG Validation Acc 59.75 %\n",
      "Epoch:90/200 AVG Training Loss:0.574 AVG Validation Loss:0.726 AVG Training Acc 68.04 % AVG Validation Acc 59.93 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.571 AVG Validation Loss:0.722 AVG Training Acc 68.27 % AVG Validation Acc 59.75 %\n",
      "Epoch:110/200 AVG Training Loss:0.572 AVG Validation Loss:0.721 AVG Training Acc 68.27 % AVG Validation Acc 59.93 %\n",
      "Epoch:120/200 AVG Training Loss:0.569 AVG Validation Loss:0.717 AVG Training Acc 68.40 % AVG Validation Acc 60.56 %\n",
      "Epoch:130/200 AVG Training Loss:0.570 AVG Validation Loss:0.724 AVG Training Acc 68.20 % AVG Validation Acc 59.39 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.570 AVG Validation Loss:0.723 AVG Training Acc 68.65 % AVG Validation Acc 59.66 %\n",
      "Epoch:150/200 AVG Training Loss:0.569 AVG Validation Loss:0.723 AVG Training Acc 68.31 % AVG Validation Acc 59.48 %\n",
      "Epoch:160/200 AVG Training Loss:0.569 AVG Validation Loss:0.719 AVG Training Acc 68.39 % AVG Validation Acc 59.39 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.570 AVG Validation Loss:0.722 AVG Training Acc 68.28 % AVG Validation Acc 58.84 %\n",
      "Epoch:180/200 AVG Training Loss:0.569 AVG Validation Loss:0.717 AVG Training Acc 68.22 % AVG Validation Acc 61.28 %\n",
      "Epoch:190/200 AVG Training Loss:0.571 AVG Validation Loss:0.713 AVG Training Acc 68.26 % AVG Validation Acc 60.92 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.571 AVG Validation Loss:0.719 AVG Training Acc 67.85 % AVG Validation Acc 59.75 %\n",
      "Split 171\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8e093692f394894bfc7dfc4df3ed5aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.658 AVG Training Acc 61.85 % AVG Validation Acc 62.04 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.656 AVG Training Acc 61.88 % AVG Validation Acc 61.95 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.639 AVG Validation Loss:0.657 AVG Training Acc 62.66 % AVG Validation Acc 59.69 %\n",
      "Epoch:40/200 AVG Training Loss:0.631 AVG Validation Loss:0.659 AVG Training Acc 63.71 % AVG Validation Acc 60.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.624 AVG Validation Loss:0.662 AVG Training Acc 63.98 % AVG Validation Acc 59.51 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.620 AVG Validation Loss:0.662 AVG Training Acc 64.50 % AVG Validation Acc 59.78 %\n",
      "Epoch:70/200 AVG Training Loss:0.618 AVG Validation Loss:0.663 AVG Training Acc 64.90 % AVG Validation Acc 59.60 %\n",
      "Epoch:80/200 AVG Training Loss:0.618 AVG Validation Loss:0.666 AVG Training Acc 64.52 % AVG Validation Acc 59.60 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.617 AVG Validation Loss:0.662 AVG Training Acc 64.66 % AVG Validation Acc 60.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.616 AVG Validation Loss:0.664 AVG Training Acc 65.24 % AVG Validation Acc 60.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.616 AVG Validation Loss:0.666 AVG Training Acc 65.00 % AVG Validation Acc 59.69 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.616 AVG Validation Loss:0.663 AVG Training Acc 64.91 % AVG Validation Acc 59.87 %\n",
      "Epoch:130/200 AVG Training Loss:0.613 AVG Validation Loss:0.665 AVG Training Acc 64.89 % AVG Validation Acc 59.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.615 AVG Validation Loss:0.664 AVG Training Acc 65.08 % AVG Validation Acc 60.05 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.617 AVG Validation Loss:0.663 AVG Training Acc 64.84 % AVG Validation Acc 60.05 %\n",
      "Epoch:160/200 AVG Training Loss:0.617 AVG Validation Loss:0.668 AVG Training Acc 64.79 % AVG Validation Acc 59.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.617 AVG Validation Loss:0.664 AVG Training Acc 64.63 % AVG Validation Acc 60.14 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.616 AVG Validation Loss:0.665 AVG Training Acc 65.00 % AVG Validation Acc 59.78 %\n",
      "Epoch:190/200 AVG Training Loss:0.616 AVG Validation Loss:0.664 AVG Training Acc 65.36 % AVG Validation Acc 60.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.614 AVG Validation Loss:0.663 AVG Training Acc 65.11 % AVG Validation Acc 59.78 %\n",
      "Split 172\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1bba98e349345868fa7f64d2b851268",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 61.92 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.647 AVG Validation Loss:0.656 AVG Training Acc 61.54 % AVG Validation Acc 61.77 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.628 AVG Validation Loss:0.669 AVG Training Acc 63.04 % AVG Validation Acc 62.49 %\n",
      "Epoch:40/200 AVG Training Loss:0.614 AVG Validation Loss:0.691 AVG Training Acc 64.51 % AVG Validation Acc 62.40 %\n",
      "Epoch:50/200 AVG Training Loss:0.605 AVG Validation Loss:0.700 AVG Training Acc 65.07 % AVG Validation Acc 61.41 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.594 AVG Validation Loss:0.705 AVG Training Acc 66.10 % AVG Validation Acc 61.50 %\n",
      "Epoch:70/200 AVG Training Loss:0.591 AVG Validation Loss:0.705 AVG Training Acc 66.56 % AVG Validation Acc 61.95 %\n",
      "Epoch:80/200 AVG Training Loss:0.589 AVG Validation Loss:0.715 AVG Training Acc 66.54 % AVG Validation Acc 61.68 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.589 AVG Validation Loss:0.710 AVG Training Acc 66.50 % AVG Validation Acc 62.04 %\n",
      "Epoch:100/200 AVG Training Loss:0.590 AVG Validation Loss:0.712 AVG Training Acc 66.30 % AVG Validation Acc 62.13 %\n",
      "Epoch:110/200 AVG Training Loss:0.590 AVG Validation Loss:0.711 AVG Training Acc 66.46 % AVG Validation Acc 61.41 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.586 AVG Validation Loss:0.714 AVG Training Acc 66.58 % AVG Validation Acc 61.68 %\n",
      "Epoch:130/200 AVG Training Loss:0.588 AVG Validation Loss:0.716 AVG Training Acc 66.69 % AVG Validation Acc 61.32 %\n",
      "Epoch:140/200 AVG Training Loss:0.588 AVG Validation Loss:0.712 AVG Training Acc 66.60 % AVG Validation Acc 61.05 %\n",
      "Epoch:150/200 AVG Training Loss:0.588 AVG Validation Loss:0.720 AVG Training Acc 66.50 % AVG Validation Acc 61.77 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.588 AVG Validation Loss:0.712 AVG Training Acc 66.76 % AVG Validation Acc 61.59 %\n",
      "Epoch:170/200 AVG Training Loss:0.591 AVG Validation Loss:0.713 AVG Training Acc 66.52 % AVG Validation Acc 61.32 %\n",
      "Epoch:180/200 AVG Training Loss:0.589 AVG Validation Loss:0.712 AVG Training Acc 66.82 % AVG Validation Acc 61.68 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.590 AVG Validation Loss:0.714 AVG Training Acc 65.81 % AVG Validation Acc 61.59 %\n",
      "Epoch:200/200 AVG Training Loss:0.592 AVG Validation Loss:0.710 AVG Training Acc 65.81 % AVG Validation Acc 60.96 %\n",
      "Split 173\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66da2db0f2684dbb9183457ff19d3fa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.661 AVG Training Acc 61.75 % AVG Validation Acc 62.04 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.663 AVG Training Acc 61.63 % AVG Validation Acc 61.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.662 AVG Validation Loss:0.662 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.659 AVG Validation Loss:0.660 AVG Training Acc 61.86 % AVG Validation Acc 61.86 %\n",
      "Epoch:50/200 AVG Training Loss:0.658 AVG Validation Loss:0.661 AVG Training Acc 61.94 % AVG Validation Acc 61.86 %\n",
      "Epoch:60/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.656 AVG Validation Loss:0.663 AVG Training Acc 61.99 % AVG Validation Acc 61.95 %\n",
      "Epoch:80/200 AVG Training Loss:0.656 AVG Validation Loss:0.663 AVG Training Acc 61.94 % AVG Validation Acc 62.04 %\n",
      "Epoch:90/200 AVG Training Loss:0.656 AVG Validation Loss:0.663 AVG Training Acc 61.96 % AVG Validation Acc 62.13 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.656 AVG Validation Loss:0.662 AVG Training Acc 61.98 % AVG Validation Acc 62.04 %\n",
      "Epoch:110/200 AVG Training Loss:0.655 AVG Validation Loss:0.663 AVG Training Acc 62.01 % AVG Validation Acc 62.13 %\n",
      "Epoch:120/200 AVG Training Loss:0.656 AVG Validation Loss:0.662 AVG Training Acc 61.98 % AVG Validation Acc 62.13 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.656 AVG Validation Loss:0.662 AVG Training Acc 62.04 % AVG Validation Acc 62.13 %\n",
      "Epoch:140/200 AVG Training Loss:0.655 AVG Validation Loss:0.663 AVG Training Acc 62.00 % AVG Validation Acc 62.13 %\n",
      "Epoch:150/200 AVG Training Loss:0.656 AVG Validation Loss:0.663 AVG Training Acc 62.03 % AVG Validation Acc 62.04 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.655 AVG Validation Loss:0.663 AVG Training Acc 61.93 % AVG Validation Acc 62.13 %\n",
      "Epoch:170/200 AVG Training Loss:0.656 AVG Validation Loss:0.663 AVG Training Acc 61.86 % AVG Validation Acc 62.13 %\n",
      "Epoch:180/200 AVG Training Loss:0.655 AVG Validation Loss:0.663 AVG Training Acc 61.98 % AVG Validation Acc 62.13 %\n",
      "Epoch:190/200 AVG Training Loss:0.655 AVG Validation Loss:0.662 AVG Training Acc 61.98 % AVG Validation Acc 62.13 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.655 AVG Validation Loss:0.663 AVG Training Acc 61.97 % AVG Validation Acc 62.13 %\n",
      "Split 174\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3be9af6735504a3a89aafb84f62c6983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.657 AVG Validation Loss:0.664 AVG Training Acc 61.87 % AVG Validation Acc 62.13 %\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.647 AVG Validation Loss:0.657 AVG Training Acc 62.55 % AVG Validation Acc 62.31 %\n",
      "Epoch:30/200 AVG Training Loss:0.639 AVG Validation Loss:0.656 AVG Training Acc 62.48 % AVG Validation Acc 61.59 %\n",
      "Epoch:40/200 AVG Training Loss:0.634 AVG Validation Loss:0.658 AVG Training Acc 62.64 % AVG Validation Acc 62.13 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.626 AVG Validation Loss:0.663 AVG Training Acc 64.04 % AVG Validation Acc 62.49 %\n",
      "Epoch:60/200 AVG Training Loss:0.625 AVG Validation Loss:0.669 AVG Training Acc 63.74 % AVG Validation Acc 62.67 %\n",
      "Epoch:70/200 AVG Training Loss:0.624 AVG Validation Loss:0.671 AVG Training Acc 63.94 % AVG Validation Acc 62.76 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.621 AVG Validation Loss:0.676 AVG Training Acc 63.79 % AVG Validation Acc 62.67 %\n",
      "Epoch:90/200 AVG Training Loss:0.622 AVG Validation Loss:0.669 AVG Training Acc 64.09 % AVG Validation Acc 61.95 %\n",
      "Epoch:100/200 AVG Training Loss:0.622 AVG Validation Loss:0.675 AVG Training Acc 64.33 % AVG Validation Acc 62.76 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.622 AVG Validation Loss:0.674 AVG Training Acc 63.88 % AVG Validation Acc 62.40 %\n",
      "Epoch:120/200 AVG Training Loss:0.623 AVG Validation Loss:0.673 AVG Training Acc 63.92 % AVG Validation Acc 62.22 %\n",
      "Epoch:130/200 AVG Training Loss:0.622 AVG Validation Loss:0.674 AVG Training Acc 63.83 % AVG Validation Acc 62.31 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.623 AVG Validation Loss:0.675 AVG Training Acc 63.94 % AVG Validation Acc 61.77 %\n",
      "Epoch:150/200 AVG Training Loss:0.622 AVG Validation Loss:0.673 AVG Training Acc 64.14 % AVG Validation Acc 62.22 %\n",
      "Epoch:160/200 AVG Training Loss:0.622 AVG Validation Loss:0.674 AVG Training Acc 63.97 % AVG Validation Acc 62.04 %\n",
      "Epoch:170/200 AVG Training Loss:0.622 AVG Validation Loss:0.671 AVG Training Acc 64.28 % AVG Validation Acc 62.49 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.623 AVG Validation Loss:0.673 AVG Training Acc 63.56 % AVG Validation Acc 62.31 %\n",
      "Epoch:190/200 AVG Training Loss:0.623 AVG Validation Loss:0.679 AVG Training Acc 63.58 % AVG Validation Acc 61.68 %\n",
      "Epoch:200/200 AVG Training Loss:0.621 AVG Validation Loss:0.672 AVG Training Acc 63.97 % AVG Validation Acc 61.68 %\n",
      "Split 175\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b6b51dd36a74cfda999a69a8fd99402",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.653 AVG Training Acc 61.81 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.654 AVG Training Acc 61.82 % AVG Validation Acc 61.95 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.634 AVG Validation Loss:0.652 AVG Training Acc 62.50 % AVG Validation Acc 61.59 %\n",
      "Epoch:40/200 AVG Training Loss:0.619 AVG Validation Loss:0.660 AVG Training Acc 63.67 % AVG Validation Acc 60.41 %\n",
      "Epoch:50/200 AVG Training Loss:0.609 AVG Validation Loss:0.671 AVG Training Acc 64.37 % AVG Validation Acc 60.32 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.606 AVG Validation Loss:0.672 AVG Training Acc 63.86 % AVG Validation Acc 60.69 %\n",
      "Epoch:70/200 AVG Training Loss:0.600 AVG Validation Loss:0.679 AVG Training Acc 64.64 % AVG Validation Acc 59.24 %\n",
      "Epoch:80/200 AVG Training Loss:0.598 AVG Validation Loss:0.676 AVG Training Acc 65.12 % AVG Validation Acc 59.60 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.595 AVG Validation Loss:0.680 AVG Training Acc 64.88 % AVG Validation Acc 59.24 %\n",
      "Epoch:100/200 AVG Training Loss:0.596 AVG Validation Loss:0.674 AVG Training Acc 64.53 % AVG Validation Acc 58.88 %\n",
      "Epoch:110/200 AVG Training Loss:0.596 AVG Validation Loss:0.682 AVG Training Acc 64.73 % AVG Validation Acc 58.79 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.597 AVG Validation Loss:0.677 AVG Training Acc 64.87 % AVG Validation Acc 59.24 %\n",
      "Epoch:130/200 AVG Training Loss:0.594 AVG Validation Loss:0.679 AVG Training Acc 64.83 % AVG Validation Acc 58.88 %\n",
      "Epoch:140/200 AVG Training Loss:0.594 AVG Validation Loss:0.678 AVG Training Acc 64.99 % AVG Validation Acc 59.69 %\n",
      "Epoch:150/200 AVG Training Loss:0.595 AVG Validation Loss:0.680 AVG Training Acc 65.11 % AVG Validation Acc 59.15 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.596 AVG Validation Loss:0.680 AVG Training Acc 64.63 % AVG Validation Acc 58.88 %\n",
      "Epoch:170/200 AVG Training Loss:0.597 AVG Validation Loss:0.681 AVG Training Acc 64.57 % AVG Validation Acc 58.61 %\n",
      "Epoch:180/200 AVG Training Loss:0.593 AVG Validation Loss:0.677 AVG Training Acc 65.09 % AVG Validation Acc 58.79 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.595 AVG Validation Loss:0.675 AVG Training Acc 64.85 % AVG Validation Acc 59.33 %\n",
      "Epoch:200/200 AVG Training Loss:0.596 AVG Validation Loss:0.680 AVG Training Acc 64.63 % AVG Validation Acc 59.24 %\n",
      "Split 176\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f301c1f7d89349e7b8d16b3f188d245a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.656 AVG Training Acc 61.88 % AVG Validation Acc 61.64 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.659 AVG Training Acc 61.96 % AVG Validation Acc 61.10 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.638 AVG Validation Loss:0.659 AVG Training Acc 62.88 % AVG Validation Acc 61.10 %\n",
      "Epoch:40/200 AVG Training Loss:0.630 AVG Validation Loss:0.668 AVG Training Acc 63.24 % AVG Validation Acc 61.82 %\n",
      "Epoch:50/200 AVG Training Loss:0.624 AVG Validation Loss:0.681 AVG Training Acc 63.90 % AVG Validation Acc 62.36 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.617 AVG Validation Loss:0.689 AVG Training Acc 64.22 % AVG Validation Acc 62.55 %\n",
      "Epoch:70/200 AVG Training Loss:0.615 AVG Validation Loss:0.691 AVG Training Acc 64.83 % AVG Validation Acc 62.18 %\n",
      "Epoch:80/200 AVG Training Loss:0.615 AVG Validation Loss:0.687 AVG Training Acc 64.64 % AVG Validation Acc 62.55 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.614 AVG Validation Loss:0.693 AVG Training Acc 64.42 % AVG Validation Acc 62.27 %\n",
      "Epoch:100/200 AVG Training Loss:0.612 AVG Validation Loss:0.687 AVG Training Acc 65.08 % AVG Validation Acc 62.27 %\n",
      "Epoch:110/200 AVG Training Loss:0.613 AVG Validation Loss:0.688 AVG Training Acc 65.00 % AVG Validation Acc 62.82 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.614 AVG Validation Loss:0.688 AVG Training Acc 65.01 % AVG Validation Acc 62.36 %\n",
      "Epoch:130/200 AVG Training Loss:0.613 AVG Validation Loss:0.692 AVG Training Acc 64.95 % AVG Validation Acc 62.18 %\n",
      "Epoch:140/200 AVG Training Loss:0.612 AVG Validation Loss:0.695 AVG Training Acc 64.79 % AVG Validation Acc 62.18 %\n",
      "Epoch:150/200 AVG Training Loss:0.615 AVG Validation Loss:0.697 AVG Training Acc 64.62 % AVG Validation Acc 62.09 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.611 AVG Validation Loss:0.694 AVG Training Acc 64.90 % AVG Validation Acc 62.45 %\n",
      "Epoch:170/200 AVG Training Loss:0.612 AVG Validation Loss:0.696 AVG Training Acc 64.93 % AVG Validation Acc 62.36 %\n",
      "Epoch:180/200 AVG Training Loss:0.613 AVG Validation Loss:0.696 AVG Training Acc 64.89 % AVG Validation Acc 62.27 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.612 AVG Validation Loss:0.695 AVG Training Acc 64.76 % AVG Validation Acc 62.55 %\n",
      "Epoch:200/200 AVG Training Loss:0.614 AVG Validation Loss:0.685 AVG Training Acc 64.87 % AVG Validation Acc 62.55 %\n",
      "Split 177\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a435a6dd82f477d890c91985ec76144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.658 AVG Training Acc 61.75 % AVG Validation Acc 62.00 %\n",
      "Epoch:20/200 AVG Training Loss:0.647 AVG Validation Loss:0.654 AVG Training Acc 61.80 % AVG Validation Acc 61.55 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.628 AVG Validation Loss:0.652 AVG Training Acc 63.17 % AVG Validation Acc 63.27 %\n",
      "Epoch:40/200 AVG Training Loss:0.610 AVG Validation Loss:0.675 AVG Training Acc 64.22 % AVG Validation Acc 61.37 %\n",
      "Epoch:50/200 AVG Training Loss:0.595 AVG Validation Loss:0.696 AVG Training Acc 64.89 % AVG Validation Acc 62.18 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.585 AVG Validation Loss:0.697 AVG Training Acc 65.64 % AVG Validation Acc 62.55 %\n",
      "Epoch:70/200 AVG Training Loss:0.583 AVG Validation Loss:0.705 AVG Training Acc 65.76 % AVG Validation Acc 61.64 %\n",
      "Epoch:80/200 AVG Training Loss:0.578 AVG Validation Loss:0.707 AVG Training Acc 65.72 % AVG Validation Acc 61.73 %\n",
      "Epoch:90/200 AVG Training Loss:0.579 AVG Validation Loss:0.707 AVG Training Acc 65.64 % AVG Validation Acc 62.45 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.579 AVG Validation Loss:0.705 AVG Training Acc 65.79 % AVG Validation Acc 62.00 %\n",
      "Epoch:110/200 AVG Training Loss:0.581 AVG Validation Loss:0.714 AVG Training Acc 65.86 % AVG Validation Acc 62.36 %\n",
      "Epoch:120/200 AVG Training Loss:0.578 AVG Validation Loss:0.703 AVG Training Acc 65.85 % AVG Validation Acc 62.27 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.578 AVG Validation Loss:0.708 AVG Training Acc 66.05 % AVG Validation Acc 61.55 %\n",
      "Epoch:140/200 AVG Training Loss:0.581 AVG Validation Loss:0.712 AVG Training Acc 65.44 % AVG Validation Acc 61.37 %\n",
      "Epoch:150/200 AVG Training Loss:0.578 AVG Validation Loss:0.713 AVG Training Acc 65.94 % AVG Validation Acc 62.55 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.578 AVG Validation Loss:0.710 AVG Training Acc 65.81 % AVG Validation Acc 61.55 %\n",
      "Epoch:170/200 AVG Training Loss:0.582 AVG Validation Loss:0.704 AVG Training Acc 65.53 % AVG Validation Acc 62.64 %\n",
      "Epoch:180/200 AVG Training Loss:0.581 AVG Validation Loss:0.712 AVG Training Acc 65.75 % AVG Validation Acc 62.55 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.580 AVG Validation Loss:0.707 AVG Training Acc 65.91 % AVG Validation Acc 63.36 %\n",
      "Epoch:200/200 AVG Training Loss:0.581 AVG Validation Loss:0.716 AVG Training Acc 66.09 % AVG Validation Acc 62.36 %\n",
      "Split 178\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9529dd81c2b04fd79d6441219d038214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.656 AVG Training Acc 61.75 % AVG Validation Acc 61.55 %\n",
      "Epoch:20/200 AVG Training Loss:0.656 AVG Validation Loss:0.652 AVG Training Acc 61.84 % AVG Validation Acc 62.00 %\n",
      "Epoch:30/200 AVG Training Loss:0.648 AVG Validation Loss:0.663 AVG Training Acc 62.21 % AVG Validation Acc 61.64 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.628 AVG Validation Loss:0.668 AVG Training Acc 63.21 % AVG Validation Acc 61.01 %\n",
      "Epoch:50/200 AVG Training Loss:0.619 AVG Validation Loss:0.671 AVG Training Acc 64.24 % AVG Validation Acc 61.28 %\n",
      "Epoch:60/200 AVG Training Loss:0.616 AVG Validation Loss:0.678 AVG Training Acc 64.71 % AVG Validation Acc 60.20 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.609 AVG Validation Loss:0.680 AVG Training Acc 65.10 % AVG Validation Acc 61.01 %\n",
      "Epoch:80/200 AVG Training Loss:0.607 AVG Validation Loss:0.685 AVG Training Acc 65.16 % AVG Validation Acc 60.83 %\n",
      "Epoch:90/200 AVG Training Loss:0.605 AVG Validation Loss:0.682 AVG Training Acc 65.20 % AVG Validation Acc 60.47 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.607 AVG Validation Loss:0.685 AVG Training Acc 65.22 % AVG Validation Acc 61.01 %\n",
      "Epoch:110/200 AVG Training Loss:0.605 AVG Validation Loss:0.682 AVG Training Acc 65.31 % AVG Validation Acc 60.92 %\n",
      "Epoch:120/200 AVG Training Loss:0.603 AVG Validation Loss:0.685 AVG Training Acc 65.30 % AVG Validation Acc 60.56 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.607 AVG Validation Loss:0.690 AVG Training Acc 65.49 % AVG Validation Acc 60.38 %\n",
      "Epoch:140/200 AVG Training Loss:0.605 AVG Validation Loss:0.690 AVG Training Acc 65.15 % AVG Validation Acc 60.83 %\n",
      "Epoch:150/200 AVG Training Loss:0.605 AVG Validation Loss:0.685 AVG Training Acc 65.14 % AVG Validation Acc 60.38 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.603 AVG Validation Loss:0.684 AVG Training Acc 65.38 % AVG Validation Acc 60.38 %\n",
      "Epoch:170/200 AVG Training Loss:0.605 AVG Validation Loss:0.692 AVG Training Acc 65.14 % AVG Validation Acc 60.65 %\n",
      "Epoch:180/200 AVG Training Loss:0.605 AVG Validation Loss:0.684 AVG Training Acc 65.29 % AVG Validation Acc 60.38 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.604 AVG Validation Loss:0.685 AVG Training Acc 65.28 % AVG Validation Acc 60.11 %\n",
      "Epoch:200/200 AVG Training Loss:0.607 AVG Validation Loss:0.683 AVG Training Acc 65.15 % AVG Validation Acc 60.11 %\n",
      "Split 179\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c3c6a3356e9467fa1021e07fd7f14a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.664 AVG Training Acc 61.76 % AVG Validation Acc 62.00 %\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.649 AVG Validation Loss:0.673 AVG Training Acc 61.96 % AVG Validation Acc 60.20 %\n",
      "Epoch:30/200 AVG Training Loss:0.643 AVG Validation Loss:0.675 AVG Training Acc 62.67 % AVG Validation Acc 59.93 %\n",
      "Epoch:40/200 AVG Training Loss:0.637 AVG Validation Loss:0.681 AVG Training Acc 62.86 % AVG Validation Acc 59.75 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.632 AVG Validation Loss:0.681 AVG Training Acc 63.18 % AVG Validation Acc 58.94 %\n",
      "Epoch:60/200 AVG Training Loss:0.630 AVG Validation Loss:0.682 AVG Training Acc 63.34 % AVG Validation Acc 58.57 %\n",
      "Epoch:70/200 AVG Training Loss:0.629 AVG Validation Loss:0.683 AVG Training Acc 62.89 % AVG Validation Acc 58.84 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.628 AVG Validation Loss:0.684 AVG Training Acc 63.20 % AVG Validation Acc 59.03 %\n",
      "Epoch:90/200 AVG Training Loss:0.628 AVG Validation Loss:0.685 AVG Training Acc 63.45 % AVG Validation Acc 58.48 %\n",
      "Epoch:100/200 AVG Training Loss:0.628 AVG Validation Loss:0.685 AVG Training Acc 63.54 % AVG Validation Acc 59.21 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.627 AVG Validation Loss:0.684 AVG Training Acc 63.46 % AVG Validation Acc 58.57 %\n",
      "Epoch:120/200 AVG Training Loss:0.627 AVG Validation Loss:0.685 AVG Training Acc 63.62 % AVG Validation Acc 58.57 %\n",
      "Epoch:130/200 AVG Training Loss:0.625 AVG Validation Loss:0.685 AVG Training Acc 63.70 % AVG Validation Acc 59.21 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.627 AVG Validation Loss:0.684 AVG Training Acc 63.51 % AVG Validation Acc 59.39 %\n",
      "Epoch:150/200 AVG Training Loss:0.627 AVG Validation Loss:0.686 AVG Training Acc 63.48 % AVG Validation Acc 58.84 %\n",
      "Epoch:160/200 AVG Training Loss:0.627 AVG Validation Loss:0.684 AVG Training Acc 63.36 % AVG Validation Acc 58.57 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.627 AVG Validation Loss:0.685 AVG Training Acc 63.13 % AVG Validation Acc 58.94 %\n",
      "Epoch:180/200 AVG Training Loss:0.627 AVG Validation Loss:0.685 AVG Training Acc 63.66 % AVG Validation Acc 58.66 %\n",
      "Epoch:190/200 AVG Training Loss:0.627 AVG Validation Loss:0.685 AVG Training Acc 63.45 % AVG Validation Acc 58.94 %\n",
      "Epoch:200/200 AVG Training Loss:0.625 AVG Validation Loss:0.685 AVG Training Acc 63.34 % AVG Validation Acc 58.39 %\n",
      "Split 180\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b681b218f1ac4890aeeb4b03aeb64826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.656 AVG Training Acc 61.74 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.652 AVG Training Acc 61.87 % AVG Validation Acc 61.28 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.627 AVG Validation Loss:0.655 AVG Training Acc 63.06 % AVG Validation Acc 59.48 %\n",
      "Epoch:40/200 AVG Training Loss:0.609 AVG Validation Loss:0.666 AVG Training Acc 65.24 % AVG Validation Acc 60.29 %\n",
      "Epoch:50/200 AVG Training Loss:0.599 AVG Validation Loss:0.666 AVG Training Acc 65.55 % AVG Validation Acc 61.01 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.588 AVG Validation Loss:0.671 AVG Training Acc 66.66 % AVG Validation Acc 60.65 %\n",
      "Epoch:70/200 AVG Training Loss:0.585 AVG Validation Loss:0.676 AVG Training Acc 67.19 % AVG Validation Acc 61.37 %\n",
      "Epoch:80/200 AVG Training Loss:0.586 AVG Validation Loss:0.675 AVG Training Acc 67.24 % AVG Validation Acc 61.01 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.583 AVG Validation Loss:0.675 AVG Training Acc 67.01 % AVG Validation Acc 61.01 %\n",
      "Epoch:100/200 AVG Training Loss:0.584 AVG Validation Loss:0.675 AVG Training Acc 67.41 % AVG Validation Acc 60.83 %\n",
      "Epoch:110/200 AVG Training Loss:0.581 AVG Validation Loss:0.673 AVG Training Acc 67.70 % AVG Validation Acc 60.74 %\n",
      "Epoch:120/200 AVG Training Loss:0.581 AVG Validation Loss:0.678 AVG Training Acc 67.15 % AVG Validation Acc 61.19 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.582 AVG Validation Loss:0.675 AVG Training Acc 67.25 % AVG Validation Acc 60.65 %\n",
      "Epoch:140/200 AVG Training Loss:0.580 AVG Validation Loss:0.677 AVG Training Acc 67.27 % AVG Validation Acc 60.92 %\n",
      "Epoch:150/200 AVG Training Loss:0.583 AVG Validation Loss:0.674 AVG Training Acc 67.38 % AVG Validation Acc 62.00 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.581 AVG Validation Loss:0.678 AVG Training Acc 67.03 % AVG Validation Acc 61.10 %\n",
      "Epoch:170/200 AVG Training Loss:0.583 AVG Validation Loss:0.680 AVG Training Acc 67.19 % AVG Validation Acc 60.92 %\n",
      "Epoch:180/200 AVG Training Loss:0.579 AVG Validation Loss:0.674 AVG Training Acc 67.52 % AVG Validation Acc 60.65 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.582 AVG Validation Loss:0.679 AVG Training Acc 67.27 % AVG Validation Acc 60.74 %\n",
      "Epoch:200/200 AVG Training Loss:0.579 AVG Validation Loss:0.673 AVG Training Acc 67.58 % AVG Validation Acc 60.92 %\n",
      "Split 181\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d2d50e49f164821a1aea183e01d38b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.661 AVG Training Acc 61.88 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.662 AVG Training Acc 61.94 % AVG Validation Acc 61.32 %\n",
      "Epoch:30/200 AVG Training Loss:0.642 AVG Validation Loss:0.664 AVG Training Acc 62.38 % AVG Validation Acc 61.32 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.617 AVG Validation Loss:0.670 AVG Training Acc 64.25 % AVG Validation Acc 60.50 %\n",
      "Epoch:50/200 AVG Training Loss:0.609 AVG Validation Loss:0.682 AVG Training Acc 64.83 % AVG Validation Acc 59.69 %\n",
      "Epoch:60/200 AVG Training Loss:0.602 AVG Validation Loss:0.691 AVG Training Acc 65.24 % AVG Validation Acc 60.05 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.594 AVG Validation Loss:0.703 AVG Training Acc 65.57 % AVG Validation Acc 60.23 %\n",
      "Epoch:80/200 AVG Training Loss:0.593 AVG Validation Loss:0.701 AVG Training Acc 65.82 % AVG Validation Acc 60.69 %\n",
      "Epoch:90/200 AVG Training Loss:0.593 AVG Validation Loss:0.700 AVG Training Acc 65.70 % AVG Validation Acc 60.05 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.592 AVG Validation Loss:0.705 AVG Training Acc 65.68 % AVG Validation Acc 60.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.591 AVG Validation Loss:0.705 AVG Training Acc 65.73 % AVG Validation Acc 60.23 %\n",
      "Epoch:120/200 AVG Training Loss:0.594 AVG Validation Loss:0.702 AVG Training Acc 65.55 % AVG Validation Acc 59.78 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.593 AVG Validation Loss:0.701 AVG Training Acc 65.53 % AVG Validation Acc 60.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.590 AVG Validation Loss:0.704 AVG Training Acc 65.76 % AVG Validation Acc 60.32 %\n",
      "Epoch:150/200 AVG Training Loss:0.593 AVG Validation Loss:0.700 AVG Training Acc 65.62 % AVG Validation Acc 60.41 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.590 AVG Validation Loss:0.701 AVG Training Acc 65.57 % AVG Validation Acc 59.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.593 AVG Validation Loss:0.702 AVG Training Acc 65.67 % AVG Validation Acc 60.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.594 AVG Validation Loss:0.702 AVG Training Acc 65.86 % AVG Validation Acc 60.41 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.592 AVG Validation Loss:0.701 AVG Training Acc 65.65 % AVG Validation Acc 60.41 %\n",
      "Epoch:200/200 AVG Training Loss:0.590 AVG Validation Loss:0.704 AVG Training Acc 65.95 % AVG Validation Acc 60.69 %\n",
      "Split 182\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e86f77bcf5894fb28e0119d3a2b174eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.653 AVG Training Acc 61.79 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.649 AVG Validation Loss:0.650 AVG Training Acc 61.97 % AVG Validation Acc 61.50 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.631 AVG Validation Loss:0.662 AVG Training Acc 63.50 % AVG Validation Acc 61.68 %\n",
      "Epoch:40/200 AVG Training Loss:0.619 AVG Validation Loss:0.674 AVG Training Acc 64.62 % AVG Validation Acc 61.41 %\n",
      "Epoch:50/200 AVG Training Loss:0.606 AVG Validation Loss:0.688 AVG Training Acc 65.98 % AVG Validation Acc 60.32 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.598 AVG Validation Loss:0.690 AVG Training Acc 65.95 % AVG Validation Acc 59.60 %\n",
      "Epoch:70/200 AVG Training Loss:0.597 AVG Validation Loss:0.698 AVG Training Acc 65.79 % AVG Validation Acc 60.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.595 AVG Validation Loss:0.691 AVG Training Acc 66.17 % AVG Validation Acc 59.51 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.595 AVG Validation Loss:0.694 AVG Training Acc 66.22 % AVG Validation Acc 59.78 %\n",
      "Epoch:100/200 AVG Training Loss:0.596 AVG Validation Loss:0.698 AVG Training Acc 66.04 % AVG Validation Acc 59.96 %\n",
      "Epoch:110/200 AVG Training Loss:0.594 AVG Validation Loss:0.697 AVG Training Acc 65.92 % AVG Validation Acc 59.60 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.594 AVG Validation Loss:0.699 AVG Training Acc 66.20 % AVG Validation Acc 59.87 %\n",
      "Epoch:130/200 AVG Training Loss:0.596 AVG Validation Loss:0.698 AVG Training Acc 66.15 % AVG Validation Acc 59.33 %\n",
      "Epoch:140/200 AVG Training Loss:0.593 AVG Validation Loss:0.698 AVG Training Acc 66.17 % AVG Validation Acc 59.87 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.592 AVG Validation Loss:0.697 AVG Training Acc 66.16 % AVG Validation Acc 59.60 %\n",
      "Epoch:160/200 AVG Training Loss:0.595 AVG Validation Loss:0.694 AVG Training Acc 65.77 % AVG Validation Acc 59.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.593 AVG Validation Loss:0.702 AVG Training Acc 66.51 % AVG Validation Acc 59.51 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.594 AVG Validation Loss:0.703 AVG Training Acc 65.70 % AVG Validation Acc 59.51 %\n",
      "Epoch:190/200 AVG Training Loss:0.593 AVG Validation Loss:0.700 AVG Training Acc 66.36 % AVG Validation Acc 59.60 %\n",
      "Epoch:200/200 AVG Training Loss:0.593 AVG Validation Loss:0.699 AVG Training Acc 66.13 % AVG Validation Acc 59.69 %\n",
      "Split 183\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a191846434e430a84fd6af6652ed2da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.662 AVG Training Acc 61.91 % AVG Validation Acc 61.77 %\n",
      "Epoch:20/200 AVG Training Loss:0.649 AVG Validation Loss:0.661 AVG Training Acc 61.71 % AVG Validation Acc 62.76 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.648 AVG Validation Loss:0.655 AVG Training Acc 62.25 % AVG Validation Acc 61.68 %\n",
      "Epoch:40/200 AVG Training Loss:0.637 AVG Validation Loss:0.662 AVG Training Acc 63.38 % AVG Validation Acc 61.32 %\n",
      "Epoch:50/200 AVG Training Loss:0.629 AVG Validation Loss:0.669 AVG Training Acc 63.99 % AVG Validation Acc 60.87 %\n",
      "Epoch:60/200 AVG Training Loss:0.621 AVG Validation Loss:0.675 AVG Training Acc 64.25 % AVG Validation Acc 61.14 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.617 AVG Validation Loss:0.679 AVG Training Acc 64.84 % AVG Validation Acc 61.59 %\n",
      "Epoch:80/200 AVG Training Loss:0.616 AVG Validation Loss:0.682 AVG Training Acc 64.68 % AVG Validation Acc 60.32 %\n",
      "Epoch:90/200 AVG Training Loss:0.615 AVG Validation Loss:0.677 AVG Training Acc 64.75 % AVG Validation Acc 60.96 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.613 AVG Validation Loss:0.679 AVG Training Acc 64.64 % AVG Validation Acc 60.50 %\n",
      "Epoch:110/200 AVG Training Loss:0.615 AVG Validation Loss:0.680 AVG Training Acc 64.61 % AVG Validation Acc 60.87 %\n",
      "Epoch:120/200 AVG Training Loss:0.614 AVG Validation Loss:0.682 AVG Training Acc 65.22 % AVG Validation Acc 60.32 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.614 AVG Validation Loss:0.680 AVG Training Acc 65.04 % AVG Validation Acc 60.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.613 AVG Validation Loss:0.682 AVG Training Acc 65.49 % AVG Validation Acc 60.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.614 AVG Validation Loss:0.682 AVG Training Acc 64.98 % AVG Validation Acc 60.05 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.615 AVG Validation Loss:0.683 AVG Training Acc 64.90 % AVG Validation Acc 60.69 %\n",
      "Epoch:170/200 AVG Training Loss:0.614 AVG Validation Loss:0.678 AVG Training Acc 64.90 % AVG Validation Acc 60.78 %\n",
      "Epoch:180/200 AVG Training Loss:0.615 AVG Validation Loss:0.682 AVG Training Acc 65.18 % AVG Validation Acc 60.60 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.614 AVG Validation Loss:0.680 AVG Training Acc 64.85 % AVG Validation Acc 60.87 %\n",
      "Epoch:200/200 AVG Training Loss:0.614 AVG Validation Loss:0.679 AVG Training Acc 64.87 % AVG Validation Acc 60.60 %\n",
      "Split 184\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00d2fe5d959448c08c75acf28462d9f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.658 AVG Training Acc 61.88 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.658 AVG Training Acc 61.83 % AVG Validation Acc 62.04 %\n",
      "Epoch:30/200 AVG Training Loss:0.644 AVG Validation Loss:0.663 AVG Training Acc 62.67 % AVG Validation Acc 61.86 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.626 AVG Validation Loss:0.658 AVG Training Acc 63.31 % AVG Validation Acc 61.50 %\n",
      "Epoch:50/200 AVG Training Loss:0.618 AVG Validation Loss:0.656 AVG Training Acc 64.11 % AVG Validation Acc 62.04 %\n",
      "Epoch:60/200 AVG Training Loss:0.610 AVG Validation Loss:0.662 AVG Training Acc 64.65 % AVG Validation Acc 62.22 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.603 AVG Validation Loss:0.662 AVG Training Acc 65.38 % AVG Validation Acc 62.13 %\n",
      "Epoch:80/200 AVG Training Loss:0.602 AVG Validation Loss:0.667 AVG Training Acc 65.70 % AVG Validation Acc 61.59 %\n",
      "Epoch:90/200 AVG Training Loss:0.600 AVG Validation Loss:0.665 AVG Training Acc 65.64 % AVG Validation Acc 61.50 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.600 AVG Validation Loss:0.665 AVG Training Acc 65.39 % AVG Validation Acc 61.50 %\n",
      "Epoch:110/200 AVG Training Loss:0.601 AVG Validation Loss:0.667 AVG Training Acc 65.66 % AVG Validation Acc 61.23 %\n",
      "Epoch:120/200 AVG Training Loss:0.598 AVG Validation Loss:0.670 AVG Training Acc 65.86 % AVG Validation Acc 61.77 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.599 AVG Validation Loss:0.668 AVG Training Acc 65.52 % AVG Validation Acc 61.32 %\n",
      "Epoch:140/200 AVG Training Loss:0.599 AVG Validation Loss:0.667 AVG Training Acc 65.92 % AVG Validation Acc 61.41 %\n",
      "Epoch:150/200 AVG Training Loss:0.601 AVG Validation Loss:0.666 AVG Training Acc 65.56 % AVG Validation Acc 61.32 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.600 AVG Validation Loss:0.665 AVG Training Acc 65.62 % AVG Validation Acc 61.77 %\n",
      "Epoch:170/200 AVG Training Loss:0.599 AVG Validation Loss:0.665 AVG Training Acc 65.53 % AVG Validation Acc 61.41 %\n",
      "Epoch:180/200 AVG Training Loss:0.598 AVG Validation Loss:0.664 AVG Training Acc 65.99 % AVG Validation Acc 60.96 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.600 AVG Validation Loss:0.668 AVG Training Acc 65.33 % AVG Validation Acc 60.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.601 AVG Validation Loss:0.663 AVG Training Acc 65.66 % AVG Validation Acc 61.50 %\n",
      "Split 185\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a1b9dcd17564e48878fb16000833ed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.655 AVG Training Acc 61.83 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.657 AVG Training Acc 62.02 % AVG Validation Acc 62.76 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.637 AVG Validation Loss:0.654 AVG Training Acc 62.54 % AVG Validation Acc 62.85 %\n",
      "Epoch:40/200 AVG Training Loss:0.625 AVG Validation Loss:0.658 AVG Training Acc 64.20 % AVG Validation Acc 62.40 %\n",
      "Epoch:50/200 AVG Training Loss:0.618 AVG Validation Loss:0.665 AVG Training Acc 64.37 % AVG Validation Acc 62.49 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.612 AVG Validation Loss:0.667 AVG Training Acc 64.98 % AVG Validation Acc 62.49 %\n",
      "Epoch:70/200 AVG Training Loss:0.610 AVG Validation Loss:0.673 AVG Training Acc 64.70 % AVG Validation Acc 61.95 %\n",
      "Epoch:80/200 AVG Training Loss:0.610 AVG Validation Loss:0.671 AVG Training Acc 64.67 % AVG Validation Acc 62.40 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.607 AVG Validation Loss:0.669 AVG Training Acc 65.06 % AVG Validation Acc 62.85 %\n",
      "Epoch:100/200 AVG Training Loss:0.608 AVG Validation Loss:0.671 AVG Training Acc 65.20 % AVG Validation Acc 62.76 %\n",
      "Epoch:110/200 AVG Training Loss:0.609 AVG Validation Loss:0.669 AVG Training Acc 64.87 % AVG Validation Acc 62.76 %\n",
      "Epoch:120/200 AVG Training Loss:0.607 AVG Validation Loss:0.672 AVG Training Acc 65.12 % AVG Validation Acc 62.58 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.608 AVG Validation Loss:0.672 AVG Training Acc 65.38 % AVG Validation Acc 62.76 %\n",
      "Epoch:140/200 AVG Training Loss:0.606 AVG Validation Loss:0.673 AVG Training Acc 65.39 % AVG Validation Acc 63.03 %\n",
      "Epoch:150/200 AVG Training Loss:0.608 AVG Validation Loss:0.668 AVG Training Acc 64.89 % AVG Validation Acc 62.85 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.609 AVG Validation Loss:0.671 AVG Training Acc 64.96 % AVG Validation Acc 63.21 %\n",
      "Epoch:170/200 AVG Training Loss:0.606 AVG Validation Loss:0.668 AVG Training Acc 64.85 % AVG Validation Acc 62.76 %\n",
      "Epoch:180/200 AVG Training Loss:0.607 AVG Validation Loss:0.671 AVG Training Acc 64.80 % AVG Validation Acc 62.94 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.609 AVG Validation Loss:0.669 AVG Training Acc 64.69 % AVG Validation Acc 62.67 %\n",
      "Epoch:200/200 AVG Training Loss:0.608 AVG Validation Loss:0.673 AVG Training Acc 64.80 % AVG Validation Acc 62.13 %\n",
      "Split 186\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68de42ee5b3742c794b46c4a3121ebc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.656 AVG Training Acc 61.74 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.649 AVG Validation Loss:0.653 AVG Training Acc 61.77 % AVG Validation Acc 62.18 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.630 AVG Validation Loss:0.668 AVG Training Acc 63.72 % AVG Validation Acc 61.82 %\n",
      "Epoch:40/200 AVG Training Loss:0.616 AVG Validation Loss:0.678 AVG Training Acc 64.28 % AVG Validation Acc 62.55 %\n",
      "Epoch:50/200 AVG Training Loss:0.604 AVG Validation Loss:0.699 AVG Training Acc 65.21 % AVG Validation Acc 62.09 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.593 AVG Validation Loss:0.708 AVG Training Acc 66.19 % AVG Validation Acc 61.82 %\n",
      "Epoch:70/200 AVG Training Loss:0.592 AVG Validation Loss:0.714 AVG Training Acc 66.57 % AVG Validation Acc 61.01 %\n",
      "Epoch:80/200 AVG Training Loss:0.589 AVG Validation Loss:0.713 AVG Training Acc 66.67 % AVG Validation Acc 61.19 %\n",
      "Epoch:90/200 AVG Training Loss:0.588 AVG Validation Loss:0.718 AVG Training Acc 66.13 % AVG Validation Acc 61.01 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.590 AVG Validation Loss:0.716 AVG Training Acc 66.30 % AVG Validation Acc 60.92 %\n",
      "Epoch:110/200 AVG Training Loss:0.586 AVG Validation Loss:0.719 AVG Training Acc 66.61 % AVG Validation Acc 60.92 %\n",
      "Epoch:120/200 AVG Training Loss:0.588 AVG Validation Loss:0.714 AVG Training Acc 66.59 % AVG Validation Acc 61.10 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.588 AVG Validation Loss:0.718 AVG Training Acc 66.31 % AVG Validation Acc 60.65 %\n",
      "Epoch:140/200 AVG Training Loss:0.589 AVG Validation Loss:0.718 AVG Training Acc 66.28 % AVG Validation Acc 60.47 %\n",
      "Epoch:150/200 AVG Training Loss:0.588 AVG Validation Loss:0.717 AVG Training Acc 66.40 % AVG Validation Acc 60.56 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.586 AVG Validation Loss:0.718 AVG Training Acc 66.92 % AVG Validation Acc 60.65 %\n",
      "Epoch:170/200 AVG Training Loss:0.587 AVG Validation Loss:0.716 AVG Training Acc 66.45 % AVG Validation Acc 61.10 %\n",
      "Epoch:180/200 AVG Training Loss:0.589 AVG Validation Loss:0.718 AVG Training Acc 66.75 % AVG Validation Acc 60.92 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.589 AVG Validation Loss:0.718 AVG Training Acc 66.45 % AVG Validation Acc 60.65 %\n",
      "Epoch:200/200 AVG Training Loss:0.587 AVG Validation Loss:0.720 AVG Training Acc 66.55 % AVG Validation Acc 60.38 %\n",
      "Split 187\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "573bfa87a1954d05b8b3f9df4d913662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 61.71 % AVG Validation Acc 62.00 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.659 AVG Training Acc 61.86 % AVG Validation Acc 62.27 %\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.660 AVG Training Acc 62.32 % AVG Validation Acc 61.82 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.632 AVG Validation Loss:0.658 AVG Training Acc 63.25 % AVG Validation Acc 61.73 %\n",
      "Epoch:50/200 AVG Training Loss:0.621 AVG Validation Loss:0.668 AVG Training Acc 63.94 % AVG Validation Acc 61.73 %\n",
      "Epoch:60/200 AVG Training Loss:0.611 AVG Validation Loss:0.674 AVG Training Acc 64.11 % AVG Validation Acc 61.55 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.602 AVG Validation Loss:0.684 AVG Training Acc 65.13 % AVG Validation Acc 61.01 %\n",
      "Epoch:80/200 AVG Training Loss:0.603 AVG Validation Loss:0.683 AVG Training Acc 64.86 % AVG Validation Acc 60.65 %\n",
      "Epoch:90/200 AVG Training Loss:0.601 AVG Validation Loss:0.680 AVG Training Acc 65.05 % AVG Validation Acc 60.56 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.599 AVG Validation Loss:0.686 AVG Training Acc 65.18 % AVG Validation Acc 60.02 %\n",
      "Epoch:110/200 AVG Training Loss:0.599 AVG Validation Loss:0.686 AVG Training Acc 65.06 % AVG Validation Acc 60.29 %\n",
      "Epoch:120/200 AVG Training Loss:0.600 AVG Validation Loss:0.687 AVG Training Acc 65.04 % AVG Validation Acc 60.02 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.598 AVG Validation Loss:0.684 AVG Training Acc 64.97 % AVG Validation Acc 60.47 %\n",
      "Epoch:140/200 AVG Training Loss:0.598 AVG Validation Loss:0.685 AVG Training Acc 65.28 % AVG Validation Acc 59.84 %\n",
      "Epoch:150/200 AVG Training Loss:0.599 AVG Validation Loss:0.686 AVG Training Acc 64.93 % AVG Validation Acc 59.84 %\n",
      "Epoch:160/200 AVG Training Loss:0.599 AVG Validation Loss:0.684 AVG Training Acc 65.10 % AVG Validation Acc 60.38 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.599 AVG Validation Loss:0.683 AVG Training Acc 65.14 % AVG Validation Acc 60.29 %\n",
      "Epoch:180/200 AVG Training Loss:0.600 AVG Validation Loss:0.683 AVG Training Acc 65.15 % AVG Validation Acc 60.38 %\n",
      "Epoch:190/200 AVG Training Loss:0.599 AVG Validation Loss:0.688 AVG Training Acc 65.21 % AVG Validation Acc 60.38 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.598 AVG Validation Loss:0.688 AVG Training Acc 65.09 % AVG Validation Acc 60.02 %\n",
      "Split 188\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b13dead4762412bb72f0664dad616b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.660 AVG Training Acc 61.83 % AVG Validation Acc 62.00 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.661 AVG Training Acc 62.03 % AVG Validation Acc 62.00 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.640 AVG Validation Loss:0.665 AVG Training Acc 62.59 % AVG Validation Acc 59.93 %\n",
      "Epoch:40/200 AVG Training Loss:0.631 AVG Validation Loss:0.668 AVG Training Acc 63.05 % AVG Validation Acc 59.84 %\n",
      "Epoch:50/200 AVG Training Loss:0.625 AVG Validation Loss:0.673 AVG Training Acc 63.31 % AVG Validation Acc 58.75 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.619 AVG Validation Loss:0.677 AVG Training Acc 64.04 % AVG Validation Acc 59.84 %\n",
      "Epoch:70/200 AVG Training Loss:0.616 AVG Validation Loss:0.682 AVG Training Acc 64.03 % AVG Validation Acc 59.57 %\n",
      "Epoch:80/200 AVG Training Loss:0.616 AVG Validation Loss:0.684 AVG Training Acc 64.12 % AVG Validation Acc 59.48 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.615 AVG Validation Loss:0.685 AVG Training Acc 63.85 % AVG Validation Acc 58.75 %\n",
      "Epoch:100/200 AVG Training Loss:0.613 AVG Validation Loss:0.686 AVG Training Acc 64.04 % AVG Validation Acc 59.03 %\n",
      "Epoch:110/200 AVG Training Loss:0.614 AVG Validation Loss:0.685 AVG Training Acc 64.85 % AVG Validation Acc 58.48 %\n",
      "Epoch:120/200 AVG Training Loss:0.615 AVG Validation Loss:0.686 AVG Training Acc 64.14 % AVG Validation Acc 58.84 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.615 AVG Validation Loss:0.682 AVG Training Acc 64.38 % AVG Validation Acc 58.75 %\n",
      "Epoch:140/200 AVG Training Loss:0.614 AVG Validation Loss:0.682 AVG Training Acc 64.18 % AVG Validation Acc 59.12 %\n",
      "Epoch:150/200 AVG Training Loss:0.613 AVG Validation Loss:0.686 AVG Training Acc 64.46 % AVG Validation Acc 58.57 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.612 AVG Validation Loss:0.685 AVG Training Acc 64.81 % AVG Validation Acc 58.84 %\n",
      "Epoch:170/200 AVG Training Loss:0.614 AVG Validation Loss:0.686 AVG Training Acc 64.48 % AVG Validation Acc 59.30 %\n",
      "Epoch:180/200 AVG Training Loss:0.614 AVG Validation Loss:0.685 AVG Training Acc 64.74 % AVG Validation Acc 58.39 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.613 AVG Validation Loss:0.686 AVG Training Acc 64.19 % AVG Validation Acc 58.94 %\n",
      "Epoch:200/200 AVG Training Loss:0.614 AVG Validation Loss:0.684 AVG Training Acc 64.54 % AVG Validation Acc 59.12 %\n",
      "Split 189\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9577c662e41b4b5e931d3b72d2b54ca8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.656 AVG Training Acc 61.85 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.661 AVG Training Acc 61.84 % AVG Validation Acc 61.82 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.646 AVG Validation Loss:0.652 AVG Training Acc 61.81 % AVG Validation Acc 61.73 %\n",
      "Epoch:40/200 AVG Training Loss:0.642 AVG Validation Loss:0.653 AVG Training Acc 62.30 % AVG Validation Acc 62.45 %\n",
      "Epoch:50/200 AVG Training Loss:0.633 AVG Validation Loss:0.656 AVG Training Acc 62.56 % AVG Validation Acc 62.64 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.629 AVG Validation Loss:0.659 AVG Training Acc 63.21 % AVG Validation Acc 61.91 %\n",
      "Epoch:70/200 AVG Training Loss:0.628 AVG Validation Loss:0.660 AVG Training Acc 63.48 % AVG Validation Acc 61.64 %\n",
      "Epoch:80/200 AVG Training Loss:0.626 AVG Validation Loss:0.659 AVG Training Acc 63.37 % AVG Validation Acc 61.55 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.626 AVG Validation Loss:0.659 AVG Training Acc 62.93 % AVG Validation Acc 61.64 %\n",
      "Epoch:100/200 AVG Training Loss:0.625 AVG Validation Loss:0.660 AVG Training Acc 63.56 % AVG Validation Acc 61.46 %\n",
      "Epoch:110/200 AVG Training Loss:0.624 AVG Validation Loss:0.661 AVG Training Acc 63.11 % AVG Validation Acc 61.10 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.624 AVG Validation Loss:0.662 AVG Training Acc 63.34 % AVG Validation Acc 61.64 %\n",
      "Epoch:130/200 AVG Training Loss:0.624 AVG Validation Loss:0.661 AVG Training Acc 63.68 % AVG Validation Acc 60.92 %\n",
      "Epoch:140/200 AVG Training Loss:0.625 AVG Validation Loss:0.661 AVG Training Acc 62.94 % AVG Validation Acc 61.55 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.623 AVG Validation Loss:0.661 AVG Training Acc 63.53 % AVG Validation Acc 61.28 %\n",
      "Epoch:160/200 AVG Training Loss:0.623 AVG Validation Loss:0.660 AVG Training Acc 63.60 % AVG Validation Acc 61.46 %\n",
      "Epoch:170/200 AVG Training Loss:0.623 AVG Validation Loss:0.661 AVG Training Acc 63.56 % AVG Validation Acc 61.19 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.624 AVG Validation Loss:0.661 AVG Training Acc 63.09 % AVG Validation Acc 61.28 %\n",
      "Epoch:190/200 AVG Training Loss:0.627 AVG Validation Loss:0.661 AVG Training Acc 63.18 % AVG Validation Acc 61.19 %\n",
      "Epoch:200/200 AVG Training Loss:0.624 AVG Validation Loss:0.662 AVG Training Acc 63.46 % AVG Validation Acc 61.01 %\n",
      "Split 190\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e561a8822aea4e45ac5691b3c6b3cbd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.660 AVG Training Acc 61.95 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.655 AVG Training Acc 62.00 % AVG Validation Acc 61.73 %\n",
      "Epoch:30/200 AVG Training Loss:0.647 AVG Validation Loss:0.668 AVG Training Acc 62.10 % AVG Validation Acc 61.64 %\n",
      "Epoch:40/200 AVG Training Loss:0.635 AVG Validation Loss:0.653 AVG Training Acc 63.56 % AVG Validation Acc 60.83 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.604 AVG Validation Loss:0.677 AVG Training Acc 65.80 % AVG Validation Acc 61.19 %\n",
      "Epoch:60/200 AVG Training Loss:0.587 AVG Validation Loss:0.690 AVG Training Acc 67.12 % AVG Validation Acc 61.46 %\n",
      "Epoch:70/200 AVG Training Loss:0.580 AVG Validation Loss:0.699 AVG Training Acc 67.70 % AVG Validation Acc 60.47 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.566 AVG Validation Loss:0.706 AVG Training Acc 68.78 % AVG Validation Acc 61.19 %\n",
      "Epoch:90/200 AVG Training Loss:0.562 AVG Validation Loss:0.708 AVG Training Acc 69.01 % AVG Validation Acc 60.56 %\n",
      "Epoch:100/200 AVG Training Loss:0.564 AVG Validation Loss:0.716 AVG Training Acc 69.25 % AVG Validation Acc 59.93 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.561 AVG Validation Loss:0.712 AVG Training Acc 68.99 % AVG Validation Acc 59.57 %\n",
      "Epoch:120/200 AVG Training Loss:0.560 AVG Validation Loss:0.718 AVG Training Acc 68.98 % AVG Validation Acc 59.75 %\n",
      "Epoch:130/200 AVG Training Loss:0.559 AVG Validation Loss:0.714 AVG Training Acc 68.87 % AVG Validation Acc 60.02 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.562 AVG Validation Loss:0.714 AVG Training Acc 68.92 % AVG Validation Acc 60.11 %\n",
      "Epoch:150/200 AVG Training Loss:0.560 AVG Validation Loss:0.719 AVG Training Acc 68.86 % AVG Validation Acc 59.30 %\n",
      "Epoch:160/200 AVG Training Loss:0.557 AVG Validation Loss:0.711 AVG Training Acc 69.51 % AVG Validation Acc 60.38 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.562 AVG Validation Loss:0.718 AVG Training Acc 68.88 % AVG Validation Acc 60.29 %\n",
      "Epoch:180/200 AVG Training Loss:0.559 AVG Validation Loss:0.712 AVG Training Acc 69.58 % AVG Validation Acc 59.48 %\n",
      "Epoch:190/200 AVG Training Loss:0.558 AVG Validation Loss:0.715 AVG Training Acc 69.40 % AVG Validation Acc 60.20 %\n",
      "Epoch:200/200 AVG Training Loss:0.564 AVG Validation Loss:0.711 AVG Training Acc 68.84 % AVG Validation Acc 60.38 %\n",
      "Epoch   200: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Split 191\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35a01596a1ae49789eefcf715905b156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.657 AVG Validation Loss:0.666 AVG Training Acc 61.80 % AVG Validation Acc 61.95 %\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.667 AVG Training Acc 61.95 % AVG Validation Acc 60.78 %\n",
      "Epoch:30/200 AVG Training Loss:0.646 AVG Validation Loss:0.668 AVG Training Acc 62.04 % AVG Validation Acc 60.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.640 AVG Validation Loss:0.672 AVG Training Acc 62.82 % AVG Validation Acc 60.32 %\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.636 AVG Validation Loss:0.674 AVG Training Acc 63.00 % AVG Validation Acc 60.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.634 AVG Validation Loss:0.676 AVG Training Acc 63.04 % AVG Validation Acc 59.96 %\n",
      "Epoch:70/200 AVG Training Loss:0.634 AVG Validation Loss:0.676 AVG Training Acc 63.37 % AVG Validation Acc 59.42 %\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.633 AVG Validation Loss:0.678 AVG Training Acc 63.43 % AVG Validation Acc 59.87 %\n",
      "Epoch:90/200 AVG Training Loss:0.633 AVG Validation Loss:0.677 AVG Training Acc 63.58 % AVG Validation Acc 59.87 %\n",
      "Epoch:100/200 AVG Training Loss:0.632 AVG Validation Loss:0.678 AVG Training Acc 63.90 % AVG Validation Acc 59.96 %\n",
      "Epoch   106: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.632 AVG Validation Loss:0.678 AVG Training Acc 64.20 % AVG Validation Acc 59.87 %\n",
      "Epoch:120/200 AVG Training Loss:0.630 AVG Validation Loss:0.678 AVG Training Acc 63.46 % AVG Validation Acc 60.05 %\n",
      "Epoch:130/200 AVG Training Loss:0.631 AVG Validation Loss:0.677 AVG Training Acc 63.78 % AVG Validation Acc 60.05 %\n",
      "Epoch   137: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.632 AVG Validation Loss:0.678 AVG Training Acc 63.47 % AVG Validation Acc 59.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.632 AVG Validation Loss:0.678 AVG Training Acc 63.48 % AVG Validation Acc 59.60 %\n",
      "Epoch:160/200 AVG Training Loss:0.631 AVG Validation Loss:0.678 AVG Training Acc 63.96 % AVG Validation Acc 59.87 %\n",
      "Epoch   168: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.631 AVG Validation Loss:0.678 AVG Training Acc 63.83 % AVG Validation Acc 59.87 %\n",
      "Epoch:180/200 AVG Training Loss:0.631 AVG Validation Loss:0.677 AVG Training Acc 63.53 % AVG Validation Acc 59.87 %\n",
      "Epoch:190/200 AVG Training Loss:0.630 AVG Validation Loss:0.678 AVG Training Acc 63.91 % AVG Validation Acc 59.87 %\n",
      "Epoch:200/200 AVG Training Loss:0.631 AVG Validation Loss:0.678 AVG Training Acc 63.60 % AVG Validation Acc 59.69 %\n",
      "Split 192\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "924ba856df5947c6a78f3733ee649357",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.657 AVG Training Acc 61.94 % AVG Validation Acc 62.04 %\n",
      "Epoch:20/200 AVG Training Loss:0.649 AVG Validation Loss:0.650 AVG Training Acc 62.10 % AVG Validation Acc 61.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.640 AVG Validation Loss:0.652 AVG Training Acc 62.26 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.632 AVG Validation Loss:0.664 AVG Training Acc 62.80 % AVG Validation Acc 62.22 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.608 AVG Validation Loss:0.673 AVG Training Acc 64.53 % AVG Validation Acc 60.50 %\n",
      "Epoch:60/200 AVG Training Loss:0.598 AVG Validation Loss:0.689 AVG Training Acc 64.82 % AVG Validation Acc 59.87 %\n",
      "Epoch:70/200 AVG Training Loss:0.588 AVG Validation Loss:0.702 AVG Training Acc 65.29 % AVG Validation Acc 59.51 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.580 AVG Validation Loss:0.705 AVG Training Acc 65.90 % AVG Validation Acc 59.24 %\n",
      "Epoch:90/200 AVG Training Loss:0.576 AVG Validation Loss:0.710 AVG Training Acc 65.88 % AVG Validation Acc 58.88 %\n",
      "Epoch:100/200 AVG Training Loss:0.575 AVG Validation Loss:0.715 AVG Training Acc 66.87 % AVG Validation Acc 58.70 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.576 AVG Validation Loss:0.711 AVG Training Acc 66.69 % AVG Validation Acc 58.16 %\n",
      "Epoch:120/200 AVG Training Loss:0.576 AVG Validation Loss:0.718 AVG Training Acc 66.22 % AVG Validation Acc 59.24 %\n",
      "Epoch:130/200 AVG Training Loss:0.574 AVG Validation Loss:0.718 AVG Training Acc 66.97 % AVG Validation Acc 59.42 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.576 AVG Validation Loss:0.716 AVG Training Acc 66.17 % AVG Validation Acc 59.60 %\n",
      "Epoch:150/200 AVG Training Loss:0.575 AVG Validation Loss:0.712 AVG Training Acc 66.31 % AVG Validation Acc 58.88 %\n",
      "Epoch:160/200 AVG Training Loss:0.575 AVG Validation Loss:0.713 AVG Training Acc 66.56 % AVG Validation Acc 59.15 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.576 AVG Validation Loss:0.712 AVG Training Acc 66.28 % AVG Validation Acc 59.15 %\n",
      "Epoch:180/200 AVG Training Loss:0.574 AVG Validation Loss:0.716 AVG Training Acc 66.73 % AVG Validation Acc 58.61 %\n",
      "Epoch:190/200 AVG Training Loss:0.574 AVG Validation Loss:0.716 AVG Training Acc 66.43 % AVG Validation Acc 59.33 %\n",
      "Epoch   198: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.575 AVG Validation Loss:0.713 AVG Training Acc 66.43 % AVG Validation Acc 59.15 %\n",
      "Split 193\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2538a90f940147e7b9a0f453e7c4700e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 61.73 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.654 AVG Training Acc 62.19 % AVG Validation Acc 61.68 %\n",
      "Epoch:30/200 AVG Training Loss:0.650 AVG Validation Loss:0.660 AVG Training Acc 62.00 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.639 AVG Validation Loss:0.661 AVG Training Acc 63.03 % AVG Validation Acc 62.13 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.622 AVG Validation Loss:0.674 AVG Training Acc 63.70 % AVG Validation Acc 61.50 %\n",
      "Epoch:60/200 AVG Training Loss:0.602 AVG Validation Loss:0.690 AVG Training Acc 65.51 % AVG Validation Acc 61.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.590 AVG Validation Loss:0.706 AVG Training Acc 66.17 % AVG Validation Acc 59.60 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.583 AVG Validation Loss:0.721 AVG Training Acc 66.17 % AVG Validation Acc 59.78 %\n",
      "Epoch:90/200 AVG Training Loss:0.582 AVG Validation Loss:0.721 AVG Training Acc 66.79 % AVG Validation Acc 59.06 %\n",
      "Epoch:100/200 AVG Training Loss:0.581 AVG Validation Loss:0.724 AVG Training Acc 66.82 % AVG Validation Acc 59.33 %\n",
      "Epoch:110/200 AVG Training Loss:0.576 AVG Validation Loss:0.722 AVG Training Acc 66.86 % AVG Validation Acc 59.78 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.579 AVG Validation Loss:0.727 AVG Training Acc 66.83 % AVG Validation Acc 59.06 %\n",
      "Epoch:130/200 AVG Training Loss:0.578 AVG Validation Loss:0.721 AVG Training Acc 67.00 % AVG Validation Acc 59.51 %\n",
      "Epoch:140/200 AVG Training Loss:0.579 AVG Validation Loss:0.726 AVG Training Acc 67.08 % AVG Validation Acc 59.15 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.578 AVG Validation Loss:0.724 AVG Training Acc 67.35 % AVG Validation Acc 58.52 %\n",
      "Epoch:160/200 AVG Training Loss:0.579 AVG Validation Loss:0.726 AVG Training Acc 67.11 % AVG Validation Acc 59.06 %\n",
      "Epoch:170/200 AVG Training Loss:0.579 AVG Validation Loss:0.728 AVG Training Acc 66.90 % AVG Validation Acc 59.06 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.577 AVG Validation Loss:0.730 AVG Training Acc 67.24 % AVG Validation Acc 58.88 %\n",
      "Epoch:190/200 AVG Training Loss:0.579 AVG Validation Loss:0.730 AVG Training Acc 66.84 % AVG Validation Acc 59.42 %\n",
      "Epoch:200/200 AVG Training Loss:0.577 AVG Validation Loss:0.723 AVG Training Acc 67.36 % AVG Validation Acc 59.06 %\n",
      "Split 194\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ba66495c0147d9be0c43ea94a22cb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.654 AVG Training Acc 61.92 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.650 AVG Training Acc 61.90 % AVG Validation Acc 61.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.658 AVG Training Acc 62.17 % AVG Validation Acc 61.86 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.647 AVG Validation Loss:0.647 AVG Training Acc 62.69 % AVG Validation Acc 61.68 %\n",
      "Epoch:50/200 AVG Training Loss:0.641 AVG Validation Loss:0.647 AVG Training Acc 63.37 % AVG Validation Acc 62.58 %\n",
      "Epoch:60/200 AVG Training Loss:0.636 AVG Validation Loss:0.652 AVG Training Acc 63.74 % AVG Validation Acc 61.32 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.632 AVG Validation Loss:0.651 AVG Training Acc 63.94 % AVG Validation Acc 62.04 %\n",
      "Epoch:80/200 AVG Training Loss:0.630 AVG Validation Loss:0.651 AVG Training Acc 64.42 % AVG Validation Acc 62.49 %\n",
      "Epoch:90/200 AVG Training Loss:0.631 AVG Validation Loss:0.650 AVG Training Acc 63.98 % AVG Validation Acc 62.22 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.631 AVG Validation Loss:0.652 AVG Training Acc 64.20 % AVG Validation Acc 61.32 %\n",
      "Epoch:110/200 AVG Training Loss:0.628 AVG Validation Loss:0.651 AVG Training Acc 64.08 % AVG Validation Acc 61.86 %\n",
      "Epoch:120/200 AVG Training Loss:0.628 AVG Validation Loss:0.654 AVG Training Acc 64.52 % AVG Validation Acc 61.77 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.627 AVG Validation Loss:0.652 AVG Training Acc 64.75 % AVG Validation Acc 62.13 %\n",
      "Epoch:140/200 AVG Training Loss:0.629 AVG Validation Loss:0.654 AVG Training Acc 64.60 % AVG Validation Acc 61.68 %\n",
      "Epoch:150/200 AVG Training Loss:0.630 AVG Validation Loss:0.651 AVG Training Acc 64.75 % AVG Validation Acc 62.49 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.629 AVG Validation Loss:0.651 AVG Training Acc 64.65 % AVG Validation Acc 61.77 %\n",
      "Epoch:170/200 AVG Training Loss:0.630 AVG Validation Loss:0.651 AVG Training Acc 64.21 % AVG Validation Acc 62.22 %\n",
      "Epoch:180/200 AVG Training Loss:0.627 AVG Validation Loss:0.653 AVG Training Acc 64.63 % AVG Validation Acc 62.13 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.630 AVG Validation Loss:0.653 AVG Training Acc 64.39 % AVG Validation Acc 61.86 %\n",
      "Epoch:200/200 AVG Training Loss:0.628 AVG Validation Loss:0.651 AVG Training Acc 64.60 % AVG Validation Acc 61.50 %\n",
      "Split 195\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd3638fff69459aafd0be54413cf70e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.665 AVG Training Acc 62.00 % AVG Validation Acc 61.77 %\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.665 AVG Training Acc 62.12 % AVG Validation Acc 61.59 %\n",
      "Epoch:30/200 AVG Training Loss:0.649 AVG Validation Loss:0.664 AVG Training Acc 62.24 % AVG Validation Acc 61.77 %\n",
      "Epoch:40/200 AVG Training Loss:0.645 AVG Validation Loss:0.668 AVG Training Acc 62.22 % AVG Validation Acc 60.50 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.638 AVG Validation Loss:0.667 AVG Training Acc 62.95 % AVG Validation Acc 60.87 %\n",
      "Epoch:60/200 AVG Training Loss:0.638 AVG Validation Loss:0.666 AVG Training Acc 62.66 % AVG Validation Acc 60.96 %\n",
      "Epoch:70/200 AVG Training Loss:0.636 AVG Validation Loss:0.667 AVG Training Acc 63.05 % AVG Validation Acc 60.14 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.634 AVG Validation Loss:0.667 AVG Training Acc 63.10 % AVG Validation Acc 59.87 %\n",
      "Epoch:90/200 AVG Training Loss:0.635 AVG Validation Loss:0.671 AVG Training Acc 62.96 % AVG Validation Acc 59.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.635 AVG Validation Loss:0.669 AVG Training Acc 63.02 % AVG Validation Acc 60.05 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.635 AVG Validation Loss:0.670 AVG Training Acc 62.63 % AVG Validation Acc 60.50 %\n",
      "Epoch:120/200 AVG Training Loss:0.635 AVG Validation Loss:0.668 AVG Training Acc 62.64 % AVG Validation Acc 60.60 %\n",
      "Epoch:130/200 AVG Training Loss:0.637 AVG Validation Loss:0.669 AVG Training Acc 62.47 % AVG Validation Acc 60.78 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.635 AVG Validation Loss:0.670 AVG Training Acc 63.17 % AVG Validation Acc 60.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.636 AVG Validation Loss:0.669 AVG Training Acc 62.98 % AVG Validation Acc 60.50 %\n",
      "Epoch:160/200 AVG Training Loss:0.636 AVG Validation Loss:0.670 AVG Training Acc 62.94 % AVG Validation Acc 60.78 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.636 AVG Validation Loss:0.670 AVG Training Acc 62.69 % AVG Validation Acc 60.87 %\n",
      "Epoch:180/200 AVG Training Loss:0.636 AVG Validation Loss:0.669 AVG Training Acc 62.61 % AVG Validation Acc 60.41 %\n",
      "Epoch:190/200 AVG Training Loss:0.637 AVG Validation Loss:0.671 AVG Training Acc 62.84 % AVG Validation Acc 60.87 %\n",
      "Epoch:200/200 AVG Training Loss:0.636 AVG Validation Loss:0.671 AVG Training Acc 62.57 % AVG Validation Acc 61.23 %\n",
      "Split 196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d892ec60d1446b096417223c6688efe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.666 AVG Training Acc 61.78 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.648 AVG Validation Loss:0.665 AVG Training Acc 62.30 % AVG Validation Acc 62.73 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.633 AVG Validation Loss:0.671 AVG Training Acc 63.37 % AVG Validation Acc 61.10 %\n",
      "Epoch:40/200 AVG Training Loss:0.625 AVG Validation Loss:0.687 AVG Training Acc 63.10 % AVG Validation Acc 61.19 %\n",
      "Epoch:50/200 AVG Training Loss:0.619 AVG Validation Loss:0.688 AVG Training Acc 63.78 % AVG Validation Acc 61.10 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.612 AVG Validation Loss:0.700 AVG Training Acc 64.60 % AVG Validation Acc 60.74 %\n",
      "Epoch:70/200 AVG Training Loss:0.609 AVG Validation Loss:0.705 AVG Training Acc 64.27 % AVG Validation Acc 60.20 %\n",
      "Epoch:80/200 AVG Training Loss:0.606 AVG Validation Loss:0.704 AVG Training Acc 64.43 % AVG Validation Acc 60.11 %\n",
      "Epoch:90/200 AVG Training Loss:0.606 AVG Validation Loss:0.704 AVG Training Acc 64.79 % AVG Validation Acc 60.29 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.606 AVG Validation Loss:0.706 AVG Training Acc 64.90 % AVG Validation Acc 59.93 %\n",
      "Epoch:110/200 AVG Training Loss:0.604 AVG Validation Loss:0.705 AVG Training Acc 64.47 % AVG Validation Acc 59.75 %\n",
      "Epoch:120/200 AVG Training Loss:0.604 AVG Validation Loss:0.709 AVG Training Acc 64.75 % AVG Validation Acc 60.20 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.604 AVG Validation Loss:0.702 AVG Training Acc 64.69 % AVG Validation Acc 60.29 %\n",
      "Epoch:140/200 AVG Training Loss:0.605 AVG Validation Loss:0.709 AVG Training Acc 64.80 % AVG Validation Acc 60.02 %\n",
      "Epoch:150/200 AVG Training Loss:0.603 AVG Validation Loss:0.705 AVG Training Acc 64.47 % AVG Validation Acc 60.20 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.604 AVG Validation Loss:0.702 AVG Training Acc 64.83 % AVG Validation Acc 60.38 %\n",
      "Epoch:170/200 AVG Training Loss:0.605 AVG Validation Loss:0.704 AVG Training Acc 64.51 % AVG Validation Acc 60.20 %\n",
      "Epoch:180/200 AVG Training Loss:0.603 AVG Validation Loss:0.712 AVG Training Acc 64.89 % AVG Validation Acc 59.93 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.604 AVG Validation Loss:0.707 AVG Training Acc 64.63 % AVG Validation Acc 60.38 %\n",
      "Epoch:200/200 AVG Training Loss:0.605 AVG Validation Loss:0.705 AVG Training Acc 64.50 % AVG Validation Acc 59.57 %\n",
      "Split 197\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "762ebfb7c099477fae1de9ca8956bce5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.654 AVG Training Acc 61.81 % AVG Validation Acc 62.00 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.654 AVG Training Acc 61.78 % AVG Validation Acc 62.36 %\n",
      "Epoch:30/200 AVG Training Loss:0.644 AVG Validation Loss:0.656 AVG Training Acc 62.42 % AVG Validation Acc 61.10 %\n",
      "Epoch:40/200 AVG Training Loss:0.637 AVG Validation Loss:0.647 AVG Training Acc 63.18 % AVG Validation Acc 61.82 %\n",
      "Epoch:50/200 AVG Training Loss:0.659 AVG Validation Loss:0.659 AVG Training Acc 61.76 % AVG Validation Acc 61.91 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.650 AVG Validation Loss:0.658 AVG Training Acc 61.96 % AVG Validation Acc 62.00 %\n",
      "Epoch:70/200 AVG Training Loss:0.646 AVG Validation Loss:0.658 AVG Training Acc 62.19 % AVG Validation Acc 61.91 %\n",
      "Epoch:80/200 AVG Training Loss:0.641 AVG Validation Loss:0.661 AVG Training Acc 62.19 % AVG Validation Acc 62.00 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.635 AVG Validation Loss:0.660 AVG Training Acc 62.00 % AVG Validation Acc 61.64 %\n",
      "Epoch:100/200 AVG Training Loss:0.637 AVG Validation Loss:0.661 AVG Training Acc 62.41 % AVG Validation Acc 61.64 %\n",
      "Epoch:110/200 AVG Training Loss:0.635 AVG Validation Loss:0.664 AVG Training Acc 62.36 % AVG Validation Acc 61.46 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.635 AVG Validation Loss:0.665 AVG Training Acc 62.32 % AVG Validation Acc 61.37 %\n",
      "Epoch:130/200 AVG Training Loss:0.634 AVG Validation Loss:0.666 AVG Training Acc 62.74 % AVG Validation Acc 61.46 %\n",
      "Epoch:140/200 AVG Training Loss:0.635 AVG Validation Loss:0.664 AVG Training Acc 62.38 % AVG Validation Acc 61.46 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.635 AVG Validation Loss:0.665 AVG Training Acc 62.48 % AVG Validation Acc 61.91 %\n",
      "Epoch:160/200 AVG Training Loss:0.635 AVG Validation Loss:0.664 AVG Training Acc 62.65 % AVG Validation Acc 61.91 %\n",
      "Epoch:170/200 AVG Training Loss:0.635 AVG Validation Loss:0.663 AVG Training Acc 62.36 % AVG Validation Acc 61.82 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.635 AVG Validation Loss:0.662 AVG Training Acc 62.19 % AVG Validation Acc 62.09 %\n",
      "Epoch:190/200 AVG Training Loss:0.634 AVG Validation Loss:0.661 AVG Training Acc 62.76 % AVG Validation Acc 61.91 %\n",
      "Epoch:200/200 AVG Training Loss:0.634 AVG Validation Loss:0.662 AVG Training Acc 62.42 % AVG Validation Acc 60.83 %\n",
      "Split 198\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaf88445e361467e9309e906faec6299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.654 AVG Training Acc 61.78 % AVG Validation Acc 62.27 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.653 AVG Training Acc 61.93 % AVG Validation Acc 62.55 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.643 AVG Validation Loss:0.659 AVG Training Acc 62.59 % AVG Validation Acc 61.73 %\n",
      "Epoch:40/200 AVG Training Loss:0.632 AVG Validation Loss:0.666 AVG Training Acc 63.51 % AVG Validation Acc 60.11 %\n",
      "Epoch:50/200 AVG Training Loss:0.626 AVG Validation Loss:0.669 AVG Training Acc 64.31 % AVG Validation Acc 60.56 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.618 AVG Validation Loss:0.676 AVG Training Acc 64.39 % AVG Validation Acc 60.38 %\n",
      "Epoch:70/200 AVG Training Loss:0.617 AVG Validation Loss:0.676 AVG Training Acc 64.55 % AVG Validation Acc 59.93 %\n",
      "Epoch:80/200 AVG Training Loss:0.616 AVG Validation Loss:0.676 AVG Training Acc 65.09 % AVG Validation Acc 60.74 %\n",
      "Epoch:90/200 AVG Training Loss:0.612 AVG Validation Loss:0.675 AVG Training Acc 65.21 % AVG Validation Acc 60.56 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.614 AVG Validation Loss:0.679 AVG Training Acc 64.90 % AVG Validation Acc 60.47 %\n",
      "Epoch:110/200 AVG Training Loss:0.611 AVG Validation Loss:0.683 AVG Training Acc 65.26 % AVG Validation Acc 60.11 %\n",
      "Epoch:120/200 AVG Training Loss:0.614 AVG Validation Loss:0.677 AVG Training Acc 64.95 % AVG Validation Acc 60.65 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.613 AVG Validation Loss:0.681 AVG Training Acc 65.04 % AVG Validation Acc 60.65 %\n",
      "Epoch:140/200 AVG Training Loss:0.614 AVG Validation Loss:0.682 AVG Training Acc 65.04 % AVG Validation Acc 60.29 %\n",
      "Epoch:150/200 AVG Training Loss:0.615 AVG Validation Loss:0.678 AVG Training Acc 64.94 % AVG Validation Acc 61.10 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.612 AVG Validation Loss:0.678 AVG Training Acc 65.53 % AVG Validation Acc 60.65 %\n",
      "Epoch:170/200 AVG Training Loss:0.612 AVG Validation Loss:0.678 AVG Training Acc 65.47 % AVG Validation Acc 60.56 %\n",
      "Epoch:180/200 AVG Training Loss:0.614 AVG Validation Loss:0.680 AVG Training Acc 65.26 % AVG Validation Acc 60.47 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.613 AVG Validation Loss:0.681 AVG Training Acc 65.16 % AVG Validation Acc 59.93 %\n",
      "Epoch:200/200 AVG Training Loss:0.613 AVG Validation Loss:0.676 AVG Training Acc 65.23 % AVG Validation Acc 60.38 %\n",
      "Split 199\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd5d64272744452827fda5144995947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.656 AVG Training Acc 61.79 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.653 AVG Training Acc 62.21 % AVG Validation Acc 61.82 %\n",
      "Epoch:30/200 AVG Training Loss:0.647 AVG Validation Loss:0.652 AVG Training Acc 62.19 % AVG Validation Acc 62.18 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.628 AVG Validation Loss:0.657 AVG Training Acc 63.34 % AVG Validation Acc 61.55 %\n",
      "Epoch:50/200 AVG Training Loss:0.619 AVG Validation Loss:0.667 AVG Training Acc 63.88 % AVG Validation Acc 61.37 %\n",
      "Epoch:60/200 AVG Training Loss:0.610 AVG Validation Loss:0.680 AVG Training Acc 64.41 % AVG Validation Acc 60.20 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.603 AVG Validation Loss:0.682 AVG Training Acc 64.55 % AVG Validation Acc 60.20 %\n",
      "Epoch:80/200 AVG Training Loss:0.603 AVG Validation Loss:0.685 AVG Training Acc 64.49 % AVG Validation Acc 60.29 %\n",
      "Epoch:90/200 AVG Training Loss:0.602 AVG Validation Loss:0.682 AVG Training Acc 65.10 % AVG Validation Acc 60.02 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.600 AVG Validation Loss:0.688 AVG Training Acc 65.48 % AVG Validation Acc 59.39 %\n",
      "Epoch:110/200 AVG Training Loss:0.600 AVG Validation Loss:0.684 AVG Training Acc 65.07 % AVG Validation Acc 60.29 %\n",
      "Epoch:120/200 AVG Training Loss:0.600 AVG Validation Loss:0.685 AVG Training Acc 65.31 % AVG Validation Acc 60.56 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.601 AVG Validation Loss:0.689 AVG Training Acc 65.08 % AVG Validation Acc 59.75 %\n",
      "Epoch:140/200 AVG Training Loss:0.601 AVG Validation Loss:0.690 AVG Training Acc 64.98 % AVG Validation Acc 60.02 %\n",
      "Epoch:150/200 AVG Training Loss:0.601 AVG Validation Loss:0.681 AVG Training Acc 65.15 % AVG Validation Acc 60.56 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.601 AVG Validation Loss:0.681 AVG Training Acc 65.22 % AVG Validation Acc 59.84 %\n",
      "Epoch:170/200 AVG Training Loss:0.599 AVG Validation Loss:0.683 AVG Training Acc 64.68 % AVG Validation Acc 59.93 %\n",
      "Epoch:180/200 AVG Training Loss:0.601 AVG Validation Loss:0.681 AVG Training Acc 65.12 % AVG Validation Acc 60.29 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.600 AVG Validation Loss:0.688 AVG Training Acc 64.70 % AVG Validation Acc 59.75 %\n",
      "Epoch:200/200 AVG Training Loss:0.599 AVG Validation Loss:0.689 AVG Training Acc 64.99 % AVG Validation Acc 60.20 %\n",
      "Split 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f32245bdaf0944a781c1be287d6d1143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.658 AVG Training Acc 61.84 % AVG Validation Acc 61.82 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.661 AVG Training Acc 62.12 % AVG Validation Acc 61.37 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.631 AVG Validation Loss:0.658 AVG Training Acc 63.54 % AVG Validation Acc 61.73 %\n",
      "Epoch:40/200 AVG Training Loss:0.621 AVG Validation Loss:0.668 AVG Training Acc 64.21 % AVG Validation Acc 62.00 %\n",
      "Epoch:50/200 AVG Training Loss:0.613 AVG Validation Loss:0.678 AVG Training Acc 64.89 % AVG Validation Acc 62.18 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.602 AVG Validation Loss:0.688 AVG Training Acc 65.53 % AVG Validation Acc 60.92 %\n",
      "Epoch:70/200 AVG Training Loss:0.602 AVG Validation Loss:0.691 AVG Training Acc 65.51 % AVG Validation Acc 61.28 %\n",
      "Epoch:80/200 AVG Training Loss:0.600 AVG Validation Loss:0.696 AVG Training Acc 65.91 % AVG Validation Acc 61.01 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.599 AVG Validation Loss:0.700 AVG Training Acc 65.30 % AVG Validation Acc 60.65 %\n",
      "Epoch:100/200 AVG Training Loss:0.599 AVG Validation Loss:0.701 AVG Training Acc 65.65 % AVG Validation Acc 60.92 %\n",
      "Epoch:110/200 AVG Training Loss:0.600 AVG Validation Loss:0.703 AVG Training Acc 65.67 % AVG Validation Acc 60.83 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.600 AVG Validation Loss:0.699 AVG Training Acc 65.53 % AVG Validation Acc 60.92 %\n",
      "Epoch:130/200 AVG Training Loss:0.600 AVG Validation Loss:0.706 AVG Training Acc 65.91 % AVG Validation Acc 60.65 %\n",
      "Epoch:140/200 AVG Training Loss:0.600 AVG Validation Loss:0.701 AVG Training Acc 65.42 % AVG Validation Acc 60.74 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.599 AVG Validation Loss:0.700 AVG Training Acc 65.06 % AVG Validation Acc 60.29 %\n",
      "Epoch:160/200 AVG Training Loss:0.598 AVG Validation Loss:0.703 AVG Training Acc 65.31 % AVG Validation Acc 61.37 %\n",
      "Epoch:170/200 AVG Training Loss:0.600 AVG Validation Loss:0.700 AVG Training Acc 65.76 % AVG Validation Acc 60.92 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.600 AVG Validation Loss:0.701 AVG Training Acc 65.91 % AVG Validation Acc 60.65 %\n",
      "Epoch:190/200 AVG Training Loss:0.598 AVG Validation Loss:0.702 AVG Training Acc 65.46 % AVG Validation Acc 60.92 %\n",
      "Epoch:200/200 AVG Training Loss:0.600 AVG Validation Loss:0.700 AVG Training Acc 65.86 % AVG Validation Acc 60.47 %\n",
      "Split 201\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6214714ea2ac47589c168895a1ffee73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.656 AVG Training Acc 61.74 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.648 AVG Validation Loss:0.651 AVG Training Acc 61.82 % AVG Validation Acc 62.94 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.628 AVG Validation Loss:0.662 AVG Training Acc 63.01 % AVG Validation Acc 62.58 %\n",
      "Epoch:40/200 AVG Training Loss:0.612 AVG Validation Loss:0.681 AVG Training Acc 64.75 % AVG Validation Acc 62.67 %\n",
      "Epoch:50/200 AVG Training Loss:0.594 AVG Validation Loss:0.705 AVG Training Acc 65.28 % AVG Validation Acc 61.95 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.582 AVG Validation Loss:0.722 AVG Training Acc 65.80 % AVG Validation Acc 60.60 %\n",
      "Epoch:70/200 AVG Training Loss:0.582 AVG Validation Loss:0.717 AVG Training Acc 66.32 % AVG Validation Acc 61.50 %\n",
      "Epoch:80/200 AVG Training Loss:0.582 AVG Validation Loss:0.724 AVG Training Acc 65.69 % AVG Validation Acc 60.78 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.574 AVG Validation Loss:0.723 AVG Training Acc 66.43 % AVG Validation Acc 60.69 %\n",
      "Epoch:100/200 AVG Training Loss:0.575 AVG Validation Loss:0.723 AVG Training Acc 66.45 % AVG Validation Acc 60.96 %\n",
      "Epoch:110/200 AVG Training Loss:0.577 AVG Validation Loss:0.727 AVG Training Acc 66.39 % AVG Validation Acc 61.05 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.576 AVG Validation Loss:0.727 AVG Training Acc 66.70 % AVG Validation Acc 60.96 %\n",
      "Epoch:130/200 AVG Training Loss:0.577 AVG Validation Loss:0.726 AVG Training Acc 66.17 % AVG Validation Acc 61.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.576 AVG Validation Loss:0.727 AVG Training Acc 66.67 % AVG Validation Acc 60.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.576 AVG Validation Loss:0.726 AVG Training Acc 66.20 % AVG Validation Acc 60.60 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.576 AVG Validation Loss:0.720 AVG Training Acc 66.57 % AVG Validation Acc 61.59 %\n",
      "Epoch:170/200 AVG Training Loss:0.574 AVG Validation Loss:0.731 AVG Training Acc 66.60 % AVG Validation Acc 60.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.575 AVG Validation Loss:0.725 AVG Training Acc 66.53 % AVG Validation Acc 60.87 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.576 AVG Validation Loss:0.719 AVG Training Acc 66.64 % AVG Validation Acc 61.32 %\n",
      "Epoch:200/200 AVG Training Loss:0.576 AVG Validation Loss:0.725 AVG Training Acc 66.39 % AVG Validation Acc 60.96 %\n",
      "Split 202\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71497b0ccff448079bb5bd1327fd10a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.662 AVG Validation Loss:0.662 AVG Training Acc 61.80 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.659 AVG Training Acc 61.77 % AVG Validation Acc 62.40 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.638 AVG Validation Loss:0.664 AVG Training Acc 63.25 % AVG Validation Acc 60.23 %\n",
      "Epoch:40/200 AVG Training Loss:0.628 AVG Validation Loss:0.673 AVG Training Acc 64.14 % AVG Validation Acc 60.69 %\n",
      "Epoch:50/200 AVG Training Loss:0.618 AVG Validation Loss:0.684 AVG Training Acc 65.19 % AVG Validation Acc 61.32 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.612 AVG Validation Loss:0.691 AVG Training Acc 65.64 % AVG Validation Acc 60.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.606 AVG Validation Loss:0.700 AVG Training Acc 65.76 % AVG Validation Acc 60.32 %\n",
      "Epoch:80/200 AVG Training Loss:0.604 AVG Validation Loss:0.699 AVG Training Acc 66.07 % AVG Validation Acc 60.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.604 AVG Validation Loss:0.705 AVG Training Acc 66.26 % AVG Validation Acc 60.69 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.603 AVG Validation Loss:0.701 AVG Training Acc 66.19 % AVG Validation Acc 60.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.603 AVG Validation Loss:0.702 AVG Training Acc 66.04 % AVG Validation Acc 60.60 %\n",
      "Epoch:120/200 AVG Training Loss:0.601 AVG Validation Loss:0.702 AVG Training Acc 66.58 % AVG Validation Acc 60.78 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.601 AVG Validation Loss:0.701 AVG Training Acc 66.91 % AVG Validation Acc 60.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.603 AVG Validation Loss:0.700 AVG Training Acc 66.27 % AVG Validation Acc 60.69 %\n",
      "Epoch:150/200 AVG Training Loss:0.601 AVG Validation Loss:0.704 AVG Training Acc 66.11 % AVG Validation Acc 60.78 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.605 AVG Validation Loss:0.704 AVG Training Acc 66.33 % AVG Validation Acc 60.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.604 AVG Validation Loss:0.702 AVG Training Acc 66.05 % AVG Validation Acc 60.69 %\n",
      "Epoch:180/200 AVG Training Loss:0.602 AVG Validation Loss:0.701 AVG Training Acc 66.35 % AVG Validation Acc 60.32 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.603 AVG Validation Loss:0.705 AVG Training Acc 66.12 % AVG Validation Acc 60.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.603 AVG Validation Loss:0.705 AVG Training Acc 66.21 % AVG Validation Acc 60.23 %\n",
      "Split 203\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fdd2d700370b4484a8d8ac972bedf638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.655 AVG Training Acc 61.80 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.655 AVG Training Acc 61.81 % AVG Validation Acc 62.04 %\n",
      "Epoch:30/200 AVG Training Loss:0.646 AVG Validation Loss:0.655 AVG Training Acc 62.25 % AVG Validation Acc 61.86 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.664 AVG Validation Loss:0.665 AVG Training Acc 61.86 % AVG Validation Acc 61.86 %\n",
      "Epoch:50/200 AVG Training Loss:0.664 AVG Validation Loss:0.665 AVG Training Acc 61.88 % AVG Validation Acc 61.86 %\n",
      "Epoch:60/200 AVG Training Loss:0.663 AVG Validation Loss:0.664 AVG Training Acc 61.86 % AVG Validation Acc 61.86 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.662 AVG Validation Loss:0.664 AVG Training Acc 61.89 % AVG Validation Acc 61.77 %\n",
      "Epoch:80/200 AVG Training Loss:0.662 AVG Validation Loss:0.665 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:90/200 AVG Training Loss:0.663 AVG Validation Loss:0.664 AVG Training Acc 61.97 % AVG Validation Acc 61.86 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.662 AVG Validation Loss:0.664 AVG Training Acc 61.85 % AVG Validation Acc 61.86 %\n",
      "Epoch:110/200 AVG Training Loss:0.663 AVG Validation Loss:0.664 AVG Training Acc 61.93 % AVG Validation Acc 61.86 %\n",
      "Epoch:120/200 AVG Training Loss:0.662 AVG Validation Loss:0.664 AVG Training Acc 61.86 % AVG Validation Acc 61.86 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.664 AVG Validation Loss:0.664 AVG Training Acc 61.93 % AVG Validation Acc 61.86 %\n",
      "Epoch:140/200 AVG Training Loss:0.663 AVG Validation Loss:0.665 AVG Training Acc 61.94 % AVG Validation Acc 61.86 %\n",
      "Epoch:150/200 AVG Training Loss:0.662 AVG Validation Loss:0.664 AVG Training Acc 61.88 % AVG Validation Acc 61.86 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.662 AVG Validation Loss:0.665 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:170/200 AVG Training Loss:0.662 AVG Validation Loss:0.664 AVG Training Acc 61.88 % AVG Validation Acc 61.86 %\n",
      "Epoch:180/200 AVG Training Loss:0.662 AVG Validation Loss:0.664 AVG Training Acc 61.79 % AVG Validation Acc 61.86 %\n",
      "Epoch:190/200 AVG Training Loss:0.662 AVG Validation Loss:0.664 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.662 AVG Validation Loss:0.664 AVG Training Acc 61.83 % AVG Validation Acc 61.86 %\n",
      "Split 204\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b646437b4b544a0ea46869965113e778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.665 AVG Training Acc 61.90 % AVG Validation Acc 62.04 %\n",
      "Epoch:20/200 AVG Training Loss:0.650 AVG Validation Loss:0.661 AVG Training Acc 62.28 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.639 AVG Validation Loss:0.660 AVG Training Acc 62.83 % AVG Validation Acc 61.50 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.609 AVG Validation Loss:0.660 AVG Training Acc 64.87 % AVG Validation Acc 60.96 %\n",
      "Epoch:50/200 AVG Training Loss:0.592 AVG Validation Loss:0.672 AVG Training Acc 66.32 % AVG Validation Acc 61.59 %\n",
      "Epoch:60/200 AVG Training Loss:0.582 AVG Validation Loss:0.691 AVG Training Acc 67.37 % AVG Validation Acc 60.32 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.575 AVG Validation Loss:0.695 AVG Training Acc 67.21 % AVG Validation Acc 59.87 %\n",
      "Epoch:80/200 AVG Training Loss:0.567 AVG Validation Loss:0.701 AVG Training Acc 68.35 % AVG Validation Acc 59.06 %\n",
      "Epoch:90/200 AVG Training Loss:0.568 AVG Validation Loss:0.706 AVG Training Acc 68.57 % AVG Validation Acc 58.97 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.567 AVG Validation Loss:0.707 AVG Training Acc 68.13 % AVG Validation Acc 59.06 %\n",
      "Epoch:110/200 AVG Training Loss:0.567 AVG Validation Loss:0.701 AVG Training Acc 68.29 % AVG Validation Acc 59.33 %\n",
      "Epoch:120/200 AVG Training Loss:0.567 AVG Validation Loss:0.702 AVG Training Acc 68.06 % AVG Validation Acc 58.88 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.565 AVG Validation Loss:0.709 AVG Training Acc 68.19 % AVG Validation Acc 59.51 %\n",
      "Epoch:140/200 AVG Training Loss:0.567 AVG Validation Loss:0.710 AVG Training Acc 68.18 % AVG Validation Acc 59.06 %\n",
      "Epoch:150/200 AVG Training Loss:0.570 AVG Validation Loss:0.700 AVG Training Acc 68.04 % AVG Validation Acc 59.51 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.568 AVG Validation Loss:0.700 AVG Training Acc 68.30 % AVG Validation Acc 59.06 %\n",
      "Epoch:170/200 AVG Training Loss:0.564 AVG Validation Loss:0.714 AVG Training Acc 68.91 % AVG Validation Acc 58.88 %\n",
      "Epoch:180/200 AVG Training Loss:0.565 AVG Validation Loss:0.704 AVG Training Acc 68.34 % AVG Validation Acc 58.88 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.565 AVG Validation Loss:0.701 AVG Training Acc 68.46 % AVG Validation Acc 58.88 %\n",
      "Epoch:200/200 AVG Training Loss:0.566 AVG Validation Loss:0.706 AVG Training Acc 68.16 % AVG Validation Acc 59.51 %\n",
      "Split 205\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0405c4096d5540d5a938553b6d0c92a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.659 AVG Training Acc 61.98 % AVG Validation Acc 61.68 %\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:0.657 AVG Training Acc 61.83 % AVG Validation Acc 61.41 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.642 AVG Validation Loss:0.664 AVG Training Acc 62.67 % AVG Validation Acc 61.59 %\n",
      "Epoch:40/200 AVG Training Loss:0.631 AVG Validation Loss:0.667 AVG Training Acc 63.48 % AVG Validation Acc 62.94 %\n",
      "Epoch:50/200 AVG Training Loss:0.627 AVG Validation Loss:0.674 AVG Training Acc 63.65 % AVG Validation Acc 63.21 %\n",
      "Epoch:60/200 AVG Training Loss:0.622 AVG Validation Loss:0.674 AVG Training Acc 63.71 % AVG Validation Acc 63.39 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.618 AVG Validation Loss:0.678 AVG Training Acc 64.17 % AVG Validation Acc 63.21 %\n",
      "Epoch:80/200 AVG Training Loss:0.618 AVG Validation Loss:0.679 AVG Training Acc 64.62 % AVG Validation Acc 63.48 %\n",
      "Epoch:90/200 AVG Training Loss:0.615 AVG Validation Loss:0.680 AVG Training Acc 64.63 % AVG Validation Acc 63.03 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.616 AVG Validation Loss:0.681 AVG Training Acc 64.57 % AVG Validation Acc 62.67 %\n",
      "Epoch:110/200 AVG Training Loss:0.616 AVG Validation Loss:0.679 AVG Training Acc 64.37 % AVG Validation Acc 63.03 %\n",
      "Epoch:120/200 AVG Training Loss:0.614 AVG Validation Loss:0.681 AVG Training Acc 64.77 % AVG Validation Acc 63.57 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.614 AVG Validation Loss:0.677 AVG Training Acc 64.51 % AVG Validation Acc 63.21 %\n",
      "Epoch:140/200 AVG Training Loss:0.613 AVG Validation Loss:0.679 AVG Training Acc 64.78 % AVG Validation Acc 62.58 %\n",
      "Epoch:150/200 AVG Training Loss:0.615 AVG Validation Loss:0.679 AVG Training Acc 64.40 % AVG Validation Acc 62.85 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.615 AVG Validation Loss:0.681 AVG Training Acc 63.91 % AVG Validation Acc 63.12 %\n",
      "Epoch:170/200 AVG Training Loss:0.613 AVG Validation Loss:0.680 AVG Training Acc 64.89 % AVG Validation Acc 63.03 %\n",
      "Epoch:180/200 AVG Training Loss:0.616 AVG Validation Loss:0.682 AVG Training Acc 64.39 % AVG Validation Acc 62.94 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.613 AVG Validation Loss:0.681 AVG Training Acc 64.36 % AVG Validation Acc 62.94 %\n",
      "Epoch:200/200 AVG Training Loss:0.613 AVG Validation Loss:0.679 AVG Training Acc 63.93 % AVG Validation Acc 62.85 %\n",
      "Split 206\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14441805c6d3426abc3e08434674a57b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.666 AVG Validation Loss:0.663 AVG Training Acc 61.74 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.661 AVG Validation Loss:0.656 AVG Training Acc 61.86 % AVG Validation Acc 62.00 %\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.656 AVG Training Acc 62.25 % AVG Validation Acc 61.73 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.642 AVG Validation Loss:0.666 AVG Training Acc 62.89 % AVG Validation Acc 60.29 %\n",
      "Epoch:50/200 AVG Training Loss:0.637 AVG Validation Loss:0.673 AVG Training Acc 62.74 % AVG Validation Acc 60.20 %\n",
      "Epoch:60/200 AVG Training Loss:0.632 AVG Validation Loss:0.679 AVG Training Acc 63.10 % AVG Validation Acc 60.20 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.629 AVG Validation Loss:0.681 AVG Training Acc 63.74 % AVG Validation Acc 59.84 %\n",
      "Epoch:80/200 AVG Training Loss:0.628 AVG Validation Loss:0.684 AVG Training Acc 63.46 % AVG Validation Acc 59.75 %\n",
      "Epoch:90/200 AVG Training Loss:0.628 AVG Validation Loss:0.683 AVG Training Acc 63.48 % AVG Validation Acc 59.75 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.627 AVG Validation Loss:0.685 AVG Training Acc 63.68 % AVG Validation Acc 59.12 %\n",
      "Epoch:110/200 AVG Training Loss:0.626 AVG Validation Loss:0.686 AVG Training Acc 63.39 % AVG Validation Acc 59.21 %\n",
      "Epoch:120/200 AVG Training Loss:0.627 AVG Validation Loss:0.685 AVG Training Acc 63.58 % AVG Validation Acc 59.75 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.627 AVG Validation Loss:0.687 AVG Training Acc 63.15 % AVG Validation Acc 59.12 %\n",
      "Epoch:140/200 AVG Training Loss:0.626 AVG Validation Loss:0.687 AVG Training Acc 63.55 % AVG Validation Acc 59.03 %\n",
      "Epoch:150/200 AVG Training Loss:0.627 AVG Validation Loss:0.686 AVG Training Acc 63.22 % AVG Validation Acc 59.39 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.626 AVG Validation Loss:0.686 AVG Training Acc 63.40 % AVG Validation Acc 59.48 %\n",
      "Epoch:170/200 AVG Training Loss:0.627 AVG Validation Loss:0.687 AVG Training Acc 63.75 % AVG Validation Acc 59.30 %\n",
      "Epoch:180/200 AVG Training Loss:0.625 AVG Validation Loss:0.688 AVG Training Acc 63.60 % AVG Validation Acc 59.48 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.626 AVG Validation Loss:0.685 AVG Training Acc 63.48 % AVG Validation Acc 59.57 %\n",
      "Epoch:200/200 AVG Training Loss:0.628 AVG Validation Loss:0.686 AVG Training Acc 63.51 % AVG Validation Acc 59.57 %\n",
      "Split 207\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "299b2ef48da04a73ac42b0788bb6c621",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 61.79 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.659 AVG Training Acc 61.53 % AVG Validation Acc 62.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.649 AVG Validation Loss:0.658 AVG Training Acc 62.16 % AVG Validation Acc 62.36 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.624 AVG Validation Loss:0.676 AVG Training Acc 63.63 % AVG Validation Acc 60.47 %\n",
      "Epoch:50/200 AVG Training Loss:0.612 AVG Validation Loss:0.680 AVG Training Acc 64.81 % AVG Validation Acc 60.74 %\n",
      "Epoch:60/200 AVG Training Loss:0.603 AVG Validation Loss:0.691 AVG Training Acc 64.79 % AVG Validation Acc 59.75 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.598 AVG Validation Loss:0.690 AVG Training Acc 65.28 % AVG Validation Acc 59.84 %\n",
      "Epoch:80/200 AVG Training Loss:0.597 AVG Validation Loss:0.700 AVG Training Acc 65.48 % AVG Validation Acc 60.11 %\n",
      "Epoch:90/200 AVG Training Loss:0.594 AVG Validation Loss:0.697 AVG Training Acc 65.65 % AVG Validation Acc 60.29 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.594 AVG Validation Loss:0.703 AVG Training Acc 66.00 % AVG Validation Acc 59.48 %\n",
      "Epoch:110/200 AVG Training Loss:0.593 AVG Validation Loss:0.707 AVG Training Acc 66.17 % AVG Validation Acc 59.75 %\n",
      "Epoch:120/200 AVG Training Loss:0.594 AVG Validation Loss:0.704 AVG Training Acc 65.88 % AVG Validation Acc 60.11 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.594 AVG Validation Loss:0.704 AVG Training Acc 66.09 % AVG Validation Acc 59.84 %\n",
      "Epoch:140/200 AVG Training Loss:0.594 AVG Validation Loss:0.697 AVG Training Acc 65.99 % AVG Validation Acc 60.29 %\n",
      "Epoch:150/200 AVG Training Loss:0.593 AVG Validation Loss:0.700 AVG Training Acc 65.88 % AVG Validation Acc 60.29 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.593 AVG Validation Loss:0.698 AVG Training Acc 65.75 % AVG Validation Acc 60.83 %\n",
      "Epoch:170/200 AVG Training Loss:0.594 AVG Validation Loss:0.707 AVG Training Acc 66.26 % AVG Validation Acc 60.29 %\n",
      "Epoch:180/200 AVG Training Loss:0.595 AVG Validation Loss:0.698 AVG Training Acc 66.10 % AVG Validation Acc 60.29 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.594 AVG Validation Loss:0.697 AVG Training Acc 65.74 % AVG Validation Acc 60.20 %\n",
      "Epoch:200/200 AVG Training Loss:0.593 AVG Validation Loss:0.697 AVG Training Acc 65.75 % AVG Validation Acc 60.02 %\n",
      "Split 208\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7cc8fd37722464b8a7e28cc028ab55b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.657 AVG Validation Loss:0.667 AVG Training Acc 61.95 % AVG Validation Acc 61.64 %\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:0.664 AVG Training Acc 61.78 % AVG Validation Acc 62.00 %\n",
      "Epoch:30/200 AVG Training Loss:0.648 AVG Validation Loss:0.680 AVG Training Acc 61.94 % AVG Validation Acc 61.37 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.627 AVG Validation Loss:0.680 AVG Training Acc 63.28 % AVG Validation Acc 60.92 %\n",
      "Epoch:50/200 AVG Training Loss:0.617 AVG Validation Loss:0.689 AVG Training Acc 63.92 % AVG Validation Acc 60.92 %\n",
      "Epoch:60/200 AVG Training Loss:0.613 AVG Validation Loss:0.701 AVG Training Acc 64.19 % AVG Validation Acc 62.00 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.607 AVG Validation Loss:0.707 AVG Training Acc 64.79 % AVG Validation Acc 61.01 %\n",
      "Epoch:80/200 AVG Training Loss:0.607 AVG Validation Loss:0.705 AVG Training Acc 64.73 % AVG Validation Acc 60.56 %\n",
      "Epoch:90/200 AVG Training Loss:0.606 AVG Validation Loss:0.707 AVG Training Acc 64.52 % AVG Validation Acc 60.02 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.607 AVG Validation Loss:0.707 AVG Training Acc 64.96 % AVG Validation Acc 60.29 %\n",
      "Epoch:110/200 AVG Training Loss:0.607 AVG Validation Loss:0.708 AVG Training Acc 65.08 % AVG Validation Acc 60.38 %\n",
      "Epoch:120/200 AVG Training Loss:0.604 AVG Validation Loss:0.707 AVG Training Acc 65.25 % AVG Validation Acc 60.47 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.606 AVG Validation Loss:0.709 AVG Training Acc 65.19 % AVG Validation Acc 60.83 %\n",
      "Epoch:140/200 AVG Training Loss:0.606 AVG Validation Loss:0.710 AVG Training Acc 64.90 % AVG Validation Acc 61.19 %\n",
      "Epoch:150/200 AVG Training Loss:0.606 AVG Validation Loss:0.708 AVG Training Acc 64.88 % AVG Validation Acc 60.92 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.605 AVG Validation Loss:0.709 AVG Training Acc 64.80 % AVG Validation Acc 60.02 %\n",
      "Epoch:170/200 AVG Training Loss:0.603 AVG Validation Loss:0.712 AVG Training Acc 65.13 % AVG Validation Acc 60.92 %\n",
      "Epoch:180/200 AVG Training Loss:0.605 AVG Validation Loss:0.712 AVG Training Acc 64.88 % AVG Validation Acc 60.74 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.606 AVG Validation Loss:0.708 AVG Training Acc 65.46 % AVG Validation Acc 60.29 %\n",
      "Epoch:200/200 AVG Training Loss:0.604 AVG Validation Loss:0.705 AVG Training Acc 65.21 % AVG Validation Acc 61.19 %\n",
      "Split 209\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58cf3f686fea402c86ee0dfbbb23058c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.656 AVG Training Acc 61.63 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.657 AVG Training Acc 61.99 % AVG Validation Acc 62.00 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.633 AVG Validation Loss:0.661 AVG Training Acc 63.86 % AVG Validation Acc 60.74 %\n",
      "Epoch:40/200 AVG Training Loss:0.619 AVG Validation Loss:0.674 AVG Training Acc 64.54 % AVG Validation Acc 59.03 %\n",
      "Epoch:50/200 AVG Training Loss:0.609 AVG Validation Loss:0.681 AVG Training Acc 65.64 % AVG Validation Acc 58.94 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.593 AVG Validation Loss:0.696 AVG Training Acc 66.92 % AVG Validation Acc 59.12 %\n",
      "Epoch:70/200 AVG Training Loss:0.594 AVG Validation Loss:0.697 AVG Training Acc 67.20 % AVG Validation Acc 59.39 %\n",
      "Epoch:80/200 AVG Training Loss:0.588 AVG Validation Loss:0.703 AVG Training Acc 67.67 % AVG Validation Acc 59.03 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.585 AVG Validation Loss:0.704 AVG Training Acc 67.61 % AVG Validation Acc 59.12 %\n",
      "Epoch:100/200 AVG Training Loss:0.588 AVG Validation Loss:0.704 AVG Training Acc 67.72 % AVG Validation Acc 59.30 %\n",
      "Epoch:110/200 AVG Training Loss:0.585 AVG Validation Loss:0.709 AVG Training Acc 67.65 % AVG Validation Acc 58.94 %\n",
      "Epoch:120/200 AVG Training Loss:0.588 AVG Validation Loss:0.703 AVG Training Acc 67.85 % AVG Validation Acc 58.94 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.589 AVG Validation Loss:0.702 AVG Training Acc 67.37 % AVG Validation Acc 58.48 %\n",
      "Epoch:140/200 AVG Training Loss:0.587 AVG Validation Loss:0.707 AVG Training Acc 67.00 % AVG Validation Acc 58.30 %\n",
      "Epoch:150/200 AVG Training Loss:0.588 AVG Validation Loss:0.707 AVG Training Acc 67.49 % AVG Validation Acc 58.12 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.587 AVG Validation Loss:0.704 AVG Training Acc 67.62 % AVG Validation Acc 57.94 %\n",
      "Epoch:170/200 AVG Training Loss:0.586 AVG Validation Loss:0.711 AVG Training Acc 67.52 % AVG Validation Acc 57.94 %\n",
      "Epoch:180/200 AVG Training Loss:0.589 AVG Validation Loss:0.707 AVG Training Acc 67.42 % AVG Validation Acc 58.21 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.586 AVG Validation Loss:0.705 AVG Training Acc 67.46 % AVG Validation Acc 58.84 %\n",
      "Epoch:200/200 AVG Training Loss:0.588 AVG Validation Loss:0.702 AVG Training Acc 67.57 % AVG Validation Acc 58.57 %\n",
      "Split 210\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "061fccfc25174654a2cf62c43d16a75e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.656 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.656 AVG Validation Loss:0.659 AVG Training Acc 61.67 % AVG Validation Acc 61.37 %\n",
      "Epoch:30/200 AVG Training Loss:0.651 AVG Validation Loss:0.665 AVG Training Acc 61.84 % AVG Validation Acc 61.55 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.643 AVG Validation Loss:0.665 AVG Training Acc 62.55 % AVG Validation Acc 60.74 %\n",
      "Epoch:50/200 AVG Training Loss:0.636 AVG Validation Loss:0.673 AVG Training Acc 62.35 % AVG Validation Acc 60.74 %\n",
      "Epoch:60/200 AVG Training Loss:0.630 AVG Validation Loss:0.677 AVG Training Acc 63.53 % AVG Validation Acc 59.39 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.624 AVG Validation Loss:0.680 AVG Training Acc 63.60 % AVG Validation Acc 60.20 %\n",
      "Epoch:80/200 AVG Training Loss:0.625 AVG Validation Loss:0.680 AVG Training Acc 63.88 % AVG Validation Acc 59.84 %\n",
      "Epoch:90/200 AVG Training Loss:0.623 AVG Validation Loss:0.682 AVG Training Acc 63.70 % AVG Validation Acc 59.84 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.622 AVG Validation Loss:0.683 AVG Training Acc 64.04 % AVG Validation Acc 61.10 %\n",
      "Epoch:110/200 AVG Training Loss:0.622 AVG Validation Loss:0.681 AVG Training Acc 64.04 % AVG Validation Acc 60.83 %\n",
      "Epoch:120/200 AVG Training Loss:0.623 AVG Validation Loss:0.680 AVG Training Acc 63.75 % AVG Validation Acc 61.64 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.621 AVG Validation Loss:0.680 AVG Training Acc 64.03 % AVG Validation Acc 60.47 %\n",
      "Epoch:140/200 AVG Training Loss:0.622 AVG Validation Loss:0.680 AVG Training Acc 64.36 % AVG Validation Acc 61.10 %\n",
      "Epoch:150/200 AVG Training Loss:0.622 AVG Validation Loss:0.684 AVG Training Acc 63.62 % AVG Validation Acc 60.65 %\n",
      "Epoch:160/200 AVG Training Loss:0.621 AVG Validation Loss:0.682 AVG Training Acc 64.03 % AVG Validation Acc 60.74 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.620 AVG Validation Loss:0.680 AVG Training Acc 64.05 % AVG Validation Acc 61.64 %\n",
      "Epoch:180/200 AVG Training Loss:0.621 AVG Validation Loss:0.683 AVG Training Acc 64.29 % AVG Validation Acc 60.65 %\n",
      "Epoch:190/200 AVG Training Loss:0.622 AVG Validation Loss:0.682 AVG Training Acc 63.79 % AVG Validation Acc 60.02 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.621 AVG Validation Loss:0.681 AVG Training Acc 64.36 % AVG Validation Acc 59.93 %\n",
      "Split 211\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c64e8ad660042f9a9db991f215a6381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.659 AVG Training Acc 61.97 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.666 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.643 AVG Validation Loss:0.678 AVG Training Acc 62.45 % AVG Validation Acc 60.23 %\n",
      "Epoch:40/200 AVG Training Loss:0.636 AVG Validation Loss:0.681 AVG Training Acc 62.77 % AVG Validation Acc 59.78 %\n",
      "Epoch:50/200 AVG Training Loss:0.631 AVG Validation Loss:0.684 AVG Training Acc 63.16 % AVG Validation Acc 59.78 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.625 AVG Validation Loss:0.684 AVG Training Acc 63.77 % AVG Validation Acc 60.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.625 AVG Validation Loss:0.685 AVG Training Acc 63.47 % AVG Validation Acc 60.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.623 AVG Validation Loss:0.686 AVG Training Acc 63.99 % AVG Validation Acc 60.23 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.623 AVG Validation Loss:0.687 AVG Training Acc 63.93 % AVG Validation Acc 59.78 %\n",
      "Epoch:100/200 AVG Training Loss:0.622 AVG Validation Loss:0.684 AVG Training Acc 63.57 % AVG Validation Acc 60.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.622 AVG Validation Loss:0.685 AVG Training Acc 63.76 % AVG Validation Acc 60.32 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.622 AVG Validation Loss:0.685 AVG Training Acc 63.90 % AVG Validation Acc 60.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.623 AVG Validation Loss:0.686 AVG Training Acc 63.47 % AVG Validation Acc 59.69 %\n",
      "Epoch:140/200 AVG Training Loss:0.623 AVG Validation Loss:0.689 AVG Training Acc 63.56 % AVG Validation Acc 60.14 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.623 AVG Validation Loss:0.686 AVG Training Acc 63.60 % AVG Validation Acc 60.05 %\n",
      "Epoch:160/200 AVG Training Loss:0.622 AVG Validation Loss:0.684 AVG Training Acc 64.11 % AVG Validation Acc 60.23 %\n",
      "Epoch:170/200 AVG Training Loss:0.622 AVG Validation Loss:0.689 AVG Training Acc 63.41 % AVG Validation Acc 59.69 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.622 AVG Validation Loss:0.685 AVG Training Acc 63.63 % AVG Validation Acc 60.05 %\n",
      "Epoch:190/200 AVG Training Loss:0.624 AVG Validation Loss:0.690 AVG Training Acc 63.53 % AVG Validation Acc 60.50 %\n",
      "Epoch:200/200 AVG Training Loss:0.623 AVG Validation Loss:0.684 AVG Training Acc 63.63 % AVG Validation Acc 59.87 %\n",
      "Split 212\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b4fe6d23414ba5b57d7cff7c5be80e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.665 AVG Training Acc 61.93 % AVG Validation Acc 61.86 %\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.662 AVG Training Acc 61.94 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.646 AVG Validation Loss:0.659 AVG Training Acc 62.25 % AVG Validation Acc 62.40 %\n",
      "Epoch:40/200 AVG Training Loss:0.641 AVG Validation Loss:0.663 AVG Training Acc 62.67 % AVG Validation Acc 62.58 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.639 AVG Validation Loss:0.662 AVG Training Acc 63.01 % AVG Validation Acc 62.67 %\n",
      "Epoch:60/200 AVG Training Loss:0.636 AVG Validation Loss:0.662 AVG Training Acc 63.31 % AVG Validation Acc 62.58 %\n",
      "Epoch:70/200 AVG Training Loss:0.637 AVG Validation Loss:0.661 AVG Training Acc 63.18 % AVG Validation Acc 62.58 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.635 AVG Validation Loss:0.665 AVG Training Acc 63.05 % AVG Validation Acc 62.31 %\n",
      "Epoch:90/200 AVG Training Loss:0.637 AVG Validation Loss:0.662 AVG Training Acc 63.23 % AVG Validation Acc 62.22 %\n",
      "Epoch:100/200 AVG Training Loss:0.637 AVG Validation Loss:0.664 AVG Training Acc 63.27 % AVG Validation Acc 62.31 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.636 AVG Validation Loss:0.664 AVG Training Acc 62.75 % AVG Validation Acc 62.13 %\n",
      "Epoch:120/200 AVG Training Loss:0.636 AVG Validation Loss:0.664 AVG Training Acc 63.01 % AVG Validation Acc 62.04 %\n",
      "Epoch:130/200 AVG Training Loss:0.635 AVG Validation Loss:0.665 AVG Training Acc 63.13 % AVG Validation Acc 62.49 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.636 AVG Validation Loss:0.664 AVG Training Acc 63.25 % AVG Validation Acc 62.40 %\n",
      "Epoch:150/200 AVG Training Loss:0.637 AVG Validation Loss:0.662 AVG Training Acc 62.88 % AVG Validation Acc 62.04 %\n",
      "Epoch:160/200 AVG Training Loss:0.636 AVG Validation Loss:0.664 AVG Training Acc 63.25 % AVG Validation Acc 62.31 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.635 AVG Validation Loss:0.663 AVG Training Acc 63.10 % AVG Validation Acc 62.22 %\n",
      "Epoch:180/200 AVG Training Loss:0.637 AVG Validation Loss:0.663 AVG Training Acc 62.85 % AVG Validation Acc 62.40 %\n",
      "Epoch:190/200 AVG Training Loss:0.637 AVG Validation Loss:0.664 AVG Training Acc 63.02 % AVG Validation Acc 62.22 %\n",
      "Epoch:200/200 AVG Training Loss:0.637 AVG Validation Loss:0.664 AVG Training Acc 63.21 % AVG Validation Acc 62.22 %\n",
      "Split 213\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50880708abf844d3a375d4ed310ba809",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.653 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.652 AVG Training Acc 62.32 % AVG Validation Acc 61.59 %\n",
      "Epoch:30/200 AVG Training Loss:0.644 AVG Validation Loss:0.652 AVG Training Acc 62.67 % AVG Validation Acc 61.41 %\n",
      "Epoch:40/200 AVG Training Loss:0.670 AVG Validation Loss:0.672 AVG Training Acc 61.02 % AVG Validation Acc 61.77 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.665 AVG Validation Loss:0.663 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:60/200 AVG Training Loss:0.665 AVG Validation Loss:0.664 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:70/200 AVG Training Loss:0.665 AVG Validation Loss:0.663 AVG Training Acc 61.86 % AVG Validation Acc 61.86 %\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.663 AVG Validation Loss:0.663 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:90/200 AVG Training Loss:0.663 AVG Validation Loss:0.664 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:100/200 AVG Training Loss:0.664 AVG Validation Loss:0.664 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch   104: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.663 AVG Validation Loss:0.663 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:120/200 AVG Training Loss:0.664 AVG Validation Loss:0.665 AVG Training Acc 61.92 % AVG Validation Acc 61.86 %\n",
      "Epoch:130/200 AVG Training Loss:0.664 AVG Validation Loss:0.664 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch   135: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.663 AVG Validation Loss:0.664 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch:150/200 AVG Training Loss:0.663 AVG Validation Loss:0.663 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:160/200 AVG Training Loss:0.662 AVG Validation Loss:0.666 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch   166: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.663 AVG Validation Loss:0.664 AVG Training Acc 61.87 % AVG Validation Acc 61.86 %\n",
      "Epoch:180/200 AVG Training Loss:0.664 AVG Validation Loss:0.665 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:190/200 AVG Training Loss:0.663 AVG Validation Loss:0.664 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch   197: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.663 AVG Validation Loss:0.664 AVG Training Acc 61.93 % AVG Validation Acc 61.86 %\n",
      "Split 214\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5054f8837dbf47078889b6ba40717f9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.667 AVG Training Acc 61.76 % AVG Validation Acc 61.77 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.663 AVG Training Acc 62.29 % AVG Validation Acc 61.77 %\n",
      "Epoch:30/200 AVG Training Loss:0.639 AVG Validation Loss:0.667 AVG Training Acc 62.62 % AVG Validation Acc 61.95 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.616 AVG Validation Loss:0.684 AVG Training Acc 63.70 % AVG Validation Acc 60.78 %\n",
      "Epoch:50/200 AVG Training Loss:0.610 AVG Validation Loss:0.700 AVG Training Acc 63.66 % AVG Validation Acc 60.23 %\n",
      "Epoch:60/200 AVG Training Loss:0.602 AVG Validation Loss:0.708 AVG Training Acc 63.84 % AVG Validation Acc 59.78 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.598 AVG Validation Loss:0.707 AVG Training Acc 64.41 % AVG Validation Acc 59.33 %\n",
      "Epoch:80/200 AVG Training Loss:0.596 AVG Validation Loss:0.721 AVG Training Acc 64.47 % AVG Validation Acc 59.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.595 AVG Validation Loss:0.705 AVG Training Acc 64.26 % AVG Validation Acc 58.34 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.595 AVG Validation Loss:0.728 AVG Training Acc 64.90 % AVG Validation Acc 58.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.593 AVG Validation Loss:0.719 AVG Training Acc 64.71 % AVG Validation Acc 59.51 %\n",
      "Epoch:120/200 AVG Training Loss:0.593 AVG Validation Loss:0.719 AVG Training Acc 64.61 % AVG Validation Acc 58.70 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.593 AVG Validation Loss:0.714 AVG Training Acc 64.79 % AVG Validation Acc 58.70 %\n",
      "Epoch:140/200 AVG Training Loss:0.594 AVG Validation Loss:0.711 AVG Training Acc 64.49 % AVG Validation Acc 59.51 %\n",
      "Epoch:150/200 AVG Training Loss:0.592 AVG Validation Loss:0.715 AVG Training Acc 64.80 % AVG Validation Acc 59.24 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.593 AVG Validation Loss:0.720 AVG Training Acc 64.72 % AVG Validation Acc 58.88 %\n",
      "Epoch:170/200 AVG Training Loss:0.596 AVG Validation Loss:0.711 AVG Training Acc 64.33 % AVG Validation Acc 59.24 %\n",
      "Epoch:180/200 AVG Training Loss:0.593 AVG Validation Loss:0.720 AVG Training Acc 64.78 % AVG Validation Acc 58.88 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.594 AVG Validation Loss:0.718 AVG Training Acc 64.34 % AVG Validation Acc 59.06 %\n",
      "Epoch:200/200 AVG Training Loss:0.594 AVG Validation Loss:0.714 AVG Training Acc 64.92 % AVG Validation Acc 59.06 %\n",
      "Split 215\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2864f72778b48b1b67a690166395c44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.659 AVG Training Acc 61.92 % AVG Validation Acc 61.86 %\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.647 AVG Validation Loss:0.659 AVG Training Acc 62.07 % AVG Validation Acc 61.59 %\n",
      "Epoch:30/200 AVG Training Loss:0.639 AVG Validation Loss:0.668 AVG Training Acc 62.91 % AVG Validation Acc 61.32 %\n",
      "Epoch:40/200 AVG Training Loss:0.633 AVG Validation Loss:0.667 AVG Training Acc 63.49 % AVG Validation Acc 60.87 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.626 AVG Validation Loss:0.675 AVG Training Acc 63.99 % AVG Validation Acc 61.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.624 AVG Validation Loss:0.677 AVG Training Acc 63.80 % AVG Validation Acc 60.78 %\n",
      "Epoch:70/200 AVG Training Loss:0.623 AVG Validation Loss:0.677 AVG Training Acc 64.13 % AVG Validation Acc 60.87 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.622 AVG Validation Loss:0.678 AVG Training Acc 64.20 % AVG Validation Acc 61.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.622 AVG Validation Loss:0.679 AVG Training Acc 64.07 % AVG Validation Acc 60.87 %\n",
      "Epoch:100/200 AVG Training Loss:0.622 AVG Validation Loss:0.679 AVG Training Acc 63.97 % AVG Validation Acc 61.32 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.622 AVG Validation Loss:0.679 AVG Training Acc 64.28 % AVG Validation Acc 60.78 %\n",
      "Epoch:120/200 AVG Training Loss:0.620 AVG Validation Loss:0.679 AVG Training Acc 64.34 % AVG Validation Acc 60.78 %\n",
      "Epoch:130/200 AVG Training Loss:0.620 AVG Validation Loss:0.680 AVG Training Acc 64.46 % AVG Validation Acc 60.69 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.620 AVG Validation Loss:0.680 AVG Training Acc 64.45 % AVG Validation Acc 60.69 %\n",
      "Epoch:150/200 AVG Training Loss:0.621 AVG Validation Loss:0.678 AVG Training Acc 64.27 % AVG Validation Acc 60.87 %\n",
      "Epoch:160/200 AVG Training Loss:0.621 AVG Validation Loss:0.679 AVG Training Acc 64.00 % AVG Validation Acc 60.96 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.620 AVG Validation Loss:0.678 AVG Training Acc 64.31 % AVG Validation Acc 60.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.622 AVG Validation Loss:0.678 AVG Training Acc 64.07 % AVG Validation Acc 61.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.620 AVG Validation Loss:0.679 AVG Training Acc 64.05 % AVG Validation Acc 60.96 %\n",
      "Epoch:200/200 AVG Training Loss:0.623 AVG Validation Loss:0.680 AVG Training Acc 64.32 % AVG Validation Acc 60.78 %\n",
      "Split 216\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c58444230304b828635794c316b360e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 61.86 % AVG Validation Acc 61.82 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.651 AVG Training Acc 62.08 % AVG Validation Acc 62.55 %\n",
      "Epoch:30/200 AVG Training Loss:0.646 AVG Validation Loss:0.654 AVG Training Acc 62.52 % AVG Validation Acc 62.45 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.635 AVG Validation Loss:0.654 AVG Training Acc 63.27 % AVG Validation Acc 62.45 %\n",
      "Epoch:50/200 AVG Training Loss:0.627 AVG Validation Loss:0.660 AVG Training Acc 63.38 % AVG Validation Acc 61.91 %\n",
      "Epoch:60/200 AVG Training Loss:0.619 AVG Validation Loss:0.664 AVG Training Acc 64.50 % AVG Validation Acc 62.45 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.612 AVG Validation Loss:0.668 AVG Training Acc 64.93 % AVG Validation Acc 61.55 %\n",
      "Epoch:80/200 AVG Training Loss:0.610 AVG Validation Loss:0.668 AVG Training Acc 64.85 % AVG Validation Acc 61.64 %\n",
      "Epoch:90/200 AVG Training Loss:0.611 AVG Validation Loss:0.669 AVG Training Acc 64.74 % AVG Validation Acc 61.91 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.610 AVG Validation Loss:0.673 AVG Training Acc 64.94 % AVG Validation Acc 61.46 %\n",
      "Epoch:110/200 AVG Training Loss:0.609 AVG Validation Loss:0.672 AVG Training Acc 65.41 % AVG Validation Acc 60.83 %\n",
      "Epoch:120/200 AVG Training Loss:0.610 AVG Validation Loss:0.671 AVG Training Acc 65.16 % AVG Validation Acc 61.37 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.609 AVG Validation Loss:0.674 AVG Training Acc 65.12 % AVG Validation Acc 61.82 %\n",
      "Epoch:140/200 AVG Training Loss:0.610 AVG Validation Loss:0.675 AVG Training Acc 64.71 % AVG Validation Acc 61.37 %\n",
      "Epoch:150/200 AVG Training Loss:0.608 AVG Validation Loss:0.675 AVG Training Acc 65.28 % AVG Validation Acc 61.28 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.610 AVG Validation Loss:0.671 AVG Training Acc 65.16 % AVG Validation Acc 61.01 %\n",
      "Epoch:170/200 AVG Training Loss:0.609 AVG Validation Loss:0.670 AVG Training Acc 65.05 % AVG Validation Acc 61.19 %\n",
      "Epoch:180/200 AVG Training Loss:0.609 AVG Validation Loss:0.672 AVG Training Acc 64.66 % AVG Validation Acc 61.73 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.609 AVG Validation Loss:0.673 AVG Training Acc 65.43 % AVG Validation Acc 61.46 %\n",
      "Epoch:200/200 AVG Training Loss:0.610 AVG Validation Loss:0.672 AVG Training Acc 64.87 % AVG Validation Acc 61.46 %\n",
      "Split 217\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90c755c9723b4464b7c3f9e73956004e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.662 AVG Training Acc 61.81 % AVG Validation Acc 61.82 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.657 AVG Training Acc 61.82 % AVG Validation Acc 62.00 %\n",
      "Epoch:30/200 AVG Training Loss:0.644 AVG Validation Loss:0.673 AVG Training Acc 62.37 % AVG Validation Acc 59.39 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.616 AVG Validation Loss:0.665 AVG Training Acc 64.89 % AVG Validation Acc 61.46 %\n",
      "Epoch:50/200 AVG Training Loss:0.607 AVG Validation Loss:0.671 AVG Training Acc 65.56 % AVG Validation Acc 60.65 %\n",
      "Epoch:60/200 AVG Training Loss:0.595 AVG Validation Loss:0.676 AVG Training Acc 66.33 % AVG Validation Acc 61.01 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.589 AVG Validation Loss:0.682 AVG Training Acc 66.96 % AVG Validation Acc 60.20 %\n",
      "Epoch:80/200 AVG Training Loss:0.587 AVG Validation Loss:0.680 AVG Training Acc 67.23 % AVG Validation Acc 61.55 %\n",
      "Epoch:90/200 AVG Training Loss:0.582 AVG Validation Loss:0.683 AVG Training Acc 67.08 % AVG Validation Acc 60.47 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.584 AVG Validation Loss:0.681 AVG Training Acc 67.34 % AVG Validation Acc 60.47 %\n",
      "Epoch:110/200 AVG Training Loss:0.586 AVG Validation Loss:0.685 AVG Training Acc 66.83 % AVG Validation Acc 59.75 %\n",
      "Epoch:120/200 AVG Training Loss:0.584 AVG Validation Loss:0.686 AVG Training Acc 66.75 % AVG Validation Acc 60.20 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.585 AVG Validation Loss:0.680 AVG Training Acc 67.26 % AVG Validation Acc 60.47 %\n",
      "Epoch:140/200 AVG Training Loss:0.582 AVG Validation Loss:0.684 AVG Training Acc 67.05 % AVG Validation Acc 60.47 %\n",
      "Epoch:150/200 AVG Training Loss:0.584 AVG Validation Loss:0.681 AVG Training Acc 66.97 % AVG Validation Acc 59.75 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.585 AVG Validation Loss:0.684 AVG Training Acc 67.01 % AVG Validation Acc 60.65 %\n",
      "Epoch:170/200 AVG Training Loss:0.584 AVG Validation Loss:0.687 AVG Training Acc 67.00 % AVG Validation Acc 60.20 %\n",
      "Epoch:180/200 AVG Training Loss:0.587 AVG Validation Loss:0.685 AVG Training Acc 66.83 % AVG Validation Acc 61.01 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.580 AVG Validation Loss:0.684 AVG Training Acc 67.46 % AVG Validation Acc 60.11 %\n",
      "Epoch:200/200 AVG Training Loss:0.584 AVG Validation Loss:0.690 AVG Training Acc 67.18 % AVG Validation Acc 60.56 %\n",
      "Split 218\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692960531ec746e0b4401511454f1662",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.659 AVG Training Acc 61.97 % AVG Validation Acc 62.00 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.659 AVG Training Acc 62.16 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.663 AVG Validation Loss:0.663 AVG Training Acc 61.89 % AVG Validation Acc 62.00 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.648 AVG Validation Loss:0.667 AVG Training Acc 62.42 % AVG Validation Acc 61.64 %\n",
      "Epoch:50/200 AVG Training Loss:0.640 AVG Validation Loss:0.680 AVG Training Acc 62.84 % AVG Validation Acc 61.91 %\n",
      "Epoch:60/200 AVG Training Loss:0.634 AVG Validation Loss:0.686 AVG Training Acc 62.95 % AVG Validation Acc 62.45 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.631 AVG Validation Loss:0.691 AVG Training Acc 63.34 % AVG Validation Acc 62.36 %\n",
      "Epoch:80/200 AVG Training Loss:0.628 AVG Validation Loss:0.693 AVG Training Acc 63.66 % AVG Validation Acc 62.73 %\n",
      "Epoch:90/200 AVG Training Loss:0.627 AVG Validation Loss:0.697 AVG Training Acc 63.66 % AVG Validation Acc 62.64 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.627 AVG Validation Loss:0.692 AVG Training Acc 63.41 % AVG Validation Acc 62.36 %\n",
      "Epoch:110/200 AVG Training Loss:0.627 AVG Validation Loss:0.694 AVG Training Acc 63.62 % AVG Validation Acc 62.18 %\n",
      "Epoch:120/200 AVG Training Loss:0.627 AVG Validation Loss:0.694 AVG Training Acc 63.39 % AVG Validation Acc 62.45 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.627 AVG Validation Loss:0.695 AVG Training Acc 63.55 % AVG Validation Acc 62.27 %\n",
      "Epoch:140/200 AVG Training Loss:0.628 AVG Validation Loss:0.695 AVG Training Acc 63.24 % AVG Validation Acc 61.91 %\n",
      "Epoch:150/200 AVG Training Loss:0.625 AVG Validation Loss:0.697 AVG Training Acc 63.71 % AVG Validation Acc 62.00 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.626 AVG Validation Loss:0.693 AVG Training Acc 64.15 % AVG Validation Acc 62.27 %\n",
      "Epoch:170/200 AVG Training Loss:0.626 AVG Validation Loss:0.694 AVG Training Acc 63.93 % AVG Validation Acc 62.45 %\n",
      "Epoch:180/200 AVG Training Loss:0.626 AVG Validation Loss:0.694 AVG Training Acc 63.65 % AVG Validation Acc 61.82 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.628 AVG Validation Loss:0.693 AVG Training Acc 63.55 % AVG Validation Acc 62.45 %\n",
      "Epoch:200/200 AVG Training Loss:0.625 AVG Validation Loss:0.694 AVG Training Acc 63.53 % AVG Validation Acc 62.09 %\n",
      "Split 219\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f66fbee566948dfba10851956fd8ef2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.656 AVG Training Acc 61.79 % AVG Validation Acc 62.00 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.649 AVG Training Acc 61.74 % AVG Validation Acc 62.27 %\n",
      "Epoch:30/200 AVG Training Loss:0.641 AVG Validation Loss:0.646 AVG Training Acc 62.40 % AVG Validation Acc 62.27 %\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.654 AVG Training Acc 61.57 % AVG Validation Acc 61.91 %\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.632 AVG Validation Loss:0.658 AVG Training Acc 63.01 % AVG Validation Acc 61.73 %\n",
      "Epoch:60/200 AVG Training Loss:0.623 AVG Validation Loss:0.666 AVG Training Acc 63.46 % AVG Validation Acc 60.92 %\n",
      "Epoch:70/200 AVG Training Loss:0.610 AVG Validation Loss:0.677 AVG Training Acc 64.06 % AVG Validation Acc 61.10 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.602 AVG Validation Loss:0.682 AVG Training Acc 65.28 % AVG Validation Acc 61.19 %\n",
      "Epoch:90/200 AVG Training Loss:0.602 AVG Validation Loss:0.685 AVG Training Acc 65.35 % AVG Validation Acc 60.74 %\n",
      "Epoch:100/200 AVG Training Loss:0.600 AVG Validation Loss:0.687 AVG Training Acc 65.34 % AVG Validation Acc 61.01 %\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.600 AVG Validation Loss:0.686 AVG Training Acc 65.77 % AVG Validation Acc 61.82 %\n",
      "Epoch:120/200 AVG Training Loss:0.599 AVG Validation Loss:0.685 AVG Training Acc 65.67 % AVG Validation Acc 60.74 %\n",
      "Epoch:130/200 AVG Training Loss:0.601 AVG Validation Loss:0.695 AVG Training Acc 65.40 % AVG Validation Acc 60.92 %\n",
      "Epoch   134: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.599 AVG Validation Loss:0.686 AVG Training Acc 65.18 % AVG Validation Acc 61.37 %\n",
      "Epoch:150/200 AVG Training Loss:0.599 AVG Validation Loss:0.684 AVG Training Acc 65.52 % AVG Validation Acc 61.19 %\n",
      "Epoch:160/200 AVG Training Loss:0.597 AVG Validation Loss:0.688 AVG Training Acc 65.41 % AVG Validation Acc 61.28 %\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.602 AVG Validation Loss:0.684 AVG Training Acc 64.91 % AVG Validation Acc 60.92 %\n",
      "Epoch:180/200 AVG Training Loss:0.600 AVG Validation Loss:0.692 AVG Training Acc 65.17 % AVG Validation Acc 61.37 %\n",
      "Epoch:190/200 AVG Training Loss:0.600 AVG Validation Loss:0.685 AVG Training Acc 65.05 % AVG Validation Acc 61.37 %\n",
      "Epoch   196: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.599 AVG Validation Loss:0.691 AVG Training Acc 65.20 % AVG Validation Acc 60.20 %\n",
      "Split 220\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27deb48d91d04a118d80a70c7f2200af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.660 AVG Training Acc 61.91 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 61.72 % AVG Validation Acc 61.91 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.661 AVG Training Acc 62.15 % AVG Validation Acc 61.46 %\n",
      "Epoch:40/200 AVG Training Loss:0.654 AVG Validation Loss:0.659 AVG Training Acc 62.16 % AVG Validation Acc 61.01 %\n",
      "Epoch:50/200 AVG Training Loss:0.651 AVG Validation Loss:0.661 AVG Training Acc 62.46 % AVG Validation Acc 60.83 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.649 AVG Validation Loss:0.662 AVG Training Acc 62.40 % AVG Validation Acc 60.65 %\n",
      "Epoch:70/200 AVG Training Loss:0.648 AVG Validation Loss:0.663 AVG Training Acc 62.45 % AVG Validation Acc 60.47 %\n",
      "Epoch:80/200 AVG Training Loss:0.648 AVG Validation Loss:0.663 AVG Training Acc 62.31 % AVG Validation Acc 60.47 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.647 AVG Validation Loss:0.664 AVG Training Acc 62.44 % AVG Validation Acc 60.29 %\n",
      "Epoch:100/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.39 % AVG Validation Acc 60.29 %\n",
      "Epoch:110/200 AVG Training Loss:0.647 AVG Validation Loss:0.666 AVG Training Acc 62.55 % AVG Validation Acc 60.38 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.648 AVG Validation Loss:0.663 AVG Training Acc 62.53 % AVG Validation Acc 60.29 %\n",
      "Epoch:130/200 AVG Training Loss:0.648 AVG Validation Loss:0.664 AVG Training Acc 62.46 % AVG Validation Acc 60.38 %\n",
      "Epoch:140/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 62.43 % AVG Validation Acc 60.47 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 62.60 % AVG Validation Acc 60.38 %\n",
      "Epoch:160/200 AVG Training Loss:0.646 AVG Validation Loss:0.664 AVG Training Acc 62.48 % AVG Validation Acc 60.56 %\n",
      "Epoch:170/200 AVG Training Loss:0.648 AVG Validation Loss:0.666 AVG Training Acc 62.45 % AVG Validation Acc 60.47 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.646 AVG Validation Loss:0.668 AVG Training Acc 62.31 % AVG Validation Acc 60.47 %\n",
      "Epoch:190/200 AVG Training Loss:0.647 AVG Validation Loss:0.666 AVG Training Acc 62.54 % AVG Validation Acc 60.56 %\n",
      "Epoch:200/200 AVG Training Loss:0.647 AVG Validation Loss:0.664 AVG Training Acc 62.56 % AVG Validation Acc 60.65 %\n",
      "Split 221\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b595d6bb6394a9abd8ef175401dd3e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.664 AVG Training Acc 61.89 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.660 AVG Training Acc 61.67 % AVG Validation Acc 61.95 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.638 AVG Validation Loss:0.664 AVG Training Acc 62.28 % AVG Validation Acc 60.60 %\n",
      "Epoch:40/200 AVG Training Loss:0.628 AVG Validation Loss:0.672 AVG Training Acc 62.89 % AVG Validation Acc 60.96 %\n",
      "Epoch:50/200 AVG Training Loss:0.618 AVG Validation Loss:0.679 AVG Training Acc 63.47 % AVG Validation Acc 60.32 %\n",
      "Epoch:60/200 AVG Training Loss:0.614 AVG Validation Loss:0.680 AVG Training Acc 63.08 % AVG Validation Acc 60.69 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.610 AVG Validation Loss:0.681 AVG Training Acc 64.17 % AVG Validation Acc 60.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.608 AVG Validation Loss:0.682 AVG Training Acc 63.80 % AVG Validation Acc 59.78 %\n",
      "Epoch:90/200 AVG Training Loss:0.610 AVG Validation Loss:0.686 AVG Training Acc 63.53 % AVG Validation Acc 59.78 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.607 AVG Validation Loss:0.685 AVG Training Acc 64.43 % AVG Validation Acc 59.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.606 AVG Validation Loss:0.686 AVG Training Acc 63.67 % AVG Validation Acc 59.15 %\n",
      "Epoch:120/200 AVG Training Loss:0.608 AVG Validation Loss:0.687 AVG Training Acc 63.96 % AVG Validation Acc 59.60 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.606 AVG Validation Loss:0.691 AVG Training Acc 63.66 % AVG Validation Acc 59.51 %\n",
      "Epoch:140/200 AVG Training Loss:0.607 AVG Validation Loss:0.686 AVG Training Acc 64.05 % AVG Validation Acc 59.87 %\n",
      "Epoch:150/200 AVG Training Loss:0.608 AVG Validation Loss:0.688 AVG Training Acc 63.54 % AVG Validation Acc 59.42 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.607 AVG Validation Loss:0.683 AVG Training Acc 64.16 % AVG Validation Acc 59.24 %\n",
      "Epoch:170/200 AVG Training Loss:0.605 AVG Validation Loss:0.687 AVG Training Acc 64.12 % AVG Validation Acc 59.06 %\n",
      "Epoch:180/200 AVG Training Loss:0.607 AVG Validation Loss:0.682 AVG Training Acc 63.47 % AVG Validation Acc 59.69 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.609 AVG Validation Loss:0.681 AVG Training Acc 63.59 % AVG Validation Acc 59.24 %\n",
      "Epoch:200/200 AVG Training Loss:0.606 AVG Validation Loss:0.686 AVG Training Acc 64.52 % AVG Validation Acc 59.42 %\n",
      "Split 222\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36e29e974ed74e92ba01e270e153403b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.657 AVG Training Acc 61.90 % AVG Validation Acc 61.77 %\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:0.653 AVG Training Acc 61.91 % AVG Validation Acc 61.50 %\n",
      "Epoch:30/200 AVG Training Loss:0.650 AVG Validation Loss:0.653 AVG Training Acc 62.22 % AVG Validation Acc 62.13 %\n",
      "Epoch:40/200 AVG Training Loss:0.647 AVG Validation Loss:0.655 AVG Training Acc 62.24 % AVG Validation Acc 62.13 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.621 AVG Validation Loss:0.651 AVG Training Acc 64.21 % AVG Validation Acc 62.94 %\n",
      "Epoch:60/200 AVG Training Loss:0.603 AVG Validation Loss:0.663 AVG Training Acc 65.40 % AVG Validation Acc 62.04 %\n",
      "Epoch:70/200 AVG Training Loss:0.593 AVG Validation Loss:0.671 AVG Training Acc 66.24 % AVG Validation Acc 61.77 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.584 AVG Validation Loss:0.683 AVG Training Acc 67.04 % AVG Validation Acc 61.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.582 AVG Validation Loss:0.682 AVG Training Acc 66.97 % AVG Validation Acc 61.23 %\n",
      "Epoch:100/200 AVG Training Loss:0.581 AVG Validation Loss:0.688 AVG Training Acc 67.11 % AVG Validation Acc 60.96 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.579 AVG Validation Loss:0.685 AVG Training Acc 66.92 % AVG Validation Acc 61.23 %\n",
      "Epoch:120/200 AVG Training Loss:0.579 AVG Validation Loss:0.688 AVG Training Acc 67.35 % AVG Validation Acc 60.41 %\n",
      "Epoch:130/200 AVG Training Loss:0.581 AVG Validation Loss:0.689 AVG Training Acc 66.92 % AVG Validation Acc 60.60 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.582 AVG Validation Loss:0.691 AVG Training Acc 66.94 % AVG Validation Acc 60.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.578 AVG Validation Loss:0.691 AVG Training Acc 67.64 % AVG Validation Acc 60.41 %\n",
      "Epoch:160/200 AVG Training Loss:0.582 AVG Validation Loss:0.685 AVG Training Acc 67.17 % AVG Validation Acc 60.50 %\n",
      "Epoch:170/200 AVG Training Loss:0.581 AVG Validation Loss:0.687 AVG Training Acc 66.69 % AVG Validation Acc 60.87 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.579 AVG Validation Loss:0.691 AVG Training Acc 66.91 % AVG Validation Acc 60.96 %\n",
      "Epoch:190/200 AVG Training Loss:0.580 AVG Validation Loss:0.694 AVG Training Acc 67.16 % AVG Validation Acc 61.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.581 AVG Validation Loss:0.691 AVG Training Acc 67.17 % AVG Validation Acc 59.96 %\n",
      "Split 223\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "665e89c5f71447d498b0eaa97da6e81f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 61.66 % AVG Validation Acc 61.41 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.660 AVG Training Acc 61.81 % AVG Validation Acc 61.68 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.638 AVG Validation Loss:0.665 AVG Training Acc 62.48 % AVG Validation Acc 61.23 %\n",
      "Epoch:40/200 AVG Training Loss:0.629 AVG Validation Loss:0.666 AVG Training Acc 63.10 % AVG Validation Acc 60.41 %\n",
      "Epoch:50/200 AVG Training Loss:0.622 AVG Validation Loss:0.674 AVG Training Acc 63.80 % AVG Validation Acc 59.78 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.617 AVG Validation Loss:0.679 AVG Training Acc 63.87 % AVG Validation Acc 61.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.613 AVG Validation Loss:0.682 AVG Training Acc 64.08 % AVG Validation Acc 60.78 %\n",
      "Epoch:80/200 AVG Training Loss:0.612 AVG Validation Loss:0.680 AVG Training Acc 64.42 % AVG Validation Acc 61.50 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.611 AVG Validation Loss:0.676 AVG Training Acc 64.49 % AVG Validation Acc 61.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.614 AVG Validation Loss:0.679 AVG Training Acc 64.47 % AVG Validation Acc 61.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.613 AVG Validation Loss:0.680 AVG Training Acc 64.31 % AVG Validation Acc 61.05 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.614 AVG Validation Loss:0.677 AVG Training Acc 63.61 % AVG Validation Acc 61.23 %\n",
      "Epoch:130/200 AVG Training Loss:0.613 AVG Validation Loss:0.678 AVG Training Acc 64.86 % AVG Validation Acc 61.68 %\n",
      "Epoch:140/200 AVG Training Loss:0.613 AVG Validation Loss:0.678 AVG Training Acc 64.19 % AVG Validation Acc 61.59 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.612 AVG Validation Loss:0.677 AVG Training Acc 64.48 % AVG Validation Acc 61.68 %\n",
      "Epoch:160/200 AVG Training Loss:0.612 AVG Validation Loss:0.680 AVG Training Acc 64.59 % AVG Validation Acc 60.69 %\n",
      "Epoch:170/200 AVG Training Loss:0.612 AVG Validation Loss:0.677 AVG Training Acc 64.17 % AVG Validation Acc 61.41 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.612 AVG Validation Loss:0.681 AVG Training Acc 64.19 % AVG Validation Acc 61.50 %\n",
      "Epoch:190/200 AVG Training Loss:0.612 AVG Validation Loss:0.680 AVG Training Acc 64.50 % AVG Validation Acc 61.32 %\n",
      "Epoch:200/200 AVG Training Loss:0.613 AVG Validation Loss:0.681 AVG Training Acc 64.22 % AVG Validation Acc 60.96 %\n",
      "Split 224\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaf7f7962c4b467abfe76b7360124abb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.663 AVG Training Acc 61.87 % AVG Validation Acc 62.04 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.661 AVG Training Acc 61.94 % AVG Validation Acc 61.95 %\n",
      "Epoch:30/200 AVG Training Loss:0.681 AVG Validation Loss:0.664 AVG Training Acc 60.38 % AVG Validation Acc 61.23 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.663 AVG Validation Loss:0.664 AVG Training Acc 61.88 % AVG Validation Acc 61.86 %\n",
      "Epoch:50/200 AVG Training Loss:0.661 AVG Validation Loss:0.664 AVG Training Acc 61.88 % AVG Validation Acc 61.86 %\n",
      "Epoch:60/200 AVG Training Loss:0.662 AVG Validation Loss:0.664 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.662 AVG Validation Loss:0.664 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch:80/200 AVG Training Loss:0.661 AVG Validation Loss:0.664 AVG Training Acc 61.93 % AVG Validation Acc 61.86 %\n",
      "Epoch:90/200 AVG Training Loss:0.662 AVG Validation Loss:0.664 AVG Training Acc 61.92 % AVG Validation Acc 61.86 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.662 AVG Validation Loss:0.664 AVG Training Acc 61.92 % AVG Validation Acc 61.86 %\n",
      "Epoch:110/200 AVG Training Loss:0.662 AVG Validation Loss:0.664 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch:120/200 AVG Training Loss:0.661 AVG Validation Loss:0.665 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.660 AVG Validation Loss:0.664 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:140/200 AVG Training Loss:0.661 AVG Validation Loss:0.664 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch:150/200 AVG Training Loss:0.661 AVG Validation Loss:0.664 AVG Training Acc 61.87 % AVG Validation Acc 61.86 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.662 AVG Validation Loss:0.664 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:170/200 AVG Training Loss:0.662 AVG Validation Loss:0.664 AVG Training Acc 61.88 % AVG Validation Acc 61.86 %\n",
      "Epoch:180/200 AVG Training Loss:0.661 AVG Validation Loss:0.664 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch:190/200 AVG Training Loss:0.661 AVG Validation Loss:0.664 AVG Training Acc 61.94 % AVG Validation Acc 61.86 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.662 AVG Validation Loss:0.663 AVG Training Acc 61.90 % AVG Validation Acc 61.86 %\n",
      "Split 225\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16503dd628014cecab58b25f45f60fcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.659 AVG Training Acc 61.84 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.657 AVG Training Acc 61.76 % AVG Validation Acc 61.68 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.636 AVG Validation Loss:0.661 AVG Training Acc 62.88 % AVG Validation Acc 62.40 %\n",
      "Epoch:40/200 AVG Training Loss:0.621 AVG Validation Loss:0.666 AVG Training Acc 64.03 % AVG Validation Acc 60.96 %\n",
      "Epoch:50/200 AVG Training Loss:0.613 AVG Validation Loss:0.669 AVG Training Acc 65.10 % AVG Validation Acc 61.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.606 AVG Validation Loss:0.677 AVG Training Acc 65.66 % AVG Validation Acc 60.69 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.601 AVG Validation Loss:0.679 AVG Training Acc 66.04 % AVG Validation Acc 59.24 %\n",
      "Epoch:80/200 AVG Training Loss:0.599 AVG Validation Loss:0.675 AVG Training Acc 66.16 % AVG Validation Acc 60.60 %\n",
      "Epoch:90/200 AVG Training Loss:0.599 AVG Validation Loss:0.679 AVG Training Acc 66.33 % AVG Validation Acc 59.60 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.597 AVG Validation Loss:0.682 AVG Training Acc 66.72 % AVG Validation Acc 59.69 %\n",
      "Epoch:110/200 AVG Training Loss:0.598 AVG Validation Loss:0.681 AVG Training Acc 66.14 % AVG Validation Acc 60.14 %\n",
      "Epoch:120/200 AVG Training Loss:0.599 AVG Validation Loss:0.681 AVG Training Acc 66.02 % AVG Validation Acc 60.32 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.597 AVG Validation Loss:0.680 AVG Training Acc 66.72 % AVG Validation Acc 59.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.597 AVG Validation Loss:0.681 AVG Training Acc 66.46 % AVG Validation Acc 59.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.597 AVG Validation Loss:0.682 AVG Training Acc 66.39 % AVG Validation Acc 59.87 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.599 AVG Validation Loss:0.681 AVG Training Acc 66.30 % AVG Validation Acc 60.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.599 AVG Validation Loss:0.674 AVG Training Acc 66.31 % AVG Validation Acc 60.50 %\n",
      "Epoch:180/200 AVG Training Loss:0.600 AVG Validation Loss:0.681 AVG Training Acc 66.42 % AVG Validation Acc 59.60 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.600 AVG Validation Loss:0.675 AVG Training Acc 66.25 % AVG Validation Acc 60.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.599 AVG Validation Loss:0.677 AVG Training Acc 66.34 % AVG Validation Acc 59.96 %\n",
      "Split 226\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50916122aa0f450ebcb84fff63296103",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.657 AVG Validation Loss:0.656 AVG Training Acc 61.57 % AVG Validation Acc 62.00 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.656 AVG Training Acc 61.68 % AVG Validation Acc 61.82 %\n",
      "Epoch:30/200 AVG Training Loss:0.643 AVG Validation Loss:0.660 AVG Training Acc 62.45 % AVG Validation Acc 61.64 %\n",
      "Epoch:40/200 AVG Training Loss:0.639 AVG Validation Loss:0.659 AVG Training Acc 63.05 % AVG Validation Acc 61.82 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.620 AVG Validation Loss:0.672 AVG Training Acc 64.44 % AVG Validation Acc 60.02 %\n",
      "Epoch:60/200 AVG Training Loss:0.610 AVG Validation Loss:0.682 AVG Training Acc 64.90 % AVG Validation Acc 60.29 %\n",
      "Epoch:70/200 AVG Training Loss:0.601 AVG Validation Loss:0.688 AVG Training Acc 65.49 % AVG Validation Acc 59.75 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.601 AVG Validation Loss:0.690 AVG Training Acc 65.83 % AVG Validation Acc 59.03 %\n",
      "Epoch:90/200 AVG Training Loss:0.599 AVG Validation Loss:0.687 AVG Training Acc 65.95 % AVG Validation Acc 59.30 %\n",
      "Epoch:100/200 AVG Training Loss:0.596 AVG Validation Loss:0.692 AVG Training Acc 66.10 % AVG Validation Acc 59.75 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.597 AVG Validation Loss:0.690 AVG Training Acc 65.78 % AVG Validation Acc 59.39 %\n",
      "Epoch:120/200 AVG Training Loss:0.595 AVG Validation Loss:0.694 AVG Training Acc 66.11 % AVG Validation Acc 59.48 %\n",
      "Epoch:130/200 AVG Training Loss:0.594 AVG Validation Loss:0.695 AVG Training Acc 65.94 % AVG Validation Acc 59.30 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.596 AVG Validation Loss:0.696 AVG Training Acc 66.01 % AVG Validation Acc 60.02 %\n",
      "Epoch:150/200 AVG Training Loss:0.596 AVG Validation Loss:0.694 AVG Training Acc 65.81 % AVG Validation Acc 59.66 %\n",
      "Epoch:160/200 AVG Training Loss:0.597 AVG Validation Loss:0.699 AVG Training Acc 66.13 % AVG Validation Acc 59.03 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.596 AVG Validation Loss:0.697 AVG Training Acc 65.62 % AVG Validation Acc 58.84 %\n",
      "Epoch:180/200 AVG Training Loss:0.595 AVG Validation Loss:0.695 AVG Training Acc 66.09 % AVG Validation Acc 59.84 %\n",
      "Epoch:190/200 AVG Training Loss:0.595 AVG Validation Loss:0.692 AVG Training Acc 66.25 % AVG Validation Acc 59.12 %\n",
      "Epoch   198: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.594 AVG Validation Loss:0.693 AVG Training Acc 65.98 % AVG Validation Acc 59.75 %\n",
      "Split 227\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e8810ed18934a68a4f7e037f0dab997",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.654 AVG Training Acc 61.93 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.653 AVG Training Acc 61.98 % AVG Validation Acc 61.19 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.638 AVG Validation Loss:0.652 AVG Training Acc 63.01 % AVG Validation Acc 61.37 %\n",
      "Epoch:40/200 AVG Training Loss:0.629 AVG Validation Loss:0.662 AVG Training Acc 63.08 % AVG Validation Acc 61.64 %\n",
      "Epoch:50/200 AVG Training Loss:0.620 AVG Validation Loss:0.670 AVG Training Acc 64.37 % AVG Validation Acc 61.28 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.613 AVG Validation Loss:0.673 AVG Training Acc 64.21 % AVG Validation Acc 61.64 %\n",
      "Epoch:70/200 AVG Training Loss:0.613 AVG Validation Loss:0.679 AVG Training Acc 64.22 % AVG Validation Acc 61.64 %\n",
      "Epoch:80/200 AVG Training Loss:0.610 AVG Validation Loss:0.676 AVG Training Acc 64.75 % AVG Validation Acc 61.28 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.609 AVG Validation Loss:0.671 AVG Training Acc 64.57 % AVG Validation Acc 61.55 %\n",
      "Epoch:100/200 AVG Training Loss:0.608 AVG Validation Loss:0.674 AVG Training Acc 64.66 % AVG Validation Acc 62.36 %\n",
      "Epoch:110/200 AVG Training Loss:0.608 AVG Validation Loss:0.679 AVG Training Acc 64.96 % AVG Validation Acc 61.91 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.610 AVG Validation Loss:0.677 AVG Training Acc 64.48 % AVG Validation Acc 61.82 %\n",
      "Epoch:130/200 AVG Training Loss:0.608 AVG Validation Loss:0.673 AVG Training Acc 64.97 % AVG Validation Acc 62.27 %\n",
      "Epoch:140/200 AVG Training Loss:0.610 AVG Validation Loss:0.676 AVG Training Acc 64.16 % AVG Validation Acc 61.91 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.606 AVG Validation Loss:0.672 AVG Training Acc 64.70 % AVG Validation Acc 61.91 %\n",
      "Epoch:160/200 AVG Training Loss:0.609 AVG Validation Loss:0.673 AVG Training Acc 64.48 % AVG Validation Acc 62.00 %\n",
      "Epoch:170/200 AVG Training Loss:0.607 AVG Validation Loss:0.678 AVG Training Acc 64.39 % AVG Validation Acc 62.00 %\n",
      "Epoch:180/200 AVG Training Loss:0.607 AVG Validation Loss:0.676 AVG Training Acc 64.68 % AVG Validation Acc 61.82 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.607 AVG Validation Loss:0.677 AVG Training Acc 64.91 % AVG Validation Acc 61.82 %\n",
      "Epoch:200/200 AVG Training Loss:0.609 AVG Validation Loss:0.675 AVG Training Acc 64.58 % AVG Validation Acc 61.46 %\n",
      "Split 228\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6bce519e63b4734bfcbee1774a4d144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 61.95 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.661 AVG Training Acc 62.16 % AVG Validation Acc 61.28 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.641 AVG Validation Loss:0.663 AVG Training Acc 62.60 % AVG Validation Acc 61.37 %\n",
      "Epoch:40/200 AVG Training Loss:0.636 AVG Validation Loss:0.661 AVG Training Acc 63.11 % AVG Validation Acc 61.46 %\n",
      "Epoch:50/200 AVG Training Loss:0.632 AVG Validation Loss:0.671 AVG Training Acc 63.62 % AVG Validation Acc 61.46 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.628 AVG Validation Loss:0.673 AVG Training Acc 64.16 % AVG Validation Acc 61.73 %\n",
      "Epoch:70/200 AVG Training Loss:0.626 AVG Validation Loss:0.675 AVG Training Acc 64.09 % AVG Validation Acc 61.55 %\n",
      "Epoch:80/200 AVG Training Loss:0.624 AVG Validation Loss:0.675 AVG Training Acc 63.99 % AVG Validation Acc 61.46 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.623 AVG Validation Loss:0.673 AVG Training Acc 64.32 % AVG Validation Acc 62.00 %\n",
      "Epoch:100/200 AVG Training Loss:0.625 AVG Validation Loss:0.675 AVG Training Acc 63.93 % AVG Validation Acc 62.00 %\n",
      "Epoch:110/200 AVG Training Loss:0.625 AVG Validation Loss:0.674 AVG Training Acc 64.44 % AVG Validation Acc 62.00 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.624 AVG Validation Loss:0.676 AVG Training Acc 64.27 % AVG Validation Acc 61.46 %\n",
      "Epoch:130/200 AVG Training Loss:0.625 AVG Validation Loss:0.674 AVG Training Acc 64.19 % AVG Validation Acc 62.27 %\n",
      "Epoch:140/200 AVG Training Loss:0.624 AVG Validation Loss:0.674 AVG Training Acc 63.97 % AVG Validation Acc 62.09 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.625 AVG Validation Loss:0.675 AVG Training Acc 64.08 % AVG Validation Acc 61.82 %\n",
      "Epoch:160/200 AVG Training Loss:0.624 AVG Validation Loss:0.674 AVG Training Acc 64.32 % AVG Validation Acc 62.27 %\n",
      "Epoch:170/200 AVG Training Loss:0.625 AVG Validation Loss:0.675 AVG Training Acc 64.12 % AVG Validation Acc 61.82 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.623 AVG Validation Loss:0.675 AVG Training Acc 64.77 % AVG Validation Acc 62.00 %\n",
      "Epoch:190/200 AVG Training Loss:0.624 AVG Validation Loss:0.674 AVG Training Acc 64.04 % AVG Validation Acc 61.82 %\n",
      "Epoch:200/200 AVG Training Loss:0.622 AVG Validation Loss:0.674 AVG Training Acc 64.73 % AVG Validation Acc 62.09 %\n",
      "Split 229\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7afe2e80808c4e999ffd90f042ecf72c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.666 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.647 AVG Validation Loss:0.659 AVG Training Acc 62.35 % AVG Validation Acc 61.55 %\n",
      "Epoch:30/200 AVG Training Loss:0.634 AVG Validation Loss:0.667 AVG Training Acc 63.03 % AVG Validation Acc 60.83 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.610 AVG Validation Loss:0.693 AVG Training Acc 65.01 % AVG Validation Acc 59.75 %\n",
      "Epoch:50/200 AVG Training Loss:0.594 AVG Validation Loss:0.708 AVG Training Acc 66.23 % AVG Validation Acc 59.75 %\n",
      "Epoch:60/200 AVG Training Loss:0.586 AVG Validation Loss:0.721 AVG Training Acc 66.64 % AVG Validation Acc 59.39 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.583 AVG Validation Loss:0.724 AVG Training Acc 66.69 % AVG Validation Acc 58.57 %\n",
      "Epoch:80/200 AVG Training Loss:0.579 AVG Validation Loss:0.731 AVG Training Acc 66.78 % AVG Validation Acc 59.21 %\n",
      "Epoch:90/200 AVG Training Loss:0.578 AVG Validation Loss:0.730 AVG Training Acc 67.14 % AVG Validation Acc 59.12 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.578 AVG Validation Loss:0.730 AVG Training Acc 67.11 % AVG Validation Acc 59.30 %\n",
      "Epoch:110/200 AVG Training Loss:0.577 AVG Validation Loss:0.736 AVG Training Acc 67.31 % AVG Validation Acc 58.66 %\n",
      "Epoch:120/200 AVG Training Loss:0.578 AVG Validation Loss:0.742 AVG Training Acc 67.16 % AVG Validation Acc 59.30 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.576 AVG Validation Loss:0.731 AVG Training Acc 67.24 % AVG Validation Acc 59.12 %\n",
      "Epoch:140/200 AVG Training Loss:0.578 AVG Validation Loss:0.738 AVG Training Acc 66.90 % AVG Validation Acc 59.30 %\n",
      "Epoch:150/200 AVG Training Loss:0.577 AVG Validation Loss:0.740 AVG Training Acc 67.47 % AVG Validation Acc 59.21 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.577 AVG Validation Loss:0.733 AVG Training Acc 67.04 % AVG Validation Acc 59.03 %\n",
      "Epoch:170/200 AVG Training Loss:0.577 AVG Validation Loss:0.732 AVG Training Acc 67.11 % AVG Validation Acc 58.57 %\n",
      "Epoch:180/200 AVG Training Loss:0.578 AVG Validation Loss:0.738 AVG Training Acc 67.35 % AVG Validation Acc 58.66 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.577 AVG Validation Loss:0.735 AVG Training Acc 67.65 % AVG Validation Acc 59.66 %\n",
      "Epoch:200/200 AVG Training Loss:0.576 AVG Validation Loss:0.737 AVG Training Acc 67.32 % AVG Validation Acc 57.76 %\n",
      "Split 230\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491fb668ee4640f0ba98980989884bc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.655 AVG Training Acc 61.86 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.653 AVG Training Acc 61.86 % AVG Validation Acc 62.27 %\n",
      "Epoch:30/200 AVG Training Loss:0.643 AVG Validation Loss:0.658 AVG Training Acc 61.98 % AVG Validation Acc 61.46 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.619 AVG Validation Loss:0.657 AVG Training Acc 63.58 % AVG Validation Acc 63.27 %\n",
      "Epoch:50/200 AVG Training Loss:0.604 AVG Validation Loss:0.668 AVG Training Acc 64.79 % AVG Validation Acc 63.00 %\n",
      "Epoch:60/200 AVG Training Loss:0.601 AVG Validation Loss:0.683 AVG Training Acc 64.99 % AVG Validation Acc 62.45 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.590 AVG Validation Loss:0.688 AVG Training Acc 65.64 % AVG Validation Acc 61.82 %\n",
      "Epoch:80/200 AVG Training Loss:0.590 AVG Validation Loss:0.689 AVG Training Acc 65.52 % AVG Validation Acc 62.09 %\n",
      "Epoch:90/200 AVG Training Loss:0.589 AVG Validation Loss:0.692 AVG Training Acc 65.80 % AVG Validation Acc 61.01 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.587 AVG Validation Loss:0.691 AVG Training Acc 65.84 % AVG Validation Acc 61.19 %\n",
      "Epoch:110/200 AVG Training Loss:0.587 AVG Validation Loss:0.694 AVG Training Acc 66.03 % AVG Validation Acc 61.10 %\n",
      "Epoch:120/200 AVG Training Loss:0.588 AVG Validation Loss:0.688 AVG Training Acc 66.01 % AVG Validation Acc 61.55 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.586 AVG Validation Loss:0.691 AVG Training Acc 66.16 % AVG Validation Acc 61.82 %\n",
      "Epoch:140/200 AVG Training Loss:0.586 AVG Validation Loss:0.693 AVG Training Acc 66.04 % AVG Validation Acc 61.91 %\n",
      "Epoch:150/200 AVG Training Loss:0.587 AVG Validation Loss:0.696 AVG Training Acc 65.87 % AVG Validation Acc 61.55 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.587 AVG Validation Loss:0.690 AVG Training Acc 65.52 % AVG Validation Acc 62.00 %\n",
      "Epoch:170/200 AVG Training Loss:0.586 AVG Validation Loss:0.695 AVG Training Acc 66.08 % AVG Validation Acc 61.91 %\n",
      "Epoch:180/200 AVG Training Loss:0.586 AVG Validation Loss:0.690 AVG Training Acc 66.23 % AVG Validation Acc 61.19 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.589 AVG Validation Loss:0.691 AVG Training Acc 65.78 % AVG Validation Acc 61.91 %\n",
      "Epoch:200/200 AVG Training Loss:0.587 AVG Validation Loss:0.695 AVG Training Acc 65.94 % AVG Validation Acc 61.37 %\n",
      "Split 231\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "597340904bc94416b60f930ab6d44b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.655 AVG Training Acc 61.97 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.655 AVG Training Acc 61.99 % AVG Validation Acc 61.59 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.642 AVG Validation Loss:0.665 AVG Training Acc 62.32 % AVG Validation Acc 60.50 %\n",
      "Epoch:40/200 AVG Training Loss:0.628 AVG Validation Loss:0.672 AVG Training Acc 63.48 % AVG Validation Acc 60.50 %\n",
      "Epoch:50/200 AVG Training Loss:0.619 AVG Validation Loss:0.677 AVG Training Acc 63.46 % AVG Validation Acc 58.88 %\n",
      "Epoch:60/200 AVG Training Loss:0.614 AVG Validation Loss:0.684 AVG Training Acc 63.81 % AVG Validation Acc 58.43 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.608 AVG Validation Loss:0.682 AVG Training Acc 64.43 % AVG Validation Acc 58.52 %\n",
      "Epoch:80/200 AVG Training Loss:0.607 AVG Validation Loss:0.686 AVG Training Acc 64.57 % AVG Validation Acc 58.88 %\n",
      "Epoch:90/200 AVG Training Loss:0.606 AVG Validation Loss:0.686 AVG Training Acc 64.83 % AVG Validation Acc 58.34 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.605 AVG Validation Loss:0.686 AVG Training Acc 64.69 % AVG Validation Acc 59.33 %\n",
      "Epoch:110/200 AVG Training Loss:0.605 AVG Validation Loss:0.685 AVG Training Acc 65.13 % AVG Validation Acc 58.52 %\n",
      "Epoch:120/200 AVG Training Loss:0.605 AVG Validation Loss:0.685 AVG Training Acc 64.66 % AVG Validation Acc 58.70 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.606 AVG Validation Loss:0.689 AVG Training Acc 64.48 % AVG Validation Acc 58.61 %\n",
      "Epoch:140/200 AVG Training Loss:0.602 AVG Validation Loss:0.691 AVG Training Acc 65.06 % AVG Validation Acc 59.06 %\n",
      "Epoch:150/200 AVG Training Loss:0.605 AVG Validation Loss:0.689 AVG Training Acc 64.86 % AVG Validation Acc 59.33 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.605 AVG Validation Loss:0.689 AVG Training Acc 65.09 % AVG Validation Acc 59.06 %\n",
      "Epoch:170/200 AVG Training Loss:0.605 AVG Validation Loss:0.685 AVG Training Acc 64.32 % AVG Validation Acc 58.97 %\n",
      "Epoch:180/200 AVG Training Loss:0.604 AVG Validation Loss:0.686 AVG Training Acc 64.97 % AVG Validation Acc 58.88 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.605 AVG Validation Loss:0.686 AVG Training Acc 64.33 % AVG Validation Acc 58.97 %\n",
      "Epoch:200/200 AVG Training Loss:0.603 AVG Validation Loss:0.690 AVG Training Acc 64.67 % AVG Validation Acc 59.51 %\n",
      "Split 232\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6498fb12dd8349bf913c2a9428953674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.656 AVG Training Acc 61.82 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.661 AVG Training Acc 61.90 % AVG Validation Acc 61.77 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.632 AVG Validation Loss:0.668 AVG Training Acc 63.26 % AVG Validation Acc 62.04 %\n",
      "Epoch:40/200 AVG Training Loss:0.623 AVG Validation Loss:0.676 AVG Training Acc 63.65 % AVG Validation Acc 61.95 %\n",
      "Epoch:50/200 AVG Training Loss:0.615 AVG Validation Loss:0.678 AVG Training Acc 64.29 % AVG Validation Acc 60.96 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.608 AVG Validation Loss:0.687 AVG Training Acc 64.95 % AVG Validation Acc 60.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.605 AVG Validation Loss:0.688 AVG Training Acc 64.92 % AVG Validation Acc 59.69 %\n",
      "Epoch:80/200 AVG Training Loss:0.607 AVG Validation Loss:0.690 AVG Training Acc 64.48 % AVG Validation Acc 60.14 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.605 AVG Validation Loss:0.691 AVG Training Acc 65.03 % AVG Validation Acc 59.78 %\n",
      "Epoch:100/200 AVG Training Loss:0.606 AVG Validation Loss:0.690 AVG Training Acc 65.11 % AVG Validation Acc 59.42 %\n",
      "Epoch:110/200 AVG Training Loss:0.605 AVG Validation Loss:0.690 AVG Training Acc 64.88 % AVG Validation Acc 60.23 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.604 AVG Validation Loss:0.690 AVG Training Acc 65.01 % AVG Validation Acc 59.33 %\n",
      "Epoch:130/200 AVG Training Loss:0.606 AVG Validation Loss:0.689 AVG Training Acc 65.04 % AVG Validation Acc 60.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.605 AVG Validation Loss:0.693 AVG Training Acc 65.27 % AVG Validation Acc 59.51 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.605 AVG Validation Loss:0.692 AVG Training Acc 64.67 % AVG Validation Acc 59.15 %\n",
      "Epoch:160/200 AVG Training Loss:0.605 AVG Validation Loss:0.689 AVG Training Acc 65.02 % AVG Validation Acc 59.51 %\n",
      "Epoch:170/200 AVG Training Loss:0.605 AVG Validation Loss:0.689 AVG Training Acc 65.29 % AVG Validation Acc 59.51 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.607 AVG Validation Loss:0.690 AVG Training Acc 64.60 % AVG Validation Acc 58.97 %\n",
      "Epoch:190/200 AVG Training Loss:0.605 AVG Validation Loss:0.691 AVG Training Acc 64.69 % AVG Validation Acc 59.42 %\n",
      "Epoch:200/200 AVG Training Loss:0.605 AVG Validation Loss:0.690 AVG Training Acc 64.86 % AVG Validation Acc 59.69 %\n",
      "Split 233\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fad3d40d8cfb44429a81eae47c76a78d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.660 AVG Training Acc 61.80 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.659 AVG Training Acc 61.94 % AVG Validation Acc 62.22 %\n",
      "Epoch:30/200 AVG Training Loss:0.642 AVG Validation Loss:0.656 AVG Training Acc 62.51 % AVG Validation Acc 62.13 %\n",
      "Epoch:40/200 AVG Training Loss:0.636 AVG Validation Loss:0.660 AVG Training Acc 63.00 % AVG Validation Acc 61.68 %\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.607 AVG Validation Loss:0.682 AVG Training Acc 65.75 % AVG Validation Acc 59.78 %\n",
      "Epoch:60/200 AVG Training Loss:0.594 AVG Validation Loss:0.683 AVG Training Acc 67.44 % AVG Validation Acc 60.60 %\n",
      "Epoch:70/200 AVG Training Loss:0.588 AVG Validation Loss:0.692 AVG Training Acc 68.17 % AVG Validation Acc 61.59 %\n",
      "Epoch    71: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.578 AVG Validation Loss:0.695 AVG Training Acc 69.05 % AVG Validation Acc 59.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.581 AVG Validation Loss:0.699 AVG Training Acc 68.86 % AVG Validation Acc 59.69 %\n",
      "Epoch:100/200 AVG Training Loss:0.581 AVG Validation Loss:0.697 AVG Training Acc 68.72 % AVG Validation Acc 60.50 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.575 AVG Validation Loss:0.704 AVG Training Acc 69.27 % AVG Validation Acc 59.42 %\n",
      "Epoch:120/200 AVG Training Loss:0.579 AVG Validation Loss:0.696 AVG Training Acc 68.69 % AVG Validation Acc 60.23 %\n",
      "Epoch:130/200 AVG Training Loss:0.574 AVG Validation Loss:0.699 AVG Training Acc 69.41 % AVG Validation Acc 60.05 %\n",
      "Epoch   133: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.577 AVG Validation Loss:0.701 AVG Training Acc 69.18 % AVG Validation Acc 60.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.578 AVG Validation Loss:0.699 AVG Training Acc 68.70 % AVG Validation Acc 59.87 %\n",
      "Epoch:160/200 AVG Training Loss:0.578 AVG Validation Loss:0.697 AVG Training Acc 69.16 % AVG Validation Acc 60.32 %\n",
      "Epoch   164: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.577 AVG Validation Loss:0.697 AVG Training Acc 69.37 % AVG Validation Acc 60.50 %\n",
      "Epoch:180/200 AVG Training Loss:0.575 AVG Validation Loss:0.694 AVG Training Acc 69.02 % AVG Validation Acc 60.69 %\n",
      "Epoch:190/200 AVG Training Loss:0.575 AVG Validation Loss:0.699 AVG Training Acc 69.25 % AVG Validation Acc 60.23 %\n",
      "Epoch   195: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.576 AVG Validation Loss:0.706 AVG Training Acc 68.77 % AVG Validation Acc 60.14 %\n",
      "Split 234\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44b8b6ef19354af48ef5996f10f2bb60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.657 AVG Training Acc 61.81 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.664 AVG Training Acc 62.09 % AVG Validation Acc 61.05 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.640 AVG Validation Loss:0.661 AVG Training Acc 62.47 % AVG Validation Acc 59.78 %\n",
      "Epoch:40/200 AVG Training Loss:0.635 AVG Validation Loss:0.664 AVG Training Acc 63.12 % AVG Validation Acc 60.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.626 AVG Validation Loss:0.675 AVG Training Acc 63.64 % AVG Validation Acc 60.14 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.622 AVG Validation Loss:0.670 AVG Training Acc 63.91 % AVG Validation Acc 59.33 %\n",
      "Epoch:70/200 AVG Training Loss:0.620 AVG Validation Loss:0.672 AVG Training Acc 64.33 % AVG Validation Acc 59.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.618 AVG Validation Loss:0.675 AVG Training Acc 64.36 % AVG Validation Acc 60.05 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.618 AVG Validation Loss:0.673 AVG Training Acc 64.38 % AVG Validation Acc 60.50 %\n",
      "Epoch:100/200 AVG Training Loss:0.617 AVG Validation Loss:0.674 AVG Training Acc 64.42 % AVG Validation Acc 60.50 %\n",
      "Epoch:110/200 AVG Training Loss:0.618 AVG Validation Loss:0.676 AVG Training Acc 64.35 % AVG Validation Acc 60.41 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.619 AVG Validation Loss:0.675 AVG Training Acc 64.27 % AVG Validation Acc 60.23 %\n",
      "Epoch:130/200 AVG Training Loss:0.618 AVG Validation Loss:0.679 AVG Training Acc 64.40 % AVG Validation Acc 60.41 %\n",
      "Epoch:140/200 AVG Training Loss:0.618 AVG Validation Loss:0.681 AVG Training Acc 63.93 % AVG Validation Acc 60.78 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.618 AVG Validation Loss:0.675 AVG Training Acc 63.97 % AVG Validation Acc 60.23 %\n",
      "Epoch:160/200 AVG Training Loss:0.618 AVG Validation Loss:0.673 AVG Training Acc 64.57 % AVG Validation Acc 60.69 %\n",
      "Epoch:170/200 AVG Training Loss:0.616 AVG Validation Loss:0.678 AVG Training Acc 64.90 % AVG Validation Acc 60.50 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.618 AVG Validation Loss:0.675 AVG Training Acc 64.60 % AVG Validation Acc 60.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.618 AVG Validation Loss:0.675 AVG Training Acc 64.33 % AVG Validation Acc 60.87 %\n",
      "Epoch:200/200 AVG Training Loss:0.618 AVG Validation Loss:0.675 AVG Training Acc 64.60 % AVG Validation Acc 60.14 %\n",
      "Split 235\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "752972cdcf0f40c6ace134c9a7df305e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.656 AVG Validation Loss:0.662 AVG Training Acc 61.89 % AVG Validation Acc 61.86 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.665 AVG Validation Loss:0.664 AVG Training Acc 61.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.663 AVG Validation Loss:0.664 AVG Training Acc 61.93 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.661 AVG Validation Loss:0.662 AVG Training Acc 61.93 % AVG Validation Acc 61.86 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.658 AVG Validation Loss:0.661 AVG Training Acc 62.09 % AVG Validation Acc 61.86 %\n",
      "Epoch:60/200 AVG Training Loss:0.659 AVG Validation Loss:0.660 AVG Training Acc 61.98 % AVG Validation Acc 61.95 %\n",
      "Epoch:70/200 AVG Training Loss:0.657 AVG Validation Loss:0.661 AVG Training Acc 62.12 % AVG Validation Acc 62.04 %\n",
      "Epoch:80/200 AVG Training Loss:0.656 AVG Validation Loss:0.660 AVG Training Acc 62.20 % AVG Validation Acc 61.95 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.656 AVG Validation Loss:0.661 AVG Training Acc 62.06 % AVG Validation Acc 62.04 %\n",
      "Epoch:100/200 AVG Training Loss:0.657 AVG Validation Loss:0.661 AVG Training Acc 62.20 % AVG Validation Acc 62.04 %\n",
      "Epoch:110/200 AVG Training Loss:0.657 AVG Validation Loss:0.660 AVG Training Acc 62.09 % AVG Validation Acc 61.95 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.655 AVG Validation Loss:0.661 AVG Training Acc 62.19 % AVG Validation Acc 61.95 %\n",
      "Epoch:130/200 AVG Training Loss:0.658 AVG Validation Loss:0.660 AVG Training Acc 62.11 % AVG Validation Acc 61.95 %\n",
      "Epoch:140/200 AVG Training Loss:0.656 AVG Validation Loss:0.661 AVG Training Acc 62.12 % AVG Validation Acc 61.95 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.655 AVG Validation Loss:0.661 AVG Training Acc 62.10 % AVG Validation Acc 61.95 %\n",
      "Epoch:160/200 AVG Training Loss:0.656 AVG Validation Loss:0.661 AVG Training Acc 62.11 % AVG Validation Acc 61.95 %\n",
      "Epoch:170/200 AVG Training Loss:0.657 AVG Validation Loss:0.660 AVG Training Acc 62.15 % AVG Validation Acc 61.95 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.657 AVG Validation Loss:0.661 AVG Training Acc 62.04 % AVG Validation Acc 61.95 %\n",
      "Epoch:190/200 AVG Training Loss:0.657 AVG Validation Loss:0.661 AVG Training Acc 62.02 % AVG Validation Acc 61.95 %\n",
      "Epoch:200/200 AVG Training Loss:0.655 AVG Validation Loss:0.661 AVG Training Acc 62.11 % AVG Validation Acc 61.95 %\n",
      "Split 236\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "15c7dfa03ac84ef19b447e7ccd42b556",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.661 AVG Training Acc 61.71 % AVG Validation Acc 62.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.652 AVG Training Acc 61.82 % AVG Validation Acc 61.73 %\n",
      "Epoch:30/200 AVG Training Loss:0.642 AVG Validation Loss:0.655 AVG Training Acc 62.47 % AVG Validation Acc 61.28 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.616 AVG Validation Loss:0.655 AVG Training Acc 64.31 % AVG Validation Acc 62.73 %\n",
      "Epoch:50/200 AVG Training Loss:0.593 AVG Validation Loss:0.663 AVG Training Acc 66.63 % AVG Validation Acc 61.64 %\n",
      "Epoch:60/200 AVG Training Loss:0.582 AVG Validation Loss:0.680 AVG Training Acc 67.52 % AVG Validation Acc 60.74 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.572 AVG Validation Loss:0.693 AVG Training Acc 67.86 % AVG Validation Acc 61.28 %\n",
      "Epoch:80/200 AVG Training Loss:0.565 AVG Validation Loss:0.695 AVG Training Acc 68.45 % AVG Validation Acc 60.38 %\n",
      "Epoch:90/200 AVG Training Loss:0.562 AVG Validation Loss:0.697 AVG Training Acc 69.07 % AVG Validation Acc 60.20 %\n",
      "Epoch:100/200 AVG Training Loss:0.565 AVG Validation Loss:0.700 AVG Training Acc 68.76 % AVG Validation Acc 60.56 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.562 AVG Validation Loss:0.693 AVG Training Acc 68.41 % AVG Validation Acc 61.10 %\n",
      "Epoch:120/200 AVG Training Loss:0.561 AVG Validation Loss:0.696 AVG Training Acc 68.48 % AVG Validation Acc 60.02 %\n",
      "Epoch:130/200 AVG Training Loss:0.561 AVG Validation Loss:0.698 AVG Training Acc 69.00 % AVG Validation Acc 60.29 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.563 AVG Validation Loss:0.699 AVG Training Acc 68.83 % AVG Validation Acc 59.66 %\n",
      "Epoch:150/200 AVG Training Loss:0.563 AVG Validation Loss:0.695 AVG Training Acc 69.04 % AVG Validation Acc 60.11 %\n",
      "Epoch:160/200 AVG Training Loss:0.563 AVG Validation Loss:0.698 AVG Training Acc 68.78 % AVG Validation Acc 60.56 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.564 AVG Validation Loss:0.694 AVG Training Acc 68.85 % AVG Validation Acc 60.20 %\n",
      "Epoch:180/200 AVG Training Loss:0.563 AVG Validation Loss:0.695 AVG Training Acc 68.93 % AVG Validation Acc 60.11 %\n",
      "Epoch:190/200 AVG Training Loss:0.562 AVG Validation Loss:0.696 AVG Training Acc 68.89 % AVG Validation Acc 59.66 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.562 AVG Validation Loss:0.695 AVG Training Acc 68.71 % AVG Validation Acc 60.20 %\n",
      "Split 237\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "751eac91345c4c1d94cec9ba1e7029d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.663 AVG Training Acc 61.76 % AVG Validation Acc 61.73 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.658 AVG Training Acc 61.96 % AVG Validation Acc 61.28 %\n",
      "Epoch:30/200 AVG Training Loss:0.646 AVG Validation Loss:0.657 AVG Training Acc 62.74 % AVG Validation Acc 62.27 %\n",
      "Epoch:40/200 AVG Training Loss:0.635 AVG Validation Loss:0.653 AVG Training Acc 62.82 % AVG Validation Acc 61.73 %\n",
      "Epoch:50/200 AVG Training Loss:0.626 AVG Validation Loss:0.675 AVG Training Acc 62.95 % AVG Validation Acc 60.83 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.592 AVG Validation Loss:0.689 AVG Training Acc 65.80 % AVG Validation Acc 61.19 %\n",
      "Epoch:70/200 AVG Training Loss:0.579 AVG Validation Loss:0.694 AVG Training Acc 66.53 % AVG Validation Acc 61.19 %\n",
      "Epoch:80/200 AVG Training Loss:0.577 AVG Validation Loss:0.707 AVG Training Acc 66.23 % AVG Validation Acc 61.10 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.567 AVG Validation Loss:0.710 AVG Training Acc 66.81 % AVG Validation Acc 61.73 %\n",
      "Epoch:100/200 AVG Training Loss:0.568 AVG Validation Loss:0.709 AVG Training Acc 67.38 % AVG Validation Acc 61.91 %\n",
      "Epoch:110/200 AVG Training Loss:0.564 AVG Validation Loss:0.713 AVG Training Acc 67.21 % AVG Validation Acc 61.91 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.566 AVG Validation Loss:0.712 AVG Training Acc 67.51 % AVG Validation Acc 61.91 %\n",
      "Epoch:130/200 AVG Training Loss:0.564 AVG Validation Loss:0.710 AVG Training Acc 67.75 % AVG Validation Acc 62.27 %\n",
      "Epoch:140/200 AVG Training Loss:0.565 AVG Validation Loss:0.714 AVG Training Acc 67.52 % AVG Validation Acc 61.64 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.565 AVG Validation Loss:0.712 AVG Training Acc 67.59 % AVG Validation Acc 61.28 %\n",
      "Epoch:160/200 AVG Training Loss:0.566 AVG Validation Loss:0.714 AVG Training Acc 67.28 % AVG Validation Acc 61.46 %\n",
      "Epoch:170/200 AVG Training Loss:0.564 AVG Validation Loss:0.710 AVG Training Acc 67.13 % AVG Validation Acc 61.55 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.567 AVG Validation Loss:0.714 AVG Training Acc 67.03 % AVG Validation Acc 61.28 %\n",
      "Epoch:190/200 AVG Training Loss:0.565 AVG Validation Loss:0.715 AVG Training Acc 67.51 % AVG Validation Acc 61.28 %\n",
      "Epoch:200/200 AVG Training Loss:0.563 AVG Validation Loss:0.710 AVG Training Acc 67.30 % AVG Validation Acc 60.65 %\n",
      "Split 238\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a13a20a4b3d42dfac858873b53f3777",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.657 AVG Validation Loss:0.669 AVG Training Acc 61.88 % AVG Validation Acc 61.82 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.644 AVG Validation Loss:0.669 AVG Training Acc 62.12 % AVG Validation Acc 61.82 %\n",
      "Epoch:30/200 AVG Training Loss:0.634 AVG Validation Loss:0.670 AVG Training Acc 62.65 % AVG Validation Acc 62.27 %\n",
      "Epoch:40/200 AVG Training Loss:0.629 AVG Validation Loss:0.677 AVG Training Acc 63.33 % AVG Validation Acc 62.27 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.614 AVG Validation Loss:0.683 AVG Training Acc 64.48 % AVG Validation Acc 62.36 %\n",
      "Epoch:60/200 AVG Training Loss:0.612 AVG Validation Loss:0.684 AVG Training Acc 64.75 % AVG Validation Acc 62.91 %\n",
      "Epoch:70/200 AVG Training Loss:0.611 AVG Validation Loss:0.682 AVG Training Acc 64.79 % AVG Validation Acc 62.73 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.610 AVG Validation Loss:0.686 AVG Training Acc 64.92 % AVG Validation Acc 62.18 %\n",
      "Epoch:90/200 AVG Training Loss:0.611 AVG Validation Loss:0.686 AVG Training Acc 64.54 % AVG Validation Acc 62.18 %\n",
      "Epoch:100/200 AVG Training Loss:0.610 AVG Validation Loss:0.689 AVG Training Acc 64.85 % AVG Validation Acc 62.09 %\n",
      "Epoch:110/200 AVG Training Loss:0.610 AVG Validation Loss:0.687 AVG Training Acc 64.77 % AVG Validation Acc 63.00 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.610 AVG Validation Loss:0.686 AVG Training Acc 65.05 % AVG Validation Acc 62.73 %\n",
      "Epoch:130/200 AVG Training Loss:0.608 AVG Validation Loss:0.689 AVG Training Acc 64.91 % AVG Validation Acc 62.18 %\n",
      "Epoch:140/200 AVG Training Loss:0.609 AVG Validation Loss:0.688 AVG Training Acc 64.98 % AVG Validation Acc 62.45 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.610 AVG Validation Loss:0.688 AVG Training Acc 65.20 % AVG Validation Acc 62.36 %\n",
      "Epoch:160/200 AVG Training Loss:0.608 AVG Validation Loss:0.686 AVG Training Acc 64.59 % AVG Validation Acc 62.36 %\n",
      "Epoch:170/200 AVG Training Loss:0.608 AVG Validation Loss:0.688 AVG Training Acc 64.86 % AVG Validation Acc 62.45 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.609 AVG Validation Loss:0.688 AVG Training Acc 64.72 % AVG Validation Acc 62.64 %\n",
      "Epoch:190/200 AVG Training Loss:0.609 AVG Validation Loss:0.685 AVG Training Acc 64.82 % AVG Validation Acc 62.27 %\n",
      "Epoch:200/200 AVG Training Loss:0.609 AVG Validation Loss:0.684 AVG Training Acc 64.41 % AVG Validation Acc 62.73 %\n",
      "Split 239\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26615448305347149ce4e446531e6c3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.655 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.650 AVG Training Acc 61.94 % AVG Validation Acc 62.27 %\n",
      "Epoch:30/200 AVG Training Loss:0.650 AVG Validation Loss:0.652 AVG Training Acc 62.03 % AVG Validation Acc 62.73 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.632 AVG Validation Loss:0.651 AVG Training Acc 62.97 % AVG Validation Acc 62.64 %\n",
      "Epoch:50/200 AVG Training Loss:0.624 AVG Validation Loss:0.656 AVG Training Acc 63.62 % AVG Validation Acc 62.73 %\n",
      "Epoch:60/200 AVG Training Loss:0.617 AVG Validation Loss:0.666 AVG Training Acc 64.28 % AVG Validation Acc 62.27 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.611 AVG Validation Loss:0.667 AVG Training Acc 64.97 % AVG Validation Acc 62.18 %\n",
      "Epoch:80/200 AVG Training Loss:0.610 AVG Validation Loss:0.666 AVG Training Acc 64.45 % AVG Validation Acc 62.45 %\n",
      "Epoch:90/200 AVG Training Loss:0.610 AVG Validation Loss:0.669 AVG Training Acc 65.06 % AVG Validation Acc 62.00 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.608 AVG Validation Loss:0.670 AVG Training Acc 65.26 % AVG Validation Acc 61.91 %\n",
      "Epoch:110/200 AVG Training Loss:0.610 AVG Validation Loss:0.672 AVG Training Acc 64.64 % AVG Validation Acc 62.18 %\n",
      "Epoch:120/200 AVG Training Loss:0.609 AVG Validation Loss:0.670 AVG Training Acc 64.48 % AVG Validation Acc 62.18 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.607 AVG Validation Loss:0.673 AVG Training Acc 64.72 % AVG Validation Acc 62.45 %\n",
      "Epoch:140/200 AVG Training Loss:0.609 AVG Validation Loss:0.672 AVG Training Acc 64.63 % AVG Validation Acc 62.18 %\n",
      "Epoch:150/200 AVG Training Loss:0.609 AVG Validation Loss:0.679 AVG Training Acc 64.89 % AVG Validation Acc 62.09 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.609 AVG Validation Loss:0.669 AVG Training Acc 64.61 % AVG Validation Acc 62.09 %\n",
      "Epoch:170/200 AVG Training Loss:0.609 AVG Validation Loss:0.669 AVG Training Acc 64.37 % AVG Validation Acc 61.82 %\n",
      "Epoch:180/200 AVG Training Loss:0.608 AVG Validation Loss:0.670 AVG Training Acc 65.00 % AVG Validation Acc 62.36 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.610 AVG Validation Loss:0.674 AVG Training Acc 64.78 % AVG Validation Acc 61.91 %\n",
      "Epoch:200/200 AVG Training Loss:0.609 AVG Validation Loss:0.675 AVG Training Acc 64.88 % AVG Validation Acc 61.82 %\n",
      "Split 240\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a6f5a20f02b4a41b1ac6a6d08b47dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.656 AVG Training Acc 61.80 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.650 AVG Training Acc 61.90 % AVG Validation Acc 62.18 %\n",
      "Epoch:30/200 AVG Training Loss:0.644 AVG Validation Loss:0.658 AVG Training Acc 62.46 % AVG Validation Acc 61.37 %\n",
      "Epoch:40/200 AVG Training Loss:0.632 AVG Validation Loss:0.645 AVG Training Acc 63.51 % AVG Validation Acc 62.27 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.601 AVG Validation Loss:0.666 AVG Training Acc 66.16 % AVG Validation Acc 62.09 %\n",
      "Epoch:60/200 AVG Training Loss:0.579 AVG Validation Loss:0.686 AVG Training Acc 67.98 % AVG Validation Acc 62.00 %\n",
      "Epoch:70/200 AVG Training Loss:0.564 AVG Validation Loss:0.714 AVG Training Acc 69.12 % AVG Validation Acc 60.83 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.553 AVG Validation Loss:0.726 AVG Training Acc 70.27 % AVG Validation Acc 60.83 %\n",
      "Epoch:90/200 AVG Training Loss:0.547 AVG Validation Loss:0.741 AVG Training Acc 70.83 % AVG Validation Acc 60.56 %\n",
      "Epoch:100/200 AVG Training Loss:0.544 AVG Validation Loss:0.748 AVG Training Acc 70.95 % AVG Validation Acc 60.11 %\n",
      "Epoch:110/200 AVG Training Loss:0.544 AVG Validation Loss:0.748 AVG Training Acc 70.73 % AVG Validation Acc 60.92 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.543 AVG Validation Loss:0.734 AVG Training Acc 70.80 % AVG Validation Acc 60.83 %\n",
      "Epoch:130/200 AVG Training Loss:0.545 AVG Validation Loss:0.739 AVG Training Acc 70.63 % AVG Validation Acc 61.10 %\n",
      "Epoch:140/200 AVG Training Loss:0.542 AVG Validation Loss:0.739 AVG Training Acc 70.90 % AVG Validation Acc 59.93 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.541 AVG Validation Loss:0.737 AVG Training Acc 71.33 % AVG Validation Acc 60.74 %\n",
      "Epoch:160/200 AVG Training Loss:0.545 AVG Validation Loss:0.749 AVG Training Acc 70.64 % AVG Validation Acc 60.29 %\n",
      "Epoch:170/200 AVG Training Loss:0.543 AVG Validation Loss:0.733 AVG Training Acc 70.68 % AVG Validation Acc 60.38 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.543 AVG Validation Loss:0.737 AVG Training Acc 70.56 % AVG Validation Acc 60.11 %\n",
      "Epoch:190/200 AVG Training Loss:0.543 AVG Validation Loss:0.738 AVG Training Acc 70.63 % AVG Validation Acc 60.47 %\n",
      "Epoch:200/200 AVG Training Loss:0.544 AVG Validation Loss:0.734 AVG Training Acc 70.88 % AVG Validation Acc 60.38 %\n",
      "Split 241\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98f5d4236a18424bb53cd007e22bf5ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.660 AVG Training Acc 61.78 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.655 AVG Training Acc 61.59 % AVG Validation Acc 62.40 %\n",
      "Epoch:30/200 AVG Training Loss:0.648 AVG Validation Loss:0.652 AVG Training Acc 61.75 % AVG Validation Acc 62.58 %\n",
      "Epoch:40/200 AVG Training Loss:0.645 AVG Validation Loss:0.652 AVG Training Acc 62.34 % AVG Validation Acc 61.41 %\n",
      "Epoch:50/200 AVG Training Loss:0.640 AVG Validation Loss:0.654 AVG Training Acc 62.32 % AVG Validation Acc 61.86 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.624 AVG Validation Loss:0.659 AVG Training Acc 63.39 % AVG Validation Acc 61.59 %\n",
      "Epoch:70/200 AVG Training Loss:0.612 AVG Validation Loss:0.672 AVG Training Acc 64.60 % AVG Validation Acc 61.59 %\n",
      "Epoch:80/200 AVG Training Loss:0.608 AVG Validation Loss:0.685 AVG Training Acc 64.43 % AVG Validation Acc 60.60 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.596 AVG Validation Loss:0.693 AVG Training Acc 65.48 % AVG Validation Acc 59.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.594 AVG Validation Loss:0.693 AVG Training Acc 65.96 % AVG Validation Acc 60.32 %\n",
      "Epoch:110/200 AVG Training Loss:0.595 AVG Validation Loss:0.698 AVG Training Acc 65.86 % AVG Validation Acc 60.32 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.591 AVG Validation Loss:0.700 AVG Training Acc 65.70 % AVG Validation Acc 59.87 %\n",
      "Epoch:130/200 AVG Training Loss:0.595 AVG Validation Loss:0.704 AVG Training Acc 65.52 % AVG Validation Acc 59.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.591 AVG Validation Loss:0.711 AVG Training Acc 65.75 % AVG Validation Acc 59.51 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.594 AVG Validation Loss:0.698 AVG Training Acc 65.30 % AVG Validation Acc 60.32 %\n",
      "Epoch:160/200 AVG Training Loss:0.592 AVG Validation Loss:0.707 AVG Training Acc 66.74 % AVG Validation Acc 59.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.592 AVG Validation Loss:0.698 AVG Training Acc 65.73 % AVG Validation Acc 60.41 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.591 AVG Validation Loss:0.698 AVG Training Acc 66.23 % AVG Validation Acc 60.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.593 AVG Validation Loss:0.699 AVG Training Acc 65.90 % AVG Validation Acc 60.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.593 AVG Validation Loss:0.705 AVG Training Acc 65.78 % AVG Validation Acc 60.69 %\n",
      "Split 242\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a09daae8c44ce6b8f7ed1cdab8a9df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.654 AVG Training Acc 61.73 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.654 AVG Training Acc 62.01 % AVG Validation Acc 62.40 %\n",
      "Epoch:30/200 AVG Training Loss:0.646 AVG Validation Loss:0.656 AVG Training Acc 62.31 % AVG Validation Acc 62.13 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.627 AVG Validation Loss:0.664 AVG Training Acc 63.96 % AVG Validation Acc 60.50 %\n",
      "Epoch:50/200 AVG Training Loss:0.613 AVG Validation Loss:0.677 AVG Training Acc 64.81 % AVG Validation Acc 59.33 %\n",
      "Epoch:60/200 AVG Training Loss:0.601 AVG Validation Loss:0.690 AVG Training Acc 66.08 % AVG Validation Acc 59.60 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.595 AVG Validation Loss:0.695 AVG Training Acc 66.30 % AVG Validation Acc 58.97 %\n",
      "Epoch:80/200 AVG Training Loss:0.595 AVG Validation Loss:0.691 AVG Training Acc 66.08 % AVG Validation Acc 58.97 %\n",
      "Epoch:90/200 AVG Training Loss:0.594 AVG Validation Loss:0.698 AVG Training Acc 66.40 % AVG Validation Acc 58.79 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.594 AVG Validation Loss:0.695 AVG Training Acc 66.44 % AVG Validation Acc 59.51 %\n",
      "Epoch:110/200 AVG Training Loss:0.594 AVG Validation Loss:0.697 AVG Training Acc 66.48 % AVG Validation Acc 59.69 %\n",
      "Epoch:120/200 AVG Training Loss:0.591 AVG Validation Loss:0.692 AVG Training Acc 66.75 % AVG Validation Acc 59.78 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.594 AVG Validation Loss:0.697 AVG Training Acc 66.53 % AVG Validation Acc 59.51 %\n",
      "Epoch:140/200 AVG Training Loss:0.592 AVG Validation Loss:0.700 AVG Training Acc 66.39 % AVG Validation Acc 58.88 %\n",
      "Epoch:150/200 AVG Training Loss:0.591 AVG Validation Loss:0.698 AVG Training Acc 66.03 % AVG Validation Acc 59.33 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.592 AVG Validation Loss:0.693 AVG Training Acc 66.50 % AVG Validation Acc 58.88 %\n",
      "Epoch:170/200 AVG Training Loss:0.591 AVG Validation Loss:0.696 AVG Training Acc 66.84 % AVG Validation Acc 59.24 %\n",
      "Epoch:180/200 AVG Training Loss:0.594 AVG Validation Loss:0.693 AVG Training Acc 66.12 % AVG Validation Acc 58.88 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.593 AVG Validation Loss:0.696 AVG Training Acc 66.21 % AVG Validation Acc 59.15 %\n",
      "Epoch:200/200 AVG Training Loss:0.592 AVG Validation Loss:0.697 AVG Training Acc 66.63 % AVG Validation Acc 58.88 %\n",
      "Split 243\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b6afffbe4504e29822ce0eefa3aed82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.660 AVG Training Acc 62.01 % AVG Validation Acc 61.77 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.658 AVG Training Acc 62.08 % AVG Validation Acc 61.68 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.636 AVG Validation Loss:0.666 AVG Training Acc 63.36 % AVG Validation Acc 61.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.626 AVG Validation Loss:0.675 AVG Training Acc 64.13 % AVG Validation Acc 61.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.615 AVG Validation Loss:0.684 AVG Training Acc 64.63 % AVG Validation Acc 60.14 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.608 AVG Validation Loss:0.689 AVG Training Acc 65.37 % AVG Validation Acc 58.52 %\n",
      "Epoch:70/200 AVG Training Loss:0.608 AVG Validation Loss:0.692 AVG Training Acc 64.84 % AVG Validation Acc 58.88 %\n",
      "Epoch:80/200 AVG Training Loss:0.608 AVG Validation Loss:0.694 AVG Training Acc 64.79 % AVG Validation Acc 59.06 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.606 AVG Validation Loss:0.692 AVG Training Acc 65.38 % AVG Validation Acc 58.79 %\n",
      "Epoch:100/200 AVG Training Loss:0.606 AVG Validation Loss:0.694 AVG Training Acc 65.16 % AVG Validation Acc 58.61 %\n",
      "Epoch:110/200 AVG Training Loss:0.605 AVG Validation Loss:0.695 AVG Training Acc 65.57 % AVG Validation Acc 58.43 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.606 AVG Validation Loss:0.696 AVG Training Acc 65.83 % AVG Validation Acc 58.25 %\n",
      "Epoch:130/200 AVG Training Loss:0.605 AVG Validation Loss:0.694 AVG Training Acc 65.39 % AVG Validation Acc 58.52 %\n",
      "Epoch:140/200 AVG Training Loss:0.605 AVG Validation Loss:0.693 AVG Training Acc 65.17 % AVG Validation Acc 58.97 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.606 AVG Validation Loss:0.696 AVG Training Acc 65.26 % AVG Validation Acc 57.98 %\n",
      "Epoch:160/200 AVG Training Loss:0.605 AVG Validation Loss:0.696 AVG Training Acc 65.34 % AVG Validation Acc 58.43 %\n",
      "Epoch:170/200 AVG Training Loss:0.606 AVG Validation Loss:0.694 AVG Training Acc 65.51 % AVG Validation Acc 58.61 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.605 AVG Validation Loss:0.693 AVG Training Acc 65.24 % AVG Validation Acc 58.34 %\n",
      "Epoch:190/200 AVG Training Loss:0.606 AVG Validation Loss:0.694 AVG Training Acc 65.30 % AVG Validation Acc 58.43 %\n",
      "Epoch:200/200 AVG Training Loss:0.605 AVG Validation Loss:0.696 AVG Training Acc 65.72 % AVG Validation Acc 58.43 %\n",
      "Split 244\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "636f31fff2a74c068d2ecc372f373648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.659 AVG Training Acc 61.84 % AVG Validation Acc 61.59 %\n",
      "Epoch:20/200 AVG Training Loss:0.650 AVG Validation Loss:0.659 AVG Training Acc 62.43 % AVG Validation Acc 61.41 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.634 AVG Validation Loss:0.665 AVG Training Acc 62.93 % AVG Validation Acc 61.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.621 AVG Validation Loss:0.676 AVG Training Acc 63.99 % AVG Validation Acc 61.50 %\n",
      "Epoch:50/200 AVG Training Loss:0.613 AVG Validation Loss:0.688 AVG Training Acc 64.27 % AVG Validation Acc 61.59 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.604 AVG Validation Loss:0.698 AVG Training Acc 65.13 % AVG Validation Acc 61.59 %\n",
      "Epoch:70/200 AVG Training Loss:0.604 AVG Validation Loss:0.713 AVG Training Acc 65.30 % AVG Validation Acc 61.23 %\n",
      "Epoch:80/200 AVG Training Loss:0.604 AVG Validation Loss:0.715 AVG Training Acc 64.85 % AVG Validation Acc 60.87 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.601 AVG Validation Loss:0.710 AVG Training Acc 65.38 % AVG Validation Acc 61.41 %\n",
      "Epoch:100/200 AVG Training Loss:0.600 AVG Validation Loss:0.716 AVG Training Acc 65.54 % AVG Validation Acc 61.68 %\n",
      "Epoch:110/200 AVG Training Loss:0.602 AVG Validation Loss:0.717 AVG Training Acc 65.00 % AVG Validation Acc 61.41 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.600 AVG Validation Loss:0.716 AVG Training Acc 65.35 % AVG Validation Acc 61.41 %\n",
      "Epoch:130/200 AVG Training Loss:0.601 AVG Validation Loss:0.712 AVG Training Acc 65.10 % AVG Validation Acc 61.50 %\n",
      "Epoch:140/200 AVG Training Loss:0.599 AVG Validation Loss:0.717 AVG Training Acc 65.33 % AVG Validation Acc 61.05 %\n",
      "Epoch:150/200 AVG Training Loss:0.601 AVG Validation Loss:0.722 AVG Training Acc 65.19 % AVG Validation Acc 61.23 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.600 AVG Validation Loss:0.715 AVG Training Acc 65.31 % AVG Validation Acc 61.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.601 AVG Validation Loss:0.712 AVG Training Acc 65.03 % AVG Validation Acc 61.50 %\n",
      "Epoch:180/200 AVG Training Loss:0.600 AVG Validation Loss:0.709 AVG Training Acc 65.52 % AVG Validation Acc 61.41 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.599 AVG Validation Loss:0.720 AVG Training Acc 65.49 % AVG Validation Acc 60.96 %\n",
      "Epoch:200/200 AVG Training Loss:0.601 AVG Validation Loss:0.713 AVG Training Acc 65.16 % AVG Validation Acc 61.14 %\n",
      "Split 245\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab88c4f358ff4b5fa2d4e84dfa34a6cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.657 AVG Training Acc 61.87 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.658 AVG Training Acc 61.90 % AVG Validation Acc 61.77 %\n",
      "Epoch:30/200 AVG Training Loss:0.647 AVG Validation Loss:0.653 AVG Training Acc 62.12 % AVG Validation Acc 62.04 %\n",
      "Epoch:40/200 AVG Training Loss:0.641 AVG Validation Loss:0.660 AVG Training Acc 62.41 % AVG Validation Acc 61.50 %\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.612 AVG Validation Loss:0.678 AVG Training Acc 64.75 % AVG Validation Acc 61.95 %\n",
      "Epoch:60/200 AVG Training Loss:0.602 AVG Validation Loss:0.709 AVG Training Acc 65.09 % AVG Validation Acc 61.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.593 AVG Validation Loss:0.720 AVG Training Acc 65.60 % AVG Validation Acc 61.23 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.584 AVG Validation Loss:0.723 AVG Training Acc 66.36 % AVG Validation Acc 61.50 %\n",
      "Epoch:90/200 AVG Training Loss:0.581 AVG Validation Loss:0.736 AVG Training Acc 66.97 % AVG Validation Acc 60.69 %\n",
      "Epoch:100/200 AVG Training Loss:0.581 AVG Validation Loss:0.734 AVG Training Acc 66.68 % AVG Validation Acc 60.87 %\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.583 AVG Validation Loss:0.733 AVG Training Acc 66.70 % AVG Validation Acc 61.32 %\n",
      "Epoch:120/200 AVG Training Loss:0.578 AVG Validation Loss:0.731 AVG Training Acc 67.32 % AVG Validation Acc 60.78 %\n",
      "Epoch:130/200 AVG Training Loss:0.581 AVG Validation Loss:0.736 AVG Training Acc 66.78 % AVG Validation Acc 60.78 %\n",
      "Epoch   134: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.581 AVG Validation Loss:0.724 AVG Training Acc 66.62 % AVG Validation Acc 61.59 %\n",
      "Epoch:150/200 AVG Training Loss:0.580 AVG Validation Loss:0.736 AVG Training Acc 66.95 % AVG Validation Acc 60.96 %\n",
      "Epoch:160/200 AVG Training Loss:0.580 AVG Validation Loss:0.729 AVG Training Acc 66.53 % AVG Validation Acc 60.87 %\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.579 AVG Validation Loss:0.728 AVG Training Acc 66.81 % AVG Validation Acc 60.78 %\n",
      "Epoch:180/200 AVG Training Loss:0.582 AVG Validation Loss:0.730 AVG Training Acc 66.66 % AVG Validation Acc 60.69 %\n",
      "Epoch:190/200 AVG Training Loss:0.581 AVG Validation Loss:0.736 AVG Training Acc 66.60 % AVG Validation Acc 60.69 %\n",
      "Epoch   196: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.581 AVG Validation Loss:0.728 AVG Training Acc 66.46 % AVG Validation Acc 61.41 %\n",
      "Split 246\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22535713b3bc4a15ad0329706e3982aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.658 AVG Training Acc 61.87 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.659 AVG Training Acc 61.97 % AVG Validation Acc 62.09 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.641 AVG Validation Loss:0.660 AVG Training Acc 62.78 % AVG Validation Acc 60.65 %\n",
      "Epoch:40/200 AVG Training Loss:0.630 AVG Validation Loss:0.669 AVG Training Acc 62.78 % AVG Validation Acc 61.28 %\n",
      "Epoch:50/200 AVG Training Loss:0.620 AVG Validation Loss:0.681 AVG Training Acc 63.63 % AVG Validation Acc 61.01 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.615 AVG Validation Loss:0.689 AVG Training Acc 64.20 % AVG Validation Acc 60.56 %\n",
      "Epoch:70/200 AVG Training Loss:0.612 AVG Validation Loss:0.690 AVG Training Acc 64.41 % AVG Validation Acc 60.29 %\n",
      "Epoch:80/200 AVG Training Loss:0.611 AVG Validation Loss:0.693 AVG Training Acc 64.47 % AVG Validation Acc 59.66 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.607 AVG Validation Loss:0.694 AVG Training Acc 64.76 % AVG Validation Acc 60.38 %\n",
      "Epoch:100/200 AVG Training Loss:0.608 AVG Validation Loss:0.700 AVG Training Acc 64.44 % AVG Validation Acc 60.02 %\n",
      "Epoch:110/200 AVG Training Loss:0.607 AVG Validation Loss:0.697 AVG Training Acc 64.28 % AVG Validation Acc 60.65 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.608 AVG Validation Loss:0.693 AVG Training Acc 64.59 % AVG Validation Acc 61.10 %\n",
      "Epoch:130/200 AVG Training Loss:0.609 AVG Validation Loss:0.696 AVG Training Acc 64.39 % AVG Validation Acc 60.65 %\n",
      "Epoch:140/200 AVG Training Loss:0.610 AVG Validation Loss:0.698 AVG Training Acc 64.33 % AVG Validation Acc 60.20 %\n",
      "Epoch:150/200 AVG Training Loss:0.611 AVG Validation Loss:0.696 AVG Training Acc 64.58 % AVG Validation Acc 59.57 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.607 AVG Validation Loss:0.694 AVG Training Acc 64.62 % AVG Validation Acc 60.92 %\n",
      "Epoch:170/200 AVG Training Loss:0.607 AVG Validation Loss:0.698 AVG Training Acc 64.29 % AVG Validation Acc 61.01 %\n",
      "Epoch:180/200 AVG Training Loss:0.610 AVG Validation Loss:0.697 AVG Training Acc 64.21 % AVG Validation Acc 60.20 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.609 AVG Validation Loss:0.694 AVG Training Acc 64.41 % AVG Validation Acc 60.47 %\n",
      "Epoch:200/200 AVG Training Loss:0.609 AVG Validation Loss:0.696 AVG Training Acc 64.83 % AVG Validation Acc 60.20 %\n",
      "Split 247\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22922594be714fafa97c3cc664ed0204",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.654 AVG Training Acc 61.70 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:0.653 AVG Training Acc 61.93 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.649 AVG Validation Loss:0.652 AVG Training Acc 62.26 % AVG Validation Acc 61.64 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.631 AVG Validation Loss:0.661 AVG Training Acc 63.20 % AVG Validation Acc 60.02 %\n",
      "Epoch:50/200 AVG Training Loss:0.624 AVG Validation Loss:0.664 AVG Training Acc 63.82 % AVG Validation Acc 60.20 %\n",
      "Epoch:60/200 AVG Training Loss:0.618 AVG Validation Loss:0.668 AVG Training Acc 64.34 % AVG Validation Acc 59.93 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.612 AVG Validation Loss:0.665 AVG Training Acc 65.31 % AVG Validation Acc 59.57 %\n",
      "Epoch:80/200 AVG Training Loss:0.612 AVG Validation Loss:0.668 AVG Training Acc 64.61 % AVG Validation Acc 59.66 %\n",
      "Epoch:90/200 AVG Training Loss:0.611 AVG Validation Loss:0.677 AVG Training Acc 64.84 % AVG Validation Acc 59.39 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.612 AVG Validation Loss:0.670 AVG Training Acc 64.71 % AVG Validation Acc 59.75 %\n",
      "Epoch:110/200 AVG Training Loss:0.610 AVG Validation Loss:0.670 AVG Training Acc 64.95 % AVG Validation Acc 59.84 %\n",
      "Epoch:120/200 AVG Training Loss:0.610 AVG Validation Loss:0.675 AVG Training Acc 64.69 % AVG Validation Acc 58.94 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.610 AVG Validation Loss:0.669 AVG Training Acc 64.97 % AVG Validation Acc 60.11 %\n",
      "Epoch:140/200 AVG Training Loss:0.613 AVG Validation Loss:0.673 AVG Training Acc 64.74 % AVG Validation Acc 58.94 %\n",
      "Epoch:150/200 AVG Training Loss:0.612 AVG Validation Loss:0.672 AVG Training Acc 65.18 % AVG Validation Acc 59.66 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.611 AVG Validation Loss:0.671 AVG Training Acc 65.01 % AVG Validation Acc 59.21 %\n",
      "Epoch:170/200 AVG Training Loss:0.611 AVG Validation Loss:0.675 AVG Training Acc 64.77 % AVG Validation Acc 59.39 %\n",
      "Epoch:180/200 AVG Training Loss:0.610 AVG Validation Loss:0.677 AVG Training Acc 64.86 % AVG Validation Acc 59.48 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.611 AVG Validation Loss:0.671 AVG Training Acc 65.13 % AVG Validation Acc 59.57 %\n",
      "Epoch:200/200 AVG Training Loss:0.611 AVG Validation Loss:0.670 AVG Training Acc 65.09 % AVG Validation Acc 59.12 %\n",
      "Split 248\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d5b3ff8fbf24aea8c106ab43e7bd99a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.654 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.650 AVG Validation Loss:0.658 AVG Training Acc 61.96 % AVG Validation Acc 61.73 %\n",
      "Epoch:30/200 AVG Training Loss:0.665 AVG Validation Loss:0.673 AVG Training Acc 61.30 % AVG Validation Acc 61.91 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.664 AVG Validation Loss:0.664 AVG Training Acc 61.91 % AVG Validation Acc 61.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.665 AVG Validation Loss:0.662 AVG Training Acc 61.91 % AVG Validation Acc 61.91 %\n",
      "Epoch:60/200 AVG Training Loss:0.664 AVG Validation Loss:0.662 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.664 AVG Validation Loss:0.662 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch:80/200 AVG Training Loss:0.663 AVG Validation Loss:0.660 AVG Training Acc 61.91 % AVG Validation Acc 61.91 %\n",
      "Epoch:90/200 AVG Training Loss:0.663 AVG Validation Loss:0.661 AVG Training Acc 61.95 % AVG Validation Acc 61.91 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.663 AVG Validation Loss:0.661 AVG Training Acc 61.87 % AVG Validation Acc 61.91 %\n",
      "Epoch:110/200 AVG Training Loss:0.663 AVG Validation Loss:0.660 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch:120/200 AVG Training Loss:0.663 AVG Validation Loss:0.660 AVG Training Acc 61.91 % AVG Validation Acc 61.91 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.663 AVG Validation Loss:0.661 AVG Training Acc 61.92 % AVG Validation Acc 61.91 %\n",
      "Epoch:140/200 AVG Training Loss:0.663 AVG Validation Loss:0.661 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Epoch:150/200 AVG Training Loss:0.663 AVG Validation Loss:0.661 AVG Training Acc 61.93 % AVG Validation Acc 61.91 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.663 AVG Validation Loss:0.660 AVG Training Acc 61.91 % AVG Validation Acc 61.91 %\n",
      "Epoch:170/200 AVG Training Loss:0.663 AVG Validation Loss:0.661 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch:180/200 AVG Training Loss:0.663 AVG Validation Loss:0.661 AVG Training Acc 61.92 % AVG Validation Acc 61.91 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.663 AVG Validation Loss:0.661 AVG Training Acc 61.86 % AVG Validation Acc 61.91 %\n",
      "Epoch:200/200 AVG Training Loss:0.663 AVG Validation Loss:0.661 AVG Training Acc 61.86 % AVG Validation Acc 61.91 %\n",
      "Split 249\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daff3920b25a4acdbb5a49300f116f75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 61.86 % AVG Validation Acc 61.82 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.656 AVG Training Acc 61.82 % AVG Validation Acc 61.82 %\n",
      "Epoch:30/200 AVG Training Loss:0.665 AVG Validation Loss:0.666 AVG Training Acc 61.84 % AVG Validation Acc 61.91 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.660 AVG Validation Loss:0.664 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.660 AVG Validation Loss:0.667 AVG Training Acc 61.87 % AVG Validation Acc 61.91 %\n",
      "Epoch:60/200 AVG Training Loss:0.656 AVG Validation Loss:0.664 AVG Training Acc 61.87 % AVG Validation Acc 61.91 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.654 AVG Validation Loss:0.665 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch:80/200 AVG Training Loss:0.653 AVG Validation Loss:0.665 AVG Training Acc 61.96 % AVG Validation Acc 61.91 %\n",
      "Epoch:90/200 AVG Training Loss:0.653 AVG Validation Loss:0.666 AVG Training Acc 62.01 % AVG Validation Acc 62.00 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.652 AVG Validation Loss:0.667 AVG Training Acc 61.90 % AVG Validation Acc 62.00 %\n",
      "Epoch:110/200 AVG Training Loss:0.653 AVG Validation Loss:0.667 AVG Training Acc 61.92 % AVG Validation Acc 62.00 %\n",
      "Epoch:120/200 AVG Training Loss:0.652 AVG Validation Loss:0.666 AVG Training Acc 62.01 % AVG Validation Acc 62.00 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.652 AVG Validation Loss:0.667 AVG Training Acc 61.92 % AVG Validation Acc 62.00 %\n",
      "Epoch:140/200 AVG Training Loss:0.652 AVG Validation Loss:0.666 AVG Training Acc 62.04 % AVG Validation Acc 62.00 %\n",
      "Epoch:150/200 AVG Training Loss:0.653 AVG Validation Loss:0.667 AVG Training Acc 61.96 % AVG Validation Acc 62.00 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.652 AVG Validation Loss:0.667 AVG Training Acc 61.88 % AVG Validation Acc 62.00 %\n",
      "Epoch:170/200 AVG Training Loss:0.652 AVG Validation Loss:0.667 AVG Training Acc 61.97 % AVG Validation Acc 62.00 %\n",
      "Epoch:180/200 AVG Training Loss:0.651 AVG Validation Loss:0.667 AVG Training Acc 61.97 % AVG Validation Acc 62.00 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.652 AVG Validation Loss:0.666 AVG Training Acc 61.97 % AVG Validation Acc 62.00 %\n",
      "Epoch:200/200 AVG Training Loss:0.652 AVG Validation Loss:0.666 AVG Training Acc 61.87 % AVG Validation Acc 62.00 %\n",
      "Split 250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "923be96961fd45af87b64ea420b3f640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.664 AVG Training Acc 61.75 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.664 AVG Training Acc 62.11 % AVG Validation Acc 61.64 %\n",
      "Epoch:30/200 AVG Training Loss:0.644 AVG Validation Loss:0.664 AVG Training Acc 62.54 % AVG Validation Acc 61.19 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.625 AVG Validation Loss:0.676 AVG Training Acc 64.02 % AVG Validation Acc 59.84 %\n",
      "Epoch:50/200 AVG Training Loss:0.613 AVG Validation Loss:0.681 AVG Training Acc 64.52 % AVG Validation Acc 60.11 %\n",
      "Epoch:60/200 AVG Training Loss:0.605 AVG Validation Loss:0.685 AVG Training Acc 65.02 % AVG Validation Acc 59.48 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.598 AVG Validation Loss:0.688 AVG Training Acc 65.64 % AVG Validation Acc 59.57 %\n",
      "Epoch:80/200 AVG Training Loss:0.593 AVG Validation Loss:0.689 AVG Training Acc 66.67 % AVG Validation Acc 59.57 %\n",
      "Epoch:90/200 AVG Training Loss:0.593 AVG Validation Loss:0.695 AVG Training Acc 66.75 % AVG Validation Acc 59.75 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.589 AVG Validation Loss:0.693 AVG Training Acc 66.65 % AVG Validation Acc 60.38 %\n",
      "Epoch:110/200 AVG Training Loss:0.589 AVG Validation Loss:0.694 AVG Training Acc 66.23 % AVG Validation Acc 59.93 %\n",
      "Epoch:120/200 AVG Training Loss:0.590 AVG Validation Loss:0.695 AVG Training Acc 66.41 % AVG Validation Acc 60.56 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.589 AVG Validation Loss:0.694 AVG Training Acc 66.48 % AVG Validation Acc 60.20 %\n",
      "Epoch:140/200 AVG Training Loss:0.590 AVG Validation Loss:0.693 AVG Training Acc 66.03 % AVG Validation Acc 60.29 %\n",
      "Epoch:150/200 AVG Training Loss:0.593 AVG Validation Loss:0.693 AVG Training Acc 66.22 % AVG Validation Acc 59.93 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.587 AVG Validation Loss:0.691 AVG Training Acc 66.75 % AVG Validation Acc 59.30 %\n",
      "Epoch:170/200 AVG Training Loss:0.592 AVG Validation Loss:0.695 AVG Training Acc 65.96 % AVG Validation Acc 60.11 %\n",
      "Epoch:180/200 AVG Training Loss:0.590 AVG Validation Loss:0.691 AVG Training Acc 66.87 % AVG Validation Acc 60.11 %\n",
      "Epoch:190/200 AVG Training Loss:0.590 AVG Validation Loss:0.694 AVG Training Acc 66.50 % AVG Validation Acc 60.11 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.591 AVG Validation Loss:0.695 AVG Training Acc 66.35 % AVG Validation Acc 60.38 %\n",
      "Split 251\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d792d98fe0de47a2867f7cc35c7ee1ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.656 AVG Training Acc 61.61 % AVG Validation Acc 62.04 %\n",
      "Epoch:20/200 AVG Training Loss:0.650 AVG Validation Loss:0.654 AVG Training Acc 62.22 % AVG Validation Acc 62.13 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.635 AVG Validation Loss:0.663 AVG Training Acc 63.57 % AVG Validation Acc 60.60 %\n",
      "Epoch:40/200 AVG Training Loss:0.625 AVG Validation Loss:0.670 AVG Training Acc 64.38 % AVG Validation Acc 60.23 %\n",
      "Epoch:50/200 AVG Training Loss:0.617 AVG Validation Loss:0.678 AVG Training Acc 65.03 % AVG Validation Acc 59.78 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.609 AVG Validation Loss:0.686 AVG Training Acc 65.68 % AVG Validation Acc 60.32 %\n",
      "Epoch:70/200 AVG Training Loss:0.607 AVG Validation Loss:0.693 AVG Training Acc 66.01 % AVG Validation Acc 60.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.606 AVG Validation Loss:0.691 AVG Training Acc 65.97 % AVG Validation Acc 60.50 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.607 AVG Validation Loss:0.691 AVG Training Acc 66.09 % AVG Validation Acc 60.69 %\n",
      "Epoch:100/200 AVG Training Loss:0.606 AVG Validation Loss:0.690 AVG Training Acc 66.64 % AVG Validation Acc 60.50 %\n",
      "Epoch:110/200 AVG Training Loss:0.607 AVG Validation Loss:0.695 AVG Training Acc 66.14 % AVG Validation Acc 59.78 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.605 AVG Validation Loss:0.694 AVG Training Acc 66.09 % AVG Validation Acc 60.87 %\n",
      "Epoch:130/200 AVG Training Loss:0.607 AVG Validation Loss:0.692 AVG Training Acc 65.70 % AVG Validation Acc 59.69 %\n",
      "Epoch:140/200 AVG Training Loss:0.606 AVG Validation Loss:0.694 AVG Training Acc 66.04 % AVG Validation Acc 60.69 %\n",
      "Epoch:150/200 AVG Training Loss:0.604 AVG Validation Loss:0.693 AVG Training Acc 66.17 % AVG Validation Acc 60.50 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.604 AVG Validation Loss:0.693 AVG Training Acc 66.51 % AVG Validation Acc 60.23 %\n",
      "Epoch:170/200 AVG Training Loss:0.604 AVG Validation Loss:0.693 AVG Training Acc 66.07 % AVG Validation Acc 60.87 %\n",
      "Epoch:180/200 AVG Training Loss:0.605 AVG Validation Loss:0.693 AVG Training Acc 66.21 % AVG Validation Acc 60.32 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.604 AVG Validation Loss:0.691 AVG Training Acc 66.55 % AVG Validation Acc 60.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.604 AVG Validation Loss:0.694 AVG Training Acc 66.03 % AVG Validation Acc 60.78 %\n",
      "Split 252\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9495bb7c97bc4f1e85f1ebee63e0f22b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.656 AVG Training Acc 61.95 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.657 AVG Training Acc 61.91 % AVG Validation Acc 61.68 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.640 AVG Validation Loss:0.669 AVG Training Acc 62.09 % AVG Validation Acc 61.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.632 AVG Validation Loss:0.679 AVG Training Acc 62.87 % AVG Validation Acc 61.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.625 AVG Validation Loss:0.689 AVG Training Acc 63.48 % AVG Validation Acc 60.69 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.620 AVG Validation Loss:0.693 AVG Training Acc 63.96 % AVG Validation Acc 61.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.620 AVG Validation Loss:0.700 AVG Training Acc 63.40 % AVG Validation Acc 60.78 %\n",
      "Epoch:80/200 AVG Training Loss:0.618 AVG Validation Loss:0.702 AVG Training Acc 64.29 % AVG Validation Acc 61.14 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.618 AVG Validation Loss:0.700 AVG Training Acc 63.56 % AVG Validation Acc 61.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.616 AVG Validation Loss:0.700 AVG Training Acc 64.33 % AVG Validation Acc 61.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.617 AVG Validation Loss:0.705 AVG Training Acc 64.20 % AVG Validation Acc 60.96 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.617 AVG Validation Loss:0.703 AVG Training Acc 64.04 % AVG Validation Acc 61.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.616 AVG Validation Loss:0.704 AVG Training Acc 64.00 % AVG Validation Acc 60.69 %\n",
      "Epoch:140/200 AVG Training Loss:0.617 AVG Validation Loss:0.699 AVG Training Acc 64.39 % AVG Validation Acc 60.96 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.617 AVG Validation Loss:0.708 AVG Training Acc 64.26 % AVG Validation Acc 60.78 %\n",
      "Epoch:160/200 AVG Training Loss:0.619 AVG Validation Loss:0.704 AVG Training Acc 64.00 % AVG Validation Acc 60.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.618 AVG Validation Loss:0.701 AVG Training Acc 63.87 % AVG Validation Acc 61.23 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.617 AVG Validation Loss:0.704 AVG Training Acc 63.98 % AVG Validation Acc 60.96 %\n",
      "Epoch:190/200 AVG Training Loss:0.619 AVG Validation Loss:0.703 AVG Training Acc 63.51 % AVG Validation Acc 60.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.617 AVG Validation Loss:0.704 AVG Training Acc 63.91 % AVG Validation Acc 60.96 %\n",
      "Split 253\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "283b2fc055b64ffd81777015a95e0eef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.667 AVG Training Acc 61.77 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.667 AVG Training Acc 61.79 % AVG Validation Acc 62.22 %\n",
      "Epoch:30/200 AVG Training Loss:0.652 AVG Validation Loss:0.663 AVG Training Acc 61.89 % AVG Validation Acc 62.04 %\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.635 AVG Validation Loss:0.666 AVG Training Acc 62.80 % AVG Validation Acc 62.85 %\n",
      "Epoch:50/200 AVG Training Loss:0.619 AVG Validation Loss:0.680 AVG Training Acc 63.50 % AVG Validation Acc 61.95 %\n",
      "Epoch:60/200 AVG Training Loss:0.612 AVG Validation Loss:0.677 AVG Training Acc 63.42 % AVG Validation Acc 61.68 %\n",
      "Epoch:70/200 AVG Training Loss:0.607 AVG Validation Loss:0.685 AVG Training Acc 63.87 % AVG Validation Acc 61.77 %\n",
      "Epoch    70: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.602 AVG Validation Loss:0.690 AVG Training Acc 64.36 % AVG Validation Acc 62.22 %\n",
      "Epoch:90/200 AVG Training Loss:0.602 AVG Validation Loss:0.690 AVG Training Acc 64.35 % AVG Validation Acc 62.22 %\n",
      "Epoch:100/200 AVG Training Loss:0.601 AVG Validation Loss:0.689 AVG Training Acc 64.38 % AVG Validation Acc 62.04 %\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.599 AVG Validation Loss:0.688 AVG Training Acc 64.35 % AVG Validation Acc 62.49 %\n",
      "Epoch:120/200 AVG Training Loss:0.599 AVG Validation Loss:0.691 AVG Training Acc 64.84 % AVG Validation Acc 61.77 %\n",
      "Epoch:130/200 AVG Training Loss:0.600 AVG Validation Loss:0.695 AVG Training Acc 64.40 % AVG Validation Acc 61.86 %\n",
      "Epoch   132: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.599 AVG Validation Loss:0.685 AVG Training Acc 64.23 % AVG Validation Acc 62.22 %\n",
      "Epoch:150/200 AVG Training Loss:0.600 AVG Validation Loss:0.691 AVG Training Acc 64.25 % AVG Validation Acc 61.86 %\n",
      "Epoch:160/200 AVG Training Loss:0.602 AVG Validation Loss:0.692 AVG Training Acc 64.28 % AVG Validation Acc 62.04 %\n",
      "Epoch   163: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.601 AVG Validation Loss:0.691 AVG Training Acc 64.29 % AVG Validation Acc 61.86 %\n",
      "Epoch:180/200 AVG Training Loss:0.600 AVG Validation Loss:0.687 AVG Training Acc 64.60 % AVG Validation Acc 62.13 %\n",
      "Epoch:190/200 AVG Training Loss:0.603 AVG Validation Loss:0.690 AVG Training Acc 64.32 % AVG Validation Acc 61.95 %\n",
      "Epoch   194: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.599 AVG Validation Loss:0.690 AVG Training Acc 64.52 % AVG Validation Acc 62.31 %\n",
      "Split 254\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0e69f470ff943ba8962eb445cbd5f0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.660 AVG Training Acc 61.87 % AVG Validation Acc 62.22 %\n",
      "Epoch:20/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 62.13 % AVG Validation Acc 61.77 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.635 AVG Validation Loss:0.667 AVG Training Acc 63.06 % AVG Validation Acc 61.41 %\n",
      "Epoch:40/200 AVG Training Loss:0.628 AVG Validation Loss:0.677 AVG Training Acc 63.42 % AVG Validation Acc 61.95 %\n",
      "Epoch:50/200 AVG Training Loss:0.623 AVG Validation Loss:0.680 AVG Training Acc 64.25 % AVG Validation Acc 61.41 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.615 AVG Validation Loss:0.685 AVG Training Acc 64.38 % AVG Validation Acc 61.68 %\n",
      "Epoch:70/200 AVG Training Loss:0.612 AVG Validation Loss:0.686 AVG Training Acc 64.67 % AVG Validation Acc 61.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.612 AVG Validation Loss:0.690 AVG Training Acc 64.82 % AVG Validation Acc 60.32 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.611 AVG Validation Loss:0.687 AVG Training Acc 64.85 % AVG Validation Acc 60.87 %\n",
      "Epoch:100/200 AVG Training Loss:0.610 AVG Validation Loss:0.688 AVG Training Acc 64.96 % AVG Validation Acc 61.50 %\n",
      "Epoch:110/200 AVG Training Loss:0.610 AVG Validation Loss:0.689 AVG Training Acc 64.97 % AVG Validation Acc 61.50 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.610 AVG Validation Loss:0.688 AVG Training Acc 65.46 % AVG Validation Acc 60.78 %\n",
      "Epoch:130/200 AVG Training Loss:0.611 AVG Validation Loss:0.687 AVG Training Acc 64.83 % AVG Validation Acc 60.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.612 AVG Validation Loss:0.689 AVG Training Acc 64.68 % AVG Validation Acc 61.05 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.611 AVG Validation Loss:0.686 AVG Training Acc 64.52 % AVG Validation Acc 61.05 %\n",
      "Epoch:160/200 AVG Training Loss:0.610 AVG Validation Loss:0.685 AVG Training Acc 64.74 % AVG Validation Acc 61.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.611 AVG Validation Loss:0.690 AVG Training Acc 64.33 % AVG Validation Acc 60.78 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.610 AVG Validation Loss:0.690 AVG Training Acc 65.26 % AVG Validation Acc 61.05 %\n",
      "Epoch:190/200 AVG Training Loss:0.611 AVG Validation Loss:0.687 AVG Training Acc 64.67 % AVG Validation Acc 61.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.609 AVG Validation Loss:0.690 AVG Training Acc 64.79 % AVG Validation Acc 61.14 %\n",
      "Split 255\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "605f838a43354bb99c6492781f4087b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.662 AVG Validation Loss:0.655 AVG Training Acc 61.86 % AVG Validation Acc 61.77 %\n",
      "Epoch:20/200 AVG Training Loss:0.656 AVG Validation Loss:0.651 AVG Training Acc 61.99 % AVG Validation Acc 61.68 %\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.648 AVG Training Acc 61.76 % AVG Validation Acc 61.59 %\n",
      "Epoch:40/200 AVG Training Loss:0.642 AVG Validation Loss:0.654 AVG Training Acc 62.33 % AVG Validation Acc 61.86 %\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.620 AVG Validation Loss:0.675 AVG Training Acc 63.39 % AVG Validation Acc 61.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.612 AVG Validation Loss:0.694 AVG Training Acc 64.00 % AVG Validation Acc 60.32 %\n",
      "Epoch:70/200 AVG Training Loss:0.609 AVG Validation Loss:0.701 AVG Training Acc 64.31 % AVG Validation Acc 60.05 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.604 AVG Validation Loss:0.711 AVG Training Acc 64.95 % AVG Validation Acc 59.60 %\n",
      "Epoch:90/200 AVG Training Loss:0.604 AVG Validation Loss:0.712 AVG Training Acc 65.00 % AVG Validation Acc 59.15 %\n",
      "Epoch:100/200 AVG Training Loss:0.600 AVG Validation Loss:0.711 AVG Training Acc 64.88 % AVG Validation Acc 59.15 %\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.602 AVG Validation Loss:0.715 AVG Training Acc 64.80 % AVG Validation Acc 59.42 %\n",
      "Epoch:120/200 AVG Training Loss:0.601 AVG Validation Loss:0.716 AVG Training Acc 64.97 % AVG Validation Acc 58.97 %\n",
      "Epoch:130/200 AVG Training Loss:0.600 AVG Validation Loss:0.717 AVG Training Acc 64.50 % AVG Validation Acc 59.42 %\n",
      "Epoch   134: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.603 AVG Validation Loss:0.714 AVG Training Acc 64.73 % AVG Validation Acc 58.97 %\n",
      "Epoch:150/200 AVG Training Loss:0.603 AVG Validation Loss:0.713 AVG Training Acc 64.38 % AVG Validation Acc 59.24 %\n",
      "Epoch:160/200 AVG Training Loss:0.602 AVG Validation Loss:0.714 AVG Training Acc 65.32 % AVG Validation Acc 59.33 %\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.601 AVG Validation Loss:0.717 AVG Training Acc 65.13 % AVG Validation Acc 58.97 %\n",
      "Epoch:180/200 AVG Training Loss:0.601 AVG Validation Loss:0.714 AVG Training Acc 64.67 % AVG Validation Acc 59.33 %\n",
      "Epoch:190/200 AVG Training Loss:0.600 AVG Validation Loss:0.712 AVG Training Acc 65.04 % AVG Validation Acc 59.15 %\n",
      "Epoch   196: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.600 AVG Validation Loss:0.711 AVG Training Acc 64.52 % AVG Validation Acc 59.87 %\n",
      "Split 256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d51954392b79405f95535f4dde7ddd8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.655 AVG Training Acc 61.84 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.651 AVG Training Acc 61.80 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.646 AVG Validation Loss:0.645 AVG Training Acc 62.49 % AVG Validation Acc 62.64 %\n",
      "Epoch:40/200 AVG Training Loss:0.635 AVG Validation Loss:0.649 AVG Training Acc 62.68 % AVG Validation Acc 62.45 %\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.610 AVG Validation Loss:0.665 AVG Training Acc 64.86 % AVG Validation Acc 60.47 %\n",
      "Epoch:60/200 AVG Training Loss:0.596 AVG Validation Loss:0.682 AVG Training Acc 65.72 % AVG Validation Acc 60.47 %\n",
      "Epoch:70/200 AVG Training Loss:0.586 AVG Validation Loss:0.693 AVG Training Acc 66.80 % AVG Validation Acc 60.20 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.581 AVG Validation Loss:0.689 AVG Training Acc 67.02 % AVG Validation Acc 60.74 %\n",
      "Epoch:90/200 AVG Training Loss:0.580 AVG Validation Loss:0.690 AVG Training Acc 67.11 % AVG Validation Acc 60.47 %\n",
      "Epoch:100/200 AVG Training Loss:0.579 AVG Validation Loss:0.686 AVG Training Acc 67.70 % AVG Validation Acc 61.37 %\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.578 AVG Validation Loss:0.694 AVG Training Acc 67.70 % AVG Validation Acc 60.47 %\n",
      "Epoch:120/200 AVG Training Loss:0.578 AVG Validation Loss:0.698 AVG Training Acc 67.04 % AVG Validation Acc 61.28 %\n",
      "Epoch:130/200 AVG Training Loss:0.578 AVG Validation Loss:0.692 AVG Training Acc 67.33 % AVG Validation Acc 61.01 %\n",
      "Epoch   134: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.579 AVG Validation Loss:0.692 AVG Training Acc 67.04 % AVG Validation Acc 61.19 %\n",
      "Epoch:150/200 AVG Training Loss:0.578 AVG Validation Loss:0.697 AVG Training Acc 67.06 % AVG Validation Acc 60.92 %\n",
      "Epoch:160/200 AVG Training Loss:0.581 AVG Validation Loss:0.697 AVG Training Acc 66.92 % AVG Validation Acc 60.47 %\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.578 AVG Validation Loss:0.694 AVG Training Acc 67.44 % AVG Validation Acc 60.29 %\n",
      "Epoch:180/200 AVG Training Loss:0.579 AVG Validation Loss:0.690 AVG Training Acc 67.40 % AVG Validation Acc 61.19 %\n",
      "Epoch:190/200 AVG Training Loss:0.578 AVG Validation Loss:0.699 AVG Training Acc 67.02 % AVG Validation Acc 61.01 %\n",
      "Epoch   196: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.578 AVG Validation Loss:0.695 AVG Training Acc 67.30 % AVG Validation Acc 60.02 %\n",
      "Split 257\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec29efbda4a848578e1ab0d0cb0d3da6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.657 AVG Training Acc 61.91 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.653 AVG Training Acc 62.00 % AVG Validation Acc 61.73 %\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:0.656 AVG Training Acc 61.61 % AVG Validation Acc 62.27 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.637 AVG Validation Loss:0.660 AVG Training Acc 63.14 % AVG Validation Acc 62.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.629 AVG Validation Loss:0.667 AVG Training Acc 63.25 % AVG Validation Acc 62.55 %\n",
      "Epoch:60/200 AVG Training Loss:0.620 AVG Validation Loss:0.669 AVG Training Acc 64.02 % AVG Validation Acc 62.82 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.616 AVG Validation Loss:0.673 AVG Training Acc 64.36 % AVG Validation Acc 63.45 %\n",
      "Epoch:80/200 AVG Training Loss:0.613 AVG Validation Loss:0.676 AVG Training Acc 64.85 % AVG Validation Acc 62.73 %\n",
      "Epoch:90/200 AVG Training Loss:0.613 AVG Validation Loss:0.671 AVG Training Acc 64.82 % AVG Validation Acc 62.82 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.612 AVG Validation Loss:0.674 AVG Training Acc 64.58 % AVG Validation Acc 62.55 %\n",
      "Epoch:110/200 AVG Training Loss:0.611 AVG Validation Loss:0.670 AVG Training Acc 64.75 % AVG Validation Acc 62.73 %\n",
      "Epoch:120/200 AVG Training Loss:0.610 AVG Validation Loss:0.672 AVG Training Acc 64.81 % AVG Validation Acc 62.55 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.612 AVG Validation Loss:0.673 AVG Training Acc 64.80 % AVG Validation Acc 63.18 %\n",
      "Epoch:140/200 AVG Training Loss:0.612 AVG Validation Loss:0.675 AVG Training Acc 64.58 % AVG Validation Acc 63.27 %\n",
      "Epoch:150/200 AVG Training Loss:0.610 AVG Validation Loss:0.677 AVG Training Acc 65.12 % AVG Validation Acc 63.09 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.609 AVG Validation Loss:0.675 AVG Training Acc 65.22 % AVG Validation Acc 63.00 %\n",
      "Epoch:170/200 AVG Training Loss:0.613 AVG Validation Loss:0.675 AVG Training Acc 64.50 % AVG Validation Acc 62.82 %\n",
      "Epoch:180/200 AVG Training Loss:0.615 AVG Validation Loss:0.672 AVG Training Acc 64.64 % AVG Validation Acc 62.55 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.612 AVG Validation Loss:0.674 AVG Training Acc 64.27 % AVG Validation Acc 62.82 %\n",
      "Epoch:200/200 AVG Training Loss:0.611 AVG Validation Loss:0.672 AVG Training Acc 64.66 % AVG Validation Acc 62.64 %\n",
      "Split 258\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca35c2b6ee0468b9f8bd0162eb031bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.663 AVG Training Acc 61.85 % AVG Validation Acc 61.73 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.662 AVG Training Acc 61.94 % AVG Validation Acc 61.55 %\n",
      "Epoch:30/200 AVG Training Loss:0.642 AVG Validation Loss:0.670 AVG Training Acc 62.57 % AVG Validation Acc 61.19 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.618 AVG Validation Loss:0.683 AVG Training Acc 64.30 % AVG Validation Acc 60.83 %\n",
      "Epoch:50/200 AVG Training Loss:0.607 AVG Validation Loss:0.699 AVG Training Acc 64.98 % AVG Validation Acc 61.55 %\n",
      "Epoch:60/200 AVG Training Loss:0.598 AVG Validation Loss:0.708 AVG Training Acc 65.44 % AVG Validation Acc 61.01 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.587 AVG Validation Loss:0.719 AVG Training Acc 66.10 % AVG Validation Acc 61.01 %\n",
      "Epoch:80/200 AVG Training Loss:0.585 AVG Validation Loss:0.721 AVG Training Acc 66.17 % AVG Validation Acc 60.47 %\n",
      "Epoch:90/200 AVG Training Loss:0.586 AVG Validation Loss:0.727 AVG Training Acc 66.31 % AVG Validation Acc 59.57 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.583 AVG Validation Loss:0.728 AVG Training Acc 66.74 % AVG Validation Acc 60.47 %\n",
      "Epoch:110/200 AVG Training Loss:0.581 AVG Validation Loss:0.735 AVG Training Acc 66.75 % AVG Validation Acc 60.29 %\n",
      "Epoch:120/200 AVG Training Loss:0.583 AVG Validation Loss:0.733 AVG Training Acc 66.32 % AVG Validation Acc 60.11 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.585 AVG Validation Loss:0.731 AVG Training Acc 66.16 % AVG Validation Acc 59.93 %\n",
      "Epoch:140/200 AVG Training Loss:0.584 AVG Validation Loss:0.733 AVG Training Acc 66.73 % AVG Validation Acc 60.29 %\n",
      "Epoch:150/200 AVG Training Loss:0.584 AVG Validation Loss:0.733 AVG Training Acc 66.74 % AVG Validation Acc 60.02 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.585 AVG Validation Loss:0.727 AVG Training Acc 65.93 % AVG Validation Acc 59.75 %\n",
      "Epoch:170/200 AVG Training Loss:0.582 AVG Validation Loss:0.733 AVG Training Acc 67.22 % AVG Validation Acc 60.11 %\n",
      "Epoch:180/200 AVG Training Loss:0.582 AVG Validation Loss:0.730 AVG Training Acc 66.32 % AVG Validation Acc 60.29 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.582 AVG Validation Loss:0.729 AVG Training Acc 66.56 % AVG Validation Acc 60.20 %\n",
      "Epoch:200/200 AVG Training Loss:0.583 AVG Validation Loss:0.730 AVG Training Acc 66.97 % AVG Validation Acc 60.02 %\n",
      "Split 259\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75165b3ae55041eab32809f4c8fce060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.665 AVG Training Acc 61.85 % AVG Validation Acc 62.00 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.665 AVG Training Acc 61.95 % AVG Validation Acc 60.92 %\n",
      "Epoch:30/200 AVG Training Loss:0.643 AVG Validation Loss:0.673 AVG Training Acc 62.48 % AVG Validation Acc 60.38 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.624 AVG Validation Loss:0.662 AVG Training Acc 64.39 % AVG Validation Acc 61.28 %\n",
      "Epoch:50/200 AVG Training Loss:0.613 AVG Validation Loss:0.674 AVG Training Acc 65.57 % AVG Validation Acc 60.65 %\n",
      "Epoch:60/200 AVG Training Loss:0.606 AVG Validation Loss:0.686 AVG Training Acc 65.77 % AVG Validation Acc 60.02 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.596 AVG Validation Loss:0.685 AVG Training Acc 66.63 % AVG Validation Acc 59.30 %\n",
      "Epoch:80/200 AVG Training Loss:0.594 AVG Validation Loss:0.691 AVG Training Acc 66.71 % AVG Validation Acc 59.57 %\n",
      "Epoch:90/200 AVG Training Loss:0.593 AVG Validation Loss:0.692 AVG Training Acc 66.46 % AVG Validation Acc 59.30 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.591 AVG Validation Loss:0.692 AVG Training Acc 67.00 % AVG Validation Acc 59.39 %\n",
      "Epoch:110/200 AVG Training Loss:0.590 AVG Validation Loss:0.694 AVG Training Acc 66.94 % AVG Validation Acc 59.39 %\n",
      "Epoch:120/200 AVG Training Loss:0.593 AVG Validation Loss:0.692 AVG Training Acc 66.40 % AVG Validation Acc 59.30 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.592 AVG Validation Loss:0.692 AVG Training Acc 66.72 % AVG Validation Acc 59.66 %\n",
      "Epoch:140/200 AVG Training Loss:0.592 AVG Validation Loss:0.692 AVG Training Acc 66.75 % AVG Validation Acc 59.84 %\n",
      "Epoch:150/200 AVG Training Loss:0.593 AVG Validation Loss:0.694 AVG Training Acc 67.05 % AVG Validation Acc 59.39 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.591 AVG Validation Loss:0.690 AVG Training Acc 67.27 % AVG Validation Acc 59.21 %\n",
      "Epoch:170/200 AVG Training Loss:0.591 AVG Validation Loss:0.688 AVG Training Acc 67.13 % AVG Validation Acc 59.12 %\n",
      "Epoch:180/200 AVG Training Loss:0.592 AVG Validation Loss:0.698 AVG Training Acc 66.66 % AVG Validation Acc 58.48 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.592 AVG Validation Loss:0.698 AVG Training Acc 66.98 % AVG Validation Acc 58.84 %\n",
      "Epoch:200/200 AVG Training Loss:0.590 AVG Validation Loss:0.694 AVG Training Acc 66.98 % AVG Validation Acc 60.02 %\n",
      "Split 260\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba8c52ded4e4cbf860a710b387312cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.657 AVG Training Acc 62.08 % AVG Validation Acc 62.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.656 AVG Validation Loss:0.656 AVG Training Acc 61.97 % AVG Validation Acc 62.00 %\n",
      "Epoch:30/200 AVG Training Loss:0.648 AVG Validation Loss:0.659 AVG Training Acc 61.96 % AVG Validation Acc 61.37 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.628 AVG Validation Loss:0.662 AVG Training Acc 63.75 % AVG Validation Acc 59.93 %\n",
      "Epoch:50/200 AVG Training Loss:0.615 AVG Validation Loss:0.668 AVG Training Acc 64.53 % AVG Validation Acc 60.11 %\n",
      "Epoch:60/200 AVG Training Loss:0.608 AVG Validation Loss:0.676 AVG Training Acc 65.45 % AVG Validation Acc 60.38 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.598 AVG Validation Loss:0.685 AVG Training Acc 66.07 % AVG Validation Acc 59.66 %\n",
      "Epoch:80/200 AVG Training Loss:0.597 AVG Validation Loss:0.685 AVG Training Acc 65.93 % AVG Validation Acc 60.38 %\n",
      "Epoch:90/200 AVG Training Loss:0.597 AVG Validation Loss:0.686 AVG Training Acc 66.64 % AVG Validation Acc 60.20 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.596 AVG Validation Loss:0.688 AVG Training Acc 66.14 % AVG Validation Acc 60.65 %\n",
      "Epoch:110/200 AVG Training Loss:0.593 AVG Validation Loss:0.687 AVG Training Acc 66.81 % AVG Validation Acc 60.47 %\n",
      "Epoch:120/200 AVG Training Loss:0.594 AVG Validation Loss:0.689 AVG Training Acc 66.11 % AVG Validation Acc 59.66 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.594 AVG Validation Loss:0.686 AVG Training Acc 66.36 % AVG Validation Acc 59.75 %\n",
      "Epoch:140/200 AVG Training Loss:0.592 AVG Validation Loss:0.686 AVG Training Acc 66.64 % AVG Validation Acc 60.20 %\n",
      "Epoch:150/200 AVG Training Loss:0.595 AVG Validation Loss:0.684 AVG Training Acc 66.26 % AVG Validation Acc 60.47 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.594 AVG Validation Loss:0.689 AVG Training Acc 66.36 % AVG Validation Acc 59.84 %\n",
      "Epoch:170/200 AVG Training Loss:0.594 AVG Validation Loss:0.690 AVG Training Acc 66.31 % AVG Validation Acc 59.84 %\n",
      "Epoch:180/200 AVG Training Loss:0.596 AVG Validation Loss:0.688 AVG Training Acc 66.23 % AVG Validation Acc 60.02 %\n",
      "Epoch:190/200 AVG Training Loss:0.593 AVG Validation Loss:0.690 AVG Training Acc 66.39 % AVG Validation Acc 59.84 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.593 AVG Validation Loss:0.687 AVG Training Acc 66.21 % AVG Validation Acc 60.02 %\n",
      "Split 261\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1147de230fe645e184aeb9553a1b5816",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.662 AVG Validation Loss:0.660 AVG Training Acc 61.82 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.654 AVG Training Acc 62.24 % AVG Validation Acc 62.13 %\n",
      "Epoch:30/200 AVG Training Loss:0.646 AVG Validation Loss:0.659 AVG Training Acc 62.30 % AVG Validation Acc 62.40 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.629 AVG Validation Loss:0.667 AVG Training Acc 63.54 % AVG Validation Acc 61.68 %\n",
      "Epoch:50/200 AVG Training Loss:0.618 AVG Validation Loss:0.673 AVG Training Acc 64.41 % AVG Validation Acc 60.96 %\n",
      "Epoch:60/200 AVG Training Loss:0.611 AVG Validation Loss:0.687 AVG Training Acc 65.06 % AVG Validation Acc 60.87 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.606 AVG Validation Loss:0.692 AVG Training Acc 65.32 % AVG Validation Acc 60.60 %\n",
      "Epoch:80/200 AVG Training Loss:0.602 AVG Validation Loss:0.695 AVG Training Acc 65.55 % AVG Validation Acc 60.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.603 AVG Validation Loss:0.696 AVG Training Acc 65.39 % AVG Validation Acc 61.14 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.600 AVG Validation Loss:0.697 AVG Training Acc 66.07 % AVG Validation Acc 60.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.601 AVG Validation Loss:0.701 AVG Training Acc 65.76 % AVG Validation Acc 60.78 %\n",
      "Epoch:120/200 AVG Training Loss:0.601 AVG Validation Loss:0.695 AVG Training Acc 65.67 % AVG Validation Acc 61.14 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.602 AVG Validation Loss:0.702 AVG Training Acc 65.89 % AVG Validation Acc 61.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.601 AVG Validation Loss:0.697 AVG Training Acc 65.47 % AVG Validation Acc 61.05 %\n",
      "Epoch:150/200 AVG Training Loss:0.601 AVG Validation Loss:0.693 AVG Training Acc 65.65 % AVG Validation Acc 61.50 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.598 AVG Validation Loss:0.699 AVG Training Acc 65.70 % AVG Validation Acc 61.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.600 AVG Validation Loss:0.699 AVG Training Acc 66.10 % AVG Validation Acc 61.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.601 AVG Validation Loss:0.697 AVG Training Acc 65.89 % AVG Validation Acc 61.05 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.599 AVG Validation Loss:0.700 AVG Training Acc 65.87 % AVG Validation Acc 59.96 %\n",
      "Epoch:200/200 AVG Training Loss:0.601 AVG Validation Loss:0.695 AVG Training Acc 65.68 % AVG Validation Acc 60.96 %\n",
      "Split 262\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "183c06e633e442c9b1daa3d4a72c0323",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.657 AVG Validation Loss:0.662 AVG Training Acc 61.76 % AVG Validation Acc 61.68 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.649 AVG Validation Loss:0.663 AVG Training Acc 62.26 % AVG Validation Acc 61.41 %\n",
      "Epoch:30/200 AVG Training Loss:0.643 AVG Validation Loss:0.663 AVG Training Acc 62.86 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.638 AVG Validation Loss:0.665 AVG Training Acc 63.60 % AVG Validation Acc 61.59 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.632 AVG Validation Loss:0.666 AVG Training Acc 64.43 % AVG Validation Acc 61.59 %\n",
      "Epoch:60/200 AVG Training Loss:0.629 AVG Validation Loss:0.668 AVG Training Acc 64.43 % AVG Validation Acc 61.41 %\n",
      "Epoch:70/200 AVG Training Loss:0.629 AVG Validation Loss:0.666 AVG Training Acc 64.68 % AVG Validation Acc 61.23 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.628 AVG Validation Loss:0.671 AVG Training Acc 64.31 % AVG Validation Acc 61.05 %\n",
      "Epoch:90/200 AVG Training Loss:0.626 AVG Validation Loss:0.668 AVG Training Acc 64.67 % AVG Validation Acc 60.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.627 AVG Validation Loss:0.670 AVG Training Acc 64.77 % AVG Validation Acc 60.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.627 AVG Validation Loss:0.668 AVG Training Acc 65.05 % AVG Validation Acc 60.69 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.626 AVG Validation Loss:0.670 AVG Training Acc 64.56 % AVG Validation Acc 61.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.626 AVG Validation Loss:0.668 AVG Training Acc 64.65 % AVG Validation Acc 61.32 %\n",
      "Epoch:140/200 AVG Training Loss:0.628 AVG Validation Loss:0.668 AVG Training Acc 64.82 % AVG Validation Acc 60.87 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.626 AVG Validation Loss:0.670 AVG Training Acc 64.94 % AVG Validation Acc 61.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.625 AVG Validation Loss:0.669 AVG Training Acc 64.86 % AVG Validation Acc 61.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.627 AVG Validation Loss:0.668 AVG Training Acc 64.45 % AVG Validation Acc 61.14 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.627 AVG Validation Loss:0.670 AVG Training Acc 64.76 % AVG Validation Acc 60.78 %\n",
      "Epoch:190/200 AVG Training Loss:0.625 AVG Validation Loss:0.668 AVG Training Acc 64.92 % AVG Validation Acc 61.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.627 AVG Validation Loss:0.670 AVG Training Acc 64.94 % AVG Validation Acc 60.96 %\n",
      "Split 263\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "511aabe7dad34d3696f56793d2fa8b92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.660 AVG Training Acc 61.82 % AVG Validation Acc 62.04 %\n",
      "Epoch:20/200 AVG Training Loss:0.650 AVG Validation Loss:0.661 AVG Training Acc 62.06 % AVG Validation Acc 61.41 %\n",
      "Epoch:30/200 AVG Training Loss:0.646 AVG Validation Loss:0.656 AVG Training Acc 62.80 % AVG Validation Acc 62.13 %\n",
      "Epoch:40/200 AVG Training Loss:0.662 AVG Validation Loss:0.659 AVG Training Acc 61.60 % AVG Validation Acc 62.04 %\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.652 AVG Validation Loss:0.662 AVG Training Acc 62.28 % AVG Validation Acc 61.77 %\n",
      "Epoch:60/200 AVG Training Loss:0.648 AVG Validation Loss:0.665 AVG Training Acc 62.47 % AVG Validation Acc 61.77 %\n",
      "Epoch:70/200 AVG Training Loss:0.645 AVG Validation Loss:0.666 AVG Training Acc 62.98 % AVG Validation Acc 61.86 %\n",
      "Epoch    71: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.640 AVG Validation Loss:0.666 AVG Training Acc 63.01 % AVG Validation Acc 61.59 %\n",
      "Epoch:90/200 AVG Training Loss:0.641 AVG Validation Loss:0.668 AVG Training Acc 62.94 % AVG Validation Acc 61.50 %\n",
      "Epoch:100/200 AVG Training Loss:0.639 AVG Validation Loss:0.667 AVG Training Acc 63.15 % AVG Validation Acc 61.68 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.640 AVG Validation Loss:0.668 AVG Training Acc 63.04 % AVG Validation Acc 61.50 %\n",
      "Epoch:120/200 AVG Training Loss:0.639 AVG Validation Loss:0.667 AVG Training Acc 63.14 % AVG Validation Acc 61.59 %\n",
      "Epoch:130/200 AVG Training Loss:0.640 AVG Validation Loss:0.667 AVG Training Acc 63.17 % AVG Validation Acc 61.59 %\n",
      "Epoch   133: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.641 AVG Validation Loss:0.668 AVG Training Acc 63.18 % AVG Validation Acc 61.68 %\n",
      "Epoch:150/200 AVG Training Loss:0.638 AVG Validation Loss:0.667 AVG Training Acc 63.03 % AVG Validation Acc 61.41 %\n",
      "Epoch:160/200 AVG Training Loss:0.640 AVG Validation Loss:0.667 AVG Training Acc 63.32 % AVG Validation Acc 61.50 %\n",
      "Epoch   164: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.638 AVG Validation Loss:0.667 AVG Training Acc 63.13 % AVG Validation Acc 61.59 %\n",
      "Epoch:180/200 AVG Training Loss:0.639 AVG Validation Loss:0.666 AVG Training Acc 63.16 % AVG Validation Acc 61.59 %\n",
      "Epoch:190/200 AVG Training Loss:0.640 AVG Validation Loss:0.667 AVG Training Acc 62.93 % AVG Validation Acc 61.50 %\n",
      "Epoch   195: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.638 AVG Validation Loss:0.667 AVG Training Acc 63.19 % AVG Validation Acc 61.59 %\n",
      "Split 264\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a57a89767274e4db33157416f05e76e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.661 AVG Training Acc 61.92 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.659 AVG Training Acc 62.07 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.645 AVG Validation Loss:0.656 AVG Training Acc 61.86 % AVG Validation Acc 62.04 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.623 AVG Validation Loss:0.666 AVG Training Acc 63.64 % AVG Validation Acc 60.60 %\n",
      "Epoch:50/200 AVG Training Loss:0.611 AVG Validation Loss:0.673 AVG Training Acc 65.30 % AVG Validation Acc 60.87 %\n",
      "Epoch:60/200 AVG Training Loss:0.601 AVG Validation Loss:0.679 AVG Training Acc 65.81 % AVG Validation Acc 60.78 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.592 AVG Validation Loss:0.690 AVG Training Acc 66.78 % AVG Validation Acc 59.69 %\n",
      "Epoch:80/200 AVG Training Loss:0.592 AVG Validation Loss:0.694 AVG Training Acc 66.94 % AVG Validation Acc 59.15 %\n",
      "Epoch:90/200 AVG Training Loss:0.587 AVG Validation Loss:0.690 AVG Training Acc 66.88 % AVG Validation Acc 59.51 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.590 AVG Validation Loss:0.693 AVG Training Acc 67.27 % AVG Validation Acc 59.33 %\n",
      "Epoch:110/200 AVG Training Loss:0.588 AVG Validation Loss:0.695 AVG Training Acc 67.40 % AVG Validation Acc 60.05 %\n",
      "Epoch:120/200 AVG Training Loss:0.589 AVG Validation Loss:0.690 AVG Training Acc 66.35 % AVG Validation Acc 59.51 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.589 AVG Validation Loss:0.698 AVG Training Acc 66.64 % AVG Validation Acc 59.15 %\n",
      "Epoch:140/200 AVG Training Loss:0.589 AVG Validation Loss:0.696 AVG Training Acc 67.35 % AVG Validation Acc 59.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.587 AVG Validation Loss:0.686 AVG Training Acc 66.49 % AVG Validation Acc 59.87 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.589 AVG Validation Loss:0.686 AVG Training Acc 67.07 % AVG Validation Acc 59.69 %\n",
      "Epoch:170/200 AVG Training Loss:0.590 AVG Validation Loss:0.696 AVG Training Acc 67.04 % AVG Validation Acc 58.97 %\n",
      "Epoch:180/200 AVG Training Loss:0.587 AVG Validation Loss:0.695 AVG Training Acc 67.28 % AVG Validation Acc 59.60 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.590 AVG Validation Loss:0.692 AVG Training Acc 66.89 % AVG Validation Acc 59.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.585 AVG Validation Loss:0.690 AVG Training Acc 67.21 % AVG Validation Acc 60.32 %\n",
      "Split 265\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "845e582238614c768d8e2863ab42e2f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.652 AVG Training Acc 61.97 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.648 AVG Training Acc 62.17 % AVG Validation Acc 61.59 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.635 AVG Validation Loss:0.657 AVG Training Acc 63.48 % AVG Validation Acc 60.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.628 AVG Validation Loss:0.664 AVG Training Acc 63.64 % AVG Validation Acc 60.96 %\n",
      "Epoch:50/200 AVG Training Loss:0.619 AVG Validation Loss:0.668 AVG Training Acc 63.85 % AVG Validation Acc 60.96 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.611 AVG Validation Loss:0.674 AVG Training Acc 64.44 % AVG Validation Acc 60.60 %\n",
      "Epoch:70/200 AVG Training Loss:0.609 AVG Validation Loss:0.679 AVG Training Acc 65.06 % AVG Validation Acc 61.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.609 AVG Validation Loss:0.676 AVG Training Acc 64.39 % AVG Validation Acc 60.87 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.609 AVG Validation Loss:0.677 AVG Training Acc 64.69 % AVG Validation Acc 61.59 %\n",
      "Epoch:100/200 AVG Training Loss:0.608 AVG Validation Loss:0.679 AVG Training Acc 64.97 % AVG Validation Acc 61.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.608 AVG Validation Loss:0.679 AVG Training Acc 64.94 % AVG Validation Acc 61.05 %\n",
      "Epoch:120/200 AVG Training Loss:0.606 AVG Validation Loss:0.680 AVG Training Acc 64.89 % AVG Validation Acc 61.32 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.607 AVG Validation Loss:0.677 AVG Training Acc 65.03 % AVG Validation Acc 61.68 %\n",
      "Epoch:140/200 AVG Training Loss:0.606 AVG Validation Loss:0.678 AVG Training Acc 64.90 % AVG Validation Acc 61.59 %\n",
      "Epoch:150/200 AVG Training Loss:0.609 AVG Validation Loss:0.676 AVG Training Acc 64.88 % AVG Validation Acc 61.14 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.608 AVG Validation Loss:0.674 AVG Training Acc 64.20 % AVG Validation Acc 61.77 %\n",
      "Epoch:170/200 AVG Training Loss:0.607 AVG Validation Loss:0.677 AVG Training Acc 65.05 % AVG Validation Acc 61.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.609 AVG Validation Loss:0.678 AVG Training Acc 64.86 % AVG Validation Acc 61.14 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.607 AVG Validation Loss:0.677 AVG Training Acc 64.47 % AVG Validation Acc 61.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.607 AVG Validation Loss:0.674 AVG Training Acc 65.31 % AVG Validation Acc 61.59 %\n",
      "Split 266\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f30a297dfa97490187ec425474fbe3d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.651 AVG Training Acc 61.84 % AVG Validation Acc 62.00 %\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:0.648 AVG Training Acc 61.73 % AVG Validation Acc 62.09 %\n",
      "Epoch:30/200 AVG Training Loss:0.650 AVG Validation Loss:0.649 AVG Training Acc 61.92 % AVG Validation Acc 61.10 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.634 AVG Validation Loss:0.644 AVG Training Acc 63.21 % AVG Validation Acc 61.46 %\n",
      "Epoch:50/200 AVG Training Loss:0.627 AVG Validation Loss:0.643 AVG Training Acc 63.29 % AVG Validation Acc 61.73 %\n",
      "Epoch:60/200 AVG Training Loss:0.619 AVG Validation Loss:0.651 AVG Training Acc 64.36 % AVG Validation Acc 60.92 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.614 AVG Validation Loss:0.651 AVG Training Acc 64.66 % AVG Validation Acc 61.10 %\n",
      "Epoch:80/200 AVG Training Loss:0.613 AVG Validation Loss:0.653 AVG Training Acc 64.56 % AVG Validation Acc 61.28 %\n",
      "Epoch:90/200 AVG Training Loss:0.610 AVG Validation Loss:0.655 AVG Training Acc 65.00 % AVG Validation Acc 60.74 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.611 AVG Validation Loss:0.654 AVG Training Acc 64.67 % AVG Validation Acc 61.46 %\n",
      "Epoch:110/200 AVG Training Loss:0.612 AVG Validation Loss:0.654 AVG Training Acc 64.46 % AVG Validation Acc 60.83 %\n",
      "Epoch:120/200 AVG Training Loss:0.608 AVG Validation Loss:0.654 AVG Training Acc 65.17 % AVG Validation Acc 61.10 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.611 AVG Validation Loss:0.654 AVG Training Acc 64.75 % AVG Validation Acc 61.55 %\n",
      "Epoch:140/200 AVG Training Loss:0.611 AVG Validation Loss:0.653 AVG Training Acc 64.93 % AVG Validation Acc 61.01 %\n",
      "Epoch:150/200 AVG Training Loss:0.610 AVG Validation Loss:0.656 AVG Training Acc 64.85 % AVG Validation Acc 61.28 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.610 AVG Validation Loss:0.653 AVG Training Acc 65.05 % AVG Validation Acc 61.10 %\n",
      "Epoch:170/200 AVG Training Loss:0.610 AVG Validation Loss:0.655 AVG Training Acc 64.99 % AVG Validation Acc 61.46 %\n",
      "Epoch:180/200 AVG Training Loss:0.611 AVG Validation Loss:0.653 AVG Training Acc 64.76 % AVG Validation Acc 61.46 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.612 AVG Validation Loss:0.652 AVG Training Acc 64.82 % AVG Validation Acc 61.55 %\n",
      "Epoch:200/200 AVG Training Loss:0.611 AVG Validation Loss:0.652 AVG Training Acc 64.94 % AVG Validation Acc 61.19 %\n",
      "Split 267\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4cc7d8fa2d04e56b19a8f5b2abe1ad8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.656 AVG Training Acc 61.87 % AVG Validation Acc 61.82 %\n",
      "Epoch:20/200 AVG Training Loss:0.650 AVG Validation Loss:0.659 AVG Training Acc 61.99 % AVG Validation Acc 62.09 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.633 AVG Validation Loss:0.665 AVG Training Acc 63.13 % AVG Validation Acc 60.74 %\n",
      "Epoch:40/200 AVG Training Loss:0.622 AVG Validation Loss:0.673 AVG Training Acc 63.74 % AVG Validation Acc 60.83 %\n",
      "Epoch:50/200 AVG Training Loss:0.616 AVG Validation Loss:0.684 AVG Training Acc 63.79 % AVG Validation Acc 62.00 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.608 AVG Validation Loss:0.689 AVG Training Acc 64.54 % AVG Validation Acc 60.92 %\n",
      "Epoch:70/200 AVG Training Loss:0.603 AVG Validation Loss:0.690 AVG Training Acc 65.05 % AVG Validation Acc 60.74 %\n",
      "Epoch:80/200 AVG Training Loss:0.602 AVG Validation Loss:0.693 AVG Training Acc 64.69 % AVG Validation Acc 60.38 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.601 AVG Validation Loss:0.697 AVG Training Acc 65.23 % AVG Validation Acc 60.11 %\n",
      "Epoch:100/200 AVG Training Loss:0.600 AVG Validation Loss:0.694 AVG Training Acc 64.95 % AVG Validation Acc 60.29 %\n",
      "Epoch:110/200 AVG Training Loss:0.601 AVG Validation Loss:0.688 AVG Training Acc 65.02 % AVG Validation Acc 60.83 %\n",
      "Epoch:120/200 AVG Training Loss:0.600 AVG Validation Loss:0.700 AVG Training Acc 65.05 % AVG Validation Acc 59.75 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.603 AVG Validation Loss:0.695 AVG Training Acc 64.53 % AVG Validation Acc 60.56 %\n",
      "Epoch:140/200 AVG Training Loss:0.601 AVG Validation Loss:0.693 AVG Training Acc 65.24 % AVG Validation Acc 59.93 %\n",
      "Epoch:150/200 AVG Training Loss:0.603 AVG Validation Loss:0.693 AVG Training Acc 65.04 % AVG Validation Acc 60.11 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.602 AVG Validation Loss:0.690 AVG Training Acc 64.82 % AVG Validation Acc 60.20 %\n",
      "Epoch:170/200 AVG Training Loss:0.601 AVG Validation Loss:0.696 AVG Training Acc 65.29 % AVG Validation Acc 59.93 %\n",
      "Epoch:180/200 AVG Training Loss:0.600 AVG Validation Loss:0.697 AVG Training Acc 65.63 % AVG Validation Acc 60.20 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.602 AVG Validation Loss:0.692 AVG Training Acc 64.61 % AVG Validation Acc 60.29 %\n",
      "Epoch:200/200 AVG Training Loss:0.601 AVG Validation Loss:0.694 AVG Training Acc 64.89 % AVG Validation Acc 59.84 %\n",
      "Split 268\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13c47155084442bb1b5b3dd52a145aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.665 AVG Training Acc 61.80 % AVG Validation Acc 61.82 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.661 AVG Training Acc 62.01 % AVG Validation Acc 61.73 %\n",
      "Epoch:30/200 AVG Training Loss:0.663 AVG Validation Loss:0.663 AVG Training Acc 61.57 % AVG Validation Acc 61.91 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.649 AVG Validation Loss:0.661 AVG Training Acc 61.99 % AVG Validation Acc 61.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.645 AVG Validation Loss:0.664 AVG Training Acc 62.40 % AVG Validation Acc 62.36 %\n",
      "Epoch:60/200 AVG Training Loss:0.640 AVG Validation Loss:0.663 AVG Training Acc 62.71 % AVG Validation Acc 62.27 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.635 AVG Validation Loss:0.670 AVG Training Acc 62.67 % AVG Validation Acc 62.55 %\n",
      "Epoch:80/200 AVG Training Loss:0.635 AVG Validation Loss:0.668 AVG Training Acc 62.40 % AVG Validation Acc 62.45 %\n",
      "Epoch:90/200 AVG Training Loss:0.632 AVG Validation Loss:0.669 AVG Training Acc 62.69 % AVG Validation Acc 62.91 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.632 AVG Validation Loss:0.670 AVG Training Acc 62.16 % AVG Validation Acc 62.64 %\n",
      "Epoch:110/200 AVG Training Loss:0.632 AVG Validation Loss:0.670 AVG Training Acc 62.90 % AVG Validation Acc 62.00 %\n",
      "Epoch:120/200 AVG Training Loss:0.631 AVG Validation Loss:0.671 AVG Training Acc 62.26 % AVG Validation Acc 62.55 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.633 AVG Validation Loss:0.670 AVG Training Acc 62.40 % AVG Validation Acc 62.36 %\n",
      "Epoch:140/200 AVG Training Loss:0.631 AVG Validation Loss:0.669 AVG Training Acc 62.96 % AVG Validation Acc 62.27 %\n",
      "Epoch:150/200 AVG Training Loss:0.632 AVG Validation Loss:0.670 AVG Training Acc 62.65 % AVG Validation Acc 62.18 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.633 AVG Validation Loss:0.671 AVG Training Acc 62.81 % AVG Validation Acc 62.55 %\n",
      "Epoch:170/200 AVG Training Loss:0.634 AVG Validation Loss:0.670 AVG Training Acc 62.90 % AVG Validation Acc 62.27 %\n",
      "Epoch:180/200 AVG Training Loss:0.631 AVG Validation Loss:0.668 AVG Training Acc 62.72 % AVG Validation Acc 62.64 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.630 AVG Validation Loss:0.668 AVG Training Acc 62.83 % AVG Validation Acc 62.64 %\n",
      "Epoch:200/200 AVG Training Loss:0.632 AVG Validation Loss:0.669 AVG Training Acc 62.57 % AVG Validation Acc 62.91 %\n",
      "Split 269\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "658c08e35b884a2492c43d66166afbc0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.655 AVG Validation Loss:0.666 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.645 AVG Validation Loss:0.687 AVG Training Acc 62.60 % AVG Validation Acc 59.39 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.647 AVG Validation Loss:0.678 AVG Training Acc 62.10 % AVG Validation Acc 61.82 %\n",
      "Epoch:40/200 AVG Training Loss:0.636 AVG Validation Loss:0.691 AVG Training Acc 62.71 % AVG Validation Acc 61.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.632 AVG Validation Loss:0.699 AVG Training Acc 62.60 % AVG Validation Acc 61.82 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.625 AVG Validation Loss:0.709 AVG Training Acc 63.19 % AVG Validation Acc 61.28 %\n",
      "Epoch:70/200 AVG Training Loss:0.625 AVG Validation Loss:0.711 AVG Training Acc 62.93 % AVG Validation Acc 61.10 %\n",
      "Epoch:80/200 AVG Training Loss:0.623 AVG Validation Loss:0.716 AVG Training Acc 63.02 % AVG Validation Acc 61.10 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.621 AVG Validation Loss:0.722 AVG Training Acc 63.18 % AVG Validation Acc 61.01 %\n",
      "Epoch:100/200 AVG Training Loss:0.623 AVG Validation Loss:0.713 AVG Training Acc 63.08 % AVG Validation Acc 60.83 %\n",
      "Epoch:110/200 AVG Training Loss:0.622 AVG Validation Loss:0.718 AVG Training Acc 63.16 % AVG Validation Acc 60.92 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.622 AVG Validation Loss:0.716 AVG Training Acc 63.43 % AVG Validation Acc 61.01 %\n",
      "Epoch:130/200 AVG Training Loss:0.623 AVG Validation Loss:0.719 AVG Training Acc 62.90 % AVG Validation Acc 60.92 %\n",
      "Epoch:140/200 AVG Training Loss:0.622 AVG Validation Loss:0.723 AVG Training Acc 63.13 % AVG Validation Acc 60.83 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.624 AVG Validation Loss:0.716 AVG Training Acc 63.22 % AVG Validation Acc 61.01 %\n",
      "Epoch:160/200 AVG Training Loss:0.622 AVG Validation Loss:0.716 AVG Training Acc 63.07 % AVG Validation Acc 60.65 %\n",
      "Epoch:170/200 AVG Training Loss:0.621 AVG Validation Loss:0.718 AVG Training Acc 63.29 % AVG Validation Acc 61.19 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.622 AVG Validation Loss:0.719 AVG Training Acc 63.37 % AVG Validation Acc 60.83 %\n",
      "Epoch:190/200 AVG Training Loss:0.622 AVG Validation Loss:0.715 AVG Training Acc 63.06 % AVG Validation Acc 61.01 %\n",
      "Epoch:200/200 AVG Training Loss:0.623 AVG Validation Loss:0.717 AVG Training Acc 62.81 % AVG Validation Acc 61.01 %\n",
      "Split 270\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf2d8e7c24e4912880cd7f631c90f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.656 AVG Validation Loss:0.662 AVG Training Acc 61.87 % AVG Validation Acc 62.00 %\n",
      "Epoch:20/200 AVG Training Loss:0.649 AVG Validation Loss:0.660 AVG Training Acc 62.54 % AVG Validation Acc 62.00 %\n",
      "Epoch:30/200 AVG Training Loss:0.648 AVG Validation Loss:0.660 AVG Training Acc 61.71 % AVG Validation Acc 62.00 %\n",
      "Epoch:40/200 AVG Training Loss:0.642 AVG Validation Loss:0.659 AVG Training Acc 62.45 % AVG Validation Acc 62.18 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.625 AVG Validation Loss:0.668 AVG Training Acc 63.67 % AVG Validation Acc 60.83 %\n",
      "Epoch:60/200 AVG Training Loss:0.601 AVG Validation Loss:0.692 AVG Training Acc 66.15 % AVG Validation Acc 56.95 %\n",
      "Epoch:70/200 AVG Training Loss:0.594 AVG Validation Loss:0.695 AVG Training Acc 67.25 % AVG Validation Acc 57.58 %\n",
      "Epoch:80/200 AVG Training Loss:0.585 AVG Validation Loss:0.713 AVG Training Acc 67.80 % AVG Validation Acc 57.04 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.581 AVG Validation Loss:0.711 AVG Training Acc 67.86 % AVG Validation Acc 56.77 %\n",
      "Epoch:100/200 AVG Training Loss:0.578 AVG Validation Loss:0.712 AVG Training Acc 68.41 % AVG Validation Acc 56.86 %\n",
      "Epoch:110/200 AVG Training Loss:0.581 AVG Validation Loss:0.716 AVG Training Acc 68.01 % AVG Validation Acc 56.59 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.579 AVG Validation Loss:0.719 AVG Training Acc 68.08 % AVG Validation Acc 56.86 %\n",
      "Epoch:130/200 AVG Training Loss:0.577 AVG Validation Loss:0.714 AVG Training Acc 68.36 % AVG Validation Acc 56.95 %\n",
      "Epoch:140/200 AVG Training Loss:0.576 AVG Validation Loss:0.710 AVG Training Acc 68.65 % AVG Validation Acc 56.95 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.578 AVG Validation Loss:0.715 AVG Training Acc 68.40 % AVG Validation Acc 57.22 %\n",
      "Epoch:160/200 AVG Training Loss:0.576 AVG Validation Loss:0.713 AVG Training Acc 67.82 % AVG Validation Acc 56.23 %\n",
      "Epoch:170/200 AVG Training Loss:0.575 AVG Validation Loss:0.715 AVG Training Acc 68.29 % AVG Validation Acc 56.86 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.577 AVG Validation Loss:0.713 AVG Training Acc 68.10 % AVG Validation Acc 57.13 %\n",
      "Epoch:190/200 AVG Training Loss:0.574 AVG Validation Loss:0.715 AVG Training Acc 68.43 % AVG Validation Acc 57.40 %\n",
      "Epoch:200/200 AVG Training Loss:0.576 AVG Validation Loss:0.712 AVG Training Acc 68.53 % AVG Validation Acc 57.04 %\n",
      "Split 271\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4694b58a634945199c99da05ee11857c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.656 AVG Training Acc 62.10 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.656 AVG Validation Loss:0.652 AVG Training Acc 61.87 % AVG Validation Acc 62.04 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.644 AVG Validation Loss:0.651 AVG Training Acc 62.48 % AVG Validation Acc 61.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.633 AVG Validation Loss:0.662 AVG Training Acc 63.27 % AVG Validation Acc 62.49 %\n",
      "Epoch:50/200 AVG Training Loss:0.623 AVG Validation Loss:0.667 AVG Training Acc 64.33 % AVG Validation Acc 61.95 %\n",
      "Epoch:60/200 AVG Training Loss:0.616 AVG Validation Loss:0.674 AVG Training Acc 64.39 % AVG Validation Acc 61.23 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.614 AVG Validation Loss:0.673 AVG Training Acc 64.49 % AVG Validation Acc 61.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.610 AVG Validation Loss:0.683 AVG Training Acc 64.93 % AVG Validation Acc 61.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.611 AVG Validation Loss:0.682 AVG Training Acc 64.84 % AVG Validation Acc 61.14 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.608 AVG Validation Loss:0.682 AVG Training Acc 65.38 % AVG Validation Acc 61.32 %\n",
      "Epoch:110/200 AVG Training Loss:0.608 AVG Validation Loss:0.685 AVG Training Acc 65.46 % AVG Validation Acc 60.60 %\n",
      "Epoch:120/200 AVG Training Loss:0.610 AVG Validation Loss:0.685 AVG Training Acc 65.36 % AVG Validation Acc 61.50 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.610 AVG Validation Loss:0.680 AVG Training Acc 64.69 % AVG Validation Acc 61.32 %\n",
      "Epoch:140/200 AVG Training Loss:0.609 AVG Validation Loss:0.687 AVG Training Acc 65.14 % AVG Validation Acc 60.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.610 AVG Validation Loss:0.690 AVG Training Acc 64.83 % AVG Validation Acc 60.69 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.610 AVG Validation Loss:0.682 AVG Training Acc 64.85 % AVG Validation Acc 60.96 %\n",
      "Epoch:170/200 AVG Training Loss:0.610 AVG Validation Loss:0.679 AVG Training Acc 64.84 % AVG Validation Acc 60.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.609 AVG Validation Loss:0.682 AVG Training Acc 65.02 % AVG Validation Acc 60.87 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.607 AVG Validation Loss:0.688 AVG Training Acc 65.10 % AVG Validation Acc 61.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.610 AVG Validation Loss:0.690 AVG Training Acc 64.86 % AVG Validation Acc 61.23 %\n",
      "Split 272\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4b14117ab184e2aa16434e6266e8f86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.656 AVG Training Acc 61.88 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.656 AVG Validation Loss:0.655 AVG Training Acc 61.85 % AVG Validation Acc 61.86 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.637 AVG Validation Loss:0.660 AVG Training Acc 62.88 % AVG Validation Acc 63.21 %\n",
      "Epoch:40/200 AVG Training Loss:0.625 AVG Validation Loss:0.669 AVG Training Acc 64.21 % AVG Validation Acc 61.95 %\n",
      "Epoch:50/200 AVG Training Loss:0.618 AVG Validation Loss:0.670 AVG Training Acc 64.68 % AVG Validation Acc 62.49 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.609 AVG Validation Loss:0.676 AVG Training Acc 65.67 % AVG Validation Acc 62.67 %\n",
      "Epoch:70/200 AVG Training Loss:0.609 AVG Validation Loss:0.679 AVG Training Acc 66.09 % AVG Validation Acc 61.50 %\n",
      "Epoch:80/200 AVG Training Loss:0.605 AVG Validation Loss:0.680 AVG Training Acc 65.81 % AVG Validation Acc 62.13 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.603 AVG Validation Loss:0.681 AVG Training Acc 65.65 % AVG Validation Acc 62.49 %\n",
      "Epoch:100/200 AVG Training Loss:0.603 AVG Validation Loss:0.681 AVG Training Acc 65.86 % AVG Validation Acc 61.59 %\n",
      "Epoch:110/200 AVG Training Loss:0.606 AVG Validation Loss:0.681 AVG Training Acc 65.92 % AVG Validation Acc 62.31 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.602 AVG Validation Loss:0.681 AVG Training Acc 65.77 % AVG Validation Acc 62.40 %\n",
      "Epoch:130/200 AVG Training Loss:0.603 AVG Validation Loss:0.680 AVG Training Acc 65.55 % AVG Validation Acc 62.67 %\n",
      "Epoch:140/200 AVG Training Loss:0.603 AVG Validation Loss:0.682 AVG Training Acc 66.10 % AVG Validation Acc 62.40 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.601 AVG Validation Loss:0.678 AVG Training Acc 65.97 % AVG Validation Acc 62.58 %\n",
      "Epoch:160/200 AVG Training Loss:0.605 AVG Validation Loss:0.681 AVG Training Acc 65.78 % AVG Validation Acc 62.31 %\n",
      "Epoch:170/200 AVG Training Loss:0.603 AVG Validation Loss:0.682 AVG Training Acc 66.01 % AVG Validation Acc 63.03 %\n",
      "Epoch:180/200 AVG Training Loss:0.604 AVG Validation Loss:0.681 AVG Training Acc 65.69 % AVG Validation Acc 62.31 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.601 AVG Validation Loss:0.680 AVG Training Acc 66.04 % AVG Validation Acc 63.03 %\n",
      "Epoch:200/200 AVG Training Loss:0.604 AVG Validation Loss:0.681 AVG Training Acc 65.69 % AVG Validation Acc 62.22 %\n",
      "Split 273\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69a02bd7ec8741479fc9c5537c878d0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.659 AVG Training Acc 61.84 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.652 AVG Training Acc 62.10 % AVG Validation Acc 61.77 %\n",
      "Epoch:30/200 AVG Training Loss:0.639 AVG Validation Loss:0.670 AVG Training Acc 63.22 % AVG Validation Acc 60.41 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.611 AVG Validation Loss:0.682 AVG Training Acc 65.04 % AVG Validation Acc 60.87 %\n",
      "Epoch:50/200 AVG Training Loss:0.600 AVG Validation Loss:0.693 AVG Training Acc 65.58 % AVG Validation Acc 61.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.587 AVG Validation Loss:0.710 AVG Training Acc 66.03 % AVG Validation Acc 62.13 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.581 AVG Validation Loss:0.716 AVG Training Acc 67.01 % AVG Validation Acc 61.23 %\n",
      "Epoch:80/200 AVG Training Loss:0.578 AVG Validation Loss:0.717 AVG Training Acc 66.78 % AVG Validation Acc 60.87 %\n",
      "Epoch:90/200 AVG Training Loss:0.576 AVG Validation Loss:0.720 AVG Training Acc 66.84 % AVG Validation Acc 61.05 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.577 AVG Validation Loss:0.729 AVG Training Acc 66.72 % AVG Validation Acc 61.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.577 AVG Validation Loss:0.728 AVG Training Acc 66.85 % AVG Validation Acc 60.32 %\n",
      "Epoch:120/200 AVG Training Loss:0.575 AVG Validation Loss:0.723 AVG Training Acc 67.03 % AVG Validation Acc 60.87 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.574 AVG Validation Loss:0.724 AVG Training Acc 67.30 % AVG Validation Acc 60.50 %\n",
      "Epoch:140/200 AVG Training Loss:0.574 AVG Validation Loss:0.723 AVG Training Acc 66.91 % AVG Validation Acc 61.05 %\n",
      "Epoch:150/200 AVG Training Loss:0.576 AVG Validation Loss:0.723 AVG Training Acc 67.05 % AVG Validation Acc 60.69 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.574 AVG Validation Loss:0.730 AVG Training Acc 67.05 % AVG Validation Acc 60.41 %\n",
      "Epoch:170/200 AVG Training Loss:0.576 AVG Validation Loss:0.727 AVG Training Acc 67.10 % AVG Validation Acc 61.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.576 AVG Validation Loss:0.724 AVG Training Acc 66.73 % AVG Validation Acc 60.60 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.575 AVG Validation Loss:0.725 AVG Training Acc 67.26 % AVG Validation Acc 60.41 %\n",
      "Epoch:200/200 AVG Training Loss:0.574 AVG Validation Loss:0.728 AVG Training Acc 67.06 % AVG Validation Acc 60.05 %\n",
      "Split 274\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8180af7bf3f6481f8359163eed5ded6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.654 AVG Training Acc 61.93 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.649 AVG Validation Loss:0.667 AVG Training Acc 62.00 % AVG Validation Acc 61.05 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.635 AVG Validation Loss:0.659 AVG Training Acc 62.66 % AVG Validation Acc 60.32 %\n",
      "Epoch:40/200 AVG Training Loss:0.625 AVG Validation Loss:0.664 AVG Training Acc 63.66 % AVG Validation Acc 59.15 %\n",
      "Epoch:50/200 AVG Training Loss:0.614 AVG Validation Loss:0.673 AVG Training Acc 64.74 % AVG Validation Acc 59.33 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.608 AVG Validation Loss:0.677 AVG Training Acc 65.16 % AVG Validation Acc 59.42 %\n",
      "Epoch:70/200 AVG Training Loss:0.606 AVG Validation Loss:0.677 AVG Training Acc 65.43 % AVG Validation Acc 59.51 %\n",
      "Epoch:80/200 AVG Training Loss:0.606 AVG Validation Loss:0.683 AVG Training Acc 65.60 % AVG Validation Acc 59.24 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.605 AVG Validation Loss:0.683 AVG Training Acc 65.21 % AVG Validation Acc 58.79 %\n",
      "Epoch:100/200 AVG Training Loss:0.605 AVG Validation Loss:0.680 AVG Training Acc 65.44 % AVG Validation Acc 59.06 %\n",
      "Epoch:110/200 AVG Training Loss:0.602 AVG Validation Loss:0.678 AVG Training Acc 65.89 % AVG Validation Acc 59.24 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.604 AVG Validation Loss:0.678 AVG Training Acc 65.00 % AVG Validation Acc 59.42 %\n",
      "Epoch:130/200 AVG Training Loss:0.602 AVG Validation Loss:0.680 AVG Training Acc 65.82 % AVG Validation Acc 59.33 %\n",
      "Epoch:140/200 AVG Training Loss:0.605 AVG Validation Loss:0.683 AVG Training Acc 65.08 % AVG Validation Acc 58.70 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.603 AVG Validation Loss:0.679 AVG Training Acc 66.05 % AVG Validation Acc 59.42 %\n",
      "Epoch:160/200 AVG Training Loss:0.603 AVG Validation Loss:0.684 AVG Training Acc 65.51 % AVG Validation Acc 58.70 %\n",
      "Epoch:170/200 AVG Training Loss:0.603 AVG Validation Loss:0.682 AVG Training Acc 65.48 % AVG Validation Acc 59.24 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.602 AVG Validation Loss:0.679 AVG Training Acc 65.49 % AVG Validation Acc 59.33 %\n",
      "Epoch:190/200 AVG Training Loss:0.602 AVG Validation Loss:0.683 AVG Training Acc 65.70 % AVG Validation Acc 59.24 %\n",
      "Epoch:200/200 AVG Training Loss:0.606 AVG Validation Loss:0.683 AVG Training Acc 65.47 % AVG Validation Acc 58.88 %\n",
      "Split 275\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd5403a7c702476485d9611a42c2ab22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.660 AVG Validation Loss:0.659 AVG Training Acc 61.86 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.665 AVG Training Acc 61.75 % AVG Validation Acc 61.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:0.653 AVG Training Acc 61.63 % AVG Validation Acc 61.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.646 AVG Validation Loss:0.650 AVG Training Acc 62.39 % AVG Validation Acc 62.58 %\n",
      "Epoch:50/200 AVG Training Loss:0.642 AVG Validation Loss:0.647 AVG Training Acc 62.10 % AVG Validation Acc 62.04 %\n",
      "Epoch:60/200 AVG Training Loss:0.638 AVG Validation Loss:0.656 AVG Training Acc 63.32 % AVG Validation Acc 62.94 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:70/200 AVG Training Loss:0.607 AVG Validation Loss:0.664 AVG Training Acc 65.42 % AVG Validation Acc 61.86 %\n",
      "Epoch:80/200 AVG Training Loss:0.597 AVG Validation Loss:0.665 AVG Training Acc 66.19 % AVG Validation Acc 61.32 %\n",
      "Epoch:90/200 AVG Training Loss:0.590 AVG Validation Loss:0.678 AVG Training Acc 66.45 % AVG Validation Acc 61.59 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.584 AVG Validation Loss:0.673 AVG Training Acc 67.35 % AVG Validation Acc 60.69 %\n",
      "Epoch:110/200 AVG Training Loss:0.585 AVG Validation Loss:0.676 AVG Training Acc 67.19 % AVG Validation Acc 60.60 %\n",
      "Epoch:120/200 AVG Training Loss:0.584 AVG Validation Loss:0.676 AVG Training Acc 67.77 % AVG Validation Acc 60.96 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.583 AVG Validation Loss:0.680 AVG Training Acc 67.88 % AVG Validation Acc 60.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.580 AVG Validation Loss:0.682 AVG Training Acc 67.40 % AVG Validation Acc 61.32 %\n",
      "Epoch:150/200 AVG Training Loss:0.582 AVG Validation Loss:0.685 AVG Training Acc 67.50 % AVG Validation Acc 60.41 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.580 AVG Validation Loss:0.679 AVG Training Acc 67.10 % AVG Validation Acc 61.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.582 AVG Validation Loss:0.678 AVG Training Acc 67.75 % AVG Validation Acc 61.50 %\n",
      "Epoch:180/200 AVG Training Loss:0.581 AVG Validation Loss:0.686 AVG Training Acc 67.47 % AVG Validation Acc 60.60 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.581 AVG Validation Loss:0.689 AVG Training Acc 67.84 % AVG Validation Acc 59.60 %\n",
      "Epoch:200/200 AVG Training Loss:0.582 AVG Validation Loss:0.683 AVG Training Acc 67.37 % AVG Validation Acc 60.69 %\n",
      "Split 276\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5da85fc92d614b538067599c9101ec60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.659 AVG Training Acc 62.00 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.660 AVG Training Acc 61.87 % AVG Validation Acc 61.73 %\n",
      "Epoch:30/200 AVG Training Loss:0.646 AVG Validation Loss:0.668 AVG Training Acc 62.28 % AVG Validation Acc 61.73 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.631 AVG Validation Loss:0.671 AVG Training Acc 63.15 % AVG Validation Acc 61.37 %\n",
      "Epoch:50/200 AVG Training Loss:0.622 AVG Validation Loss:0.686 AVG Training Acc 63.65 % AVG Validation Acc 61.73 %\n",
      "Epoch:60/200 AVG Training Loss:0.615 AVG Validation Loss:0.692 AVG Training Acc 64.59 % AVG Validation Acc 61.73 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.605 AVG Validation Loss:0.699 AVG Training Acc 65.06 % AVG Validation Acc 61.64 %\n",
      "Epoch:80/200 AVG Training Loss:0.606 AVG Validation Loss:0.698 AVG Training Acc 65.13 % AVG Validation Acc 61.82 %\n",
      "Epoch:90/200 AVG Training Loss:0.604 AVG Validation Loss:0.703 AVG Training Acc 64.98 % AVG Validation Acc 62.00 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.605 AVG Validation Loss:0.703 AVG Training Acc 65.46 % AVG Validation Acc 61.82 %\n",
      "Epoch:110/200 AVG Training Loss:0.603 AVG Validation Loss:0.700 AVG Training Acc 65.16 % AVG Validation Acc 62.00 %\n",
      "Epoch:120/200 AVG Training Loss:0.604 AVG Validation Loss:0.701 AVG Training Acc 65.88 % AVG Validation Acc 62.00 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.606 AVG Validation Loss:0.702 AVG Training Acc 65.12 % AVG Validation Acc 62.27 %\n",
      "Epoch:140/200 AVG Training Loss:0.603 AVG Validation Loss:0.701 AVG Training Acc 65.26 % AVG Validation Acc 61.73 %\n",
      "Epoch:150/200 AVG Training Loss:0.603 AVG Validation Loss:0.704 AVG Training Acc 65.40 % AVG Validation Acc 61.64 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.603 AVG Validation Loss:0.703 AVG Training Acc 65.60 % AVG Validation Acc 61.73 %\n",
      "Epoch:170/200 AVG Training Loss:0.602 AVG Validation Loss:0.702 AVG Training Acc 65.48 % AVG Validation Acc 61.73 %\n",
      "Epoch:180/200 AVG Training Loss:0.603 AVG Validation Loss:0.707 AVG Training Acc 65.84 % AVG Validation Acc 62.09 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.602 AVG Validation Loss:0.699 AVG Training Acc 65.68 % AVG Validation Acc 62.00 %\n",
      "Epoch:200/200 AVG Training Loss:0.604 AVG Validation Loss:0.701 AVG Training Acc 65.44 % AVG Validation Acc 61.64 %\n",
      "Split 277\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f9ab2ff9a641a28f02ee936c5c49c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.663 AVG Validation Loss:0.668 AVG Training Acc 61.88 % AVG Validation Acc 61.91 %\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.658 AVG Validation Loss:0.666 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:0.666 AVG Training Acc 61.99 % AVG Validation Acc 61.82 %\n",
      "Epoch:40/200 AVG Training Loss:0.654 AVG Validation Loss:0.663 AVG Training Acc 61.93 % AVG Validation Acc 61.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.651 AVG Validation Loss:0.659 AVG Training Acc 61.99 % AVG Validation Acc 61.91 %\n",
      "Epoch:60/200 AVG Training Loss:0.649 AVG Validation Loss:0.659 AVG Training Acc 62.08 % AVG Validation Acc 62.36 %\n",
      "Epoch:70/200 AVG Training Loss:0.646 AVG Validation Loss:0.658 AVG Training Acc 62.20 % AVG Validation Acc 61.91 %\n",
      "Epoch    70: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.641 AVG Validation Loss:0.665 AVG Training Acc 62.45 % AVG Validation Acc 61.01 %\n",
      "Epoch:90/200 AVG Training Loss:0.641 AVG Validation Loss:0.668 AVG Training Acc 62.53 % AVG Validation Acc 61.10 %\n",
      "Epoch:100/200 AVG Training Loss:0.639 AVG Validation Loss:0.673 AVG Training Acc 62.71 % AVG Validation Acc 61.19 %\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.640 AVG Validation Loss:0.674 AVG Training Acc 62.56 % AVG Validation Acc 61.10 %\n",
      "Epoch:120/200 AVG Training Loss:0.640 AVG Validation Loss:0.674 AVG Training Acc 62.34 % AVG Validation Acc 61.10 %\n",
      "Epoch:130/200 AVG Training Loss:0.639 AVG Validation Loss:0.675 AVG Training Acc 62.93 % AVG Validation Acc 61.10 %\n",
      "Epoch   132: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.639 AVG Validation Loss:0.675 AVG Training Acc 62.83 % AVG Validation Acc 61.10 %\n",
      "Epoch:150/200 AVG Training Loss:0.639 AVG Validation Loss:0.676 AVG Training Acc 62.65 % AVG Validation Acc 61.19 %\n",
      "Epoch:160/200 AVG Training Loss:0.639 AVG Validation Loss:0.675 AVG Training Acc 62.68 % AVG Validation Acc 61.19 %\n",
      "Epoch   163: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.639 AVG Validation Loss:0.676 AVG Training Acc 62.92 % AVG Validation Acc 61.10 %\n",
      "Epoch:180/200 AVG Training Loss:0.640 AVG Validation Loss:0.675 AVG Training Acc 62.64 % AVG Validation Acc 61.10 %\n",
      "Epoch:190/200 AVG Training Loss:0.639 AVG Validation Loss:0.675 AVG Training Acc 62.74 % AVG Validation Acc 61.28 %\n",
      "Epoch   194: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.639 AVG Validation Loss:0.675 AVG Training Acc 62.70 % AVG Validation Acc 61.01 %\n",
      "Split 278\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf86665219b845da914fa5d67bac7c24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.660 AVG Training Acc 61.68 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.650 AVG Validation Loss:0.662 AVG Training Acc 62.13 % AVG Validation Acc 61.64 %\n",
      "Epoch:30/200 AVG Training Loss:0.642 AVG Validation Loss:0.661 AVG Training Acc 62.34 % AVG Validation Acc 61.64 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.646 AVG Validation Loss:0.662 AVG Training Acc 62.33 % AVG Validation Acc 62.45 %\n",
      "Epoch:50/200 AVG Training Loss:0.636 AVG Validation Loss:0.664 AVG Training Acc 62.60 % AVG Validation Acc 61.46 %\n",
      "Epoch:60/200 AVG Training Loss:0.626 AVG Validation Loss:0.674 AVG Training Acc 62.99 % AVG Validation Acc 60.83 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.618 AVG Validation Loss:0.681 AVG Training Acc 63.42 % AVG Validation Acc 60.83 %\n",
      "Epoch:80/200 AVG Training Loss:0.615 AVG Validation Loss:0.680 AVG Training Acc 63.90 % AVG Validation Acc 60.83 %\n",
      "Epoch:90/200 AVG Training Loss:0.614 AVG Validation Loss:0.683 AVG Training Acc 63.88 % AVG Validation Acc 60.11 %\n",
      "Epoch:100/200 AVG Training Loss:0.611 AVG Validation Loss:0.685 AVG Training Acc 64.40 % AVG Validation Acc 60.02 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.612 AVG Validation Loss:0.684 AVG Training Acc 64.08 % AVG Validation Acc 60.47 %\n",
      "Epoch:120/200 AVG Training Loss:0.612 AVG Validation Loss:0.685 AVG Training Acc 64.18 % AVG Validation Acc 60.38 %\n",
      "Epoch:130/200 AVG Training Loss:0.612 AVG Validation Loss:0.688 AVG Training Acc 64.26 % AVG Validation Acc 60.29 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.613 AVG Validation Loss:0.687 AVG Training Acc 63.55 % AVG Validation Acc 60.65 %\n",
      "Epoch:150/200 AVG Training Loss:0.613 AVG Validation Loss:0.689 AVG Training Acc 64.01 % AVG Validation Acc 60.65 %\n",
      "Epoch:160/200 AVG Training Loss:0.612 AVG Validation Loss:0.685 AVG Training Acc 64.13 % AVG Validation Acc 60.29 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.610 AVG Validation Loss:0.682 AVG Training Acc 64.37 % AVG Validation Acc 60.83 %\n",
      "Epoch:180/200 AVG Training Loss:0.612 AVG Validation Loss:0.684 AVG Training Acc 64.12 % AVG Validation Acc 60.20 %\n",
      "Epoch:190/200 AVG Training Loss:0.614 AVG Validation Loss:0.684 AVG Training Acc 64.06 % AVG Validation Acc 60.20 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.611 AVG Validation Loss:0.689 AVG Training Acc 64.60 % AVG Validation Acc 60.47 %\n",
      "Split 279\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2e40e214c6f4f4f810f1cf48c59583a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 61.99 % AVG Validation Acc 61.82 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.656 AVG Training Acc 62.22 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:0.666 AVG Training Acc 61.78 % AVG Validation Acc 61.19 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:0.655 AVG Training Acc 62.07 % AVG Validation Acc 61.73 %\n",
      "Epoch:50/200 AVG Training Loss:0.645 AVG Validation Loss:0.654 AVG Training Acc 62.10 % AVG Validation Acc 61.73 %\n",
      "Epoch:60/200 AVG Training Loss:0.642 AVG Validation Loss:0.658 AVG Training Acc 62.49 % AVG Validation Acc 62.18 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.636 AVG Validation Loss:0.662 AVG Training Acc 62.98 % AVG Validation Acc 62.82 %\n",
      "Epoch:80/200 AVG Training Loss:0.634 AVG Validation Loss:0.664 AVG Training Acc 62.56 % AVG Validation Acc 62.82 %\n",
      "Epoch:90/200 AVG Training Loss:0.635 AVG Validation Loss:0.662 AVG Training Acc 62.69 % AVG Validation Acc 62.55 %\n",
      "Epoch:100/200 AVG Training Loss:0.634 AVG Validation Loss:0.664 AVG Training Acc 62.64 % AVG Validation Acc 62.91 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.633 AVG Validation Loss:0.665 AVG Training Acc 62.75 % AVG Validation Acc 62.64 %\n",
      "Epoch:120/200 AVG Training Loss:0.634 AVG Validation Loss:0.663 AVG Training Acc 62.90 % AVG Validation Acc 62.36 %\n",
      "Epoch:130/200 AVG Training Loss:0.634 AVG Validation Loss:0.663 AVG Training Acc 62.86 % AVG Validation Acc 62.55 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.633 AVG Validation Loss:0.664 AVG Training Acc 63.10 % AVG Validation Acc 62.36 %\n",
      "Epoch:150/200 AVG Training Loss:0.634 AVG Validation Loss:0.667 AVG Training Acc 62.64 % AVG Validation Acc 62.18 %\n",
      "Epoch:160/200 AVG Training Loss:0.634 AVG Validation Loss:0.665 AVG Training Acc 62.83 % AVG Validation Acc 62.45 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.633 AVG Validation Loss:0.669 AVG Training Acc 63.06 % AVG Validation Acc 62.36 %\n",
      "Epoch:180/200 AVG Training Loss:0.633 AVG Validation Loss:0.667 AVG Training Acc 63.19 % AVG Validation Acc 62.55 %\n",
      "Epoch:190/200 AVG Training Loss:0.634 AVG Validation Loss:0.663 AVG Training Acc 62.62 % AVG Validation Acc 61.91 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.633 AVG Validation Loss:0.664 AVG Training Acc 63.07 % AVG Validation Acc 62.55 %\n",
      "Split 280\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc080676b6b4e42a971e974af95c0b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.663 AVG Validation Loss:0.662 AVG Training Acc 61.89 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.657 AVG Training Acc 62.02 % AVG Validation Acc 61.55 %\n",
      "Epoch:30/200 AVG Training Loss:0.643 AVG Validation Loss:0.665 AVG Training Acc 62.34 % AVG Validation Acc 61.28 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.619 AVG Validation Loss:0.682 AVG Training Acc 64.39 % AVG Validation Acc 59.03 %\n",
      "Epoch:50/200 AVG Training Loss:0.610 AVG Validation Loss:0.689 AVG Training Acc 64.75 % AVG Validation Acc 57.94 %\n",
      "Epoch:60/200 AVG Training Loss:0.605 AVG Validation Loss:0.692 AVG Training Acc 65.65 % AVG Validation Acc 58.66 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.598 AVG Validation Loss:0.697 AVG Training Acc 65.77 % AVG Validation Acc 58.12 %\n",
      "Epoch:80/200 AVG Training Loss:0.596 AVG Validation Loss:0.702 AVG Training Acc 65.90 % AVG Validation Acc 57.49 %\n",
      "Epoch:90/200 AVG Training Loss:0.595 AVG Validation Loss:0.702 AVG Training Acc 66.05 % AVG Validation Acc 57.67 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.595 AVG Validation Loss:0.700 AVG Training Acc 66.67 % AVG Validation Acc 57.85 %\n",
      "Epoch:110/200 AVG Training Loss:0.593 AVG Validation Loss:0.700 AVG Training Acc 66.69 % AVG Validation Acc 57.76 %\n",
      "Epoch:120/200 AVG Training Loss:0.595 AVG Validation Loss:0.702 AVG Training Acc 65.93 % AVG Validation Acc 56.86 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.593 AVG Validation Loss:0.699 AVG Training Acc 66.83 % AVG Validation Acc 57.76 %\n",
      "Epoch:140/200 AVG Training Loss:0.594 AVG Validation Loss:0.702 AVG Training Acc 66.34 % AVG Validation Acc 57.31 %\n",
      "Epoch:150/200 AVG Training Loss:0.594 AVG Validation Loss:0.700 AVG Training Acc 66.60 % AVG Validation Acc 57.67 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.596 AVG Validation Loss:0.700 AVG Training Acc 66.25 % AVG Validation Acc 57.58 %\n",
      "Epoch:170/200 AVG Training Loss:0.597 AVG Validation Loss:0.701 AVG Training Acc 66.08 % AVG Validation Acc 57.49 %\n",
      "Epoch:180/200 AVG Training Loss:0.594 AVG Validation Loss:0.700 AVG Training Acc 66.09 % AVG Validation Acc 57.49 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.594 AVG Validation Loss:0.705 AVG Training Acc 66.10 % AVG Validation Acc 57.22 %\n",
      "Epoch:200/200 AVG Training Loss:0.595 AVG Validation Loss:0.700 AVG Training Acc 65.97 % AVG Validation Acc 56.86 %\n",
      "Split 281\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7601d5819cb4800b4bc5c013cd01903",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.664 AVG Training Acc 61.86 % AVG Validation Acc 62.13 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.669 AVG Training Acc 61.77 % AVG Validation Acc 62.22 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.637 AVG Validation Loss:0.668 AVG Training Acc 62.37 % AVG Validation Acc 61.32 %\n",
      "Epoch:40/200 AVG Training Loss:0.629 AVG Validation Loss:0.668 AVG Training Acc 63.07 % AVG Validation Acc 60.69 %\n",
      "Epoch:50/200 AVG Training Loss:0.620 AVG Validation Loss:0.676 AVG Training Acc 63.50 % AVG Validation Acc 60.14 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.613 AVG Validation Loss:0.687 AVG Training Acc 64.11 % AVG Validation Acc 60.41 %\n",
      "Epoch:70/200 AVG Training Loss:0.612 AVG Validation Loss:0.687 AVG Training Acc 63.97 % AVG Validation Acc 60.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.611 AVG Validation Loss:0.688 AVG Training Acc 64.40 % AVG Validation Acc 60.14 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.609 AVG Validation Loss:0.692 AVG Training Acc 64.38 % AVG Validation Acc 59.60 %\n",
      "Epoch:100/200 AVG Training Loss:0.610 AVG Validation Loss:0.691 AVG Training Acc 64.39 % AVG Validation Acc 59.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.610 AVG Validation Loss:0.689 AVG Training Acc 63.95 % AVG Validation Acc 60.60 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.607 AVG Validation Loss:0.692 AVG Training Acc 64.64 % AVG Validation Acc 59.96 %\n",
      "Epoch:130/200 AVG Training Loss:0.608 AVG Validation Loss:0.690 AVG Training Acc 64.37 % AVG Validation Acc 59.24 %\n",
      "Epoch:140/200 AVG Training Loss:0.609 AVG Validation Loss:0.693 AVG Training Acc 64.53 % AVG Validation Acc 59.42 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.609 AVG Validation Loss:0.690 AVG Training Acc 64.14 % AVG Validation Acc 60.50 %\n",
      "Epoch:160/200 AVG Training Loss:0.611 AVG Validation Loss:0.689 AVG Training Acc 64.13 % AVG Validation Acc 59.51 %\n",
      "Epoch:170/200 AVG Training Loss:0.609 AVG Validation Loss:0.694 AVG Training Acc 64.25 % AVG Validation Acc 59.96 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.610 AVG Validation Loss:0.691 AVG Training Acc 64.27 % AVG Validation Acc 59.78 %\n",
      "Epoch:190/200 AVG Training Loss:0.608 AVG Validation Loss:0.689 AVG Training Acc 64.83 % AVG Validation Acc 60.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.609 AVG Validation Loss:0.693 AVG Training Acc 64.23 % AVG Validation Acc 59.24 %\n",
      "Split 282\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8576031cefb747a0a85a7d04a556352c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.654 AVG Training Acc 61.77 % AVG Validation Acc 62.04 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.654 AVG Training Acc 61.88 % AVG Validation Acc 62.40 %\n",
      "Epoch:30/200 AVG Training Loss:0.646 AVG Validation Loss:0.652 AVG Training Acc 62.22 % AVG Validation Acc 61.95 %\n",
      "Epoch:40/200 AVG Training Loss:0.638 AVG Validation Loss:0.664 AVG Training Acc 62.38 % AVG Validation Acc 60.87 %\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.607 AVG Validation Loss:0.670 AVG Training Acc 65.03 % AVG Validation Acc 61.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.596 AVG Validation Loss:0.684 AVG Training Acc 66.01 % AVG Validation Acc 59.69 %\n",
      "Epoch:70/200 AVG Training Loss:0.591 AVG Validation Loss:0.689 AVG Training Acc 66.37 % AVG Validation Acc 59.87 %\n",
      "Epoch    71: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.586 AVG Validation Loss:0.696 AVG Training Acc 66.79 % AVG Validation Acc 58.97 %\n",
      "Epoch:90/200 AVG Training Loss:0.585 AVG Validation Loss:0.699 AVG Training Acc 67.00 % AVG Validation Acc 59.51 %\n",
      "Epoch:100/200 AVG Training Loss:0.584 AVG Validation Loss:0.697 AVG Training Acc 66.77 % AVG Validation Acc 59.60 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.581 AVG Validation Loss:0.695 AVG Training Acc 67.28 % AVG Validation Acc 60.14 %\n",
      "Epoch:120/200 AVG Training Loss:0.582 AVG Validation Loss:0.702 AVG Training Acc 67.26 % AVG Validation Acc 59.78 %\n",
      "Epoch:130/200 AVG Training Loss:0.580 AVG Validation Loss:0.695 AVG Training Acc 67.65 % AVG Validation Acc 60.41 %\n",
      "Epoch   133: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.583 AVG Validation Loss:0.692 AVG Training Acc 66.77 % AVG Validation Acc 60.14 %\n",
      "Epoch:150/200 AVG Training Loss:0.581 AVG Validation Loss:0.696 AVG Training Acc 67.50 % AVG Validation Acc 59.69 %\n",
      "Epoch:160/200 AVG Training Loss:0.582 AVG Validation Loss:0.695 AVG Training Acc 67.12 % AVG Validation Acc 59.87 %\n",
      "Epoch   164: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.584 AVG Validation Loss:0.695 AVG Training Acc 67.03 % AVG Validation Acc 59.78 %\n",
      "Epoch:180/200 AVG Training Loss:0.582 AVG Validation Loss:0.697 AVG Training Acc 67.29 % AVG Validation Acc 60.05 %\n",
      "Epoch:190/200 AVG Training Loss:0.583 AVG Validation Loss:0.697 AVG Training Acc 66.75 % AVG Validation Acc 59.60 %\n",
      "Epoch   195: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.581 AVG Validation Loss:0.695 AVG Training Acc 67.45 % AVG Validation Acc 59.96 %\n",
      "Split 283\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a2557c501c8473eb70eda2dbc151aca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.651 AVG Training Acc 61.77 % AVG Validation Acc 61.59 %\n",
      "Epoch:20/200 AVG Training Loss:0.648 AVG Validation Loss:0.651 AVG Training Acc 61.88 % AVG Validation Acc 61.59 %\n",
      "Epoch:30/200 AVG Training Loss:0.639 AVG Validation Loss:0.657 AVG Training Acc 62.67 % AVG Validation Acc 61.95 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "New Best Accuracy found: 64.38%\n",
      "Epoch: 36\n",
      "Epoch:40/200 AVG Training Loss:0.611 AVG Validation Loss:0.669 AVG Training Acc 65.38 % AVG Validation Acc 63.03 %\n",
      "Epoch:50/200 AVG Training Loss:0.601 AVG Validation Loss:0.688 AVG Training Acc 66.47 % AVG Validation Acc 61.50 %\n",
      "Epoch:60/200 AVG Training Loss:0.593 AVG Validation Loss:0.700 AVG Training Acc 66.92 % AVG Validation Acc 60.69 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.586 AVG Validation Loss:0.715 AVG Training Acc 67.08 % AVG Validation Acc 61.86 %\n",
      "Epoch:80/200 AVG Training Loss:0.584 AVG Validation Loss:0.708 AVG Training Acc 67.89 % AVG Validation Acc 61.77 %\n",
      "Epoch:90/200 AVG Training Loss:0.585 AVG Validation Loss:0.709 AVG Training Acc 67.54 % AVG Validation Acc 61.41 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.579 AVG Validation Loss:0.713 AVG Training Acc 68.18 % AVG Validation Acc 61.59 %\n",
      "Epoch:110/200 AVG Training Loss:0.581 AVG Validation Loss:0.715 AVG Training Acc 68.20 % AVG Validation Acc 61.50 %\n",
      "Epoch:120/200 AVG Training Loss:0.581 AVG Validation Loss:0.712 AVG Training Acc 67.57 % AVG Validation Acc 60.69 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.581 AVG Validation Loss:0.712 AVG Training Acc 67.72 % AVG Validation Acc 60.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.583 AVG Validation Loss:0.720 AVG Training Acc 67.94 % AVG Validation Acc 61.32 %\n",
      "Epoch:150/200 AVG Training Loss:0.580 AVG Validation Loss:0.717 AVG Training Acc 67.81 % AVG Validation Acc 61.86 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.583 AVG Validation Loss:0.717 AVG Training Acc 67.75 % AVG Validation Acc 60.69 %\n",
      "Epoch:170/200 AVG Training Loss:0.582 AVG Validation Loss:0.716 AVG Training Acc 67.72 % AVG Validation Acc 60.69 %\n",
      "Epoch:180/200 AVG Training Loss:0.582 AVG Validation Loss:0.714 AVG Training Acc 67.41 % AVG Validation Acc 61.50 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.581 AVG Validation Loss:0.720 AVG Training Acc 67.71 % AVG Validation Acc 61.50 %\n",
      "Epoch:200/200 AVG Training Loss:0.582 AVG Validation Loss:0.720 AVG Training Acc 67.70 % AVG Validation Acc 60.69 %\n",
      "Split 284\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b0b7e5ad8004ae194172a7b4366e733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.656 AVG Training Acc 61.89 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.654 AVG Training Acc 61.86 % AVG Validation Acc 62.22 %\n",
      "Epoch:30/200 AVG Training Loss:0.647 AVG Validation Loss:0.654 AVG Training Acc 62.23 % AVG Validation Acc 62.13 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.632 AVG Validation Loss:0.659 AVG Training Acc 63.10 % AVG Validation Acc 61.68 %\n",
      "Epoch:50/200 AVG Training Loss:0.622 AVG Validation Loss:0.664 AVG Training Acc 63.43 % AVG Validation Acc 61.50 %\n",
      "Epoch:60/200 AVG Training Loss:0.616 AVG Validation Loss:0.669 AVG Training Acc 63.45 % AVG Validation Acc 60.69 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.610 AVG Validation Loss:0.675 AVG Training Acc 64.41 % AVG Validation Acc 60.69 %\n",
      "Epoch:80/200 AVG Training Loss:0.607 AVG Validation Loss:0.673 AVG Training Acc 64.17 % AVG Validation Acc 61.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.608 AVG Validation Loss:0.676 AVG Training Acc 64.21 % AVG Validation Acc 61.05 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.607 AVG Validation Loss:0.672 AVG Training Acc 64.57 % AVG Validation Acc 61.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.605 AVG Validation Loss:0.674 AVG Training Acc 64.60 % AVG Validation Acc 61.14 %\n",
      "Epoch:120/200 AVG Training Loss:0.605 AVG Validation Loss:0.674 AVG Training Acc 65.04 % AVG Validation Acc 61.14 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.605 AVG Validation Loss:0.672 AVG Training Acc 64.06 % AVG Validation Acc 60.69 %\n",
      "Epoch:140/200 AVG Training Loss:0.605 AVG Validation Loss:0.677 AVG Training Acc 64.29 % AVG Validation Acc 60.87 %\n",
      "Epoch:150/200 AVG Training Loss:0.604 AVG Validation Loss:0.674 AVG Training Acc 64.81 % AVG Validation Acc 61.14 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.606 AVG Validation Loss:0.675 AVG Training Acc 64.55 % AVG Validation Acc 61.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.606 AVG Validation Loss:0.672 AVG Training Acc 64.49 % AVG Validation Acc 61.05 %\n",
      "Epoch:180/200 AVG Training Loss:0.603 AVG Validation Loss:0.680 AVG Training Acc 64.81 % AVG Validation Acc 61.14 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.607 AVG Validation Loss:0.673 AVG Training Acc 64.29 % AVG Validation Acc 61.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.605 AVG Validation Loss:0.675 AVG Training Acc 65.14 % AVG Validation Acc 61.14 %\n",
      "Split 285\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b9b319fb97493e9167a06fd32a56a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.661 AVG Validation Loss:0.659 AVG Training Acc 61.86 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.653 AVG Training Acc 61.82 % AVG Validation Acc 61.68 %\n",
      "Epoch:30/200 AVG Training Loss:0.652 AVG Validation Loss:0.655 AVG Training Acc 61.92 % AVG Validation Acc 61.86 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.638 AVG Validation Loss:0.653 AVG Training Acc 62.74 % AVG Validation Acc 62.13 %\n",
      "Epoch:50/200 AVG Training Loss:0.631 AVG Validation Loss:0.653 AVG Training Acc 63.15 % AVG Validation Acc 62.58 %\n",
      "Epoch:60/200 AVG Training Loss:0.624 AVG Validation Loss:0.657 AVG Training Acc 63.07 % AVG Validation Acc 60.23 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.622 AVG Validation Loss:0.658 AVG Training Acc 64.47 % AVG Validation Acc 61.41 %\n",
      "Epoch:80/200 AVG Training Loss:0.620 AVG Validation Loss:0.659 AVG Training Acc 64.45 % AVG Validation Acc 61.50 %\n",
      "Epoch:90/200 AVG Training Loss:0.618 AVG Validation Loss:0.661 AVG Training Acc 64.32 % AVG Validation Acc 62.13 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.618 AVG Validation Loss:0.659 AVG Training Acc 64.05 % AVG Validation Acc 61.86 %\n",
      "Epoch:110/200 AVG Training Loss:0.618 AVG Validation Loss:0.659 AVG Training Acc 64.03 % AVG Validation Acc 61.86 %\n",
      "Epoch:120/200 AVG Training Loss:0.617 AVG Validation Loss:0.661 AVG Training Acc 63.90 % AVG Validation Acc 61.32 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.617 AVG Validation Loss:0.658 AVG Training Acc 64.19 % AVG Validation Acc 61.95 %\n",
      "Epoch:140/200 AVG Training Loss:0.616 AVG Validation Loss:0.659 AVG Training Acc 64.19 % AVG Validation Acc 62.13 %\n",
      "Epoch:150/200 AVG Training Loss:0.617 AVG Validation Loss:0.658 AVG Training Acc 64.13 % AVG Validation Acc 61.77 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.616 AVG Validation Loss:0.661 AVG Training Acc 64.28 % AVG Validation Acc 61.86 %\n",
      "Epoch:170/200 AVG Training Loss:0.618 AVG Validation Loss:0.660 AVG Training Acc 64.20 % AVG Validation Acc 61.59 %\n",
      "Epoch:180/200 AVG Training Loss:0.617 AVG Validation Loss:0.663 AVG Training Acc 64.29 % AVG Validation Acc 61.95 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.617 AVG Validation Loss:0.662 AVG Training Acc 64.01 % AVG Validation Acc 61.68 %\n",
      "Epoch:200/200 AVG Training Loss:0.616 AVG Validation Loss:0.659 AVG Training Acc 64.23 % AVG Validation Acc 61.59 %\n",
      "Split 286\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6974e8f3d422420d9a96bda60ddbea13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.657 AVG Validation Loss:0.660 AVG Training Acc 61.82 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.647 AVG Validation Loss:0.664 AVG Training Acc 62.27 % AVG Validation Acc 61.19 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.626 AVG Validation Loss:0.674 AVG Training Acc 63.69 % AVG Validation Acc 59.66 %\n",
      "Epoch:40/200 AVG Training Loss:0.610 AVG Validation Loss:0.692 AVG Training Acc 65.06 % AVG Validation Acc 59.84 %\n",
      "Epoch:50/200 AVG Training Loss:0.600 AVG Validation Loss:0.718 AVG Training Acc 65.37 % AVG Validation Acc 59.48 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.587 AVG Validation Loss:0.733 AVG Training Acc 66.62 % AVG Validation Acc 59.12 %\n",
      "Epoch:70/200 AVG Training Loss:0.587 AVG Validation Loss:0.735 AVG Training Acc 65.99 % AVG Validation Acc 58.57 %\n",
      "Epoch:80/200 AVG Training Loss:0.581 AVG Validation Loss:0.737 AVG Training Acc 66.54 % AVG Validation Acc 58.57 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.583 AVG Validation Loss:0.740 AVG Training Acc 66.86 % AVG Validation Acc 58.94 %\n",
      "Epoch:100/200 AVG Training Loss:0.583 AVG Validation Loss:0.739 AVG Training Acc 66.73 % AVG Validation Acc 58.66 %\n",
      "Epoch:110/200 AVG Training Loss:0.581 AVG Validation Loss:0.749 AVG Training Acc 66.45 % AVG Validation Acc 58.84 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.583 AVG Validation Loss:0.744 AVG Training Acc 66.47 % AVG Validation Acc 58.66 %\n",
      "Epoch:130/200 AVG Training Loss:0.581 AVG Validation Loss:0.744 AVG Training Acc 66.69 % AVG Validation Acc 59.21 %\n",
      "Epoch:140/200 AVG Training Loss:0.582 AVG Validation Loss:0.743 AVG Training Acc 66.77 % AVG Validation Acc 58.66 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.580 AVG Validation Loss:0.746 AVG Training Acc 66.93 % AVG Validation Acc 58.57 %\n",
      "Epoch:160/200 AVG Training Loss:0.580 AVG Validation Loss:0.746 AVG Training Acc 66.81 % AVG Validation Acc 58.66 %\n",
      "Epoch:170/200 AVG Training Loss:0.580 AVG Validation Loss:0.746 AVG Training Acc 66.66 % AVG Validation Acc 58.75 %\n",
      "Epoch:180/200 AVG Training Loss:0.582 AVG Validation Loss:0.743 AVG Training Acc 67.01 % AVG Validation Acc 58.57 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.582 AVG Validation Loss:0.744 AVG Training Acc 66.90 % AVG Validation Acc 58.75 %\n",
      "Epoch:200/200 AVG Training Loss:0.581 AVG Validation Loss:0.742 AVG Training Acc 66.60 % AVG Validation Acc 58.75 %\n",
      "Split 287\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0d051f5c5c54a719a80ab6f53d45fae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.656 AVG Training Acc 61.86 % AVG Validation Acc 61.64 %\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:0.655 AVG Training Acc 62.03 % AVG Validation Acc 62.27 %\n",
      "Epoch:30/200 AVG Training Loss:0.642 AVG Validation Loss:0.652 AVG Training Acc 62.29 % AVG Validation Acc 62.18 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.619 AVG Validation Loss:0.656 AVG Training Acc 64.47 % AVG Validation Acc 61.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.606 AVG Validation Loss:0.669 AVG Training Acc 65.68 % AVG Validation Acc 61.01 %\n",
      "Epoch:60/200 AVG Training Loss:0.603 AVG Validation Loss:0.671 AVG Training Acc 65.89 % AVG Validation Acc 61.91 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.593 AVG Validation Loss:0.676 AVG Training Acc 66.62 % AVG Validation Acc 60.92 %\n",
      "Epoch:80/200 AVG Training Loss:0.591 AVG Validation Loss:0.685 AVG Training Acc 66.73 % AVG Validation Acc 61.10 %\n",
      "Epoch:90/200 AVG Training Loss:0.591 AVG Validation Loss:0.679 AVG Training Acc 67.01 % AVG Validation Acc 62.00 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.591 AVG Validation Loss:0.681 AVG Training Acc 66.92 % AVG Validation Acc 61.64 %\n",
      "Epoch:110/200 AVG Training Loss:0.590 AVG Validation Loss:0.678 AVG Training Acc 66.81 % AVG Validation Acc 61.91 %\n",
      "Epoch:120/200 AVG Training Loss:0.589 AVG Validation Loss:0.678 AVG Training Acc 66.82 % AVG Validation Acc 61.82 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.587 AVG Validation Loss:0.677 AVG Training Acc 67.08 % AVG Validation Acc 61.55 %\n",
      "Epoch:140/200 AVG Training Loss:0.588 AVG Validation Loss:0.680 AVG Training Acc 66.71 % AVG Validation Acc 61.73 %\n",
      "Epoch:150/200 AVG Training Loss:0.588 AVG Validation Loss:0.681 AVG Training Acc 66.72 % AVG Validation Acc 62.00 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.590 AVG Validation Loss:0.679 AVG Training Acc 67.18 % AVG Validation Acc 62.00 %\n",
      "Epoch:170/200 AVG Training Loss:0.589 AVG Validation Loss:0.680 AVG Training Acc 67.00 % AVG Validation Acc 62.36 %\n",
      "Epoch:180/200 AVG Training Loss:0.587 AVG Validation Loss:0.681 AVG Training Acc 67.28 % AVG Validation Acc 61.64 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.590 AVG Validation Loss:0.681 AVG Training Acc 67.18 % AVG Validation Acc 61.73 %\n",
      "Epoch:200/200 AVG Training Loss:0.591 AVG Validation Loss:0.678 AVG Training Acc 66.75 % AVG Validation Acc 62.09 %\n",
      "Split 288\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06f51cb766a8428fbe790a052be00574",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.656 AVG Training Acc 61.77 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.658 AVG Training Acc 61.94 % AVG Validation Acc 62.64 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.646 AVG Validation Loss:0.655 AVG Training Acc 62.21 % AVG Validation Acc 62.45 %\n",
      "Epoch:40/200 AVG Training Loss:0.638 AVG Validation Loss:0.660 AVG Training Acc 63.51 % AVG Validation Acc 62.55 %\n",
      "Epoch:50/200 AVG Training Loss:0.629 AVG Validation Loss:0.664 AVG Training Acc 63.26 % AVG Validation Acc 62.73 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.624 AVG Validation Loss:0.669 AVG Training Acc 63.95 % AVG Validation Acc 62.91 %\n",
      "Epoch:70/200 AVG Training Loss:0.621 AVG Validation Loss:0.673 AVG Training Acc 63.97 % AVG Validation Acc 62.36 %\n",
      "Epoch:80/200 AVG Training Loss:0.621 AVG Validation Loss:0.669 AVG Training Acc 64.15 % AVG Validation Acc 62.55 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.619 AVG Validation Loss:0.668 AVG Training Acc 64.30 % AVG Validation Acc 62.45 %\n",
      "Epoch:100/200 AVG Training Loss:0.619 AVG Validation Loss:0.670 AVG Training Acc 64.26 % AVG Validation Acc 62.55 %\n",
      "Epoch:110/200 AVG Training Loss:0.620 AVG Validation Loss:0.669 AVG Training Acc 64.08 % AVG Validation Acc 62.36 %\n",
      "Epoch:120/200 AVG Training Loss:0.619 AVG Validation Loss:0.668 AVG Training Acc 64.25 % AVG Validation Acc 62.73 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.622 AVG Validation Loss:0.669 AVG Training Acc 63.63 % AVG Validation Acc 62.45 %\n",
      "Epoch:140/200 AVG Training Loss:0.620 AVG Validation Loss:0.670 AVG Training Acc 64.06 % AVG Validation Acc 62.18 %\n",
      "Epoch:150/200 AVG Training Loss:0.620 AVG Validation Loss:0.668 AVG Training Acc 64.06 % AVG Validation Acc 62.27 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.621 AVG Validation Loss:0.672 AVG Training Acc 64.41 % AVG Validation Acc 62.18 %\n",
      "Epoch:170/200 AVG Training Loss:0.620 AVG Validation Loss:0.669 AVG Training Acc 64.03 % AVG Validation Acc 62.45 %\n",
      "Epoch:180/200 AVG Training Loss:0.621 AVG Validation Loss:0.669 AVG Training Acc 63.99 % AVG Validation Acc 62.45 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.620 AVG Validation Loss:0.672 AVG Training Acc 64.30 % AVG Validation Acc 62.18 %\n",
      "Epoch:200/200 AVG Training Loss:0.621 AVG Validation Loss:0.671 AVG Training Acc 64.03 % AVG Validation Acc 62.18 %\n",
      "Split 289\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "423e7027c5d84f3fb067b6b0528d3cfd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.660 AVG Training Acc 61.70 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.650 AVG Validation Loss:0.657 AVG Training Acc 61.57 % AVG Validation Acc 61.73 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.639 AVG Validation Loss:0.660 AVG Training Acc 62.21 % AVG Validation Acc 60.29 %\n",
      "Epoch:40/200 AVG Training Loss:0.620 AVG Validation Loss:0.674 AVG Training Acc 63.87 % AVG Validation Acc 58.30 %\n",
      "Epoch:50/200 AVG Training Loss:0.606 AVG Validation Loss:0.691 AVG Training Acc 64.67 % AVG Validation Acc 57.94 %\n",
      "Epoch:60/200 AVG Training Loss:0.595 AVG Validation Loss:0.709 AVG Training Acc 65.18 % AVG Validation Acc 57.04 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.594 AVG Validation Loss:0.712 AVG Training Acc 65.08 % AVG Validation Acc 57.13 %\n",
      "Epoch:80/200 AVG Training Loss:0.591 AVG Validation Loss:0.716 AVG Training Acc 65.43 % AVG Validation Acc 56.59 %\n",
      "Epoch:90/200 AVG Training Loss:0.590 AVG Validation Loss:0.716 AVG Training Acc 65.78 % AVG Validation Acc 56.59 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.587 AVG Validation Loss:0.719 AVG Training Acc 65.84 % AVG Validation Acc 56.32 %\n",
      "Epoch:110/200 AVG Training Loss:0.587 AVG Validation Loss:0.723 AVG Training Acc 65.54 % AVG Validation Acc 56.32 %\n",
      "Epoch:120/200 AVG Training Loss:0.588 AVG Validation Loss:0.728 AVG Training Acc 65.52 % AVG Validation Acc 56.68 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.589 AVG Validation Loss:0.720 AVG Training Acc 66.07 % AVG Validation Acc 56.50 %\n",
      "Epoch:140/200 AVG Training Loss:0.588 AVG Validation Loss:0.716 AVG Training Acc 65.31 % AVG Validation Acc 56.41 %\n",
      "Epoch:150/200 AVG Training Loss:0.588 AVG Validation Loss:0.721 AVG Training Acc 65.49 % AVG Validation Acc 56.86 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.586 AVG Validation Loss:0.722 AVG Training Acc 65.53 % AVG Validation Acc 56.50 %\n",
      "Epoch:170/200 AVG Training Loss:0.589 AVG Validation Loss:0.712 AVG Training Acc 65.67 % AVG Validation Acc 57.04 %\n",
      "Epoch:180/200 AVG Training Loss:0.586 AVG Validation Loss:0.717 AVG Training Acc 65.77 % AVG Validation Acc 56.14 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.585 AVG Validation Loss:0.720 AVG Training Acc 65.56 % AVG Validation Acc 57.13 %\n",
      "Epoch:200/200 AVG Training Loss:0.589 AVG Validation Loss:0.721 AVG Training Acc 66.02 % AVG Validation Acc 56.23 %\n",
      "Split 290\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a99098d84d4612a541be1e48ea0933",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.663 AVG Training Acc 61.83 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 62.19 % AVG Validation Acc 60.92 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.630 AVG Validation Loss:0.658 AVG Training Acc 63.30 % AVG Validation Acc 61.46 %\n",
      "Epoch:40/200 AVG Training Loss:0.619 AVG Validation Loss:0.667 AVG Training Acc 63.83 % AVG Validation Acc 60.92 %\n",
      "Epoch:50/200 AVG Training Loss:0.610 AVG Validation Loss:0.680 AVG Training Acc 64.79 % AVG Validation Acc 60.65 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.601 AVG Validation Loss:0.686 AVG Training Acc 65.96 % AVG Validation Acc 60.74 %\n",
      "Epoch:70/200 AVG Training Loss:0.598 AVG Validation Loss:0.693 AVG Training Acc 65.72 % AVG Validation Acc 60.74 %\n",
      "Epoch:80/200 AVG Training Loss:0.597 AVG Validation Loss:0.693 AVG Training Acc 65.91 % AVG Validation Acc 60.47 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.595 AVG Validation Loss:0.694 AVG Training Acc 66.01 % AVG Validation Acc 59.84 %\n",
      "Epoch:100/200 AVG Training Loss:0.596 AVG Validation Loss:0.682 AVG Training Acc 65.94 % AVG Validation Acc 60.56 %\n",
      "Epoch:110/200 AVG Training Loss:0.596 AVG Validation Loss:0.688 AVG Training Acc 65.72 % AVG Validation Acc 60.56 %\n",
      "Epoch:120/200 AVG Training Loss:0.595 AVG Validation Loss:0.687 AVG Training Acc 65.72 % AVG Validation Acc 60.92 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.596 AVG Validation Loss:0.692 AVG Training Acc 65.82 % AVG Validation Acc 60.56 %\n",
      "Epoch:140/200 AVG Training Loss:0.595 AVG Validation Loss:0.700 AVG Training Acc 66.30 % AVG Validation Acc 60.29 %\n",
      "Epoch:150/200 AVG Training Loss:0.595 AVG Validation Loss:0.690 AVG Training Acc 65.97 % AVG Validation Acc 60.83 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.596 AVG Validation Loss:0.691 AVG Training Acc 65.86 % AVG Validation Acc 60.56 %\n",
      "Epoch:170/200 AVG Training Loss:0.596 AVG Validation Loss:0.695 AVG Training Acc 66.17 % AVG Validation Acc 59.93 %\n",
      "Epoch:180/200 AVG Training Loss:0.596 AVG Validation Loss:0.696 AVG Training Acc 65.66 % AVG Validation Acc 60.83 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.597 AVG Validation Loss:0.688 AVG Training Acc 66.02 % AVG Validation Acc 60.65 %\n",
      "Epoch:200/200 AVG Training Loss:0.597 AVG Validation Loss:0.691 AVG Training Acc 65.98 % AVG Validation Acc 60.38 %\n",
      "Split 291\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5861614b5f2342dea4bbe1d007b60f28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.657 AVG Training Acc 62.01 % AVG Validation Acc 62.22 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:0.659 AVG Training Acc 62.04 % AVG Validation Acc 62.40 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.637 AVG Validation Loss:0.659 AVG Training Acc 63.34 % AVG Validation Acc 61.59 %\n",
      "Epoch:40/200 AVG Training Loss:0.626 AVG Validation Loss:0.661 AVG Training Acc 64.26 % AVG Validation Acc 61.95 %\n",
      "Epoch:50/200 AVG Training Loss:0.618 AVG Validation Loss:0.667 AVG Training Acc 64.57 % AVG Validation Acc 61.32 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.611 AVG Validation Loss:0.675 AVG Training Acc 65.28 % AVG Validation Acc 61.32 %\n",
      "Epoch:70/200 AVG Training Loss:0.608 AVG Validation Loss:0.676 AVG Training Acc 65.54 % AVG Validation Acc 61.23 %\n",
      "Epoch:80/200 AVG Training Loss:0.607 AVG Validation Loss:0.678 AVG Training Acc 65.34 % AVG Validation Acc 61.23 %\n",
      "Epoch:90/200 AVG Training Loss:0.606 AVG Validation Loss:0.679 AVG Training Acc 65.37 % AVG Validation Acc 61.14 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.606 AVG Validation Loss:0.678 AVG Training Acc 65.17 % AVG Validation Acc 61.32 %\n",
      "Epoch:110/200 AVG Training Loss:0.608 AVG Validation Loss:0.679 AVG Training Acc 65.35 % AVG Validation Acc 61.41 %\n",
      "Epoch:120/200 AVG Training Loss:0.606 AVG Validation Loss:0.677 AVG Training Acc 65.12 % AVG Validation Acc 61.32 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.606 AVG Validation Loss:0.675 AVG Training Acc 65.44 % AVG Validation Acc 61.77 %\n",
      "Epoch:140/200 AVG Training Loss:0.604 AVG Validation Loss:0.676 AVG Training Acc 65.22 % AVG Validation Acc 61.68 %\n",
      "Epoch:150/200 AVG Training Loss:0.606 AVG Validation Loss:0.677 AVG Training Acc 65.35 % AVG Validation Acc 61.05 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.605 AVG Validation Loss:0.678 AVG Training Acc 65.41 % AVG Validation Acc 61.41 %\n",
      "Epoch:170/200 AVG Training Loss:0.604 AVG Validation Loss:0.677 AVG Training Acc 65.39 % AVG Validation Acc 61.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.606 AVG Validation Loss:0.678 AVG Training Acc 65.62 % AVG Validation Acc 61.59 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.605 AVG Validation Loss:0.676 AVG Training Acc 65.10 % AVG Validation Acc 61.50 %\n",
      "Epoch:200/200 AVG Training Loss:0.606 AVG Validation Loss:0.677 AVG Training Acc 65.58 % AVG Validation Acc 61.86 %\n",
      "Split 292\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc6d2a456b574246ab9d7cff66cb7f78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.659 AVG Training Acc 61.97 % AVG Validation Acc 61.95 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.656 AVG Training Acc 61.74 % AVG Validation Acc 61.77 %\n",
      "Epoch:30/200 AVG Training Loss:0.647 AVG Validation Loss:0.647 AVG Training Acc 62.40 % AVG Validation Acc 61.68 %\n",
      "Epoch:40/200 AVG Training Loss:0.635 AVG Validation Loss:0.656 AVG Training Acc 62.73 % AVG Validation Acc 62.94 %\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.608 AVG Validation Loss:0.666 AVG Training Acc 65.09 % AVG Validation Acc 61.95 %\n",
      "Epoch:60/200 AVG Training Loss:0.594 AVG Validation Loss:0.681 AVG Training Acc 65.78 % AVG Validation Acc 61.95 %\n",
      "Epoch:70/200 AVG Training Loss:0.585 AVG Validation Loss:0.701 AVG Training Acc 66.56 % AVG Validation Acc 61.14 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.576 AVG Validation Loss:0.708 AVG Training Acc 67.08 % AVG Validation Acc 61.23 %\n",
      "Epoch:90/200 AVG Training Loss:0.576 AVG Validation Loss:0.712 AVG Training Acc 66.72 % AVG Validation Acc 61.05 %\n",
      "Epoch:100/200 AVG Training Loss:0.574 AVG Validation Loss:0.714 AVG Training Acc 66.56 % AVG Validation Acc 61.32 %\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.571 AVG Validation Loss:0.713 AVG Training Acc 66.99 % AVG Validation Acc 60.69 %\n",
      "Epoch:120/200 AVG Training Loss:0.575 AVG Validation Loss:0.708 AVG Training Acc 66.81 % AVG Validation Acc 61.77 %\n",
      "Epoch:130/200 AVG Training Loss:0.572 AVG Validation Loss:0.715 AVG Training Acc 67.13 % AVG Validation Acc 61.59 %\n",
      "Epoch   134: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.571 AVG Validation Loss:0.719 AVG Training Acc 66.91 % AVG Validation Acc 61.86 %\n",
      "Epoch:150/200 AVG Training Loss:0.573 AVG Validation Loss:0.717 AVG Training Acc 67.11 % AVG Validation Acc 61.05 %\n",
      "Epoch:160/200 AVG Training Loss:0.573 AVG Validation Loss:0.713 AVG Training Acc 67.03 % AVG Validation Acc 61.59 %\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.572 AVG Validation Loss:0.719 AVG Training Acc 66.70 % AVG Validation Acc 61.50 %\n",
      "Epoch:180/200 AVG Training Loss:0.572 AVG Validation Loss:0.723 AVG Training Acc 67.37 % AVG Validation Acc 61.86 %\n",
      "Epoch:190/200 AVG Training Loss:0.570 AVG Validation Loss:0.709 AVG Training Acc 67.34 % AVG Validation Acc 61.23 %\n",
      "Epoch   196: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.571 AVG Validation Loss:0.720 AVG Training Acc 67.05 % AVG Validation Acc 61.14 %\n",
      "Split 293\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78edbed99bdc4b529f92de20ceee5150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.663 AVG Training Acc 61.74 % AVG Validation Acc 61.68 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.654 AVG Training Acc 62.22 % AVG Validation Acc 61.77 %\n",
      "Epoch:30/200 AVG Training Loss:0.650 AVG Validation Loss:0.660 AVG Training Acc 61.65 % AVG Validation Acc 61.41 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.644 AVG Validation Loss:0.654 AVG Training Acc 62.28 % AVG Validation Acc 61.23 %\n",
      "Epoch:50/200 AVG Training Loss:0.628 AVG Validation Loss:0.664 AVG Training Acc 63.52 % AVG Validation Acc 60.60 %\n",
      "Epoch:60/200 AVG Training Loss:0.618 AVG Validation Loss:0.667 AVG Training Acc 64.70 % AVG Validation Acc 60.23 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.611 AVG Validation Loss:0.669 AVG Training Acc 65.17 % AVG Validation Acc 59.60 %\n",
      "Epoch:80/200 AVG Training Loss:0.607 AVG Validation Loss:0.676 AVG Training Acc 65.37 % AVG Validation Acc 59.78 %\n",
      "Epoch:90/200 AVG Training Loss:0.607 AVG Validation Loss:0.673 AVG Training Acc 65.87 % AVG Validation Acc 59.78 %\n",
      "Epoch:100/200 AVG Training Loss:0.605 AVG Validation Loss:0.673 AVG Training Acc 65.90 % AVG Validation Acc 59.51 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.604 AVG Validation Loss:0.673 AVG Training Acc 66.64 % AVG Validation Acc 59.42 %\n",
      "Epoch:120/200 AVG Training Loss:0.605 AVG Validation Loss:0.678 AVG Training Acc 65.87 % AVG Validation Acc 58.34 %\n",
      "Epoch:130/200 AVG Training Loss:0.606 AVG Validation Loss:0.676 AVG Training Acc 66.26 % AVG Validation Acc 59.78 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.602 AVG Validation Loss:0.681 AVG Training Acc 66.62 % AVG Validation Acc 58.88 %\n",
      "Epoch:150/200 AVG Training Loss:0.603 AVG Validation Loss:0.678 AVG Training Acc 65.99 % AVG Validation Acc 59.15 %\n",
      "Epoch:160/200 AVG Training Loss:0.603 AVG Validation Loss:0.672 AVG Training Acc 66.24 % AVG Validation Acc 59.15 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.605 AVG Validation Loss:0.672 AVG Training Acc 65.84 % AVG Validation Acc 60.05 %\n",
      "Epoch:180/200 AVG Training Loss:0.606 AVG Validation Loss:0.679 AVG Training Acc 65.45 % AVG Validation Acc 59.78 %\n",
      "Epoch:190/200 AVG Training Loss:0.604 AVG Validation Loss:0.669 AVG Training Acc 66.04 % AVG Validation Acc 59.60 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.606 AVG Validation Loss:0.674 AVG Training Acc 65.50 % AVG Validation Acc 59.69 %\n",
      "Split 294\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70053ee9a6484ea1ae79ea8e85e79708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.656 AVG Training Acc 61.94 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:0.656 AVG Training Acc 62.24 % AVG Validation Acc 61.86 %\n",
      "Epoch:30/200 AVG Training Loss:0.644 AVG Validation Loss:0.658 AVG Training Acc 62.56 % AVG Validation Acc 61.05 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.620 AVG Validation Loss:0.673 AVG Training Acc 64.81 % AVG Validation Acc 59.33 %\n",
      "Epoch:50/200 AVG Training Loss:0.609 AVG Validation Loss:0.679 AVG Training Acc 65.54 % AVG Validation Acc 59.06 %\n",
      "Epoch:60/200 AVG Training Loss:0.598 AVG Validation Loss:0.693 AVG Training Acc 65.91 % AVG Validation Acc 58.25 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.590 AVG Validation Loss:0.701 AVG Training Acc 66.78 % AVG Validation Acc 58.07 %\n",
      "Epoch:80/200 AVG Training Loss:0.588 AVG Validation Loss:0.707 AVG Training Acc 67.03 % AVG Validation Acc 57.98 %\n",
      "Epoch:90/200 AVG Training Loss:0.586 AVG Validation Loss:0.708 AVG Training Acc 67.18 % AVG Validation Acc 58.61 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.584 AVG Validation Loss:0.706 AVG Training Acc 67.07 % AVG Validation Acc 58.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.585 AVG Validation Loss:0.714 AVG Training Acc 66.56 % AVG Validation Acc 57.98 %\n",
      "Epoch:120/200 AVG Training Loss:0.587 AVG Validation Loss:0.707 AVG Training Acc 66.59 % AVG Validation Acc 58.79 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.585 AVG Validation Loss:0.710 AVG Training Acc 67.31 % AVG Validation Acc 58.34 %\n",
      "Epoch:140/200 AVG Training Loss:0.588 AVG Validation Loss:0.712 AVG Training Acc 66.86 % AVG Validation Acc 58.07 %\n",
      "Epoch:150/200 AVG Training Loss:0.585 AVG Validation Loss:0.704 AVG Training Acc 67.66 % AVG Validation Acc 58.79 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.586 AVG Validation Loss:0.707 AVG Training Acc 66.84 % AVG Validation Acc 58.07 %\n",
      "Epoch:170/200 AVG Training Loss:0.585 AVG Validation Loss:0.712 AVG Training Acc 67.02 % AVG Validation Acc 58.70 %\n",
      "Epoch:180/200 AVG Training Loss:0.585 AVG Validation Loss:0.710 AVG Training Acc 67.02 % AVG Validation Acc 58.16 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.587 AVG Validation Loss:0.708 AVG Training Acc 67.14 % AVG Validation Acc 58.16 %\n",
      "Epoch:200/200 AVG Training Loss:0.586 AVG Validation Loss:0.706 AVG Training Acc 66.93 % AVG Validation Acc 58.43 %\n",
      "Split 295\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b09ee309e61e4d2e8589a6b22b773adb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.657 AVG Validation Loss:0.667 AVG Training Acc 61.94 % AVG Validation Acc 61.86 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:0.660 AVG Training Acc 61.76 % AVG Validation Acc 61.86 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.650 AVG Validation Loss:0.665 AVG Training Acc 62.24 % AVG Validation Acc 61.23 %\n",
      "Epoch:40/200 AVG Training Loss:0.635 AVG Validation Loss:0.671 AVG Training Acc 62.45 % AVG Validation Acc 60.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.625 AVG Validation Loss:0.680 AVG Training Acc 63.57 % AVG Validation Acc 61.50 %\n",
      "Epoch:60/200 AVG Training Loss:0.619 AVG Validation Loss:0.684 AVG Training Acc 63.73 % AVG Validation Acc 61.86 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.614 AVG Validation Loss:0.686 AVG Training Acc 64.63 % AVG Validation Acc 61.59 %\n",
      "Epoch:80/200 AVG Training Loss:0.615 AVG Validation Loss:0.690 AVG Training Acc 64.35 % AVG Validation Acc 61.59 %\n",
      "Epoch:90/200 AVG Training Loss:0.611 AVG Validation Loss:0.692 AVG Training Acc 65.09 % AVG Validation Acc 61.50 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.611 AVG Validation Loss:0.690 AVG Training Acc 64.33 % AVG Validation Acc 61.32 %\n",
      "Epoch:110/200 AVG Training Loss:0.612 AVG Validation Loss:0.689 AVG Training Acc 64.61 % AVG Validation Acc 61.41 %\n",
      "Epoch:120/200 AVG Training Loss:0.610 AVG Validation Loss:0.693 AVG Training Acc 64.59 % AVG Validation Acc 61.32 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.611 AVG Validation Loss:0.695 AVG Training Acc 64.61 % AVG Validation Acc 60.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.611 AVG Validation Loss:0.691 AVG Training Acc 64.93 % AVG Validation Acc 61.23 %\n",
      "Epoch:150/200 AVG Training Loss:0.612 AVG Validation Loss:0.693 AVG Training Acc 64.70 % AVG Validation Acc 61.14 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.610 AVG Validation Loss:0.694 AVG Training Acc 64.24 % AVG Validation Acc 61.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.610 AVG Validation Loss:0.693 AVG Training Acc 64.75 % AVG Validation Acc 61.41 %\n",
      "Epoch:180/200 AVG Training Loss:0.611 AVG Validation Loss:0.692 AVG Training Acc 64.64 % AVG Validation Acc 60.96 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.612 AVG Validation Loss:0.693 AVG Training Acc 64.38 % AVG Validation Acc 61.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.612 AVG Validation Loss:0.694 AVG Training Acc 64.46 % AVG Validation Acc 61.23 %\n",
      "Split 296\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c545ebd3654a18b9559f952c11c00e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.654 AVG Training Acc 61.82 % AVG Validation Acc 62.09 %\n",
      "Epoch:20/200 AVG Training Loss:0.650 AVG Validation Loss:0.658 AVG Training Acc 62.10 % AVG Validation Acc 61.46 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.632 AVG Validation Loss:0.668 AVG Training Acc 63.17 % AVG Validation Acc 61.64 %\n",
      "Epoch:40/200 AVG Training Loss:0.624 AVG Validation Loss:0.675 AVG Training Acc 63.66 % AVG Validation Acc 59.93 %\n",
      "Epoch:50/200 AVG Training Loss:0.618 AVG Validation Loss:0.675 AVG Training Acc 63.93 % AVG Validation Acc 59.75 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.614 AVG Validation Loss:0.677 AVG Training Acc 64.64 % AVG Validation Acc 60.47 %\n",
      "Epoch:70/200 AVG Training Loss:0.612 AVG Validation Loss:0.680 AVG Training Acc 64.31 % AVG Validation Acc 60.29 %\n",
      "Epoch:80/200 AVG Training Loss:0.609 AVG Validation Loss:0.680 AVG Training Acc 64.99 % AVG Validation Acc 60.11 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.610 AVG Validation Loss:0.682 AVG Training Acc 64.87 % AVG Validation Acc 60.11 %\n",
      "Epoch:100/200 AVG Training Loss:0.609 AVG Validation Loss:0.678 AVG Training Acc 64.81 % AVG Validation Acc 60.20 %\n",
      "Epoch:110/200 AVG Training Loss:0.609 AVG Validation Loss:0.679 AVG Training Acc 64.99 % AVG Validation Acc 60.74 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.609 AVG Validation Loss:0.684 AVG Training Acc 64.63 % AVG Validation Acc 60.02 %\n",
      "Epoch:130/200 AVG Training Loss:0.609 AVG Validation Loss:0.680 AVG Training Acc 64.73 % AVG Validation Acc 60.56 %\n",
      "Epoch:140/200 AVG Training Loss:0.608 AVG Validation Loss:0.680 AVG Training Acc 64.55 % AVG Validation Acc 60.20 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.608 AVG Validation Loss:0.678 AVG Training Acc 64.94 % AVG Validation Acc 60.83 %\n",
      "Epoch:160/200 AVG Training Loss:0.608 AVG Validation Loss:0.683 AVG Training Acc 64.80 % AVG Validation Acc 60.29 %\n",
      "Epoch:170/200 AVG Training Loss:0.608 AVG Validation Loss:0.681 AVG Training Acc 64.87 % AVG Validation Acc 60.02 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.609 AVG Validation Loss:0.679 AVG Training Acc 65.16 % AVG Validation Acc 60.20 %\n",
      "Epoch:190/200 AVG Training Loss:0.611 AVG Validation Loss:0.682 AVG Training Acc 64.50 % AVG Validation Acc 59.93 %\n",
      "Epoch:200/200 AVG Training Loss:0.608 AVG Validation Loss:0.677 AVG Training Acc 65.03 % AVG Validation Acc 59.84 %\n",
      "Split 297\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "508e30890ad34a8eb527edcdd42dd6a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.663 AVG Training Acc 61.74 % AVG Validation Acc 62.00 %\n",
      "Epoch:20/200 AVG Training Loss:0.650 AVG Validation Loss:0.655 AVG Training Acc 62.40 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.636 AVG Validation Loss:0.656 AVG Training Acc 62.83 % AVG Validation Acc 60.83 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.608 AVG Validation Loss:0.676 AVG Training Acc 64.64 % AVG Validation Acc 61.82 %\n",
      "Epoch:50/200 AVG Training Loss:0.594 AVG Validation Loss:0.691 AVG Training Acc 66.23 % AVG Validation Acc 61.46 %\n",
      "Epoch:60/200 AVG Training Loss:0.583 AVG Validation Loss:0.700 AVG Training Acc 66.37 % AVG Validation Acc 61.73 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.573 AVG Validation Loss:0.707 AVG Training Acc 67.10 % AVG Validation Acc 60.92 %\n",
      "Epoch:80/200 AVG Training Loss:0.574 AVG Validation Loss:0.713 AVG Training Acc 67.13 % AVG Validation Acc 60.29 %\n",
      "Epoch:90/200 AVG Training Loss:0.572 AVG Validation Loss:0.715 AVG Training Acc 67.33 % AVG Validation Acc 60.02 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.571 AVG Validation Loss:0.723 AVG Training Acc 67.24 % AVG Validation Acc 59.84 %\n",
      "Epoch:110/200 AVG Training Loss:0.568 AVG Validation Loss:0.716 AVG Training Acc 67.58 % AVG Validation Acc 60.02 %\n",
      "Epoch:120/200 AVG Training Loss:0.572 AVG Validation Loss:0.709 AVG Training Acc 67.23 % AVG Validation Acc 60.47 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.570 AVG Validation Loss:0.713 AVG Training Acc 67.41 % AVG Validation Acc 60.20 %\n",
      "Epoch:140/200 AVG Training Loss:0.574 AVG Validation Loss:0.717 AVG Training Acc 67.24 % AVG Validation Acc 60.02 %\n",
      "Epoch:150/200 AVG Training Loss:0.571 AVG Validation Loss:0.713 AVG Training Acc 67.61 % AVG Validation Acc 60.29 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.568 AVG Validation Loss:0.720 AVG Training Acc 68.19 % AVG Validation Acc 59.66 %\n",
      "Epoch:170/200 AVG Training Loss:0.571 AVG Validation Loss:0.717 AVG Training Acc 67.48 % AVG Validation Acc 59.57 %\n",
      "Epoch:180/200 AVG Training Loss:0.571 AVG Validation Loss:0.720 AVG Training Acc 67.18 % AVG Validation Acc 59.75 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.570 AVG Validation Loss:0.715 AVG Training Acc 67.49 % AVG Validation Acc 59.48 %\n",
      "Epoch:200/200 AVG Training Loss:0.569 AVG Validation Loss:0.715 AVG Training Acc 67.32 % AVG Validation Acc 60.11 %\n",
      "Split 298\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bf2316483e145f9b6dc4a8e92bdccc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 61.82 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.654 AVG Training Acc 61.62 % AVG Validation Acc 61.82 %\n",
      "Epoch:30/200 AVG Training Loss:0.645 AVG Validation Loss:0.656 AVG Training Acc 62.48 % AVG Validation Acc 62.45 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.624 AVG Validation Loss:0.668 AVG Training Acc 63.67 % AVG Validation Acc 61.19 %\n",
      "Epoch:50/200 AVG Training Loss:0.611 AVG Validation Loss:0.677 AVG Training Acc 64.14 % AVG Validation Acc 60.20 %\n",
      "Epoch:60/200 AVG Training Loss:0.604 AVG Validation Loss:0.683 AVG Training Acc 65.32 % AVG Validation Acc 59.66 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.597 AVG Validation Loss:0.688 AVG Training Acc 65.66 % AVG Validation Acc 58.75 %\n",
      "Epoch:80/200 AVG Training Loss:0.594 AVG Validation Loss:0.692 AVG Training Acc 65.60 % AVG Validation Acc 59.12 %\n",
      "Epoch:90/200 AVG Training Loss:0.593 AVG Validation Loss:0.694 AVG Training Acc 65.26 % AVG Validation Acc 58.84 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.592 AVG Validation Loss:0.692 AVG Training Acc 65.68 % AVG Validation Acc 59.03 %\n",
      "Epoch:110/200 AVG Training Loss:0.592 AVG Validation Loss:0.690 AVG Training Acc 65.44 % AVG Validation Acc 58.57 %\n",
      "Epoch:120/200 AVG Training Loss:0.590 AVG Validation Loss:0.692 AVG Training Acc 66.00 % AVG Validation Acc 58.48 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.592 AVG Validation Loss:0.691 AVG Training Acc 65.71 % AVG Validation Acc 58.57 %\n",
      "Epoch:140/200 AVG Training Loss:0.591 AVG Validation Loss:0.694 AVG Training Acc 65.81 % AVG Validation Acc 58.84 %\n",
      "Epoch:150/200 AVG Training Loss:0.591 AVG Validation Loss:0.691 AVG Training Acc 65.87 % AVG Validation Acc 58.57 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.591 AVG Validation Loss:0.691 AVG Training Acc 65.44 % AVG Validation Acc 58.94 %\n",
      "Epoch:170/200 AVG Training Loss:0.591 AVG Validation Loss:0.694 AVG Training Acc 65.73 % AVG Validation Acc 58.57 %\n",
      "Epoch:180/200 AVG Training Loss:0.591 AVG Validation Loss:0.696 AVG Training Acc 65.95 % AVG Validation Acc 59.12 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.592 AVG Validation Loss:0.694 AVG Training Acc 65.91 % AVG Validation Acc 58.75 %\n",
      "Epoch:200/200 AVG Training Loss:0.592 AVG Validation Loss:0.695 AVG Training Acc 65.66 % AVG Validation Acc 59.21 %\n",
      "Split 299\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceb1c40ca2ad4dfbb34ca920c3326a72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.658 AVG Validation Loss:0.661 AVG Training Acc 61.58 % AVG Validation Acc 62.00 %\n",
      "Epoch:20/200 AVG Training Loss:0.651 AVG Validation Loss:0.662 AVG Training Acc 61.86 % AVG Validation Acc 61.82 %\n",
      "Epoch:30/200 AVG Training Loss:0.648 AVG Validation Loss:0.662 AVG Training Acc 62.14 % AVG Validation Acc 62.09 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.628 AVG Validation Loss:0.681 AVG Training Acc 63.37 % AVG Validation Acc 58.21 %\n",
      "Epoch:50/200 AVG Training Loss:0.620 AVG Validation Loss:0.687 AVG Training Acc 64.40 % AVG Validation Acc 58.48 %\n",
      "Epoch:60/200 AVG Training Loss:0.613 AVG Validation Loss:0.698 AVG Training Acc 64.34 % AVG Validation Acc 58.66 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.607 AVG Validation Loss:0.705 AVG Training Acc 65.15 % AVG Validation Acc 58.39 %\n",
      "Epoch:80/200 AVG Training Loss:0.605 AVG Validation Loss:0.711 AVG Training Acc 65.19 % AVG Validation Acc 57.76 %\n",
      "Epoch:90/200 AVG Training Loss:0.606 AVG Validation Loss:0.713 AVG Training Acc 65.30 % AVG Validation Acc 58.12 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.602 AVG Validation Loss:0.710 AVG Training Acc 65.64 % AVG Validation Acc 57.85 %\n",
      "Epoch:110/200 AVG Training Loss:0.604 AVG Validation Loss:0.710 AVG Training Acc 65.12 % AVG Validation Acc 58.03 %\n",
      "Epoch:120/200 AVG Training Loss:0.602 AVG Validation Loss:0.714 AVG Training Acc 65.17 % AVG Validation Acc 57.31 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.602 AVG Validation Loss:0.705 AVG Training Acc 65.42 % AVG Validation Acc 58.30 %\n",
      "Epoch:140/200 AVG Training Loss:0.603 AVG Validation Loss:0.710 AVG Training Acc 65.12 % AVG Validation Acc 57.49 %\n",
      "Epoch:150/200 AVG Training Loss:0.604 AVG Validation Loss:0.712 AVG Training Acc 65.26 % AVG Validation Acc 58.12 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.603 AVG Validation Loss:0.713 AVG Training Acc 64.99 % AVG Validation Acc 58.03 %\n",
      "Epoch:170/200 AVG Training Loss:0.601 AVG Validation Loss:0.714 AVG Training Acc 65.29 % AVG Validation Acc 57.40 %\n",
      "Epoch:180/200 AVG Training Loss:0.603 AVG Validation Loss:0.707 AVG Training Acc 65.19 % AVG Validation Acc 57.76 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.604 AVG Validation Loss:0.707 AVG Training Acc 65.51 % AVG Validation Acc 57.76 %\n",
      "Epoch:200/200 AVG Training Loss:0.602 AVG Validation Loss:0.712 AVG Training Acc 65.31 % AVG Validation Acc 58.12 %\n",
      "Split 300\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6622712870294296ac0cc9337767c715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.659 AVG Validation Loss:0.656 AVG Training Acc 61.71 % AVG Validation Acc 61.91 %\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:0.653 AVG Training Acc 61.90 % AVG Validation Acc 61.91 %\n",
      "Epoch:30/200 AVG Training Loss:0.641 AVG Validation Loss:0.668 AVG Training Acc 62.61 % AVG Validation Acc 61.19 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.614 AVG Validation Loss:0.690 AVG Training Acc 64.56 % AVG Validation Acc 58.48 %\n",
      "Epoch:50/200 AVG Training Loss:0.602 AVG Validation Loss:0.697 AVG Training Acc 64.94 % AVG Validation Acc 58.94 %\n",
      "Epoch:60/200 AVG Training Loss:0.591 AVG Validation Loss:0.716 AVG Training Acc 65.60 % AVG Validation Acc 58.84 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.586 AVG Validation Loss:0.723 AVG Training Acc 66.23 % AVG Validation Acc 57.49 %\n",
      "Epoch:80/200 AVG Training Loss:0.585 AVG Validation Loss:0.724 AVG Training Acc 66.20 % AVG Validation Acc 57.85 %\n",
      "Epoch:90/200 AVG Training Loss:0.583 AVG Validation Loss:0.732 AVG Training Acc 66.06 % AVG Validation Acc 57.04 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.580 AVG Validation Loss:0.736 AVG Training Acc 66.75 % AVG Validation Acc 57.76 %\n",
      "Epoch:110/200 AVG Training Loss:0.580 AVG Validation Loss:0.734 AVG Training Acc 66.60 % AVG Validation Acc 57.76 %\n",
      "Epoch:120/200 AVG Training Loss:0.582 AVG Validation Loss:0.728 AVG Training Acc 66.60 % AVG Validation Acc 57.94 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.581 AVG Validation Loss:0.728 AVG Training Acc 66.24 % AVG Validation Acc 57.67 %\n",
      "Epoch:140/200 AVG Training Loss:0.580 AVG Validation Loss:0.727 AVG Training Acc 66.63 % AVG Validation Acc 57.85 %\n",
      "Epoch:150/200 AVG Training Loss:0.581 AVG Validation Loss:0.727 AVG Training Acc 66.33 % AVG Validation Acc 57.67 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.582 AVG Validation Loss:0.732 AVG Training Acc 66.14 % AVG Validation Acc 57.31 %\n",
      "Epoch:170/200 AVG Training Loss:0.580 AVG Validation Loss:0.732 AVG Training Acc 66.41 % AVG Validation Acc 57.76 %\n",
      "Epoch:180/200 AVG Training Loss:0.581 AVG Validation Loss:0.736 AVG Training Acc 65.70 % AVG Validation Acc 57.40 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.580 AVG Validation Loss:0.733 AVG Training Acc 66.24 % AVG Validation Acc 57.13 %\n",
      "Epoch:200/200 AVG Training Loss:0.583 AVG Validation Loss:0.736 AVG Training Acc 66.19 % AVG Validation Acc 57.85 %\n",
      "final_gifted\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "254faf5912fb42b49dc3f4d456fc6fd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93a1291f61024e48afc7281e37695e52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best Accuracy found: 80.16%\n",
      "Epoch: 1\n",
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 79.98 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.20 % AVG Validation Acc 79.89 %\n",
      "New Best Accuracy found: 80.25%\n",
      "Epoch: 35\n",
      "Epoch:40/200 AVG Training Loss:0.485 AVG Validation Loss:0.493 AVG Training Acc 80.35 % AVG Validation Acc 80.07 %\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.472 AVG Validation Loss:0.508 AVG Training Acc 80.70 % AVG Validation Acc 79.62 %\n",
      "Epoch:60/200 AVG Training Loss:0.464 AVG Validation Loss:0.518 AVG Training Acc 80.93 % AVG Validation Acc 79.53 %\n",
      "Epoch:70/200 AVG Training Loss:0.462 AVG Validation Loss:0.545 AVG Training Acc 81.09 % AVG Validation Acc 79.53 %\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.457 AVG Validation Loss:0.539 AVG Training Acc 81.43 % AVG Validation Acc 79.26 %\n",
      "Epoch:90/200 AVG Training Loss:0.454 AVG Validation Loss:0.541 AVG Training Acc 81.36 % AVG Validation Acc 78.90 %\n",
      "Epoch:100/200 AVG Training Loss:0.454 AVG Validation Loss:0.544 AVG Training Acc 81.54 % AVG Validation Acc 79.08 %\n",
      "Epoch   106: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.454 AVG Validation Loss:0.550 AVG Training Acc 81.56 % AVG Validation Acc 78.99 %\n",
      "Epoch:120/200 AVG Training Loss:0.453 AVG Validation Loss:0.549 AVG Training Acc 81.63 % AVG Validation Acc 78.63 %\n",
      "Epoch:130/200 AVG Training Loss:0.453 AVG Validation Loss:0.547 AVG Training Acc 81.48 % AVG Validation Acc 78.99 %\n",
      "Epoch   137: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.453 AVG Validation Loss:0.549 AVG Training Acc 81.52 % AVG Validation Acc 78.81 %\n",
      "Epoch:150/200 AVG Training Loss:0.452 AVG Validation Loss:0.544 AVG Training Acc 81.43 % AVG Validation Acc 78.90 %\n",
      "Epoch:160/200 AVG Training Loss:0.454 AVG Validation Loss:0.546 AVG Training Acc 81.52 % AVG Validation Acc 78.99 %\n",
      "Epoch   168: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.453 AVG Validation Loss:0.551 AVG Training Acc 81.51 % AVG Validation Acc 78.63 %\n",
      "Epoch:180/200 AVG Training Loss:0.453 AVG Validation Loss:0.545 AVG Training Acc 81.59 % AVG Validation Acc 78.99 %\n",
      "Epoch:190/200 AVG Training Loss:0.455 AVG Validation Loss:0.544 AVG Training Acc 81.58 % AVG Validation Acc 78.90 %\n",
      "Epoch   199: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.452 AVG Validation Loss:0.547 AVG Training Acc 81.58 % AVG Validation Acc 78.81 %\n",
      "Split 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b43ab01ab4e4279bc378538423e9732",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.29 % AVG Validation Acc 79.98 %\n",
      "Epoch:40/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.43 % AVG Validation Acc 79.71 %\n",
      "Epoch:50/200 AVG Training Loss:0.477 AVG Validation Loss:0.501 AVG Training Acc 80.56 % AVG Validation Acc 79.71 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.469 AVG Validation Loss:0.506 AVG Training Acc 80.79 % AVG Validation Acc 79.89 %\n",
      "Epoch:70/200 AVG Training Loss:0.468 AVG Validation Loss:0.510 AVG Training Acc 80.84 % AVG Validation Acc 79.62 %\n",
      "Epoch:80/200 AVG Training Loss:0.467 AVG Validation Loss:0.510 AVG Training Acc 80.91 % AVG Validation Acc 79.62 %\n",
      "Epoch:90/200 AVG Training Loss:0.465 AVG Validation Loss:0.515 AVG Training Acc 80.93 % AVG Validation Acc 79.71 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.465 AVG Validation Loss:0.513 AVG Training Acc 80.92 % AVG Validation Acc 79.62 %\n",
      "Epoch:110/200 AVG Training Loss:0.465 AVG Validation Loss:0.515 AVG Training Acc 81.00 % AVG Validation Acc 79.62 %\n",
      "Epoch:120/200 AVG Training Loss:0.465 AVG Validation Loss:0.514 AVG Training Acc 81.00 % AVG Validation Acc 79.62 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.465 AVG Validation Loss:0.515 AVG Training Acc 81.05 % AVG Validation Acc 79.71 %\n",
      "Epoch:140/200 AVG Training Loss:0.464 AVG Validation Loss:0.515 AVG Training Acc 81.04 % AVG Validation Acc 79.71 %\n",
      "Epoch:150/200 AVG Training Loss:0.467 AVG Validation Loss:0.514 AVG Training Acc 80.94 % AVG Validation Acc 79.62 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.465 AVG Validation Loss:0.513 AVG Training Acc 80.97 % AVG Validation Acc 79.62 %\n",
      "Epoch:170/200 AVG Training Loss:0.465 AVG Validation Loss:0.512 AVG Training Acc 80.97 % AVG Validation Acc 79.71 %\n",
      "Epoch:180/200 AVG Training Loss:0.464 AVG Validation Loss:0.517 AVG Training Acc 81.05 % AVG Validation Acc 79.53 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.465 AVG Validation Loss:0.517 AVG Training Acc 81.10 % AVG Validation Acc 79.62 %\n",
      "Epoch:200/200 AVG Training Loss:0.466 AVG Validation Loss:0.513 AVG Training Acc 81.02 % AVG Validation Acc 79.71 %\n",
      "Split 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd346545fc944acda2ccf04772cfdaa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.18 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "New Best Accuracy found: 80.34%\n",
      "Epoch: 32\n",
      "Epoch:40/200 AVG Training Loss:0.485 AVG Validation Loss:0.489 AVG Training Acc 80.26 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.482 AVG Validation Loss:0.487 AVG Training Acc 80.42 % AVG Validation Acc 80.25 %\n",
      "Epoch:60/200 AVG Training Loss:0.479 AVG Validation Loss:0.482 AVG Training Acc 80.44 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.485 AVG Validation Loss:0.482 AVG Training Acc 80.27 % AVG Validation Acc 80.16 %\n",
      "Epoch    71: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:80/200 AVG Training Loss:0.472 AVG Validation Loss:0.490 AVG Training Acc 80.44 % AVG Validation Acc 80.25 %\n",
      "New Best Accuracy found: 80.43%\n",
      "Epoch: 87\n",
      "Epoch:90/200 AVG Training Loss:0.470 AVG Validation Loss:0.500 AVG Training Acc 80.51 % AVG Validation Acc 80.16 %\n",
      "Epoch:100/200 AVG Training Loss:0.466 AVG Validation Loss:0.500 AVG Training Acc 80.53 % AVG Validation Acc 80.16 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:110/200 AVG Training Loss:0.463 AVG Validation Loss:0.495 AVG Training Acc 80.77 % AVG Validation Acc 80.07 %\n",
      "New Best Accuracy found: 80.52%\n",
      "Epoch: 113\n",
      "Epoch:120/200 AVG Training Loss:0.463 AVG Validation Loss:0.502 AVG Training Acc 80.71 % AVG Validation Acc 80.34 %\n",
      "Epoch:130/200 AVG Training Loss:0.462 AVG Validation Loss:0.500 AVG Training Acc 80.70 % AVG Validation Acc 80.34 %\n",
      "Epoch   133: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:140/200 AVG Training Loss:0.460 AVG Validation Loss:0.501 AVG Training Acc 80.72 % AVG Validation Acc 80.52 %\n",
      "Epoch:150/200 AVG Training Loss:0.462 AVG Validation Loss:0.501 AVG Training Acc 80.68 % AVG Validation Acc 80.34 %\n",
      "Epoch:160/200 AVG Training Loss:0.462 AVG Validation Loss:0.503 AVG Training Acc 80.67 % AVG Validation Acc 80.34 %\n",
      "Epoch   164: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:170/200 AVG Training Loss:0.462 AVG Validation Loss:0.498 AVG Training Acc 80.55 % AVG Validation Acc 80.43 %\n",
      "Epoch:180/200 AVG Training Loss:0.461 AVG Validation Loss:0.500 AVG Training Acc 80.79 % AVG Validation Acc 80.25 %\n",
      "Epoch:190/200 AVG Training Loss:0.462 AVG Validation Loss:0.501 AVG Training Acc 80.77 % AVG Validation Acc 80.43 %\n",
      "Epoch   195: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:200/200 AVG Training Loss:0.460 AVG Validation Loss:0.504 AVG Training Acc 80.77 % AVG Validation Acc 80.43 %\n",
      "Split 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4578aae763444f1bb2b956ce06b50c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.22 % AVG Validation Acc 80.16 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.480 AVG Validation Loss:0.495 AVG Training Acc 80.30 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.474 AVG Validation Loss:0.500 AVG Training Acc 80.30 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.469 AVG Validation Loss:0.503 AVG Training Acc 80.38 % AVG Validation Acc 79.98 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.464 AVG Validation Loss:0.515 AVG Training Acc 80.36 % AVG Validation Acc 79.89 %\n",
      "Epoch:80/200 AVG Training Loss:0.463 AVG Validation Loss:0.513 AVG Training Acc 80.53 % AVG Validation Acc 79.89 %\n",
      "Epoch:90/200 AVG Training Loss:0.461 AVG Validation Loss:0.516 AVG Training Acc 80.41 % AVG Validation Acc 79.98 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.462 AVG Validation Loss:0.515 AVG Training Acc 80.47 % AVG Validation Acc 79.98 %\n",
      "Epoch:110/200 AVG Training Loss:0.460 AVG Validation Loss:0.517 AVG Training Acc 80.58 % AVG Validation Acc 79.98 %\n",
      "Epoch:120/200 AVG Training Loss:0.461 AVG Validation Loss:0.516 AVG Training Acc 80.49 % AVG Validation Acc 79.98 %\n",
      "Epoch:130/200 AVG Training Loss:0.462 AVG Validation Loss:0.514 AVG Training Acc 80.50 % AVG Validation Acc 79.98 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.460 AVG Validation Loss:0.513 AVG Training Acc 80.52 % AVG Validation Acc 79.98 %\n",
      "Epoch:150/200 AVG Training Loss:0.460 AVG Validation Loss:0.520 AVG Training Acc 80.57 % AVG Validation Acc 79.89 %\n",
      "Epoch:160/200 AVG Training Loss:0.461 AVG Validation Loss:0.515 AVG Training Acc 80.49 % AVG Validation Acc 79.98 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.461 AVG Validation Loss:0.517 AVG Training Acc 80.35 % AVG Validation Acc 79.98 %\n",
      "Epoch:180/200 AVG Training Loss:0.461 AVG Validation Loss:0.516 AVG Training Acc 80.50 % AVG Validation Acc 79.89 %\n",
      "Epoch:190/200 AVG Training Loss:0.461 AVG Validation Loss:0.517 AVG Training Acc 80.52 % AVG Validation Acc 79.98 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.461 AVG Validation Loss:0.515 AVG Training Acc 80.44 % AVG Validation Acc 79.98 %\n",
      "Split 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "291142ebdbb34578bc0f215e9addbe89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.498 AVG Training Acc 80.11 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.499 AVG Training Acc 80.15 % AVG Validation Acc 79.98 %\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.508 AVG Training Acc 80.32 % AVG Validation Acc 80.16 %\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.474 AVG Validation Loss:0.515 AVG Training Acc 80.55 % AVG Validation Acc 79.62 %\n",
      "Epoch:60/200 AVG Training Loss:0.467 AVG Validation Loss:0.516 AVG Training Acc 80.84 % AVG Validation Acc 79.53 %\n",
      "Epoch:70/200 AVG Training Loss:0.462 AVG Validation Loss:0.521 AVG Training Acc 80.97 % AVG Validation Acc 79.71 %\n",
      "Epoch    71: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.459 AVG Validation Loss:0.526 AVG Training Acc 81.12 % AVG Validation Acc 79.53 %\n",
      "Epoch:90/200 AVG Training Loss:0.459 AVG Validation Loss:0.527 AVG Training Acc 81.09 % AVG Validation Acc 79.44 %\n",
      "Epoch:100/200 AVG Training Loss:0.458 AVG Validation Loss:0.526 AVG Training Acc 81.06 % AVG Validation Acc 79.44 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.457 AVG Validation Loss:0.529 AVG Training Acc 81.08 % AVG Validation Acc 79.44 %\n",
      "Epoch:120/200 AVG Training Loss:0.458 AVG Validation Loss:0.527 AVG Training Acc 81.09 % AVG Validation Acc 79.35 %\n",
      "Epoch:130/200 AVG Training Loss:0.459 AVG Validation Loss:0.528 AVG Training Acc 81.24 % AVG Validation Acc 79.53 %\n",
      "Epoch   133: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.456 AVG Validation Loss:0.527 AVG Training Acc 81.18 % AVG Validation Acc 79.44 %\n",
      "Epoch:150/200 AVG Training Loss:0.456 AVG Validation Loss:0.524 AVG Training Acc 81.24 % AVG Validation Acc 79.35 %\n",
      "Epoch:160/200 AVG Training Loss:0.457 AVG Validation Loss:0.526 AVG Training Acc 81.03 % AVG Validation Acc 79.53 %\n",
      "Epoch   164: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.458 AVG Validation Loss:0.526 AVG Training Acc 81.20 % AVG Validation Acc 79.53 %\n",
      "Epoch:180/200 AVG Training Loss:0.457 AVG Validation Loss:0.527 AVG Training Acc 81.24 % AVG Validation Acc 79.44 %\n",
      "Epoch:190/200 AVG Training Loss:0.458 AVG Validation Loss:0.528 AVG Training Acc 81.09 % AVG Validation Acc 79.53 %\n",
      "Epoch   195: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.457 AVG Validation Loss:0.525 AVG Training Acc 81.15 % AVG Validation Acc 79.53 %\n",
      "Split 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f8673e8e53b431b85d535f4ddb29b6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.492 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.476 AVG Validation Loss:0.497 AVG Training Acc 80.61 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.471 AVG Validation Loss:0.509 AVG Training Acc 80.81 % AVG Validation Acc 79.96 %\n",
      "Epoch:60/200 AVG Training Loss:0.462 AVG Validation Loss:0.520 AVG Training Acc 81.14 % AVG Validation Acc 79.87 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.458 AVG Validation Loss:0.523 AVG Training Acc 81.48 % AVG Validation Acc 79.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.457 AVG Validation Loss:0.528 AVG Training Acc 81.38 % AVG Validation Acc 79.87 %\n",
      "Epoch:90/200 AVG Training Loss:0.456 AVG Validation Loss:0.529 AVG Training Acc 81.40 % AVG Validation Acc 79.87 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.455 AVG Validation Loss:0.532 AVG Training Acc 81.44 % AVG Validation Acc 79.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.455 AVG Validation Loss:0.532 AVG Training Acc 81.51 % AVG Validation Acc 79.96 %\n",
      "Epoch:120/200 AVG Training Loss:0.455 AVG Validation Loss:0.530 AVG Training Acc 81.48 % AVG Validation Acc 79.96 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.454 AVG Validation Loss:0.532 AVG Training Acc 81.44 % AVG Validation Acc 79.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.455 AVG Validation Loss:0.533 AVG Training Acc 81.43 % AVG Validation Acc 79.87 %\n",
      "Epoch:150/200 AVG Training Loss:0.454 AVG Validation Loss:0.533 AVG Training Acc 81.49 % AVG Validation Acc 79.78 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.454 AVG Validation Loss:0.532 AVG Training Acc 81.56 % AVG Validation Acc 79.96 %\n",
      "Epoch:170/200 AVG Training Loss:0.455 AVG Validation Loss:0.534 AVG Training Acc 81.47 % AVG Validation Acc 79.87 %\n",
      "Epoch:180/200 AVG Training Loss:0.455 AVG Validation Loss:0.532 AVG Training Acc 81.53 % AVG Validation Acc 79.87 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.455 AVG Validation Loss:0.533 AVG Training Acc 81.53 % AVG Validation Acc 79.78 %\n",
      "Epoch:200/200 AVG Training Loss:0.453 AVG Validation Loss:0.533 AVG Training Acc 81.46 % AVG Validation Acc 79.87 %\n",
      "Split 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "377d9e8b28604a46a2cdaff077347571",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.10 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.498 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.483 AVG Validation Loss:0.504 AVG Training Acc 80.25 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.478 AVG Validation Loss:0.508 AVG Training Acc 80.44 % AVG Validation Acc 79.96 %\n",
      "Epoch:50/200 AVG Training Loss:0.471 AVG Validation Loss:0.514 AVG Training Acc 80.75 % AVG Validation Acc 79.69 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.466 AVG Validation Loss:0.517 AVG Training Acc 80.85 % AVG Validation Acc 79.33 %\n",
      "Epoch:70/200 AVG Training Loss:0.465 AVG Validation Loss:0.518 AVG Training Acc 80.89 % AVG Validation Acc 79.42 %\n",
      "Epoch:80/200 AVG Training Loss:0.463 AVG Validation Loss:0.517 AVG Training Acc 81.06 % AVG Validation Acc 79.42 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.464 AVG Validation Loss:0.517 AVG Training Acc 80.93 % AVG Validation Acc 79.51 %\n",
      "Epoch:100/200 AVG Training Loss:0.463 AVG Validation Loss:0.520 AVG Training Acc 81.00 % AVG Validation Acc 79.51 %\n",
      "Epoch:110/200 AVG Training Loss:0.462 AVG Validation Loss:0.520 AVG Training Acc 81.00 % AVG Validation Acc 79.51 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.463 AVG Validation Loss:0.519 AVG Training Acc 81.00 % AVG Validation Acc 79.42 %\n",
      "Epoch:130/200 AVG Training Loss:0.464 AVG Validation Loss:0.520 AVG Training Acc 80.95 % AVG Validation Acc 79.51 %\n",
      "Epoch:140/200 AVG Training Loss:0.464 AVG Validation Loss:0.517 AVG Training Acc 80.83 % AVG Validation Acc 79.60 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.463 AVG Validation Loss:0.520 AVG Training Acc 81.02 % AVG Validation Acc 79.42 %\n",
      "Epoch:160/200 AVG Training Loss:0.462 AVG Validation Loss:0.519 AVG Training Acc 81.02 % AVG Validation Acc 79.60 %\n",
      "Epoch:170/200 AVG Training Loss:0.464 AVG Validation Loss:0.519 AVG Training Acc 81.16 % AVG Validation Acc 79.51 %\n",
      "Epoch:180/200 AVG Training Loss:0.463 AVG Validation Loss:0.519 AVG Training Acc 80.95 % AVG Validation Acc 79.51 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.463 AVG Validation Loss:0.520 AVG Training Acc 80.94 % AVG Validation Acc 79.51 %\n",
      "Epoch:200/200 AVG Training Loss:0.462 AVG Validation Loss:0.519 AVG Training Acc 80.97 % AVG Validation Acc 79.51 %\n",
      "Split 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afbe1100801e4da894048954f5ded5d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.498 AVG Training Acc 80.16 % AVG Validation Acc 80.05 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.484 AVG Validation Loss:0.498 AVG Training Acc 80.27 % AVG Validation Acc 79.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.477 AVG Validation Loss:0.500 AVG Training Acc 80.52 % AVG Validation Acc 79.78 %\n",
      "Epoch:50/200 AVG Training Loss:0.473 AVG Validation Loss:0.503 AVG Training Acc 80.68 % AVG Validation Acc 79.60 %\n",
      "Epoch:60/200 AVG Training Loss:0.467 AVG Validation Loss:0.505 AVG Training Acc 80.80 % AVG Validation Acc 79.15 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.466 AVG Validation Loss:0.506 AVG Training Acc 80.78 % AVG Validation Acc 78.97 %\n",
      "Epoch:80/200 AVG Training Loss:0.466 AVG Validation Loss:0.514 AVG Training Acc 80.81 % AVG Validation Acc 79.06 %\n",
      "Epoch:90/200 AVG Training Loss:0.464 AVG Validation Loss:0.509 AVG Training Acc 80.90 % AVG Validation Acc 79.06 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.463 AVG Validation Loss:0.513 AVG Training Acc 80.99 % AVG Validation Acc 78.97 %\n",
      "Epoch:110/200 AVG Training Loss:0.464 AVG Validation Loss:0.515 AVG Training Acc 80.79 % AVG Validation Acc 79.15 %\n",
      "Epoch:120/200 AVG Training Loss:0.463 AVG Validation Loss:0.514 AVG Training Acc 80.87 % AVG Validation Acc 78.97 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.464 AVG Validation Loss:0.510 AVG Training Acc 80.83 % AVG Validation Acc 78.97 %\n",
      "Epoch:140/200 AVG Training Loss:0.464 AVG Validation Loss:0.509 AVG Training Acc 80.68 % AVG Validation Acc 79.24 %\n",
      "Epoch:150/200 AVG Training Loss:0.463 AVG Validation Loss:0.512 AVG Training Acc 80.85 % AVG Validation Acc 78.97 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.464 AVG Validation Loss:0.513 AVG Training Acc 80.86 % AVG Validation Acc 79.24 %\n",
      "Epoch:170/200 AVG Training Loss:0.464 AVG Validation Loss:0.514 AVG Training Acc 80.83 % AVG Validation Acc 78.97 %\n",
      "Epoch:180/200 AVG Training Loss:0.463 AVG Validation Loss:0.514 AVG Training Acc 80.79 % AVG Validation Acc 79.06 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.463 AVG Validation Loss:0.512 AVG Training Acc 80.90 % AVG Validation Acc 78.97 %\n",
      "Epoch:200/200 AVG Training Loss:0.463 AVG Validation Loss:0.511 AVG Training Acc 80.84 % AVG Validation Acc 79.24 %\n",
      "Split 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c9913f70c9541f5ae86979b79c5122b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.493 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.489 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.21 % AVG Validation Acc 80.05 %\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.473 AVG Validation Loss:0.492 AVG Training Acc 80.55 % AVG Validation Acc 80.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.465 AVG Validation Loss:0.498 AVG Training Acc 81.04 % AVG Validation Acc 79.87 %\n",
      "Epoch:70/200 AVG Training Loss:0.459 AVG Validation Loss:0.511 AVG Training Acc 81.34 % AVG Validation Acc 79.60 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.455 AVG Validation Loss:0.516 AVG Training Acc 81.58 % AVG Validation Acc 79.24 %\n",
      "Epoch:90/200 AVG Training Loss:0.455 AVG Validation Loss:0.513 AVG Training Acc 81.66 % AVG Validation Acc 79.60 %\n",
      "Epoch:100/200 AVG Training Loss:0.455 AVG Validation Loss:0.517 AVG Training Acc 81.57 % AVG Validation Acc 79.24 %\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.453 AVG Validation Loss:0.516 AVG Training Acc 81.56 % AVG Validation Acc 79.33 %\n",
      "Epoch:120/200 AVG Training Loss:0.454 AVG Validation Loss:0.515 AVG Training Acc 81.64 % AVG Validation Acc 79.60 %\n",
      "Epoch:130/200 AVG Training Loss:0.451 AVG Validation Loss:0.514 AVG Training Acc 81.51 % AVG Validation Acc 79.42 %\n",
      "Epoch   134: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.454 AVG Validation Loss:0.517 AVG Training Acc 81.44 % AVG Validation Acc 79.42 %\n",
      "Epoch:150/200 AVG Training Loss:0.455 AVG Validation Loss:0.519 AVG Training Acc 81.49 % AVG Validation Acc 79.15 %\n",
      "Epoch:160/200 AVG Training Loss:0.453 AVG Validation Loss:0.516 AVG Training Acc 81.51 % AVG Validation Acc 79.24 %\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.455 AVG Validation Loss:0.514 AVG Training Acc 81.42 % AVG Validation Acc 79.51 %\n",
      "Epoch:180/200 AVG Training Loss:0.452 AVG Validation Loss:0.517 AVG Training Acc 81.49 % AVG Validation Acc 79.33 %\n",
      "Epoch:190/200 AVG Training Loss:0.453 AVG Validation Loss:0.517 AVG Training Acc 81.54 % AVG Validation Acc 79.42 %\n",
      "Epoch   196: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.454 AVG Validation Loss:0.517 AVG Training Acc 81.36 % AVG Validation Acc 79.33 %\n",
      "Split 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff6fe83f2b54959986b372eca91a3b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.486 AVG Validation Loss:0.492 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.482 AVG Validation Loss:0.496 AVG Training Acc 80.44 % AVG Validation Acc 80.05 %\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.471 AVG Validation Loss:0.501 AVG Training Acc 80.76 % AVG Validation Acc 79.60 %\n",
      "Epoch:60/200 AVG Training Loss:0.465 AVG Validation Loss:0.511 AVG Training Acc 81.01 % AVG Validation Acc 79.51 %\n",
      "Epoch:70/200 AVG Training Loss:0.460 AVG Validation Loss:0.512 AVG Training Acc 81.15 % AVG Validation Acc 79.24 %\n",
      "Epoch    71: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.458 AVG Validation Loss:0.525 AVG Training Acc 81.24 % AVG Validation Acc 78.97 %\n",
      "Epoch:90/200 AVG Training Loss:0.458 AVG Validation Loss:0.520 AVG Training Acc 81.34 % AVG Validation Acc 79.15 %\n",
      "Epoch:100/200 AVG Training Loss:0.457 AVG Validation Loss:0.523 AVG Training Acc 81.27 % AVG Validation Acc 79.24 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.455 AVG Validation Loss:0.533 AVG Training Acc 81.52 % AVG Validation Acc 78.70 %\n",
      "Epoch:120/200 AVG Training Loss:0.455 AVG Validation Loss:0.529 AVG Training Acc 81.40 % AVG Validation Acc 78.88 %\n",
      "Epoch:130/200 AVG Training Loss:0.455 AVG Validation Loss:0.523 AVG Training Acc 81.54 % AVG Validation Acc 79.06 %\n",
      "Epoch   133: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.455 AVG Validation Loss:0.529 AVG Training Acc 81.38 % AVG Validation Acc 78.97 %\n",
      "Epoch:150/200 AVG Training Loss:0.454 AVG Validation Loss:0.525 AVG Training Acc 81.46 % AVG Validation Acc 78.88 %\n",
      "Epoch:160/200 AVG Training Loss:0.455 AVG Validation Loss:0.531 AVG Training Acc 81.38 % AVG Validation Acc 79.15 %\n",
      "Epoch   164: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.457 AVG Validation Loss:0.524 AVG Training Acc 81.22 % AVG Validation Acc 79.06 %\n",
      "Epoch:180/200 AVG Training Loss:0.457 AVG Validation Loss:0.529 AVG Training Acc 81.24 % AVG Validation Acc 78.79 %\n",
      "Epoch:190/200 AVG Training Loss:0.455 AVG Validation Loss:0.528 AVG Training Acc 81.44 % AVG Validation Acc 79.06 %\n",
      "Epoch   195: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.457 AVG Validation Loss:0.525 AVG Training Acc 81.40 % AVG Validation Acc 79.06 %\n",
      "Split 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77ac90b28abc4704822901dcd992493e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.485 AVG Validation Loss:0.492 AVG Training Acc 80.25 % AVG Validation Acc 80.25 %\n",
      "Epoch:50/200 AVG Training Loss:0.483 AVG Validation Loss:0.491 AVG Training Acc 80.37 % AVG Validation Acc 80.34 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.477 AVG Validation Loss:0.497 AVG Training Acc 80.56 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.476 AVG Validation Loss:0.495 AVG Training Acc 80.60 % AVG Validation Acc 80.16 %\n",
      "Epoch:80/200 AVG Training Loss:0.475 AVG Validation Loss:0.501 AVG Training Acc 80.60 % AVG Validation Acc 80.16 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.476 AVG Validation Loss:0.495 AVG Training Acc 80.59 % AVG Validation Acc 80.16 %\n",
      "Epoch:100/200 AVG Training Loss:0.475 AVG Validation Loss:0.499 AVG Training Acc 80.62 % AVG Validation Acc 80.25 %\n",
      "Epoch:110/200 AVG Training Loss:0.476 AVG Validation Loss:0.502 AVG Training Acc 80.62 % AVG Validation Acc 80.25 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.475 AVG Validation Loss:0.500 AVG Training Acc 80.67 % AVG Validation Acc 80.25 %\n",
      "Epoch:130/200 AVG Training Loss:0.475 AVG Validation Loss:0.496 AVG Training Acc 80.61 % AVG Validation Acc 80.34 %\n",
      "Epoch:140/200 AVG Training Loss:0.475 AVG Validation Loss:0.502 AVG Training Acc 80.61 % AVG Validation Acc 80.25 %\n",
      "Epoch:150/200 AVG Training Loss:0.474 AVG Validation Loss:0.502 AVG Training Acc 80.67 % AVG Validation Acc 80.25 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.475 AVG Validation Loss:0.502 AVG Training Acc 80.55 % AVG Validation Acc 80.25 %\n",
      "Epoch:170/200 AVG Training Loss:0.474 AVG Validation Loss:0.501 AVG Training Acc 80.67 % AVG Validation Acc 80.16 %\n",
      "Epoch:180/200 AVG Training Loss:0.474 AVG Validation Loss:0.501 AVG Training Acc 80.67 % AVG Validation Acc 80.25 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.474 AVG Validation Loss:0.495 AVG Training Acc 80.69 % AVG Validation Acc 80.34 %\n",
      "Epoch:200/200 AVG Training Loss:0.475 AVG Validation Loss:0.502 AVG Training Acc 80.68 % AVG Validation Acc 80.16 %\n",
      "Split 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c6b67af6ae145f69262080995550f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.492 AVG Training Acc 80.18 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.25 % AVG Validation Acc 80.16 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.480 AVG Validation Loss:0.499 AVG Training Acc 80.44 % AVG Validation Acc 79.89 %\n",
      "Epoch:50/200 AVG Training Loss:0.473 AVG Validation Loss:0.509 AVG Training Acc 80.71 % AVG Validation Acc 79.71 %\n",
      "Epoch:60/200 AVG Training Loss:0.469 AVG Validation Loss:0.516 AVG Training Acc 80.80 % AVG Validation Acc 79.71 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.464 AVG Validation Loss:0.519 AVG Training Acc 81.02 % AVG Validation Acc 79.80 %\n",
      "Epoch:80/200 AVG Training Loss:0.463 AVG Validation Loss:0.521 AVG Training Acc 81.04 % AVG Validation Acc 79.62 %\n",
      "Epoch:90/200 AVG Training Loss:0.462 AVG Validation Loss:0.522 AVG Training Acc 81.09 % AVG Validation Acc 79.44 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.461 AVG Validation Loss:0.525 AVG Training Acc 81.14 % AVG Validation Acc 79.62 %\n",
      "Epoch:110/200 AVG Training Loss:0.462 AVG Validation Loss:0.526 AVG Training Acc 81.10 % AVG Validation Acc 79.53 %\n",
      "Epoch:120/200 AVG Training Loss:0.462 AVG Validation Loss:0.525 AVG Training Acc 81.10 % AVG Validation Acc 79.71 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.461 AVG Validation Loss:0.523 AVG Training Acc 81.10 % AVG Validation Acc 79.62 %\n",
      "Epoch:140/200 AVG Training Loss:0.460 AVG Validation Loss:0.530 AVG Training Acc 81.04 % AVG Validation Acc 79.62 %\n",
      "Epoch:150/200 AVG Training Loss:0.463 AVG Validation Loss:0.522 AVG Training Acc 81.01 % AVG Validation Acc 79.71 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.462 AVG Validation Loss:0.521 AVG Training Acc 81.11 % AVG Validation Acc 79.71 %\n",
      "Epoch:170/200 AVG Training Loss:0.462 AVG Validation Loss:0.527 AVG Training Acc 81.04 % AVG Validation Acc 79.62 %\n",
      "Epoch:180/200 AVG Training Loss:0.462 AVG Validation Loss:0.523 AVG Training Acc 81.21 % AVG Validation Acc 79.62 %\n",
      "Epoch:190/200 AVG Training Loss:0.462 AVG Validation Loss:0.524 AVG Training Acc 81.13 % AVG Validation Acc 79.53 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.461 AVG Validation Loss:0.526 AVG Training Acc 81.08 % AVG Validation Acc 79.71 %\n",
      "Split 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fa84b98029c455d8f83d0e2ce0fdc2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.493 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.493 AVG Training Acc 80.10 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.21 % AVG Validation Acc 79.98 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.474 AVG Validation Loss:0.500 AVG Training Acc 80.60 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.466 AVG Validation Loss:0.507 AVG Training Acc 80.92 % AVG Validation Acc 79.80 %\n",
      "Epoch:60/200 AVG Training Loss:0.459 AVG Validation Loss:0.520 AVG Training Acc 81.09 % AVG Validation Acc 79.53 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.454 AVG Validation Loss:0.522 AVG Training Acc 81.45 % AVG Validation Acc 79.71 %\n",
      "Epoch:80/200 AVG Training Loss:0.452 AVG Validation Loss:0.522 AVG Training Acc 81.54 % AVG Validation Acc 79.26 %\n",
      "Epoch:90/200 AVG Training Loss:0.451 AVG Validation Loss:0.522 AVG Training Acc 81.38 % AVG Validation Acc 79.08 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.449 AVG Validation Loss:0.523 AVG Training Acc 81.54 % AVG Validation Acc 78.90 %\n",
      "Epoch:110/200 AVG Training Loss:0.450 AVG Validation Loss:0.520 AVG Training Acc 81.55 % AVG Validation Acc 79.26 %\n",
      "Epoch:120/200 AVG Training Loss:0.450 AVG Validation Loss:0.522 AVG Training Acc 81.56 % AVG Validation Acc 79.35 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.451 AVG Validation Loss:0.523 AVG Training Acc 81.57 % AVG Validation Acc 79.08 %\n",
      "Epoch:140/200 AVG Training Loss:0.450 AVG Validation Loss:0.523 AVG Training Acc 81.64 % AVG Validation Acc 79.35 %\n",
      "Epoch:150/200 AVG Training Loss:0.450 AVG Validation Loss:0.525 AVG Training Acc 81.66 % AVG Validation Acc 79.35 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.448 AVG Validation Loss:0.521 AVG Training Acc 81.64 % AVG Validation Acc 79.17 %\n",
      "Epoch:170/200 AVG Training Loss:0.449 AVG Validation Loss:0.525 AVG Training Acc 81.65 % AVG Validation Acc 79.26 %\n",
      "Epoch:180/200 AVG Training Loss:0.450 AVG Validation Loss:0.523 AVG Training Acc 81.52 % AVG Validation Acc 79.08 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.450 AVG Validation Loss:0.523 AVG Training Acc 81.47 % AVG Validation Acc 79.08 %\n",
      "Epoch:200/200 AVG Training Loss:0.447 AVG Validation Loss:0.525 AVG Training Acc 81.57 % AVG Validation Acc 79.08 %\n",
      "Split 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f9361063398490683920fb2002995e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.493 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.492 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.496 AVG Validation Loss:0.495 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.28 % AVG Validation Acc 79.89 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.481 AVG Validation Loss:0.487 AVG Training Acc 80.23 % AVG Validation Acc 80.25 %\n",
      "Epoch:60/200 AVG Training Loss:0.477 AVG Validation Loss:0.492 AVG Training Acc 80.25 % AVG Validation Acc 80.25 %\n",
      "Epoch:70/200 AVG Training Loss:0.472 AVG Validation Loss:0.496 AVG Training Acc 80.32 % AVG Validation Acc 80.16 %\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.468 AVG Validation Loss:0.494 AVG Training Acc 80.48 % AVG Validation Acc 79.98 %\n",
      "Epoch:90/200 AVG Training Loss:0.467 AVG Validation Loss:0.496 AVG Training Acc 80.46 % AVG Validation Acc 79.89 %\n",
      "Epoch:100/200 AVG Training Loss:0.467 AVG Validation Loss:0.494 AVG Training Acc 80.49 % AVG Validation Acc 79.98 %\n",
      "Epoch   104: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.467 AVG Validation Loss:0.496 AVG Training Acc 80.48 % AVG Validation Acc 80.07 %\n",
      "Epoch:120/200 AVG Training Loss:0.468 AVG Validation Loss:0.495 AVG Training Acc 80.42 % AVG Validation Acc 80.07 %\n",
      "Epoch:130/200 AVG Training Loss:0.467 AVG Validation Loss:0.496 AVG Training Acc 80.50 % AVG Validation Acc 80.16 %\n",
      "Epoch   135: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.468 AVG Validation Loss:0.497 AVG Training Acc 80.52 % AVG Validation Acc 79.98 %\n",
      "Epoch:150/200 AVG Training Loss:0.468 AVG Validation Loss:0.495 AVG Training Acc 80.38 % AVG Validation Acc 80.16 %\n",
      "Epoch:160/200 AVG Training Loss:0.467 AVG Validation Loss:0.496 AVG Training Acc 80.44 % AVG Validation Acc 80.07 %\n",
      "Epoch   166: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.467 AVG Validation Loss:0.494 AVG Training Acc 80.43 % AVG Validation Acc 80.25 %\n",
      "Epoch:180/200 AVG Training Loss:0.467 AVG Validation Loss:0.497 AVG Training Acc 80.43 % AVG Validation Acc 80.16 %\n",
      "Epoch:190/200 AVG Training Loss:0.467 AVG Validation Loss:0.495 AVG Training Acc 80.49 % AVG Validation Acc 80.16 %\n",
      "Epoch   197: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.467 AVG Validation Loss:0.495 AVG Training Acc 80.44 % AVG Validation Acc 80.16 %\n",
      "Split 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e7827321a994899b02af5cfdcabecd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.499 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.497 AVG Training Acc 80.16 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.487 AVG Validation Loss:0.499 AVG Training Acc 80.20 % AVG Validation Acc 79.98 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.483 AVG Validation Loss:0.499 AVG Training Acc 80.30 % AVG Validation Acc 79.89 %\n",
      "Epoch:50/200 AVG Training Loss:0.473 AVG Validation Loss:0.504 AVG Training Acc 80.48 % AVG Validation Acc 79.89 %\n",
      "Epoch:60/200 AVG Training Loss:0.468 AVG Validation Loss:0.507 AVG Training Acc 80.72 % AVG Validation Acc 79.80 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.463 AVG Validation Loss:0.516 AVG Training Acc 80.90 % AVG Validation Acc 78.99 %\n",
      "Epoch:80/200 AVG Training Loss:0.459 AVG Validation Loss:0.515 AVG Training Acc 80.95 % AVG Validation Acc 79.08 %\n",
      "Epoch:90/200 AVG Training Loss:0.458 AVG Validation Loss:0.516 AVG Training Acc 80.95 % AVG Validation Acc 78.99 %\n",
      "Epoch:100/200 AVG Training Loss:0.456 AVG Validation Loss:0.520 AVG Training Acc 80.98 % AVG Validation Acc 79.08 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.459 AVG Validation Loss:0.523 AVG Training Acc 81.07 % AVG Validation Acc 78.90 %\n",
      "Epoch:120/200 AVG Training Loss:0.456 AVG Validation Loss:0.518 AVG Training Acc 81.13 % AVG Validation Acc 79.08 %\n",
      "Epoch:130/200 AVG Training Loss:0.457 AVG Validation Loss:0.520 AVG Training Acc 81.12 % AVG Validation Acc 79.08 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.459 AVG Validation Loss:0.523 AVG Training Acc 81.04 % AVG Validation Acc 79.08 %\n",
      "Epoch:150/200 AVG Training Loss:0.457 AVG Validation Loss:0.521 AVG Training Acc 80.95 % AVG Validation Acc 79.17 %\n",
      "Epoch:160/200 AVG Training Loss:0.458 AVG Validation Loss:0.518 AVG Training Acc 81.04 % AVG Validation Acc 79.26 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.457 AVG Validation Loss:0.520 AVG Training Acc 81.03 % AVG Validation Acc 79.17 %\n",
      "Epoch:180/200 AVG Training Loss:0.458 AVG Validation Loss:0.521 AVG Training Acc 80.99 % AVG Validation Acc 78.99 %\n",
      "Epoch:190/200 AVG Training Loss:0.458 AVG Validation Loss:0.520 AVG Training Acc 80.99 % AVG Validation Acc 78.99 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.458 AVG Validation Loss:0.520 AVG Training Acc 81.06 % AVG Validation Acc 79.26 %\n",
      "Split 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc0fe71c856461097de0b37de4eee54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.23 % AVG Validation Acc 79.69 %\n",
      "Epoch:40/200 AVG Training Loss:0.482 AVG Validation Loss:0.495 AVG Training Acc 80.32 % AVG Validation Acc 79.96 %\n",
      "Epoch:50/200 AVG Training Loss:0.479 AVG Validation Loss:0.498 AVG Training Acc 80.51 % AVG Validation Acc 80.05 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.544 AVG Validation Loss:0.540 AVG Training Acc 79.68 % AVG Validation Acc 79.33 %\n",
      "Epoch:70/200 AVG Training Loss:0.510 AVG Validation Loss:0.506 AVG Training Acc 79.75 % AVG Validation Acc 79.60 %\n",
      "Epoch:80/200 AVG Training Loss:0.500 AVG Validation Loss:0.500 AVG Training Acc 79.93 % AVG Validation Acc 79.51 %\n",
      "Epoch:90/200 AVG Training Loss:0.498 AVG Validation Loss:0.497 AVG Training Acc 79.89 % AVG Validation Acc 79.69 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.496 AVG Validation Loss:0.498 AVG Training Acc 79.94 % AVG Validation Acc 79.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.496 AVG Validation Loss:0.498 AVG Training Acc 79.86 % AVG Validation Acc 79.69 %\n",
      "Epoch:120/200 AVG Training Loss:0.498 AVG Validation Loss:0.497 AVG Training Acc 79.87 % AVG Validation Acc 79.96 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.495 AVG Validation Loss:0.498 AVG Training Acc 79.93 % AVG Validation Acc 79.60 %\n",
      "Epoch:140/200 AVG Training Loss:0.497 AVG Validation Loss:0.498 AVG Training Acc 79.95 % AVG Validation Acc 79.60 %\n",
      "Epoch:150/200 AVG Training Loss:0.496 AVG Validation Loss:0.498 AVG Training Acc 79.95 % AVG Validation Acc 79.69 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.496 AVG Validation Loss:0.496 AVG Training Acc 79.90 % AVG Validation Acc 79.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.496 AVG Validation Loss:0.495 AVG Training Acc 79.88 % AVG Validation Acc 79.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.496 AVG Validation Loss:0.498 AVG Training Acc 79.96 % AVG Validation Acc 79.69 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.496 AVG Validation Loss:0.496 AVG Training Acc 79.84 % AVG Validation Acc 79.87 %\n",
      "Epoch:200/200 AVG Training Loss:0.497 AVG Validation Loss:0.497 AVG Training Acc 79.89 % AVG Validation Acc 79.87 %\n",
      "Split 17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af9423ecc83a4f1a8096d6228b19346a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.30 % AVG Validation Acc 80.05 %\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.471 AVG Validation Loss:0.507 AVG Training Acc 80.66 % AVG Validation Acc 79.78 %\n",
      "Epoch:60/200 AVG Training Loss:0.467 AVG Validation Loss:0.522 AVG Training Acc 80.90 % AVG Validation Acc 79.60 %\n",
      "Epoch:70/200 AVG Training Loss:0.463 AVG Validation Loss:0.523 AVG Training Acc 81.06 % AVG Validation Acc 79.24 %\n",
      "Epoch    71: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.460 AVG Validation Loss:0.521 AVG Training Acc 81.20 % AVG Validation Acc 79.60 %\n",
      "Epoch:90/200 AVG Training Loss:0.458 AVG Validation Loss:0.531 AVG Training Acc 81.39 % AVG Validation Acc 79.15 %\n",
      "Epoch:100/200 AVG Training Loss:0.456 AVG Validation Loss:0.536 AVG Training Acc 81.33 % AVG Validation Acc 79.24 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.458 AVG Validation Loss:0.532 AVG Training Acc 81.42 % AVG Validation Acc 79.42 %\n",
      "Epoch:120/200 AVG Training Loss:0.455 AVG Validation Loss:0.531 AVG Training Acc 81.28 % AVG Validation Acc 79.15 %\n",
      "Epoch:130/200 AVG Training Loss:0.457 AVG Validation Loss:0.539 AVG Training Acc 81.12 % AVG Validation Acc 78.88 %\n",
      "Epoch   133: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.457 AVG Validation Loss:0.528 AVG Training Acc 81.32 % AVG Validation Acc 79.24 %\n",
      "Epoch:150/200 AVG Training Loss:0.457 AVG Validation Loss:0.537 AVG Training Acc 81.34 % AVG Validation Acc 78.79 %\n",
      "Epoch:160/200 AVG Training Loss:0.457 AVG Validation Loss:0.534 AVG Training Acc 81.20 % AVG Validation Acc 79.06 %\n",
      "Epoch   164: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.456 AVG Validation Loss:0.535 AVG Training Acc 81.41 % AVG Validation Acc 78.97 %\n",
      "Epoch:180/200 AVG Training Loss:0.457 AVG Validation Loss:0.534 AVG Training Acc 81.30 % AVG Validation Acc 78.97 %\n",
      "Epoch:190/200 AVG Training Loss:0.457 AVG Validation Loss:0.528 AVG Training Acc 81.35 % AVG Validation Acc 78.97 %\n",
      "Epoch   195: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.457 AVG Validation Loss:0.535 AVG Training Acc 81.41 % AVG Validation Acc 78.88 %\n",
      "Split 18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e243ed09d4034d458be248b040452172",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.499 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.492 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.16 % AVG Validation Acc 79.78 %\n",
      "Epoch:40/200 AVG Training Loss:0.485 AVG Validation Loss:0.505 AVG Training Acc 80.27 % AVG Validation Acc 79.42 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.477 AVG Validation Loss:0.504 AVG Training Acc 80.60 % AVG Validation Acc 79.42 %\n",
      "Epoch:60/200 AVG Training Loss:0.474 AVG Validation Loss:0.520 AVG Training Acc 80.72 % AVG Validation Acc 78.97 %\n",
      "Epoch:70/200 AVG Training Loss:0.470 AVG Validation Loss:0.540 AVG Training Acc 80.82 % AVG Validation Acc 78.88 %\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.464 AVG Validation Loss:0.544 AVG Training Acc 81.00 % AVG Validation Acc 78.88 %\n",
      "Epoch:90/200 AVG Training Loss:0.462 AVG Validation Loss:0.544 AVG Training Acc 81.07 % AVG Validation Acc 78.79 %\n",
      "Epoch:100/200 AVG Training Loss:0.462 AVG Validation Loss:0.542 AVG Training Acc 81.05 % AVG Validation Acc 78.79 %\n",
      "Epoch   104: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.461 AVG Validation Loss:0.539 AVG Training Acc 81.19 % AVG Validation Acc 78.88 %\n",
      "Epoch:120/200 AVG Training Loss:0.463 AVG Validation Loss:0.552 AVG Training Acc 81.27 % AVG Validation Acc 78.79 %\n",
      "Epoch:130/200 AVG Training Loss:0.462 AVG Validation Loss:0.551 AVG Training Acc 81.09 % AVG Validation Acc 78.97 %\n",
      "Epoch   135: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.462 AVG Validation Loss:0.549 AVG Training Acc 81.15 % AVG Validation Acc 78.70 %\n",
      "Epoch:150/200 AVG Training Loss:0.462 AVG Validation Loss:0.548 AVG Training Acc 81.12 % AVG Validation Acc 78.79 %\n",
      "Epoch:160/200 AVG Training Loss:0.462 AVG Validation Loss:0.552 AVG Training Acc 81.21 % AVG Validation Acc 78.79 %\n",
      "Epoch   166: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.463 AVG Validation Loss:0.544 AVG Training Acc 81.33 % AVG Validation Acc 78.70 %\n",
      "Epoch:180/200 AVG Training Loss:0.461 AVG Validation Loss:0.551 AVG Training Acc 81.13 % AVG Validation Acc 78.79 %\n",
      "Epoch:190/200 AVG Training Loss:0.460 AVG Validation Loss:0.547 AVG Training Acc 81.29 % AVG Validation Acc 78.70 %\n",
      "Epoch   197: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.463 AVG Validation Loss:0.551 AVG Training Acc 81.22 % AVG Validation Acc 78.70 %\n",
      "Split 19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ef63a79e512444ca0599a7c3a226d35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.497 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.35 % AVG Validation Acc 79.69 %\n",
      "Epoch:40/200 AVG Training Loss:0.480 AVG Validation Loss:0.503 AVG Training Acc 80.50 % AVG Validation Acc 79.69 %\n",
      "Epoch:50/200 AVG Training Loss:0.476 AVG Validation Loss:0.503 AVG Training Acc 80.65 % AVG Validation Acc 79.60 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.475 AVG Validation Loss:0.506 AVG Training Acc 80.69 % AVG Validation Acc 79.33 %\n",
      "Epoch:70/200 AVG Training Loss:0.472 AVG Validation Loss:0.509 AVG Training Acc 80.81 % AVG Validation Acc 79.24 %\n",
      "Epoch:80/200 AVG Training Loss:0.473 AVG Validation Loss:0.510 AVG Training Acc 80.77 % AVG Validation Acc 79.06 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.473 AVG Validation Loss:0.507 AVG Training Acc 80.82 % AVG Validation Acc 79.24 %\n",
      "Epoch:100/200 AVG Training Loss:0.472 AVG Validation Loss:0.507 AVG Training Acc 80.82 % AVG Validation Acc 79.24 %\n",
      "Epoch:110/200 AVG Training Loss:0.471 AVG Validation Loss:0.508 AVG Training Acc 80.79 % AVG Validation Acc 79.24 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.472 AVG Validation Loss:0.508 AVG Training Acc 80.89 % AVG Validation Acc 79.24 %\n",
      "Epoch:130/200 AVG Training Loss:0.472 AVG Validation Loss:0.507 AVG Training Acc 80.88 % AVG Validation Acc 79.15 %\n",
      "Epoch:140/200 AVG Training Loss:0.471 AVG Validation Loss:0.507 AVG Training Acc 80.96 % AVG Validation Acc 79.15 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.473 AVG Validation Loss:0.511 AVG Training Acc 80.65 % AVG Validation Acc 79.06 %\n",
      "Epoch:160/200 AVG Training Loss:0.474 AVG Validation Loss:0.508 AVG Training Acc 80.81 % AVG Validation Acc 79.15 %\n",
      "Epoch:170/200 AVG Training Loss:0.473 AVG Validation Loss:0.508 AVG Training Acc 80.80 % AVG Validation Acc 79.24 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.471 AVG Validation Loss:0.508 AVG Training Acc 80.90 % AVG Validation Acc 79.24 %\n",
      "Epoch:190/200 AVG Training Loss:0.471 AVG Validation Loss:0.509 AVG Training Acc 80.85 % AVG Validation Acc 79.24 %\n",
      "Epoch:200/200 AVG Training Loss:0.472 AVG Validation Loss:0.510 AVG Training Acc 80.75 % AVG Validation Acc 79.15 %\n",
      "Split 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f113607701ae47918a4e5781c13aceaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.500 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.490 AVG Validation Loss:0.501 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.22 % AVG Validation Acc 79.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.473 AVG Validation Loss:0.511 AVG Training Acc 80.45 % AVG Validation Acc 79.96 %\n",
      "Epoch:50/200 AVG Training Loss:0.469 AVG Validation Loss:0.519 AVG Training Acc 80.61 % AVG Validation Acc 80.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.464 AVG Validation Loss:0.521 AVG Training Acc 80.65 % AVG Validation Acc 79.87 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.461 AVG Validation Loss:0.532 AVG Training Acc 80.83 % AVG Validation Acc 79.69 %\n",
      "Epoch:80/200 AVG Training Loss:0.458 AVG Validation Loss:0.538 AVG Training Acc 81.07 % AVG Validation Acc 79.69 %\n",
      "Epoch:90/200 AVG Training Loss:0.459 AVG Validation Loss:0.536 AVG Training Acc 80.91 % AVG Validation Acc 79.69 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.460 AVG Validation Loss:0.540 AVG Training Acc 80.89 % AVG Validation Acc 79.69 %\n",
      "Epoch:110/200 AVG Training Loss:0.458 AVG Validation Loss:0.542 AVG Training Acc 80.89 % AVG Validation Acc 79.60 %\n",
      "Epoch:120/200 AVG Training Loss:0.460 AVG Validation Loss:0.544 AVG Training Acc 80.93 % AVG Validation Acc 79.60 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.458 AVG Validation Loss:0.543 AVG Training Acc 80.86 % AVG Validation Acc 79.51 %\n",
      "Epoch:140/200 AVG Training Loss:0.459 AVG Validation Loss:0.542 AVG Training Acc 80.97 % AVG Validation Acc 79.60 %\n",
      "Epoch:150/200 AVG Training Loss:0.459 AVG Validation Loss:0.542 AVG Training Acc 80.74 % AVG Validation Acc 79.69 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.458 AVG Validation Loss:0.540 AVG Training Acc 80.87 % AVG Validation Acc 79.60 %\n",
      "Epoch:170/200 AVG Training Loss:0.458 AVG Validation Loss:0.542 AVG Training Acc 80.84 % AVG Validation Acc 79.69 %\n",
      "Epoch:180/200 AVG Training Loss:0.458 AVG Validation Loss:0.547 AVG Training Acc 80.88 % AVG Validation Acc 79.60 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.458 AVG Validation Loss:0.540 AVG Training Acc 80.97 % AVG Validation Acc 79.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.457 AVG Validation Loss:0.541 AVG Training Acc 80.99 % AVG Validation Acc 79.51 %\n",
      "Split 21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2631cefff7a4055b2b54fc117825c8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.18 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.483 AVG Validation Loss:0.496 AVG Training Acc 80.29 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.479 AVG Validation Loss:0.505 AVG Training Acc 80.41 % AVG Validation Acc 79.89 %\n",
      "Epoch:50/200 AVG Training Loss:0.473 AVG Validation Loss:0.517 AVG Training Acc 80.50 % AVG Validation Acc 79.71 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.471 AVG Validation Loss:0.519 AVG Training Acc 80.68 % AVG Validation Acc 79.44 %\n",
      "Epoch:70/200 AVG Training Loss:0.468 AVG Validation Loss:0.519 AVG Training Acc 80.74 % AVG Validation Acc 79.44 %\n",
      "Epoch:80/200 AVG Training Loss:0.467 AVG Validation Loss:0.519 AVG Training Acc 80.70 % AVG Validation Acc 79.26 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.467 AVG Validation Loss:0.523 AVG Training Acc 80.70 % AVG Validation Acc 79.26 %\n",
      "Epoch:100/200 AVG Training Loss:0.467 AVG Validation Loss:0.526 AVG Training Acc 80.76 % AVG Validation Acc 79.26 %\n",
      "Epoch:110/200 AVG Training Loss:0.467 AVG Validation Loss:0.514 AVG Training Acc 80.64 % AVG Validation Acc 79.35 %\n",
      "Epoch:120/200 AVG Training Loss:0.466 AVG Validation Loss:0.518 AVG Training Acc 80.72 % AVG Validation Acc 79.44 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.467 AVG Validation Loss:0.519 AVG Training Acc 80.73 % AVG Validation Acc 79.26 %\n",
      "Epoch:140/200 AVG Training Loss:0.466 AVG Validation Loss:0.518 AVG Training Acc 80.72 % AVG Validation Acc 79.44 %\n",
      "Epoch:150/200 AVG Training Loss:0.465 AVG Validation Loss:0.521 AVG Training Acc 80.76 % AVG Validation Acc 79.35 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.466 AVG Validation Loss:0.522 AVG Training Acc 80.81 % AVG Validation Acc 79.26 %\n",
      "Epoch:170/200 AVG Training Loss:0.466 AVG Validation Loss:0.516 AVG Training Acc 80.68 % AVG Validation Acc 79.35 %\n",
      "Epoch:180/200 AVG Training Loss:0.466 AVG Validation Loss:0.518 AVG Training Acc 80.72 % AVG Validation Acc 79.35 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.467 AVG Validation Loss:0.521 AVG Training Acc 80.70 % AVG Validation Acc 79.26 %\n",
      "Epoch:200/200 AVG Training Loss:0.466 AVG Validation Loss:0.517 AVG Training Acc 80.68 % AVG Validation Acc 79.35 %\n",
      "Split 22\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3007a904ec24496eb82dc2691185e459",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.500 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.489 AVG Validation Loss:0.502 AVG Training Acc 80.22 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.485 AVG Validation Loss:0.502 AVG Training Acc 80.24 % AVG Validation Acc 79.98 %\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.29 % AVG Validation Acc 79.98 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.484 AVG Validation Loss:0.502 AVG Training Acc 80.28 % AVG Validation Acc 79.98 %\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.502 AVG Training Acc 80.37 % AVG Validation Acc 79.98 %\n",
      "Epoch:70/200 AVG Training Loss:0.483 AVG Validation Loss:0.502 AVG Training Acc 80.33 % AVG Validation Acc 79.80 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.481 AVG Validation Loss:0.505 AVG Training Acc 80.38 % AVG Validation Acc 79.71 %\n",
      "Epoch:90/200 AVG Training Loss:0.482 AVG Validation Loss:0.504 AVG Training Acc 80.37 % AVG Validation Acc 79.71 %\n",
      "Epoch:100/200 AVG Training Loss:0.482 AVG Validation Loss:0.505 AVG Training Acc 80.32 % AVG Validation Acc 79.71 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.481 AVG Validation Loss:0.503 AVG Training Acc 80.34 % AVG Validation Acc 79.71 %\n",
      "Epoch:120/200 AVG Training Loss:0.482 AVG Validation Loss:0.504 AVG Training Acc 80.29 % AVG Validation Acc 79.71 %\n",
      "Epoch:130/200 AVG Training Loss:0.482 AVG Validation Loss:0.504 AVG Training Acc 80.35 % AVG Validation Acc 79.71 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.482 AVG Validation Loss:0.505 AVG Training Acc 80.30 % AVG Validation Acc 79.71 %\n",
      "Epoch:150/200 AVG Training Loss:0.482 AVG Validation Loss:0.504 AVG Training Acc 80.35 % AVG Validation Acc 79.71 %\n",
      "Epoch:160/200 AVG Training Loss:0.482 AVG Validation Loss:0.504 AVG Training Acc 80.34 % AVG Validation Acc 79.71 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.482 AVG Validation Loss:0.506 AVG Training Acc 80.39 % AVG Validation Acc 79.71 %\n",
      "Epoch:180/200 AVG Training Loss:0.482 AVG Validation Loss:0.505 AVG Training Acc 80.42 % AVG Validation Acc 79.71 %\n",
      "Epoch:190/200 AVG Training Loss:0.483 AVG Validation Loss:0.505 AVG Training Acc 80.25 % AVG Validation Acc 79.71 %\n",
      "Epoch:200/200 AVG Training Loss:0.481 AVG Validation Loss:0.503 AVG Training Acc 80.37 % AVG Validation Acc 79.71 %\n",
      "Split 23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e44cc5ba1614d3b91e76a377d153d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.499 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.499 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.480 AVG Validation Loss:0.499 AVG Training Acc 80.21 % AVG Validation Acc 79.71 %\n",
      "Epoch:60/200 AVG Training Loss:0.465 AVG Validation Loss:0.510 AVG Training Acc 80.65 % AVG Validation Acc 79.26 %\n",
      "Epoch:70/200 AVG Training Loss:0.458 AVG Validation Loss:0.523 AVG Training Acc 80.83 % AVG Validation Acc 79.26 %\n",
      "Epoch:80/200 AVG Training Loss:0.446 AVG Validation Loss:0.535 AVG Training Acc 81.06 % AVG Validation Acc 79.26 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.444 AVG Validation Loss:0.538 AVG Training Acc 81.31 % AVG Validation Acc 79.35 %\n",
      "Epoch:100/200 AVG Training Loss:0.444 AVG Validation Loss:0.547 AVG Training Acc 81.26 % AVG Validation Acc 79.17 %\n",
      "Epoch:110/200 AVG Training Loss:0.444 AVG Validation Loss:0.544 AVG Training Acc 81.45 % AVG Validation Acc 79.17 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.439 AVG Validation Loss:0.543 AVG Training Acc 81.57 % AVG Validation Acc 78.81 %\n",
      "Epoch:130/200 AVG Training Loss:0.442 AVG Validation Loss:0.539 AVG Training Acc 81.55 % AVG Validation Acc 79.17 %\n",
      "Epoch:140/200 AVG Training Loss:0.440 AVG Validation Loss:0.538 AVG Training Acc 81.41 % AVG Validation Acc 79.17 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.442 AVG Validation Loss:0.540 AVG Training Acc 81.50 % AVG Validation Acc 79.26 %\n",
      "Epoch:160/200 AVG Training Loss:0.441 AVG Validation Loss:0.540 AVG Training Acc 81.31 % AVG Validation Acc 78.99 %\n",
      "Epoch:170/200 AVG Training Loss:0.442 AVG Validation Loss:0.547 AVG Training Acc 81.44 % AVG Validation Acc 79.17 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.440 AVG Validation Loss:0.542 AVG Training Acc 81.40 % AVG Validation Acc 78.99 %\n",
      "Epoch:190/200 AVG Training Loss:0.440 AVG Validation Loss:0.545 AVG Training Acc 81.35 % AVG Validation Acc 78.72 %\n",
      "Epoch:200/200 AVG Training Loss:0.442 AVG Validation Loss:0.540 AVG Training Acc 81.29 % AVG Validation Acc 79.08 %\n",
      "Split 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f177813ef854e16904274caeb4913ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.499 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.493 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.485 AVG Validation Loss:0.493 AVG Training Acc 80.32 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.473 AVG Validation Loss:0.504 AVG Training Acc 80.69 % AVG Validation Acc 79.62 %\n",
      "Epoch:60/200 AVG Training Loss:0.466 AVG Validation Loss:0.513 AVG Training Acc 80.83 % AVG Validation Acc 79.44 %\n",
      "Epoch:70/200 AVG Training Loss:0.461 AVG Validation Loss:0.525 AVG Training Acc 81.08 % AVG Validation Acc 79.17 %\n",
      "Epoch    70: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.456 AVG Validation Loss:0.527 AVG Training Acc 81.22 % AVG Validation Acc 79.26 %\n",
      "Epoch:90/200 AVG Training Loss:0.456 AVG Validation Loss:0.528 AVG Training Acc 81.28 % AVG Validation Acc 79.08 %\n",
      "Epoch:100/200 AVG Training Loss:0.456 AVG Validation Loss:0.529 AVG Training Acc 81.18 % AVG Validation Acc 78.63 %\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.457 AVG Validation Loss:0.531 AVG Training Acc 81.10 % AVG Validation Acc 78.63 %\n",
      "Epoch:120/200 AVG Training Loss:0.455 AVG Validation Loss:0.530 AVG Training Acc 81.34 % AVG Validation Acc 78.72 %\n",
      "Epoch:130/200 AVG Training Loss:0.453 AVG Validation Loss:0.528 AVG Training Acc 81.36 % AVG Validation Acc 78.54 %\n",
      "Epoch   132: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.454 AVG Validation Loss:0.529 AVG Training Acc 81.40 % AVG Validation Acc 78.54 %\n",
      "Epoch:150/200 AVG Training Loss:0.455 AVG Validation Loss:0.526 AVG Training Acc 81.24 % AVG Validation Acc 78.81 %\n",
      "Epoch:160/200 AVG Training Loss:0.453 AVG Validation Loss:0.527 AVG Training Acc 81.30 % AVG Validation Acc 78.81 %\n",
      "Epoch   163: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.455 AVG Validation Loss:0.530 AVG Training Acc 81.23 % AVG Validation Acc 78.63 %\n",
      "Epoch:180/200 AVG Training Loss:0.453 AVG Validation Loss:0.528 AVG Training Acc 81.42 % AVG Validation Acc 78.81 %\n",
      "Epoch:190/200 AVG Training Loss:0.454 AVG Validation Loss:0.529 AVG Training Acc 81.32 % AVG Validation Acc 78.90 %\n",
      "Epoch   194: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.455 AVG Validation Loss:0.527 AVG Training Acc 81.12 % AVG Validation Acc 78.90 %\n",
      "Split 25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd14ce82abec46a58ba33d8c0851855a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.10 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.486 AVG Validation Loss:0.499 AVG Training Acc 80.22 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.32 % AVG Validation Acc 79.98 %\n",
      "Epoch:50/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.34 % AVG Validation Acc 79.98 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.465 AVG Validation Loss:0.502 AVG Training Acc 80.95 % AVG Validation Acc 80.07 %\n",
      "Epoch:70/200 AVG Training Loss:0.456 AVG Validation Loss:0.511 AVG Training Acc 81.14 % AVG Validation Acc 79.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.449 AVG Validation Loss:0.522 AVG Training Acc 81.34 % AVG Validation Acc 80.07 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.444 AVG Validation Loss:0.530 AVG Training Acc 81.59 % AVG Validation Acc 79.98 %\n",
      "Epoch:100/200 AVG Training Loss:0.443 AVG Validation Loss:0.531 AVG Training Acc 81.47 % AVG Validation Acc 80.07 %\n",
      "Epoch:110/200 AVG Training Loss:0.443 AVG Validation Loss:0.531 AVG Training Acc 81.50 % AVG Validation Acc 80.07 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.442 AVG Validation Loss:0.532 AVG Training Acc 81.59 % AVG Validation Acc 80.16 %\n",
      "Epoch:130/200 AVG Training Loss:0.442 AVG Validation Loss:0.529 AVG Training Acc 81.42 % AVG Validation Acc 80.25 %\n",
      "Epoch:140/200 AVG Training Loss:0.441 AVG Validation Loss:0.535 AVG Training Acc 81.43 % AVG Validation Acc 80.07 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.443 AVG Validation Loss:0.529 AVG Training Acc 81.47 % AVG Validation Acc 80.16 %\n",
      "Epoch:160/200 AVG Training Loss:0.442 AVG Validation Loss:0.535 AVG Training Acc 81.56 % AVG Validation Acc 79.71 %\n",
      "Epoch:170/200 AVG Training Loss:0.444 AVG Validation Loss:0.531 AVG Training Acc 81.53 % AVG Validation Acc 80.07 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.442 AVG Validation Loss:0.533 AVG Training Acc 81.45 % AVG Validation Acc 79.80 %\n",
      "Epoch:190/200 AVG Training Loss:0.440 AVG Validation Loss:0.535 AVG Training Acc 81.56 % AVG Validation Acc 79.89 %\n",
      "Epoch:200/200 AVG Training Loss:0.441 AVG Validation Loss:0.532 AVG Training Acc 81.49 % AVG Validation Acc 80.25 %\n",
      "Split 26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71c10fd425754281bf8f0338d47ecbb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.493 AVG Validation Loss:0.493 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.493 AVG Training Acc 80.16 % AVG Validation Acc 80.05 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.21 % AVG Validation Acc 80.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.475 AVG Validation Loss:0.499 AVG Training Acc 80.37 % AVG Validation Acc 79.78 %\n",
      "Epoch:70/200 AVG Training Loss:0.469 AVG Validation Loss:0.516 AVG Training Acc 80.59 % AVG Validation Acc 79.60 %\n",
      "Epoch:80/200 AVG Training Loss:0.463 AVG Validation Loss:0.526 AVG Training Acc 80.85 % AVG Validation Acc 79.69 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.460 AVG Validation Loss:0.533 AVG Training Acc 81.04 % AVG Validation Acc 79.15 %\n",
      "Epoch:100/200 AVG Training Loss:0.460 AVG Validation Loss:0.533 AVG Training Acc 81.00 % AVG Validation Acc 79.15 %\n",
      "Epoch:110/200 AVG Training Loss:0.457 AVG Validation Loss:0.536 AVG Training Acc 81.15 % AVG Validation Acc 79.33 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.458 AVG Validation Loss:0.542 AVG Training Acc 81.04 % AVG Validation Acc 79.24 %\n",
      "Epoch:130/200 AVG Training Loss:0.459 AVG Validation Loss:0.542 AVG Training Acc 81.06 % AVG Validation Acc 79.24 %\n",
      "Epoch:140/200 AVG Training Loss:0.457 AVG Validation Loss:0.539 AVG Training Acc 81.00 % AVG Validation Acc 79.42 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.456 AVG Validation Loss:0.540 AVG Training Acc 81.27 % AVG Validation Acc 79.24 %\n",
      "Epoch:160/200 AVG Training Loss:0.457 AVG Validation Loss:0.541 AVG Training Acc 81.11 % AVG Validation Acc 79.33 %\n",
      "Epoch:170/200 AVG Training Loss:0.457 AVG Validation Loss:0.542 AVG Training Acc 81.33 % AVG Validation Acc 79.15 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.457 AVG Validation Loss:0.540 AVG Training Acc 81.25 % AVG Validation Acc 78.97 %\n",
      "Epoch:190/200 AVG Training Loss:0.457 AVG Validation Loss:0.539 AVG Training Acc 81.16 % AVG Validation Acc 79.33 %\n",
      "Epoch:200/200 AVG Training Loss:0.459 AVG Validation Loss:0.543 AVG Training Acc 81.20 % AVG Validation Acc 79.06 %\n",
      "Split 27\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0dc2646a52e49499f02a9269446187c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.05 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.23 % AVG Validation Acc 79.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.500 AVG Training Acc 80.30 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.482 AVG Validation Loss:0.500 AVG Training Acc 80.34 % AVG Validation Acc 80.14 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.481 AVG Validation Loss:0.503 AVG Training Acc 80.49 % AVG Validation Acc 80.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.480 AVG Validation Loss:0.505 AVG Training Acc 80.44 % AVG Validation Acc 80.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.479 AVG Validation Loss:0.507 AVG Training Acc 80.42 % AVG Validation Acc 80.05 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.480 AVG Validation Loss:0.506 AVG Training Acc 80.48 % AVG Validation Acc 80.05 %\n",
      "Epoch:100/200 AVG Training Loss:0.479 AVG Validation Loss:0.506 AVG Training Acc 80.46 % AVG Validation Acc 80.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.478 AVG Validation Loss:0.507 AVG Training Acc 80.55 % AVG Validation Acc 80.05 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.479 AVG Validation Loss:0.507 AVG Training Acc 80.51 % AVG Validation Acc 80.05 %\n",
      "Epoch:130/200 AVG Training Loss:0.479 AVG Validation Loss:0.507 AVG Training Acc 80.48 % AVG Validation Acc 80.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.478 AVG Validation Loss:0.507 AVG Training Acc 80.54 % AVG Validation Acc 80.05 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.479 AVG Validation Loss:0.507 AVG Training Acc 80.41 % AVG Validation Acc 80.05 %\n",
      "Epoch:160/200 AVG Training Loss:0.479 AVG Validation Loss:0.507 AVG Training Acc 80.42 % AVG Validation Acc 80.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.479 AVG Validation Loss:0.507 AVG Training Acc 80.41 % AVG Validation Acc 80.05 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.479 AVG Validation Loss:0.506 AVG Training Acc 80.50 % AVG Validation Acc 80.05 %\n",
      "Epoch:190/200 AVG Training Loss:0.479 AVG Validation Loss:0.507 AVG Training Acc 80.48 % AVG Validation Acc 80.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.479 AVG Validation Loss:0.507 AVG Training Acc 80.47 % AVG Validation Acc 80.05 %\n",
      "Split 28\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23edcbe98d214cdc8f179e01866b07ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.23 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.479 AVG Validation Loss:0.498 AVG Training Acc 80.42 % AVG Validation Acc 79.96 %\n",
      "Epoch:60/200 AVG Training Loss:0.472 AVG Validation Loss:0.500 AVG Training Acc 80.87 % AVG Validation Acc 79.78 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.466 AVG Validation Loss:0.500 AVG Training Acc 80.97 % AVG Validation Acc 79.69 %\n",
      "Epoch:80/200 AVG Training Loss:0.465 AVG Validation Loss:0.502 AVG Training Acc 80.98 % AVG Validation Acc 79.60 %\n",
      "Epoch:90/200 AVG Training Loss:0.461 AVG Validation Loss:0.502 AVG Training Acc 81.19 % AVG Validation Acc 79.15 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.462 AVG Validation Loss:0.502 AVG Training Acc 81.04 % AVG Validation Acc 79.42 %\n",
      "Epoch:110/200 AVG Training Loss:0.463 AVG Validation Loss:0.502 AVG Training Acc 81.06 % AVG Validation Acc 79.33 %\n",
      "Epoch:120/200 AVG Training Loss:0.461 AVG Validation Loss:0.502 AVG Training Acc 81.11 % AVG Validation Acc 79.60 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.462 AVG Validation Loss:0.504 AVG Training Acc 81.04 % AVG Validation Acc 79.42 %\n",
      "Epoch:140/200 AVG Training Loss:0.461 AVG Validation Loss:0.504 AVG Training Acc 81.17 % AVG Validation Acc 79.51 %\n",
      "Epoch:150/200 AVG Training Loss:0.463 AVG Validation Loss:0.504 AVG Training Acc 81.12 % AVG Validation Acc 79.24 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.462 AVG Validation Loss:0.501 AVG Training Acc 81.16 % AVG Validation Acc 79.33 %\n",
      "Epoch:170/200 AVG Training Loss:0.464 AVG Validation Loss:0.500 AVG Training Acc 81.18 % AVG Validation Acc 79.42 %\n",
      "Epoch:180/200 AVG Training Loss:0.461 AVG Validation Loss:0.502 AVG Training Acc 81.32 % AVG Validation Acc 79.33 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.461 AVG Validation Loss:0.504 AVG Training Acc 81.16 % AVG Validation Acc 79.42 %\n",
      "Epoch:200/200 AVG Training Loss:0.462 AVG Validation Loss:0.503 AVG Training Acc 81.11 % AVG Validation Acc 79.60 %\n",
      "Split 29\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9d0245856954a569bf789adcc1bb0e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.481 AVG Validation Loss:0.497 AVG Training Acc 80.31 % AVG Validation Acc 79.96 %\n",
      "Epoch:50/200 AVG Training Loss:0.477 AVG Validation Loss:0.502 AVG Training Acc 80.48 % AVG Validation Acc 79.96 %\n",
      "Epoch:60/200 AVG Training Loss:0.474 AVG Validation Loss:0.510 AVG Training Acc 80.58 % AVG Validation Acc 79.51 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.471 AVG Validation Loss:0.505 AVG Training Acc 80.69 % AVG Validation Acc 79.33 %\n",
      "Epoch:80/200 AVG Training Loss:0.470 AVG Validation Loss:0.508 AVG Training Acc 80.72 % AVG Validation Acc 79.06 %\n",
      "Epoch:90/200 AVG Training Loss:0.470 AVG Validation Loss:0.508 AVG Training Acc 80.70 % AVG Validation Acc 79.15 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.470 AVG Validation Loss:0.508 AVG Training Acc 80.74 % AVG Validation Acc 79.15 %\n",
      "Epoch:110/200 AVG Training Loss:0.468 AVG Validation Loss:0.508 AVG Training Acc 80.80 % AVG Validation Acc 79.06 %\n",
      "Epoch:120/200 AVG Training Loss:0.470 AVG Validation Loss:0.508 AVG Training Acc 80.77 % AVG Validation Acc 79.06 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.469 AVG Validation Loss:0.508 AVG Training Acc 80.80 % AVG Validation Acc 79.15 %\n",
      "Epoch:140/200 AVG Training Loss:0.468 AVG Validation Loss:0.508 AVG Training Acc 80.78 % AVG Validation Acc 79.06 %\n",
      "Epoch:150/200 AVG Training Loss:0.468 AVG Validation Loss:0.508 AVG Training Acc 80.85 % AVG Validation Acc 79.06 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.468 AVG Validation Loss:0.509 AVG Training Acc 80.77 % AVG Validation Acc 79.06 %\n",
      "Epoch:170/200 AVG Training Loss:0.469 AVG Validation Loss:0.508 AVG Training Acc 80.77 % AVG Validation Acc 79.06 %\n",
      "Epoch:180/200 AVG Training Loss:0.467 AVG Validation Loss:0.508 AVG Training Acc 80.79 % AVG Validation Acc 79.06 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.469 AVG Validation Loss:0.507 AVG Training Acc 80.87 % AVG Validation Acc 79.15 %\n",
      "Epoch:200/200 AVG Training Loss:0.469 AVG Validation Loss:0.508 AVG Training Acc 80.93 % AVG Validation Acc 79.15 %\n",
      "Split 30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a6118603a6f4dea849bd587676c4a0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.24 % AVG Validation Acc 80.14 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.481 AVG Validation Loss:0.502 AVG Training Acc 80.52 % AVG Validation Acc 79.60 %\n",
      "Epoch:50/200 AVG Training Loss:0.475 AVG Validation Loss:0.506 AVG Training Acc 80.74 % AVG Validation Acc 79.51 %\n",
      "Epoch:60/200 AVG Training Loss:0.471 AVG Validation Loss:0.511 AVG Training Acc 80.75 % AVG Validation Acc 79.24 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.468 AVG Validation Loss:0.518 AVG Training Acc 80.79 % AVG Validation Acc 78.97 %\n",
      "Epoch:80/200 AVG Training Loss:0.468 AVG Validation Loss:0.518 AVG Training Acc 80.93 % AVG Validation Acc 78.88 %\n",
      "Epoch:90/200 AVG Training Loss:0.467 AVG Validation Loss:0.518 AVG Training Acc 80.85 % AVG Validation Acc 78.97 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.467 AVG Validation Loss:0.518 AVG Training Acc 80.90 % AVG Validation Acc 79.06 %\n",
      "Epoch:110/200 AVG Training Loss:0.466 AVG Validation Loss:0.517 AVG Training Acc 80.92 % AVG Validation Acc 79.15 %\n",
      "Epoch:120/200 AVG Training Loss:0.466 AVG Validation Loss:0.519 AVG Training Acc 80.97 % AVG Validation Acc 78.88 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.467 AVG Validation Loss:0.519 AVG Training Acc 80.93 % AVG Validation Acc 78.88 %\n",
      "Epoch:140/200 AVG Training Loss:0.466 AVG Validation Loss:0.517 AVG Training Acc 80.92 % AVG Validation Acc 79.06 %\n",
      "Epoch:150/200 AVG Training Loss:0.467 AVG Validation Loss:0.517 AVG Training Acc 80.87 % AVG Validation Acc 78.97 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.466 AVG Validation Loss:0.518 AVG Training Acc 80.92 % AVG Validation Acc 78.97 %\n",
      "Epoch:170/200 AVG Training Loss:0.466 AVG Validation Loss:0.520 AVG Training Acc 80.99 % AVG Validation Acc 78.97 %\n",
      "Epoch:180/200 AVG Training Loss:0.466 AVG Validation Loss:0.517 AVG Training Acc 80.91 % AVG Validation Acc 78.97 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.467 AVG Validation Loss:0.519 AVG Training Acc 80.98 % AVG Validation Acc 79.06 %\n",
      "Epoch:200/200 AVG Training Loss:0.465 AVG Validation Loss:0.520 AVG Training Acc 80.96 % AVG Validation Acc 78.97 %\n",
      "Split 31\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8246754852c84effbb5124282dc18a2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.497 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.18 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.498 AVG Training Acc 80.32 % AVG Validation Acc 79.89 %\n",
      "Epoch:50/200 AVG Training Loss:0.475 AVG Validation Loss:0.499 AVG Training Acc 80.57 % AVG Validation Acc 79.89 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.469 AVG Validation Loss:0.502 AVG Training Acc 80.82 % AVG Validation Acc 79.80 %\n",
      "Epoch:70/200 AVG Training Loss:0.468 AVG Validation Loss:0.505 AVG Training Acc 80.89 % AVG Validation Acc 79.80 %\n",
      "Epoch:80/200 AVG Training Loss:0.469 AVG Validation Loss:0.504 AVG Training Acc 80.91 % AVG Validation Acc 79.98 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.466 AVG Validation Loss:0.507 AVG Training Acc 80.98 % AVG Validation Acc 79.62 %\n",
      "Epoch:100/200 AVG Training Loss:0.466 AVG Validation Loss:0.504 AVG Training Acc 80.83 % AVG Validation Acc 79.89 %\n",
      "Epoch:110/200 AVG Training Loss:0.466 AVG Validation Loss:0.508 AVG Training Acc 80.90 % AVG Validation Acc 79.62 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.466 AVG Validation Loss:0.508 AVG Training Acc 80.97 % AVG Validation Acc 79.71 %\n",
      "Epoch:130/200 AVG Training Loss:0.466 AVG Validation Loss:0.503 AVG Training Acc 80.88 % AVG Validation Acc 79.71 %\n",
      "Epoch:140/200 AVG Training Loss:0.467 AVG Validation Loss:0.504 AVG Training Acc 80.91 % AVG Validation Acc 79.89 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.466 AVG Validation Loss:0.509 AVG Training Acc 81.09 % AVG Validation Acc 79.71 %\n",
      "Epoch:160/200 AVG Training Loss:0.467 AVG Validation Loss:0.504 AVG Training Acc 81.00 % AVG Validation Acc 79.80 %\n",
      "Epoch:170/200 AVG Training Loss:0.467 AVG Validation Loss:0.506 AVG Training Acc 80.90 % AVG Validation Acc 79.80 %\n",
      "Epoch:180/200 AVG Training Loss:0.466 AVG Validation Loss:0.507 AVG Training Acc 80.98 % AVG Validation Acc 79.80 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.467 AVG Validation Loss:0.504 AVG Training Acc 81.01 % AVG Validation Acc 79.80 %\n",
      "Epoch:200/200 AVG Training Loss:0.466 AVG Validation Loss:0.508 AVG Training Acc 80.96 % AVG Validation Acc 79.80 %\n",
      "Split 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "910fc15630264976a2741b9b2977eb5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.500 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.483 AVG Validation Loss:0.493 AVG Training Acc 80.37 % AVG Validation Acc 80.34 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.470 AVG Validation Loss:0.504 AVG Training Acc 80.48 % AVG Validation Acc 79.80 %\n",
      "Epoch:60/200 AVG Training Loss:0.465 AVG Validation Loss:0.513 AVG Training Acc 80.75 % AVG Validation Acc 79.62 %\n",
      "Epoch:70/200 AVG Training Loss:0.458 AVG Validation Loss:0.522 AVG Training Acc 80.92 % AVG Validation Acc 79.44 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.455 AVG Validation Loss:0.529 AVG Training Acc 81.04 % AVG Validation Acc 78.99 %\n",
      "Epoch:90/200 AVG Training Loss:0.452 AVG Validation Loss:0.528 AVG Training Acc 81.08 % AVG Validation Acc 78.99 %\n",
      "Epoch:100/200 AVG Training Loss:0.452 AVG Validation Loss:0.529 AVG Training Acc 81.06 % AVG Validation Acc 78.90 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.452 AVG Validation Loss:0.531 AVG Training Acc 81.12 % AVG Validation Acc 78.72 %\n",
      "Epoch:120/200 AVG Training Loss:0.451 AVG Validation Loss:0.531 AVG Training Acc 81.08 % AVG Validation Acc 78.90 %\n",
      "Epoch:130/200 AVG Training Loss:0.451 AVG Validation Loss:0.531 AVG Training Acc 81.05 % AVG Validation Acc 79.17 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.453 AVG Validation Loss:0.535 AVG Training Acc 81.03 % AVG Validation Acc 78.81 %\n",
      "Epoch:150/200 AVG Training Loss:0.451 AVG Validation Loss:0.531 AVG Training Acc 81.19 % AVG Validation Acc 78.72 %\n",
      "Epoch:160/200 AVG Training Loss:0.454 AVG Validation Loss:0.533 AVG Training Acc 80.85 % AVG Validation Acc 78.99 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.451 AVG Validation Loss:0.532 AVG Training Acc 81.09 % AVG Validation Acc 78.90 %\n",
      "Epoch:180/200 AVG Training Loss:0.450 AVG Validation Loss:0.530 AVG Training Acc 81.24 % AVG Validation Acc 79.08 %\n",
      "Epoch:190/200 AVG Training Loss:0.451 AVG Validation Loss:0.528 AVG Training Acc 81.15 % AVG Validation Acc 78.90 %\n",
      "Epoch   198: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.452 AVG Validation Loss:0.529 AVG Training Acc 81.14 % AVG Validation Acc 79.17 %\n",
      "Split 33\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeacd8246c2840a69141edf1febf63a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.27 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.483 AVG Validation Loss:0.495 AVG Training Acc 80.52 % AVG Validation Acc 79.89 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.473 AVG Validation Loss:0.503 AVG Training Acc 80.78 % AVG Validation Acc 79.53 %\n",
      "Epoch:60/200 AVG Training Loss:0.467 AVG Validation Loss:0.515 AVG Training Acc 81.04 % AVG Validation Acc 79.17 %\n",
      "Epoch:70/200 AVG Training Loss:0.461 AVG Validation Loss:0.530 AVG Training Acc 81.43 % AVG Validation Acc 78.99 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.456 AVG Validation Loss:0.539 AVG Training Acc 81.47 % AVG Validation Acc 78.63 %\n",
      "Epoch:90/200 AVG Training Loss:0.453 AVG Validation Loss:0.537 AVG Training Acc 81.81 % AVG Validation Acc 78.54 %\n",
      "Epoch:100/200 AVG Training Loss:0.452 AVG Validation Loss:0.541 AVG Training Acc 81.67 % AVG Validation Acc 78.45 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.453 AVG Validation Loss:0.548 AVG Training Acc 81.62 % AVG Validation Acc 78.81 %\n",
      "Epoch:120/200 AVG Training Loss:0.452 AVG Validation Loss:0.543 AVG Training Acc 81.65 % AVG Validation Acc 78.63 %\n",
      "Epoch:130/200 AVG Training Loss:0.451 AVG Validation Loss:0.541 AVG Training Acc 81.82 % AVG Validation Acc 78.54 %\n",
      "Epoch:140/200 AVG Training Loss:0.451 AVG Validation Loss:0.542 AVG Training Acc 81.70 % AVG Validation Acc 78.45 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.452 AVG Validation Loss:0.541 AVG Training Acc 81.76 % AVG Validation Acc 78.63 %\n",
      "Epoch:160/200 AVG Training Loss:0.453 AVG Validation Loss:0.544 AVG Training Acc 81.65 % AVG Validation Acc 78.45 %\n",
      "Epoch:170/200 AVG Training Loss:0.451 AVG Validation Loss:0.544 AVG Training Acc 81.85 % AVG Validation Acc 78.54 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.452 AVG Validation Loss:0.552 AVG Training Acc 81.81 % AVG Validation Acc 78.54 %\n",
      "Epoch:190/200 AVG Training Loss:0.450 AVG Validation Loss:0.542 AVG Training Acc 81.74 % AVG Validation Acc 78.63 %\n",
      "Epoch:200/200 AVG Training Loss:0.453 AVG Validation Loss:0.536 AVG Training Acc 81.62 % AVG Validation Acc 78.81 %\n",
      "Split 34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6e8ecd507534e47a202291a166634a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.492 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.490 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.487 AVG Training Acc 80.11 % AVG Validation Acc 79.98 %\n",
      "Epoch:40/200 AVG Training Loss:0.483 AVG Validation Loss:0.489 AVG Training Acc 80.43 % AVG Validation Acc 80.25 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.473 AVG Validation Loss:0.486 AVG Training Acc 80.47 % AVG Validation Acc 80.34 %\n",
      "Epoch:60/200 AVG Training Loss:0.469 AVG Validation Loss:0.493 AVG Training Acc 80.66 % AVG Validation Acc 80.43 %\n",
      "Epoch:70/200 AVG Training Loss:0.464 AVG Validation Loss:0.497 AVG Training Acc 81.03 % AVG Validation Acc 79.89 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.458 AVG Validation Loss:0.499 AVG Training Acc 81.18 % AVG Validation Acc 80.16 %\n",
      "Epoch:90/200 AVG Training Loss:0.456 AVG Validation Loss:0.501 AVG Training Acc 81.17 % AVG Validation Acc 80.07 %\n",
      "Epoch:100/200 AVG Training Loss:0.455 AVG Validation Loss:0.500 AVG Training Acc 81.28 % AVG Validation Acc 79.98 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.455 AVG Validation Loss:0.499 AVG Training Acc 81.34 % AVG Validation Acc 80.34 %\n",
      "Epoch:120/200 AVG Training Loss:0.457 AVG Validation Loss:0.500 AVG Training Acc 81.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:130/200 AVG Training Loss:0.456 AVG Validation Loss:0.503 AVG Training Acc 81.28 % AVG Validation Acc 79.98 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.456 AVG Validation Loss:0.501 AVG Training Acc 81.12 % AVG Validation Acc 80.07 %\n",
      "Epoch:150/200 AVG Training Loss:0.455 AVG Validation Loss:0.506 AVG Training Acc 81.24 % AVG Validation Acc 80.07 %\n",
      "Epoch:160/200 AVG Training Loss:0.453 AVG Validation Loss:0.504 AVG Training Acc 81.39 % AVG Validation Acc 80.07 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.455 AVG Validation Loss:0.506 AVG Training Acc 81.30 % AVG Validation Acc 79.89 %\n",
      "Epoch:180/200 AVG Training Loss:0.457 AVG Validation Loss:0.502 AVG Training Acc 81.27 % AVG Validation Acc 80.16 %\n",
      "Epoch:190/200 AVG Training Loss:0.456 AVG Validation Loss:0.502 AVG Training Acc 81.24 % AVG Validation Acc 80.25 %\n",
      "Epoch   198: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.456 AVG Validation Loss:0.504 AVG Training Acc 81.16 % AVG Validation Acc 79.98 %\n",
      "Split 35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c8b1d01ec643e7ada91b8a6c94e236",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.500 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.490 AVG Validation Loss:0.496 AVG Training Acc 80.16 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.16 % AVG Validation Acc 79.98 %\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.20 % AVG Validation Acc 79.98 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.482 AVG Validation Loss:0.499 AVG Training Acc 80.21 % AVG Validation Acc 79.89 %\n",
      "Epoch:60/200 AVG Training Loss:0.482 AVG Validation Loss:0.499 AVG Training Acc 80.20 % AVG Validation Acc 79.89 %\n",
      "Epoch:70/200 AVG Training Loss:0.482 AVG Validation Loss:0.498 AVG Training Acc 80.24 % AVG Validation Acc 79.89 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.482 AVG Validation Loss:0.498 AVG Training Acc 80.22 % AVG Validation Acc 79.89 %\n",
      "Epoch:90/200 AVG Training Loss:0.482 AVG Validation Loss:0.499 AVG Training Acc 80.26 % AVG Validation Acc 79.89 %\n",
      "Epoch:100/200 AVG Training Loss:0.482 AVG Validation Loss:0.499 AVG Training Acc 80.21 % AVG Validation Acc 79.89 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.482 AVG Validation Loss:0.498 AVG Training Acc 80.19 % AVG Validation Acc 79.89 %\n",
      "Epoch:120/200 AVG Training Loss:0.483 AVG Validation Loss:0.499 AVG Training Acc 80.20 % AVG Validation Acc 79.89 %\n",
      "Epoch:130/200 AVG Training Loss:0.482 AVG Validation Loss:0.499 AVG Training Acc 80.22 % AVG Validation Acc 79.89 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.481 AVG Validation Loss:0.498 AVG Training Acc 80.18 % AVG Validation Acc 79.89 %\n",
      "Epoch:150/200 AVG Training Loss:0.483 AVG Validation Loss:0.499 AVG Training Acc 80.17 % AVG Validation Acc 79.89 %\n",
      "Epoch:160/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.21 % AVG Validation Acc 79.89 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.482 AVG Validation Loss:0.498 AVG Training Acc 80.17 % AVG Validation Acc 79.89 %\n",
      "Epoch:180/200 AVG Training Loss:0.482 AVG Validation Loss:0.499 AVG Training Acc 80.21 % AVG Validation Acc 79.89 %\n",
      "Epoch:190/200 AVG Training Loss:0.482 AVG Validation Loss:0.499 AVG Training Acc 80.27 % AVG Validation Acc 79.89 %\n",
      "Epoch:200/200 AVG Training Loss:0.482 AVG Validation Loss:0.500 AVG Training Acc 80.22 % AVG Validation Acc 79.89 %\n",
      "Split 36\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "236db6e6b4284d01b802064ff20941bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.490 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.499 AVG Training Acc 80.14 % AVG Validation Acc 80.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.500 AVG Training Acc 80.29 % AVG Validation Acc 80.23 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.482 AVG Validation Loss:0.505 AVG Training Acc 80.39 % AVG Validation Acc 79.78 %\n",
      "Epoch:60/200 AVG Training Loss:0.482 AVG Validation Loss:0.505 AVG Training Acc 80.31 % AVG Validation Acc 79.87 %\n",
      "Epoch:70/200 AVG Training Loss:0.482 AVG Validation Loss:0.507 AVG Training Acc 80.40 % AVG Validation Acc 79.69 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.482 AVG Validation Loss:0.510 AVG Training Acc 80.44 % AVG Validation Acc 79.69 %\n",
      "Epoch:90/200 AVG Training Loss:0.481 AVG Validation Loss:0.511 AVG Training Acc 80.42 % AVG Validation Acc 79.69 %\n",
      "Epoch:100/200 AVG Training Loss:0.481 AVG Validation Loss:0.510 AVG Training Acc 80.45 % AVG Validation Acc 79.69 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.481 AVG Validation Loss:0.512 AVG Training Acc 80.35 % AVG Validation Acc 79.60 %\n",
      "Epoch:120/200 AVG Training Loss:0.481 AVG Validation Loss:0.511 AVG Training Acc 80.41 % AVG Validation Acc 79.60 %\n",
      "Epoch:130/200 AVG Training Loss:0.482 AVG Validation Loss:0.511 AVG Training Acc 80.38 % AVG Validation Acc 79.69 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.480 AVG Validation Loss:0.512 AVG Training Acc 80.54 % AVG Validation Acc 79.69 %\n",
      "Epoch:150/200 AVG Training Loss:0.481 AVG Validation Loss:0.511 AVG Training Acc 80.35 % AVG Validation Acc 79.69 %\n",
      "Epoch:160/200 AVG Training Loss:0.481 AVG Validation Loss:0.511 AVG Training Acc 80.42 % AVG Validation Acc 79.69 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.480 AVG Validation Loss:0.511 AVG Training Acc 80.53 % AVG Validation Acc 79.69 %\n",
      "Epoch:180/200 AVG Training Loss:0.481 AVG Validation Loss:0.511 AVG Training Acc 80.39 % AVG Validation Acc 79.69 %\n",
      "Epoch:190/200 AVG Training Loss:0.481 AVG Validation Loss:0.510 AVG Training Acc 80.47 % AVG Validation Acc 79.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.481 AVG Validation Loss:0.510 AVG Training Acc 80.41 % AVG Validation Acc 79.69 %\n",
      "Split 37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "487fea2358674a5e891413a8bd3affd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.07 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.11 % AVG Validation Acc 80.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.494 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.470 AVG Validation Loss:0.505 AVG Training Acc 80.44 % AVG Validation Acc 79.60 %\n",
      "Epoch:60/200 AVG Training Loss:0.456 AVG Validation Loss:0.516 AVG Training Acc 81.04 % AVG Validation Acc 78.97 %\n",
      "Epoch:70/200 AVG Training Loss:0.449 AVG Validation Loss:0.522 AVG Training Acc 81.29 % AVG Validation Acc 78.52 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.443 AVG Validation Loss:0.528 AVG Training Acc 81.56 % AVG Validation Acc 78.70 %\n",
      "Epoch:90/200 AVG Training Loss:0.442 AVG Validation Loss:0.526 AVG Training Acc 81.49 % AVG Validation Acc 78.70 %\n",
      "Epoch:100/200 AVG Training Loss:0.441 AVG Validation Loss:0.526 AVG Training Acc 81.66 % AVG Validation Acc 78.25 %\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.439 AVG Validation Loss:0.527 AVG Training Acc 81.85 % AVG Validation Acc 78.61 %\n",
      "Epoch:120/200 AVG Training Loss:0.442 AVG Validation Loss:0.529 AVG Training Acc 81.66 % AVG Validation Acc 78.25 %\n",
      "Epoch:130/200 AVG Training Loss:0.439 AVG Validation Loss:0.527 AVG Training Acc 81.80 % AVG Validation Acc 78.34 %\n",
      "Epoch   134: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.439 AVG Validation Loss:0.530 AVG Training Acc 81.93 % AVG Validation Acc 78.61 %\n",
      "Epoch:150/200 AVG Training Loss:0.438 AVG Validation Loss:0.531 AVG Training Acc 81.74 % AVG Validation Acc 78.97 %\n",
      "Epoch:160/200 AVG Training Loss:0.439 AVG Validation Loss:0.526 AVG Training Acc 81.67 % AVG Validation Acc 78.25 %\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.438 AVG Validation Loss:0.532 AVG Training Acc 81.81 % AVG Validation Acc 78.52 %\n",
      "Epoch:180/200 AVG Training Loss:0.440 AVG Validation Loss:0.528 AVG Training Acc 81.62 % AVG Validation Acc 78.52 %\n",
      "Epoch:190/200 AVG Training Loss:0.442 AVG Validation Loss:0.525 AVG Training Acc 81.64 % AVG Validation Acc 78.34 %\n",
      "Epoch   196: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.437 AVG Validation Loss:0.527 AVG Training Acc 81.83 % AVG Validation Acc 78.43 %\n",
      "Split 38\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8160e5645be346a9a33bd003e6671449",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.24 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.480 AVG Validation Loss:0.502 AVG Training Acc 80.33 % AVG Validation Acc 80.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.473 AVG Validation Loss:0.511 AVG Training Acc 80.47 % AVG Validation Acc 79.69 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.466 AVG Validation Loss:0.516 AVG Training Acc 80.60 % AVG Validation Acc 79.78 %\n",
      "Epoch:80/200 AVG Training Loss:0.466 AVG Validation Loss:0.513 AVG Training Acc 80.60 % AVG Validation Acc 79.78 %\n",
      "Epoch:90/200 AVG Training Loss:0.464 AVG Validation Loss:0.516 AVG Training Acc 80.61 % AVG Validation Acc 79.78 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.463 AVG Validation Loss:0.518 AVG Training Acc 80.69 % AVG Validation Acc 79.69 %\n",
      "Epoch:110/200 AVG Training Loss:0.463 AVG Validation Loss:0.517 AVG Training Acc 80.71 % AVG Validation Acc 79.69 %\n",
      "Epoch:120/200 AVG Training Loss:0.462 AVG Validation Loss:0.519 AVG Training Acc 80.68 % AVG Validation Acc 79.69 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.462 AVG Validation Loss:0.518 AVG Training Acc 80.76 % AVG Validation Acc 79.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.463 AVG Validation Loss:0.518 AVG Training Acc 80.67 % AVG Validation Acc 79.69 %\n",
      "Epoch:150/200 AVG Training Loss:0.462 AVG Validation Loss:0.519 AVG Training Acc 80.71 % AVG Validation Acc 79.78 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.463 AVG Validation Loss:0.518 AVG Training Acc 80.73 % AVG Validation Acc 79.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.462 AVG Validation Loss:0.518 AVG Training Acc 80.77 % AVG Validation Acc 79.78 %\n",
      "Epoch:180/200 AVG Training Loss:0.463 AVG Validation Loss:0.516 AVG Training Acc 80.67 % AVG Validation Acc 79.78 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.463 AVG Validation Loss:0.518 AVG Training Acc 80.70 % AVG Validation Acc 79.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.461 AVG Validation Loss:0.517 AVG Training Acc 80.76 % AVG Validation Acc 79.78 %\n",
      "Split 39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03d2de6da23e4b40b223f12ea1952092",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.29 % AVG Validation Acc 80.32 %\n",
      "Epoch:40/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.475 AVG Validation Loss:0.501 AVG Training Acc 80.72 % AVG Validation Acc 80.23 %\n",
      "Epoch:60/200 AVG Training Loss:0.468 AVG Validation Loss:0.510 AVG Training Acc 80.99 % AVG Validation Acc 80.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.462 AVG Validation Loss:0.522 AVG Training Acc 81.21 % AVG Validation Acc 79.78 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.459 AVG Validation Loss:0.522 AVG Training Acc 81.37 % AVG Validation Acc 79.69 %\n",
      "Epoch:90/200 AVG Training Loss:0.458 AVG Validation Loss:0.520 AVG Training Acc 81.43 % AVG Validation Acc 79.51 %\n",
      "Epoch:100/200 AVG Training Loss:0.456 AVG Validation Loss:0.526 AVG Training Acc 81.29 % AVG Validation Acc 79.60 %\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.456 AVG Validation Loss:0.522 AVG Training Acc 81.43 % AVG Validation Acc 79.60 %\n",
      "Epoch:120/200 AVG Training Loss:0.455 AVG Validation Loss:0.522 AVG Training Acc 81.40 % AVG Validation Acc 79.69 %\n",
      "Epoch:130/200 AVG Training Loss:0.456 AVG Validation Loss:0.524 AVG Training Acc 81.35 % AVG Validation Acc 79.69 %\n",
      "Epoch   134: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.457 AVG Validation Loss:0.524 AVG Training Acc 81.40 % AVG Validation Acc 79.69 %\n",
      "Epoch:150/200 AVG Training Loss:0.456 AVG Validation Loss:0.521 AVG Training Acc 81.46 % AVG Validation Acc 79.60 %\n",
      "Epoch:160/200 AVG Training Loss:0.457 AVG Validation Loss:0.521 AVG Training Acc 81.50 % AVG Validation Acc 79.69 %\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.457 AVG Validation Loss:0.520 AVG Training Acc 81.44 % AVG Validation Acc 79.69 %\n",
      "Epoch:180/200 AVG Training Loss:0.456 AVG Validation Loss:0.523 AVG Training Acc 81.52 % AVG Validation Acc 79.51 %\n",
      "Epoch:190/200 AVG Training Loss:0.457 AVG Validation Loss:0.522 AVG Training Acc 81.44 % AVG Validation Acc 79.69 %\n",
      "Epoch   196: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.456 AVG Validation Loss:0.523 AVG Training Acc 81.39 % AVG Validation Acc 79.60 %\n",
      "Split 40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ffb7def55fe4231a0b3f7b66d8fa708",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.16 % AVG Validation Acc 80.23 %\n",
      "Epoch:30/200 AVG Training Loss:0.486 AVG Validation Loss:0.490 AVG Training Acc 80.34 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.483 AVG Validation Loss:0.490 AVG Training Acc 80.35 % AVG Validation Acc 80.23 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.496 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.27 % AVG Validation Acc 80.05 %\n",
      "Epoch:90/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.33 % AVG Validation Acc 80.05 %\n",
      "Epoch:100/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.33 % AVG Validation Acc 80.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.491 AVG Validation Loss:0.496 AVG Training Acc 80.35 % AVG Validation Acc 80.05 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.491 AVG Validation Loss:0.496 AVG Training Acc 80.39 % AVG Validation Acc 79.96 %\n",
      "Epoch:130/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.29 % AVG Validation Acc 79.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.35 % AVG Validation Acc 79.96 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.491 AVG Validation Loss:0.496 AVG Training Acc 80.35 % AVG Validation Acc 79.96 %\n",
      "Epoch:160/200 AVG Training Loss:0.490 AVG Validation Loss:0.496 AVG Training Acc 80.39 % AVG Validation Acc 79.96 %\n",
      "Epoch:170/200 AVG Training Loss:0.491 AVG Validation Loss:0.496 AVG Training Acc 80.32 % AVG Validation Acc 79.96 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.34 % AVG Validation Acc 79.96 %\n",
      "Epoch:190/200 AVG Training Loss:0.491 AVG Validation Loss:0.496 AVG Training Acc 80.35 % AVG Validation Acc 79.96 %\n",
      "Epoch:200/200 AVG Training Loss:0.490 AVG Validation Loss:0.496 AVG Training Acc 80.32 % AVG Validation Acc 79.96 %\n",
      "Split 41\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d4f53d45af04fedb27995c44b74ea0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.10 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.10 % AVG Validation Acc 80.16 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.25 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.485 AVG Validation Loss:0.502 AVG Training Acc 80.28 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.483 AVG Validation Loss:0.504 AVG Training Acc 80.36 % AVG Validation Acc 79.89 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.482 AVG Validation Loss:0.506 AVG Training Acc 80.37 % AVG Validation Acc 80.07 %\n",
      "Epoch:70/200 AVG Training Loss:0.480 AVG Validation Loss:0.509 AVG Training Acc 80.47 % AVG Validation Acc 80.07 %\n",
      "Epoch:80/200 AVG Training Loss:0.480 AVG Validation Loss:0.510 AVG Training Acc 80.45 % AVG Validation Acc 79.89 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.480 AVG Validation Loss:0.509 AVG Training Acc 80.47 % AVG Validation Acc 79.98 %\n",
      "Epoch:100/200 AVG Training Loss:0.480 AVG Validation Loss:0.511 AVG Training Acc 80.45 % AVG Validation Acc 79.89 %\n",
      "Epoch:110/200 AVG Training Loss:0.479 AVG Validation Loss:0.512 AVG Training Acc 80.50 % AVG Validation Acc 79.89 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.479 AVG Validation Loss:0.510 AVG Training Acc 80.51 % AVG Validation Acc 79.98 %\n",
      "Epoch:130/200 AVG Training Loss:0.480 AVG Validation Loss:0.511 AVG Training Acc 80.46 % AVG Validation Acc 79.89 %\n",
      "Epoch:140/200 AVG Training Loss:0.480 AVG Validation Loss:0.511 AVG Training Acc 80.43 % AVG Validation Acc 79.98 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.479 AVG Validation Loss:0.510 AVG Training Acc 80.51 % AVG Validation Acc 79.89 %\n",
      "Epoch:160/200 AVG Training Loss:0.480 AVG Validation Loss:0.511 AVG Training Acc 80.42 % AVG Validation Acc 79.89 %\n",
      "Epoch:170/200 AVG Training Loss:0.479 AVG Validation Loss:0.510 AVG Training Acc 80.50 % AVG Validation Acc 79.89 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.479 AVG Validation Loss:0.511 AVG Training Acc 80.52 % AVG Validation Acc 79.89 %\n",
      "Epoch:190/200 AVG Training Loss:0.479 AVG Validation Loss:0.511 AVG Training Acc 80.44 % AVG Validation Acc 79.89 %\n",
      "Epoch:200/200 AVG Training Loss:0.480 AVG Validation Loss:0.511 AVG Training Acc 80.48 % AVG Validation Acc 79.89 %\n",
      "Split 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a7e8df2f3c443fdb0a9044eac38f6af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.499 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.18 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.479 AVG Validation Loss:0.502 AVG Training Acc 80.42 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.480 AVG Validation Loss:0.507 AVG Training Acc 80.46 % AVG Validation Acc 79.71 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.463 AVG Validation Loss:0.502 AVG Training Acc 80.93 % AVG Validation Acc 79.62 %\n",
      "Epoch:70/200 AVG Training Loss:0.451 AVG Validation Loss:0.513 AVG Training Acc 81.54 % AVG Validation Acc 78.81 %\n",
      "Epoch:80/200 AVG Training Loss:0.446 AVG Validation Loss:0.521 AVG Training Acc 81.65 % AVG Validation Acc 78.63 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.440 AVG Validation Loss:0.524 AVG Training Acc 82.28 % AVG Validation Acc 78.09 %\n",
      "Epoch:100/200 AVG Training Loss:0.439 AVG Validation Loss:0.526 AVG Training Acc 82.26 % AVG Validation Acc 78.09 %\n",
      "Epoch:110/200 AVG Training Loss:0.440 AVG Validation Loss:0.534 AVG Training Acc 82.21 % AVG Validation Acc 77.82 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.440 AVG Validation Loss:0.528 AVG Training Acc 82.22 % AVG Validation Acc 78.36 %\n",
      "Epoch:130/200 AVG Training Loss:0.438 AVG Validation Loss:0.532 AVG Training Acc 82.37 % AVG Validation Acc 78.45 %\n",
      "Epoch:140/200 AVG Training Loss:0.437 AVG Validation Loss:0.529 AVG Training Acc 82.35 % AVG Validation Acc 78.36 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.435 AVG Validation Loss:0.530 AVG Training Acc 82.44 % AVG Validation Acc 78.36 %\n",
      "Epoch:160/200 AVG Training Loss:0.438 AVG Validation Loss:0.529 AVG Training Acc 82.33 % AVG Validation Acc 78.45 %\n",
      "Epoch:170/200 AVG Training Loss:0.438 AVG Validation Loss:0.533 AVG Training Acc 82.43 % AVG Validation Acc 78.36 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.436 AVG Validation Loss:0.531 AVG Training Acc 82.36 % AVG Validation Acc 78.27 %\n",
      "Epoch:190/200 AVG Training Loss:0.437 AVG Validation Loss:0.529 AVG Training Acc 82.36 % AVG Validation Acc 78.09 %\n",
      "Epoch:200/200 AVG Training Loss:0.439 AVG Validation Loss:0.530 AVG Training Acc 82.27 % AVG Validation Acc 78.18 %\n",
      "Split 43\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ed64a21249453b96b7f6b3a862b95b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.490 AVG Validation Loss:0.496 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.481 AVG Validation Loss:0.498 AVG Training Acc 80.38 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.477 AVG Validation Loss:0.503 AVG Training Acc 80.44 % AVG Validation Acc 79.80 %\n",
      "Epoch:50/200 AVG Training Loss:0.475 AVG Validation Loss:0.511 AVG Training Acc 80.55 % AVG Validation Acc 79.98 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.472 AVG Validation Loss:0.516 AVG Training Acc 80.66 % AVG Validation Acc 79.89 %\n",
      "Epoch:70/200 AVG Training Loss:0.470 AVG Validation Loss:0.515 AVG Training Acc 80.79 % AVG Validation Acc 79.89 %\n",
      "Epoch:80/200 AVG Training Loss:0.471 AVG Validation Loss:0.517 AVG Training Acc 80.77 % AVG Validation Acc 79.80 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.470 AVG Validation Loss:0.519 AVG Training Acc 80.74 % AVG Validation Acc 79.80 %\n",
      "Epoch:100/200 AVG Training Loss:0.470 AVG Validation Loss:0.518 AVG Training Acc 80.77 % AVG Validation Acc 79.80 %\n",
      "Epoch:110/200 AVG Training Loss:0.469 AVG Validation Loss:0.519 AVG Training Acc 80.73 % AVG Validation Acc 79.80 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.471 AVG Validation Loss:0.520 AVG Training Acc 80.76 % AVG Validation Acc 79.80 %\n",
      "Epoch:130/200 AVG Training Loss:0.470 AVG Validation Loss:0.518 AVG Training Acc 80.68 % AVG Validation Acc 79.71 %\n",
      "Epoch:140/200 AVG Training Loss:0.470 AVG Validation Loss:0.519 AVG Training Acc 80.77 % AVG Validation Acc 79.71 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.470 AVG Validation Loss:0.519 AVG Training Acc 80.79 % AVG Validation Acc 79.80 %\n",
      "Epoch:160/200 AVG Training Loss:0.471 AVG Validation Loss:0.519 AVG Training Acc 80.73 % AVG Validation Acc 79.80 %\n",
      "Epoch:170/200 AVG Training Loss:0.470 AVG Validation Loss:0.520 AVG Training Acc 80.76 % AVG Validation Acc 79.80 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.469 AVG Validation Loss:0.521 AVG Training Acc 80.83 % AVG Validation Acc 79.80 %\n",
      "Epoch:190/200 AVG Training Loss:0.470 AVG Validation Loss:0.518 AVG Training Acc 80.70 % AVG Validation Acc 79.80 %\n",
      "Epoch:200/200 AVG Training Loss:0.469 AVG Validation Loss:0.519 AVG Training Acc 80.80 % AVG Validation Acc 79.80 %\n",
      "Split 44\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf646dc8f29a4b98bf2ecd08f2fc21ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.482 AVG Validation Loss:0.501 AVG Training Acc 80.20 % AVG Validation Acc 80.25 %\n",
      "Epoch:50/200 AVG Training Loss:0.476 AVG Validation Loss:0.506 AVG Training Acc 80.54 % AVG Validation Acc 80.25 %\n",
      "Epoch:60/200 AVG Training Loss:0.470 AVG Validation Loss:0.513 AVG Training Acc 80.69 % AVG Validation Acc 80.25 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.466 AVG Validation Loss:0.513 AVG Training Acc 80.78 % AVG Validation Acc 80.16 %\n",
      "Epoch:80/200 AVG Training Loss:0.467 AVG Validation Loss:0.517 AVG Training Acc 80.77 % AVG Validation Acc 80.16 %\n",
      "Epoch:90/200 AVG Training Loss:0.465 AVG Validation Loss:0.515 AVG Training Acc 80.85 % AVG Validation Acc 80.16 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.466 AVG Validation Loss:0.518 AVG Training Acc 80.80 % AVG Validation Acc 80.07 %\n",
      "Epoch:110/200 AVG Training Loss:0.465 AVG Validation Loss:0.519 AVG Training Acc 80.80 % AVG Validation Acc 80.16 %\n",
      "Epoch:120/200 AVG Training Loss:0.465 AVG Validation Loss:0.515 AVG Training Acc 80.86 % AVG Validation Acc 80.07 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.464 AVG Validation Loss:0.516 AVG Training Acc 80.88 % AVG Validation Acc 80.16 %\n",
      "Epoch:140/200 AVG Training Loss:0.465 AVG Validation Loss:0.518 AVG Training Acc 80.74 % AVG Validation Acc 80.07 %\n",
      "Epoch:150/200 AVG Training Loss:0.466 AVG Validation Loss:0.516 AVG Training Acc 80.75 % AVG Validation Acc 80.07 %\n",
      "Epoch:160/200 AVG Training Loss:0.465 AVG Validation Loss:0.518 AVG Training Acc 80.84 % AVG Validation Acc 80.07 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.465 AVG Validation Loss:0.519 AVG Training Acc 80.84 % AVG Validation Acc 79.98 %\n",
      "Epoch:180/200 AVG Training Loss:0.465 AVG Validation Loss:0.517 AVG Training Acc 80.96 % AVG Validation Acc 80.07 %\n",
      "Epoch:190/200 AVG Training Loss:0.463 AVG Validation Loss:0.515 AVG Training Acc 80.83 % AVG Validation Acc 80.07 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.464 AVG Validation Loss:0.517 AVG Training Acc 80.90 % AVG Validation Acc 80.07 %\n",
      "Split 45\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac4a97173c5e428e8212641c7bad9a70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.480 AVG Validation Loss:0.498 AVG Training Acc 80.34 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.473 AVG Validation Loss:0.504 AVG Training Acc 80.41 % AVG Validation Acc 79.89 %\n",
      "Epoch:50/200 AVG Training Loss:0.469 AVG Validation Loss:0.505 AVG Training Acc 80.59 % AVG Validation Acc 79.98 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.459 AVG Validation Loss:0.507 AVG Training Acc 81.13 % AVG Validation Acc 79.80 %\n",
      "Epoch:70/200 AVG Training Loss:0.457 AVG Validation Loss:0.511 AVG Training Acc 81.08 % AVG Validation Acc 79.80 %\n",
      "Epoch:80/200 AVG Training Loss:0.456 AVG Validation Loss:0.510 AVG Training Acc 81.08 % AVG Validation Acc 79.80 %\n",
      "Epoch:90/200 AVG Training Loss:0.456 AVG Validation Loss:0.512 AVG Training Acc 81.21 % AVG Validation Acc 79.44 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.454 AVG Validation Loss:0.514 AVG Training Acc 81.30 % AVG Validation Acc 79.35 %\n",
      "Epoch:110/200 AVG Training Loss:0.455 AVG Validation Loss:0.512 AVG Training Acc 81.26 % AVG Validation Acc 79.53 %\n",
      "Epoch:120/200 AVG Training Loss:0.455 AVG Validation Loss:0.512 AVG Training Acc 81.26 % AVG Validation Acc 79.62 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.455 AVG Validation Loss:0.514 AVG Training Acc 81.04 % AVG Validation Acc 79.44 %\n",
      "Epoch:140/200 AVG Training Loss:0.454 AVG Validation Loss:0.515 AVG Training Acc 81.29 % AVG Validation Acc 79.35 %\n",
      "Epoch:150/200 AVG Training Loss:0.455 AVG Validation Loss:0.511 AVG Training Acc 81.07 % AVG Validation Acc 79.71 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.455 AVG Validation Loss:0.512 AVG Training Acc 81.34 % AVG Validation Acc 79.35 %\n",
      "Epoch:170/200 AVG Training Loss:0.455 AVG Validation Loss:0.513 AVG Training Acc 81.22 % AVG Validation Acc 79.44 %\n",
      "Epoch:180/200 AVG Training Loss:0.455 AVG Validation Loss:0.514 AVG Training Acc 81.18 % AVG Validation Acc 79.44 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.455 AVG Validation Loss:0.513 AVG Training Acc 81.08 % AVG Validation Acc 79.44 %\n",
      "Epoch:200/200 AVG Training Loss:0.454 AVG Validation Loss:0.510 AVG Training Acc 81.23 % AVG Validation Acc 79.44 %\n",
      "Split 46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "636954ab8e7f4b728a112bce631a20de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.492 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.490 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.482 AVG Validation Loss:0.491 AVG Training Acc 80.39 % AVG Validation Acc 80.14 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.466 AVG Validation Loss:0.499 AVG Training Acc 80.90 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.450 AVG Validation Loss:0.511 AVG Training Acc 81.22 % AVG Validation Acc 79.24 %\n",
      "Epoch:70/200 AVG Training Loss:0.442 AVG Validation Loss:0.530 AVG Training Acc 81.72 % AVG Validation Acc 79.06 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.435 AVG Validation Loss:0.540 AVG Training Acc 82.23 % AVG Validation Acc 78.61 %\n",
      "Epoch:90/200 AVG Training Loss:0.435 AVG Validation Loss:0.545 AVG Training Acc 81.95 % AVG Validation Acc 77.71 %\n",
      "Epoch:100/200 AVG Training Loss:0.433 AVG Validation Loss:0.542 AVG Training Acc 82.14 % AVG Validation Acc 78.61 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.431 AVG Validation Loss:0.536 AVG Training Acc 82.48 % AVG Validation Acc 78.79 %\n",
      "Epoch:120/200 AVG Training Loss:0.432 AVG Validation Loss:0.529 AVG Training Acc 82.44 % AVG Validation Acc 78.88 %\n",
      "Epoch:130/200 AVG Training Loss:0.430 AVG Validation Loss:0.538 AVG Training Acc 82.34 % AVG Validation Acc 78.43 %\n",
      "Epoch:140/200 AVG Training Loss:0.430 AVG Validation Loss:0.534 AVG Training Acc 82.38 % AVG Validation Acc 78.61 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.430 AVG Validation Loss:0.540 AVG Training Acc 82.36 % AVG Validation Acc 78.88 %\n",
      "Epoch:160/200 AVG Training Loss:0.430 AVG Validation Loss:0.540 AVG Training Acc 82.24 % AVG Validation Acc 78.43 %\n",
      "Epoch:170/200 AVG Training Loss:0.430 AVG Validation Loss:0.538 AVG Training Acc 82.42 % AVG Validation Acc 79.06 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.431 AVG Validation Loss:0.538 AVG Training Acc 82.34 % AVG Validation Acc 78.52 %\n",
      "Epoch:190/200 AVG Training Loss:0.432 AVG Validation Loss:0.540 AVG Training Acc 82.33 % AVG Validation Acc 78.88 %\n",
      "Epoch:200/200 AVG Training Loss:0.430 AVG Validation Loss:0.540 AVG Training Acc 82.40 % AVG Validation Acc 78.70 %\n",
      "Split 47\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e65e6b34598449e192be20ab0197119e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.501 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.18 % AVG Validation Acc 79.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.45 % AVG Validation Acc 79.78 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.472 AVG Validation Loss:0.509 AVG Training Acc 80.78 % AVG Validation Acc 79.60 %\n",
      "Epoch:60/200 AVG Training Loss:0.464 AVG Validation Loss:0.514 AVG Training Acc 81.13 % AVG Validation Acc 79.51 %\n",
      "Epoch:70/200 AVG Training Loss:0.458 AVG Validation Loss:0.525 AVG Training Acc 81.29 % AVG Validation Acc 79.15 %\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.453 AVG Validation Loss:0.527 AVG Training Acc 81.55 % AVG Validation Acc 79.33 %\n",
      "Epoch:90/200 AVG Training Loss:0.452 AVG Validation Loss:0.526 AVG Training Acc 81.47 % AVG Validation Acc 79.33 %\n",
      "Epoch:100/200 AVG Training Loss:0.453 AVG Validation Loss:0.526 AVG Training Acc 81.51 % AVG Validation Acc 79.42 %\n",
      "Epoch   104: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.453 AVG Validation Loss:0.525 AVG Training Acc 81.52 % AVG Validation Acc 79.24 %\n",
      "Epoch:120/200 AVG Training Loss:0.451 AVG Validation Loss:0.526 AVG Training Acc 81.56 % AVG Validation Acc 79.33 %\n",
      "Epoch:130/200 AVG Training Loss:0.452 AVG Validation Loss:0.530 AVG Training Acc 81.63 % AVG Validation Acc 79.42 %\n",
      "Epoch   135: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.452 AVG Validation Loss:0.528 AVG Training Acc 81.56 % AVG Validation Acc 79.33 %\n",
      "Epoch:150/200 AVG Training Loss:0.450 AVG Validation Loss:0.529 AVG Training Acc 81.69 % AVG Validation Acc 79.24 %\n",
      "Epoch:160/200 AVG Training Loss:0.452 AVG Validation Loss:0.528 AVG Training Acc 81.55 % AVG Validation Acc 79.33 %\n",
      "Epoch   166: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.452 AVG Validation Loss:0.527 AVG Training Acc 81.52 % AVG Validation Acc 79.51 %\n",
      "Epoch:180/200 AVG Training Loss:0.451 AVG Validation Loss:0.526 AVG Training Acc 81.56 % AVG Validation Acc 79.24 %\n",
      "Epoch:190/200 AVG Training Loss:0.452 AVG Validation Loss:0.529 AVG Training Acc 81.48 % AVG Validation Acc 78.97 %\n",
      "Epoch   197: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.451 AVG Validation Loss:0.526 AVG Training Acc 81.62 % AVG Validation Acc 79.24 %\n",
      "Split 48\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "639e09b6df814558a2671655ada8fb87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.25 % AVG Validation Acc 80.23 %\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.30 % AVG Validation Acc 80.14 %\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.478 AVG Validation Loss:0.493 AVG Training Acc 80.40 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.472 AVG Validation Loss:0.501 AVG Training Acc 80.65 % AVG Validation Acc 79.60 %\n",
      "Epoch:70/200 AVG Training Loss:0.462 AVG Validation Loss:0.505 AVG Training Acc 80.97 % AVG Validation Acc 79.51 %\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.458 AVG Validation Loss:0.509 AVG Training Acc 81.16 % AVG Validation Acc 79.42 %\n",
      "Epoch:90/200 AVG Training Loss:0.457 AVG Validation Loss:0.516 AVG Training Acc 81.22 % AVG Validation Acc 79.33 %\n",
      "Epoch:100/200 AVG Training Loss:0.455 AVG Validation Loss:0.514 AVG Training Acc 81.35 % AVG Validation Acc 79.33 %\n",
      "Epoch   106: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.455 AVG Validation Loss:0.510 AVG Training Acc 81.36 % AVG Validation Acc 79.24 %\n",
      "Epoch:120/200 AVG Training Loss:0.454 AVG Validation Loss:0.521 AVG Training Acc 81.31 % AVG Validation Acc 79.24 %\n",
      "Epoch:130/200 AVG Training Loss:0.454 AVG Validation Loss:0.514 AVG Training Acc 81.32 % AVG Validation Acc 79.15 %\n",
      "Epoch   137: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.451 AVG Validation Loss:0.515 AVG Training Acc 81.30 % AVG Validation Acc 79.33 %\n",
      "Epoch:150/200 AVG Training Loss:0.456 AVG Validation Loss:0.517 AVG Training Acc 81.16 % AVG Validation Acc 79.42 %\n",
      "Epoch:160/200 AVG Training Loss:0.455 AVG Validation Loss:0.513 AVG Training Acc 81.13 % AVG Validation Acc 79.33 %\n",
      "Epoch   168: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.453 AVG Validation Loss:0.516 AVG Training Acc 81.29 % AVG Validation Acc 79.24 %\n",
      "Epoch:180/200 AVG Training Loss:0.453 AVG Validation Loss:0.513 AVG Training Acc 81.27 % AVG Validation Acc 79.33 %\n",
      "Epoch:190/200 AVG Training Loss:0.454 AVG Validation Loss:0.515 AVG Training Acc 81.35 % AVG Validation Acc 79.33 %\n",
      "Epoch   199: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.456 AVG Validation Loss:0.512 AVG Training Acc 81.12 % AVG Validation Acc 79.24 %\n",
      "Split 49\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cbfb01244894d3cb9b6f35ed09ca665",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.496 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.498 AVG Training Acc 80.28 % AVG Validation Acc 79.87 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.478 AVG Validation Loss:0.510 AVG Training Acc 80.79 % AVG Validation Acc 79.33 %\n",
      "Epoch:50/200 AVG Training Loss:0.473 AVG Validation Loss:0.520 AVG Training Acc 81.07 % AVG Validation Acc 79.51 %\n",
      "Epoch:60/200 AVG Training Loss:0.469 AVG Validation Loss:0.533 AVG Training Acc 81.23 % AVG Validation Acc 79.33 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.467 AVG Validation Loss:0.537 AVG Training Acc 81.20 % AVG Validation Acc 79.15 %\n",
      "Epoch:80/200 AVG Training Loss:0.465 AVG Validation Loss:0.543 AVG Training Acc 81.39 % AVG Validation Acc 79.24 %\n",
      "Epoch:90/200 AVG Training Loss:0.463 AVG Validation Loss:0.542 AVG Training Acc 81.44 % AVG Validation Acc 79.15 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.464 AVG Validation Loss:0.540 AVG Training Acc 81.47 % AVG Validation Acc 79.24 %\n",
      "Epoch:110/200 AVG Training Loss:0.463 AVG Validation Loss:0.541 AVG Training Acc 81.39 % AVG Validation Acc 79.24 %\n",
      "Epoch:120/200 AVG Training Loss:0.464 AVG Validation Loss:0.544 AVG Training Acc 81.40 % AVG Validation Acc 79.33 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.464 AVG Validation Loss:0.540 AVG Training Acc 81.46 % AVG Validation Acc 79.15 %\n",
      "Epoch:140/200 AVG Training Loss:0.462 AVG Validation Loss:0.542 AVG Training Acc 81.55 % AVG Validation Acc 79.24 %\n",
      "Epoch:150/200 AVG Training Loss:0.465 AVG Validation Loss:0.541 AVG Training Acc 81.50 % AVG Validation Acc 79.33 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.464 AVG Validation Loss:0.543 AVG Training Acc 81.50 % AVG Validation Acc 79.24 %\n",
      "Epoch:170/200 AVG Training Loss:0.464 AVG Validation Loss:0.543 AVG Training Acc 81.44 % AVG Validation Acc 79.24 %\n",
      "Epoch:180/200 AVG Training Loss:0.463 AVG Validation Loss:0.543 AVG Training Acc 81.50 % AVG Validation Acc 79.06 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.465 AVG Validation Loss:0.541 AVG Training Acc 81.43 % AVG Validation Acc 79.24 %\n",
      "Epoch:200/200 AVG Training Loss:0.464 AVG Validation Loss:0.538 AVG Training Acc 81.36 % AVG Validation Acc 79.24 %\n",
      "Split 50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "693a9d4065534f2a82315c1c3cda92b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 80.32 %\n",
      "Epoch:40/200 AVG Training Loss:0.480 AVG Validation Loss:0.502 AVG Training Acc 80.40 % AVG Validation Acc 80.32 %\n",
      "Epoch:50/200 AVG Training Loss:0.476 AVG Validation Loss:0.507 AVG Training Acc 80.51 % AVG Validation Acc 80.23 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.473 AVG Validation Loss:0.510 AVG Training Acc 80.49 % AVG Validation Acc 80.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.472 AVG Validation Loss:0.512 AVG Training Acc 80.59 % AVG Validation Acc 79.87 %\n",
      "Epoch:80/200 AVG Training Loss:0.471 AVG Validation Loss:0.514 AVG Training Acc 80.62 % AVG Validation Acc 79.87 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.471 AVG Validation Loss:0.515 AVG Training Acc 80.71 % AVG Validation Acc 80.05 %\n",
      "Epoch:100/200 AVG Training Loss:0.469 AVG Validation Loss:0.512 AVG Training Acc 80.60 % AVG Validation Acc 80.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.470 AVG Validation Loss:0.512 AVG Training Acc 80.66 % AVG Validation Acc 80.14 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.470 AVG Validation Loss:0.515 AVG Training Acc 80.64 % AVG Validation Acc 80.05 %\n",
      "Epoch:130/200 AVG Training Loss:0.470 AVG Validation Loss:0.512 AVG Training Acc 80.72 % AVG Validation Acc 80.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.470 AVG Validation Loss:0.513 AVG Training Acc 80.70 % AVG Validation Acc 79.87 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.470 AVG Validation Loss:0.514 AVG Training Acc 80.65 % AVG Validation Acc 79.96 %\n",
      "Epoch:160/200 AVG Training Loss:0.470 AVG Validation Loss:0.514 AVG Training Acc 80.79 % AVG Validation Acc 79.96 %\n",
      "Epoch:170/200 AVG Training Loss:0.470 AVG Validation Loss:0.513 AVG Training Acc 80.71 % AVG Validation Acc 80.05 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.471 AVG Validation Loss:0.515 AVG Training Acc 80.66 % AVG Validation Acc 80.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.470 AVG Validation Loss:0.515 AVG Training Acc 80.69 % AVG Validation Acc 80.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.469 AVG Validation Loss:0.515 AVG Training Acc 80.67 % AVG Validation Acc 79.96 %\n",
      "Split 51\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00ff81d344f2401ba42e1546c5d8118f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.491 AVG Training Acc 80.10 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.489 AVG Training Acc 80.14 % AVG Validation Acc 80.25 %\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.498 AVG Training Acc 80.18 % AVG Validation Acc 79.98 %\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.480 AVG Validation Loss:0.496 AVG Training Acc 80.52 % AVG Validation Acc 80.07 %\n",
      "Epoch:60/200 AVG Training Loss:0.474 AVG Validation Loss:0.501 AVG Training Acc 80.57 % AVG Validation Acc 79.89 %\n",
      "Epoch:70/200 AVG Training Loss:0.468 AVG Validation Loss:0.516 AVG Training Acc 80.66 % AVG Validation Acc 79.80 %\n",
      "Epoch    71: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.463 AVG Validation Loss:0.520 AVG Training Acc 80.93 % AVG Validation Acc 79.62 %\n",
      "Epoch:90/200 AVG Training Loss:0.463 AVG Validation Loss:0.524 AVG Training Acc 80.82 % AVG Validation Acc 79.71 %\n",
      "Epoch:100/200 AVG Training Loss:0.461 AVG Validation Loss:0.522 AVG Training Acc 80.87 % AVG Validation Acc 79.53 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.463 AVG Validation Loss:0.526 AVG Training Acc 80.72 % AVG Validation Acc 79.44 %\n",
      "Epoch:120/200 AVG Training Loss:0.460 AVG Validation Loss:0.522 AVG Training Acc 80.90 % AVG Validation Acc 79.17 %\n",
      "Epoch:130/200 AVG Training Loss:0.462 AVG Validation Loss:0.525 AVG Training Acc 80.77 % AVG Validation Acc 79.35 %\n",
      "Epoch   133: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.460 AVG Validation Loss:0.524 AVG Training Acc 80.94 % AVG Validation Acc 79.62 %\n",
      "Epoch:150/200 AVG Training Loss:0.462 AVG Validation Loss:0.525 AVG Training Acc 80.77 % AVG Validation Acc 79.17 %\n",
      "Epoch:160/200 AVG Training Loss:0.461 AVG Validation Loss:0.525 AVG Training Acc 80.95 % AVG Validation Acc 79.17 %\n",
      "Epoch   164: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.463 AVG Validation Loss:0.523 AVG Training Acc 80.86 % AVG Validation Acc 79.35 %\n",
      "Epoch:180/200 AVG Training Loss:0.462 AVG Validation Loss:0.526 AVG Training Acc 80.86 % AVG Validation Acc 79.35 %\n",
      "Epoch:190/200 AVG Training Loss:0.460 AVG Validation Loss:0.527 AVG Training Acc 80.91 % AVG Validation Acc 79.35 %\n",
      "Epoch   195: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.462 AVG Validation Loss:0.524 AVG Training Acc 80.86 % AVG Validation Acc 79.35 %\n",
      "Split 52\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f94e585081764e76a7a24a7cfd9019cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.482 AVG Validation Loss:0.493 AVG Training Acc 80.29 % AVG Validation Acc 80.07 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.472 AVG Validation Loss:0.501 AVG Training Acc 80.54 % AVG Validation Acc 79.98 %\n",
      "Epoch:50/200 AVG Training Loss:0.458 AVG Validation Loss:0.504 AVG Training Acc 80.91 % AVG Validation Acc 79.89 %\n",
      "Epoch:60/200 AVG Training Loss:0.448 AVG Validation Loss:0.516 AVG Training Acc 81.44 % AVG Validation Acc 79.62 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.441 AVG Validation Loss:0.525 AVG Training Acc 81.54 % AVG Validation Acc 79.08 %\n",
      "Epoch:80/200 AVG Training Loss:0.439 AVG Validation Loss:0.535 AVG Training Acc 81.81 % AVG Validation Acc 78.90 %\n",
      "Epoch:90/200 AVG Training Loss:0.435 AVG Validation Loss:0.533 AVG Training Acc 81.85 % AVG Validation Acc 78.36 %\n",
      "Epoch:100/200 AVG Training Loss:0.434 AVG Validation Loss:0.529 AVG Training Acc 81.93 % AVG Validation Acc 78.54 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.433 AVG Validation Loss:0.527 AVG Training Acc 81.92 % AVG Validation Acc 78.45 %\n",
      "Epoch:120/200 AVG Training Loss:0.436 AVG Validation Loss:0.535 AVG Training Acc 82.08 % AVG Validation Acc 78.72 %\n",
      "Epoch:130/200 AVG Training Loss:0.435 AVG Validation Loss:0.528 AVG Training Acc 81.79 % AVG Validation Acc 78.54 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.435 AVG Validation Loss:0.530 AVG Training Acc 81.98 % AVG Validation Acc 78.54 %\n",
      "Epoch:150/200 AVG Training Loss:0.436 AVG Validation Loss:0.525 AVG Training Acc 81.53 % AVG Validation Acc 78.81 %\n",
      "Epoch:160/200 AVG Training Loss:0.436 AVG Validation Loss:0.527 AVG Training Acc 81.85 % AVG Validation Acc 79.17 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.437 AVG Validation Loss:0.525 AVG Training Acc 81.70 % AVG Validation Acc 78.72 %\n",
      "Epoch:180/200 AVG Training Loss:0.435 AVG Validation Loss:0.534 AVG Training Acc 81.84 % AVG Validation Acc 78.45 %\n",
      "Epoch:190/200 AVG Training Loss:0.434 AVG Validation Loss:0.532 AVG Training Acc 81.65 % AVG Validation Acc 78.45 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.436 AVG Validation Loss:0.537 AVG Training Acc 81.57 % AVG Validation Acc 78.54 %\n",
      "Split 53\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e0c20a833c4c9f9600e8992f72ca12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.492 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.489 AVG Training Acc 80.10 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.490 AVG Training Acc 80.33 % AVG Validation Acc 80.25 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.474 AVG Validation Loss:0.495 AVG Training Acc 80.75 % AVG Validation Acc 79.80 %\n",
      "Epoch:50/200 AVG Training Loss:0.467 AVG Validation Loss:0.497 AVG Training Acc 81.03 % AVG Validation Acc 79.71 %\n",
      "Epoch:60/200 AVG Training Loss:0.459 AVG Validation Loss:0.502 AVG Training Acc 81.33 % AVG Validation Acc 79.44 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.452 AVG Validation Loss:0.507 AVG Training Acc 81.62 % AVG Validation Acc 79.44 %\n",
      "Epoch:80/200 AVG Training Loss:0.454 AVG Validation Loss:0.508 AVG Training Acc 81.52 % AVG Validation Acc 79.08 %\n",
      "Epoch:90/200 AVG Training Loss:0.449 AVG Validation Loss:0.510 AVG Training Acc 81.61 % AVG Validation Acc 79.44 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.452 AVG Validation Loss:0.511 AVG Training Acc 81.59 % AVG Validation Acc 79.26 %\n",
      "Epoch:110/200 AVG Training Loss:0.451 AVG Validation Loss:0.511 AVG Training Acc 81.71 % AVG Validation Acc 79.44 %\n",
      "Epoch:120/200 AVG Training Loss:0.450 AVG Validation Loss:0.510 AVG Training Acc 81.58 % AVG Validation Acc 78.90 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.449 AVG Validation Loss:0.511 AVG Training Acc 81.65 % AVG Validation Acc 79.26 %\n",
      "Epoch:140/200 AVG Training Loss:0.450 AVG Validation Loss:0.515 AVG Training Acc 81.46 % AVG Validation Acc 78.99 %\n",
      "Epoch:150/200 AVG Training Loss:0.450 AVG Validation Loss:0.516 AVG Training Acc 81.73 % AVG Validation Acc 78.99 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.453 AVG Validation Loss:0.514 AVG Training Acc 81.34 % AVG Validation Acc 79.26 %\n",
      "Epoch:170/200 AVG Training Loss:0.449 AVG Validation Loss:0.516 AVG Training Acc 81.73 % AVG Validation Acc 79.26 %\n",
      "Epoch:180/200 AVG Training Loss:0.450 AVG Validation Loss:0.510 AVG Training Acc 81.65 % AVG Validation Acc 79.35 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.449 AVG Validation Loss:0.511 AVG Training Acc 81.47 % AVG Validation Acc 79.35 %\n",
      "Epoch:200/200 AVG Training Loss:0.448 AVG Validation Loss:0.515 AVG Training Acc 81.65 % AVG Validation Acc 79.08 %\n",
      "Split 54\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94081e929bf49ccbfb9f904c257f1c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.501 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.489 AVG Validation Loss:0.500 AVG Training Acc 80.21 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.485 AVG Validation Loss:0.504 AVG Training Acc 80.31 % AVG Validation Acc 79.89 %\n",
      "Epoch:40/200 AVG Training Loss:0.481 AVG Validation Loss:0.514 AVG Training Acc 80.46 % AVG Validation Acc 79.44 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.478 AVG Validation Loss:0.517 AVG Training Acc 80.63 % AVG Validation Acc 79.17 %\n",
      "Epoch:60/200 AVG Training Loss:0.475 AVG Validation Loss:0.521 AVG Training Acc 80.66 % AVG Validation Acc 78.99 %\n",
      "Epoch:70/200 AVG Training Loss:0.475 AVG Validation Loss:0.521 AVG Training Acc 80.60 % AVG Validation Acc 78.99 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.473 AVG Validation Loss:0.521 AVG Training Acc 80.67 % AVG Validation Acc 79.26 %\n",
      "Epoch:90/200 AVG Training Loss:0.474 AVG Validation Loss:0.522 AVG Training Acc 80.63 % AVG Validation Acc 79.08 %\n",
      "Epoch:100/200 AVG Training Loss:0.475 AVG Validation Loss:0.521 AVG Training Acc 80.67 % AVG Validation Acc 79.26 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.474 AVG Validation Loss:0.521 AVG Training Acc 80.59 % AVG Validation Acc 79.08 %\n",
      "Epoch:120/200 AVG Training Loss:0.474 AVG Validation Loss:0.523 AVG Training Acc 80.62 % AVG Validation Acc 79.17 %\n",
      "Epoch:130/200 AVG Training Loss:0.474 AVG Validation Loss:0.521 AVG Training Acc 80.68 % AVG Validation Acc 79.17 %\n",
      "Epoch:140/200 AVG Training Loss:0.475 AVG Validation Loss:0.522 AVG Training Acc 80.63 % AVG Validation Acc 79.08 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.474 AVG Validation Loss:0.522 AVG Training Acc 80.65 % AVG Validation Acc 79.17 %\n",
      "Epoch:160/200 AVG Training Loss:0.474 AVG Validation Loss:0.521 AVG Training Acc 80.66 % AVG Validation Acc 79.17 %\n",
      "Epoch:170/200 AVG Training Loss:0.473 AVG Validation Loss:0.522 AVG Training Acc 80.68 % AVG Validation Acc 78.99 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.474 AVG Validation Loss:0.523 AVG Training Acc 80.63 % AVG Validation Acc 79.17 %\n",
      "Epoch:190/200 AVG Training Loss:0.474 AVG Validation Loss:0.521 AVG Training Acc 80.67 % AVG Validation Acc 79.26 %\n",
      "Epoch:200/200 AVG Training Loss:0.474 AVG Validation Loss:0.522 AVG Training Acc 80.64 % AVG Validation Acc 79.08 %\n",
      "Split 55\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2cfc622f87cf4fb4921fda1ac7a3df54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.498 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.498 AVG Validation Loss:0.498 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.497 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:60/200 AVG Training Loss:0.496 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.497 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:80/200 AVG Training Loss:0.496 AVG Validation Loss:0.498 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:90/200 AVG Training Loss:0.496 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.496 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:110/200 AVG Training Loss:0.496 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch:120/200 AVG Training Loss:0.496 AVG Validation Loss:0.498 AVG Training Acc 80.13 % AVG Validation Acc 80.07 %\n",
      "Epoch:130/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.496 AVG Validation Loss:0.496 AVG Training Acc 80.16 % AVG Validation Acc 80.07 %\n",
      "Epoch:150/200 AVG Training Loss:0.496 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:160/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:180/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch:190/200 AVG Training Loss:0.496 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Split 56\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "239e8c175ad044c0a8b03c32a928a60b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.491 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.488 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.484 AVG Training Acc 80.24 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.503 AVG Validation Loss:0.498 AVG Training Acc 80.07 % AVG Validation Acc 80.14 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.496 AVG Validation Loss:0.493 AVG Training Acc 80.12 % AVG Validation Acc 80.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.494 AVG Validation Loss:0.491 AVG Training Acc 80.15 % AVG Validation Acc 80.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.494 AVG Validation Loss:0.488 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.492 AVG Validation Loss:0.487 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.493 AVG Validation Loss:0.486 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.492 AVG Validation Loss:0.486 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.490 AVG Validation Loss:0.486 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch:120/200 AVG Training Loss:0.491 AVG Validation Loss:0.485 AVG Training Acc 80.17 % AVG Validation Acc 80.05 %\n",
      "Epoch:130/200 AVG Training Loss:0.492 AVG Validation Loss:0.484 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.492 AVG Validation Loss:0.485 AVG Training Acc 80.10 % AVG Validation Acc 80.14 %\n",
      "Epoch:150/200 AVG Training Loss:0.492 AVG Validation Loss:0.486 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.492 AVG Validation Loss:0.487 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.492 AVG Validation Loss:0.486 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.492 AVG Validation Loss:0.485 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.492 AVG Validation Loss:0.485 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.492 AVG Validation Loss:0.485 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Split 57\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43399cf86a8e4e0ba50892516b8951f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.502 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.505 AVG Training Acc 80.15 % AVG Validation Acc 80.05 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.482 AVG Validation Loss:0.505 AVG Training Acc 80.32 % AVG Validation Acc 79.78 %\n",
      "Epoch:50/200 AVG Training Loss:0.474 AVG Validation Loss:0.523 AVG Training Acc 80.50 % AVG Validation Acc 79.42 %\n",
      "Epoch:60/200 AVG Training Loss:0.468 AVG Validation Loss:0.542 AVG Training Acc 80.68 % AVG Validation Acc 79.33 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.463 AVG Validation Loss:0.555 AVG Training Acc 80.80 % AVG Validation Acc 79.33 %\n",
      "Epoch:80/200 AVG Training Loss:0.460 AVG Validation Loss:0.556 AVG Training Acc 80.93 % AVG Validation Acc 79.06 %\n",
      "Epoch:90/200 AVG Training Loss:0.461 AVG Validation Loss:0.559 AVG Training Acc 80.91 % AVG Validation Acc 79.06 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.459 AVG Validation Loss:0.560 AVG Training Acc 80.97 % AVG Validation Acc 79.06 %\n",
      "Epoch:110/200 AVG Training Loss:0.459 AVG Validation Loss:0.564 AVG Training Acc 81.07 % AVG Validation Acc 79.06 %\n",
      "Epoch:120/200 AVG Training Loss:0.460 AVG Validation Loss:0.563 AVG Training Acc 80.93 % AVG Validation Acc 79.06 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.459 AVG Validation Loss:0.561 AVG Training Acc 81.11 % AVG Validation Acc 79.06 %\n",
      "Epoch:140/200 AVG Training Loss:0.459 AVG Validation Loss:0.564 AVG Training Acc 81.10 % AVG Validation Acc 78.97 %\n",
      "Epoch:150/200 AVG Training Loss:0.460 AVG Validation Loss:0.563 AVG Training Acc 81.05 % AVG Validation Acc 78.97 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.458 AVG Validation Loss:0.559 AVG Training Acc 81.17 % AVG Validation Acc 78.97 %\n",
      "Epoch:170/200 AVG Training Loss:0.458 AVG Validation Loss:0.562 AVG Training Acc 81.10 % AVG Validation Acc 79.06 %\n",
      "Epoch:180/200 AVG Training Loss:0.459 AVG Validation Loss:0.563 AVG Training Acc 81.01 % AVG Validation Acc 78.97 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.459 AVG Validation Loss:0.563 AVG Training Acc 80.99 % AVG Validation Acc 78.97 %\n",
      "Epoch:200/200 AVG Training Loss:0.459 AVG Validation Loss:0.563 AVG Training Acc 81.05 % AVG Validation Acc 78.97 %\n",
      "Split 58\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51c7e125cdfa42a2a90bfe45d3b2e15e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.485 AVG Validation Loss:0.508 AVG Training Acc 80.24 % AVG Validation Acc 80.14 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.480 AVG Validation Loss:0.497 AVG Training Acc 80.28 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.472 AVG Validation Loss:0.508 AVG Training Acc 80.61 % AVG Validation Acc 79.69 %\n",
      "Epoch:60/200 AVG Training Loss:0.465 AVG Validation Loss:0.511 AVG Training Acc 80.90 % AVG Validation Acc 79.69 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.461 AVG Validation Loss:0.520 AVG Training Acc 81.05 % AVG Validation Acc 79.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.460 AVG Validation Loss:0.522 AVG Training Acc 81.04 % AVG Validation Acc 79.69 %\n",
      "Epoch:90/200 AVG Training Loss:0.460 AVG Validation Loss:0.525 AVG Training Acc 81.14 % AVG Validation Acc 79.78 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.460 AVG Validation Loss:0.527 AVG Training Acc 81.06 % AVG Validation Acc 79.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.458 AVG Validation Loss:0.531 AVG Training Acc 81.14 % AVG Validation Acc 79.42 %\n",
      "Epoch:120/200 AVG Training Loss:0.459 AVG Validation Loss:0.532 AVG Training Acc 80.95 % AVG Validation Acc 79.51 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.458 AVG Validation Loss:0.527 AVG Training Acc 81.00 % AVG Validation Acc 79.69 %\n",
      "Epoch:140/200 AVG Training Loss:0.458 AVG Validation Loss:0.531 AVG Training Acc 81.09 % AVG Validation Acc 79.42 %\n",
      "Epoch:150/200 AVG Training Loss:0.457 AVG Validation Loss:0.528 AVG Training Acc 81.08 % AVG Validation Acc 79.51 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.458 AVG Validation Loss:0.530 AVG Training Acc 81.20 % AVG Validation Acc 79.42 %\n",
      "Epoch:170/200 AVG Training Loss:0.459 AVG Validation Loss:0.531 AVG Training Acc 81.15 % AVG Validation Acc 79.69 %\n",
      "Epoch:180/200 AVG Training Loss:0.459 AVG Validation Loss:0.527 AVG Training Acc 81.11 % AVG Validation Acc 79.78 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.459 AVG Validation Loss:0.532 AVG Training Acc 81.09 % AVG Validation Acc 79.60 %\n",
      "Epoch:200/200 AVG Training Loss:0.459 AVG Validation Loss:0.530 AVG Training Acc 81.07 % AVG Validation Acc 79.69 %\n",
      "Split 59\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fa29d08e59f49b8ae3da85bf42d8d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.502 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.488 AVG Validation Loss:0.503 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.487 AVG Validation Loss:0.504 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.502 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.502 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.484 AVG Validation Loss:0.502 AVG Training Acc 80.23 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.25 % AVG Validation Acc 80.14 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.484 AVG Validation Loss:0.504 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.25 % AVG Validation Acc 80.14 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.484 AVG Validation Loss:0.501 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch:120/200 AVG Training Loss:0.485 AVG Validation Loss:0.502 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.484 AVG Validation Loss:0.502 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch:150/200 AVG Training Loss:0.484 AVG Validation Loss:0.502 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.502 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.483 AVG Validation Loss:0.503 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.483 AVG Validation Loss:0.502 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.484 AVG Validation Loss:0.504 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Split 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f130f36de16b480b92d458cfc52f9b51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.489 AVG Training Acc 80.25 % AVG Validation Acc 80.23 %\n",
      "Epoch:50/200 AVG Training Loss:0.480 AVG Validation Loss:0.495 AVG Training Acc 80.56 % AVG Validation Acc 79.96 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.462 AVG Validation Loss:0.498 AVG Training Acc 81.10 % AVG Validation Acc 79.51 %\n",
      "Epoch:70/200 AVG Training Loss:0.454 AVG Validation Loss:0.512 AVG Training Acc 81.43 % AVG Validation Acc 79.15 %\n",
      "Epoch:80/200 AVG Training Loss:0.450 AVG Validation Loss:0.525 AVG Training Acc 81.67 % AVG Validation Acc 79.06 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.444 AVG Validation Loss:0.518 AVG Training Acc 81.70 % AVG Validation Acc 79.24 %\n",
      "Epoch:100/200 AVG Training Loss:0.444 AVG Validation Loss:0.517 AVG Training Acc 81.98 % AVG Validation Acc 79.33 %\n",
      "Epoch:110/200 AVG Training Loss:0.442 AVG Validation Loss:0.516 AVG Training Acc 81.95 % AVG Validation Acc 79.51 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.442 AVG Validation Loss:0.521 AVG Training Acc 81.82 % AVG Validation Acc 79.15 %\n",
      "Epoch:130/200 AVG Training Loss:0.440 AVG Validation Loss:0.508 AVG Training Acc 81.92 % AVG Validation Acc 79.15 %\n",
      "Epoch:140/200 AVG Training Loss:0.441 AVG Validation Loss:0.522 AVG Training Acc 81.80 % AVG Validation Acc 79.33 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.444 AVG Validation Loss:0.518 AVG Training Acc 81.79 % AVG Validation Acc 79.33 %\n",
      "Epoch:160/200 AVG Training Loss:0.443 AVG Validation Loss:0.520 AVG Training Acc 81.74 % AVG Validation Acc 79.15 %\n",
      "Epoch:170/200 AVG Training Loss:0.441 AVG Validation Loss:0.524 AVG Training Acc 81.90 % AVG Validation Acc 79.51 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.440 AVG Validation Loss:0.517 AVG Training Acc 81.97 % AVG Validation Acc 79.15 %\n",
      "Epoch:190/200 AVG Training Loss:0.442 AVG Validation Loss:0.522 AVG Training Acc 81.97 % AVG Validation Acc 79.06 %\n",
      "Epoch:200/200 AVG Training Loss:0.442 AVG Validation Loss:0.522 AVG Training Acc 81.94 % AVG Validation Acc 79.15 %\n",
      "Split 61\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd1e91d7811e4bc1b568053921704ffd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.24 % AVG Validation Acc 80.25 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.476 AVG Validation Loss:0.496 AVG Training Acc 80.74 % AVG Validation Acc 79.98 %\n",
      "Epoch:50/200 AVG Training Loss:0.469 AVG Validation Loss:0.502 AVG Training Acc 80.89 % AVG Validation Acc 79.80 %\n",
      "Epoch:60/200 AVG Training Loss:0.464 AVG Validation Loss:0.513 AVG Training Acc 81.13 % AVG Validation Acc 79.71 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.460 AVG Validation Loss:0.512 AVG Training Acc 81.39 % AVG Validation Acc 79.89 %\n",
      "Epoch:80/200 AVG Training Loss:0.460 AVG Validation Loss:0.513 AVG Training Acc 81.42 % AVG Validation Acc 79.89 %\n",
      "Epoch:90/200 AVG Training Loss:0.458 AVG Validation Loss:0.519 AVG Training Acc 81.48 % AVG Validation Acc 79.62 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.456 AVG Validation Loss:0.519 AVG Training Acc 81.61 % AVG Validation Acc 79.53 %\n",
      "Epoch:110/200 AVG Training Loss:0.456 AVG Validation Loss:0.517 AVG Training Acc 81.63 % AVG Validation Acc 79.89 %\n",
      "Epoch:120/200 AVG Training Loss:0.458 AVG Validation Loss:0.518 AVG Training Acc 81.52 % AVG Validation Acc 79.71 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.457 AVG Validation Loss:0.517 AVG Training Acc 81.63 % AVG Validation Acc 79.71 %\n",
      "Epoch:140/200 AVG Training Loss:0.456 AVG Validation Loss:0.518 AVG Training Acc 81.49 % AVG Validation Acc 79.71 %\n",
      "Epoch:150/200 AVG Training Loss:0.457 AVG Validation Loss:0.517 AVG Training Acc 81.55 % AVG Validation Acc 79.62 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.457 AVG Validation Loss:0.518 AVG Training Acc 81.52 % AVG Validation Acc 79.71 %\n",
      "Epoch:170/200 AVG Training Loss:0.457 AVG Validation Loss:0.519 AVG Training Acc 81.45 % AVG Validation Acc 79.62 %\n",
      "Epoch:180/200 AVG Training Loss:0.456 AVG Validation Loss:0.518 AVG Training Acc 81.56 % AVG Validation Acc 79.44 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.456 AVG Validation Loss:0.518 AVG Training Acc 81.50 % AVG Validation Acc 79.53 %\n",
      "Epoch:200/200 AVG Training Loss:0.456 AVG Validation Loss:0.518 AVG Training Acc 81.51 % AVG Validation Acc 79.62 %\n",
      "Split 62\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b832bf8ce37a462fb2d2f7feefadaa58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.19 % AVG Validation Acc 80.25 %\n",
      "Epoch:40/200 AVG Training Loss:0.482 AVG Validation Loss:0.498 AVG Training Acc 80.22 % AVG Validation Acc 79.98 %\n",
      "Epoch:50/200 AVG Training Loss:0.476 AVG Validation Loss:0.502 AVG Training Acc 80.41 % AVG Validation Acc 79.80 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.472 AVG Validation Loss:0.507 AVG Training Acc 80.69 % AVG Validation Acc 79.62 %\n",
      "Epoch:70/200 AVG Training Loss:0.471 AVG Validation Loss:0.508 AVG Training Acc 80.69 % AVG Validation Acc 79.26 %\n",
      "Epoch:80/200 AVG Training Loss:0.471 AVG Validation Loss:0.509 AVG Training Acc 80.85 % AVG Validation Acc 79.26 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.468 AVG Validation Loss:0.507 AVG Training Acc 80.90 % AVG Validation Acc 79.26 %\n",
      "Epoch:100/200 AVG Training Loss:0.470 AVG Validation Loss:0.508 AVG Training Acc 80.74 % AVG Validation Acc 79.17 %\n",
      "Epoch:110/200 AVG Training Loss:0.470 AVG Validation Loss:0.509 AVG Training Acc 80.86 % AVG Validation Acc 79.17 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.470 AVG Validation Loss:0.509 AVG Training Acc 80.96 % AVG Validation Acc 79.17 %\n",
      "Epoch:130/200 AVG Training Loss:0.470 AVG Validation Loss:0.509 AVG Training Acc 80.88 % AVG Validation Acc 79.26 %\n",
      "Epoch:140/200 AVG Training Loss:0.469 AVG Validation Loss:0.508 AVG Training Acc 80.87 % AVG Validation Acc 79.17 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.470 AVG Validation Loss:0.508 AVG Training Acc 80.82 % AVG Validation Acc 79.17 %\n",
      "Epoch:160/200 AVG Training Loss:0.468 AVG Validation Loss:0.509 AVG Training Acc 80.95 % AVG Validation Acc 79.26 %\n",
      "Epoch:170/200 AVG Training Loss:0.469 AVG Validation Loss:0.511 AVG Training Acc 80.97 % AVG Validation Acc 79.26 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.469 AVG Validation Loss:0.509 AVG Training Acc 80.90 % AVG Validation Acc 79.26 %\n",
      "Epoch:190/200 AVG Training Loss:0.469 AVG Validation Loss:0.509 AVG Training Acc 80.80 % AVG Validation Acc 79.26 %\n",
      "Epoch:200/200 AVG Training Loss:0.468 AVG Validation Loss:0.509 AVG Training Acc 80.96 % AVG Validation Acc 79.17 %\n",
      "Split 63\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "562436a13c284d2a8ccc7ed2255153e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.18 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.18 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.16 % AVG Validation Acc 79.98 %\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.491 AVG Training Acc 80.29 % AVG Validation Acc 80.07 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.471 AVG Validation Loss:0.505 AVG Training Acc 80.66 % AVG Validation Acc 79.89 %\n",
      "Epoch:60/200 AVG Training Loss:0.464 AVG Validation Loss:0.508 AVG Training Acc 80.67 % AVG Validation Acc 79.89 %\n",
      "Epoch:70/200 AVG Training Loss:0.460 AVG Validation Loss:0.517 AVG Training Acc 80.86 % AVG Validation Acc 79.62 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.457 AVG Validation Loss:0.518 AVG Training Acc 80.89 % AVG Validation Acc 79.62 %\n",
      "Epoch:90/200 AVG Training Loss:0.454 AVG Validation Loss:0.521 AVG Training Acc 80.97 % AVG Validation Acc 79.53 %\n",
      "Epoch:100/200 AVG Training Loss:0.452 AVG Validation Loss:0.522 AVG Training Acc 80.99 % AVG Validation Acc 79.53 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.452 AVG Validation Loss:0.523 AVG Training Acc 81.00 % AVG Validation Acc 79.44 %\n",
      "Epoch:120/200 AVG Training Loss:0.453 AVG Validation Loss:0.521 AVG Training Acc 80.92 % AVG Validation Acc 79.62 %\n",
      "Epoch:130/200 AVG Training Loss:0.453 AVG Validation Loss:0.525 AVG Training Acc 80.90 % AVG Validation Acc 79.44 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.452 AVG Validation Loss:0.529 AVG Training Acc 81.06 % AVG Validation Acc 79.35 %\n",
      "Epoch:150/200 AVG Training Loss:0.452 AVG Validation Loss:0.527 AVG Training Acc 81.00 % AVG Validation Acc 79.44 %\n",
      "Epoch:160/200 AVG Training Loss:0.451 AVG Validation Loss:0.523 AVG Training Acc 80.95 % AVG Validation Acc 79.62 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.452 AVG Validation Loss:0.522 AVG Training Acc 81.06 % AVG Validation Acc 79.53 %\n",
      "Epoch:180/200 AVG Training Loss:0.452 AVG Validation Loss:0.519 AVG Training Acc 80.99 % AVG Validation Acc 79.53 %\n",
      "Epoch:190/200 AVG Training Loss:0.452 AVG Validation Loss:0.526 AVG Training Acc 81.04 % AVG Validation Acc 79.53 %\n",
      "Epoch:200/200 AVG Training Loss:0.455 AVG Validation Loss:0.526 AVG Training Acc 80.92 % AVG Validation Acc 79.53 %\n",
      "Epoch   200: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Split 64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d5a588008bf4db9b0a87f1bde24d952",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.492 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.480 AVG Validation Loss:0.500 AVG Training Acc 80.33 % AVG Validation Acc 80.25 %\n",
      "Epoch:50/200 AVG Training Loss:0.475 AVG Validation Loss:0.505 AVG Training Acc 80.39 % AVG Validation Acc 79.98 %\n",
      "Epoch:60/200 AVG Training Loss:0.470 AVG Validation Loss:0.511 AVG Training Acc 80.55 % AVG Validation Acc 79.89 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.470 AVG Validation Loss:0.515 AVG Training Acc 80.70 % AVG Validation Acc 79.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.469 AVG Validation Loss:0.517 AVG Training Acc 80.54 % AVG Validation Acc 79.80 %\n",
      "Epoch:90/200 AVG Training Loss:0.468 AVG Validation Loss:0.517 AVG Training Acc 80.60 % AVG Validation Acc 79.98 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.467 AVG Validation Loss:0.525 AVG Training Acc 80.70 % AVG Validation Acc 79.71 %\n",
      "Epoch:110/200 AVG Training Loss:0.468 AVG Validation Loss:0.519 AVG Training Acc 80.58 % AVG Validation Acc 79.80 %\n",
      "Epoch:120/200 AVG Training Loss:0.467 AVG Validation Loss:0.524 AVG Training Acc 80.66 % AVG Validation Acc 79.71 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.467 AVG Validation Loss:0.520 AVG Training Acc 80.67 % AVG Validation Acc 79.62 %\n",
      "Epoch:140/200 AVG Training Loss:0.469 AVG Validation Loss:0.518 AVG Training Acc 80.67 % AVG Validation Acc 79.71 %\n",
      "Epoch:150/200 AVG Training Loss:0.468 AVG Validation Loss:0.525 AVG Training Acc 80.56 % AVG Validation Acc 79.80 %\n",
      "Epoch:160/200 AVG Training Loss:0.467 AVG Validation Loss:0.519 AVG Training Acc 80.66 % AVG Validation Acc 79.80 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.468 AVG Validation Loss:0.524 AVG Training Acc 80.62 % AVG Validation Acc 79.71 %\n",
      "Epoch:180/200 AVG Training Loss:0.468 AVG Validation Loss:0.517 AVG Training Acc 80.66 % AVG Validation Acc 79.98 %\n",
      "Epoch:190/200 AVG Training Loss:0.468 AVG Validation Loss:0.524 AVG Training Acc 80.64 % AVG Validation Acc 79.89 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.467 AVG Validation Loss:0.524 AVG Training Acc 80.69 % AVG Validation Acc 79.89 %\n",
      "Split 65\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc23207159d4cc184c16eb1d7fe24ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.492 AVG Training Acc 80.19 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.24 % AVG Validation Acc 79.98 %\n",
      "Epoch:40/200 AVG Training Loss:0.481 AVG Validation Loss:0.491 AVG Training Acc 80.46 % AVG Validation Acc 80.07 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.473 AVG Validation Loss:0.495 AVG Training Acc 80.59 % AVG Validation Acc 79.98 %\n",
      "Epoch:60/200 AVG Training Loss:0.456 AVG Validation Loss:0.512 AVG Training Acc 80.96 % AVG Validation Acc 79.80 %\n",
      "Epoch:70/200 AVG Training Loss:0.448 AVG Validation Loss:0.522 AVG Training Acc 81.29 % AVG Validation Acc 79.44 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.444 AVG Validation Loss:0.522 AVG Training Acc 81.34 % AVG Validation Acc 79.62 %\n",
      "Epoch:90/200 AVG Training Loss:0.440 AVG Validation Loss:0.524 AVG Training Acc 81.62 % AVG Validation Acc 79.44 %\n",
      "Epoch:100/200 AVG Training Loss:0.439 AVG Validation Loss:0.531 AVG Training Acc 81.62 % AVG Validation Acc 79.44 %\n",
      "Epoch:110/200 AVG Training Loss:0.441 AVG Validation Loss:0.531 AVG Training Acc 81.41 % AVG Validation Acc 79.44 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.441 AVG Validation Loss:0.530 AVG Training Acc 81.49 % AVG Validation Acc 79.44 %\n",
      "Epoch:130/200 AVG Training Loss:0.440 AVG Validation Loss:0.530 AVG Training Acc 81.61 % AVG Validation Acc 79.44 %\n",
      "Epoch:140/200 AVG Training Loss:0.439 AVG Validation Loss:0.529 AVG Training Acc 81.45 % AVG Validation Acc 79.62 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.438 AVG Validation Loss:0.534 AVG Training Acc 81.51 % AVG Validation Acc 79.44 %\n",
      "Epoch:160/200 AVG Training Loss:0.437 AVG Validation Loss:0.529 AVG Training Acc 81.59 % AVG Validation Acc 79.44 %\n",
      "Epoch:170/200 AVG Training Loss:0.440 AVG Validation Loss:0.529 AVG Training Acc 81.55 % AVG Validation Acc 79.44 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.440 AVG Validation Loss:0.536 AVG Training Acc 81.50 % AVG Validation Acc 79.26 %\n",
      "Epoch:190/200 AVG Training Loss:0.439 AVG Validation Loss:0.531 AVG Training Acc 81.52 % AVG Validation Acc 79.62 %\n",
      "Epoch:200/200 AVG Training Loss:0.438 AVG Validation Loss:0.532 AVG Training Acc 81.57 % AVG Validation Acc 79.44 %\n",
      "Split 66\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f44d3c622fd4f08bf9fb39db196c077",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.23 % AVG Validation Acc 79.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.477 AVG Validation Loss:0.506 AVG Training Acc 80.28 % AVG Validation Acc 79.96 %\n",
      "Epoch:50/200 AVG Training Loss:0.469 AVG Validation Loss:0.519 AVG Training Acc 80.45 % AVG Validation Acc 79.87 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.462 AVG Validation Loss:0.525 AVG Training Acc 80.75 % AVG Validation Acc 79.33 %\n",
      "Epoch:70/200 AVG Training Loss:0.459 AVG Validation Loss:0.526 AVG Training Acc 80.84 % AVG Validation Acc 79.15 %\n",
      "Epoch:80/200 AVG Training Loss:0.459 AVG Validation Loss:0.530 AVG Training Acc 80.86 % AVG Validation Acc 79.24 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.457 AVG Validation Loss:0.528 AVG Training Acc 80.92 % AVG Validation Acc 79.15 %\n",
      "Epoch:100/200 AVG Training Loss:0.457 AVG Validation Loss:0.532 AVG Training Acc 80.96 % AVG Validation Acc 78.97 %\n",
      "Epoch:110/200 AVG Training Loss:0.458 AVG Validation Loss:0.530 AVG Training Acc 80.90 % AVG Validation Acc 79.15 %\n",
      "Epoch:120/200 AVG Training Loss:0.456 AVG Validation Loss:0.531 AVG Training Acc 81.22 % AVG Validation Acc 79.06 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.459 AVG Validation Loss:0.532 AVG Training Acc 80.90 % AVG Validation Acc 78.88 %\n",
      "Epoch:140/200 AVG Training Loss:0.458 AVG Validation Loss:0.531 AVG Training Acc 80.87 % AVG Validation Acc 78.97 %\n",
      "Epoch:150/200 AVG Training Loss:0.458 AVG Validation Loss:0.531 AVG Training Acc 80.96 % AVG Validation Acc 79.06 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.460 AVG Validation Loss:0.531 AVG Training Acc 80.78 % AVG Validation Acc 79.06 %\n",
      "Epoch:170/200 AVG Training Loss:0.457 AVG Validation Loss:0.533 AVG Training Acc 80.93 % AVG Validation Acc 79.15 %\n",
      "Epoch:180/200 AVG Training Loss:0.458 AVG Validation Loss:0.531 AVG Training Acc 80.97 % AVG Validation Acc 78.79 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.457 AVG Validation Loss:0.530 AVG Training Acc 80.87 % AVG Validation Acc 79.15 %\n",
      "Epoch:200/200 AVG Training Loss:0.457 AVG Validation Loss:0.533 AVG Training Acc 81.02 % AVG Validation Acc 79.06 %\n",
      "Split 67\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07ebcaa46a0f4c9fba49679af99bd4c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.28 % AVG Validation Acc 80.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.31 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.29 % AVG Validation Acc 79.96 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.32 % AVG Validation Acc 79.78 %\n",
      "Epoch:70/200 AVG Training Loss:0.482 AVG Validation Loss:0.498 AVG Training Acc 80.40 % AVG Validation Acc 79.87 %\n",
      "Epoch:80/200 AVG Training Loss:0.482 AVG Validation Loss:0.497 AVG Training Acc 80.37 % AVG Validation Acc 79.78 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.482 AVG Validation Loss:0.496 AVG Training Acc 80.36 % AVG Validation Acc 79.78 %\n",
      "Epoch:100/200 AVG Training Loss:0.482 AVG Validation Loss:0.497 AVG Training Acc 80.44 % AVG Validation Acc 79.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.482 AVG Validation Loss:0.497 AVG Training Acc 80.33 % AVG Validation Acc 79.78 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.481 AVG Validation Loss:0.497 AVG Training Acc 80.36 % AVG Validation Acc 79.78 %\n",
      "Epoch:130/200 AVG Training Loss:0.481 AVG Validation Loss:0.497 AVG Training Acc 80.40 % AVG Validation Acc 79.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.482 AVG Validation Loss:0.497 AVG Training Acc 80.39 % AVG Validation Acc 79.78 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.481 AVG Validation Loss:0.497 AVG Training Acc 80.39 % AVG Validation Acc 79.78 %\n",
      "Epoch:160/200 AVG Training Loss:0.481 AVG Validation Loss:0.497 AVG Training Acc 80.42 % AVG Validation Acc 79.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.481 AVG Validation Loss:0.497 AVG Training Acc 80.36 % AVG Validation Acc 79.78 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.482 AVG Validation Loss:0.497 AVG Training Acc 80.45 % AVG Validation Acc 79.78 %\n",
      "Epoch:190/200 AVG Training Loss:0.481 AVG Validation Loss:0.497 AVG Training Acc 80.41 % AVG Validation Acc 79.78 %\n",
      "Epoch:200/200 AVG Training Loss:0.481 AVG Validation Loss:0.497 AVG Training Acc 80.37 % AVG Validation Acc 79.78 %\n",
      "Split 68\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "497d6b70c05c446fbeef180300d9d6de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.492 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.492 AVG Training Acc 80.18 % AVG Validation Acc 80.05 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.481 AVG Validation Loss:0.492 AVG Training Acc 80.31 % AVG Validation Acc 79.78 %\n",
      "Epoch:50/200 AVG Training Loss:0.479 AVG Validation Loss:0.493 AVG Training Acc 80.44 % AVG Validation Acc 79.69 %\n",
      "Epoch:60/200 AVG Training Loss:0.475 AVG Validation Loss:0.495 AVG Training Acc 80.52 % AVG Validation Acc 79.60 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.475 AVG Validation Loss:0.496 AVG Training Acc 80.61 % AVG Validation Acc 79.60 %\n",
      "Epoch:80/200 AVG Training Loss:0.474 AVG Validation Loss:0.495 AVG Training Acc 80.57 % AVG Validation Acc 79.69 %\n",
      "Epoch:90/200 AVG Training Loss:0.472 AVG Validation Loss:0.499 AVG Training Acc 80.65 % AVG Validation Acc 79.51 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.472 AVG Validation Loss:0.499 AVG Training Acc 80.58 % AVG Validation Acc 79.51 %\n",
      "Epoch:110/200 AVG Training Loss:0.472 AVG Validation Loss:0.500 AVG Training Acc 80.71 % AVG Validation Acc 79.51 %\n",
      "Epoch:120/200 AVG Training Loss:0.471 AVG Validation Loss:0.500 AVG Training Acc 80.68 % AVG Validation Acc 79.51 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.471 AVG Validation Loss:0.498 AVG Training Acc 80.59 % AVG Validation Acc 79.60 %\n",
      "Epoch:140/200 AVG Training Loss:0.472 AVG Validation Loss:0.501 AVG Training Acc 80.63 % AVG Validation Acc 79.60 %\n",
      "Epoch:150/200 AVG Training Loss:0.472 AVG Validation Loss:0.500 AVG Training Acc 80.61 % AVG Validation Acc 79.51 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.472 AVG Validation Loss:0.500 AVG Training Acc 80.66 % AVG Validation Acc 79.51 %\n",
      "Epoch:170/200 AVG Training Loss:0.471 AVG Validation Loss:0.500 AVG Training Acc 80.73 % AVG Validation Acc 79.60 %\n",
      "Epoch:180/200 AVG Training Loss:0.473 AVG Validation Loss:0.500 AVG Training Acc 80.65 % AVG Validation Acc 79.60 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.472 AVG Validation Loss:0.501 AVG Training Acc 80.60 % AVG Validation Acc 79.42 %\n",
      "Epoch:200/200 AVG Training Loss:0.472 AVG Validation Loss:0.500 AVG Training Acc 80.59 % AVG Validation Acc 79.60 %\n",
      "Split 69\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d00054ee0c44c5390bde837e58ef52e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.501 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.500 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.500 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.499 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.500 AVG Training Acc 80.15 % AVG Validation Acc 80.05 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.482 AVG Validation Loss:0.500 AVG Training Acc 80.30 % AVG Validation Acc 79.96 %\n",
      "Epoch:70/200 AVG Training Loss:0.482 AVG Validation Loss:0.501 AVG Training Acc 80.40 % AVG Validation Acc 79.87 %\n",
      "Epoch:80/200 AVG Training Loss:0.481 AVG Validation Loss:0.503 AVG Training Acc 80.33 % AVG Validation Acc 79.69 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.481 AVG Validation Loss:0.503 AVG Training Acc 80.32 % AVG Validation Acc 79.69 %\n",
      "Epoch:100/200 AVG Training Loss:0.480 AVG Validation Loss:0.502 AVG Training Acc 80.36 % AVG Validation Acc 79.69 %\n",
      "Epoch:110/200 AVG Training Loss:0.481 AVG Validation Loss:0.503 AVG Training Acc 80.23 % AVG Validation Acc 79.69 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.481 AVG Validation Loss:0.502 AVG Training Acc 80.28 % AVG Validation Acc 79.69 %\n",
      "Epoch:130/200 AVG Training Loss:0.481 AVG Validation Loss:0.503 AVG Training Acc 80.31 % AVG Validation Acc 79.69 %\n",
      "Epoch:140/200 AVG Training Loss:0.481 AVG Validation Loss:0.503 AVG Training Acc 80.37 % AVG Validation Acc 79.69 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.480 AVG Validation Loss:0.503 AVG Training Acc 80.45 % AVG Validation Acc 79.69 %\n",
      "Epoch:160/200 AVG Training Loss:0.481 AVG Validation Loss:0.503 AVG Training Acc 80.35 % AVG Validation Acc 79.69 %\n",
      "Epoch:170/200 AVG Training Loss:0.481 AVG Validation Loss:0.502 AVG Training Acc 80.31 % AVG Validation Acc 79.69 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.481 AVG Validation Loss:0.503 AVG Training Acc 80.36 % AVG Validation Acc 79.69 %\n",
      "Epoch:190/200 AVG Training Loss:0.480 AVG Validation Loss:0.503 AVG Training Acc 80.38 % AVG Validation Acc 79.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.481 AVG Validation Loss:0.503 AVG Training Acc 80.34 % AVG Validation Acc 79.69 %\n",
      "Split 70\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d59510e7d0b649539a15787cad2b0858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.485 AVG Validation Loss:0.499 AVG Training Acc 80.26 % AVG Validation Acc 79.87 %\n",
      "Epoch:40/200 AVG Training Loss:0.478 AVG Validation Loss:0.502 AVG Training Acc 80.48 % AVG Validation Acc 79.69 %\n",
      "Epoch:50/200 AVG Training Loss:0.473 AVG Validation Loss:0.511 AVG Training Acc 80.65 % AVG Validation Acc 79.69 %\n",
      "Epoch:60/200 AVG Training Loss:0.468 AVG Validation Loss:0.518 AVG Training Acc 80.75 % AVG Validation Acc 79.33 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.463 AVG Validation Loss:0.521 AVG Training Acc 80.92 % AVG Validation Acc 79.33 %\n",
      "Epoch:80/200 AVG Training Loss:0.463 AVG Validation Loss:0.525 AVG Training Acc 80.96 % AVG Validation Acc 79.42 %\n",
      "Epoch:90/200 AVG Training Loss:0.461 AVG Validation Loss:0.526 AVG Training Acc 81.03 % AVG Validation Acc 79.24 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.461 AVG Validation Loss:0.526 AVG Training Acc 80.99 % AVG Validation Acc 79.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.462 AVG Validation Loss:0.526 AVG Training Acc 81.05 % AVG Validation Acc 79.42 %\n",
      "Epoch:120/200 AVG Training Loss:0.462 AVG Validation Loss:0.526 AVG Training Acc 80.98 % AVG Validation Acc 79.33 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.462 AVG Validation Loss:0.526 AVG Training Acc 80.92 % AVG Validation Acc 79.24 %\n",
      "Epoch:140/200 AVG Training Loss:0.461 AVG Validation Loss:0.527 AVG Training Acc 81.07 % AVG Validation Acc 79.24 %\n",
      "Epoch:150/200 AVG Training Loss:0.462 AVG Validation Loss:0.527 AVG Training Acc 80.93 % AVG Validation Acc 79.33 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.461 AVG Validation Loss:0.527 AVG Training Acc 80.97 % AVG Validation Acc 79.33 %\n",
      "Epoch:170/200 AVG Training Loss:0.461 AVG Validation Loss:0.527 AVG Training Acc 81.08 % AVG Validation Acc 79.33 %\n",
      "Epoch:180/200 AVG Training Loss:0.461 AVG Validation Loss:0.524 AVG Training Acc 80.98 % AVG Validation Acc 79.33 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.464 AVG Validation Loss:0.523 AVG Training Acc 80.86 % AVG Validation Acc 79.42 %\n",
      "Epoch:200/200 AVG Training Loss:0.463 AVG Validation Loss:0.525 AVG Training Acc 80.96 % AVG Validation Acc 79.60 %\n",
      "Split 71\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "175d0f86adec467aa6368f01c9a175bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.492 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.491 AVG Training Acc 80.16 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.488 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.485 AVG Validation Loss:0.487 AVG Training Acc 80.34 % AVG Validation Acc 80.07 %\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.473 AVG Validation Loss:0.490 AVG Training Acc 80.56 % AVG Validation Acc 79.98 %\n",
      "Epoch:60/200 AVG Training Loss:0.467 AVG Validation Loss:0.501 AVG Training Acc 80.73 % AVG Validation Acc 80.07 %\n",
      "Epoch:70/200 AVG Training Loss:0.461 AVG Validation Loss:0.505 AVG Training Acc 80.92 % AVG Validation Acc 80.07 %\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.457 AVG Validation Loss:0.516 AVG Training Acc 81.04 % AVG Validation Acc 79.71 %\n",
      "Epoch:90/200 AVG Training Loss:0.456 AVG Validation Loss:0.515 AVG Training Acc 81.04 % AVG Validation Acc 79.71 %\n",
      "Epoch:100/200 AVG Training Loss:0.457 AVG Validation Loss:0.517 AVG Training Acc 80.88 % AVG Validation Acc 79.62 %\n",
      "Epoch   106: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.454 AVG Validation Loss:0.518 AVG Training Acc 81.08 % AVG Validation Acc 79.89 %\n",
      "Epoch:120/200 AVG Training Loss:0.455 AVG Validation Loss:0.514 AVG Training Acc 81.02 % AVG Validation Acc 79.89 %\n",
      "Epoch:130/200 AVG Training Loss:0.456 AVG Validation Loss:0.516 AVG Training Acc 80.95 % AVG Validation Acc 79.89 %\n",
      "Epoch   137: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.454 AVG Validation Loss:0.522 AVG Training Acc 81.10 % AVG Validation Acc 79.62 %\n",
      "Epoch:150/200 AVG Training Loss:0.454 AVG Validation Loss:0.519 AVG Training Acc 81.11 % AVG Validation Acc 80.07 %\n",
      "Epoch:160/200 AVG Training Loss:0.453 AVG Validation Loss:0.518 AVG Training Acc 81.15 % AVG Validation Acc 79.89 %\n",
      "Epoch   168: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.454 AVG Validation Loss:0.517 AVG Training Acc 80.91 % AVG Validation Acc 79.71 %\n",
      "Epoch:180/200 AVG Training Loss:0.455 AVG Validation Loss:0.518 AVG Training Acc 81.13 % AVG Validation Acc 79.71 %\n",
      "Epoch:190/200 AVG Training Loss:0.453 AVG Validation Loss:0.520 AVG Training Acc 81.15 % AVG Validation Acc 79.71 %\n",
      "Epoch   199: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.455 AVG Validation Loss:0.520 AVG Training Acc 81.07 % AVG Validation Acc 79.98 %\n",
      "Split 72\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c218327ef41540c88afc927edb8aeacf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.492 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.30 % AVG Validation Acc 79.71 %\n",
      "Epoch:40/200 AVG Training Loss:0.478 AVG Validation Loss:0.504 AVG Training Acc 80.49 % AVG Validation Acc 79.62 %\n",
      "Epoch:50/200 AVG Training Loss:0.473 AVG Validation Loss:0.512 AVG Training Acc 80.74 % AVG Validation Acc 79.62 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.469 AVG Validation Loss:0.515 AVG Training Acc 80.90 % AVG Validation Acc 79.53 %\n",
      "Epoch:70/200 AVG Training Loss:0.466 AVG Validation Loss:0.517 AVG Training Acc 81.05 % AVG Validation Acc 79.26 %\n",
      "Epoch:80/200 AVG Training Loss:0.465 AVG Validation Loss:0.520 AVG Training Acc 81.07 % AVG Validation Acc 79.17 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.464 AVG Validation Loss:0.521 AVG Training Acc 81.20 % AVG Validation Acc 79.08 %\n",
      "Epoch:100/200 AVG Training Loss:0.464 AVG Validation Loss:0.520 AVG Training Acc 81.05 % AVG Validation Acc 79.17 %\n",
      "Epoch:110/200 AVG Training Loss:0.466 AVG Validation Loss:0.520 AVG Training Acc 80.97 % AVG Validation Acc 79.08 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.465 AVG Validation Loss:0.520 AVG Training Acc 81.01 % AVG Validation Acc 79.08 %\n",
      "Epoch:130/200 AVG Training Loss:0.463 AVG Validation Loss:0.521 AVG Training Acc 81.15 % AVG Validation Acc 79.08 %\n",
      "Epoch:140/200 AVG Training Loss:0.465 AVG Validation Loss:0.519 AVG Training Acc 80.99 % AVG Validation Acc 79.17 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.466 AVG Validation Loss:0.520 AVG Training Acc 81.03 % AVG Validation Acc 79.17 %\n",
      "Epoch:160/200 AVG Training Loss:0.464 AVG Validation Loss:0.522 AVG Training Acc 81.18 % AVG Validation Acc 78.90 %\n",
      "Epoch:170/200 AVG Training Loss:0.464 AVG Validation Loss:0.521 AVG Training Acc 81.18 % AVG Validation Acc 79.17 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.465 AVG Validation Loss:0.521 AVG Training Acc 81.03 % AVG Validation Acc 79.08 %\n",
      "Epoch:190/200 AVG Training Loss:0.465 AVG Validation Loss:0.520 AVG Training Acc 81.06 % AVG Validation Acc 79.17 %\n",
      "Epoch:200/200 AVG Training Loss:0.465 AVG Validation Loss:0.521 AVG Training Acc 81.18 % AVG Validation Acc 79.08 %\n",
      "Split 73\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd448905678e418bbb9e382c4f00bf18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.492 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.494 AVG Validation Loss:0.490 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.490 AVG Training Acc 80.26 % AVG Validation Acc 79.89 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.478 AVG Validation Loss:0.500 AVG Training Acc 80.47 % AVG Validation Acc 79.98 %\n",
      "Epoch:60/200 AVG Training Loss:0.473 AVG Validation Loss:0.507 AVG Training Acc 80.48 % AVG Validation Acc 79.80 %\n",
      "Epoch:70/200 AVG Training Loss:0.466 AVG Validation Loss:0.511 AVG Training Acc 80.73 % AVG Validation Acc 79.80 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.460 AVG Validation Loss:0.523 AVG Training Acc 80.95 % AVG Validation Acc 79.98 %\n",
      "Epoch:90/200 AVG Training Loss:0.460 AVG Validation Loss:0.526 AVG Training Acc 80.81 % AVG Validation Acc 79.80 %\n",
      "Epoch:100/200 AVG Training Loss:0.459 AVG Validation Loss:0.525 AVG Training Acc 80.87 % AVG Validation Acc 79.53 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.459 AVG Validation Loss:0.526 AVG Training Acc 80.87 % AVG Validation Acc 79.80 %\n",
      "Epoch:120/200 AVG Training Loss:0.455 AVG Validation Loss:0.527 AVG Training Acc 80.92 % AVG Validation Acc 79.53 %\n",
      "Epoch:130/200 AVG Training Loss:0.459 AVG Validation Loss:0.531 AVG Training Acc 81.00 % AVG Validation Acc 79.53 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.457 AVG Validation Loss:0.528 AVG Training Acc 80.82 % AVG Validation Acc 79.53 %\n",
      "Epoch:150/200 AVG Training Loss:0.459 AVG Validation Loss:0.524 AVG Training Acc 80.73 % AVG Validation Acc 79.62 %\n",
      "Epoch:160/200 AVG Training Loss:0.458 AVG Validation Loss:0.529 AVG Training Acc 80.99 % AVG Validation Acc 79.53 %\n",
      "Epoch:170/200 AVG Training Loss:0.458 AVG Validation Loss:0.527 AVG Training Acc 80.82 % AVG Validation Acc 79.80 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.458 AVG Validation Loss:0.527 AVG Training Acc 80.99 % AVG Validation Acc 79.62 %\n",
      "Epoch:190/200 AVG Training Loss:0.457 AVG Validation Loss:0.531 AVG Training Acc 80.98 % AVG Validation Acc 79.44 %\n",
      "Epoch:200/200 AVG Training Loss:0.456 AVG Validation Loss:0.528 AVG Training Acc 80.99 % AVG Validation Acc 79.44 %\n",
      "Split 74\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee9eb0223009492882c728d1c0cf9d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.498 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.490 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.499 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.478 AVG Validation Loss:0.507 AVG Training Acc 80.40 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.474 AVG Validation Loss:0.509 AVG Training Acc 80.50 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.466 AVG Validation Loss:0.526 AVG Training Acc 80.63 % AVG Validation Acc 80.07 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.466 AVG Validation Loss:0.526 AVG Training Acc 80.70 % AVG Validation Acc 80.16 %\n",
      "Epoch:80/200 AVG Training Loss:0.464 AVG Validation Loss:0.531 AVG Training Acc 80.76 % AVG Validation Acc 80.16 %\n",
      "Epoch:90/200 AVG Training Loss:0.464 AVG Validation Loss:0.533 AVG Training Acc 80.92 % AVG Validation Acc 80.07 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.462 AVG Validation Loss:0.532 AVG Training Acc 80.81 % AVG Validation Acc 80.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.462 AVG Validation Loss:0.534 AVG Training Acc 80.80 % AVG Validation Acc 80.07 %\n",
      "Epoch:120/200 AVG Training Loss:0.462 AVG Validation Loss:0.534 AVG Training Acc 80.89 % AVG Validation Acc 80.07 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.462 AVG Validation Loss:0.534 AVG Training Acc 81.02 % AVG Validation Acc 80.07 %\n",
      "Epoch:140/200 AVG Training Loss:0.461 AVG Validation Loss:0.532 AVG Training Acc 80.96 % AVG Validation Acc 80.07 %\n",
      "Epoch:150/200 AVG Training Loss:0.463 AVG Validation Loss:0.535 AVG Training Acc 80.82 % AVG Validation Acc 80.07 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.462 AVG Validation Loss:0.534 AVG Training Acc 80.92 % AVG Validation Acc 80.07 %\n",
      "Epoch:170/200 AVG Training Loss:0.462 AVG Validation Loss:0.534 AVG Training Acc 80.90 % AVG Validation Acc 80.07 %\n",
      "Epoch:180/200 AVG Training Loss:0.463 AVG Validation Loss:0.534 AVG Training Acc 80.94 % AVG Validation Acc 80.16 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.461 AVG Validation Loss:0.532 AVG Training Acc 81.01 % AVG Validation Acc 80.07 %\n",
      "Epoch:200/200 AVG Training Loss:0.463 AVG Validation Loss:0.534 AVG Training Acc 80.88 % AVG Validation Acc 79.98 %\n",
      "Split 75\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "252b005c48fd4a208c07b64f0dd8cef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.498 AVG Validation Loss:0.499 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.499 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.499 AVG Training Acc 80.13 % AVG Validation Acc 80.07 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.480 AVG Validation Loss:0.501 AVG Training Acc 80.37 % AVG Validation Acc 79.80 %\n",
      "Epoch:50/200 AVG Training Loss:0.477 AVG Validation Loss:0.504 AVG Training Acc 80.59 % AVG Validation Acc 79.62 %\n",
      "Epoch:60/200 AVG Training Loss:0.472 AVG Validation Loss:0.505 AVG Training Acc 80.74 % AVG Validation Acc 79.53 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.471 AVG Validation Loss:0.506 AVG Training Acc 80.94 % AVG Validation Acc 79.62 %\n",
      "Epoch:80/200 AVG Training Loss:0.468 AVG Validation Loss:0.507 AVG Training Acc 80.88 % AVG Validation Acc 79.35 %\n",
      "Epoch:90/200 AVG Training Loss:0.470 AVG Validation Loss:0.505 AVG Training Acc 81.00 % AVG Validation Acc 79.26 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.467 AVG Validation Loss:0.507 AVG Training Acc 81.05 % AVG Validation Acc 79.17 %\n",
      "Epoch:110/200 AVG Training Loss:0.469 AVG Validation Loss:0.508 AVG Training Acc 80.92 % AVG Validation Acc 79.17 %\n",
      "Epoch:120/200 AVG Training Loss:0.470 AVG Validation Loss:0.507 AVG Training Acc 80.84 % AVG Validation Acc 79.17 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.468 AVG Validation Loss:0.507 AVG Training Acc 81.02 % AVG Validation Acc 79.35 %\n",
      "Epoch:140/200 AVG Training Loss:0.468 AVG Validation Loss:0.507 AVG Training Acc 80.93 % AVG Validation Acc 79.26 %\n",
      "Epoch:150/200 AVG Training Loss:0.468 AVG Validation Loss:0.507 AVG Training Acc 80.97 % AVG Validation Acc 79.26 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.468 AVG Validation Loss:0.507 AVG Training Acc 81.01 % AVG Validation Acc 79.35 %\n",
      "Epoch:170/200 AVG Training Loss:0.469 AVG Validation Loss:0.506 AVG Training Acc 81.02 % AVG Validation Acc 79.26 %\n",
      "Epoch:180/200 AVG Training Loss:0.468 AVG Validation Loss:0.509 AVG Training Acc 81.08 % AVG Validation Acc 79.08 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.468 AVG Validation Loss:0.507 AVG Training Acc 80.99 % AVG Validation Acc 79.35 %\n",
      "Epoch:200/200 AVG Training Loss:0.469 AVG Validation Loss:0.507 AVG Training Acc 80.99 % AVG Validation Acc 79.26 %\n",
      "Split 76\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c086899d7c1c4a708a809df66bb5434b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.497 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.21 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.479 AVG Validation Loss:0.500 AVG Training Acc 80.54 % AVG Validation Acc 79.87 %\n",
      "Epoch:60/200 AVG Training Loss:0.473 AVG Validation Loss:0.507 AVG Training Acc 80.92 % AVG Validation Acc 79.69 %\n",
      "Epoch:70/200 AVG Training Loss:0.470 AVG Validation Loss:0.508 AVG Training Acc 80.90 % AVG Validation Acc 79.69 %\n",
      "Epoch    70: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.463 AVG Validation Loss:0.514 AVG Training Acc 80.99 % AVG Validation Acc 79.69 %\n",
      "Epoch:90/200 AVG Training Loss:0.464 AVG Validation Loss:0.514 AVG Training Acc 81.06 % AVG Validation Acc 79.69 %\n",
      "Epoch:100/200 AVG Training Loss:0.464 AVG Validation Loss:0.516 AVG Training Acc 81.15 % AVG Validation Acc 79.78 %\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.463 AVG Validation Loss:0.513 AVG Training Acc 81.24 % AVG Validation Acc 79.87 %\n",
      "Epoch:120/200 AVG Training Loss:0.464 AVG Validation Loss:0.516 AVG Training Acc 81.19 % AVG Validation Acc 79.69 %\n",
      "Epoch:130/200 AVG Training Loss:0.465 AVG Validation Loss:0.514 AVG Training Acc 81.14 % AVG Validation Acc 79.78 %\n",
      "Epoch   132: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.463 AVG Validation Loss:0.513 AVG Training Acc 81.04 % AVG Validation Acc 79.87 %\n",
      "Epoch:150/200 AVG Training Loss:0.462 AVG Validation Loss:0.516 AVG Training Acc 81.18 % AVG Validation Acc 79.87 %\n",
      "Epoch:160/200 AVG Training Loss:0.463 AVG Validation Loss:0.514 AVG Training Acc 81.13 % AVG Validation Acc 79.78 %\n",
      "Epoch   163: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.464 AVG Validation Loss:0.514 AVG Training Acc 81.11 % AVG Validation Acc 79.69 %\n",
      "Epoch:180/200 AVG Training Loss:0.464 AVG Validation Loss:0.514 AVG Training Acc 81.12 % AVG Validation Acc 79.69 %\n",
      "Epoch:190/200 AVG Training Loss:0.463 AVG Validation Loss:0.515 AVG Training Acc 81.13 % AVG Validation Acc 79.60 %\n",
      "Epoch   194: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.463 AVG Validation Loss:0.515 AVG Training Acc 81.24 % AVG Validation Acc 79.69 %\n",
      "Split 77\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6202e882f77d481ea0edffb99fcbef7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.498 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.487 AVG Validation Loss:0.498 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.475 AVG Validation Loss:0.504 AVG Training Acc 80.53 % AVG Validation Acc 79.87 %\n",
      "Epoch:50/200 AVG Training Loss:0.468 AVG Validation Loss:0.513 AVG Training Acc 80.74 % AVG Validation Acc 79.69 %\n",
      "Epoch:60/200 AVG Training Loss:0.461 AVG Validation Loss:0.524 AVG Training Acc 81.10 % AVG Validation Acc 79.60 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.459 AVG Validation Loss:0.524 AVG Training Acc 81.20 % AVG Validation Acc 79.69 %\n",
      "Epoch:80/200 AVG Training Loss:0.458 AVG Validation Loss:0.526 AVG Training Acc 81.12 % AVG Validation Acc 79.87 %\n",
      "Epoch:90/200 AVG Training Loss:0.457 AVG Validation Loss:0.530 AVG Training Acc 81.24 % AVG Validation Acc 79.87 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.457 AVG Validation Loss:0.530 AVG Training Acc 81.18 % AVG Validation Acc 79.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.457 AVG Validation Loss:0.529 AVG Training Acc 81.27 % AVG Validation Acc 79.78 %\n",
      "Epoch:120/200 AVG Training Loss:0.456 AVG Validation Loss:0.531 AVG Training Acc 81.25 % AVG Validation Acc 79.78 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.457 AVG Validation Loss:0.533 AVG Training Acc 81.17 % AVG Validation Acc 79.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.457 AVG Validation Loss:0.531 AVG Training Acc 81.12 % AVG Validation Acc 79.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.457 AVG Validation Loss:0.528 AVG Training Acc 81.14 % AVG Validation Acc 79.69 %\n",
      "Epoch:160/200 AVG Training Loss:0.457 AVG Validation Loss:0.529 AVG Training Acc 81.16 % AVG Validation Acc 79.78 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.457 AVG Validation Loss:0.531 AVG Training Acc 81.06 % AVG Validation Acc 79.78 %\n",
      "Epoch:180/200 AVG Training Loss:0.456 AVG Validation Loss:0.528 AVG Training Acc 81.25 % AVG Validation Acc 79.96 %\n",
      "Epoch:190/200 AVG Training Loss:0.457 AVG Validation Loss:0.529 AVG Training Acc 81.19 % AVG Validation Acc 79.87 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.456 AVG Validation Loss:0.531 AVG Training Acc 81.20 % AVG Validation Acc 79.78 %\n",
      "Split 78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bbcb05ba97a44558f88b897a707cfca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.497 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.492 AVG Training Acc 80.34 % AVG Validation Acc 80.23 %\n",
      "Epoch:50/200 AVG Training Loss:0.476 AVG Validation Loss:0.500 AVG Training Acc 80.53 % AVG Validation Acc 79.78 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.464 AVG Validation Loss:0.509 AVG Training Acc 80.83 % AVG Validation Acc 79.33 %\n",
      "Epoch:70/200 AVG Training Loss:0.456 AVG Validation Loss:0.525 AVG Training Acc 81.20 % AVG Validation Acc 79.51 %\n",
      "Epoch:80/200 AVG Training Loss:0.448 AVG Validation Loss:0.535 AVG Training Acc 81.44 % AVG Validation Acc 78.79 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.447 AVG Validation Loss:0.537 AVG Training Acc 81.43 % AVG Validation Acc 78.97 %\n",
      "Epoch:100/200 AVG Training Loss:0.448 AVG Validation Loss:0.537 AVG Training Acc 81.43 % AVG Validation Acc 78.52 %\n",
      "Epoch:110/200 AVG Training Loss:0.445 AVG Validation Loss:0.536 AVG Training Acc 81.57 % AVG Validation Acc 78.52 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.444 AVG Validation Loss:0.538 AVG Training Acc 81.60 % AVG Validation Acc 78.79 %\n",
      "Epoch:130/200 AVG Training Loss:0.443 AVG Validation Loss:0.540 AVG Training Acc 81.68 % AVG Validation Acc 78.52 %\n",
      "Epoch:140/200 AVG Training Loss:0.443 AVG Validation Loss:0.542 AVG Training Acc 81.57 % AVG Validation Acc 78.70 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.444 AVG Validation Loss:0.541 AVG Training Acc 81.72 % AVG Validation Acc 78.70 %\n",
      "Epoch:160/200 AVG Training Loss:0.445 AVG Validation Loss:0.541 AVG Training Acc 81.73 % AVG Validation Acc 78.70 %\n",
      "Epoch:170/200 AVG Training Loss:0.444 AVG Validation Loss:0.540 AVG Training Acc 81.51 % AVG Validation Acc 78.61 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.444 AVG Validation Loss:0.539 AVG Training Acc 81.66 % AVG Validation Acc 78.25 %\n",
      "Epoch:190/200 AVG Training Loss:0.444 AVG Validation Loss:0.538 AVG Training Acc 81.51 % AVG Validation Acc 78.43 %\n",
      "Epoch:200/200 AVG Training Loss:0.444 AVG Validation Loss:0.534 AVG Training Acc 81.61 % AVG Validation Acc 78.70 %\n",
      "Split 79\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c1d2cf81c484b21a70a70653bc64845",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.494 AVG Training Acc 80.29 % AVG Validation Acc 79.96 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.478 AVG Validation Loss:0.509 AVG Training Acc 80.46 % AVG Validation Acc 79.78 %\n",
      "Epoch:60/200 AVG Training Loss:0.471 AVG Validation Loss:0.520 AVG Training Acc 80.65 % AVG Validation Acc 79.51 %\n",
      "Epoch:70/200 AVG Training Loss:0.463 AVG Validation Loss:0.529 AVG Training Acc 80.71 % AVG Validation Acc 79.60 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.458 AVG Validation Loss:0.531 AVG Training Acc 80.73 % AVG Validation Acc 79.33 %\n",
      "Epoch:90/200 AVG Training Loss:0.458 AVG Validation Loss:0.533 AVG Training Acc 80.89 % AVG Validation Acc 79.24 %\n",
      "Epoch:100/200 AVG Training Loss:0.458 AVG Validation Loss:0.535 AVG Training Acc 80.97 % AVG Validation Acc 79.42 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.457 AVG Validation Loss:0.536 AVG Training Acc 80.97 % AVG Validation Acc 79.24 %\n",
      "Epoch:120/200 AVG Training Loss:0.456 AVG Validation Loss:0.535 AVG Training Acc 81.00 % AVG Validation Acc 79.42 %\n",
      "Epoch:130/200 AVG Training Loss:0.454 AVG Validation Loss:0.540 AVG Training Acc 80.97 % AVG Validation Acc 79.33 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.456 AVG Validation Loss:0.537 AVG Training Acc 80.98 % AVG Validation Acc 79.24 %\n",
      "Epoch:150/200 AVG Training Loss:0.455 AVG Validation Loss:0.534 AVG Training Acc 81.07 % AVG Validation Acc 79.42 %\n",
      "Epoch:160/200 AVG Training Loss:0.456 AVG Validation Loss:0.544 AVG Training Acc 80.93 % AVG Validation Acc 79.24 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.456 AVG Validation Loss:0.534 AVG Training Acc 80.96 % AVG Validation Acc 79.24 %\n",
      "Epoch:180/200 AVG Training Loss:0.457 AVG Validation Loss:0.542 AVG Training Acc 80.93 % AVG Validation Acc 79.42 %\n",
      "Epoch:190/200 AVG Training Loss:0.454 AVG Validation Loss:0.536 AVG Training Acc 80.86 % AVG Validation Acc 79.42 %\n",
      "Epoch   198: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.456 AVG Validation Loss:0.541 AVG Training Acc 80.98 % AVG Validation Acc 79.24 %\n",
      "Split 80\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d1305ffc5fa43a2956df31541da0f51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.482 AVG Validation Loss:0.501 AVG Training Acc 80.30 % AVG Validation Acc 79.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.478 AVG Validation Loss:0.503 AVG Training Acc 80.50 % AVG Validation Acc 79.78 %\n",
      "Epoch:50/200 AVG Training Loss:0.475 AVG Validation Loss:0.509 AVG Training Acc 80.52 % AVG Validation Acc 79.87 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.465 AVG Validation Loss:0.511 AVG Training Acc 80.88 % AVG Validation Acc 79.78 %\n",
      "Epoch:70/200 AVG Training Loss:0.463 AVG Validation Loss:0.517 AVG Training Acc 80.84 % AVG Validation Acc 79.69 %\n",
      "Epoch:80/200 AVG Training Loss:0.464 AVG Validation Loss:0.514 AVG Training Acc 80.95 % AVG Validation Acc 79.60 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.462 AVG Validation Loss:0.517 AVG Training Acc 81.04 % AVG Validation Acc 79.51 %\n",
      "Epoch:100/200 AVG Training Loss:0.463 AVG Validation Loss:0.518 AVG Training Acc 80.98 % AVG Validation Acc 79.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.464 AVG Validation Loss:0.520 AVG Training Acc 80.87 % AVG Validation Acc 79.51 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.462 AVG Validation Loss:0.519 AVG Training Acc 81.00 % AVG Validation Acc 79.60 %\n",
      "Epoch:130/200 AVG Training Loss:0.462 AVG Validation Loss:0.518 AVG Training Acc 80.94 % AVG Validation Acc 79.51 %\n",
      "Epoch:140/200 AVG Training Loss:0.462 AVG Validation Loss:0.519 AVG Training Acc 81.04 % AVG Validation Acc 79.33 %\n",
      "Epoch:150/200 AVG Training Loss:0.463 AVG Validation Loss:0.518 AVG Training Acc 80.85 % AVG Validation Acc 79.51 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.463 AVG Validation Loss:0.518 AVG Training Acc 80.84 % AVG Validation Acc 79.33 %\n",
      "Epoch:170/200 AVG Training Loss:0.462 AVG Validation Loss:0.520 AVG Training Acc 80.86 % AVG Validation Acc 79.51 %\n",
      "Epoch:180/200 AVG Training Loss:0.463 AVG Validation Loss:0.518 AVG Training Acc 80.81 % AVG Validation Acc 79.33 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.464 AVG Validation Loss:0.518 AVG Training Acc 80.91 % AVG Validation Acc 79.51 %\n",
      "Epoch:200/200 AVG Training Loss:0.464 AVG Validation Loss:0.521 AVG Training Acc 80.86 % AVG Validation Acc 79.33 %\n",
      "Split 81\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5603e6f5767345e9a4da54c975007f46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.492 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.483 AVG Validation Loss:0.487 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.477 AVG Validation Loss:0.488 AVG Training Acc 80.36 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.473 AVG Validation Loss:0.489 AVG Training Acc 80.51 % AVG Validation Acc 80.07 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.468 AVG Validation Loss:0.492 AVG Training Acc 80.59 % AVG Validation Acc 79.98 %\n",
      "Epoch:90/200 AVG Training Loss:0.466 AVG Validation Loss:0.493 AVG Training Acc 80.65 % AVG Validation Acc 79.98 %\n",
      "Epoch:100/200 AVG Training Loss:0.467 AVG Validation Loss:0.493 AVG Training Acc 80.72 % AVG Validation Acc 79.98 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.465 AVG Validation Loss:0.494 AVG Training Acc 80.74 % AVG Validation Acc 79.80 %\n",
      "Epoch:120/200 AVG Training Loss:0.466 AVG Validation Loss:0.494 AVG Training Acc 80.61 % AVG Validation Acc 79.89 %\n",
      "Epoch:130/200 AVG Training Loss:0.466 AVG Validation Loss:0.494 AVG Training Acc 80.79 % AVG Validation Acc 79.89 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.466 AVG Validation Loss:0.495 AVG Training Acc 80.80 % AVG Validation Acc 79.80 %\n",
      "Epoch:150/200 AVG Training Loss:0.466 AVG Validation Loss:0.494 AVG Training Acc 80.71 % AVG Validation Acc 79.89 %\n",
      "Epoch:160/200 AVG Training Loss:0.467 AVG Validation Loss:0.494 AVG Training Acc 80.58 % AVG Validation Acc 79.89 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.467 AVG Validation Loss:0.494 AVG Training Acc 80.52 % AVG Validation Acc 79.89 %\n",
      "Epoch:180/200 AVG Training Loss:0.466 AVG Validation Loss:0.492 AVG Training Acc 80.61 % AVG Validation Acc 79.80 %\n",
      "Epoch:190/200 AVG Training Loss:0.466 AVG Validation Loss:0.496 AVG Training Acc 80.60 % AVG Validation Acc 79.80 %\n",
      "Epoch:200/200 AVG Training Loss:0.466 AVG Validation Loss:0.493 AVG Training Acc 80.71 % AVG Validation Acc 79.89 %\n",
      "Epoch   200: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Split 82\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f809cfabaab4180b6bb18f686239aab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.23 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.485 AVG Validation Loss:0.492 AVG Training Acc 80.28 % AVG Validation Acc 80.16 %\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.474 AVG Validation Loss:0.495 AVG Training Acc 80.51 % AVG Validation Acc 80.07 %\n",
      "Epoch:60/200 AVG Training Loss:0.472 AVG Validation Loss:0.500 AVG Training Acc 80.67 % AVG Validation Acc 79.89 %\n",
      "Epoch:70/200 AVG Training Loss:0.466 AVG Validation Loss:0.502 AVG Training Acc 80.84 % AVG Validation Acc 79.71 %\n",
      "Epoch    71: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.461 AVG Validation Loss:0.503 AVG Training Acc 81.05 % AVG Validation Acc 79.62 %\n",
      "Epoch:90/200 AVG Training Loss:0.461 AVG Validation Loss:0.504 AVG Training Acc 81.07 % AVG Validation Acc 79.80 %\n",
      "Epoch:100/200 AVG Training Loss:0.461 AVG Validation Loss:0.507 AVG Training Acc 80.99 % AVG Validation Acc 79.62 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.460 AVG Validation Loss:0.504 AVG Training Acc 81.17 % AVG Validation Acc 79.80 %\n",
      "Epoch:120/200 AVG Training Loss:0.460 AVG Validation Loss:0.506 AVG Training Acc 81.05 % AVG Validation Acc 79.62 %\n",
      "Epoch:130/200 AVG Training Loss:0.461 AVG Validation Loss:0.504 AVG Training Acc 81.05 % AVG Validation Acc 79.62 %\n",
      "Epoch   133: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.462 AVG Validation Loss:0.505 AVG Training Acc 81.17 % AVG Validation Acc 79.80 %\n",
      "Epoch:150/200 AVG Training Loss:0.460 AVG Validation Loss:0.503 AVG Training Acc 81.12 % AVG Validation Acc 79.62 %\n",
      "Epoch:160/200 AVG Training Loss:0.460 AVG Validation Loss:0.505 AVG Training Acc 81.14 % AVG Validation Acc 79.71 %\n",
      "Epoch   164: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.462 AVG Validation Loss:0.505 AVG Training Acc 80.98 % AVG Validation Acc 79.71 %\n",
      "Epoch:180/200 AVG Training Loss:0.461 AVG Validation Loss:0.506 AVG Training Acc 81.10 % AVG Validation Acc 79.71 %\n",
      "Epoch:190/200 AVG Training Loss:0.460 AVG Validation Loss:0.505 AVG Training Acc 81.29 % AVG Validation Acc 79.71 %\n",
      "Epoch   195: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.460 AVG Validation Loss:0.503 AVG Training Acc 81.09 % AVG Validation Acc 79.71 %\n",
      "Split 83\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac925f2566d9490e8d742c2fd98f6220",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.487 AVG Validation Loss:0.498 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.472 AVG Validation Loss:0.502 AVG Training Acc 80.37 % AVG Validation Acc 79.71 %\n",
      "Epoch:50/200 AVG Training Loss:0.465 AVG Validation Loss:0.515 AVG Training Acc 80.78 % AVG Validation Acc 79.53 %\n",
      "Epoch:60/200 AVG Training Loss:0.459 AVG Validation Loss:0.518 AVG Training Acc 80.85 % AVG Validation Acc 79.44 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.453 AVG Validation Loss:0.519 AVG Training Acc 81.06 % AVG Validation Acc 79.44 %\n",
      "Epoch:80/200 AVG Training Loss:0.451 AVG Validation Loss:0.523 AVG Training Acc 81.05 % AVG Validation Acc 79.53 %\n",
      "Epoch:90/200 AVG Training Loss:0.451 AVG Validation Loss:0.522 AVG Training Acc 81.28 % AVG Validation Acc 79.44 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.451 AVG Validation Loss:0.521 AVG Training Acc 81.24 % AVG Validation Acc 79.17 %\n",
      "Epoch:110/200 AVG Training Loss:0.451 AVG Validation Loss:0.522 AVG Training Acc 81.32 % AVG Validation Acc 79.44 %\n",
      "Epoch:120/200 AVG Training Loss:0.450 AVG Validation Loss:0.521 AVG Training Acc 81.34 % AVG Validation Acc 79.44 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.450 AVG Validation Loss:0.523 AVG Training Acc 81.33 % AVG Validation Acc 79.44 %\n",
      "Epoch:140/200 AVG Training Loss:0.451 AVG Validation Loss:0.525 AVG Training Acc 81.13 % AVG Validation Acc 79.35 %\n",
      "Epoch:150/200 AVG Training Loss:0.451 AVG Validation Loss:0.520 AVG Training Acc 81.33 % AVG Validation Acc 79.35 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.449 AVG Validation Loss:0.525 AVG Training Acc 81.38 % AVG Validation Acc 79.35 %\n",
      "Epoch:170/200 AVG Training Loss:0.450 AVG Validation Loss:0.520 AVG Training Acc 81.13 % AVG Validation Acc 79.35 %\n",
      "Epoch:180/200 AVG Training Loss:0.450 AVG Validation Loss:0.522 AVG Training Acc 81.39 % AVG Validation Acc 79.26 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.451 AVG Validation Loss:0.526 AVG Training Acc 81.21 % AVG Validation Acc 79.26 %\n",
      "Epoch:200/200 AVG Training Loss:0.452 AVG Validation Loss:0.521 AVG Training Acc 81.26 % AVG Validation Acc 79.44 %\n",
      "Split 84\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "269ebecf160a43e6806d1ea7c3a9e33d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.18 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.483 AVG Validation Loss:0.495 AVG Training Acc 80.31 % AVG Validation Acc 80.25 %\n",
      "Epoch:40/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.28 % AVG Validation Acc 80.52 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.468 AVG Validation Loss:0.527 AVG Training Acc 80.88 % AVG Validation Acc 79.26 %\n",
      "Epoch:60/200 AVG Training Loss:0.461 AVG Validation Loss:0.542 AVG Training Acc 81.20 % AVG Validation Acc 78.90 %\n",
      "Epoch:70/200 AVG Training Loss:0.458 AVG Validation Loss:0.547 AVG Training Acc 81.40 % AVG Validation Acc 78.99 %\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.452 AVG Validation Loss:0.551 AVG Training Acc 81.59 % AVG Validation Acc 78.99 %\n",
      "Epoch:90/200 AVG Training Loss:0.451 AVG Validation Loss:0.553 AVG Training Acc 81.65 % AVG Validation Acc 79.08 %\n",
      "Epoch:100/200 AVG Training Loss:0.452 AVG Validation Loss:0.560 AVG Training Acc 81.61 % AVG Validation Acc 78.81 %\n",
      "Epoch   104: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.452 AVG Validation Loss:0.562 AVG Training Acc 81.60 % AVG Validation Acc 78.81 %\n",
      "Epoch:120/200 AVG Training Loss:0.452 AVG Validation Loss:0.562 AVG Training Acc 81.68 % AVG Validation Acc 78.81 %\n",
      "Epoch:130/200 AVG Training Loss:0.450 AVG Validation Loss:0.560 AVG Training Acc 81.64 % AVG Validation Acc 78.81 %\n",
      "Epoch   135: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.451 AVG Validation Loss:0.563 AVG Training Acc 81.58 % AVG Validation Acc 78.81 %\n",
      "Epoch:150/200 AVG Training Loss:0.453 AVG Validation Loss:0.560 AVG Training Acc 81.58 % AVG Validation Acc 78.81 %\n",
      "Epoch:160/200 AVG Training Loss:0.451 AVG Validation Loss:0.562 AVG Training Acc 81.60 % AVG Validation Acc 78.81 %\n",
      "Epoch   166: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.452 AVG Validation Loss:0.559 AVG Training Acc 81.58 % AVG Validation Acc 78.90 %\n",
      "Epoch:180/200 AVG Training Loss:0.450 AVG Validation Loss:0.561 AVG Training Acc 81.76 % AVG Validation Acc 78.81 %\n",
      "Epoch:190/200 AVG Training Loss:0.451 AVG Validation Loss:0.560 AVG Training Acc 81.63 % AVG Validation Acc 78.81 %\n",
      "Epoch   197: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.451 AVG Validation Loss:0.559 AVG Training Acc 81.73 % AVG Validation Acc 78.90 %\n",
      "Split 85\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ea0f1bebd8a48d5b468caf16a67cc4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.498 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.500 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.18 % AVG Validation Acc 79.89 %\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.29 % AVG Validation Acc 79.80 %\n",
      "Epoch:50/200 AVG Training Loss:0.482 AVG Validation Loss:0.499 AVG Training Acc 80.29 % AVG Validation Acc 79.89 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.480 AVG Validation Loss:0.500 AVG Training Acc 80.30 % AVG Validation Acc 79.71 %\n",
      "Epoch:70/200 AVG Training Loss:0.480 AVG Validation Loss:0.501 AVG Training Acc 80.32 % AVG Validation Acc 79.62 %\n",
      "Epoch:80/200 AVG Training Loss:0.480 AVG Validation Loss:0.502 AVG Training Acc 80.31 % AVG Validation Acc 79.80 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.479 AVG Validation Loss:0.502 AVG Training Acc 80.39 % AVG Validation Acc 79.80 %\n",
      "Epoch:100/200 AVG Training Loss:0.479 AVG Validation Loss:0.502 AVG Training Acc 80.37 % AVG Validation Acc 79.80 %\n",
      "Epoch:110/200 AVG Training Loss:0.479 AVG Validation Loss:0.502 AVG Training Acc 80.32 % AVG Validation Acc 79.80 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.479 AVG Validation Loss:0.502 AVG Training Acc 80.38 % AVG Validation Acc 79.80 %\n",
      "Epoch:130/200 AVG Training Loss:0.479 AVG Validation Loss:0.502 AVG Training Acc 80.35 % AVG Validation Acc 79.80 %\n",
      "Epoch:140/200 AVG Training Loss:0.479 AVG Validation Loss:0.502 AVG Training Acc 80.33 % AVG Validation Acc 79.80 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.479 AVG Validation Loss:0.502 AVG Training Acc 80.37 % AVG Validation Acc 79.80 %\n",
      "Epoch:160/200 AVG Training Loss:0.479 AVG Validation Loss:0.503 AVG Training Acc 80.38 % AVG Validation Acc 79.80 %\n",
      "Epoch:170/200 AVG Training Loss:0.480 AVG Validation Loss:0.502 AVG Training Acc 80.39 % AVG Validation Acc 79.80 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.479 AVG Validation Loss:0.502 AVG Training Acc 80.37 % AVG Validation Acc 79.80 %\n",
      "Epoch:190/200 AVG Training Loss:0.479 AVG Validation Loss:0.502 AVG Training Acc 80.45 % AVG Validation Acc 79.80 %\n",
      "Epoch:200/200 AVG Training Loss:0.479 AVG Validation Loss:0.502 AVG Training Acc 80.32 % AVG Validation Acc 79.80 %\n",
      "Split 86\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d0849ba68f04baa904c6d9e2f595b2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.25 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.491 AVG Training Acc 80.23 % AVG Validation Acc 79.87 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.471 AVG Validation Loss:0.492 AVG Training Acc 80.72 % AVG Validation Acc 79.51 %\n",
      "Epoch:60/200 AVG Training Loss:0.463 AVG Validation Loss:0.513 AVG Training Acc 80.75 % AVG Validation Acc 79.06 %\n",
      "Epoch:70/200 AVG Training Loss:0.457 AVG Validation Loss:0.518 AVG Training Acc 81.03 % AVG Validation Acc 79.06 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.452 AVG Validation Loss:0.525 AVG Training Acc 81.30 % AVG Validation Acc 78.70 %\n",
      "Epoch:90/200 AVG Training Loss:0.452 AVG Validation Loss:0.524 AVG Training Acc 81.14 % AVG Validation Acc 78.61 %\n",
      "Epoch:100/200 AVG Training Loss:0.451 AVG Validation Loss:0.528 AVG Training Acc 81.27 % AVG Validation Acc 78.70 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.449 AVG Validation Loss:0.526 AVG Training Acc 81.43 % AVG Validation Acc 78.61 %\n",
      "Epoch:120/200 AVG Training Loss:0.449 AVG Validation Loss:0.529 AVG Training Acc 81.47 % AVG Validation Acc 78.70 %\n",
      "Epoch:130/200 AVG Training Loss:0.448 AVG Validation Loss:0.529 AVG Training Acc 81.28 % AVG Validation Acc 78.52 %\n",
      "Epoch:140/200 AVG Training Loss:0.450 AVG Validation Loss:0.534 AVG Training Acc 81.30 % AVG Validation Acc 78.61 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.449 AVG Validation Loss:0.526 AVG Training Acc 81.29 % AVG Validation Acc 78.52 %\n",
      "Epoch:160/200 AVG Training Loss:0.449 AVG Validation Loss:0.531 AVG Training Acc 81.31 % AVG Validation Acc 78.43 %\n",
      "Epoch:170/200 AVG Training Loss:0.449 AVG Validation Loss:0.530 AVG Training Acc 81.29 % AVG Validation Acc 78.52 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.449 AVG Validation Loss:0.528 AVG Training Acc 81.36 % AVG Validation Acc 78.70 %\n",
      "Epoch:190/200 AVG Training Loss:0.449 AVG Validation Loss:0.530 AVG Training Acc 81.44 % AVG Validation Acc 78.70 %\n",
      "Epoch:200/200 AVG Training Loss:0.449 AVG Validation Loss:0.529 AVG Training Acc 81.50 % AVG Validation Acc 78.70 %\n",
      "Split 87\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27708bae60d5442387a20a15bfa40728",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.498 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.483 AVG Validation Loss:0.490 AVG Training Acc 80.34 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.478 AVG Validation Loss:0.496 AVG Training Acc 80.57 % AVG Validation Acc 80.05 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.475 AVG Validation Loss:0.496 AVG Training Acc 80.74 % AVG Validation Acc 80.23 %\n",
      "Epoch:80/200 AVG Training Loss:0.474 AVG Validation Loss:0.497 AVG Training Acc 80.85 % AVG Validation Acc 80.23 %\n",
      "Epoch:90/200 AVG Training Loss:0.474 AVG Validation Loss:0.496 AVG Training Acc 80.70 % AVG Validation Acc 80.23 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.474 AVG Validation Loss:0.498 AVG Training Acc 80.88 % AVG Validation Acc 80.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.473 AVG Validation Loss:0.497 AVG Training Acc 80.70 % AVG Validation Acc 80.32 %\n",
      "Epoch:120/200 AVG Training Loss:0.473 AVG Validation Loss:0.498 AVG Training Acc 80.77 % AVG Validation Acc 80.32 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.473 AVG Validation Loss:0.498 AVG Training Acc 80.88 % AVG Validation Acc 80.42 %\n",
      "Epoch:140/200 AVG Training Loss:0.474 AVG Validation Loss:0.500 AVG Training Acc 80.85 % AVG Validation Acc 79.87 %\n",
      "Epoch:150/200 AVG Training Loss:0.473 AVG Validation Loss:0.499 AVG Training Acc 80.76 % AVG Validation Acc 80.23 %\n",
      "Epoch:160/200 AVG Training Loss:0.472 AVG Validation Loss:0.500 AVG Training Acc 80.96 % AVG Validation Acc 79.87 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.471 AVG Validation Loss:0.496 AVG Training Acc 80.78 % AVG Validation Acc 80.32 %\n",
      "Epoch:180/200 AVG Training Loss:0.472 AVG Validation Loss:0.499 AVG Training Acc 80.88 % AVG Validation Acc 80.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.472 AVG Validation Loss:0.500 AVG Training Acc 80.89 % AVG Validation Acc 79.96 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.472 AVG Validation Loss:0.497 AVG Training Acc 80.85 % AVG Validation Acc 80.23 %\n",
      "Split 88\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5823d96446c40ac986cdeff8576f804",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.491 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.487 AVG Validation Loss:0.489 AVG Training Acc 80.25 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.06 % AVG Validation Acc 80.14 %\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.483 AVG Validation Loss:0.493 AVG Training Acc 80.23 % AVG Validation Acc 80.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.480 AVG Validation Loss:0.496 AVG Training Acc 80.30 % AVG Validation Acc 80.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.476 AVG Validation Loss:0.498 AVG Training Acc 80.40 % AVG Validation Acc 80.05 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.475 AVG Validation Loss:0.498 AVG Training Acc 80.45 % AVG Validation Acc 80.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.474 AVG Validation Loss:0.498 AVG Training Acc 80.47 % AVG Validation Acc 79.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.473 AVG Validation Loss:0.502 AVG Training Acc 80.48 % AVG Validation Acc 80.05 %\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.472 AVG Validation Loss:0.502 AVG Training Acc 80.38 % AVG Validation Acc 80.05 %\n",
      "Epoch:120/200 AVG Training Loss:0.474 AVG Validation Loss:0.500 AVG Training Acc 80.40 % AVG Validation Acc 80.05 %\n",
      "Epoch:130/200 AVG Training Loss:0.472 AVG Validation Loss:0.501 AVG Training Acc 80.41 % AVG Validation Acc 80.14 %\n",
      "Epoch   134: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.472 AVG Validation Loss:0.503 AVG Training Acc 80.41 % AVG Validation Acc 80.05 %\n",
      "Epoch:150/200 AVG Training Loss:0.471 AVG Validation Loss:0.501 AVG Training Acc 80.41 % AVG Validation Acc 79.96 %\n",
      "Epoch:160/200 AVG Training Loss:0.473 AVG Validation Loss:0.500 AVG Training Acc 80.44 % AVG Validation Acc 80.14 %\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.471 AVG Validation Loss:0.497 AVG Training Acc 80.50 % AVG Validation Acc 80.23 %\n",
      "Epoch:180/200 AVG Training Loss:0.471 AVG Validation Loss:0.501 AVG Training Acc 80.49 % AVG Validation Acc 80.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.473 AVG Validation Loss:0.499 AVG Training Acc 80.41 % AVG Validation Acc 80.23 %\n",
      "Epoch   196: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.471 AVG Validation Loss:0.499 AVG Training Acc 80.48 % AVG Validation Acc 80.14 %\n",
      "Split 89\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5baef1371a1c49dfa61c4889f76f1044",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.26 % AVG Validation Acc 80.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.491 AVG Training Acc 80.32 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.491 AVG Training Acc 80.40 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.482 AVG Validation Loss:0.492 AVG Training Acc 80.42 % AVG Validation Acc 80.05 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.478 AVG Validation Loss:0.503 AVG Training Acc 80.65 % AVG Validation Acc 79.78 %\n",
      "Epoch:80/200 AVG Training Loss:0.478 AVG Validation Loss:0.504 AVG Training Acc 80.57 % AVG Validation Acc 79.78 %\n",
      "Epoch:90/200 AVG Training Loss:0.478 AVG Validation Loss:0.505 AVG Training Acc 80.62 % AVG Validation Acc 79.78 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.477 AVG Validation Loss:0.507 AVG Training Acc 80.61 % AVG Validation Acc 79.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.477 AVG Validation Loss:0.508 AVG Training Acc 80.57 % AVG Validation Acc 79.69 %\n",
      "Epoch:120/200 AVG Training Loss:0.477 AVG Validation Loss:0.507 AVG Training Acc 80.67 % AVG Validation Acc 79.69 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.477 AVG Validation Loss:0.508 AVG Training Acc 80.51 % AVG Validation Acc 79.69 %\n",
      "Epoch:140/200 AVG Training Loss:0.477 AVG Validation Loss:0.507 AVG Training Acc 80.61 % AVG Validation Acc 79.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.476 AVG Validation Loss:0.509 AVG Training Acc 80.64 % AVG Validation Acc 79.60 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.477 AVG Validation Loss:0.508 AVG Training Acc 80.57 % AVG Validation Acc 79.69 %\n",
      "Epoch:170/200 AVG Training Loss:0.476 AVG Validation Loss:0.508 AVG Training Acc 80.65 % AVG Validation Acc 79.69 %\n",
      "Epoch:180/200 AVG Training Loss:0.477 AVG Validation Loss:0.507 AVG Training Acc 80.55 % AVG Validation Acc 79.60 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.476 AVG Validation Loss:0.509 AVG Training Acc 80.56 % AVG Validation Acc 79.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.476 AVG Validation Loss:0.506 AVG Training Acc 80.68 % AVG Validation Acc 79.78 %\n",
      "Split 90\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12873568b9e34fab84856f4db3ba972f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.496 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.490 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.26 % AVG Validation Acc 80.23 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.484 AVG Validation Loss:0.491 AVG Training Acc 80.27 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.473 AVG Validation Loss:0.496 AVG Training Acc 80.63 % AVG Validation Acc 79.78 %\n",
      "Epoch:70/200 AVG Training Loss:0.466 AVG Validation Loss:0.502 AVG Training Acc 80.89 % AVG Validation Acc 79.87 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.460 AVG Validation Loss:0.507 AVG Training Acc 81.08 % AVG Validation Acc 79.87 %\n",
      "Epoch:90/200 AVG Training Loss:0.459 AVG Validation Loss:0.506 AVG Training Acc 81.14 % AVG Validation Acc 79.78 %\n",
      "Epoch:100/200 AVG Training Loss:0.456 AVG Validation Loss:0.510 AVG Training Acc 81.25 % AVG Validation Acc 79.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.454 AVG Validation Loss:0.511 AVG Training Acc 81.20 % AVG Validation Acc 79.87 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.455 AVG Validation Loss:0.517 AVG Training Acc 81.18 % AVG Validation Acc 79.78 %\n",
      "Epoch:130/200 AVG Training Loss:0.455 AVG Validation Loss:0.510 AVG Training Acc 81.06 % AVG Validation Acc 79.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.455 AVG Validation Loss:0.513 AVG Training Acc 81.24 % AVG Validation Acc 79.96 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.456 AVG Validation Loss:0.508 AVG Training Acc 81.16 % AVG Validation Acc 79.78 %\n",
      "Epoch:160/200 AVG Training Loss:0.456 AVG Validation Loss:0.514 AVG Training Acc 81.12 % AVG Validation Acc 79.51 %\n",
      "Epoch:170/200 AVG Training Loss:0.454 AVG Validation Loss:0.512 AVG Training Acc 81.15 % AVG Validation Acc 79.78 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.457 AVG Validation Loss:0.512 AVG Training Acc 81.13 % AVG Validation Acc 79.78 %\n",
      "Epoch:190/200 AVG Training Loss:0.455 AVG Validation Loss:0.512 AVG Training Acc 81.10 % AVG Validation Acc 79.78 %\n",
      "Epoch:200/200 AVG Training Loss:0.455 AVG Validation Loss:0.513 AVG Training Acc 81.20 % AVG Validation Acc 79.69 %\n",
      "Split 91\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "136a0d154d1d403e91202b0b23c2fa35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.496 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.483 AVG Validation Loss:0.494 AVG Training Acc 80.40 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.478 AVG Validation Loss:0.499 AVG Training Acc 80.57 % AVG Validation Acc 79.71 %\n",
      "Epoch:50/200 AVG Training Loss:0.473 AVG Validation Loss:0.503 AVG Training Acc 80.70 % AVG Validation Acc 79.44 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.469 AVG Validation Loss:0.515 AVG Training Acc 80.90 % AVG Validation Acc 79.26 %\n",
      "Epoch:70/200 AVG Training Loss:0.467 AVG Validation Loss:0.516 AVG Training Acc 80.94 % AVG Validation Acc 79.26 %\n",
      "Epoch:80/200 AVG Training Loss:0.466 AVG Validation Loss:0.519 AVG Training Acc 81.03 % AVG Validation Acc 79.17 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.466 AVG Validation Loss:0.520 AVG Training Acc 80.89 % AVG Validation Acc 79.17 %\n",
      "Epoch:100/200 AVG Training Loss:0.466 AVG Validation Loss:0.513 AVG Training Acc 80.98 % AVG Validation Acc 79.17 %\n",
      "Epoch:110/200 AVG Training Loss:0.465 AVG Validation Loss:0.519 AVG Training Acc 81.03 % AVG Validation Acc 79.17 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.466 AVG Validation Loss:0.521 AVG Training Acc 80.94 % AVG Validation Acc 79.17 %\n",
      "Epoch:130/200 AVG Training Loss:0.465 AVG Validation Loss:0.517 AVG Training Acc 81.03 % AVG Validation Acc 79.26 %\n",
      "Epoch:140/200 AVG Training Loss:0.466 AVG Validation Loss:0.519 AVG Training Acc 80.88 % AVG Validation Acc 79.17 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.467 AVG Validation Loss:0.520 AVG Training Acc 80.95 % AVG Validation Acc 79.17 %\n",
      "Epoch:160/200 AVG Training Loss:0.465 AVG Validation Loss:0.519 AVG Training Acc 81.08 % AVG Validation Acc 79.17 %\n",
      "Epoch:170/200 AVG Training Loss:0.467 AVG Validation Loss:0.519 AVG Training Acc 80.97 % AVG Validation Acc 79.26 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.465 AVG Validation Loss:0.519 AVG Training Acc 81.02 % AVG Validation Acc 79.17 %\n",
      "Epoch:190/200 AVG Training Loss:0.466 AVG Validation Loss:0.518 AVG Training Acc 81.04 % AVG Validation Acc 79.17 %\n",
      "Epoch:200/200 AVG Training Loss:0.466 AVG Validation Loss:0.519 AVG Training Acc 80.97 % AVG Validation Acc 79.17 %\n",
      "Split 92\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ca9000be62c4abf86767044ebd1251d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.479 AVG Validation Loss:0.495 AVG Training Acc 80.31 % AVG Validation Acc 80.16 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.478 AVG Validation Loss:0.494 AVG Training Acc 80.37 % AVG Validation Acc 80.34 %\n",
      "Epoch:60/200 AVG Training Loss:0.459 AVG Validation Loss:0.510 AVG Training Acc 80.71 % AVG Validation Acc 79.62 %\n",
      "Epoch:70/200 AVG Training Loss:0.451 AVG Validation Loss:0.527 AVG Training Acc 81.02 % AVG Validation Acc 79.08 %\n",
      "Epoch:80/200 AVG Training Loss:0.444 AVG Validation Loss:0.537 AVG Training Acc 81.20 % AVG Validation Acc 78.36 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.438 AVG Validation Loss:0.544 AVG Training Acc 81.70 % AVG Validation Acc 78.36 %\n",
      "Epoch:100/200 AVG Training Loss:0.436 AVG Validation Loss:0.544 AVG Training Acc 81.51 % AVG Validation Acc 77.91 %\n",
      "Epoch:110/200 AVG Training Loss:0.435 AVG Validation Loss:0.546 AVG Training Acc 81.67 % AVG Validation Acc 77.46 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.437 AVG Validation Loss:0.552 AVG Training Acc 81.38 % AVG Validation Acc 77.64 %\n",
      "Epoch:130/200 AVG Training Loss:0.434 AVG Validation Loss:0.552 AVG Training Acc 81.62 % AVG Validation Acc 77.46 %\n",
      "Epoch:140/200 AVG Training Loss:0.438 AVG Validation Loss:0.549 AVG Training Acc 81.24 % AVG Validation Acc 77.46 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.435 AVG Validation Loss:0.548 AVG Training Acc 81.64 % AVG Validation Acc 77.73 %\n",
      "Epoch:160/200 AVG Training Loss:0.433 AVG Validation Loss:0.552 AVG Training Acc 81.51 % AVG Validation Acc 77.73 %\n",
      "Epoch:170/200 AVG Training Loss:0.435 AVG Validation Loss:0.556 AVG Training Acc 81.36 % AVG Validation Acc 77.55 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.437 AVG Validation Loss:0.548 AVG Training Acc 81.52 % AVG Validation Acc 77.73 %\n",
      "Epoch:190/200 AVG Training Loss:0.434 AVG Validation Loss:0.553 AVG Training Acc 81.30 % AVG Validation Acc 77.73 %\n",
      "Epoch:200/200 AVG Training Loss:0.434 AVG Validation Loss:0.557 AVG Training Acc 81.49 % AVG Validation Acc 77.64 %\n",
      "Split 93\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1025f95fb808494aa6c6af9babd6c956",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.485 AVG Validation Loss:0.492 AVG Training Acc 80.20 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.482 AVG Validation Loss:0.497 AVG Training Acc 80.23 % AVG Validation Acc 80.16 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.477 AVG Validation Loss:0.501 AVG Training Acc 80.52 % AVG Validation Acc 79.98 %\n",
      "Epoch:70/200 AVG Training Loss:0.476 AVG Validation Loss:0.504 AVG Training Acc 80.60 % AVG Validation Acc 80.16 %\n",
      "Epoch:80/200 AVG Training Loss:0.476 AVG Validation Loss:0.506 AVG Training Acc 80.61 % AVG Validation Acc 79.98 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.475 AVG Validation Loss:0.508 AVG Training Acc 80.54 % AVG Validation Acc 79.89 %\n",
      "Epoch:100/200 AVG Training Loss:0.475 AVG Validation Loss:0.508 AVG Training Acc 80.56 % AVG Validation Acc 80.07 %\n",
      "Epoch:110/200 AVG Training Loss:0.474 AVG Validation Loss:0.509 AVG Training Acc 80.61 % AVG Validation Acc 79.89 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.476 AVG Validation Loss:0.509 AVG Training Acc 80.51 % AVG Validation Acc 79.98 %\n",
      "Epoch:130/200 AVG Training Loss:0.474 AVG Validation Loss:0.509 AVG Training Acc 80.63 % AVG Validation Acc 79.89 %\n",
      "Epoch:140/200 AVG Training Loss:0.475 AVG Validation Loss:0.509 AVG Training Acc 80.57 % AVG Validation Acc 79.89 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.475 AVG Validation Loss:0.509 AVG Training Acc 80.55 % AVG Validation Acc 79.89 %\n",
      "Epoch:160/200 AVG Training Loss:0.476 AVG Validation Loss:0.509 AVG Training Acc 80.57 % AVG Validation Acc 79.98 %\n",
      "Epoch:170/200 AVG Training Loss:0.474 AVG Validation Loss:0.509 AVG Training Acc 80.59 % AVG Validation Acc 79.98 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.475 AVG Validation Loss:0.509 AVG Training Acc 80.58 % AVG Validation Acc 79.98 %\n",
      "Epoch:190/200 AVG Training Loss:0.475 AVG Validation Loss:0.509 AVG Training Acc 80.56 % AVG Validation Acc 79.89 %\n",
      "Epoch:200/200 AVG Training Loss:0.474 AVG Validation Loss:0.509 AVG Training Acc 80.65 % AVG Validation Acc 79.98 %\n",
      "Split 94\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d8ffedd03b14c4095bb40c6716078a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.500 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.500 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.502 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.504 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.483 AVG Validation Loss:0.506 AVG Training Acc 80.20 % AVG Validation Acc 80.16 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.481 AVG Validation Loss:0.505 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.481 AVG Validation Loss:0.506 AVG Training Acc 80.24 % AVG Validation Acc 80.07 %\n",
      "Epoch:80/200 AVG Training Loss:0.480 AVG Validation Loss:0.507 AVG Training Acc 80.25 % AVG Validation Acc 80.07 %\n",
      "Epoch:90/200 AVG Training Loss:0.480 AVG Validation Loss:0.508 AVG Training Acc 80.21 % AVG Validation Acc 80.07 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.480 AVG Validation Loss:0.508 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch:110/200 AVG Training Loss:0.480 AVG Validation Loss:0.508 AVG Training Acc 80.25 % AVG Validation Acc 80.07 %\n",
      "Epoch:120/200 AVG Training Loss:0.479 AVG Validation Loss:0.508 AVG Training Acc 80.24 % AVG Validation Acc 80.07 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.479 AVG Validation Loss:0.508 AVG Training Acc 80.21 % AVG Validation Acc 80.07 %\n",
      "Epoch:140/200 AVG Training Loss:0.480 AVG Validation Loss:0.508 AVG Training Acc 80.26 % AVG Validation Acc 80.07 %\n",
      "Epoch:150/200 AVG Training Loss:0.480 AVG Validation Loss:0.508 AVG Training Acc 80.20 % AVG Validation Acc 80.07 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.479 AVG Validation Loss:0.508 AVG Training Acc 80.23 % AVG Validation Acc 80.07 %\n",
      "Epoch:170/200 AVG Training Loss:0.478 AVG Validation Loss:0.508 AVG Training Acc 80.25 % AVG Validation Acc 80.07 %\n",
      "Epoch:180/200 AVG Training Loss:0.479 AVG Validation Loss:0.509 AVG Training Acc 80.25 % AVG Validation Acc 80.07 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.479 AVG Validation Loss:0.508 AVG Training Acc 80.24 % AVG Validation Acc 80.07 %\n",
      "Epoch:200/200 AVG Training Loss:0.480 AVG Validation Loss:0.508 AVG Training Acc 80.23 % AVG Validation Acc 80.07 %\n",
      "Split 95\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dafc40481964e21a3358986cc492ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.484 AVG Validation Loss:0.490 AVG Training Acc 80.28 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.479 AVG Validation Loss:0.490 AVG Training Acc 80.52 % AVG Validation Acc 80.25 %\n",
      "Epoch:50/200 AVG Training Loss:0.475 AVG Validation Loss:0.495 AVG Training Acc 80.72 % AVG Validation Acc 79.80 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.472 AVG Validation Loss:0.501 AVG Training Acc 80.80 % AVG Validation Acc 79.62 %\n",
      "Epoch:70/200 AVG Training Loss:0.474 AVG Validation Loss:0.500 AVG Training Acc 80.80 % AVG Validation Acc 79.44 %\n",
      "Epoch:80/200 AVG Training Loss:0.472 AVG Validation Loss:0.498 AVG Training Acc 80.84 % AVG Validation Acc 79.62 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.471 AVG Validation Loss:0.500 AVG Training Acc 80.94 % AVG Validation Acc 79.53 %\n",
      "Epoch:100/200 AVG Training Loss:0.472 AVG Validation Loss:0.499 AVG Training Acc 80.83 % AVG Validation Acc 79.35 %\n",
      "Epoch:110/200 AVG Training Loss:0.471 AVG Validation Loss:0.501 AVG Training Acc 81.00 % AVG Validation Acc 79.44 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.470 AVG Validation Loss:0.505 AVG Training Acc 80.85 % AVG Validation Acc 79.17 %\n",
      "Epoch:130/200 AVG Training Loss:0.470 AVG Validation Loss:0.500 AVG Training Acc 80.85 % AVG Validation Acc 79.35 %\n",
      "Epoch:140/200 AVG Training Loss:0.470 AVG Validation Loss:0.503 AVG Training Acc 80.90 % AVG Validation Acc 79.35 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.470 AVG Validation Loss:0.499 AVG Training Acc 80.97 % AVG Validation Acc 79.71 %\n",
      "Epoch:160/200 AVG Training Loss:0.471 AVG Validation Loss:0.501 AVG Training Acc 80.85 % AVG Validation Acc 79.44 %\n",
      "Epoch:170/200 AVG Training Loss:0.470 AVG Validation Loss:0.504 AVG Training Acc 80.91 % AVG Validation Acc 79.35 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.471 AVG Validation Loss:0.503 AVG Training Acc 80.96 % AVG Validation Acc 79.26 %\n",
      "Epoch:190/200 AVG Training Loss:0.471 AVG Validation Loss:0.503 AVG Training Acc 80.91 % AVG Validation Acc 79.26 %\n",
      "Epoch:200/200 AVG Training Loss:0.471 AVG Validation Loss:0.499 AVG Training Acc 80.83 % AVG Validation Acc 79.26 %\n",
      "Split 96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73810bc7f78b4e7da97f00a97a98d9e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.491 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.489 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.483 AVG Validation Loss:0.485 AVG Training Acc 80.38 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.479 AVG Validation Loss:0.486 AVG Training Acc 80.55 % AVG Validation Acc 80.23 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.465 AVG Validation Loss:0.499 AVG Training Acc 80.93 % AVG Validation Acc 79.51 %\n",
      "Epoch:70/200 AVG Training Loss:0.461 AVG Validation Loss:0.518 AVG Training Acc 81.04 % AVG Validation Acc 79.42 %\n",
      "Epoch:80/200 AVG Training Loss:0.454 AVG Validation Loss:0.531 AVG Training Acc 81.11 % AVG Validation Acc 79.06 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.451 AVG Validation Loss:0.526 AVG Training Acc 81.38 % AVG Validation Acc 79.15 %\n",
      "Epoch:100/200 AVG Training Loss:0.450 AVG Validation Loss:0.531 AVG Training Acc 81.48 % AVG Validation Acc 79.24 %\n",
      "Epoch:110/200 AVG Training Loss:0.448 AVG Validation Loss:0.531 AVG Training Acc 81.38 % AVG Validation Acc 78.97 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.447 AVG Validation Loss:0.525 AVG Training Acc 81.39 % AVG Validation Acc 79.06 %\n",
      "Epoch:130/200 AVG Training Loss:0.449 AVG Validation Loss:0.529 AVG Training Acc 81.55 % AVG Validation Acc 79.06 %\n",
      "Epoch:140/200 AVG Training Loss:0.448 AVG Validation Loss:0.530 AVG Training Acc 81.38 % AVG Validation Acc 78.97 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.450 AVG Validation Loss:0.525 AVG Training Acc 81.36 % AVG Validation Acc 79.06 %\n",
      "Epoch:160/200 AVG Training Loss:0.448 AVG Validation Loss:0.531 AVG Training Acc 81.42 % AVG Validation Acc 79.06 %\n",
      "Epoch:170/200 AVG Training Loss:0.449 AVG Validation Loss:0.531 AVG Training Acc 81.40 % AVG Validation Acc 79.06 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.447 AVG Validation Loss:0.525 AVG Training Acc 81.44 % AVG Validation Acc 79.06 %\n",
      "Epoch:190/200 AVG Training Loss:0.448 AVG Validation Loss:0.527 AVG Training Acc 81.38 % AVG Validation Acc 78.97 %\n",
      "Epoch:200/200 AVG Training Loss:0.447 AVG Validation Loss:0.528 AVG Training Acc 81.52 % AVG Validation Acc 79.15 %\n",
      "Split 97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05e59006370945d5a22d40c672af245e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.492 AVG Training Acc 80.16 % AVG Validation Acc 80.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.477 AVG Validation Loss:0.485 AVG Training Acc 80.48 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.472 AVG Validation Loss:0.489 AVG Training Acc 80.57 % AVG Validation Acc 79.96 %\n",
      "Epoch:60/200 AVG Training Loss:0.465 AVG Validation Loss:0.500 AVG Training Acc 80.94 % AVG Validation Acc 79.87 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.462 AVG Validation Loss:0.497 AVG Training Acc 81.01 % AVG Validation Acc 80.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.461 AVG Validation Loss:0.506 AVG Training Acc 80.93 % AVG Validation Acc 80.05 %\n",
      "Epoch:90/200 AVG Training Loss:0.459 AVG Validation Loss:0.511 AVG Training Acc 81.11 % AVG Validation Acc 80.05 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.458 AVG Validation Loss:0.511 AVG Training Acc 80.98 % AVG Validation Acc 79.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.459 AVG Validation Loss:0.512 AVG Training Acc 81.14 % AVG Validation Acc 79.87 %\n",
      "Epoch:120/200 AVG Training Loss:0.460 AVG Validation Loss:0.514 AVG Training Acc 81.07 % AVG Validation Acc 79.78 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.459 AVG Validation Loss:0.515 AVG Training Acc 81.04 % AVG Validation Acc 79.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.458 AVG Validation Loss:0.502 AVG Training Acc 81.11 % AVG Validation Acc 79.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.458 AVG Validation Loss:0.514 AVG Training Acc 81.15 % AVG Validation Acc 79.69 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.457 AVG Validation Loss:0.512 AVG Training Acc 80.98 % AVG Validation Acc 79.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.459 AVG Validation Loss:0.515 AVG Training Acc 81.04 % AVG Validation Acc 79.87 %\n",
      "Epoch:180/200 AVG Training Loss:0.457 AVG Validation Loss:0.504 AVG Training Acc 81.05 % AVG Validation Acc 80.05 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.459 AVG Validation Loss:0.512 AVG Training Acc 81.05 % AVG Validation Acc 79.96 %\n",
      "Epoch:200/200 AVG Training Loss:0.457 AVG Validation Loss:0.510 AVG Training Acc 81.04 % AVG Validation Acc 79.87 %\n",
      "Split 98\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66370275f8f8404bb17914a4d0192fa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.499 AVG Validation Loss:0.503 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.19 % AVG Validation Acc 80.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.494 AVG Training Acc 80.23 % AVG Validation Acc 79.96 %\n",
      "Epoch:50/200 AVG Training Loss:0.481 AVG Validation Loss:0.493 AVG Training Acc 80.34 % AVG Validation Acc 79.96 %\n",
      "Epoch:60/200 AVG Training Loss:0.480 AVG Validation Loss:0.494 AVG Training Acc 80.30 % AVG Validation Acc 79.96 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.476 AVG Validation Loss:0.493 AVG Training Acc 80.45 % AVG Validation Acc 79.87 %\n",
      "Epoch:80/200 AVG Training Loss:0.477 AVG Validation Loss:0.492 AVG Training Acc 80.40 % AVG Validation Acc 79.87 %\n",
      "Epoch:90/200 AVG Training Loss:0.476 AVG Validation Loss:0.493 AVG Training Acc 80.44 % AVG Validation Acc 79.87 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.475 AVG Validation Loss:0.493 AVG Training Acc 80.49 % AVG Validation Acc 79.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.475 AVG Validation Loss:0.493 AVG Training Acc 80.54 % AVG Validation Acc 79.96 %\n",
      "Epoch:120/200 AVG Training Loss:0.475 AVG Validation Loss:0.493 AVG Training Acc 80.38 % AVG Validation Acc 79.87 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.476 AVG Validation Loss:0.494 AVG Training Acc 80.47 % AVG Validation Acc 79.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.476 AVG Validation Loss:0.494 AVG Training Acc 80.41 % AVG Validation Acc 79.87 %\n",
      "Epoch:150/200 AVG Training Loss:0.475 AVG Validation Loss:0.493 AVG Training Acc 80.39 % AVG Validation Acc 79.87 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.476 AVG Validation Loss:0.493 AVG Training Acc 80.47 % AVG Validation Acc 79.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.475 AVG Validation Loss:0.494 AVG Training Acc 80.45 % AVG Validation Acc 79.87 %\n",
      "Epoch:180/200 AVG Training Loss:0.475 AVG Validation Loss:0.493 AVG Training Acc 80.47 % AVG Validation Acc 79.87 %\n",
      "Epoch:190/200 AVG Training Loss:0.475 AVG Validation Loss:0.492 AVG Training Acc 80.46 % AVG Validation Acc 79.87 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.475 AVG Validation Loss:0.493 AVG Training Acc 80.45 % AVG Validation Acc 79.87 %\n",
      "Split 99\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12314db694d14c18921db2d6ceb129cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.09 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.27 % AVG Validation Acc 80.05 %\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.481 AVG Validation Loss:0.503 AVG Training Acc 80.42 % AVG Validation Acc 79.87 %\n",
      "Epoch:50/200 AVG Training Loss:0.479 AVG Validation Loss:0.511 AVG Training Acc 80.39 % AVG Validation Acc 79.69 %\n",
      "Epoch:60/200 AVG Training Loss:0.473 AVG Validation Loss:0.525 AVG Training Acc 80.53 % AVG Validation Acc 79.51 %\n",
      "Epoch:70/200 AVG Training Loss:0.471 AVG Validation Loss:0.532 AVG Training Acc 80.54 % AVG Validation Acc 79.60 %\n",
      "Epoch    70: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.468 AVG Validation Loss:0.535 AVG Training Acc 80.64 % AVG Validation Acc 79.51 %\n",
      "Epoch:90/200 AVG Training Loss:0.468 AVG Validation Loss:0.539 AVG Training Acc 80.63 % AVG Validation Acc 79.51 %\n",
      "Epoch:100/200 AVG Training Loss:0.468 AVG Validation Loss:0.538 AVG Training Acc 80.61 % AVG Validation Acc 79.51 %\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.467 AVG Validation Loss:0.540 AVG Training Acc 80.66 % AVG Validation Acc 79.51 %\n",
      "Epoch:120/200 AVG Training Loss:0.468 AVG Validation Loss:0.541 AVG Training Acc 80.62 % AVG Validation Acc 79.60 %\n",
      "Epoch:130/200 AVG Training Loss:0.468 AVG Validation Loss:0.541 AVG Training Acc 80.61 % AVG Validation Acc 79.51 %\n",
      "Epoch   132: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.467 AVG Validation Loss:0.541 AVG Training Acc 80.63 % AVG Validation Acc 79.51 %\n",
      "Epoch:150/200 AVG Training Loss:0.467 AVG Validation Loss:0.541 AVG Training Acc 80.64 % AVG Validation Acc 79.51 %\n",
      "Epoch:160/200 AVG Training Loss:0.467 AVG Validation Loss:0.540 AVG Training Acc 80.64 % AVG Validation Acc 79.51 %\n",
      "Epoch   163: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.468 AVG Validation Loss:0.541 AVG Training Acc 80.58 % AVG Validation Acc 79.51 %\n",
      "Epoch:180/200 AVG Training Loss:0.468 AVG Validation Loss:0.540 AVG Training Acc 80.67 % AVG Validation Acc 79.51 %\n",
      "Epoch:190/200 AVG Training Loss:0.467 AVG Validation Loss:0.541 AVG Training Acc 80.66 % AVG Validation Acc 79.51 %\n",
      "Epoch   194: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.468 AVG Validation Loss:0.541 AVG Training Acc 80.58 % AVG Validation Acc 79.51 %\n",
      "Split 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f122b3d85329453b91f84814fde75afd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.487 AVG Validation Loss:0.498 AVG Training Acc 80.26 % AVG Validation Acc 80.14 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.478 AVG Validation Loss:0.502 AVG Training Acc 80.50 % AVG Validation Acc 79.60 %\n",
      "Epoch:50/200 AVG Training Loss:0.470 AVG Validation Loss:0.506 AVG Training Acc 80.75 % AVG Validation Acc 79.06 %\n",
      "Epoch:60/200 AVG Training Loss:0.466 AVG Validation Loss:0.518 AVG Training Acc 80.98 % AVG Validation Acc 79.24 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.462 AVG Validation Loss:0.520 AVG Training Acc 81.03 % AVG Validation Acc 79.06 %\n",
      "Epoch:80/200 AVG Training Loss:0.459 AVG Validation Loss:0.518 AVG Training Acc 81.13 % AVG Validation Acc 79.06 %\n",
      "Epoch:90/200 AVG Training Loss:0.460 AVG Validation Loss:0.524 AVG Training Acc 80.94 % AVG Validation Acc 78.97 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.458 AVG Validation Loss:0.523 AVG Training Acc 81.06 % AVG Validation Acc 79.15 %\n",
      "Epoch:110/200 AVG Training Loss:0.460 AVG Validation Loss:0.520 AVG Training Acc 81.09 % AVG Validation Acc 79.42 %\n",
      "Epoch:120/200 AVG Training Loss:0.459 AVG Validation Loss:0.519 AVG Training Acc 81.09 % AVG Validation Acc 79.51 %\n",
      "Epoch:130/200 AVG Training Loss:0.457 AVG Validation Loss:0.518 AVG Training Acc 81.15 % AVG Validation Acc 79.15 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.457 AVG Validation Loss:0.518 AVG Training Acc 81.20 % AVG Validation Acc 79.24 %\n",
      "Epoch:150/200 AVG Training Loss:0.461 AVG Validation Loss:0.517 AVG Training Acc 81.09 % AVG Validation Acc 79.15 %\n",
      "Epoch:160/200 AVG Training Loss:0.459 AVG Validation Loss:0.517 AVG Training Acc 81.05 % AVG Validation Acc 79.06 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.457 AVG Validation Loss:0.520 AVG Training Acc 81.23 % AVG Validation Acc 79.15 %\n",
      "Epoch:180/200 AVG Training Loss:0.458 AVG Validation Loss:0.519 AVG Training Acc 81.01 % AVG Validation Acc 79.24 %\n",
      "Epoch:190/200 AVG Training Loss:0.458 AVG Validation Loss:0.525 AVG Training Acc 80.99 % AVG Validation Acc 79.33 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.459 AVG Validation Loss:0.523 AVG Training Acc 81.13 % AVG Validation Acc 79.15 %\n",
      "Split 101\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fe99d737e734c4694f159bf8fddc620",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.491 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.491 AVG Training Acc 80.23 % AVG Validation Acc 80.16 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.477 AVG Validation Loss:0.493 AVG Training Acc 80.50 % AVG Validation Acc 79.89 %\n",
      "Epoch:60/200 AVG Training Loss:0.471 AVG Validation Loss:0.495 AVG Training Acc 80.60 % AVG Validation Acc 79.98 %\n",
      "Epoch:70/200 AVG Training Loss:0.466 AVG Validation Loss:0.497 AVG Training Acc 80.80 % AVG Validation Acc 79.89 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.462 AVG Validation Loss:0.500 AVG Training Acc 81.01 % AVG Validation Acc 79.53 %\n",
      "Epoch:90/200 AVG Training Loss:0.461 AVG Validation Loss:0.502 AVG Training Acc 81.14 % AVG Validation Acc 79.44 %\n",
      "Epoch:100/200 AVG Training Loss:0.461 AVG Validation Loss:0.504 AVG Training Acc 81.15 % AVG Validation Acc 79.53 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.460 AVG Validation Loss:0.504 AVG Training Acc 81.19 % AVG Validation Acc 79.26 %\n",
      "Epoch:120/200 AVG Training Loss:0.458 AVG Validation Loss:0.504 AVG Training Acc 81.10 % AVG Validation Acc 79.44 %\n",
      "Epoch:130/200 AVG Training Loss:0.460 AVG Validation Loss:0.507 AVG Training Acc 81.09 % AVG Validation Acc 79.35 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.459 AVG Validation Loss:0.505 AVG Training Acc 81.03 % AVG Validation Acc 79.26 %\n",
      "Epoch:150/200 AVG Training Loss:0.459 AVG Validation Loss:0.505 AVG Training Acc 81.26 % AVG Validation Acc 79.26 %\n",
      "Epoch:160/200 AVG Training Loss:0.460 AVG Validation Loss:0.505 AVG Training Acc 81.23 % AVG Validation Acc 79.35 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.458 AVG Validation Loss:0.506 AVG Training Acc 81.29 % AVG Validation Acc 79.35 %\n",
      "Epoch:180/200 AVG Training Loss:0.457 AVG Validation Loss:0.506 AVG Training Acc 81.21 % AVG Validation Acc 79.35 %\n",
      "Epoch:190/200 AVG Training Loss:0.458 AVG Validation Loss:0.505 AVG Training Acc 81.17 % AVG Validation Acc 79.26 %\n",
      "Epoch:200/200 AVG Training Loss:0.458 AVG Validation Loss:0.505 AVG Training Acc 81.36 % AVG Validation Acc 79.17 %\n",
      "Epoch   200: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Split 102\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "978e0d2205e04c8685ff83a17dc1a7cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.24 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.40 % AVG Validation Acc 80.07 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.480 AVG Validation Loss:0.498 AVG Training Acc 80.31 % AVG Validation Acc 79.71 %\n",
      "Epoch:50/200 AVG Training Loss:0.474 AVG Validation Loss:0.505 AVG Training Acc 80.44 % AVG Validation Acc 79.62 %\n",
      "Epoch:60/200 AVG Training Loss:0.469 AVG Validation Loss:0.507 AVG Training Acc 80.88 % AVG Validation Acc 79.26 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.463 AVG Validation Loss:0.507 AVG Training Acc 80.99 % AVG Validation Acc 79.35 %\n",
      "Epoch:80/200 AVG Training Loss:0.461 AVG Validation Loss:0.504 AVG Training Acc 81.09 % AVG Validation Acc 79.44 %\n",
      "Epoch:90/200 AVG Training Loss:0.461 AVG Validation Loss:0.508 AVG Training Acc 81.14 % AVG Validation Acc 79.17 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.460 AVG Validation Loss:0.510 AVG Training Acc 81.27 % AVG Validation Acc 79.08 %\n",
      "Epoch:110/200 AVG Training Loss:0.460 AVG Validation Loss:0.510 AVG Training Acc 81.18 % AVG Validation Acc 79.08 %\n",
      "Epoch:120/200 AVG Training Loss:0.462 AVG Validation Loss:0.509 AVG Training Acc 81.10 % AVG Validation Acc 79.08 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.460 AVG Validation Loss:0.507 AVG Training Acc 81.27 % AVG Validation Acc 79.17 %\n",
      "Epoch:140/200 AVG Training Loss:0.459 AVG Validation Loss:0.507 AVG Training Acc 81.24 % AVG Validation Acc 79.26 %\n",
      "Epoch:150/200 AVG Training Loss:0.459 AVG Validation Loss:0.509 AVG Training Acc 81.15 % AVG Validation Acc 79.35 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.460 AVG Validation Loss:0.508 AVG Training Acc 81.27 % AVG Validation Acc 79.26 %\n",
      "Epoch:170/200 AVG Training Loss:0.461 AVG Validation Loss:0.507 AVG Training Acc 81.11 % AVG Validation Acc 79.26 %\n",
      "Epoch:180/200 AVG Training Loss:0.461 AVG Validation Loss:0.509 AVG Training Acc 81.21 % AVG Validation Acc 79.35 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.460 AVG Validation Loss:0.510 AVG Training Acc 81.36 % AVG Validation Acc 79.17 %\n",
      "Epoch:200/200 AVG Training Loss:0.461 AVG Validation Loss:0.509 AVG Training Acc 81.09 % AVG Validation Acc 79.17 %\n",
      "Split 103\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "954d325621a64dcdb40ea8c42e20bb09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.499 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.482 AVG Validation Loss:0.501 AVG Training Acc 80.32 % AVG Validation Acc 79.80 %\n",
      "Epoch:40/200 AVG Training Loss:0.476 AVG Validation Loss:0.503 AVG Training Acc 80.68 % AVG Validation Acc 79.53 %\n",
      "Epoch:50/200 AVG Training Loss:0.472 AVG Validation Loss:0.513 AVG Training Acc 80.91 % AVG Validation Acc 79.08 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.468 AVG Validation Loss:0.515 AVG Training Acc 80.91 % AVG Validation Acc 79.17 %\n",
      "Epoch:70/200 AVG Training Loss:0.467 AVG Validation Loss:0.517 AVG Training Acc 81.09 % AVG Validation Acc 78.99 %\n",
      "Epoch:80/200 AVG Training Loss:0.466 AVG Validation Loss:0.517 AVG Training Acc 81.01 % AVG Validation Acc 78.99 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.466 AVG Validation Loss:0.517 AVG Training Acc 81.10 % AVG Validation Acc 78.81 %\n",
      "Epoch:100/200 AVG Training Loss:0.466 AVG Validation Loss:0.518 AVG Training Acc 81.13 % AVG Validation Acc 78.90 %\n",
      "Epoch:110/200 AVG Training Loss:0.466 AVG Validation Loss:0.517 AVG Training Acc 81.12 % AVG Validation Acc 78.90 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.466 AVG Validation Loss:0.518 AVG Training Acc 81.09 % AVG Validation Acc 78.81 %\n",
      "Epoch:130/200 AVG Training Loss:0.465 AVG Validation Loss:0.517 AVG Training Acc 80.99 % AVG Validation Acc 78.90 %\n",
      "Epoch:140/200 AVG Training Loss:0.465 AVG Validation Loss:0.519 AVG Training Acc 81.00 % AVG Validation Acc 78.90 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.466 AVG Validation Loss:0.517 AVG Training Acc 81.15 % AVG Validation Acc 78.90 %\n",
      "Epoch:160/200 AVG Training Loss:0.466 AVG Validation Loss:0.517 AVG Training Acc 81.10 % AVG Validation Acc 78.90 %\n",
      "Epoch:170/200 AVG Training Loss:0.466 AVG Validation Loss:0.519 AVG Training Acc 81.06 % AVG Validation Acc 78.81 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.465 AVG Validation Loss:0.519 AVG Training Acc 81.03 % AVG Validation Acc 78.81 %\n",
      "Epoch:190/200 AVG Training Loss:0.466 AVG Validation Loss:0.518 AVG Training Acc 81.03 % AVG Validation Acc 78.81 %\n",
      "Epoch:200/200 AVG Training Loss:0.466 AVG Validation Loss:0.519 AVG Training Acc 81.03 % AVG Validation Acc 78.81 %\n",
      "Split 104\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6086963243f94bd08de5e499857635ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.493 AVG Training Acc 80.18 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.21 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.30 % AVG Validation Acc 80.34 %\n",
      "Epoch:50/200 AVG Training Loss:0.481 AVG Validation Loss:0.497 AVG Training Acc 80.44 % AVG Validation Acc 80.25 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.480 AVG Validation Loss:0.496 AVG Training Acc 80.34 % AVG Validation Acc 80.07 %\n",
      "Epoch:70/200 AVG Training Loss:0.474 AVG Validation Loss:0.497 AVG Training Acc 80.49 % AVG Validation Acc 80.07 %\n",
      "Epoch:80/200 AVG Training Loss:0.469 AVG Validation Loss:0.502 AVG Training Acc 80.64 % AVG Validation Acc 79.80 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.464 AVG Validation Loss:0.508 AVG Training Acc 80.90 % AVG Validation Acc 79.80 %\n",
      "Epoch:100/200 AVG Training Loss:0.462 AVG Validation Loss:0.507 AVG Training Acc 81.07 % AVG Validation Acc 79.71 %\n",
      "Epoch:110/200 AVG Training Loss:0.464 AVG Validation Loss:0.513 AVG Training Acc 80.90 % AVG Validation Acc 79.71 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.463 AVG Validation Loss:0.510 AVG Training Acc 80.92 % AVG Validation Acc 79.62 %\n",
      "Epoch:130/200 AVG Training Loss:0.461 AVG Validation Loss:0.513 AVG Training Acc 80.90 % AVG Validation Acc 79.80 %\n",
      "Epoch:140/200 AVG Training Loss:0.463 AVG Validation Loss:0.512 AVG Training Acc 80.89 % AVG Validation Acc 79.53 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.464 AVG Validation Loss:0.511 AVG Training Acc 80.94 % AVG Validation Acc 79.71 %\n",
      "Epoch:160/200 AVG Training Loss:0.462 AVG Validation Loss:0.509 AVG Training Acc 80.97 % AVG Validation Acc 79.35 %\n",
      "Epoch:170/200 AVG Training Loss:0.463 AVG Validation Loss:0.512 AVG Training Acc 80.86 % AVG Validation Acc 79.35 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.462 AVG Validation Loss:0.514 AVG Training Acc 80.88 % AVG Validation Acc 79.62 %\n",
      "Epoch:190/200 AVG Training Loss:0.463 AVG Validation Loss:0.515 AVG Training Acc 80.89 % AVG Validation Acc 79.80 %\n",
      "Epoch:200/200 AVG Training Loss:0.461 AVG Validation Loss:0.510 AVG Training Acc 80.82 % AVG Validation Acc 79.62 %\n",
      "Split 105\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "234f165e45f14493b4f9cd6780112d9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.499 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.32 % AVG Validation Acc 79.71 %\n",
      "Epoch:40/200 AVG Training Loss:0.479 AVG Validation Loss:0.512 AVG Training Acc 80.50 % AVG Validation Acc 79.62 %\n",
      "Epoch:50/200 AVG Training Loss:0.474 AVG Validation Loss:0.520 AVG Training Acc 80.63 % AVG Validation Acc 79.35 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.470 AVG Validation Loss:0.524 AVG Training Acc 80.81 % AVG Validation Acc 79.44 %\n",
      "Epoch:70/200 AVG Training Loss:0.468 AVG Validation Loss:0.525 AVG Training Acc 80.84 % AVG Validation Acc 79.26 %\n",
      "Epoch:80/200 AVG Training Loss:0.467 AVG Validation Loss:0.524 AVG Training Acc 80.88 % AVG Validation Acc 79.44 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.466 AVG Validation Loss:0.527 AVG Training Acc 80.93 % AVG Validation Acc 79.44 %\n",
      "Epoch:100/200 AVG Training Loss:0.466 AVG Validation Loss:0.527 AVG Training Acc 80.80 % AVG Validation Acc 79.26 %\n",
      "Epoch:110/200 AVG Training Loss:0.467 AVG Validation Loss:0.527 AVG Training Acc 80.82 % AVG Validation Acc 79.44 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.468 AVG Validation Loss:0.527 AVG Training Acc 80.79 % AVG Validation Acc 79.26 %\n",
      "Epoch:130/200 AVG Training Loss:0.465 AVG Validation Loss:0.527 AVG Training Acc 80.99 % AVG Validation Acc 79.44 %\n",
      "Epoch:140/200 AVG Training Loss:0.466 AVG Validation Loss:0.527 AVG Training Acc 80.74 % AVG Validation Acc 79.26 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.467 AVG Validation Loss:0.527 AVG Training Acc 80.96 % AVG Validation Acc 79.44 %\n",
      "Epoch:160/200 AVG Training Loss:0.466 AVG Validation Loss:0.526 AVG Training Acc 80.78 % AVG Validation Acc 79.35 %\n",
      "Epoch:170/200 AVG Training Loss:0.466 AVG Validation Loss:0.527 AVG Training Acc 80.93 % AVG Validation Acc 79.44 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.466 AVG Validation Loss:0.527 AVG Training Acc 80.79 % AVG Validation Acc 79.26 %\n",
      "Epoch:190/200 AVG Training Loss:0.465 AVG Validation Loss:0.526 AVG Training Acc 80.73 % AVG Validation Acc 79.26 %\n",
      "Epoch:200/200 AVG Training Loss:0.466 AVG Validation Loss:0.527 AVG Training Acc 80.83 % AVG Validation Acc 79.53 %\n",
      "Split 106\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f385e84b2e85429bacb06107fc25a7d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.490 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.489 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.482 AVG Validation Loss:0.483 AVG Training Acc 80.33 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.473 AVG Validation Loss:0.483 AVG Training Acc 80.65 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.469 AVG Validation Loss:0.492 AVG Training Acc 80.69 % AVG Validation Acc 80.05 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.462 AVG Validation Loss:0.493 AVG Training Acc 80.78 % AVG Validation Acc 80.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.463 AVG Validation Loss:0.497 AVG Training Acc 80.87 % AVG Validation Acc 79.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.464 AVG Validation Loss:0.498 AVG Training Acc 80.85 % AVG Validation Acc 80.14 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.461 AVG Validation Loss:0.498 AVG Training Acc 80.88 % AVG Validation Acc 79.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.461 AVG Validation Loss:0.499 AVG Training Acc 80.91 % AVG Validation Acc 79.87 %\n",
      "Epoch:120/200 AVG Training Loss:0.462 AVG Validation Loss:0.498 AVG Training Acc 80.87 % AVG Validation Acc 79.96 %\n",
      "Epoch:130/200 AVG Training Loss:0.462 AVG Validation Loss:0.497 AVG Training Acc 80.93 % AVG Validation Acc 80.05 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.461 AVG Validation Loss:0.495 AVG Training Acc 80.94 % AVG Validation Acc 80.05 %\n",
      "Epoch:150/200 AVG Training Loss:0.462 AVG Validation Loss:0.496 AVG Training Acc 80.97 % AVG Validation Acc 80.05 %\n",
      "Epoch:160/200 AVG Training Loss:0.464 AVG Validation Loss:0.496 AVG Training Acc 80.81 % AVG Validation Acc 80.05 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.463 AVG Validation Loss:0.498 AVG Training Acc 80.91 % AVG Validation Acc 80.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.461 AVG Validation Loss:0.495 AVG Training Acc 80.88 % AVG Validation Acc 80.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.462 AVG Validation Loss:0.500 AVG Training Acc 80.91 % AVG Validation Acc 80.05 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.461 AVG Validation Loss:0.498 AVG Training Acc 80.86 % AVG Validation Acc 80.05 %\n",
      "Split 107\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "125d0169942c486d9539457aafa2d266",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.499 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.497 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.25 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.476 AVG Validation Loss:0.509 AVG Training Acc 80.40 % AVG Validation Acc 79.60 %\n",
      "Epoch:50/200 AVG Training Loss:0.471 AVG Validation Loss:0.514 AVG Training Acc 80.50 % AVG Validation Acc 79.69 %\n",
      "Epoch:60/200 AVG Training Loss:0.466 AVG Validation Loss:0.522 AVG Training Acc 80.60 % AVG Validation Acc 79.69 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.465 AVG Validation Loss:0.522 AVG Training Acc 80.78 % AVG Validation Acc 79.60 %\n",
      "Epoch:80/200 AVG Training Loss:0.463 AVG Validation Loss:0.522 AVG Training Acc 80.65 % AVG Validation Acc 79.60 %\n",
      "Epoch:90/200 AVG Training Loss:0.465 AVG Validation Loss:0.523 AVG Training Acc 80.62 % AVG Validation Acc 79.60 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.463 AVG Validation Loss:0.518 AVG Training Acc 80.72 % AVG Validation Acc 79.51 %\n",
      "Epoch:110/200 AVG Training Loss:0.462 AVG Validation Loss:0.518 AVG Training Acc 80.75 % AVG Validation Acc 79.69 %\n",
      "Epoch:120/200 AVG Training Loss:0.463 AVG Validation Loss:0.522 AVG Training Acc 80.66 % AVG Validation Acc 79.60 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.462 AVG Validation Loss:0.520 AVG Training Acc 80.75 % AVG Validation Acc 79.51 %\n",
      "Epoch:140/200 AVG Training Loss:0.463 AVG Validation Loss:0.523 AVG Training Acc 80.77 % AVG Validation Acc 79.60 %\n",
      "Epoch:150/200 AVG Training Loss:0.464 AVG Validation Loss:0.522 AVG Training Acc 80.66 % AVG Validation Acc 79.60 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.461 AVG Validation Loss:0.523 AVG Training Acc 80.77 % AVG Validation Acc 79.51 %\n",
      "Epoch:170/200 AVG Training Loss:0.464 AVG Validation Loss:0.523 AVG Training Acc 80.70 % AVG Validation Acc 79.69 %\n",
      "Epoch:180/200 AVG Training Loss:0.464 AVG Validation Loss:0.522 AVG Training Acc 80.53 % AVG Validation Acc 79.69 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.462 AVG Validation Loss:0.521 AVG Training Acc 80.77 % AVG Validation Acc 79.60 %\n",
      "Epoch:200/200 AVG Training Loss:0.461 AVG Validation Loss:0.523 AVG Training Acc 80.62 % AVG Validation Acc 79.69 %\n",
      "Split 108\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ca7e233eea04f0395312ae44c016f58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.482 AVG Validation Loss:0.501 AVG Training Acc 80.33 % AVG Validation Acc 80.14 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.477 AVG Validation Loss:0.507 AVG Training Acc 80.56 % AVG Validation Acc 79.96 %\n",
      "Epoch:60/200 AVG Training Loss:0.475 AVG Validation Loss:0.510 AVG Training Acc 80.60 % AVG Validation Acc 79.87 %\n",
      "Epoch:70/200 AVG Training Loss:0.476 AVG Validation Loss:0.508 AVG Training Acc 80.60 % AVG Validation Acc 79.69 %\n",
      "Epoch:80/200 AVG Training Loss:0.476 AVG Validation Loss:0.512 AVG Training Acc 80.51 % AVG Validation Acc 79.69 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.474 AVG Validation Loss:0.513 AVG Training Acc 80.71 % AVG Validation Acc 79.69 %\n",
      "Epoch:100/200 AVG Training Loss:0.475 AVG Validation Loss:0.510 AVG Training Acc 80.56 % AVG Validation Acc 79.69 %\n",
      "Epoch:110/200 AVG Training Loss:0.474 AVG Validation Loss:0.512 AVG Training Acc 80.69 % AVG Validation Acc 79.69 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.474 AVG Validation Loss:0.513 AVG Training Acc 80.58 % AVG Validation Acc 79.69 %\n",
      "Epoch:130/200 AVG Training Loss:0.475 AVG Validation Loss:0.511 AVG Training Acc 80.66 % AVG Validation Acc 79.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.474 AVG Validation Loss:0.513 AVG Training Acc 80.60 % AVG Validation Acc 79.60 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.475 AVG Validation Loss:0.514 AVG Training Acc 80.62 % AVG Validation Acc 79.69 %\n",
      "Epoch:160/200 AVG Training Loss:0.474 AVG Validation Loss:0.513 AVG Training Acc 80.55 % AVG Validation Acc 79.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.474 AVG Validation Loss:0.513 AVG Training Acc 80.69 % AVG Validation Acc 79.69 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.475 AVG Validation Loss:0.514 AVG Training Acc 80.62 % AVG Validation Acc 79.69 %\n",
      "Epoch:190/200 AVG Training Loss:0.474 AVG Validation Loss:0.513 AVG Training Acc 80.60 % AVG Validation Acc 79.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.475 AVG Validation Loss:0.514 AVG Training Acc 80.68 % AVG Validation Acc 79.60 %\n",
      "Split 109\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63badd5fe9224c3fa63c78d3ec71904a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.491 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.481 AVG Validation Loss:0.494 AVG Training Acc 80.33 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.476 AVG Validation Loss:0.499 AVG Training Acc 80.64 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.471 AVG Validation Loss:0.506 AVG Training Acc 80.65 % AVG Validation Acc 79.87 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.464 AVG Validation Loss:0.503 AVG Training Acc 80.83 % AVG Validation Acc 79.78 %\n",
      "Epoch:80/200 AVG Training Loss:0.462 AVG Validation Loss:0.505 AVG Training Acc 80.99 % AVG Validation Acc 79.87 %\n",
      "Epoch:90/200 AVG Training Loss:0.463 AVG Validation Loss:0.506 AVG Training Acc 80.85 % AVG Validation Acc 79.69 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.462 AVG Validation Loss:0.507 AVG Training Acc 80.93 % AVG Validation Acc 79.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.462 AVG Validation Loss:0.506 AVG Training Acc 80.95 % AVG Validation Acc 79.69 %\n",
      "Epoch:120/200 AVG Training Loss:0.463 AVG Validation Loss:0.508 AVG Training Acc 80.98 % AVG Validation Acc 79.78 %\n",
      "Epoch:130/200 AVG Training Loss:0.462 AVG Validation Loss:0.506 AVG Training Acc 80.94 % AVG Validation Acc 79.87 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.462 AVG Validation Loss:0.503 AVG Training Acc 81.00 % AVG Validation Acc 79.60 %\n",
      "Epoch:150/200 AVG Training Loss:0.461 AVG Validation Loss:0.506 AVG Training Acc 81.05 % AVG Validation Acc 79.60 %\n",
      "Epoch:160/200 AVG Training Loss:0.462 AVG Validation Loss:0.506 AVG Training Acc 81.11 % AVG Validation Acc 79.87 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.462 AVG Validation Loss:0.508 AVG Training Acc 80.99 % AVG Validation Acc 79.78 %\n",
      "Epoch:180/200 AVG Training Loss:0.460 AVG Validation Loss:0.505 AVG Training Acc 81.10 % AVG Validation Acc 79.78 %\n",
      "Epoch:190/200 AVG Training Loss:0.462 AVG Validation Loss:0.506 AVG Training Acc 81.10 % AVG Validation Acc 79.96 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.463 AVG Validation Loss:0.509 AVG Training Acc 80.97 % AVG Validation Acc 79.69 %\n",
      "Split 110\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da2c6a9e69ac452d956e40a2afcf7f4b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.498 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.498 AVG Training Acc 80.23 % AVG Validation Acc 80.05 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.482 AVG Validation Loss:0.494 AVG Training Acc 80.38 % AVG Validation Acc 79.60 %\n",
      "Epoch:40/200 AVG Training Loss:0.475 AVG Validation Loss:0.500 AVG Training Acc 80.76 % AVG Validation Acc 79.60 %\n",
      "Epoch:50/200 AVG Training Loss:0.468 AVG Validation Loss:0.511 AVG Training Acc 80.97 % AVG Validation Acc 79.06 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.462 AVG Validation Loss:0.511 AVG Training Acc 81.24 % AVG Validation Acc 78.88 %\n",
      "Epoch:70/200 AVG Training Loss:0.460 AVG Validation Loss:0.516 AVG Training Acc 81.43 % AVG Validation Acc 78.88 %\n",
      "Epoch:80/200 AVG Training Loss:0.461 AVG Validation Loss:0.518 AVG Training Acc 81.50 % AVG Validation Acc 78.79 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.460 AVG Validation Loss:0.517 AVG Training Acc 81.32 % AVG Validation Acc 78.79 %\n",
      "Epoch:100/200 AVG Training Loss:0.459 AVG Validation Loss:0.514 AVG Training Acc 81.33 % AVG Validation Acc 78.88 %\n",
      "Epoch:110/200 AVG Training Loss:0.460 AVG Validation Loss:0.516 AVG Training Acc 81.45 % AVG Validation Acc 78.79 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.460 AVG Validation Loss:0.516 AVG Training Acc 81.35 % AVG Validation Acc 78.79 %\n",
      "Epoch:130/200 AVG Training Loss:0.459 AVG Validation Loss:0.517 AVG Training Acc 81.50 % AVG Validation Acc 78.70 %\n",
      "Epoch:140/200 AVG Training Loss:0.459 AVG Validation Loss:0.518 AVG Training Acc 81.45 % AVG Validation Acc 78.61 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.458 AVG Validation Loss:0.518 AVG Training Acc 81.41 % AVG Validation Acc 78.88 %\n",
      "Epoch:160/200 AVG Training Loss:0.459 AVG Validation Loss:0.517 AVG Training Acc 81.45 % AVG Validation Acc 78.70 %\n",
      "Epoch:170/200 AVG Training Loss:0.459 AVG Validation Loss:0.518 AVG Training Acc 81.55 % AVG Validation Acc 78.70 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.459 AVG Validation Loss:0.518 AVG Training Acc 81.49 % AVG Validation Acc 78.88 %\n",
      "Epoch:190/200 AVG Training Loss:0.460 AVG Validation Loss:0.518 AVG Training Acc 81.33 % AVG Validation Acc 78.61 %\n",
      "Epoch:200/200 AVG Training Loss:0.459 AVG Validation Loss:0.517 AVG Training Acc 81.40 % AVG Validation Acc 78.79 %\n",
      "Split 111\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f04ba32a8224dc6859e93a5bb23ad08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.493 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.492 AVG Training Acc 80.20 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.486 AVG Validation Loss:0.491 AVG Training Acc 80.27 % AVG Validation Acc 80.16 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.494 AVG Validation Loss:0.491 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.495 AVG Validation Loss:0.493 AVG Training Acc 80.07 % AVG Validation Acc 80.07 %\n",
      "Epoch:60/200 AVG Training Loss:0.493 AVG Validation Loss:0.493 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.492 AVG Validation Loss:0.490 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch:80/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.12 % AVG Validation Acc 80.07 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.491 AVG Validation Loss:0.490 AVG Training Acc 80.21 % AVG Validation Acc 80.07 %\n",
      "Epoch:100/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.23 % AVG Validation Acc 80.07 %\n",
      "Epoch:110/200 AVG Training Loss:0.491 AVG Validation Loss:0.490 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:120/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.20 % AVG Validation Acc 80.07 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.19 % AVG Validation Acc 80.07 %\n",
      "Epoch:140/200 AVG Training Loss:0.490 AVG Validation Loss:0.489 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch:150/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.26 % AVG Validation Acc 79.89 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.491 AVG Validation Loss:0.490 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:170/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.15 % AVG Validation Acc 79.98 %\n",
      "Epoch:180/200 AVG Training Loss:0.491 AVG Validation Loss:0.490 AVG Training Acc 80.16 % AVG Validation Acc 80.07 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.491 AVG Validation Loss:0.490 AVG Training Acc 80.20 % AVG Validation Acc 80.07 %\n",
      "Epoch:200/200 AVG Training Loss:0.491 AVG Validation Loss:0.488 AVG Training Acc 80.21 % AVG Validation Acc 80.07 %\n",
      "Split 112\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd27b595f08e43888ad3cd85f42f528d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 80.25 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.27 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.483 AVG Validation Loss:0.494 AVG Training Acc 80.50 % AVG Validation Acc 80.16 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.475 AVG Validation Loss:0.494 AVG Training Acc 80.49 % AVG Validation Acc 79.98 %\n",
      "Epoch:60/200 AVG Training Loss:0.468 AVG Validation Loss:0.501 AVG Training Acc 80.66 % AVG Validation Acc 79.44 %\n",
      "Epoch:70/200 AVG Training Loss:0.462 AVG Validation Loss:0.507 AVG Training Acc 80.87 % AVG Validation Acc 79.35 %\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.455 AVG Validation Loss:0.510 AVG Training Acc 81.09 % AVG Validation Acc 79.62 %\n",
      "Epoch:90/200 AVG Training Loss:0.456 AVG Validation Loss:0.509 AVG Training Acc 81.05 % AVG Validation Acc 79.44 %\n",
      "Epoch:100/200 AVG Training Loss:0.455 AVG Validation Loss:0.510 AVG Training Acc 81.37 % AVG Validation Acc 79.62 %\n",
      "Epoch   104: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.454 AVG Validation Loss:0.510 AVG Training Acc 81.36 % AVG Validation Acc 79.62 %\n",
      "Epoch:120/200 AVG Training Loss:0.453 AVG Validation Loss:0.513 AVG Training Acc 81.39 % AVG Validation Acc 79.62 %\n",
      "Epoch:130/200 AVG Training Loss:0.455 AVG Validation Loss:0.511 AVG Training Acc 81.09 % AVG Validation Acc 79.62 %\n",
      "Epoch   135: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.453 AVG Validation Loss:0.509 AVG Training Acc 81.34 % AVG Validation Acc 79.80 %\n",
      "Epoch:150/200 AVG Training Loss:0.453 AVG Validation Loss:0.512 AVG Training Acc 81.24 % AVG Validation Acc 79.62 %\n",
      "Epoch:160/200 AVG Training Loss:0.453 AVG Validation Loss:0.507 AVG Training Acc 81.39 % AVG Validation Acc 79.98 %\n",
      "Epoch   166: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.453 AVG Validation Loss:0.510 AVG Training Acc 81.31 % AVG Validation Acc 79.80 %\n",
      "Epoch:180/200 AVG Training Loss:0.453 AVG Validation Loss:0.510 AVG Training Acc 81.24 % AVG Validation Acc 79.71 %\n",
      "Epoch:190/200 AVG Training Loss:0.454 AVG Validation Loss:0.511 AVG Training Acc 81.31 % AVG Validation Acc 79.44 %\n",
      "Epoch   197: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.455 AVG Validation Loss:0.508 AVG Training Acc 81.19 % AVG Validation Acc 79.98 %\n",
      "Split 113\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d50711ba029046559fd927c5940bb675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.481 AVG Validation Loss:0.501 AVG Training Acc 80.34 % AVG Validation Acc 80.07 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.466 AVG Validation Loss:0.521 AVG Training Acc 80.88 % AVG Validation Acc 79.53 %\n",
      "Epoch:50/200 AVG Training Loss:0.454 AVG Validation Loss:0.543 AVG Training Acc 81.24 % AVG Validation Acc 78.99 %\n",
      "Epoch:60/200 AVG Training Loss:0.446 AVG Validation Loss:0.554 AVG Training Acc 81.67 % AVG Validation Acc 78.99 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.438 AVG Validation Loss:0.561 AVG Training Acc 81.92 % AVG Validation Acc 79.08 %\n",
      "Epoch:80/200 AVG Training Loss:0.438 AVG Validation Loss:0.568 AVG Training Acc 82.08 % AVG Validation Acc 79.17 %\n",
      "Epoch:90/200 AVG Training Loss:0.432 AVG Validation Loss:0.565 AVG Training Acc 82.00 % AVG Validation Acc 78.99 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.436 AVG Validation Loss:0.578 AVG Training Acc 81.99 % AVG Validation Acc 78.81 %\n",
      "Epoch:110/200 AVG Training Loss:0.433 AVG Validation Loss:0.569 AVG Training Acc 82.21 % AVG Validation Acc 78.99 %\n",
      "Epoch:120/200 AVG Training Loss:0.433 AVG Validation Loss:0.563 AVG Training Acc 82.20 % AVG Validation Acc 79.26 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.436 AVG Validation Loss:0.577 AVG Training Acc 81.98 % AVG Validation Acc 78.90 %\n",
      "Epoch:140/200 AVG Training Loss:0.434 AVG Validation Loss:0.569 AVG Training Acc 82.22 % AVG Validation Acc 78.99 %\n",
      "Epoch:150/200 AVG Training Loss:0.433 AVG Validation Loss:0.574 AVG Training Acc 82.19 % AVG Validation Acc 78.99 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.439 AVG Validation Loss:0.562 AVG Training Acc 81.89 % AVG Validation Acc 79.17 %\n",
      "Epoch:170/200 AVG Training Loss:0.436 AVG Validation Loss:0.575 AVG Training Acc 82.13 % AVG Validation Acc 78.81 %\n",
      "Epoch:180/200 AVG Training Loss:0.436 AVG Validation Loss:0.571 AVG Training Acc 82.06 % AVG Validation Acc 78.63 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.434 AVG Validation Loss:0.575 AVG Training Acc 82.20 % AVG Validation Acc 79.26 %\n",
      "Epoch:200/200 AVG Training Loss:0.433 AVG Validation Loss:0.571 AVG Training Acc 82.04 % AVG Validation Acc 78.99 %\n",
      "Split 114\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac2abe245351422e807d37a5a082bd85",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.18 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.485 AVG Validation Loss:0.491 AVG Training Acc 80.15 % AVG Validation Acc 80.25 %\n",
      "Epoch:50/200 AVG Training Loss:0.480 AVG Validation Loss:0.497 AVG Training Acc 80.47 % AVG Validation Acc 80.07 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.461 AVG Validation Loss:0.506 AVG Training Acc 80.94 % AVG Validation Acc 79.62 %\n",
      "Epoch:70/200 AVG Training Loss:0.454 AVG Validation Loss:0.510 AVG Training Acc 81.12 % AVG Validation Acc 79.62 %\n",
      "Epoch:80/200 AVG Training Loss:0.449 AVG Validation Loss:0.521 AVG Training Acc 81.45 % AVG Validation Acc 79.98 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.446 AVG Validation Loss:0.525 AVG Training Acc 81.68 % AVG Validation Acc 78.99 %\n",
      "Epoch:100/200 AVG Training Loss:0.444 AVG Validation Loss:0.519 AVG Training Acc 81.54 % AVG Validation Acc 78.81 %\n",
      "Epoch:110/200 AVG Training Loss:0.445 AVG Validation Loss:0.531 AVG Training Acc 81.61 % AVG Validation Acc 79.08 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.443 AVG Validation Loss:0.529 AVG Training Acc 81.46 % AVG Validation Acc 78.90 %\n",
      "Epoch:130/200 AVG Training Loss:0.442 AVG Validation Loss:0.523 AVG Training Acc 81.57 % AVG Validation Acc 78.99 %\n",
      "Epoch:140/200 AVG Training Loss:0.443 AVG Validation Loss:0.523 AVG Training Acc 81.77 % AVG Validation Acc 78.90 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.443 AVG Validation Loss:0.531 AVG Training Acc 81.68 % AVG Validation Acc 78.90 %\n",
      "Epoch:160/200 AVG Training Loss:0.442 AVG Validation Loss:0.528 AVG Training Acc 81.60 % AVG Validation Acc 78.45 %\n",
      "Epoch:170/200 AVG Training Loss:0.443 AVG Validation Loss:0.526 AVG Training Acc 81.60 % AVG Validation Acc 79.35 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.441 AVG Validation Loss:0.526 AVG Training Acc 81.63 % AVG Validation Acc 78.72 %\n",
      "Epoch:190/200 AVG Training Loss:0.442 AVG Validation Loss:0.520 AVG Training Acc 81.64 % AVG Validation Acc 78.90 %\n",
      "Epoch:200/200 AVG Training Loss:0.442 AVG Validation Loss:0.531 AVG Training Acc 81.73 % AVG Validation Acc 78.99 %\n",
      "Split 115\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83e979e113a64023ad3569a263edc673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.490 AVG Validation Loss:0.499 AVG Training Acc 80.16 % AVG Validation Acc 80.07 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.484 AVG Validation Loss:0.505 AVG Training Acc 80.27 % AVG Validation Acc 79.71 %\n",
      "Epoch:40/200 AVG Training Loss:0.481 AVG Validation Loss:0.504 AVG Training Acc 80.31 % AVG Validation Acc 79.62 %\n",
      "Epoch:50/200 AVG Training Loss:0.477 AVG Validation Loss:0.510 AVG Training Acc 80.36 % AVG Validation Acc 79.44 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.472 AVG Validation Loss:0.512 AVG Training Acc 80.50 % AVG Validation Acc 79.35 %\n",
      "Epoch:70/200 AVG Training Loss:0.473 AVG Validation Loss:0.512 AVG Training Acc 80.50 % AVG Validation Acc 79.35 %\n",
      "Epoch:80/200 AVG Training Loss:0.472 AVG Validation Loss:0.510 AVG Training Acc 80.48 % AVG Validation Acc 79.35 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.471 AVG Validation Loss:0.509 AVG Training Acc 80.50 % AVG Validation Acc 79.44 %\n",
      "Epoch:100/200 AVG Training Loss:0.470 AVG Validation Loss:0.509 AVG Training Acc 80.55 % AVG Validation Acc 79.44 %\n",
      "Epoch:110/200 AVG Training Loss:0.470 AVG Validation Loss:0.508 AVG Training Acc 80.50 % AVG Validation Acc 79.44 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.472 AVG Validation Loss:0.510 AVG Training Acc 80.50 % AVG Validation Acc 79.44 %\n",
      "Epoch:130/200 AVG Training Loss:0.472 AVG Validation Loss:0.510 AVG Training Acc 80.57 % AVG Validation Acc 79.44 %\n",
      "Epoch:140/200 AVG Training Loss:0.470 AVG Validation Loss:0.510 AVG Training Acc 80.62 % AVG Validation Acc 79.44 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.471 AVG Validation Loss:0.509 AVG Training Acc 80.51 % AVG Validation Acc 79.44 %\n",
      "Epoch:160/200 AVG Training Loss:0.471 AVG Validation Loss:0.510 AVG Training Acc 80.48 % AVG Validation Acc 79.53 %\n",
      "Epoch:170/200 AVG Training Loss:0.471 AVG Validation Loss:0.510 AVG Training Acc 80.61 % AVG Validation Acc 79.53 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.471 AVG Validation Loss:0.510 AVG Training Acc 80.55 % AVG Validation Acc 79.44 %\n",
      "Epoch:190/200 AVG Training Loss:0.470 AVG Validation Loss:0.510 AVG Training Acc 80.61 % AVG Validation Acc 79.53 %\n",
      "Epoch:200/200 AVG Training Loss:0.471 AVG Validation Loss:0.511 AVG Training Acc 80.57 % AVG Validation Acc 79.44 %\n",
      "Split 116\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe79b06e4b7496b89960dcb1dd2c2dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.486 AVG Validation Loss:0.494 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.476 AVG Validation Loss:0.497 AVG Training Acc 80.44 % AVG Validation Acc 79.87 %\n",
      "Epoch:50/200 AVG Training Loss:0.466 AVG Validation Loss:0.505 AVG Training Acc 80.70 % AVG Validation Acc 79.78 %\n",
      "Epoch:60/200 AVG Training Loss:0.458 AVG Validation Loss:0.512 AVG Training Acc 80.86 % AVG Validation Acc 79.24 %\n",
      "Epoch:70/200 AVG Training Loss:0.449 AVG Validation Loss:0.523 AVG Training Acc 81.20 % AVG Validation Acc 78.79 %\n",
      "Epoch    70: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.445 AVG Validation Loss:0.527 AVG Training Acc 81.38 % AVG Validation Acc 78.97 %\n",
      "Epoch:90/200 AVG Training Loss:0.447 AVG Validation Loss:0.531 AVG Training Acc 81.16 % AVG Validation Acc 78.79 %\n",
      "Epoch:100/200 AVG Training Loss:0.443 AVG Validation Loss:0.532 AVG Training Acc 81.34 % AVG Validation Acc 78.79 %\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.445 AVG Validation Loss:0.528 AVG Training Acc 81.19 % AVG Validation Acc 78.61 %\n",
      "Epoch:120/200 AVG Training Loss:0.446 AVG Validation Loss:0.535 AVG Training Acc 81.10 % AVG Validation Acc 78.97 %\n",
      "Epoch:130/200 AVG Training Loss:0.443 AVG Validation Loss:0.533 AVG Training Acc 81.23 % AVG Validation Acc 78.97 %\n",
      "Epoch   132: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.446 AVG Validation Loss:0.533 AVG Training Acc 81.14 % AVG Validation Acc 78.79 %\n",
      "Epoch:150/200 AVG Training Loss:0.446 AVG Validation Loss:0.529 AVG Training Acc 81.38 % AVG Validation Acc 79.06 %\n",
      "Epoch:160/200 AVG Training Loss:0.443 AVG Validation Loss:0.532 AVG Training Acc 81.16 % AVG Validation Acc 79.06 %\n",
      "Epoch   163: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.443 AVG Validation Loss:0.531 AVG Training Acc 81.22 % AVG Validation Acc 78.88 %\n",
      "Epoch:180/200 AVG Training Loss:0.446 AVG Validation Loss:0.533 AVG Training Acc 81.33 % AVG Validation Acc 78.88 %\n",
      "Epoch:190/200 AVG Training Loss:0.445 AVG Validation Loss:0.533 AVG Training Acc 81.27 % AVG Validation Acc 78.70 %\n",
      "Epoch   194: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.445 AVG Validation Loss:0.537 AVG Training Acc 81.34 % AVG Validation Acc 78.79 %\n",
      "Split 117\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb81b108285449294f983d91b6300cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.10 % AVG Validation Acc 80.23 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.26 % AVG Validation Acc 80.23 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.17 % AVG Validation Acc 80.23 %\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.478 AVG Validation Loss:0.496 AVG Training Acc 80.35 % AVG Validation Acc 80.23 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:70/200 AVG Training Loss:0.461 AVG Validation Loss:0.495 AVG Training Acc 80.73 % AVG Validation Acc 80.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.454 AVG Validation Loss:0.501 AVG Training Acc 81.11 % AVG Validation Acc 79.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.449 AVG Validation Loss:0.511 AVG Training Acc 81.26 % AVG Validation Acc 79.51 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.446 AVG Validation Loss:0.510 AVG Training Acc 81.28 % AVG Validation Acc 79.51 %\n",
      "Epoch:110/200 AVG Training Loss:0.444 AVG Validation Loss:0.512 AVG Training Acc 81.52 % AVG Validation Acc 79.69 %\n",
      "Epoch:120/200 AVG Training Loss:0.447 AVG Validation Loss:0.512 AVG Training Acc 81.12 % AVG Validation Acc 79.24 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.441 AVG Validation Loss:0.511 AVG Training Acc 81.37 % AVG Validation Acc 79.51 %\n",
      "Epoch:140/200 AVG Training Loss:0.446 AVG Validation Loss:0.513 AVG Training Acc 81.16 % AVG Validation Acc 79.33 %\n",
      "Epoch:150/200 AVG Training Loss:0.443 AVG Validation Loss:0.513 AVG Training Acc 81.33 % AVG Validation Acc 79.60 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.443 AVG Validation Loss:0.512 AVG Training Acc 81.34 % AVG Validation Acc 79.51 %\n",
      "Epoch:170/200 AVG Training Loss:0.443 AVG Validation Loss:0.513 AVG Training Acc 81.44 % AVG Validation Acc 79.51 %\n",
      "Epoch:180/200 AVG Training Loss:0.443 AVG Validation Loss:0.513 AVG Training Acc 81.56 % AVG Validation Acc 79.69 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.443 AVG Validation Loss:0.513 AVG Training Acc 81.32 % AVG Validation Acc 79.33 %\n",
      "Epoch:200/200 AVG Training Loss:0.443 AVG Validation Loss:0.512 AVG Training Acc 81.43 % AVG Validation Acc 79.51 %\n",
      "Split 118\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "396e1f986a94422d8f7d6e97920105a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.498 AVG Training Acc 80.25 % AVG Validation Acc 79.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.482 AVG Validation Loss:0.498 AVG Training Acc 80.42 % AVG Validation Acc 80.05 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.468 AVG Validation Loss:0.504 AVG Training Acc 80.84 % AVG Validation Acc 79.51 %\n",
      "Epoch:60/200 AVG Training Loss:0.461 AVG Validation Loss:0.517 AVG Training Acc 80.99 % AVG Validation Acc 79.42 %\n",
      "Epoch:70/200 AVG Training Loss:0.457 AVG Validation Loss:0.518 AVG Training Acc 81.06 % AVG Validation Acc 79.69 %\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.451 AVG Validation Loss:0.521 AVG Training Acc 81.38 % AVG Validation Acc 79.87 %\n",
      "Epoch:90/200 AVG Training Loss:0.450 AVG Validation Loss:0.523 AVG Training Acc 81.43 % AVG Validation Acc 79.69 %\n",
      "Epoch:100/200 AVG Training Loss:0.448 AVG Validation Loss:0.528 AVG Training Acc 81.42 % AVG Validation Acc 79.42 %\n",
      "Epoch   104: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.449 AVG Validation Loss:0.523 AVG Training Acc 81.54 % AVG Validation Acc 79.33 %\n",
      "Epoch:120/200 AVG Training Loss:0.448 AVG Validation Loss:0.531 AVG Training Acc 81.49 % AVG Validation Acc 79.33 %\n",
      "Epoch:130/200 AVG Training Loss:0.447 AVG Validation Loss:0.527 AVG Training Acc 81.52 % AVG Validation Acc 79.42 %\n",
      "Epoch   135: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.446 AVG Validation Loss:0.532 AVG Training Acc 81.49 % AVG Validation Acc 79.51 %\n",
      "Epoch:150/200 AVG Training Loss:0.449 AVG Validation Loss:0.530 AVG Training Acc 81.55 % AVG Validation Acc 79.24 %\n",
      "Epoch:160/200 AVG Training Loss:0.449 AVG Validation Loss:0.530 AVG Training Acc 81.40 % AVG Validation Acc 79.51 %\n",
      "Epoch   166: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.448 AVG Validation Loss:0.526 AVG Training Acc 81.26 % AVG Validation Acc 79.42 %\n",
      "Epoch:180/200 AVG Training Loss:0.448 AVG Validation Loss:0.528 AVG Training Acc 81.42 % AVG Validation Acc 79.33 %\n",
      "Epoch:190/200 AVG Training Loss:0.448 AVG Validation Loss:0.526 AVG Training Acc 81.50 % AVG Validation Acc 79.42 %\n",
      "Epoch   197: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.447 AVG Validation Loss:0.529 AVG Training Acc 81.48 % AVG Validation Acc 79.42 %\n",
      "Split 119\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c0fd233d8784dcf86f0fd52f80c0a41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.491 AVG Training Acc 80.25 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.480 AVG Validation Loss:0.495 AVG Training Acc 80.29 % AVG Validation Acc 79.96 %\n",
      "Epoch:60/200 AVG Training Loss:0.475 AVG Validation Loss:0.503 AVG Training Acc 80.46 % AVG Validation Acc 79.51 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.470 AVG Validation Loss:0.507 AVG Training Acc 80.63 % AVG Validation Acc 79.60 %\n",
      "Epoch:80/200 AVG Training Loss:0.469 AVG Validation Loss:0.507 AVG Training Acc 80.77 % AVG Validation Acc 79.51 %\n",
      "Epoch:90/200 AVG Training Loss:0.469 AVG Validation Loss:0.509 AVG Training Acc 80.70 % AVG Validation Acc 79.51 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.470 AVG Validation Loss:0.508 AVG Training Acc 80.78 % AVG Validation Acc 79.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.468 AVG Validation Loss:0.509 AVG Training Acc 80.80 % AVG Validation Acc 79.51 %\n",
      "Epoch:120/200 AVG Training Loss:0.467 AVG Validation Loss:0.506 AVG Training Acc 80.85 % AVG Validation Acc 79.51 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.468 AVG Validation Loss:0.509 AVG Training Acc 80.73 % AVG Validation Acc 79.51 %\n",
      "Epoch:140/200 AVG Training Loss:0.468 AVG Validation Loss:0.509 AVG Training Acc 80.73 % AVG Validation Acc 79.60 %\n",
      "Epoch:150/200 AVG Training Loss:0.468 AVG Validation Loss:0.505 AVG Training Acc 80.76 % AVG Validation Acc 79.60 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.469 AVG Validation Loss:0.508 AVG Training Acc 80.85 % AVG Validation Acc 79.60 %\n",
      "Epoch:170/200 AVG Training Loss:0.466 AVG Validation Loss:0.504 AVG Training Acc 80.81 % AVG Validation Acc 79.78 %\n",
      "Epoch:180/200 AVG Training Loss:0.468 AVG Validation Loss:0.511 AVG Training Acc 80.78 % AVG Validation Acc 79.69 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.468 AVG Validation Loss:0.505 AVG Training Acc 80.81 % AVG Validation Acc 79.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.467 AVG Validation Loss:0.506 AVG Training Acc 80.71 % AVG Validation Acc 79.69 %\n",
      "Split 120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b3e864daea940c19cbddf5bd8b38c80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.493 AVG Training Acc 80.10 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.493 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.485 AVG Validation Loss:0.492 AVG Training Acc 80.28 % AVG Validation Acc 80.32 %\n",
      "Epoch:50/200 AVG Training Loss:0.481 AVG Validation Loss:0.490 AVG Training Acc 80.30 % AVG Validation Acc 80.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.479 AVG Validation Loss:0.492 AVG Training Acc 80.30 % AVG Validation Acc 80.14 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:70/200 AVG Training Loss:0.465 AVG Validation Loss:0.491 AVG Training Acc 80.70 % AVG Validation Acc 79.87 %\n",
      "Epoch:80/200 AVG Training Loss:0.459 AVG Validation Loss:0.506 AVG Training Acc 80.75 % AVG Validation Acc 79.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.455 AVG Validation Loss:0.495 AVG Training Acc 80.79 % AVG Validation Acc 80.05 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.454 AVG Validation Loss:0.502 AVG Training Acc 80.84 % AVG Validation Acc 79.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.452 AVG Validation Loss:0.504 AVG Training Acc 80.93 % AVG Validation Acc 79.69 %\n",
      "Epoch:120/200 AVG Training Loss:0.450 AVG Validation Loss:0.507 AVG Training Acc 80.85 % AVG Validation Acc 79.51 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.450 AVG Validation Loss:0.503 AVG Training Acc 80.96 % AVG Validation Acc 79.69 %\n",
      "Epoch:140/200 AVG Training Loss:0.447 AVG Validation Loss:0.507 AVG Training Acc 81.04 % AVG Validation Acc 79.69 %\n",
      "Epoch:150/200 AVG Training Loss:0.450 AVG Validation Loss:0.503 AVG Training Acc 81.13 % AVG Validation Acc 79.69 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.449 AVG Validation Loss:0.502 AVG Training Acc 81.15 % AVG Validation Acc 79.69 %\n",
      "Epoch:170/200 AVG Training Loss:0.451 AVG Validation Loss:0.506 AVG Training Acc 80.93 % AVG Validation Acc 79.60 %\n",
      "Epoch:180/200 AVG Training Loss:0.449 AVG Validation Loss:0.504 AVG Training Acc 80.95 % AVG Validation Acc 79.96 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.448 AVG Validation Loss:0.509 AVG Training Acc 81.13 % AVG Validation Acc 79.60 %\n",
      "Epoch:200/200 AVG Training Loss:0.449 AVG Validation Loss:0.508 AVG Training Acc 80.91 % AVG Validation Acc 79.69 %\n",
      "Split 121\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a298c61cd63d48aa96c5ea3281dffe0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.485 AVG Validation Loss:0.493 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.483 AVG Validation Loss:0.493 AVG Training Acc 80.32 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.479 AVG Validation Loss:0.493 AVG Training Acc 80.39 % AVG Validation Acc 80.25 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.476 AVG Validation Loss:0.495 AVG Training Acc 80.43 % AVG Validation Acc 80.43 %\n",
      "Epoch:70/200 AVG Training Loss:0.476 AVG Validation Loss:0.494 AVG Training Acc 80.47 % AVG Validation Acc 80.43 %\n",
      "Epoch:80/200 AVG Training Loss:0.475 AVG Validation Loss:0.493 AVG Training Acc 80.46 % AVG Validation Acc 80.43 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.474 AVG Validation Loss:0.495 AVG Training Acc 80.68 % AVG Validation Acc 80.34 %\n",
      "Epoch:100/200 AVG Training Loss:0.474 AVG Validation Loss:0.494 AVG Training Acc 80.61 % AVG Validation Acc 80.34 %\n",
      "Epoch:110/200 AVG Training Loss:0.473 AVG Validation Loss:0.494 AVG Training Acc 80.59 % AVG Validation Acc 80.25 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.475 AVG Validation Loss:0.495 AVG Training Acc 80.58 % AVG Validation Acc 80.25 %\n",
      "Epoch:130/200 AVG Training Loss:0.475 AVG Validation Loss:0.496 AVG Training Acc 80.60 % AVG Validation Acc 80.25 %\n",
      "Epoch:140/200 AVG Training Loss:0.474 AVG Validation Loss:0.496 AVG Training Acc 80.60 % AVG Validation Acc 80.25 %\n",
      "Epoch:150/200 AVG Training Loss:0.473 AVG Validation Loss:0.495 AVG Training Acc 80.52 % AVG Validation Acc 80.25 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.474 AVG Validation Loss:0.495 AVG Training Acc 80.67 % AVG Validation Acc 80.25 %\n",
      "Epoch:170/200 AVG Training Loss:0.474 AVG Validation Loss:0.496 AVG Training Acc 80.53 % AVG Validation Acc 80.16 %\n",
      "Epoch:180/200 AVG Training Loss:0.473 AVG Validation Loss:0.493 AVG Training Acc 80.64 % AVG Validation Acc 80.25 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.474 AVG Validation Loss:0.494 AVG Training Acc 80.52 % AVG Validation Acc 80.16 %\n",
      "Epoch:200/200 AVG Training Loss:0.475 AVG Validation Loss:0.495 AVG Training Acc 80.49 % AVG Validation Acc 80.25 %\n",
      "Split 122\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd1050621c6421cb9220e9f1b8b4ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.504 AVG Training Acc 80.15 % AVG Validation Acc 79.98 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.484 AVG Validation Loss:0.506 AVG Training Acc 80.31 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.480 AVG Validation Loss:0.511 AVG Training Acc 80.36 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.478 AVG Validation Loss:0.514 AVG Training Acc 80.40 % AVG Validation Acc 80.07 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.474 AVG Validation Loss:0.520 AVG Training Acc 80.59 % AVG Validation Acc 79.80 %\n",
      "Epoch:70/200 AVG Training Loss:0.473 AVG Validation Loss:0.521 AVG Training Acc 80.65 % AVG Validation Acc 79.80 %\n",
      "Epoch:80/200 AVG Training Loss:0.471 AVG Validation Loss:0.523 AVG Training Acc 80.73 % AVG Validation Acc 79.80 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.471 AVG Validation Loss:0.523 AVG Training Acc 80.82 % AVG Validation Acc 79.80 %\n",
      "Epoch:100/200 AVG Training Loss:0.472 AVG Validation Loss:0.523 AVG Training Acc 80.72 % AVG Validation Acc 79.80 %\n",
      "Epoch:110/200 AVG Training Loss:0.471 AVG Validation Loss:0.523 AVG Training Acc 80.68 % AVG Validation Acc 79.80 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.471 AVG Validation Loss:0.524 AVG Training Acc 80.65 % AVG Validation Acc 79.71 %\n",
      "Epoch:130/200 AVG Training Loss:0.472 AVG Validation Loss:0.524 AVG Training Acc 80.70 % AVG Validation Acc 79.71 %\n",
      "Epoch:140/200 AVG Training Loss:0.472 AVG Validation Loss:0.525 AVG Training Acc 80.70 % AVG Validation Acc 79.71 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.470 AVG Validation Loss:0.523 AVG Training Acc 80.76 % AVG Validation Acc 79.71 %\n",
      "Epoch:160/200 AVG Training Loss:0.473 AVG Validation Loss:0.523 AVG Training Acc 80.78 % AVG Validation Acc 79.71 %\n",
      "Epoch:170/200 AVG Training Loss:0.473 AVG Validation Loss:0.524 AVG Training Acc 80.73 % AVG Validation Acc 79.71 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.472 AVG Validation Loss:0.524 AVG Training Acc 80.67 % AVG Validation Acc 79.71 %\n",
      "Epoch:190/200 AVG Training Loss:0.471 AVG Validation Loss:0.524 AVG Training Acc 80.71 % AVG Validation Acc 79.71 %\n",
      "Epoch:200/200 AVG Training Loss:0.472 AVG Validation Loss:0.524 AVG Training Acc 80.67 % AVG Validation Acc 79.71 %\n",
      "Split 123\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5deca0b41eb2448d9091be3c8087ccf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.496 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.491 AVG Training Acc 80.27 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.507 AVG Validation Loss:0.501 AVG Training Acc 80.05 % AVG Validation Acc 80.16 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.497 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.495 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:80/200 AVG Training Loss:0.498 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.496 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:100/200 AVG Training Loss:0.495 AVG Validation Loss:0.492 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.494 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.495 AVG Validation Loss:0.492 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:130/200 AVG Training Loss:0.495 AVG Validation Loss:0.491 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:140/200 AVG Training Loss:0.495 AVG Validation Loss:0.492 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.495 AVG Validation Loss:0.492 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:160/200 AVG Training Loss:0.495 AVG Validation Loss:0.493 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:170/200 AVG Training Loss:0.495 AVG Validation Loss:0.492 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.495 AVG Validation Loss:0.493 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:190/200 AVG Training Loss:0.495 AVG Validation Loss:0.492 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:200/200 AVG Training Loss:0.495 AVG Validation Loss:0.493 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Split 124\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a4525e2a9454334bba85aa753acaf73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.10 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.493 AVG Training Acc 80.33 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.491 AVG Training Acc 80.22 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.25 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.479 AVG Validation Loss:0.495 AVG Training Acc 80.48 % AVG Validation Acc 79.98 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:80/200 AVG Training Loss:0.469 AVG Validation Loss:0.499 AVG Training Acc 80.59 % AVG Validation Acc 79.80 %\n",
      "Epoch:90/200 AVG Training Loss:0.465 AVG Validation Loss:0.503 AVG Training Acc 80.76 % AVG Validation Acc 79.26 %\n",
      "Epoch:100/200 AVG Training Loss:0.459 AVG Validation Loss:0.506 AVG Training Acc 80.93 % AVG Validation Acc 79.26 %\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:110/200 AVG Training Loss:0.459 AVG Validation Loss:0.505 AVG Training Acc 81.12 % AVG Validation Acc 79.53 %\n",
      "Epoch:120/200 AVG Training Loss:0.456 AVG Validation Loss:0.507 AVG Training Acc 80.97 % AVG Validation Acc 79.35 %\n",
      "Epoch:130/200 AVG Training Loss:0.458 AVG Validation Loss:0.510 AVG Training Acc 81.14 % AVG Validation Acc 79.35 %\n",
      "Epoch   134: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:140/200 AVG Training Loss:0.456 AVG Validation Loss:0.509 AVG Training Acc 81.02 % AVG Validation Acc 79.26 %\n",
      "Epoch:150/200 AVG Training Loss:0.456 AVG Validation Loss:0.508 AVG Training Acc 81.06 % AVG Validation Acc 79.26 %\n",
      "Epoch:160/200 AVG Training Loss:0.454 AVG Validation Loss:0.509 AVG Training Acc 81.14 % AVG Validation Acc 79.26 %\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:170/200 AVG Training Loss:0.457 AVG Validation Loss:0.509 AVG Training Acc 81.11 % AVG Validation Acc 79.26 %\n",
      "Epoch:180/200 AVG Training Loss:0.456 AVG Validation Loss:0.510 AVG Training Acc 81.11 % AVG Validation Acc 79.17 %\n",
      "Epoch:190/200 AVG Training Loss:0.457 AVG Validation Loss:0.508 AVG Training Acc 80.99 % AVG Validation Acc 79.35 %\n",
      "Epoch   196: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:200/200 AVG Training Loss:0.456 AVG Validation Loss:0.510 AVG Training Acc 81.12 % AVG Validation Acc 79.26 %\n",
      "Split 125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34dcd426b3b747ddb9e3adfb825f2a7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.498 AVG Training Acc 80.13 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.497 AVG Training Acc 80.18 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.500 AVG Training Acc 80.16 % AVG Validation Acc 79.80 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.480 AVG Validation Loss:0.502 AVG Training Acc 80.28 % AVG Validation Acc 79.62 %\n",
      "Epoch:50/200 AVG Training Loss:0.472 AVG Validation Loss:0.507 AVG Training Acc 80.48 % AVG Validation Acc 79.80 %\n",
      "Epoch:60/200 AVG Training Loss:0.467 AVG Validation Loss:0.514 AVG Training Acc 80.84 % AVG Validation Acc 79.44 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.459 AVG Validation Loss:0.517 AVG Training Acc 80.99 % AVG Validation Acc 78.90 %\n",
      "Epoch:80/200 AVG Training Loss:0.458 AVG Validation Loss:0.520 AVG Training Acc 81.06 % AVG Validation Acc 78.90 %\n",
      "Epoch:90/200 AVG Training Loss:0.456 AVG Validation Loss:0.522 AVG Training Acc 81.15 % AVG Validation Acc 78.81 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.455 AVG Validation Loss:0.523 AVG Training Acc 81.32 % AVG Validation Acc 78.99 %\n",
      "Epoch:110/200 AVG Training Loss:0.455 AVG Validation Loss:0.523 AVG Training Acc 81.38 % AVG Validation Acc 78.90 %\n",
      "Epoch:120/200 AVG Training Loss:0.455 AVG Validation Loss:0.524 AVG Training Acc 81.37 % AVG Validation Acc 78.90 %\n",
      "Epoch:130/200 AVG Training Loss:0.454 AVG Validation Loss:0.524 AVG Training Acc 81.51 % AVG Validation Acc 78.90 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.454 AVG Validation Loss:0.523 AVG Training Acc 81.23 % AVG Validation Acc 78.90 %\n",
      "Epoch:150/200 AVG Training Loss:0.455 AVG Validation Loss:0.524 AVG Training Acc 81.28 % AVG Validation Acc 78.81 %\n",
      "Epoch:160/200 AVG Training Loss:0.454 AVG Validation Loss:0.522 AVG Training Acc 81.18 % AVG Validation Acc 78.99 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.454 AVG Validation Loss:0.523 AVG Training Acc 81.34 % AVG Validation Acc 78.90 %\n",
      "Epoch:180/200 AVG Training Loss:0.455 AVG Validation Loss:0.524 AVG Training Acc 81.38 % AVG Validation Acc 78.81 %\n",
      "Epoch:190/200 AVG Training Loss:0.453 AVG Validation Loss:0.524 AVG Training Acc 81.46 % AVG Validation Acc 79.08 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.456 AVG Validation Loss:0.523 AVG Training Acc 81.20 % AVG Validation Acc 79.08 %\n",
      "Split 126\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "681cb64e35e34460b56a5562d322620d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.476 AVG Validation Loss:0.503 AVG Training Acc 80.82 % AVG Validation Acc 79.42 %\n",
      "Epoch:50/200 AVG Training Loss:0.467 AVG Validation Loss:0.514 AVG Training Acc 81.23 % AVG Validation Acc 78.88 %\n",
      "Epoch:60/200 AVG Training Loss:0.459 AVG Validation Loss:0.526 AVG Training Acc 81.55 % AVG Validation Acc 79.06 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.457 AVG Validation Loss:0.530 AVG Training Acc 81.80 % AVG Validation Acc 79.15 %\n",
      "Epoch:80/200 AVG Training Loss:0.453 AVG Validation Loss:0.531 AVG Training Acc 81.83 % AVG Validation Acc 79.15 %\n",
      "Epoch:90/200 AVG Training Loss:0.453 AVG Validation Loss:0.539 AVG Training Acc 81.95 % AVG Validation Acc 78.88 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.451 AVG Validation Loss:0.533 AVG Training Acc 81.87 % AVG Validation Acc 79.06 %\n",
      "Epoch:110/200 AVG Training Loss:0.453 AVG Validation Loss:0.533 AVG Training Acc 81.78 % AVG Validation Acc 79.06 %\n",
      "Epoch:120/200 AVG Training Loss:0.451 AVG Validation Loss:0.532 AVG Training Acc 82.02 % AVG Validation Acc 78.97 %\n",
      "Epoch:130/200 AVG Training Loss:0.452 AVG Validation Loss:0.537 AVG Training Acc 82.03 % AVG Validation Acc 78.70 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.452 AVG Validation Loss:0.532 AVG Training Acc 82.00 % AVG Validation Acc 79.15 %\n",
      "Epoch:150/200 AVG Training Loss:0.452 AVG Validation Loss:0.532 AVG Training Acc 81.88 % AVG Validation Acc 78.88 %\n",
      "Epoch:160/200 AVG Training Loss:0.453 AVG Validation Loss:0.532 AVG Training Acc 81.93 % AVG Validation Acc 79.15 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.452 AVG Validation Loss:0.534 AVG Training Acc 81.90 % AVG Validation Acc 78.97 %\n",
      "Epoch:180/200 AVG Training Loss:0.450 AVG Validation Loss:0.531 AVG Training Acc 82.05 % AVG Validation Acc 79.15 %\n",
      "Epoch:190/200 AVG Training Loss:0.451 AVG Validation Loss:0.532 AVG Training Acc 82.03 % AVG Validation Acc 79.06 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.451 AVG Validation Loss:0.535 AVG Training Acc 82.07 % AVG Validation Acc 78.79 %\n",
      "Split 127\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2edb1cca18c642889fd1e5a33e185216",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.472 AVG Validation Loss:0.499 AVG Training Acc 80.53 % AVG Validation Acc 79.78 %\n",
      "Epoch:60/200 AVG Training Loss:0.466 AVG Validation Loss:0.503 AVG Training Acc 80.79 % AVG Validation Acc 79.60 %\n",
      "Epoch:70/200 AVG Training Loss:0.461 AVG Validation Loss:0.505 AVG Training Acc 81.03 % AVG Validation Acc 79.60 %\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.456 AVG Validation Loss:0.516 AVG Training Acc 80.85 % AVG Validation Acc 79.60 %\n",
      "Epoch:90/200 AVG Training Loss:0.453 AVG Validation Loss:0.525 AVG Training Acc 81.16 % AVG Validation Acc 79.24 %\n",
      "Epoch:100/200 AVG Training Loss:0.455 AVG Validation Loss:0.522 AVG Training Acc 81.09 % AVG Validation Acc 79.51 %\n",
      "Epoch   106: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.454 AVG Validation Loss:0.525 AVG Training Acc 81.02 % AVG Validation Acc 79.42 %\n",
      "Epoch:120/200 AVG Training Loss:0.453 AVG Validation Loss:0.525 AVG Training Acc 81.08 % AVG Validation Acc 79.51 %\n",
      "Epoch:130/200 AVG Training Loss:0.453 AVG Validation Loss:0.531 AVG Training Acc 81.05 % AVG Validation Acc 79.42 %\n",
      "Epoch   137: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.454 AVG Validation Loss:0.525 AVG Training Acc 81.05 % AVG Validation Acc 79.51 %\n",
      "Epoch:150/200 AVG Training Loss:0.453 AVG Validation Loss:0.527 AVG Training Acc 81.08 % AVG Validation Acc 79.42 %\n",
      "Epoch:160/200 AVG Training Loss:0.455 AVG Validation Loss:0.525 AVG Training Acc 80.97 % AVG Validation Acc 79.15 %\n",
      "Epoch   168: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.453 AVG Validation Loss:0.525 AVG Training Acc 81.01 % AVG Validation Acc 79.42 %\n",
      "Epoch:180/200 AVG Training Loss:0.453 AVG Validation Loss:0.525 AVG Training Acc 80.97 % AVG Validation Acc 79.51 %\n",
      "Epoch:190/200 AVG Training Loss:0.452 AVG Validation Loss:0.528 AVG Training Acc 81.09 % AVG Validation Acc 79.42 %\n",
      "Epoch   199: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.454 AVG Validation Loss:0.525 AVG Training Acc 80.97 % AVG Validation Acc 79.42 %\n",
      "Split 128\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad5247578df4b59b26e98bd2ee24039",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.501 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.502 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.44 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.505 AVG Validation Loss:0.503 AVG Training Acc 80.12 % AVG Validation Acc 80.05 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.497 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.495 AVG Validation Loss:0.498 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:120/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Split 129\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1f4ee55934141a0a318380f00751a60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.491 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.491 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.485 AVG Validation Loss:0.492 AVG Training Acc 80.45 % AVG Validation Acc 80.14 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.472 AVG Validation Loss:0.493 AVG Training Acc 80.69 % AVG Validation Acc 79.60 %\n",
      "Epoch:60/200 AVG Training Loss:0.467 AVG Validation Loss:0.499 AVG Training Acc 80.84 % AVG Validation Acc 79.33 %\n",
      "Epoch:70/200 AVG Training Loss:0.463 AVG Validation Loss:0.505 AVG Training Acc 81.07 % AVG Validation Acc 79.60 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.459 AVG Validation Loss:0.514 AVG Training Acc 81.14 % AVG Validation Acc 79.51 %\n",
      "Epoch:90/200 AVG Training Loss:0.456 AVG Validation Loss:0.511 AVG Training Acc 81.22 % AVG Validation Acc 79.60 %\n",
      "Epoch:100/200 AVG Training Loss:0.456 AVG Validation Loss:0.514 AVG Training Acc 81.23 % AVG Validation Acc 79.42 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.456 AVG Validation Loss:0.517 AVG Training Acc 81.25 % AVG Validation Acc 79.42 %\n",
      "Epoch:120/200 AVG Training Loss:0.454 AVG Validation Loss:0.516 AVG Training Acc 81.36 % AVG Validation Acc 79.51 %\n",
      "Epoch:130/200 AVG Training Loss:0.457 AVG Validation Loss:0.519 AVG Training Acc 81.19 % AVG Validation Acc 79.42 %\n",
      "Epoch:140/200 AVG Training Loss:0.455 AVG Validation Loss:0.516 AVG Training Acc 81.23 % AVG Validation Acc 79.60 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.455 AVG Validation Loss:0.516 AVG Training Acc 81.36 % AVG Validation Acc 79.42 %\n",
      "Epoch:160/200 AVG Training Loss:0.455 AVG Validation Loss:0.516 AVG Training Acc 81.25 % AVG Validation Acc 79.51 %\n",
      "Epoch:170/200 AVG Training Loss:0.455 AVG Validation Loss:0.519 AVG Training Acc 81.36 % AVG Validation Acc 79.33 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.453 AVG Validation Loss:0.517 AVG Training Acc 81.24 % AVG Validation Acc 79.42 %\n",
      "Epoch:190/200 AVG Training Loss:0.455 AVG Validation Loss:0.515 AVG Training Acc 81.26 % AVG Validation Acc 79.51 %\n",
      "Epoch:200/200 AVG Training Loss:0.454 AVG Validation Loss:0.518 AVG Training Acc 81.26 % AVG Validation Acc 79.42 %\n",
      "Split 130\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ed381ddce54b98b188a11d054ae82f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.498 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.486 AVG Validation Loss:0.493 AVG Training Acc 80.18 % AVG Validation Acc 80.23 %\n",
      "Epoch:40/200 AVG Training Loss:0.481 AVG Validation Loss:0.494 AVG Training Acc 80.37 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.476 AVG Validation Loss:0.499 AVG Training Acc 80.48 % AVG Validation Acc 79.96 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.467 AVG Validation Loss:0.505 AVG Training Acc 80.81 % AVG Validation Acc 79.78 %\n",
      "Epoch:70/200 AVG Training Loss:0.467 AVG Validation Loss:0.508 AVG Training Acc 80.86 % AVG Validation Acc 79.87 %\n",
      "Epoch:80/200 AVG Training Loss:0.467 AVG Validation Loss:0.508 AVG Training Acc 80.84 % AVG Validation Acc 80.05 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.467 AVG Validation Loss:0.512 AVG Training Acc 80.91 % AVG Validation Acc 79.78 %\n",
      "Epoch:100/200 AVG Training Loss:0.465 AVG Validation Loss:0.510 AVG Training Acc 80.94 % AVG Validation Acc 79.69 %\n",
      "Epoch:110/200 AVG Training Loss:0.467 AVG Validation Loss:0.508 AVG Training Acc 80.92 % AVG Validation Acc 79.87 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.464 AVG Validation Loss:0.511 AVG Training Acc 81.01 % AVG Validation Acc 79.78 %\n",
      "Epoch:130/200 AVG Training Loss:0.467 AVG Validation Loss:0.510 AVG Training Acc 81.03 % AVG Validation Acc 79.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.465 AVG Validation Loss:0.511 AVG Training Acc 81.03 % AVG Validation Acc 79.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.465 AVG Validation Loss:0.509 AVG Training Acc 80.91 % AVG Validation Acc 79.69 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.465 AVG Validation Loss:0.510 AVG Training Acc 80.87 % AVG Validation Acc 79.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.466 AVG Validation Loss:0.508 AVG Training Acc 81.13 % AVG Validation Acc 79.87 %\n",
      "Epoch:180/200 AVG Training Loss:0.466 AVG Validation Loss:0.515 AVG Training Acc 80.95 % AVG Validation Acc 79.69 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.465 AVG Validation Loss:0.513 AVG Training Acc 80.98 % AVG Validation Acc 79.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.464 AVG Validation Loss:0.513 AVG Training Acc 80.99 % AVG Validation Acc 79.69 %\n",
      "Split 131\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60bd435761eb49eeb802a60eea0d522a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.499 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.498 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.18 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.472 AVG Validation Loss:0.500 AVG Training Acc 80.44 % AVG Validation Acc 79.98 %\n",
      "Epoch:60/200 AVG Training Loss:0.468 AVG Validation Loss:0.504 AVG Training Acc 80.41 % AVG Validation Acc 80.07 %\n",
      "Epoch:70/200 AVG Training Loss:0.460 AVG Validation Loss:0.513 AVG Training Acc 80.75 % AVG Validation Acc 80.07 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.459 AVG Validation Loss:0.516 AVG Training Acc 80.74 % AVG Validation Acc 79.89 %\n",
      "Epoch:90/200 AVG Training Loss:0.456 AVG Validation Loss:0.514 AVG Training Acc 80.76 % AVG Validation Acc 79.71 %\n",
      "Epoch:100/200 AVG Training Loss:0.454 AVG Validation Loss:0.519 AVG Training Acc 80.92 % AVG Validation Acc 79.71 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.454 AVG Validation Loss:0.516 AVG Training Acc 80.74 % AVG Validation Acc 79.71 %\n",
      "Epoch:120/200 AVG Training Loss:0.454 AVG Validation Loss:0.520 AVG Training Acc 80.85 % AVG Validation Acc 79.62 %\n",
      "Epoch:130/200 AVG Training Loss:0.455 AVG Validation Loss:0.516 AVG Training Acc 80.81 % AVG Validation Acc 79.62 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.451 AVG Validation Loss:0.519 AVG Training Acc 80.96 % AVG Validation Acc 79.62 %\n",
      "Epoch:150/200 AVG Training Loss:0.453 AVG Validation Loss:0.520 AVG Training Acc 80.76 % AVG Validation Acc 79.53 %\n",
      "Epoch:160/200 AVG Training Loss:0.453 AVG Validation Loss:0.514 AVG Training Acc 80.65 % AVG Validation Acc 79.53 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.453 AVG Validation Loss:0.521 AVG Training Acc 81.02 % AVG Validation Acc 79.71 %\n",
      "Epoch:180/200 AVG Training Loss:0.453 AVG Validation Loss:0.517 AVG Training Acc 80.97 % AVG Validation Acc 79.71 %\n",
      "Epoch:190/200 AVG Training Loss:0.452 AVG Validation Loss:0.518 AVG Training Acc 80.83 % AVG Validation Acc 79.62 %\n",
      "Epoch:200/200 AVG Training Loss:0.453 AVG Validation Loss:0.520 AVG Training Acc 80.83 % AVG Validation Acc 79.71 %\n",
      "Epoch   200: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Split 132\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83185b9d7f284a6a882cb883e5cd5a06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.21 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.492 AVG Training Acc 80.21 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.35 % AVG Validation Acc 80.07 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.53 % AVG Validation Acc 79.80 %\n",
      "Epoch:70/200 AVG Training Loss:0.481 AVG Validation Loss:0.502 AVG Training Acc 80.59 % AVG Validation Acc 79.89 %\n",
      "Epoch:80/200 AVG Training Loss:0.478 AVG Validation Loss:0.507 AVG Training Acc 80.80 % AVG Validation Acc 79.80 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.476 AVG Validation Loss:0.509 AVG Training Acc 80.83 % AVG Validation Acc 80.07 %\n",
      "Epoch:100/200 AVG Training Loss:0.474 AVG Validation Loss:0.507 AVG Training Acc 80.79 % AVG Validation Acc 79.98 %\n",
      "Epoch:110/200 AVG Training Loss:0.476 AVG Validation Loss:0.511 AVG Training Acc 80.72 % AVG Validation Acc 79.80 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.472 AVG Validation Loss:0.508 AVG Training Acc 80.93 % AVG Validation Acc 79.71 %\n",
      "Epoch:130/200 AVG Training Loss:0.475 AVG Validation Loss:0.510 AVG Training Acc 80.88 % AVG Validation Acc 79.62 %\n",
      "Epoch:140/200 AVG Training Loss:0.476 AVG Validation Loss:0.508 AVG Training Acc 80.79 % AVG Validation Acc 79.89 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.474 AVG Validation Loss:0.511 AVG Training Acc 80.94 % AVG Validation Acc 79.89 %\n",
      "Epoch:160/200 AVG Training Loss:0.476 AVG Validation Loss:0.511 AVG Training Acc 80.72 % AVG Validation Acc 79.80 %\n",
      "Epoch:170/200 AVG Training Loss:0.475 AVG Validation Loss:0.509 AVG Training Acc 80.81 % AVG Validation Acc 79.80 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.476 AVG Validation Loss:0.511 AVG Training Acc 80.82 % AVG Validation Acc 79.71 %\n",
      "Epoch:190/200 AVG Training Loss:0.475 AVG Validation Loss:0.509 AVG Training Acc 80.85 % AVG Validation Acc 79.71 %\n",
      "Epoch:200/200 AVG Training Loss:0.473 AVG Validation Loss:0.510 AVG Training Acc 80.87 % AVG Validation Acc 79.71 %\n",
      "Split 133\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3051da6538ae46ff8fb3d5c88814c067",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.37 % AVG Validation Acc 80.25 %\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.477 AVG Validation Loss:0.507 AVG Training Acc 80.57 % AVG Validation Acc 79.71 %\n",
      "Epoch:50/200 AVG Training Loss:0.468 AVG Validation Loss:0.521 AVG Training Acc 80.75 % AVG Validation Acc 79.35 %\n",
      "Epoch:60/200 AVG Training Loss:0.462 AVG Validation Loss:0.532 AVG Training Acc 81.13 % AVG Validation Acc 79.08 %\n",
      "Epoch:70/200 AVG Training Loss:0.458 AVG Validation Loss:0.532 AVG Training Acc 81.35 % AVG Validation Acc 79.17 %\n",
      "Epoch    70: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.456 AVG Validation Loss:0.531 AVG Training Acc 81.38 % AVG Validation Acc 79.17 %\n",
      "Epoch:90/200 AVG Training Loss:0.453 AVG Validation Loss:0.536 AVG Training Acc 81.53 % AVG Validation Acc 78.99 %\n",
      "Epoch:100/200 AVG Training Loss:0.454 AVG Validation Loss:0.537 AVG Training Acc 81.31 % AVG Validation Acc 78.99 %\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.454 AVG Validation Loss:0.538 AVG Training Acc 81.57 % AVG Validation Acc 78.99 %\n",
      "Epoch:120/200 AVG Training Loss:0.454 AVG Validation Loss:0.539 AVG Training Acc 81.46 % AVG Validation Acc 78.81 %\n",
      "Epoch:130/200 AVG Training Loss:0.454 AVG Validation Loss:0.533 AVG Training Acc 81.48 % AVG Validation Acc 79.08 %\n",
      "Epoch   132: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.453 AVG Validation Loss:0.538 AVG Training Acc 81.61 % AVG Validation Acc 78.81 %\n",
      "Epoch:150/200 AVG Training Loss:0.453 AVG Validation Loss:0.542 AVG Training Acc 81.59 % AVG Validation Acc 78.90 %\n",
      "Epoch:160/200 AVG Training Loss:0.453 AVG Validation Loss:0.543 AVG Training Acc 81.51 % AVG Validation Acc 78.63 %\n",
      "Epoch   163: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.454 AVG Validation Loss:0.534 AVG Training Acc 81.62 % AVG Validation Acc 78.90 %\n",
      "Epoch:180/200 AVG Training Loss:0.452 AVG Validation Loss:0.535 AVG Training Acc 81.60 % AVG Validation Acc 78.99 %\n",
      "Epoch:190/200 AVG Training Loss:0.453 AVG Validation Loss:0.538 AVG Training Acc 81.49 % AVG Validation Acc 79.17 %\n",
      "Epoch   194: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.453 AVG Validation Loss:0.538 AVG Training Acc 81.27 % AVG Validation Acc 78.90 %\n",
      "Split 134\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab30ba4ae9e144aa989a80d0772e8909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.29 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.475 AVG Validation Loss:0.495 AVG Training Acc 80.59 % AVG Validation Acc 79.89 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.459 AVG Validation Loss:0.515 AVG Training Acc 80.84 % AVG Validation Acc 79.53 %\n",
      "Epoch:70/200 AVG Training Loss:0.445 AVG Validation Loss:0.538 AVG Training Acc 81.42 % AVG Validation Acc 78.90 %\n",
      "Epoch:80/200 AVG Training Loss:0.436 AVG Validation Loss:0.544 AVG Training Acc 81.81 % AVG Validation Acc 78.09 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.433 AVG Validation Loss:0.541 AVG Training Acc 82.02 % AVG Validation Acc 78.72 %\n",
      "Epoch:100/200 AVG Training Loss:0.429 AVG Validation Loss:0.552 AVG Training Acc 82.10 % AVG Validation Acc 78.00 %\n",
      "Epoch:110/200 AVG Training Loss:0.426 AVG Validation Loss:0.550 AVG Training Acc 82.15 % AVG Validation Acc 78.00 %\n",
      "Epoch:120/200 AVG Training Loss:0.429 AVG Validation Loss:0.556 AVG Training Acc 82.14 % AVG Validation Acc 77.91 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.427 AVG Validation Loss:0.545 AVG Training Acc 82.25 % AVG Validation Acc 78.00 %\n",
      "Epoch:140/200 AVG Training Loss:0.429 AVG Validation Loss:0.554 AVG Training Acc 82.14 % AVG Validation Acc 78.18 %\n",
      "Epoch:150/200 AVG Training Loss:0.425 AVG Validation Loss:0.557 AVG Training Acc 82.47 % AVG Validation Acc 77.91 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.426 AVG Validation Loss:0.554 AVG Training Acc 82.38 % AVG Validation Acc 77.73 %\n",
      "Epoch:170/200 AVG Training Loss:0.425 AVG Validation Loss:0.564 AVG Training Acc 82.09 % AVG Validation Acc 77.64 %\n",
      "Epoch:180/200 AVG Training Loss:0.427 AVG Validation Loss:0.549 AVG Training Acc 82.15 % AVG Validation Acc 78.00 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.426 AVG Validation Loss:0.555 AVG Training Acc 82.35 % AVG Validation Acc 77.73 %\n",
      "Epoch:200/200 AVG Training Loss:0.426 AVG Validation Loss:0.557 AVG Training Acc 82.38 % AVG Validation Acc 78.27 %\n",
      "Split 135\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e64b67ffbe934a0c8cb771fe913ab46c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.23 % AVG Validation Acc 79.89 %\n",
      "Epoch:40/200 AVG Training Loss:0.482 AVG Validation Loss:0.499 AVG Training Acc 80.28 % AVG Validation Acc 79.89 %\n",
      "Epoch:50/200 AVG Training Loss:0.481 AVG Validation Loss:0.498 AVG Training Acc 80.31 % AVG Validation Acc 79.89 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.478 AVG Validation Loss:0.505 AVG Training Acc 80.39 % AVG Validation Acc 79.80 %\n",
      "Epoch:70/200 AVG Training Loss:0.478 AVG Validation Loss:0.506 AVG Training Acc 80.43 % AVG Validation Acc 79.80 %\n",
      "Epoch:80/200 AVG Training Loss:0.477 AVG Validation Loss:0.505 AVG Training Acc 80.39 % AVG Validation Acc 79.80 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.477 AVG Validation Loss:0.506 AVG Training Acc 80.37 % AVG Validation Acc 79.71 %\n",
      "Epoch:100/200 AVG Training Loss:0.477 AVG Validation Loss:0.507 AVG Training Acc 80.41 % AVG Validation Acc 79.62 %\n",
      "Epoch:110/200 AVG Training Loss:0.476 AVG Validation Loss:0.511 AVG Training Acc 80.46 % AVG Validation Acc 79.62 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.475 AVG Validation Loss:0.507 AVG Training Acc 80.46 % AVG Validation Acc 79.71 %\n",
      "Epoch:130/200 AVG Training Loss:0.476 AVG Validation Loss:0.507 AVG Training Acc 80.45 % AVG Validation Acc 79.71 %\n",
      "Epoch:140/200 AVG Training Loss:0.477 AVG Validation Loss:0.510 AVG Training Acc 80.46 % AVG Validation Acc 79.62 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.477 AVG Validation Loss:0.510 AVG Training Acc 80.42 % AVG Validation Acc 79.62 %\n",
      "Epoch:160/200 AVG Training Loss:0.477 AVG Validation Loss:0.507 AVG Training Acc 80.44 % AVG Validation Acc 79.71 %\n",
      "Epoch:170/200 AVG Training Loss:0.477 AVG Validation Loss:0.507 AVG Training Acc 80.41 % AVG Validation Acc 79.71 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.476 AVG Validation Loss:0.510 AVG Training Acc 80.48 % AVG Validation Acc 79.62 %\n",
      "Epoch:190/200 AVG Training Loss:0.476 AVG Validation Loss:0.508 AVG Training Acc 80.41 % AVG Validation Acc 79.71 %\n",
      "Epoch:200/200 AVG Training Loss:0.476 AVG Validation Loss:0.511 AVG Training Acc 80.48 % AVG Validation Acc 79.62 %\n",
      "Split 136\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22628d5b01ce4737bfb50b7163d2270a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.18 % AVG Validation Acc 80.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.485 AVG Validation Loss:0.492 AVG Training Acc 80.34 % AVG Validation Acc 80.05 %\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.472 AVG Validation Loss:0.499 AVG Training Acc 80.67 % AVG Validation Acc 79.96 %\n",
      "Epoch:60/200 AVG Training Loss:0.464 AVG Validation Loss:0.509 AVG Training Acc 80.86 % AVG Validation Acc 79.60 %\n",
      "Epoch:70/200 AVG Training Loss:0.458 AVG Validation Loss:0.519 AVG Training Acc 81.07 % AVG Validation Acc 79.24 %\n",
      "Epoch    71: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.457 AVG Validation Loss:0.525 AVG Training Acc 81.12 % AVG Validation Acc 79.06 %\n",
      "Epoch:90/200 AVG Training Loss:0.455 AVG Validation Loss:0.527 AVG Training Acc 81.17 % AVG Validation Acc 78.97 %\n",
      "Epoch:100/200 AVG Training Loss:0.456 AVG Validation Loss:0.527 AVG Training Acc 81.25 % AVG Validation Acc 79.15 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.452 AVG Validation Loss:0.534 AVG Training Acc 81.17 % AVG Validation Acc 79.15 %\n",
      "Epoch:120/200 AVG Training Loss:0.454 AVG Validation Loss:0.528 AVG Training Acc 81.20 % AVG Validation Acc 79.06 %\n",
      "Epoch:130/200 AVG Training Loss:0.455 AVG Validation Loss:0.532 AVG Training Acc 81.16 % AVG Validation Acc 79.15 %\n",
      "Epoch   133: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.455 AVG Validation Loss:0.528 AVG Training Acc 81.10 % AVG Validation Acc 78.97 %\n",
      "Epoch:150/200 AVG Training Loss:0.453 AVG Validation Loss:0.530 AVG Training Acc 81.32 % AVG Validation Acc 78.97 %\n",
      "Epoch:160/200 AVG Training Loss:0.456 AVG Validation Loss:0.531 AVG Training Acc 81.05 % AVG Validation Acc 79.15 %\n",
      "Epoch   164: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.453 AVG Validation Loss:0.530 AVG Training Acc 81.02 % AVG Validation Acc 79.06 %\n",
      "Epoch:180/200 AVG Training Loss:0.453 AVG Validation Loss:0.529 AVG Training Acc 81.14 % AVG Validation Acc 79.06 %\n",
      "Epoch:190/200 AVG Training Loss:0.453 AVG Validation Loss:0.531 AVG Training Acc 81.12 % AVG Validation Acc 78.97 %\n",
      "Epoch   195: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.455 AVG Validation Loss:0.531 AVG Training Acc 81.22 % AVG Validation Acc 78.97 %\n",
      "Split 137\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b347f16654945a590039a1808c06dba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.492 AVG Training Acc 80.20 % AVG Validation Acc 79.96 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.490 AVG Training Acc 80.23 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.490 AVG Training Acc 80.18 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.481 AVG Validation Loss:0.489 AVG Training Acc 80.33 % AVG Validation Acc 79.96 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.466 AVG Validation Loss:0.492 AVG Training Acc 80.79 % AVG Validation Acc 79.69 %\n",
      "Epoch:70/200 AVG Training Loss:0.458 AVG Validation Loss:0.499 AVG Training Acc 81.03 % AVG Validation Acc 79.60 %\n",
      "Epoch:80/200 AVG Training Loss:0.453 AVG Validation Loss:0.499 AVG Training Acc 81.22 % AVG Validation Acc 79.33 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.446 AVG Validation Loss:0.500 AVG Training Acc 81.50 % AVG Validation Acc 79.15 %\n",
      "Epoch:100/200 AVG Training Loss:0.445 AVG Validation Loss:0.503 AVG Training Acc 81.62 % AVG Validation Acc 79.24 %\n",
      "Epoch:110/200 AVG Training Loss:0.445 AVG Validation Loss:0.504 AVG Training Acc 81.46 % AVG Validation Acc 79.33 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.444 AVG Validation Loss:0.505 AVG Training Acc 81.55 % AVG Validation Acc 79.24 %\n",
      "Epoch:130/200 AVG Training Loss:0.443 AVG Validation Loss:0.511 AVG Training Acc 81.54 % AVG Validation Acc 79.24 %\n",
      "Epoch:140/200 AVG Training Loss:0.442 AVG Validation Loss:0.507 AVG Training Acc 81.53 % AVG Validation Acc 79.06 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.444 AVG Validation Loss:0.503 AVG Training Acc 81.64 % AVG Validation Acc 79.51 %\n",
      "Epoch:160/200 AVG Training Loss:0.445 AVG Validation Loss:0.504 AVG Training Acc 81.67 % AVG Validation Acc 79.42 %\n",
      "Epoch:170/200 AVG Training Loss:0.445 AVG Validation Loss:0.505 AVG Training Acc 81.60 % AVG Validation Acc 79.51 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.442 AVG Validation Loss:0.506 AVG Training Acc 81.53 % AVG Validation Acc 79.42 %\n",
      "Epoch:190/200 AVG Training Loss:0.442 AVG Validation Loss:0.506 AVG Training Acc 81.68 % AVG Validation Acc 79.24 %\n",
      "Epoch:200/200 AVG Training Loss:0.443 AVG Validation Loss:0.503 AVG Training Acc 81.63 % AVG Validation Acc 79.33 %\n",
      "Split 138\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "728d0dd07e6f4e2aadbda6d46d25b252",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.09 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.24 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.482 AVG Validation Loss:0.493 AVG Training Acc 80.41 % AVG Validation Acc 79.87 %\n",
      "Epoch:60/200 AVG Training Loss:0.478 AVG Validation Loss:0.502 AVG Training Acc 80.67 % AVG Validation Acc 79.87 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.474 AVG Validation Loss:0.507 AVG Training Acc 80.76 % AVG Validation Acc 79.78 %\n",
      "Epoch:80/200 AVG Training Loss:0.474 AVG Validation Loss:0.508 AVG Training Acc 80.82 % AVG Validation Acc 79.78 %\n",
      "Epoch:90/200 AVG Training Loss:0.473 AVG Validation Loss:0.509 AVG Training Acc 80.73 % AVG Validation Acc 79.87 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.472 AVG Validation Loss:0.509 AVG Training Acc 80.86 % AVG Validation Acc 79.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.472 AVG Validation Loss:0.509 AVG Training Acc 80.84 % AVG Validation Acc 79.78 %\n",
      "Epoch:120/200 AVG Training Loss:0.472 AVG Validation Loss:0.509 AVG Training Acc 80.86 % AVG Validation Acc 79.78 %\n",
      "Epoch:130/200 AVG Training Loss:0.473 AVG Validation Loss:0.507 AVG Training Acc 80.79 % AVG Validation Acc 79.78 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.472 AVG Validation Loss:0.510 AVG Training Acc 80.84 % AVG Validation Acc 79.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.471 AVG Validation Loss:0.509 AVG Training Acc 80.87 % AVG Validation Acc 79.78 %\n",
      "Epoch:160/200 AVG Training Loss:0.472 AVG Validation Loss:0.510 AVG Training Acc 80.84 % AVG Validation Acc 79.78 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.471 AVG Validation Loss:0.509 AVG Training Acc 80.80 % AVG Validation Acc 79.78 %\n",
      "Epoch:180/200 AVG Training Loss:0.470 AVG Validation Loss:0.510 AVG Training Acc 80.86 % AVG Validation Acc 79.78 %\n",
      "Epoch:190/200 AVG Training Loss:0.471 AVG Validation Loss:0.509 AVG Training Acc 80.85 % AVG Validation Acc 79.78 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.472 AVG Validation Loss:0.510 AVG Training Acc 80.82 % AVG Validation Acc 79.87 %\n",
      "Split 139\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb78debcaa04d26b56f62729b6d03bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.496 AVG Training Acc 80.22 % AVG Validation Acc 79.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.25 % AVG Validation Acc 79.96 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.474 AVG Validation Loss:0.506 AVG Training Acc 80.59 % AVG Validation Acc 79.24 %\n",
      "Epoch:60/200 AVG Training Loss:0.468 AVG Validation Loss:0.514 AVG Training Acc 80.68 % AVG Validation Acc 79.33 %\n",
      "Epoch:70/200 AVG Training Loss:0.462 AVG Validation Loss:0.524 AVG Training Acc 81.00 % AVG Validation Acc 79.24 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.457 AVG Validation Loss:0.529 AVG Training Acc 81.22 % AVG Validation Acc 79.24 %\n",
      "Epoch:90/200 AVG Training Loss:0.455 AVG Validation Loss:0.529 AVG Training Acc 80.96 % AVG Validation Acc 79.06 %\n",
      "Epoch:100/200 AVG Training Loss:0.455 AVG Validation Loss:0.531 AVG Training Acc 81.26 % AVG Validation Acc 78.79 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.455 AVG Validation Loss:0.527 AVG Training Acc 81.14 % AVG Validation Acc 79.06 %\n",
      "Epoch:120/200 AVG Training Loss:0.453 AVG Validation Loss:0.532 AVG Training Acc 81.23 % AVG Validation Acc 79.24 %\n",
      "Epoch:130/200 AVG Training Loss:0.454 AVG Validation Loss:0.529 AVG Training Acc 81.16 % AVG Validation Acc 79.06 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.455 AVG Validation Loss:0.530 AVG Training Acc 81.20 % AVG Validation Acc 79.15 %\n",
      "Epoch:150/200 AVG Training Loss:0.454 AVG Validation Loss:0.530 AVG Training Acc 81.22 % AVG Validation Acc 79.24 %\n",
      "Epoch:160/200 AVG Training Loss:0.454 AVG Validation Loss:0.530 AVG Training Acc 81.11 % AVG Validation Acc 79.24 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.456 AVG Validation Loss:0.529 AVG Training Acc 81.09 % AVG Validation Acc 79.42 %\n",
      "Epoch:180/200 AVG Training Loss:0.455 AVG Validation Loss:0.529 AVG Training Acc 81.15 % AVG Validation Acc 78.97 %\n",
      "Epoch:190/200 AVG Training Loss:0.455 AVG Validation Loss:0.528 AVG Training Acc 81.20 % AVG Validation Acc 79.24 %\n",
      "Epoch   198: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.454 AVG Validation Loss:0.529 AVG Training Acc 81.22 % AVG Validation Acc 79.06 %\n",
      "Split 140\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4430f75cfa0f47cf97f64beb85345c29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.28 % AVG Validation Acc 80.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.23 % AVG Validation Acc 79.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.40 % AVG Validation Acc 79.69 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.480 AVG Validation Loss:0.500 AVG Training Acc 80.44 % AVG Validation Acc 79.51 %\n",
      "Epoch:60/200 AVG Training Loss:0.480 AVG Validation Loss:0.503 AVG Training Acc 80.45 % AVG Validation Acc 79.51 %\n",
      "Epoch:70/200 AVG Training Loss:0.478 AVG Validation Loss:0.503 AVG Training Acc 80.58 % AVG Validation Acc 79.42 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.478 AVG Validation Loss:0.504 AVG Training Acc 80.56 % AVG Validation Acc 79.42 %\n",
      "Epoch:90/200 AVG Training Loss:0.477 AVG Validation Loss:0.505 AVG Training Acc 80.63 % AVG Validation Acc 79.42 %\n",
      "Epoch:100/200 AVG Training Loss:0.478 AVG Validation Loss:0.504 AVG Training Acc 80.60 % AVG Validation Acc 79.42 %\n",
      "Epoch:110/200 AVG Training Loss:0.478 AVG Validation Loss:0.504 AVG Training Acc 80.58 % AVG Validation Acc 79.42 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.478 AVG Validation Loss:0.505 AVG Training Acc 80.59 % AVG Validation Acc 79.42 %\n",
      "Epoch:130/200 AVG Training Loss:0.477 AVG Validation Loss:0.505 AVG Training Acc 80.51 % AVG Validation Acc 79.42 %\n",
      "Epoch:140/200 AVG Training Loss:0.477 AVG Validation Loss:0.504 AVG Training Acc 80.69 % AVG Validation Acc 79.42 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.477 AVG Validation Loss:0.505 AVG Training Acc 80.64 % AVG Validation Acc 79.42 %\n",
      "Epoch:160/200 AVG Training Loss:0.477 AVG Validation Loss:0.505 AVG Training Acc 80.66 % AVG Validation Acc 79.42 %\n",
      "Epoch:170/200 AVG Training Loss:0.478 AVG Validation Loss:0.505 AVG Training Acc 80.58 % AVG Validation Acc 79.42 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.477 AVG Validation Loss:0.504 AVG Training Acc 80.62 % AVG Validation Acc 79.42 %\n",
      "Epoch:190/200 AVG Training Loss:0.477 AVG Validation Loss:0.504 AVG Training Acc 80.65 % AVG Validation Acc 79.42 %\n",
      "Epoch:200/200 AVG Training Loss:0.477 AVG Validation Loss:0.505 AVG Training Acc 80.62 % AVG Validation Acc 79.42 %\n",
      "Split 141\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1df7841547f84ba3812224805bee0954",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.23 % AVG Validation Acc 80.07 %\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.41 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.473 AVG Validation Loss:0.506 AVG Training Acc 80.56 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.467 AVG Validation Loss:0.518 AVG Training Acc 80.72 % AVG Validation Acc 79.98 %\n",
      "Epoch:70/200 AVG Training Loss:0.461 AVG Validation Loss:0.537 AVG Training Acc 80.93 % AVG Validation Acc 79.44 %\n",
      "Epoch    70: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.461 AVG Validation Loss:0.532 AVG Training Acc 80.92 % AVG Validation Acc 79.53 %\n",
      "Epoch:90/200 AVG Training Loss:0.460 AVG Validation Loss:0.535 AVG Training Acc 80.95 % AVG Validation Acc 79.44 %\n",
      "Epoch:100/200 AVG Training Loss:0.459 AVG Validation Loss:0.533 AVG Training Acc 80.89 % AVG Validation Acc 79.53 %\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.459 AVG Validation Loss:0.534 AVG Training Acc 81.02 % AVG Validation Acc 79.53 %\n",
      "Epoch:120/200 AVG Training Loss:0.458 AVG Validation Loss:0.537 AVG Training Acc 81.04 % AVG Validation Acc 79.53 %\n",
      "Epoch:130/200 AVG Training Loss:0.459 AVG Validation Loss:0.540 AVG Training Acc 81.06 % AVG Validation Acc 79.35 %\n",
      "Epoch   132: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.458 AVG Validation Loss:0.537 AVG Training Acc 81.02 % AVG Validation Acc 79.44 %\n",
      "Epoch:150/200 AVG Training Loss:0.459 AVG Validation Loss:0.541 AVG Training Acc 80.96 % AVG Validation Acc 79.62 %\n",
      "Epoch:160/200 AVG Training Loss:0.460 AVG Validation Loss:0.540 AVG Training Acc 80.95 % AVG Validation Acc 79.44 %\n",
      "Epoch   163: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.457 AVG Validation Loss:0.540 AVG Training Acc 81.06 % AVG Validation Acc 79.53 %\n",
      "Epoch:180/200 AVG Training Loss:0.459 AVG Validation Loss:0.537 AVG Training Acc 81.03 % AVG Validation Acc 79.35 %\n",
      "Epoch:190/200 AVG Training Loss:0.458 AVG Validation Loss:0.540 AVG Training Acc 81.01 % AVG Validation Acc 79.44 %\n",
      "Epoch   194: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.460 AVG Validation Loss:0.537 AVG Training Acc 80.93 % AVG Validation Acc 79.62 %\n",
      "Split 142\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83c0139cafb6442686c067fdaa1ab7d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.497 AVG Training Acc 80.08 % AVG Validation Acc 80.16 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.20 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.483 AVG Validation Loss:0.504 AVG Training Acc 80.25 % AVG Validation Acc 80.07 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.481 AVG Validation Loss:0.505 AVG Training Acc 80.31 % AVG Validation Acc 79.98 %\n",
      "Epoch:70/200 AVG Training Loss:0.480 AVG Validation Loss:0.505 AVG Training Acc 80.25 % AVG Validation Acc 79.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.479 AVG Validation Loss:0.506 AVG Training Acc 80.36 % AVG Validation Acc 80.07 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.480 AVG Validation Loss:0.504 AVG Training Acc 80.27 % AVG Validation Acc 80.07 %\n",
      "Epoch:100/200 AVG Training Loss:0.480 AVG Validation Loss:0.507 AVG Training Acc 80.20 % AVG Validation Acc 79.98 %\n",
      "Epoch:110/200 AVG Training Loss:0.480 AVG Validation Loss:0.504 AVG Training Acc 80.33 % AVG Validation Acc 79.98 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.479 AVG Validation Loss:0.507 AVG Training Acc 80.32 % AVG Validation Acc 79.98 %\n",
      "Epoch:130/200 AVG Training Loss:0.480 AVG Validation Loss:0.504 AVG Training Acc 80.27 % AVG Validation Acc 80.07 %\n",
      "Epoch:140/200 AVG Training Loss:0.479 AVG Validation Loss:0.505 AVG Training Acc 80.39 % AVG Validation Acc 79.98 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.479 AVG Validation Loss:0.504 AVG Training Acc 80.34 % AVG Validation Acc 79.98 %\n",
      "Epoch:160/200 AVG Training Loss:0.480 AVG Validation Loss:0.506 AVG Training Acc 80.37 % AVG Validation Acc 79.98 %\n",
      "Epoch:170/200 AVG Training Loss:0.479 AVG Validation Loss:0.508 AVG Training Acc 80.35 % AVG Validation Acc 80.07 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.479 AVG Validation Loss:0.506 AVG Training Acc 80.33 % AVG Validation Acc 79.98 %\n",
      "Epoch:190/200 AVG Training Loss:0.481 AVG Validation Loss:0.505 AVG Training Acc 80.25 % AVG Validation Acc 79.98 %\n",
      "Epoch:200/200 AVG Training Loss:0.479 AVG Validation Loss:0.505 AVG Training Acc 80.34 % AVG Validation Acc 80.07 %\n",
      "Split 143\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db05b9a465894e89b48abb78d765f430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.493 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.491 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.23 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.492 AVG Validation Loss:0.487 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.493 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.465 AVG Validation Loss:0.500 AVG Training Acc 80.40 % AVG Validation Acc 79.98 %\n",
      "Epoch:70/200 AVG Training Loss:0.457 AVG Validation Loss:0.513 AVG Training Acc 80.68 % AVG Validation Acc 79.89 %\n",
      "Epoch:80/200 AVG Training Loss:0.453 AVG Validation Loss:0.521 AVG Training Acc 80.81 % AVG Validation Acc 79.98 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.447 AVG Validation Loss:0.523 AVG Training Acc 80.96 % AVG Validation Acc 79.80 %\n",
      "Epoch:100/200 AVG Training Loss:0.446 AVG Validation Loss:0.525 AVG Training Acc 80.79 % AVG Validation Acc 79.80 %\n",
      "Epoch:110/200 AVG Training Loss:0.445 AVG Validation Loss:0.527 AVG Training Acc 81.03 % AVG Validation Acc 79.80 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.445 AVG Validation Loss:0.527 AVG Training Acc 81.00 % AVG Validation Acc 79.62 %\n",
      "Epoch:130/200 AVG Training Loss:0.445 AVG Validation Loss:0.529 AVG Training Acc 80.97 % AVG Validation Acc 79.80 %\n",
      "Epoch:140/200 AVG Training Loss:0.445 AVG Validation Loss:0.527 AVG Training Acc 80.90 % AVG Validation Acc 79.62 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.445 AVG Validation Loss:0.526 AVG Training Acc 80.98 % AVG Validation Acc 79.80 %\n",
      "Epoch:160/200 AVG Training Loss:0.445 AVG Validation Loss:0.528 AVG Training Acc 80.96 % AVG Validation Acc 79.80 %\n",
      "Epoch:170/200 AVG Training Loss:0.444 AVG Validation Loss:0.528 AVG Training Acc 81.19 % AVG Validation Acc 79.80 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.445 AVG Validation Loss:0.533 AVG Training Acc 80.99 % AVG Validation Acc 79.80 %\n",
      "Epoch:190/200 AVG Training Loss:0.446 AVG Validation Loss:0.529 AVG Training Acc 80.91 % AVG Validation Acc 79.71 %\n",
      "Epoch:200/200 AVG Training Loss:0.445 AVG Validation Loss:0.527 AVG Training Acc 80.85 % AVG Validation Acc 79.89 %\n",
      "Split 144\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f92a7a884aa45e7bf67a6ca5d70c246",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.497 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.480 AVG Validation Loss:0.503 AVG Training Acc 80.35 % AVG Validation Acc 79.62 %\n",
      "Epoch:50/200 AVG Training Loss:0.477 AVG Validation Loss:0.510 AVG Training Acc 80.38 % AVG Validation Acc 79.53 %\n",
      "Epoch:60/200 AVG Training Loss:0.471 AVG Validation Loss:0.522 AVG Training Acc 80.67 % AVG Validation Acc 79.26 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.468 AVG Validation Loss:0.529 AVG Training Acc 80.70 % AVG Validation Acc 79.35 %\n",
      "Epoch:80/200 AVG Training Loss:0.467 AVG Validation Loss:0.532 AVG Training Acc 80.75 % AVG Validation Acc 79.44 %\n",
      "Epoch:90/200 AVG Training Loss:0.464 AVG Validation Loss:0.535 AVG Training Acc 80.80 % AVG Validation Acc 79.44 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.464 AVG Validation Loss:0.537 AVG Training Acc 80.86 % AVG Validation Acc 79.35 %\n",
      "Epoch:110/200 AVG Training Loss:0.465 AVG Validation Loss:0.536 AVG Training Acc 80.82 % AVG Validation Acc 79.35 %\n",
      "Epoch:120/200 AVG Training Loss:0.464 AVG Validation Loss:0.538 AVG Training Acc 80.83 % AVG Validation Acc 79.35 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.464 AVG Validation Loss:0.540 AVG Training Acc 80.98 % AVG Validation Acc 79.35 %\n",
      "Epoch:140/200 AVG Training Loss:0.465 AVG Validation Loss:0.537 AVG Training Acc 80.78 % AVG Validation Acc 79.35 %\n",
      "Epoch:150/200 AVG Training Loss:0.464 AVG Validation Loss:0.536 AVG Training Acc 80.83 % AVG Validation Acc 79.44 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.465 AVG Validation Loss:0.540 AVG Training Acc 80.79 % AVG Validation Acc 79.44 %\n",
      "Epoch:170/200 AVG Training Loss:0.465 AVG Validation Loss:0.539 AVG Training Acc 80.69 % AVG Validation Acc 79.35 %\n",
      "Epoch:180/200 AVG Training Loss:0.464 AVG Validation Loss:0.536 AVG Training Acc 80.89 % AVG Validation Acc 79.44 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.465 AVG Validation Loss:0.539 AVG Training Acc 80.76 % AVG Validation Acc 79.44 %\n",
      "Epoch:200/200 AVG Training Loss:0.465 AVG Validation Loss:0.536 AVG Training Acc 80.88 % AVG Validation Acc 79.35 %\n",
      "Split 145\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7952c7c45b0d4f7b93880e8d7b2c3f72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.481 AVG Validation Loss:0.493 AVG Training Acc 80.29 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.469 AVG Validation Loss:0.493 AVG Training Acc 80.54 % AVG Validation Acc 80.25 %\n",
      "Epoch:60/200 AVG Training Loss:0.466 AVG Validation Loss:0.493 AVG Training Acc 80.63 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.460 AVG Validation Loss:0.499 AVG Training Acc 80.83 % AVG Validation Acc 80.16 %\n",
      "Epoch    70: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.457 AVG Validation Loss:0.497 AVG Training Acc 80.93 % AVG Validation Acc 80.16 %\n",
      "Epoch:90/200 AVG Training Loss:0.456 AVG Validation Loss:0.498 AVG Training Acc 80.67 % AVG Validation Acc 80.07 %\n",
      "Epoch:100/200 AVG Training Loss:0.456 AVG Validation Loss:0.500 AVG Training Acc 80.84 % AVG Validation Acc 80.07 %\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.455 AVG Validation Loss:0.499 AVG Training Acc 80.84 % AVG Validation Acc 79.98 %\n",
      "Epoch:120/200 AVG Training Loss:0.454 AVG Validation Loss:0.499 AVG Training Acc 81.07 % AVG Validation Acc 79.98 %\n",
      "Epoch:130/200 AVG Training Loss:0.455 AVG Validation Loss:0.498 AVG Training Acc 81.01 % AVG Validation Acc 80.16 %\n",
      "Epoch   132: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.455 AVG Validation Loss:0.499 AVG Training Acc 81.10 % AVG Validation Acc 79.80 %\n",
      "Epoch:150/200 AVG Training Loss:0.454 AVG Validation Loss:0.499 AVG Training Acc 80.99 % AVG Validation Acc 79.89 %\n",
      "Epoch:160/200 AVG Training Loss:0.455 AVG Validation Loss:0.501 AVG Training Acc 80.95 % AVG Validation Acc 80.07 %\n",
      "Epoch   163: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.453 AVG Validation Loss:0.498 AVG Training Acc 81.35 % AVG Validation Acc 79.89 %\n",
      "Epoch:180/200 AVG Training Loss:0.455 AVG Validation Loss:0.499 AVG Training Acc 81.00 % AVG Validation Acc 80.07 %\n",
      "Epoch:190/200 AVG Training Loss:0.454 AVG Validation Loss:0.500 AVG Training Acc 80.97 % AVG Validation Acc 80.07 %\n",
      "Epoch   194: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.455 AVG Validation Loss:0.498 AVG Training Acc 80.94 % AVG Validation Acc 80.16 %\n",
      "Split 146\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f933569a79240d392c92d302b990e3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.497 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.478 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.467 AVG Validation Loss:0.505 AVG Training Acc 80.68 % AVG Validation Acc 79.78 %\n",
      "Epoch:60/200 AVG Training Loss:0.457 AVG Validation Loss:0.512 AVG Training Acc 80.90 % AVG Validation Acc 79.42 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.447 AVG Validation Loss:0.516 AVG Training Acc 81.18 % AVG Validation Acc 79.42 %\n",
      "Epoch:80/200 AVG Training Loss:0.446 AVG Validation Loss:0.519 AVG Training Acc 81.08 % AVG Validation Acc 79.24 %\n",
      "Epoch:90/200 AVG Training Loss:0.443 AVG Validation Loss:0.521 AVG Training Acc 81.39 % AVG Validation Acc 78.97 %\n",
      "Epoch:100/200 AVG Training Loss:0.441 AVG Validation Loss:0.523 AVG Training Acc 81.30 % AVG Validation Acc 78.88 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.441 AVG Validation Loss:0.524 AVG Training Acc 81.39 % AVG Validation Acc 78.97 %\n",
      "Epoch:120/200 AVG Training Loss:0.442 AVG Validation Loss:0.523 AVG Training Acc 81.50 % AVG Validation Acc 78.70 %\n",
      "Epoch:130/200 AVG Training Loss:0.441 AVG Validation Loss:0.523 AVG Training Acc 81.33 % AVG Validation Acc 78.70 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.441 AVG Validation Loss:0.523 AVG Training Acc 81.40 % AVG Validation Acc 78.70 %\n",
      "Epoch:150/200 AVG Training Loss:0.443 AVG Validation Loss:0.525 AVG Training Acc 81.28 % AVG Validation Acc 78.97 %\n",
      "Epoch:160/200 AVG Training Loss:0.443 AVG Validation Loss:0.526 AVG Training Acc 81.34 % AVG Validation Acc 78.79 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.444 AVG Validation Loss:0.527 AVG Training Acc 81.31 % AVG Validation Acc 78.79 %\n",
      "Epoch:180/200 AVG Training Loss:0.441 AVG Validation Loss:0.526 AVG Training Acc 81.28 % AVG Validation Acc 78.79 %\n",
      "Epoch:190/200 AVG Training Loss:0.441 AVG Validation Loss:0.526 AVG Training Acc 81.42 % AVG Validation Acc 78.79 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.441 AVG Validation Loss:0.526 AVG Training Acc 81.40 % AVG Validation Acc 78.88 %\n",
      "Split 147\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4536da33708439cbf25ec93d6bea7f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.18 % AVG Validation Acc 80.23 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.33 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.41 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.482 AVG Validation Loss:0.498 AVG Training Acc 80.59 % AVG Validation Acc 80.05 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.478 AVG Validation Loss:0.503 AVG Training Acc 80.71 % AVG Validation Acc 80.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.477 AVG Validation Loss:0.504 AVG Training Acc 80.75 % AVG Validation Acc 80.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.475 AVG Validation Loss:0.502 AVG Training Acc 80.87 % AVG Validation Acc 80.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.475 AVG Validation Loss:0.504 AVG Training Acc 80.75 % AVG Validation Acc 79.96 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.475 AVG Validation Loss:0.506 AVG Training Acc 80.85 % AVG Validation Acc 79.96 %\n",
      "Epoch:120/200 AVG Training Loss:0.474 AVG Validation Loss:0.505 AVG Training Acc 80.79 % AVG Validation Acc 79.96 %\n",
      "Epoch:130/200 AVG Training Loss:0.473 AVG Validation Loss:0.506 AVG Training Acc 80.89 % AVG Validation Acc 79.96 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.472 AVG Validation Loss:0.506 AVG Training Acc 80.92 % AVG Validation Acc 79.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.474 AVG Validation Loss:0.505 AVG Training Acc 80.79 % AVG Validation Acc 79.96 %\n",
      "Epoch:160/200 AVG Training Loss:0.474 AVG Validation Loss:0.505 AVG Training Acc 80.79 % AVG Validation Acc 79.96 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.473 AVG Validation Loss:0.507 AVG Training Acc 80.83 % AVG Validation Acc 79.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.475 AVG Validation Loss:0.506 AVG Training Acc 80.67 % AVG Validation Acc 79.96 %\n",
      "Epoch:190/200 AVG Training Loss:0.475 AVG Validation Loss:0.508 AVG Training Acc 80.84 % AVG Validation Acc 79.96 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.475 AVG Validation Loss:0.507 AVG Training Acc 80.72 % AVG Validation Acc 79.96 %\n",
      "Split 148\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f205e06cb543cb8b6b3ad1bebb8ed9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.492 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.487 AVG Training Acc 80.18 % AVG Validation Acc 80.23 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.486 AVG Training Acc 80.18 % AVG Validation Acc 80.32 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.485 AVG Training Acc 80.16 % AVG Validation Acc 80.32 %\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.484 AVG Training Acc 80.23 % AVG Validation Acc 80.42 %\n",
      "Epoch:70/200 AVG Training Loss:0.481 AVG Validation Loss:0.483 AVG Training Acc 80.31 % AVG Validation Acc 80.42 %\n",
      "Epoch:80/200 AVG Training Loss:0.479 AVG Validation Loss:0.485 AVG Training Acc 80.41 % AVG Validation Acc 80.51 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.475 AVG Validation Loss:0.488 AVG Training Acc 80.55 % AVG Validation Acc 80.42 %\n",
      "Epoch:100/200 AVG Training Loss:0.475 AVG Validation Loss:0.489 AVG Training Acc 80.51 % AVG Validation Acc 80.42 %\n",
      "Epoch:110/200 AVG Training Loss:0.475 AVG Validation Loss:0.493 AVG Training Acc 80.52 % AVG Validation Acc 80.42 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.474 AVG Validation Loss:0.494 AVG Training Acc 80.58 % AVG Validation Acc 80.32 %\n",
      "Epoch:130/200 AVG Training Loss:0.473 AVG Validation Loss:0.494 AVG Training Acc 80.57 % AVG Validation Acc 80.42 %\n",
      "Epoch:140/200 AVG Training Loss:0.473 AVG Validation Loss:0.494 AVG Training Acc 80.59 % AVG Validation Acc 80.51 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-06.\n",
      "New Best Accuracy found: 80.60%\n",
      "Epoch: 147\n",
      "Epoch:150/200 AVG Training Loss:0.472 AVG Validation Loss:0.493 AVG Training Acc 80.58 % AVG Validation Acc 80.51 %\n",
      "Epoch:160/200 AVG Training Loss:0.474 AVG Validation Loss:0.495 AVG Training Acc 80.55 % AVG Validation Acc 80.42 %\n",
      "Epoch:170/200 AVG Training Loss:0.473 AVG Validation Loss:0.494 AVG Training Acc 80.63 % AVG Validation Acc 80.42 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.472 AVG Validation Loss:0.494 AVG Training Acc 80.65 % AVG Validation Acc 80.51 %\n",
      "Epoch:190/200 AVG Training Loss:0.473 AVG Validation Loss:0.495 AVG Training Acc 80.53 % AVG Validation Acc 80.51 %\n",
      "Epoch:200/200 AVG Training Loss:0.472 AVG Validation Loss:0.495 AVG Training Acc 80.67 % AVG Validation Acc 80.42 %\n",
      "Split 149\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "690fe5a1c3c341a2bab4c93332f4f9c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.16 % AVG Validation Acc 80.05 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.487 AVG Validation Loss:0.495 AVG Training Acc 80.32 % AVG Validation Acc 79.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.485 AVG Validation Loss:0.501 AVG Training Acc 80.35 % AVG Validation Acc 79.96 %\n",
      "Epoch:50/200 AVG Training Loss:0.481 AVG Validation Loss:0.510 AVG Training Acc 80.56 % AVG Validation Acc 79.78 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.478 AVG Validation Loss:0.512 AVG Training Acc 80.71 % AVG Validation Acc 79.78 %\n",
      "Epoch:70/200 AVG Training Loss:0.478 AVG Validation Loss:0.516 AVG Training Acc 80.67 % AVG Validation Acc 79.78 %\n",
      "Epoch:80/200 AVG Training Loss:0.479 AVG Validation Loss:0.513 AVG Training Acc 80.71 % AVG Validation Acc 79.96 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.479 AVG Validation Loss:0.517 AVG Training Acc 80.62 % AVG Validation Acc 79.78 %\n",
      "Epoch:100/200 AVG Training Loss:0.476 AVG Validation Loss:0.517 AVG Training Acc 80.73 % AVG Validation Acc 79.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.476 AVG Validation Loss:0.512 AVG Training Acc 80.76 % AVG Validation Acc 79.87 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.478 AVG Validation Loss:0.516 AVG Training Acc 80.74 % AVG Validation Acc 79.69 %\n",
      "Epoch:130/200 AVG Training Loss:0.477 AVG Validation Loss:0.519 AVG Training Acc 80.73 % AVG Validation Acc 79.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.476 AVG Validation Loss:0.516 AVG Training Acc 80.69 % AVG Validation Acc 79.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.478 AVG Validation Loss:0.516 AVG Training Acc 80.71 % AVG Validation Acc 79.78 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.478 AVG Validation Loss:0.514 AVG Training Acc 80.73 % AVG Validation Acc 79.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.477 AVG Validation Loss:0.515 AVG Training Acc 80.68 % AVG Validation Acc 79.87 %\n",
      "Epoch:180/200 AVG Training Loss:0.477 AVG Validation Loss:0.522 AVG Training Acc 80.72 % AVG Validation Acc 79.78 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.477 AVG Validation Loss:0.518 AVG Training Acc 80.74 % AVG Validation Acc 79.78 %\n",
      "Epoch:200/200 AVG Training Loss:0.476 AVG Validation Loss:0.517 AVG Training Acc 80.78 % AVG Validation Acc 79.87 %\n",
      "Split 150\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a4cd700d0674795a71bc9b5ed925d30",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.497 AVG Validation Loss:0.499 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.492 AVG Training Acc 80.36 % AVG Validation Acc 79.96 %\n",
      "Epoch:60/200 AVG Training Loss:0.481 AVG Validation Loss:0.494 AVG Training Acc 80.48 % AVG Validation Acc 79.87 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.476 AVG Validation Loss:0.496 AVG Training Acc 80.67 % AVG Validation Acc 79.78 %\n",
      "Epoch:80/200 AVG Training Loss:0.476 AVG Validation Loss:0.497 AVG Training Acc 80.75 % AVG Validation Acc 79.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.474 AVG Validation Loss:0.499 AVG Training Acc 80.83 % AVG Validation Acc 79.69 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.474 AVG Validation Loss:0.499 AVG Training Acc 80.87 % AVG Validation Acc 79.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.473 AVG Validation Loss:0.498 AVG Training Acc 80.81 % AVG Validation Acc 79.87 %\n",
      "Epoch:120/200 AVG Training Loss:0.473 AVG Validation Loss:0.499 AVG Training Acc 80.91 % AVG Validation Acc 79.78 %\n",
      "Epoch:130/200 AVG Training Loss:0.475 AVG Validation Loss:0.499 AVG Training Acc 80.75 % AVG Validation Acc 79.87 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.474 AVG Validation Loss:0.499 AVG Training Acc 80.90 % AVG Validation Acc 79.87 %\n",
      "Epoch:150/200 AVG Training Loss:0.474 AVG Validation Loss:0.500 AVG Training Acc 80.84 % AVG Validation Acc 79.78 %\n",
      "Epoch:160/200 AVG Training Loss:0.474 AVG Validation Loss:0.499 AVG Training Acc 80.85 % AVG Validation Acc 79.78 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.474 AVG Validation Loss:0.499 AVG Training Acc 80.84 % AVG Validation Acc 79.87 %\n",
      "Epoch:180/200 AVG Training Loss:0.474 AVG Validation Loss:0.499 AVG Training Acc 80.83 % AVG Validation Acc 79.69 %\n",
      "Epoch:190/200 AVG Training Loss:0.473 AVG Validation Loss:0.499 AVG Training Acc 80.78 % AVG Validation Acc 79.87 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.472 AVG Validation Loss:0.499 AVG Training Acc 80.88 % AVG Validation Acc 79.87 %\n",
      "Split 151\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0ad6820fb31467fb7947a946dcb4fc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.498 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.21 % AVG Validation Acc 80.07 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.492 AVG Training Acc 80.33 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.481 AVG Validation Loss:0.493 AVG Training Acc 80.42 % AVG Validation Acc 80.07 %\n",
      "Epoch:60/200 AVG Training Loss:0.478 AVG Validation Loss:0.494 AVG Training Acc 80.59 % AVG Validation Acc 79.98 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.476 AVG Validation Loss:0.497 AVG Training Acc 80.68 % AVG Validation Acc 79.71 %\n",
      "Epoch:80/200 AVG Training Loss:0.474 AVG Validation Loss:0.500 AVG Training Acc 80.72 % AVG Validation Acc 79.62 %\n",
      "Epoch:90/200 AVG Training Loss:0.475 AVG Validation Loss:0.496 AVG Training Acc 80.69 % AVG Validation Acc 79.71 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.475 AVG Validation Loss:0.499 AVG Training Acc 80.65 % AVG Validation Acc 79.53 %\n",
      "Epoch:110/200 AVG Training Loss:0.474 AVG Validation Loss:0.500 AVG Training Acc 80.72 % AVG Validation Acc 79.53 %\n",
      "Epoch:120/200 AVG Training Loss:0.475 AVG Validation Loss:0.498 AVG Training Acc 80.70 % AVG Validation Acc 79.62 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.475 AVG Validation Loss:0.499 AVG Training Acc 80.66 % AVG Validation Acc 79.53 %\n",
      "Epoch:140/200 AVG Training Loss:0.474 AVG Validation Loss:0.500 AVG Training Acc 80.77 % AVG Validation Acc 79.62 %\n",
      "Epoch:150/200 AVG Training Loss:0.475 AVG Validation Loss:0.499 AVG Training Acc 80.70 % AVG Validation Acc 79.53 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.475 AVG Validation Loss:0.499 AVG Training Acc 80.69 % AVG Validation Acc 79.53 %\n",
      "Epoch:170/200 AVG Training Loss:0.475 AVG Validation Loss:0.499 AVG Training Acc 80.67 % AVG Validation Acc 79.71 %\n",
      "Epoch:180/200 AVG Training Loss:0.473 AVG Validation Loss:0.499 AVG Training Acc 80.60 % AVG Validation Acc 79.53 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.473 AVG Validation Loss:0.500 AVG Training Acc 80.71 % AVG Validation Acc 79.53 %\n",
      "Epoch:200/200 AVG Training Loss:0.474 AVG Validation Loss:0.497 AVG Training Acc 80.73 % AVG Validation Acc 79.62 %\n",
      "Split 152\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a8840f4198a4646b22eeaf9bcade180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.497 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.31 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.481 AVG Validation Loss:0.502 AVG Training Acc 80.42 % AVG Validation Acc 79.98 %\n",
      "Epoch:50/200 AVG Training Loss:0.475 AVG Validation Loss:0.504 AVG Training Acc 80.79 % AVG Validation Acc 79.89 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.472 AVG Validation Loss:0.506 AVG Training Acc 80.84 % AVG Validation Acc 79.80 %\n",
      "Epoch:70/200 AVG Training Loss:0.472 AVG Validation Loss:0.507 AVG Training Acc 80.94 % AVG Validation Acc 79.80 %\n",
      "Epoch:80/200 AVG Training Loss:0.470 AVG Validation Loss:0.507 AVG Training Acc 80.92 % AVG Validation Acc 79.62 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.471 AVG Validation Loss:0.509 AVG Training Acc 80.86 % AVG Validation Acc 79.62 %\n",
      "Epoch:100/200 AVG Training Loss:0.470 AVG Validation Loss:0.509 AVG Training Acc 80.93 % AVG Validation Acc 79.62 %\n",
      "Epoch:110/200 AVG Training Loss:0.470 AVG Validation Loss:0.509 AVG Training Acc 80.86 % AVG Validation Acc 79.71 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.470 AVG Validation Loss:0.510 AVG Training Acc 80.97 % AVG Validation Acc 79.80 %\n",
      "Epoch:130/200 AVG Training Loss:0.470 AVG Validation Loss:0.506 AVG Training Acc 80.96 % AVG Validation Acc 79.80 %\n",
      "Epoch:140/200 AVG Training Loss:0.471 AVG Validation Loss:0.508 AVG Training Acc 80.89 % AVG Validation Acc 79.62 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.470 AVG Validation Loss:0.508 AVG Training Acc 80.92 % AVG Validation Acc 79.62 %\n",
      "Epoch:160/200 AVG Training Loss:0.469 AVG Validation Loss:0.508 AVG Training Acc 80.97 % AVG Validation Acc 79.80 %\n",
      "Epoch:170/200 AVG Training Loss:0.470 AVG Validation Loss:0.510 AVG Training Acc 80.85 % AVG Validation Acc 79.71 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.469 AVG Validation Loss:0.508 AVG Training Acc 80.90 % AVG Validation Acc 79.71 %\n",
      "Epoch:190/200 AVG Training Loss:0.470 AVG Validation Loss:0.508 AVG Training Acc 80.90 % AVG Validation Acc 79.71 %\n",
      "Epoch:200/200 AVG Training Loss:0.470 AVG Validation Loss:0.508 AVG Training Acc 81.00 % AVG Validation Acc 79.62 %\n",
      "Split 153\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb5cbe3fcdd041bda4429dab14f86b32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.09 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.20 % AVG Validation Acc 80.25 %\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.494 AVG Training Acc 80.26 % AVG Validation Acc 80.16 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.473 AVG Validation Loss:0.496 AVG Training Acc 80.32 % AVG Validation Acc 80.25 %\n",
      "Epoch:60/200 AVG Training Loss:0.465 AVG Validation Loss:0.504 AVG Training Acc 80.55 % AVG Validation Acc 80.07 %\n",
      "Epoch:70/200 AVG Training Loss:0.460 AVG Validation Loss:0.515 AVG Training Acc 80.62 % AVG Validation Acc 79.98 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.453 AVG Validation Loss:0.517 AVG Training Acc 80.93 % AVG Validation Acc 80.34 %\n",
      "Epoch:90/200 AVG Training Loss:0.452 AVG Validation Loss:0.518 AVG Training Acc 80.91 % AVG Validation Acc 80.25 %\n",
      "Epoch:100/200 AVG Training Loss:0.451 AVG Validation Loss:0.523 AVG Training Acc 80.92 % AVG Validation Acc 80.16 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.450 AVG Validation Loss:0.522 AVG Training Acc 80.91 % AVG Validation Acc 80.43 %\n",
      "Epoch:120/200 AVG Training Loss:0.450 AVG Validation Loss:0.518 AVG Training Acc 80.94 % AVG Validation Acc 80.25 %\n",
      "Epoch:130/200 AVG Training Loss:0.448 AVG Validation Loss:0.526 AVG Training Acc 81.08 % AVG Validation Acc 80.07 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.450 AVG Validation Loss:0.517 AVG Training Acc 80.90 % AVG Validation Acc 80.34 %\n",
      "Epoch:150/200 AVG Training Loss:0.449 AVG Validation Loss:0.518 AVG Training Acc 80.91 % AVG Validation Acc 80.16 %\n",
      "Epoch:160/200 AVG Training Loss:0.451 AVG Validation Loss:0.519 AVG Training Acc 80.88 % AVG Validation Acc 80.34 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.450 AVG Validation Loss:0.523 AVG Training Acc 80.95 % AVG Validation Acc 80.34 %\n",
      "Epoch:180/200 AVG Training Loss:0.449 AVG Validation Loss:0.523 AVG Training Acc 80.78 % AVG Validation Acc 80.25 %\n",
      "Epoch:190/200 AVG Training Loss:0.450 AVG Validation Loss:0.525 AVG Training Acc 80.81 % AVG Validation Acc 80.16 %\n",
      "Epoch:200/200 AVG Training Loss:0.451 AVG Validation Loss:0.526 AVG Training Acc 80.96 % AVG Validation Acc 79.98 %\n",
      "Epoch   200: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Split 154\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d0a18d8d9d417f99b02feabbe5c76f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.31 % AVG Validation Acc 80.16 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.472 AVG Validation Loss:0.507 AVG Training Acc 80.65 % AVG Validation Acc 79.44 %\n",
      "Epoch:50/200 AVG Training Loss:0.461 AVG Validation Loss:0.532 AVG Training Acc 81.18 % AVG Validation Acc 78.90 %\n",
      "Epoch:60/200 AVG Training Loss:0.453 AVG Validation Loss:0.539 AVG Training Acc 81.48 % AVG Validation Acc 78.72 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.448 AVG Validation Loss:0.535 AVG Training Acc 81.72 % AVG Validation Acc 78.90 %\n",
      "Epoch:80/200 AVG Training Loss:0.444 AVG Validation Loss:0.545 AVG Training Acc 81.83 % AVG Validation Acc 78.90 %\n",
      "Epoch:90/200 AVG Training Loss:0.444 AVG Validation Loss:0.540 AVG Training Acc 81.67 % AVG Validation Acc 78.63 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.443 AVG Validation Loss:0.534 AVG Training Acc 81.84 % AVG Validation Acc 78.99 %\n",
      "Epoch:110/200 AVG Training Loss:0.441 AVG Validation Loss:0.538 AVG Training Acc 81.97 % AVG Validation Acc 78.90 %\n",
      "Epoch:120/200 AVG Training Loss:0.442 AVG Validation Loss:0.548 AVG Training Acc 82.03 % AVG Validation Acc 78.63 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.441 AVG Validation Loss:0.541 AVG Training Acc 81.87 % AVG Validation Acc 78.72 %\n",
      "Epoch:140/200 AVG Training Loss:0.440 AVG Validation Loss:0.540 AVG Training Acc 82.01 % AVG Validation Acc 78.63 %\n",
      "Epoch:150/200 AVG Training Loss:0.441 AVG Validation Loss:0.544 AVG Training Acc 82.00 % AVG Validation Acc 78.63 %\n",
      "Epoch:160/200 AVG Training Loss:0.441 AVG Validation Loss:0.541 AVG Training Acc 81.81 % AVG Validation Acc 78.36 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.441 AVG Validation Loss:0.540 AVG Training Acc 81.96 % AVG Validation Acc 78.63 %\n",
      "Epoch:180/200 AVG Training Loss:0.441 AVG Validation Loss:0.542 AVG Training Acc 81.95 % AVG Validation Acc 78.54 %\n",
      "Epoch:190/200 AVG Training Loss:0.441 AVG Validation Loss:0.551 AVG Training Acc 81.85 % AVG Validation Acc 78.45 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.441 AVG Validation Loss:0.544 AVG Training Acc 81.95 % AVG Validation Acc 78.45 %\n",
      "Split 155\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9314acf798b4471d973f4266980c1d7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.16 % AVG Validation Acc 79.98 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.34 % AVG Validation Acc 79.53 %\n",
      "Epoch:40/200 AVG Training Loss:0.480 AVG Validation Loss:0.505 AVG Training Acc 80.57 % AVG Validation Acc 79.26 %\n",
      "Epoch:50/200 AVG Training Loss:0.478 AVG Validation Loss:0.507 AVG Training Acc 80.60 % AVG Validation Acc 79.35 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.474 AVG Validation Loss:0.514 AVG Training Acc 80.77 % AVG Validation Acc 79.26 %\n",
      "Epoch:70/200 AVG Training Loss:0.474 AVG Validation Loss:0.516 AVG Training Acc 80.87 % AVG Validation Acc 79.17 %\n",
      "Epoch:80/200 AVG Training Loss:0.473 AVG Validation Loss:0.520 AVG Training Acc 80.92 % AVG Validation Acc 79.17 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.473 AVG Validation Loss:0.518 AVG Training Acc 80.89 % AVG Validation Acc 79.17 %\n",
      "Epoch:100/200 AVG Training Loss:0.471 AVG Validation Loss:0.515 AVG Training Acc 81.07 % AVG Validation Acc 79.17 %\n",
      "Epoch:110/200 AVG Training Loss:0.471 AVG Validation Loss:0.521 AVG Training Acc 81.02 % AVG Validation Acc 79.17 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.471 AVG Validation Loss:0.519 AVG Training Acc 81.08 % AVG Validation Acc 79.08 %\n",
      "Epoch:130/200 AVG Training Loss:0.471 AVG Validation Loss:0.521 AVG Training Acc 80.93 % AVG Validation Acc 79.17 %\n",
      "Epoch:140/200 AVG Training Loss:0.471 AVG Validation Loss:0.520 AVG Training Acc 80.94 % AVG Validation Acc 79.08 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.472 AVG Validation Loss:0.519 AVG Training Acc 80.89 % AVG Validation Acc 79.17 %\n",
      "Epoch:160/200 AVG Training Loss:0.472 AVG Validation Loss:0.519 AVG Training Acc 80.98 % AVG Validation Acc 79.17 %\n",
      "Epoch:170/200 AVG Training Loss:0.471 AVG Validation Loss:0.521 AVG Training Acc 80.91 % AVG Validation Acc 79.17 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.472 AVG Validation Loss:0.519 AVG Training Acc 80.97 % AVG Validation Acc 79.17 %\n",
      "Epoch:190/200 AVG Training Loss:0.471 AVG Validation Loss:0.521 AVG Training Acc 80.82 % AVG Validation Acc 79.17 %\n",
      "Epoch:200/200 AVG Training Loss:0.472 AVG Validation Loss:0.521 AVG Training Acc 80.91 % AVG Validation Acc 78.99 %\n",
      "Split 156\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c97937787994975b794ccfe96111905",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.496 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.32 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.483 AVG Validation Loss:0.492 AVG Training Acc 80.49 % AVG Validation Acc 80.32 %\n",
      "Epoch:50/200 AVG Training Loss:0.481 AVG Validation Loss:0.497 AVG Training Acc 80.58 % AVG Validation Acc 79.96 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.478 AVG Validation Loss:0.499 AVG Training Acc 80.71 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.477 AVG Validation Loss:0.501 AVG Training Acc 80.74 % AVG Validation Acc 79.87 %\n",
      "Epoch:80/200 AVG Training Loss:0.477 AVG Validation Loss:0.502 AVG Training Acc 80.81 % AVG Validation Acc 79.69 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.476 AVG Validation Loss:0.504 AVG Training Acc 80.78 % AVG Validation Acc 79.87 %\n",
      "Epoch:100/200 AVG Training Loss:0.477 AVG Validation Loss:0.504 AVG Training Acc 80.84 % AVG Validation Acc 79.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.476 AVG Validation Loss:0.504 AVG Training Acc 80.77 % AVG Validation Acc 79.78 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.476 AVG Validation Loss:0.505 AVG Training Acc 80.84 % AVG Validation Acc 79.87 %\n",
      "Epoch:130/200 AVG Training Loss:0.476 AVG Validation Loss:0.506 AVG Training Acc 80.73 % AVG Validation Acc 79.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.476 AVG Validation Loss:0.507 AVG Training Acc 80.75 % AVG Validation Acc 79.69 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.475 AVG Validation Loss:0.505 AVG Training Acc 80.79 % AVG Validation Acc 79.78 %\n",
      "Epoch:160/200 AVG Training Loss:0.476 AVG Validation Loss:0.505 AVG Training Acc 80.79 % AVG Validation Acc 79.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.475 AVG Validation Loss:0.504 AVG Training Acc 80.90 % AVG Validation Acc 79.96 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.475 AVG Validation Loss:0.506 AVG Training Acc 80.80 % AVG Validation Acc 79.87 %\n",
      "Epoch:190/200 AVG Training Loss:0.476 AVG Validation Loss:0.504 AVG Training Acc 80.83 % AVG Validation Acc 79.78 %\n",
      "Epoch:200/200 AVG Training Loss:0.476 AVG Validation Loss:0.505 AVG Training Acc 80.76 % AVG Validation Acc 79.87 %\n",
      "Split 157\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71fe8b2bca0a42298891c5c58c200267",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.482 AVG Validation Loss:0.504 AVG Training Acc 80.29 % AVG Validation Acc 79.87 %\n",
      "Epoch:40/200 AVG Training Loss:0.475 AVG Validation Loss:0.511 AVG Training Acc 80.38 % AVG Validation Acc 79.60 %\n",
      "Epoch:50/200 AVG Training Loss:0.469 AVG Validation Loss:0.518 AVG Training Acc 80.57 % AVG Validation Acc 79.69 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.462 AVG Validation Loss:0.519 AVG Training Acc 80.75 % AVG Validation Acc 79.96 %\n",
      "Epoch:70/200 AVG Training Loss:0.461 AVG Validation Loss:0.524 AVG Training Acc 80.70 % AVG Validation Acc 79.87 %\n",
      "Epoch:80/200 AVG Training Loss:0.460 AVG Validation Loss:0.526 AVG Training Acc 80.93 % AVG Validation Acc 79.60 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.460 AVG Validation Loss:0.528 AVG Training Acc 80.83 % AVG Validation Acc 79.78 %\n",
      "Epoch:100/200 AVG Training Loss:0.460 AVG Validation Loss:0.529 AVG Training Acc 80.83 % AVG Validation Acc 79.51 %\n",
      "Epoch:110/200 AVG Training Loss:0.459 AVG Validation Loss:0.527 AVG Training Acc 80.75 % AVG Validation Acc 79.42 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.458 AVG Validation Loss:0.525 AVG Training Acc 80.95 % AVG Validation Acc 79.51 %\n",
      "Epoch:130/200 AVG Training Loss:0.459 AVG Validation Loss:0.529 AVG Training Acc 80.86 % AVG Validation Acc 79.60 %\n",
      "Epoch:140/200 AVG Training Loss:0.459 AVG Validation Loss:0.526 AVG Training Acc 80.75 % AVG Validation Acc 79.51 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.460 AVG Validation Loss:0.528 AVG Training Acc 80.82 % AVG Validation Acc 79.69 %\n",
      "Epoch:160/200 AVG Training Loss:0.460 AVG Validation Loss:0.527 AVG Training Acc 80.78 % AVG Validation Acc 79.51 %\n",
      "Epoch:170/200 AVG Training Loss:0.459 AVG Validation Loss:0.528 AVG Training Acc 80.86 % AVG Validation Acc 79.60 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.459 AVG Validation Loss:0.528 AVG Training Acc 80.89 % AVG Validation Acc 79.69 %\n",
      "Epoch:190/200 AVG Training Loss:0.459 AVG Validation Loss:0.525 AVG Training Acc 80.83 % AVG Validation Acc 79.78 %\n",
      "Epoch:200/200 AVG Training Loss:0.458 AVG Validation Loss:0.526 AVG Training Acc 80.99 % AVG Validation Acc 79.78 %\n",
      "Split 158\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcaae0a0038649a5a2d418e41858e759",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 80.05 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.483 AVG Validation Loss:0.495 AVG Training Acc 80.31 % AVG Validation Acc 79.69 %\n",
      "Epoch:50/200 AVG Training Loss:0.480 AVG Validation Loss:0.497 AVG Training Acc 80.39 % AVG Validation Acc 79.78 %\n",
      "Epoch:60/200 AVG Training Loss:0.473 AVG Validation Loss:0.502 AVG Training Acc 80.55 % AVG Validation Acc 79.60 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.469 AVG Validation Loss:0.505 AVG Training Acc 80.69 % AVG Validation Acc 79.42 %\n",
      "Epoch:80/200 AVG Training Loss:0.467 AVG Validation Loss:0.506 AVG Training Acc 80.69 % AVG Validation Acc 79.33 %\n",
      "Epoch:90/200 AVG Training Loss:0.467 AVG Validation Loss:0.508 AVG Training Acc 80.69 % AVG Validation Acc 79.33 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.466 AVG Validation Loss:0.506 AVG Training Acc 80.74 % AVG Validation Acc 79.33 %\n",
      "Epoch:110/200 AVG Training Loss:0.466 AVG Validation Loss:0.506 AVG Training Acc 80.70 % AVG Validation Acc 79.33 %\n",
      "Epoch:120/200 AVG Training Loss:0.466 AVG Validation Loss:0.506 AVG Training Acc 80.76 % AVG Validation Acc 79.42 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.466 AVG Validation Loss:0.508 AVG Training Acc 80.81 % AVG Validation Acc 79.33 %\n",
      "Epoch:140/200 AVG Training Loss:0.466 AVG Validation Loss:0.507 AVG Training Acc 80.73 % AVG Validation Acc 79.33 %\n",
      "Epoch:150/200 AVG Training Loss:0.465 AVG Validation Loss:0.508 AVG Training Acc 80.73 % AVG Validation Acc 79.24 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.465 AVG Validation Loss:0.506 AVG Training Acc 80.79 % AVG Validation Acc 79.33 %\n",
      "Epoch:170/200 AVG Training Loss:0.465 AVG Validation Loss:0.508 AVG Training Acc 80.85 % AVG Validation Acc 79.24 %\n",
      "Epoch:180/200 AVG Training Loss:0.465 AVG Validation Loss:0.508 AVG Training Acc 80.81 % AVG Validation Acc 79.24 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.466 AVG Validation Loss:0.508 AVG Training Acc 80.82 % AVG Validation Acc 79.24 %\n",
      "Epoch:200/200 AVG Training Loss:0.466 AVG Validation Loss:0.508 AVG Training Acc 80.75 % AVG Validation Acc 79.24 %\n",
      "Split 159\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4fda54898c74d729ff8b109bf41c6bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.497 AVG Training Acc 80.10 % AVG Validation Acc 80.14 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.23 % AVG Validation Acc 79.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.478 AVG Validation Loss:0.497 AVG Training Acc 80.45 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.472 AVG Validation Loss:0.498 AVG Training Acc 80.59 % AVG Validation Acc 80.14 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.463 AVG Validation Loss:0.501 AVG Training Acc 80.77 % AVG Validation Acc 79.96 %\n",
      "Epoch:70/200 AVG Training Loss:0.462 AVG Validation Loss:0.502 AVG Training Acc 81.04 % AVG Validation Acc 80.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.461 AVG Validation Loss:0.504 AVG Training Acc 81.04 % AVG Validation Acc 80.05 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.461 AVG Validation Loss:0.506 AVG Training Acc 81.04 % AVG Validation Acc 80.05 %\n",
      "Epoch:100/200 AVG Training Loss:0.460 AVG Validation Loss:0.506 AVG Training Acc 81.10 % AVG Validation Acc 80.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.460 AVG Validation Loss:0.506 AVG Training Acc 80.99 % AVG Validation Acc 80.05 %\n",
      "Epoch:120/200 AVG Training Loss:0.460 AVG Validation Loss:0.507 AVG Training Acc 81.20 % AVG Validation Acc 80.05 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.461 AVG Validation Loss:0.507 AVG Training Acc 81.02 % AVG Validation Acc 80.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.459 AVG Validation Loss:0.506 AVG Training Acc 81.08 % AVG Validation Acc 80.05 %\n",
      "Epoch:150/200 AVG Training Loss:0.458 AVG Validation Loss:0.507 AVG Training Acc 81.16 % AVG Validation Acc 80.05 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.458 AVG Validation Loss:0.505 AVG Training Acc 81.18 % AVG Validation Acc 80.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.459 AVG Validation Loss:0.509 AVG Training Acc 81.18 % AVG Validation Acc 80.05 %\n",
      "Epoch:180/200 AVG Training Loss:0.460 AVG Validation Loss:0.507 AVG Training Acc 81.02 % AVG Validation Acc 80.05 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.458 AVG Validation Loss:0.505 AVG Training Acc 81.12 % AVG Validation Acc 80.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.459 AVG Validation Loss:0.507 AVG Training Acc 81.16 % AVG Validation Acc 80.05 %\n",
      "Split 160\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27b600fb2b7f428495315e46a78d6d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.492 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.492 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.29 % AVG Validation Acc 79.96 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.478 AVG Validation Loss:0.489 AVG Training Acc 80.62 % AVG Validation Acc 80.23 %\n",
      "Epoch:50/200 AVG Training Loss:0.473 AVG Validation Loss:0.491 AVG Training Acc 80.76 % AVG Validation Acc 80.60 %\n",
      "New Best Accuracy found: 80.78%\n",
      "Epoch: 51\n",
      "Epoch:60/200 AVG Training Loss:0.469 AVG Validation Loss:0.494 AVG Training Acc 80.90 % AVG Validation Acc 80.42 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.464 AVG Validation Loss:0.495 AVG Training Acc 81.08 % AVG Validation Acc 80.60 %\n",
      "Epoch:80/200 AVG Training Loss:0.462 AVG Validation Loss:0.497 AVG Training Acc 81.18 % AVG Validation Acc 80.51 %\n",
      "Epoch:90/200 AVG Training Loss:0.461 AVG Validation Loss:0.497 AVG Training Acc 81.20 % AVG Validation Acc 80.23 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.459 AVG Validation Loss:0.497 AVG Training Acc 81.23 % AVG Validation Acc 80.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.461 AVG Validation Loss:0.498 AVG Training Acc 81.10 % AVG Validation Acc 80.51 %\n",
      "Epoch:120/200 AVG Training Loss:0.461 AVG Validation Loss:0.496 AVG Training Acc 81.13 % AVG Validation Acc 80.32 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.461 AVG Validation Loss:0.494 AVG Training Acc 81.29 % AVG Validation Acc 80.60 %\n",
      "Epoch:140/200 AVG Training Loss:0.461 AVG Validation Loss:0.494 AVG Training Acc 81.20 % AVG Validation Acc 80.32 %\n",
      "Epoch:150/200 AVG Training Loss:0.462 AVG Validation Loss:0.497 AVG Training Acc 81.16 % AVG Validation Acc 80.42 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.462 AVG Validation Loss:0.498 AVG Training Acc 81.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.462 AVG Validation Loss:0.499 AVG Training Acc 81.19 % AVG Validation Acc 80.05 %\n",
      "Epoch:180/200 AVG Training Loss:0.460 AVG Validation Loss:0.497 AVG Training Acc 81.19 % AVG Validation Acc 80.51 %\n",
      "Epoch:190/200 AVG Training Loss:0.461 AVG Validation Loss:0.500 AVG Training Acc 81.13 % AVG Validation Acc 80.42 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.461 AVG Validation Loss:0.497 AVG Training Acc 81.20 % AVG Validation Acc 80.42 %\n",
      "Split 161\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee4e0f742fe142f3beeba53772ae8ef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.18 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.16 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.492 AVG Validation Loss:0.490 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.32 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.476 AVG Validation Loss:0.492 AVG Training Acc 80.42 % AVG Validation Acc 80.07 %\n",
      "Epoch:70/200 AVG Training Loss:0.470 AVG Validation Loss:0.491 AVG Training Acc 80.63 % AVG Validation Acc 80.25 %\n",
      "Epoch:80/200 AVG Training Loss:0.467 AVG Validation Loss:0.496 AVG Training Acc 80.67 % AVG Validation Acc 80.43 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.465 AVG Validation Loss:0.504 AVG Training Acc 80.73 % AVG Validation Acc 79.89 %\n",
      "Epoch:100/200 AVG Training Loss:0.464 AVG Validation Loss:0.503 AVG Training Acc 80.69 % AVG Validation Acc 80.07 %\n",
      "Epoch:110/200 AVG Training Loss:0.464 AVG Validation Loss:0.508 AVG Training Acc 80.74 % AVG Validation Acc 79.98 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.462 AVG Validation Loss:0.507 AVG Training Acc 80.77 % AVG Validation Acc 80.16 %\n",
      "Epoch:130/200 AVG Training Loss:0.464 AVG Validation Loss:0.498 AVG Training Acc 80.70 % AVG Validation Acc 80.07 %\n",
      "Epoch:140/200 AVG Training Loss:0.462 AVG Validation Loss:0.497 AVG Training Acc 80.72 % AVG Validation Acc 79.98 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.462 AVG Validation Loss:0.499 AVG Training Acc 80.76 % AVG Validation Acc 79.80 %\n",
      "Epoch:160/200 AVG Training Loss:0.462 AVG Validation Loss:0.503 AVG Training Acc 80.71 % AVG Validation Acc 79.98 %\n",
      "Epoch:170/200 AVG Training Loss:0.463 AVG Validation Loss:0.508 AVG Training Acc 80.82 % AVG Validation Acc 80.07 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.461 AVG Validation Loss:0.511 AVG Training Acc 80.79 % AVG Validation Acc 80.07 %\n",
      "Epoch:190/200 AVG Training Loss:0.462 AVG Validation Loss:0.504 AVG Training Acc 80.93 % AVG Validation Acc 79.98 %\n",
      "Epoch:200/200 AVG Training Loss:0.461 AVG Validation Loss:0.503 AVG Training Acc 80.84 % AVG Validation Acc 80.25 %\n",
      "Split 162\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87a174facf8e4fa5a1d599d5e85f8815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.26 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.483 AVG Validation Loss:0.495 AVG Training Acc 80.47 % AVG Validation Acc 79.98 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.474 AVG Validation Loss:0.502 AVG Training Acc 80.69 % AVG Validation Acc 79.89 %\n",
      "Epoch:60/200 AVG Training Loss:0.469 AVG Validation Loss:0.510 AVG Training Acc 80.86 % AVG Validation Acc 79.44 %\n",
      "Epoch:70/200 AVG Training Loss:0.464 AVG Validation Loss:0.520 AVG Training Acc 81.10 % AVG Validation Acc 79.35 %\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.461 AVG Validation Loss:0.514 AVG Training Acc 81.13 % AVG Validation Acc 79.26 %\n",
      "Epoch:90/200 AVG Training Loss:0.460 AVG Validation Loss:0.514 AVG Training Acc 81.17 % AVG Validation Acc 79.53 %\n",
      "Epoch:100/200 AVG Training Loss:0.460 AVG Validation Loss:0.515 AVG Training Acc 81.20 % AVG Validation Acc 79.71 %\n",
      "Epoch   104: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.459 AVG Validation Loss:0.521 AVG Training Acc 81.15 % AVG Validation Acc 79.53 %\n",
      "Epoch:120/200 AVG Training Loss:0.461 AVG Validation Loss:0.521 AVG Training Acc 81.26 % AVG Validation Acc 79.62 %\n",
      "Epoch:130/200 AVG Training Loss:0.458 AVG Validation Loss:0.517 AVG Training Acc 81.28 % AVG Validation Acc 79.62 %\n",
      "Epoch   135: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.458 AVG Validation Loss:0.523 AVG Training Acc 81.30 % AVG Validation Acc 79.71 %\n",
      "Epoch:150/200 AVG Training Loss:0.458 AVG Validation Loss:0.518 AVG Training Acc 81.18 % AVG Validation Acc 79.35 %\n",
      "Epoch:160/200 AVG Training Loss:0.459 AVG Validation Loss:0.514 AVG Training Acc 81.16 % AVG Validation Acc 79.62 %\n",
      "Epoch   166: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.459 AVG Validation Loss:0.516 AVG Training Acc 81.17 % AVG Validation Acc 79.62 %\n",
      "Epoch:180/200 AVG Training Loss:0.459 AVG Validation Loss:0.513 AVG Training Acc 81.20 % AVG Validation Acc 79.62 %\n",
      "Epoch:190/200 AVG Training Loss:0.459 AVG Validation Loss:0.522 AVG Training Acc 81.27 % AVG Validation Acc 79.53 %\n",
      "Epoch   197: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.460 AVG Validation Loss:0.516 AVG Training Acc 81.15 % AVG Validation Acc 79.53 %\n",
      "Split 163\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c3aaf09867b44bc833feed02691dead",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.483 AVG Validation Loss:0.499 AVG Training Acc 80.36 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.477 AVG Validation Loss:0.500 AVG Training Acc 80.46 % AVG Validation Acc 79.80 %\n",
      "Epoch:60/200 AVG Training Loss:0.473 AVG Validation Loss:0.516 AVG Training Acc 80.70 % AVG Validation Acc 79.80 %\n",
      "Epoch:70/200 AVG Training Loss:0.468 AVG Validation Loss:0.527 AVG Training Acc 80.80 % AVG Validation Acc 79.53 %\n",
      "Epoch    70: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.467 AVG Validation Loss:0.530 AVG Training Acc 80.81 % AVG Validation Acc 79.53 %\n",
      "Epoch:90/200 AVG Training Loss:0.465 AVG Validation Loss:0.532 AVG Training Acc 80.90 % AVG Validation Acc 79.53 %\n",
      "Epoch:100/200 AVG Training Loss:0.463 AVG Validation Loss:0.531 AVG Training Acc 81.03 % AVG Validation Acc 79.62 %\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.463 AVG Validation Loss:0.535 AVG Training Acc 80.89 % AVG Validation Acc 79.53 %\n",
      "Epoch:120/200 AVG Training Loss:0.464 AVG Validation Loss:0.534 AVG Training Acc 80.92 % AVG Validation Acc 79.53 %\n",
      "Epoch:130/200 AVG Training Loss:0.465 AVG Validation Loss:0.534 AVG Training Acc 80.89 % AVG Validation Acc 79.53 %\n",
      "Epoch   132: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.464 AVG Validation Loss:0.530 AVG Training Acc 81.02 % AVG Validation Acc 79.53 %\n",
      "Epoch:150/200 AVG Training Loss:0.465 AVG Validation Loss:0.533 AVG Training Acc 81.02 % AVG Validation Acc 79.53 %\n",
      "Epoch:160/200 AVG Training Loss:0.465 AVG Validation Loss:0.531 AVG Training Acc 80.81 % AVG Validation Acc 79.53 %\n",
      "Epoch   163: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.463 AVG Validation Loss:0.531 AVG Training Acc 80.87 % AVG Validation Acc 79.62 %\n",
      "Epoch:180/200 AVG Training Loss:0.466 AVG Validation Loss:0.533 AVG Training Acc 80.88 % AVG Validation Acc 79.53 %\n",
      "Epoch:190/200 AVG Training Loss:0.464 AVG Validation Loss:0.535 AVG Training Acc 80.92 % AVG Validation Acc 79.53 %\n",
      "Epoch   194: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.465 AVG Validation Loss:0.535 AVG Training Acc 80.88 % AVG Validation Acc 79.53 %\n",
      "Split 164\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e388c661844e61a64c2cb8053bca38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.499 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.500 AVG Training Acc 80.13 % AVG Validation Acc 80.07 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.480 AVG Validation Loss:0.500 AVG Training Acc 80.42 % AVG Validation Acc 79.98 %\n",
      "Epoch:50/200 AVG Training Loss:0.478 AVG Validation Loss:0.503 AVG Training Acc 80.42 % AVG Validation Acc 79.80 %\n",
      "Epoch:60/200 AVG Training Loss:0.472 AVG Validation Loss:0.510 AVG Training Acc 80.68 % AVG Validation Acc 79.62 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.470 AVG Validation Loss:0.506 AVG Training Acc 80.80 % AVG Validation Acc 79.53 %\n",
      "Epoch:80/200 AVG Training Loss:0.470 AVG Validation Loss:0.510 AVG Training Acc 80.87 % AVG Validation Acc 79.53 %\n",
      "Epoch:90/200 AVG Training Loss:0.468 AVG Validation Loss:0.510 AVG Training Acc 80.90 % AVG Validation Acc 79.53 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.467 AVG Validation Loss:0.511 AVG Training Acc 80.74 % AVG Validation Acc 79.44 %\n",
      "Epoch:110/200 AVG Training Loss:0.468 AVG Validation Loss:0.509 AVG Training Acc 80.84 % AVG Validation Acc 79.44 %\n",
      "Epoch:120/200 AVG Training Loss:0.468 AVG Validation Loss:0.513 AVG Training Acc 80.94 % AVG Validation Acc 79.53 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.468 AVG Validation Loss:0.510 AVG Training Acc 81.02 % AVG Validation Acc 79.53 %\n",
      "Epoch:140/200 AVG Training Loss:0.468 AVG Validation Loss:0.511 AVG Training Acc 80.92 % AVG Validation Acc 79.53 %\n",
      "Epoch:150/200 AVG Training Loss:0.468 AVG Validation Loss:0.512 AVG Training Acc 80.98 % AVG Validation Acc 79.53 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.467 AVG Validation Loss:0.511 AVG Training Acc 80.99 % AVG Validation Acc 79.53 %\n",
      "Epoch:170/200 AVG Training Loss:0.467 AVG Validation Loss:0.509 AVG Training Acc 80.96 % AVG Validation Acc 79.44 %\n",
      "Epoch:180/200 AVG Training Loss:0.467 AVG Validation Loss:0.508 AVG Training Acc 80.83 % AVG Validation Acc 79.62 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.468 AVG Validation Loss:0.510 AVG Training Acc 80.99 % AVG Validation Acc 79.53 %\n",
      "Epoch:200/200 AVG Training Loss:0.468 AVG Validation Loss:0.511 AVG Training Acc 80.88 % AVG Validation Acc 79.44 %\n",
      "Split 165\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d960748a00f24facb2438c8f35cb647d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.13 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.499 AVG Training Acc 80.14 % AVG Validation Acc 79.98 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.482 AVG Validation Loss:0.506 AVG Training Acc 80.31 % AVG Validation Acc 79.80 %\n",
      "Epoch:50/200 AVG Training Loss:0.477 AVG Validation Loss:0.518 AVG Training Acc 80.41 % AVG Validation Acc 79.80 %\n",
      "Epoch:60/200 AVG Training Loss:0.473 AVG Validation Loss:0.522 AVG Training Acc 80.63 % AVG Validation Acc 79.53 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.470 AVG Validation Loss:0.527 AVG Training Acc 80.70 % AVG Validation Acc 79.62 %\n",
      "Epoch:80/200 AVG Training Loss:0.469 AVG Validation Loss:0.527 AVG Training Acc 80.70 % AVG Validation Acc 79.53 %\n",
      "Epoch:90/200 AVG Training Loss:0.469 AVG Validation Loss:0.530 AVG Training Acc 80.66 % AVG Validation Acc 79.62 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.469 AVG Validation Loss:0.528 AVG Training Acc 80.65 % AVG Validation Acc 79.53 %\n",
      "Epoch:110/200 AVG Training Loss:0.467 AVG Validation Loss:0.528 AVG Training Acc 80.54 % AVG Validation Acc 79.44 %\n",
      "Epoch:120/200 AVG Training Loss:0.469 AVG Validation Loss:0.528 AVG Training Acc 80.67 % AVG Validation Acc 79.62 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.469 AVG Validation Loss:0.530 AVG Training Acc 80.57 % AVG Validation Acc 79.53 %\n",
      "Epoch:140/200 AVG Training Loss:0.470 AVG Validation Loss:0.530 AVG Training Acc 80.60 % AVG Validation Acc 79.62 %\n",
      "Epoch:150/200 AVG Training Loss:0.467 AVG Validation Loss:0.530 AVG Training Acc 80.79 % AVG Validation Acc 79.44 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.468 AVG Validation Loss:0.528 AVG Training Acc 80.67 % AVG Validation Acc 79.53 %\n",
      "Epoch:170/200 AVG Training Loss:0.470 AVG Validation Loss:0.530 AVG Training Acc 80.54 % AVG Validation Acc 79.53 %\n",
      "Epoch:180/200 AVG Training Loss:0.469 AVG Validation Loss:0.530 AVG Training Acc 80.67 % AVG Validation Acc 79.53 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.467 AVG Validation Loss:0.530 AVG Training Acc 80.72 % AVG Validation Acc 79.53 %\n",
      "Epoch:200/200 AVG Training Loss:0.468 AVG Validation Loss:0.526 AVG Training Acc 80.65 % AVG Validation Acc 79.53 %\n",
      "Split 166\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f485dd55133a4b11a4d68fa0f2467fa7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.500 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.499 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.485 AVG Validation Loss:0.501 AVG Training Acc 80.25 % AVG Validation Acc 79.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.481 AVG Validation Loss:0.503 AVG Training Acc 80.38 % AVG Validation Acc 79.78 %\n",
      "Epoch:50/200 AVG Training Loss:0.477 AVG Validation Loss:0.506 AVG Training Acc 80.42 % AVG Validation Acc 79.24 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.474 AVG Validation Loss:0.511 AVG Training Acc 80.66 % AVG Validation Acc 79.06 %\n",
      "Epoch:70/200 AVG Training Loss:0.473 AVG Validation Loss:0.513 AVG Training Acc 80.69 % AVG Validation Acc 79.06 %\n",
      "Epoch:80/200 AVG Training Loss:0.472 AVG Validation Loss:0.514 AVG Training Acc 80.74 % AVG Validation Acc 79.06 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.472 AVG Validation Loss:0.513 AVG Training Acc 80.78 % AVG Validation Acc 79.06 %\n",
      "Epoch:100/200 AVG Training Loss:0.472 AVG Validation Loss:0.514 AVG Training Acc 80.66 % AVG Validation Acc 79.06 %\n",
      "Epoch:110/200 AVG Training Loss:0.470 AVG Validation Loss:0.514 AVG Training Acc 80.76 % AVG Validation Acc 79.06 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.471 AVG Validation Loss:0.515 AVG Training Acc 80.84 % AVG Validation Acc 79.06 %\n",
      "Epoch:130/200 AVG Training Loss:0.472 AVG Validation Loss:0.515 AVG Training Acc 80.74 % AVG Validation Acc 78.88 %\n",
      "Epoch:140/200 AVG Training Loss:0.471 AVG Validation Loss:0.514 AVG Training Acc 80.81 % AVG Validation Acc 78.97 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.471 AVG Validation Loss:0.515 AVG Training Acc 80.76 % AVG Validation Acc 79.06 %\n",
      "Epoch:160/200 AVG Training Loss:0.472 AVG Validation Loss:0.514 AVG Training Acc 80.80 % AVG Validation Acc 78.97 %\n",
      "Epoch:170/200 AVG Training Loss:0.471 AVG Validation Loss:0.515 AVG Training Acc 80.83 % AVG Validation Acc 78.97 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.472 AVG Validation Loss:0.515 AVG Training Acc 80.77 % AVG Validation Acc 79.06 %\n",
      "Epoch:190/200 AVG Training Loss:0.471 AVG Validation Loss:0.516 AVG Training Acc 80.77 % AVG Validation Acc 78.97 %\n",
      "Epoch:200/200 AVG Training Loss:0.473 AVG Validation Loss:0.514 AVG Training Acc 80.63 % AVG Validation Acc 78.97 %\n",
      "Split 167\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59224f1d7c674b0bbf86240f0979eb6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.25 % AVG Validation Acc 79.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.489 AVG Training Acc 80.23 % AVG Validation Acc 80.14 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.483 AVG Validation Loss:0.488 AVG Training Acc 80.46 % AVG Validation Acc 80.23 %\n",
      "Epoch:60/200 AVG Training Loss:0.470 AVG Validation Loss:0.491 AVG Training Acc 80.75 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.464 AVG Validation Loss:0.495 AVG Training Acc 80.98 % AVG Validation Acc 79.78 %\n",
      "Epoch:80/200 AVG Training Loss:0.461 AVG Validation Loss:0.499 AVG Training Acc 81.20 % AVG Validation Acc 79.87 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.458 AVG Validation Loss:0.504 AVG Training Acc 81.28 % AVG Validation Acc 79.69 %\n",
      "Epoch:100/200 AVG Training Loss:0.457 AVG Validation Loss:0.505 AVG Training Acc 81.27 % AVG Validation Acc 79.69 %\n",
      "Epoch:110/200 AVG Training Loss:0.456 AVG Validation Loss:0.510 AVG Training Acc 81.29 % AVG Validation Acc 79.51 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.457 AVG Validation Loss:0.507 AVG Training Acc 81.35 % AVG Validation Acc 79.60 %\n",
      "Epoch:130/200 AVG Training Loss:0.456 AVG Validation Loss:0.505 AVG Training Acc 81.27 % AVG Validation Acc 79.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.456 AVG Validation Loss:0.506 AVG Training Acc 81.33 % AVG Validation Acc 79.69 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.457 AVG Validation Loss:0.510 AVG Training Acc 81.31 % AVG Validation Acc 79.60 %\n",
      "Epoch:160/200 AVG Training Loss:0.457 AVG Validation Loss:0.509 AVG Training Acc 81.38 % AVG Validation Acc 79.51 %\n",
      "Epoch:170/200 AVG Training Loss:0.456 AVG Validation Loss:0.507 AVG Training Acc 81.31 % AVG Validation Acc 79.42 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.456 AVG Validation Loss:0.509 AVG Training Acc 81.26 % AVG Validation Acc 79.51 %\n",
      "Epoch:190/200 AVG Training Loss:0.457 AVG Validation Loss:0.506 AVG Training Acc 81.20 % AVG Validation Acc 79.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.455 AVG Validation Loss:0.506 AVG Training Acc 81.28 % AVG Validation Acc 79.78 %\n",
      "Split 168\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fe91283645f47d09c72ba26c2cf541b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.493 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.30 % AVG Validation Acc 80.14 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.477 AVG Validation Loss:0.495 AVG Training Acc 80.62 % AVG Validation Acc 79.87 %\n",
      "Epoch:50/200 AVG Training Loss:0.468 AVG Validation Loss:0.507 AVG Training Acc 80.91 % AVG Validation Acc 79.87 %\n",
      "Epoch:60/200 AVG Training Loss:0.463 AVG Validation Loss:0.520 AVG Training Acc 81.15 % AVG Validation Acc 79.42 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.458 AVG Validation Loss:0.523 AVG Training Acc 81.27 % AVG Validation Acc 79.24 %\n",
      "Epoch:80/200 AVG Training Loss:0.454 AVG Validation Loss:0.527 AVG Training Acc 81.58 % AVG Validation Acc 79.42 %\n",
      "Epoch:90/200 AVG Training Loss:0.455 AVG Validation Loss:0.526 AVG Training Acc 81.55 % AVG Validation Acc 79.42 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.452 AVG Validation Loss:0.527 AVG Training Acc 81.63 % AVG Validation Acc 79.15 %\n",
      "Epoch:110/200 AVG Training Loss:0.453 AVG Validation Loss:0.530 AVG Training Acc 81.61 % AVG Validation Acc 79.42 %\n",
      "Epoch:120/200 AVG Training Loss:0.453 AVG Validation Loss:0.532 AVG Training Acc 81.51 % AVG Validation Acc 79.24 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.452 AVG Validation Loss:0.531 AVG Training Acc 81.61 % AVG Validation Acc 79.15 %\n",
      "Epoch:140/200 AVG Training Loss:0.454 AVG Validation Loss:0.529 AVG Training Acc 81.55 % AVG Validation Acc 79.51 %\n",
      "Epoch:150/200 AVG Training Loss:0.453 AVG Validation Loss:0.528 AVG Training Acc 81.58 % AVG Validation Acc 79.42 %\n",
      "Epoch:160/200 AVG Training Loss:0.452 AVG Validation Loss:0.529 AVG Training Acc 81.64 % AVG Validation Acc 79.51 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.452 AVG Validation Loss:0.527 AVG Training Acc 81.39 % AVG Validation Acc 79.51 %\n",
      "Epoch:180/200 AVG Training Loss:0.454 AVG Validation Loss:0.533 AVG Training Acc 81.49 % AVG Validation Acc 79.51 %\n",
      "Epoch:190/200 AVG Training Loss:0.452 AVG Validation Loss:0.525 AVG Training Acc 81.46 % AVG Validation Acc 79.51 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.455 AVG Validation Loss:0.528 AVG Training Acc 81.54 % AVG Validation Acc 79.51 %\n",
      "Split 169\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ae20cfa00d4435b49ff13143bfa472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.484 AVG Validation Loss:0.499 AVG Training Acc 80.34 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.482 AVG Validation Loss:0.502 AVG Training Acc 80.38 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.478 AVG Validation Loss:0.502 AVG Training Acc 80.41 % AVG Validation Acc 80.14 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.473 AVG Validation Loss:0.501 AVG Training Acc 80.60 % AVG Validation Acc 80.23 %\n",
      "Epoch:70/200 AVG Training Loss:0.473 AVG Validation Loss:0.503 AVG Training Acc 80.55 % AVG Validation Acc 80.23 %\n",
      "Epoch:80/200 AVG Training Loss:0.471 AVG Validation Loss:0.503 AVG Training Acc 80.67 % AVG Validation Acc 80.14 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.472 AVG Validation Loss:0.504 AVG Training Acc 80.61 % AVG Validation Acc 80.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.473 AVG Validation Loss:0.505 AVG Training Acc 80.60 % AVG Validation Acc 80.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.472 AVG Validation Loss:0.503 AVG Training Acc 80.62 % AVG Validation Acc 80.14 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.472 AVG Validation Loss:0.503 AVG Training Acc 80.63 % AVG Validation Acc 80.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.473 AVG Validation Loss:0.503 AVG Training Acc 80.62 % AVG Validation Acc 80.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.471 AVG Validation Loss:0.505 AVG Training Acc 80.62 % AVG Validation Acc 80.14 %\n",
      "Epoch:150/200 AVG Training Loss:0.471 AVG Validation Loss:0.504 AVG Training Acc 80.70 % AVG Validation Acc 80.14 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.471 AVG Validation Loss:0.505 AVG Training Acc 80.70 % AVG Validation Acc 80.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.471 AVG Validation Loss:0.503 AVG Training Acc 80.64 % AVG Validation Acc 80.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.471 AVG Validation Loss:0.504 AVG Training Acc 80.62 % AVG Validation Acc 80.05 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.473 AVG Validation Loss:0.506 AVG Training Acc 80.64 % AVG Validation Acc 80.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.472 AVG Validation Loss:0.504 AVG Training Acc 80.58 % AVG Validation Acc 80.14 %\n",
      "Split 170\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "554414128b7a43feadfbd439d0f9c7d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.25 % AVG Validation Acc 79.69 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.479 AVG Validation Loss:0.497 AVG Training Acc 80.65 % AVG Validation Acc 79.69 %\n",
      "Epoch:50/200 AVG Training Loss:0.470 AVG Validation Loss:0.509 AVG Training Acc 80.89 % AVG Validation Acc 79.69 %\n",
      "Epoch:60/200 AVG Training Loss:0.466 AVG Validation Loss:0.521 AVG Training Acc 81.08 % AVG Validation Acc 79.33 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.459 AVG Validation Loss:0.535 AVG Training Acc 81.18 % AVG Validation Acc 79.06 %\n",
      "Epoch:80/200 AVG Training Loss:0.460 AVG Validation Loss:0.534 AVG Training Acc 81.25 % AVG Validation Acc 78.97 %\n",
      "Epoch:90/200 AVG Training Loss:0.458 AVG Validation Loss:0.535 AVG Training Acc 81.15 % AVG Validation Acc 78.97 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.457 AVG Validation Loss:0.532 AVG Training Acc 81.39 % AVG Validation Acc 79.06 %\n",
      "Epoch:110/200 AVG Training Loss:0.457 AVG Validation Loss:0.536 AVG Training Acc 81.39 % AVG Validation Acc 78.97 %\n",
      "Epoch:120/200 AVG Training Loss:0.457 AVG Validation Loss:0.537 AVG Training Acc 81.40 % AVG Validation Acc 78.97 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.458 AVG Validation Loss:0.531 AVG Training Acc 81.22 % AVG Validation Acc 78.88 %\n",
      "Epoch:140/200 AVG Training Loss:0.458 AVG Validation Loss:0.538 AVG Training Acc 81.37 % AVG Validation Acc 78.79 %\n",
      "Epoch:150/200 AVG Training Loss:0.458 AVG Validation Loss:0.539 AVG Training Acc 81.38 % AVG Validation Acc 78.97 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.457 AVG Validation Loss:0.535 AVG Training Acc 81.36 % AVG Validation Acc 78.88 %\n",
      "Epoch:170/200 AVG Training Loss:0.458 AVG Validation Loss:0.534 AVG Training Acc 81.42 % AVG Validation Acc 78.97 %\n",
      "Epoch:180/200 AVG Training Loss:0.457 AVG Validation Loss:0.539 AVG Training Acc 81.40 % AVG Validation Acc 78.88 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.457 AVG Validation Loss:0.534 AVG Training Acc 81.27 % AVG Validation Acc 78.97 %\n",
      "Epoch:200/200 AVG Training Loss:0.456 AVG Validation Loss:0.535 AVG Training Acc 81.36 % AVG Validation Acc 79.06 %\n",
      "Split 171\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b4a6438cee4732a748aa9487c18275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.505 AVG Training Acc 80.10 % AVG Validation Acc 80.16 %\n",
      "Epoch    15: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.490 AVG Validation Loss:0.501 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.501 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.504 AVG Training Acc 80.28 % AVG Validation Acc 79.89 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.484 AVG Validation Loss:0.501 AVG Training Acc 80.28 % AVG Validation Acc 80.07 %\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.502 AVG Training Acc 80.28 % AVG Validation Acc 79.98 %\n",
      "Epoch:70/200 AVG Training Loss:0.483 AVG Validation Loss:0.502 AVG Training Acc 80.28 % AVG Validation Acc 79.98 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.482 AVG Validation Loss:0.503 AVG Training Acc 80.28 % AVG Validation Acc 79.89 %\n",
      "Epoch:90/200 AVG Training Loss:0.483 AVG Validation Loss:0.503 AVG Training Acc 80.30 % AVG Validation Acc 79.89 %\n",
      "Epoch:100/200 AVG Training Loss:0.483 AVG Validation Loss:0.503 AVG Training Acc 80.30 % AVG Validation Acc 79.89 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.482 AVG Validation Loss:0.503 AVG Training Acc 80.29 % AVG Validation Acc 79.89 %\n",
      "Epoch:120/200 AVG Training Loss:0.483 AVG Validation Loss:0.503 AVG Training Acc 80.29 % AVG Validation Acc 79.89 %\n",
      "Epoch:130/200 AVG Training Loss:0.483 AVG Validation Loss:0.503 AVG Training Acc 80.24 % AVG Validation Acc 79.89 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.483 AVG Validation Loss:0.502 AVG Training Acc 80.32 % AVG Validation Acc 79.89 %\n",
      "Epoch:150/200 AVG Training Loss:0.481 AVG Validation Loss:0.503 AVG Training Acc 80.25 % AVG Validation Acc 79.89 %\n",
      "Epoch:160/200 AVG Training Loss:0.482 AVG Validation Loss:0.503 AVG Training Acc 80.30 % AVG Validation Acc 79.89 %\n",
      "Epoch:170/200 AVG Training Loss:0.482 AVG Validation Loss:0.503 AVG Training Acc 80.29 % AVG Validation Acc 79.80 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.482 AVG Validation Loss:0.503 AVG Training Acc 80.29 % AVG Validation Acc 79.89 %\n",
      "Epoch:190/200 AVG Training Loss:0.482 AVG Validation Loss:0.503 AVG Training Acc 80.27 % AVG Validation Acc 79.89 %\n",
      "Epoch:200/200 AVG Training Loss:0.483 AVG Validation Loss:0.503 AVG Training Acc 80.30 % AVG Validation Acc 79.89 %\n",
      "Split 172\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2be22e861adb4cb68b8223e6c5f190ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.10 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.487 AVG Validation Loss:0.502 AVG Training Acc 80.25 % AVG Validation Acc 80.16 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.477 AVG Validation Loss:0.505 AVG Training Acc 80.28 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.470 AVG Validation Loss:0.513 AVG Training Acc 80.47 % AVG Validation Acc 79.35 %\n",
      "Epoch:60/200 AVG Training Loss:0.461 AVG Validation Loss:0.524 AVG Training Acc 80.67 % AVG Validation Acc 79.35 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.456 AVG Validation Loss:0.532 AVG Training Acc 80.92 % AVG Validation Acc 79.35 %\n",
      "Epoch:80/200 AVG Training Loss:0.450 AVG Validation Loss:0.534 AVG Training Acc 81.11 % AVG Validation Acc 79.35 %\n",
      "Epoch:90/200 AVG Training Loss:0.453 AVG Validation Loss:0.534 AVG Training Acc 80.85 % AVG Validation Acc 79.35 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.452 AVG Validation Loss:0.533 AVG Training Acc 80.97 % AVG Validation Acc 79.35 %\n",
      "Epoch:110/200 AVG Training Loss:0.451 AVG Validation Loss:0.537 AVG Training Acc 81.13 % AVG Validation Acc 79.35 %\n",
      "Epoch:120/200 AVG Training Loss:0.451 AVG Validation Loss:0.538 AVG Training Acc 80.97 % AVG Validation Acc 79.44 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.452 AVG Validation Loss:0.536 AVG Training Acc 80.73 % AVG Validation Acc 79.35 %\n",
      "Epoch:140/200 AVG Training Loss:0.450 AVG Validation Loss:0.533 AVG Training Acc 81.17 % AVG Validation Acc 79.26 %\n",
      "Epoch:150/200 AVG Training Loss:0.451 AVG Validation Loss:0.533 AVG Training Acc 81.03 % AVG Validation Acc 79.44 %\n",
      "Epoch:160/200 AVG Training Loss:0.451 AVG Validation Loss:0.536 AVG Training Acc 81.02 % AVG Validation Acc 79.44 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.451 AVG Validation Loss:0.537 AVG Training Acc 80.75 % AVG Validation Acc 79.26 %\n",
      "Epoch:180/200 AVG Training Loss:0.450 AVG Validation Loss:0.536 AVG Training Acc 81.07 % AVG Validation Acc 79.53 %\n",
      "Epoch:190/200 AVG Training Loss:0.452 AVG Validation Loss:0.536 AVG Training Acc 80.90 % AVG Validation Acc 79.35 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.450 AVG Validation Loss:0.537 AVG Training Acc 80.97 % AVG Validation Acc 79.26 %\n",
      "Split 173\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f879ab232af4b83bf5b9593a3eb4c5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.491 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.493 AVG Training Acc 80.18 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.491 AVG Training Acc 80.27 % AVG Validation Acc 79.98 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.483 AVG Validation Loss:0.486 AVG Training Acc 80.38 % AVG Validation Acc 79.89 %\n",
      "Epoch:60/200 AVG Training Loss:0.470 AVG Validation Loss:0.485 AVG Training Acc 80.83 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.462 AVG Validation Loss:0.498 AVG Training Acc 81.18 % AVG Validation Acc 79.71 %\n",
      "Epoch:80/200 AVG Training Loss:0.459 AVG Validation Loss:0.509 AVG Training Acc 81.31 % AVG Validation Acc 79.44 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.455 AVG Validation Loss:0.510 AVG Training Acc 81.40 % AVG Validation Acc 79.44 %\n",
      "Epoch:100/200 AVG Training Loss:0.455 AVG Validation Loss:0.515 AVG Training Acc 81.45 % AVG Validation Acc 79.44 %\n",
      "Epoch:110/200 AVG Training Loss:0.454 AVG Validation Loss:0.509 AVG Training Acc 81.36 % AVG Validation Acc 79.53 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.456 AVG Validation Loss:0.512 AVG Training Acc 81.26 % AVG Validation Acc 79.62 %\n",
      "Epoch:130/200 AVG Training Loss:0.455 AVG Validation Loss:0.513 AVG Training Acc 81.32 % AVG Validation Acc 79.44 %\n",
      "Epoch:140/200 AVG Training Loss:0.452 AVG Validation Loss:0.510 AVG Training Acc 81.43 % AVG Validation Acc 79.53 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.454 AVG Validation Loss:0.509 AVG Training Acc 81.35 % AVG Validation Acc 79.71 %\n",
      "Epoch:160/200 AVG Training Loss:0.454 AVG Validation Loss:0.513 AVG Training Acc 81.46 % AVG Validation Acc 79.35 %\n",
      "Epoch:170/200 AVG Training Loss:0.453 AVG Validation Loss:0.513 AVG Training Acc 81.44 % AVG Validation Acc 79.53 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.454 AVG Validation Loss:0.510 AVG Training Acc 81.43 % AVG Validation Acc 79.53 %\n",
      "Epoch:190/200 AVG Training Loss:0.453 AVG Validation Loss:0.513 AVG Training Acc 81.49 % AVG Validation Acc 79.44 %\n",
      "Epoch:200/200 AVG Training Loss:0.452 AVG Validation Loss:0.508 AVG Training Acc 81.53 % AVG Validation Acc 79.62 %\n",
      "Split 174\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28d971a237cb4c78855c8011aa95a0d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.491 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.481 AVG Validation Loss:0.495 AVG Training Acc 80.26 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.478 AVG Validation Loss:0.495 AVG Training Acc 80.41 % AVG Validation Acc 80.25 %\n",
      "Epoch:60/200 AVG Training Loss:0.475 AVG Validation Loss:0.495 AVG Training Acc 80.60 % AVG Validation Acc 80.25 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.471 AVG Validation Loss:0.495 AVG Training Acc 80.56 % AVG Validation Acc 80.16 %\n",
      "Epoch:80/200 AVG Training Loss:0.472 AVG Validation Loss:0.495 AVG Training Acc 80.63 % AVG Validation Acc 80.34 %\n",
      "Epoch:90/200 AVG Training Loss:0.472 AVG Validation Loss:0.495 AVG Training Acc 80.59 % AVG Validation Acc 80.34 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.471 AVG Validation Loss:0.496 AVG Training Acc 80.61 % AVG Validation Acc 80.34 %\n",
      "Epoch:110/200 AVG Training Loss:0.471 AVG Validation Loss:0.496 AVG Training Acc 80.66 % AVG Validation Acc 80.25 %\n",
      "Epoch:120/200 AVG Training Loss:0.471 AVG Validation Loss:0.496 AVG Training Acc 80.67 % AVG Validation Acc 80.34 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.471 AVG Validation Loss:0.495 AVG Training Acc 80.60 % AVG Validation Acc 80.34 %\n",
      "Epoch:140/200 AVG Training Loss:0.471 AVG Validation Loss:0.496 AVG Training Acc 80.69 % AVG Validation Acc 80.25 %\n",
      "Epoch:150/200 AVG Training Loss:0.470 AVG Validation Loss:0.496 AVG Training Acc 80.68 % AVG Validation Acc 80.25 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.471 AVG Validation Loss:0.495 AVG Training Acc 80.60 % AVG Validation Acc 80.34 %\n",
      "Epoch:170/200 AVG Training Loss:0.469 AVG Validation Loss:0.495 AVG Training Acc 80.81 % AVG Validation Acc 80.34 %\n",
      "Epoch:180/200 AVG Training Loss:0.470 AVG Validation Loss:0.497 AVG Training Acc 80.66 % AVG Validation Acc 80.34 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.470 AVG Validation Loss:0.495 AVG Training Acc 80.72 % AVG Validation Acc 80.34 %\n",
      "Epoch:200/200 AVG Training Loss:0.470 AVG Validation Loss:0.496 AVG Training Acc 80.66 % AVG Validation Acc 80.34 %\n",
      "Split 175\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dbe7fb8cd864955985b35ace6a331bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.27 % AVG Validation Acc 80.07 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.473 AVG Validation Loss:0.496 AVG Training Acc 80.72 % AVG Validation Acc 79.35 %\n",
      "Epoch:50/200 AVG Training Loss:0.464 AVG Validation Loss:0.514 AVG Training Acc 80.93 % AVG Validation Acc 79.62 %\n",
      "Epoch:60/200 AVG Training Loss:0.457 AVG Validation Loss:0.519 AVG Training Acc 81.28 % AVG Validation Acc 79.44 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.453 AVG Validation Loss:0.532 AVG Training Acc 81.50 % AVG Validation Acc 78.63 %\n",
      "Epoch:80/200 AVG Training Loss:0.454 AVG Validation Loss:0.530 AVG Training Acc 81.42 % AVG Validation Acc 79.08 %\n",
      "Epoch:90/200 AVG Training Loss:0.452 AVG Validation Loss:0.532 AVG Training Acc 81.53 % AVG Validation Acc 78.90 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.451 AVG Validation Loss:0.530 AVG Training Acc 81.50 % AVG Validation Acc 78.90 %\n",
      "Epoch:110/200 AVG Training Loss:0.451 AVG Validation Loss:0.530 AVG Training Acc 81.64 % AVG Validation Acc 78.99 %\n",
      "Epoch:120/200 AVG Training Loss:0.451 AVG Validation Loss:0.534 AVG Training Acc 81.61 % AVG Validation Acc 78.81 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.452 AVG Validation Loss:0.531 AVG Training Acc 81.51 % AVG Validation Acc 78.90 %\n",
      "Epoch:140/200 AVG Training Loss:0.449 AVG Validation Loss:0.532 AVG Training Acc 81.63 % AVG Validation Acc 78.90 %\n",
      "Epoch:150/200 AVG Training Loss:0.452 AVG Validation Loss:0.531 AVG Training Acc 81.48 % AVG Validation Acc 78.63 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.451 AVG Validation Loss:0.531 AVG Training Acc 81.55 % AVG Validation Acc 78.63 %\n",
      "Epoch:170/200 AVG Training Loss:0.451 AVG Validation Loss:0.537 AVG Training Acc 81.49 % AVG Validation Acc 78.54 %\n",
      "Epoch:180/200 AVG Training Loss:0.451 AVG Validation Loss:0.532 AVG Training Acc 81.54 % AVG Validation Acc 79.08 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.452 AVG Validation Loss:0.535 AVG Training Acc 81.58 % AVG Validation Acc 78.72 %\n",
      "Epoch:200/200 AVG Training Loss:0.451 AVG Validation Loss:0.533 AVG Training Acc 81.46 % AVG Validation Acc 78.27 %\n",
      "Split 176\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67ffd56f7f9444ceb686b61a002192e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.22 % AVG Validation Acc 79.96 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.477 AVG Validation Loss:0.493 AVG Training Acc 80.70 % AVG Validation Acc 80.23 %\n",
      "Epoch:50/200 AVG Training Loss:0.473 AVG Validation Loss:0.498 AVG Training Acc 80.79 % AVG Validation Acc 80.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.468 AVG Validation Loss:0.505 AVG Training Acc 81.06 % AVG Validation Acc 79.78 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.465 AVG Validation Loss:0.504 AVG Training Acc 81.19 % AVG Validation Acc 79.78 %\n",
      "Epoch:80/200 AVG Training Loss:0.462 AVG Validation Loss:0.508 AVG Training Acc 81.30 % AVG Validation Acc 79.78 %\n",
      "Epoch:90/200 AVG Training Loss:0.462 AVG Validation Loss:0.505 AVG Training Acc 81.32 % AVG Validation Acc 79.87 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.461 AVG Validation Loss:0.502 AVG Training Acc 81.30 % AVG Validation Acc 80.23 %\n",
      "Epoch:110/200 AVG Training Loss:0.462 AVG Validation Loss:0.511 AVG Training Acc 81.17 % AVG Validation Acc 79.78 %\n",
      "Epoch:120/200 AVG Training Loss:0.460 AVG Validation Loss:0.511 AVG Training Acc 81.30 % AVG Validation Acc 79.87 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.461 AVG Validation Loss:0.511 AVG Training Acc 81.25 % AVG Validation Acc 79.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.461 AVG Validation Loss:0.508 AVG Training Acc 81.32 % AVG Validation Acc 79.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.463 AVG Validation Loss:0.506 AVG Training Acc 81.13 % AVG Validation Acc 79.69 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.461 AVG Validation Loss:0.511 AVG Training Acc 81.42 % AVG Validation Acc 79.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.462 AVG Validation Loss:0.519 AVG Training Acc 81.18 % AVG Validation Acc 79.60 %\n",
      "Epoch:180/200 AVG Training Loss:0.461 AVG Validation Loss:0.514 AVG Training Acc 81.23 % AVG Validation Acc 79.78 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.463 AVG Validation Loss:0.506 AVG Training Acc 81.20 % AVG Validation Acc 79.87 %\n",
      "Epoch:200/200 AVG Training Loss:0.462 AVG Validation Loss:0.509 AVG Training Acc 81.31 % AVG Validation Acc 79.87 %\n",
      "Split 177\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c8a1560537c45ad937e0616a2510484",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.500 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch    18: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.488 AVG Validation Loss:0.500 AVG Training Acc 80.19 % AVG Validation Acc 79.96 %\n",
      "Epoch:30/200 AVG Training Loss:0.485 AVG Validation Loss:0.503 AVG Training Acc 80.35 % AVG Validation Acc 79.69 %\n",
      "Epoch:40/200 AVG Training Loss:0.481 AVG Validation Loss:0.503 AVG Training Acc 80.57 % AVG Validation Acc 79.60 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.476 AVG Validation Loss:0.509 AVG Training Acc 80.94 % AVG Validation Acc 79.24 %\n",
      "Epoch:60/200 AVG Training Loss:0.476 AVG Validation Loss:0.509 AVG Training Acc 80.77 % AVG Validation Acc 79.42 %\n",
      "Epoch:70/200 AVG Training Loss:0.475 AVG Validation Loss:0.508 AVG Training Acc 80.88 % AVG Validation Acc 79.42 %\n",
      "Epoch:80/200 AVG Training Loss:0.474 AVG Validation Loss:0.509 AVG Training Acc 80.93 % AVG Validation Acc 79.42 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.473 AVG Validation Loss:0.510 AVG Training Acc 80.96 % AVG Validation Acc 79.42 %\n",
      "Epoch:100/200 AVG Training Loss:0.474 AVG Validation Loss:0.510 AVG Training Acc 80.89 % AVG Validation Acc 79.42 %\n",
      "Epoch:110/200 AVG Training Loss:0.473 AVG Validation Loss:0.509 AVG Training Acc 81.04 % AVG Validation Acc 79.42 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.474 AVG Validation Loss:0.510 AVG Training Acc 80.99 % AVG Validation Acc 79.42 %\n",
      "Epoch:130/200 AVG Training Loss:0.474 AVG Validation Loss:0.510 AVG Training Acc 80.87 % AVG Validation Acc 79.42 %\n",
      "Epoch:140/200 AVG Training Loss:0.473 AVG Validation Loss:0.510 AVG Training Acc 81.01 % AVG Validation Acc 79.42 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.473 AVG Validation Loss:0.510 AVG Training Acc 80.96 % AVG Validation Acc 79.42 %\n",
      "Epoch:160/200 AVG Training Loss:0.473 AVG Validation Loss:0.510 AVG Training Acc 80.92 % AVG Validation Acc 79.42 %\n",
      "Epoch:170/200 AVG Training Loss:0.473 AVG Validation Loss:0.511 AVG Training Acc 81.04 % AVG Validation Acc 79.42 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.474 AVG Validation Loss:0.510 AVG Training Acc 80.96 % AVG Validation Acc 79.42 %\n",
      "Epoch:190/200 AVG Training Loss:0.473 AVG Validation Loss:0.510 AVG Training Acc 81.02 % AVG Validation Acc 79.42 %\n",
      "Epoch:200/200 AVG Training Loss:0.474 AVG Validation Loss:0.511 AVG Training Acc 80.96 % AVG Validation Acc 79.42 %\n",
      "Split 178\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "822a7cb5f2e3437d8f530b5bb46ec00f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.498 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.493 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.501 AVG Training Acc 80.09 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.488 AVG Validation Loss:0.487 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.478 AVG Validation Loss:0.492 AVG Training Acc 80.24 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.472 AVG Validation Loss:0.495 AVG Training Acc 80.33 % AVG Validation Acc 79.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.469 AVG Validation Loss:0.495 AVG Training Acc 80.39 % AVG Validation Acc 80.14 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.463 AVG Validation Loss:0.502 AVG Training Acc 80.45 % AVG Validation Acc 79.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.461 AVG Validation Loss:0.503 AVG Training Acc 80.56 % AVG Validation Acc 79.96 %\n",
      "Epoch:110/200 AVG Training Loss:0.463 AVG Validation Loss:0.503 AVG Training Acc 80.46 % AVG Validation Acc 79.96 %\n",
      "Epoch:120/200 AVG Training Loss:0.459 AVG Validation Loss:0.499 AVG Training Acc 80.73 % AVG Validation Acc 79.96 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.459 AVG Validation Loss:0.501 AVG Training Acc 80.68 % AVG Validation Acc 79.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.460 AVG Validation Loss:0.501 AVG Training Acc 80.67 % AVG Validation Acc 79.87 %\n",
      "Epoch:150/200 AVG Training Loss:0.460 AVG Validation Loss:0.504 AVG Training Acc 80.75 % AVG Validation Acc 79.96 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.459 AVG Validation Loss:0.502 AVG Training Acc 80.83 % AVG Validation Acc 79.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.461 AVG Validation Loss:0.501 AVG Training Acc 80.55 % AVG Validation Acc 79.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.459 AVG Validation Loss:0.501 AVG Training Acc 80.73 % AVG Validation Acc 79.87 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.461 AVG Validation Loss:0.503 AVG Training Acc 80.61 % AVG Validation Acc 79.96 %\n",
      "Epoch:200/200 AVG Training Loss:0.461 AVG Validation Loss:0.501 AVG Training Acc 80.61 % AVG Validation Acc 79.96 %\n",
      "Split 179\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "396322ba3094495f9a585760022ceeef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.488 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.487 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.489 AVG Training Acc 80.32 % AVG Validation Acc 80.14 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.477 AVG Validation Loss:0.486 AVG Training Acc 80.39 % AVG Validation Acc 79.96 %\n",
      "Epoch:60/200 AVG Training Loss:0.465 AVG Validation Loss:0.499 AVG Training Acc 80.85 % AVG Validation Acc 79.78 %\n",
      "Epoch:70/200 AVG Training Loss:0.457 AVG Validation Loss:0.514 AVG Training Acc 81.35 % AVG Validation Acc 79.33 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.447 AVG Validation Loss:0.522 AVG Training Acc 81.63 % AVG Validation Acc 79.15 %\n",
      "Epoch:90/200 AVG Training Loss:0.447 AVG Validation Loss:0.522 AVG Training Acc 81.83 % AVG Validation Acc 79.06 %\n",
      "Epoch:100/200 AVG Training Loss:0.449 AVG Validation Loss:0.527 AVG Training Acc 81.67 % AVG Validation Acc 78.61 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.444 AVG Validation Loss:0.529 AVG Training Acc 81.78 % AVG Validation Acc 78.97 %\n",
      "Epoch:120/200 AVG Training Loss:0.444 AVG Validation Loss:0.528 AVG Training Acc 81.84 % AVG Validation Acc 78.61 %\n",
      "Epoch:130/200 AVG Training Loss:0.446 AVG Validation Loss:0.533 AVG Training Acc 81.87 % AVG Validation Acc 78.88 %\n",
      "Epoch:140/200 AVG Training Loss:0.446 AVG Validation Loss:0.529 AVG Training Acc 81.68 % AVG Validation Acc 78.52 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.445 AVG Validation Loss:0.526 AVG Training Acc 81.77 % AVG Validation Acc 78.61 %\n",
      "Epoch:160/200 AVG Training Loss:0.445 AVG Validation Loss:0.527 AVG Training Acc 81.82 % AVG Validation Acc 78.70 %\n",
      "Epoch:170/200 AVG Training Loss:0.444 AVG Validation Loss:0.526 AVG Training Acc 81.93 % AVG Validation Acc 78.79 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.443 AVG Validation Loss:0.528 AVG Training Acc 81.96 % AVG Validation Acc 78.88 %\n",
      "Epoch:190/200 AVG Training Loss:0.446 AVG Validation Loss:0.532 AVG Training Acc 81.69 % AVG Validation Acc 78.70 %\n",
      "Epoch:200/200 AVG Training Loss:0.444 AVG Validation Loss:0.528 AVG Training Acc 81.93 % AVG Validation Acc 78.88 %\n",
      "Split 180\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd7d8151c41d4c92a1f18a5d8d100a2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.496 AVG Training Acc 80.16 % AVG Validation Acc 79.87 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.22 % AVG Validation Acc 79.87 %\n",
      "Epoch:40/200 AVG Training Loss:0.485 AVG Validation Loss:0.502 AVG Training Acc 80.25 % AVG Validation Acc 79.78 %\n",
      "Epoch:50/200 AVG Training Loss:0.482 AVG Validation Loss:0.508 AVG Training Acc 80.34 % AVG Validation Acc 79.78 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.482 AVG Validation Loss:0.509 AVG Training Acc 80.31 % AVG Validation Acc 79.78 %\n",
      "Epoch:70/200 AVG Training Loss:0.482 AVG Validation Loss:0.509 AVG Training Acc 80.26 % AVG Validation Acc 79.69 %\n",
      "Epoch:80/200 AVG Training Loss:0.482 AVG Validation Loss:0.510 AVG Training Acc 80.37 % AVG Validation Acc 79.69 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.481 AVG Validation Loss:0.510 AVG Training Acc 80.29 % AVG Validation Acc 79.69 %\n",
      "Epoch:100/200 AVG Training Loss:0.482 AVG Validation Loss:0.510 AVG Training Acc 80.30 % AVG Validation Acc 79.69 %\n",
      "Epoch:110/200 AVG Training Loss:0.481 AVG Validation Loss:0.510 AVG Training Acc 80.31 % AVG Validation Acc 79.78 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.481 AVG Validation Loss:0.511 AVG Training Acc 80.37 % AVG Validation Acc 79.78 %\n",
      "Epoch:130/200 AVG Training Loss:0.481 AVG Validation Loss:0.510 AVG Training Acc 80.36 % AVG Validation Acc 79.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.481 AVG Validation Loss:0.510 AVG Training Acc 80.34 % AVG Validation Acc 79.78 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.481 AVG Validation Loss:0.510 AVG Training Acc 80.38 % AVG Validation Acc 79.78 %\n",
      "Epoch:160/200 AVG Training Loss:0.481 AVG Validation Loss:0.511 AVG Training Acc 80.32 % AVG Validation Acc 79.69 %\n",
      "Epoch:170/200 AVG Training Loss:0.481 AVG Validation Loss:0.510 AVG Training Acc 80.31 % AVG Validation Acc 79.87 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.482 AVG Validation Loss:0.511 AVG Training Acc 80.35 % AVG Validation Acc 79.78 %\n",
      "Epoch:190/200 AVG Training Loss:0.482 AVG Validation Loss:0.510 AVG Training Acc 80.32 % AVG Validation Acc 79.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.480 AVG Validation Loss:0.510 AVG Training Acc 80.36 % AVG Validation Acc 79.78 %\n",
      "Split 181\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd4ea0aba34490099e2222cfe89e3c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.483 AVG Validation Loss:0.504 AVG Training Acc 80.34 % AVG Validation Acc 79.53 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.465 AVG Validation Loss:0.522 AVG Training Acc 80.96 % AVG Validation Acc 79.26 %\n",
      "Epoch:50/200 AVG Training Loss:0.459 AVG Validation Loss:0.539 AVG Training Acc 81.39 % AVG Validation Acc 79.17 %\n",
      "Epoch:60/200 AVG Training Loss:0.451 AVG Validation Loss:0.547 AVG Training Acc 81.63 % AVG Validation Acc 78.99 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.447 AVG Validation Loss:0.565 AVG Training Acc 81.83 % AVG Validation Acc 78.54 %\n",
      "Epoch:80/200 AVG Training Loss:0.445 AVG Validation Loss:0.563 AVG Training Acc 81.89 % AVG Validation Acc 78.81 %\n",
      "Epoch:90/200 AVG Training Loss:0.443 AVG Validation Loss:0.564 AVG Training Acc 81.96 % AVG Validation Acc 78.99 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.445 AVG Validation Loss:0.566 AVG Training Acc 81.96 % AVG Validation Acc 78.63 %\n",
      "Epoch:110/200 AVG Training Loss:0.441 AVG Validation Loss:0.567 AVG Training Acc 82.02 % AVG Validation Acc 78.81 %\n",
      "Epoch:120/200 AVG Training Loss:0.443 AVG Validation Loss:0.566 AVG Training Acc 81.92 % AVG Validation Acc 78.90 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.443 AVG Validation Loss:0.565 AVG Training Acc 81.92 % AVG Validation Acc 78.81 %\n",
      "Epoch:140/200 AVG Training Loss:0.442 AVG Validation Loss:0.568 AVG Training Acc 82.08 % AVG Validation Acc 78.63 %\n",
      "Epoch:150/200 AVG Training Loss:0.442 AVG Validation Loss:0.567 AVG Training Acc 82.03 % AVG Validation Acc 78.90 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.442 AVG Validation Loss:0.562 AVG Training Acc 81.92 % AVG Validation Acc 78.99 %\n",
      "Epoch:170/200 AVG Training Loss:0.444 AVG Validation Loss:0.566 AVG Training Acc 81.95 % AVG Validation Acc 78.90 %\n",
      "Epoch:180/200 AVG Training Loss:0.443 AVG Validation Loss:0.572 AVG Training Acc 81.92 % AVG Validation Acc 78.72 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.444 AVG Validation Loss:0.562 AVG Training Acc 81.88 % AVG Validation Acc 78.72 %\n",
      "Epoch:200/200 AVG Training Loss:0.442 AVG Validation Loss:0.567 AVG Training Acc 82.12 % AVG Validation Acc 78.81 %\n",
      "Split 182\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a3697002edf4ccba9589043d9a4a6d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.499 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.483 AVG Validation Loss:0.495 AVG Training Acc 80.25 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.479 AVG Validation Loss:0.500 AVG Training Acc 80.30 % AVG Validation Acc 80.16 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:70/200 AVG Training Loss:0.463 AVG Validation Loss:0.506 AVG Training Acc 80.57 % AVG Validation Acc 79.80 %\n",
      "Epoch:80/200 AVG Training Loss:0.453 AVG Validation Loss:0.512 AVG Training Acc 80.85 % AVG Validation Acc 79.89 %\n",
      "Epoch:90/200 AVG Training Loss:0.447 AVG Validation Loss:0.520 AVG Training Acc 80.79 % AVG Validation Acc 79.71 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.440 AVG Validation Loss:0.525 AVG Training Acc 81.11 % AVG Validation Acc 79.80 %\n",
      "Epoch:110/200 AVG Training Loss:0.439 AVG Validation Loss:0.524 AVG Training Acc 81.09 % AVG Validation Acc 79.53 %\n",
      "Epoch:120/200 AVG Training Loss:0.440 AVG Validation Loss:0.524 AVG Training Acc 81.12 % AVG Validation Acc 79.44 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.439 AVG Validation Loss:0.529 AVG Training Acc 81.07 % AVG Validation Acc 79.44 %\n",
      "Epoch:140/200 AVG Training Loss:0.437 AVG Validation Loss:0.525 AVG Training Acc 81.32 % AVG Validation Acc 79.53 %\n",
      "Epoch:150/200 AVG Training Loss:0.439 AVG Validation Loss:0.531 AVG Training Acc 81.29 % AVG Validation Acc 79.26 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.439 AVG Validation Loss:0.525 AVG Training Acc 81.31 % AVG Validation Acc 79.26 %\n",
      "Epoch:170/200 AVG Training Loss:0.438 AVG Validation Loss:0.527 AVG Training Acc 81.35 % AVG Validation Acc 79.26 %\n",
      "Epoch:180/200 AVG Training Loss:0.438 AVG Validation Loss:0.528 AVG Training Acc 81.16 % AVG Validation Acc 79.17 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.438 AVG Validation Loss:0.531 AVG Training Acc 81.16 % AVG Validation Acc 79.08 %\n",
      "Epoch:200/200 AVG Training Loss:0.438 AVG Validation Loss:0.525 AVG Training Acc 81.02 % AVG Validation Acc 79.35 %\n",
      "Split 183\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85f1d47da5734db59cf37a3ff740e595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.22 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.503 AVG Validation Loss:0.505 AVG Training Acc 80.08 % AVG Validation Acc 80.16 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.496 AVG Validation Loss:0.494 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:90/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:100/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:120/200 AVG Training Loss:0.493 AVG Validation Loss:0.493 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:130/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.493 AVG Validation Loss:0.493 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:150/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:160/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:180/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:190/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:200/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch   200: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Split 184\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1380a84aab24499985d665d8e100a7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.503 AVG Training Acc 80.24 % AVG Validation Acc 79.98 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.476 AVG Validation Loss:0.521 AVG Training Acc 80.40 % AVG Validation Acc 79.98 %\n",
      "Epoch:50/200 AVG Training Loss:0.468 AVG Validation Loss:0.539 AVG Training Acc 80.68 % AVG Validation Acc 79.80 %\n",
      "Epoch:60/200 AVG Training Loss:0.461 AVG Validation Loss:0.563 AVG Training Acc 80.87 % AVG Validation Acc 79.53 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.453 AVG Validation Loss:0.583 AVG Training Acc 80.93 % AVG Validation Acc 79.71 %\n",
      "Epoch:80/200 AVG Training Loss:0.450 AVG Validation Loss:0.589 AVG Training Acc 81.19 % AVG Validation Acc 79.62 %\n",
      "Epoch:90/200 AVG Training Loss:0.451 AVG Validation Loss:0.590 AVG Training Acc 81.03 % AVG Validation Acc 79.62 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.450 AVG Validation Loss:0.592 AVG Training Acc 81.12 % AVG Validation Acc 79.44 %\n",
      "Epoch:110/200 AVG Training Loss:0.451 AVG Validation Loss:0.584 AVG Training Acc 80.98 % AVG Validation Acc 79.71 %\n",
      "Epoch:120/200 AVG Training Loss:0.448 AVG Validation Loss:0.594 AVG Training Acc 81.10 % AVG Validation Acc 79.44 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.449 AVG Validation Loss:0.597 AVG Training Acc 81.02 % AVG Validation Acc 79.44 %\n",
      "Epoch:140/200 AVG Training Loss:0.447 AVG Validation Loss:0.594 AVG Training Acc 81.21 % AVG Validation Acc 79.53 %\n",
      "Epoch:150/200 AVG Training Loss:0.450 AVG Validation Loss:0.591 AVG Training Acc 81.14 % AVG Validation Acc 79.53 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.448 AVG Validation Loss:0.593 AVG Training Acc 81.08 % AVG Validation Acc 79.53 %\n",
      "Epoch:170/200 AVG Training Loss:0.449 AVG Validation Loss:0.594 AVG Training Acc 81.11 % AVG Validation Acc 79.44 %\n",
      "Epoch:180/200 AVG Training Loss:0.448 AVG Validation Loss:0.594 AVG Training Acc 81.08 % AVG Validation Acc 79.44 %\n",
      "Epoch:190/200 AVG Training Loss:0.449 AVG Validation Loss:0.594 AVG Training Acc 81.05 % AVG Validation Acc 79.44 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.449 AVG Validation Loss:0.595 AVG Training Acc 81.09 % AVG Validation Acc 79.35 %\n",
      "Split 185\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cc80d5638db459ea822a44e25dbd4ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.13 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.486 AVG Validation Loss:0.492 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.492 AVG Training Acc 80.21 % AVG Validation Acc 79.98 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.467 AVG Validation Loss:0.499 AVG Training Acc 80.60 % AVG Validation Acc 79.62 %\n",
      "Epoch:60/200 AVG Training Loss:0.460 AVG Validation Loss:0.504 AVG Training Acc 80.95 % AVG Validation Acc 79.44 %\n",
      "Epoch:70/200 AVG Training Loss:0.455 AVG Validation Loss:0.509 AVG Training Acc 81.09 % AVG Validation Acc 79.35 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.453 AVG Validation Loss:0.507 AVG Training Acc 81.31 % AVG Validation Acc 79.08 %\n",
      "Epoch:90/200 AVG Training Loss:0.449 AVG Validation Loss:0.515 AVG Training Acc 81.38 % AVG Validation Acc 78.90 %\n",
      "Epoch:100/200 AVG Training Loss:0.450 AVG Validation Loss:0.515 AVG Training Acc 81.43 % AVG Validation Acc 78.90 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.447 AVG Validation Loss:0.515 AVG Training Acc 81.27 % AVG Validation Acc 79.17 %\n",
      "Epoch:120/200 AVG Training Loss:0.448 AVG Validation Loss:0.515 AVG Training Acc 81.38 % AVG Validation Acc 78.99 %\n",
      "Epoch:130/200 AVG Training Loss:0.447 AVG Validation Loss:0.518 AVG Training Acc 81.41 % AVG Validation Acc 78.54 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.448 AVG Validation Loss:0.513 AVG Training Acc 81.27 % AVG Validation Acc 79.08 %\n",
      "Epoch:150/200 AVG Training Loss:0.449 AVG Validation Loss:0.519 AVG Training Acc 81.35 % AVG Validation Acc 78.99 %\n",
      "Epoch:160/200 AVG Training Loss:0.450 AVG Validation Loss:0.514 AVG Training Acc 81.32 % AVG Validation Acc 79.08 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.448 AVG Validation Loss:0.514 AVG Training Acc 81.41 % AVG Validation Acc 78.90 %\n",
      "Epoch:180/200 AVG Training Loss:0.449 AVG Validation Loss:0.517 AVG Training Acc 81.36 % AVG Validation Acc 78.72 %\n",
      "Epoch:190/200 AVG Training Loss:0.449 AVG Validation Loss:0.515 AVG Training Acc 81.31 % AVG Validation Acc 79.26 %\n",
      "Epoch   198: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.449 AVG Validation Loss:0.513 AVG Training Acc 81.29 % AVG Validation Acc 78.99 %\n",
      "Split 186\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f151f4425eb40ad835ab27c0c9af861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.484 AVG Validation Loss:0.494 AVG Training Acc 80.29 % AVG Validation Acc 79.87 %\n",
      "Epoch:40/200 AVG Training Loss:0.480 AVG Validation Loss:0.494 AVG Training Acc 80.50 % AVG Validation Acc 80.23 %\n",
      "Epoch:50/200 AVG Training Loss:0.478 AVG Validation Loss:0.498 AVG Training Acc 80.64 % AVG Validation Acc 79.96 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.475 AVG Validation Loss:0.496 AVG Training Acc 80.73 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.476 AVG Validation Loss:0.498 AVG Training Acc 80.71 % AVG Validation Acc 80.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.475 AVG Validation Loss:0.496 AVG Training Acc 80.71 % AVG Validation Acc 80.14 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.474 AVG Validation Loss:0.499 AVG Training Acc 80.78 % AVG Validation Acc 80.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.475 AVG Validation Loss:0.497 AVG Training Acc 80.80 % AVG Validation Acc 80.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.475 AVG Validation Loss:0.497 AVG Training Acc 80.76 % AVG Validation Acc 80.05 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.474 AVG Validation Loss:0.499 AVG Training Acc 80.79 % AVG Validation Acc 80.05 %\n",
      "Epoch:130/200 AVG Training Loss:0.474 AVG Validation Loss:0.499 AVG Training Acc 80.76 % AVG Validation Acc 80.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.475 AVG Validation Loss:0.499 AVG Training Acc 80.71 % AVG Validation Acc 80.05 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.474 AVG Validation Loss:0.499 AVG Training Acc 80.79 % AVG Validation Acc 80.05 %\n",
      "Epoch:160/200 AVG Training Loss:0.474 AVG Validation Loss:0.499 AVG Training Acc 80.85 % AVG Validation Acc 80.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.474 AVG Validation Loss:0.499 AVG Training Acc 80.70 % AVG Validation Acc 80.05 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.474 AVG Validation Loss:0.497 AVG Training Acc 80.83 % AVG Validation Acc 80.23 %\n",
      "Epoch:190/200 AVG Training Loss:0.474 AVG Validation Loss:0.498 AVG Training Acc 80.78 % AVG Validation Acc 80.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.475 AVG Validation Loss:0.498 AVG Training Acc 80.77 % AVG Validation Acc 80.14 %\n",
      "Split 187\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6513c976f750472897c96972b0e43e2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.31 % AVG Validation Acc 79.87 %\n",
      "Epoch:40/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.35 % AVG Validation Acc 79.78 %\n",
      "Epoch:50/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.50 % AVG Validation Acc 79.78 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.480 AVG Validation Loss:0.498 AVG Training Acc 80.64 % AVG Validation Acc 79.78 %\n",
      "Epoch:70/200 AVG Training Loss:0.479 AVG Validation Loss:0.501 AVG Training Acc 80.69 % AVG Validation Acc 79.69 %\n",
      "Epoch:80/200 AVG Training Loss:0.479 AVG Validation Loss:0.502 AVG Training Acc 80.58 % AVG Validation Acc 79.69 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.478 AVG Validation Loss:0.502 AVG Training Acc 80.69 % AVG Validation Acc 79.69 %\n",
      "Epoch:100/200 AVG Training Loss:0.479 AVG Validation Loss:0.502 AVG Training Acc 80.62 % AVG Validation Acc 79.69 %\n",
      "Epoch:110/200 AVG Training Loss:0.477 AVG Validation Loss:0.502 AVG Training Acc 80.64 % AVG Validation Acc 79.78 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.478 AVG Validation Loss:0.501 AVG Training Acc 80.63 % AVG Validation Acc 79.69 %\n",
      "Epoch:130/200 AVG Training Loss:0.479 AVG Validation Loss:0.501 AVG Training Acc 80.58 % AVG Validation Acc 79.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.478 AVG Validation Loss:0.502 AVG Training Acc 80.64 % AVG Validation Acc 79.69 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.478 AVG Validation Loss:0.502 AVG Training Acc 80.63 % AVG Validation Acc 79.78 %\n",
      "Epoch:160/200 AVG Training Loss:0.478 AVG Validation Loss:0.502 AVG Training Acc 80.64 % AVG Validation Acc 79.69 %\n",
      "Epoch:170/200 AVG Training Loss:0.478 AVG Validation Loss:0.501 AVG Training Acc 80.63 % AVG Validation Acc 79.78 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.478 AVG Validation Loss:0.501 AVG Training Acc 80.58 % AVG Validation Acc 79.78 %\n",
      "Epoch:190/200 AVG Training Loss:0.479 AVG Validation Loss:0.502 AVG Training Acc 80.62 % AVG Validation Acc 79.78 %\n",
      "Epoch:200/200 AVG Training Loss:0.478 AVG Validation Loss:0.502 AVG Training Acc 80.72 % AVG Validation Acc 79.78 %\n",
      "Split 188\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c90cc4accd4473f83377073dd772394",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.499 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.487 AVG Validation Loss:0.498 AVG Training Acc 80.27 % AVG Validation Acc 80.14 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.474 AVG Validation Loss:0.506 AVG Training Acc 80.56 % AVG Validation Acc 79.69 %\n",
      "Epoch:50/200 AVG Training Loss:0.469 AVG Validation Loss:0.513 AVG Training Acc 80.60 % AVG Validation Acc 79.60 %\n",
      "Epoch:60/200 AVG Training Loss:0.463 AVG Validation Loss:0.520 AVG Training Acc 80.75 % AVG Validation Acc 79.60 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.458 AVG Validation Loss:0.525 AVG Training Acc 80.83 % AVG Validation Acc 79.15 %\n",
      "Epoch:80/200 AVG Training Loss:0.456 AVG Validation Loss:0.530 AVG Training Acc 80.90 % AVG Validation Acc 78.97 %\n",
      "Epoch:90/200 AVG Training Loss:0.454 AVG Validation Loss:0.527 AVG Training Acc 81.04 % AVG Validation Acc 78.97 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.455 AVG Validation Loss:0.527 AVG Training Acc 80.99 % AVG Validation Acc 78.88 %\n",
      "Epoch:110/200 AVG Training Loss:0.454 AVG Validation Loss:0.528 AVG Training Acc 81.04 % AVG Validation Acc 78.88 %\n",
      "Epoch:120/200 AVG Training Loss:0.455 AVG Validation Loss:0.526 AVG Training Acc 81.00 % AVG Validation Acc 79.15 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.453 AVG Validation Loss:0.526 AVG Training Acc 81.01 % AVG Validation Acc 79.06 %\n",
      "Epoch:140/200 AVG Training Loss:0.454 AVG Validation Loss:0.525 AVG Training Acc 81.01 % AVG Validation Acc 79.15 %\n",
      "Epoch:150/200 AVG Training Loss:0.454 AVG Validation Loss:0.526 AVG Training Acc 81.07 % AVG Validation Acc 79.06 %\n",
      "Epoch:160/200 AVG Training Loss:0.454 AVG Validation Loss:0.525 AVG Training Acc 81.06 % AVG Validation Acc 79.15 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.456 AVG Validation Loss:0.523 AVG Training Acc 80.92 % AVG Validation Acc 79.33 %\n",
      "Epoch:180/200 AVG Training Loss:0.455 AVG Validation Loss:0.527 AVG Training Acc 81.06 % AVG Validation Acc 78.88 %\n",
      "Epoch:190/200 AVG Training Loss:0.453 AVG Validation Loss:0.529 AVG Training Acc 81.00 % AVG Validation Acc 78.97 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.455 AVG Validation Loss:0.527 AVG Training Acc 80.97 % AVG Validation Acc 79.06 %\n",
      "Split 189\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91532ae2f9a94668bc73777a5338e05a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.497 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.482 AVG Validation Loss:0.500 AVG Training Acc 80.28 % AVG Validation Acc 79.69 %\n",
      "Epoch:40/200 AVG Training Loss:0.478 AVG Validation Loss:0.503 AVG Training Acc 80.45 % AVG Validation Acc 79.51 %\n",
      "Epoch:50/200 AVG Training Loss:0.472 AVG Validation Loss:0.508 AVG Training Acc 80.49 % AVG Validation Acc 79.33 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.466 AVG Validation Loss:0.515 AVG Training Acc 80.70 % AVG Validation Acc 78.97 %\n",
      "Epoch:70/200 AVG Training Loss:0.466 AVG Validation Loss:0.516 AVG Training Acc 80.70 % AVG Validation Acc 78.97 %\n",
      "Epoch:80/200 AVG Training Loss:0.465 AVG Validation Loss:0.517 AVG Training Acc 80.74 % AVG Validation Acc 79.06 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.464 AVG Validation Loss:0.519 AVG Training Acc 80.72 % AVG Validation Acc 79.06 %\n",
      "Epoch:100/200 AVG Training Loss:0.465 AVG Validation Loss:0.517 AVG Training Acc 80.68 % AVG Validation Acc 79.15 %\n",
      "Epoch:110/200 AVG Training Loss:0.464 AVG Validation Loss:0.520 AVG Training Acc 80.75 % AVG Validation Acc 79.06 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.463 AVG Validation Loss:0.521 AVG Training Acc 80.83 % AVG Validation Acc 78.97 %\n",
      "Epoch:130/200 AVG Training Loss:0.464 AVG Validation Loss:0.518 AVG Training Acc 80.80 % AVG Validation Acc 78.97 %\n",
      "Epoch:140/200 AVG Training Loss:0.462 AVG Validation Loss:0.520 AVG Training Acc 80.78 % AVG Validation Acc 79.06 %\n",
      "Epoch:150/200 AVG Training Loss:0.464 AVG Validation Loss:0.518 AVG Training Acc 80.72 % AVG Validation Acc 79.06 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.465 AVG Validation Loss:0.518 AVG Training Acc 80.62 % AVG Validation Acc 78.97 %\n",
      "Epoch:170/200 AVG Training Loss:0.465 AVG Validation Loss:0.522 AVG Training Acc 80.91 % AVG Validation Acc 78.97 %\n",
      "Epoch:180/200 AVG Training Loss:0.463 AVG Validation Loss:0.519 AVG Training Acc 80.76 % AVG Validation Acc 78.97 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.463 AVG Validation Loss:0.522 AVG Training Acc 80.82 % AVG Validation Acc 78.97 %\n",
      "Epoch:200/200 AVG Training Loss:0.464 AVG Validation Loss:0.520 AVG Training Acc 80.83 % AVG Validation Acc 79.06 %\n",
      "Split 190\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e62872be5a86411e821454eb83533664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.498 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.494 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.23 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.484 AVG Validation Loss:0.493 AVG Training Acc 80.29 % AVG Validation Acc 80.14 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.479 AVG Validation Loss:0.501 AVG Training Acc 80.42 % AVG Validation Acc 79.96 %\n",
      "Epoch:70/200 AVG Training Loss:0.476 AVG Validation Loss:0.501 AVG Training Acc 80.62 % AVG Validation Acc 80.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.477 AVG Validation Loss:0.502 AVG Training Acc 80.63 % AVG Validation Acc 80.05 %\n",
      "Epoch:90/200 AVG Training Loss:0.477 AVG Validation Loss:0.505 AVG Training Acc 80.61 % AVG Validation Acc 79.96 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.475 AVG Validation Loss:0.505 AVG Training Acc 80.55 % AVG Validation Acc 80.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.476 AVG Validation Loss:0.505 AVG Training Acc 80.65 % AVG Validation Acc 79.96 %\n",
      "Epoch:120/200 AVG Training Loss:0.476 AVG Validation Loss:0.507 AVG Training Acc 80.74 % AVG Validation Acc 79.87 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.475 AVG Validation Loss:0.507 AVG Training Acc 80.72 % AVG Validation Acc 79.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.475 AVG Validation Loss:0.507 AVG Training Acc 80.63 % AVG Validation Acc 79.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.474 AVG Validation Loss:0.508 AVG Training Acc 80.74 % AVG Validation Acc 79.87 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.475 AVG Validation Loss:0.506 AVG Training Acc 80.63 % AVG Validation Acc 79.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.476 AVG Validation Loss:0.508 AVG Training Acc 80.66 % AVG Validation Acc 79.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.476 AVG Validation Loss:0.506 AVG Training Acc 80.63 % AVG Validation Acc 80.05 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.476 AVG Validation Loss:0.507 AVG Training Acc 80.63 % AVG Validation Acc 79.87 %\n",
      "Epoch:200/200 AVG Training Loss:0.475 AVG Validation Loss:0.509 AVG Training Acc 80.70 % AVG Validation Acc 79.87 %\n",
      "Split 191\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19f00eaa09da4c638d1b0d740a5a0563",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.09 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.500 AVG Training Acc 80.31 % AVG Validation Acc 79.89 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.47 % AVG Validation Acc 79.80 %\n",
      "Epoch:50/200 AVG Training Loss:0.477 AVG Validation Loss:0.501 AVG Training Acc 80.70 % AVG Validation Acc 79.71 %\n",
      "Epoch:60/200 AVG Training Loss:0.472 AVG Validation Loss:0.503 AVG Training Acc 80.87 % AVG Validation Acc 79.44 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.466 AVG Validation Loss:0.507 AVG Training Acc 81.18 % AVG Validation Acc 79.44 %\n",
      "Epoch:80/200 AVG Training Loss:0.467 AVG Validation Loss:0.508 AVG Training Acc 81.18 % AVG Validation Acc 79.53 %\n",
      "Epoch:90/200 AVG Training Loss:0.463 AVG Validation Loss:0.509 AVG Training Acc 81.36 % AVG Validation Acc 79.35 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.464 AVG Validation Loss:0.510 AVG Training Acc 81.20 % AVG Validation Acc 79.44 %\n",
      "Epoch:110/200 AVG Training Loss:0.466 AVG Validation Loss:0.510 AVG Training Acc 81.24 % AVG Validation Acc 79.44 %\n",
      "Epoch:120/200 AVG Training Loss:0.465 AVG Validation Loss:0.510 AVG Training Acc 81.38 % AVG Validation Acc 79.44 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.464 AVG Validation Loss:0.509 AVG Training Acc 81.28 % AVG Validation Acc 79.44 %\n",
      "Epoch:140/200 AVG Training Loss:0.463 AVG Validation Loss:0.510 AVG Training Acc 81.23 % AVG Validation Acc 79.44 %\n",
      "Epoch:150/200 AVG Training Loss:0.464 AVG Validation Loss:0.509 AVG Training Acc 81.28 % AVG Validation Acc 79.44 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.463 AVG Validation Loss:0.511 AVG Training Acc 81.24 % AVG Validation Acc 79.44 %\n",
      "Epoch:170/200 AVG Training Loss:0.463 AVG Validation Loss:0.510 AVG Training Acc 81.40 % AVG Validation Acc 79.44 %\n",
      "Epoch:180/200 AVG Training Loss:0.464 AVG Validation Loss:0.509 AVG Training Acc 81.35 % AVG Validation Acc 79.44 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.464 AVG Validation Loss:0.510 AVG Training Acc 81.20 % AVG Validation Acc 79.44 %\n",
      "Epoch:200/200 AVG Training Loss:0.463 AVG Validation Loss:0.509 AVG Training Acc 81.32 % AVG Validation Acc 79.44 %\n",
      "Split 192\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b5d2818ed54c3c9ede46842dd6f13a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.500 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.23 % AVG Validation Acc 79.98 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.22 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.28 % AVG Validation Acc 79.98 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.30 % AVG Validation Acc 79.98 %\n",
      "Epoch:70/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.28 % AVG Validation Acc 79.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.483 AVG Validation Loss:0.496 AVG Training Acc 80.35 % AVG Validation Acc 79.98 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.484 AVG Validation Loss:0.498 AVG Training Acc 80.28 % AVG Validation Acc 79.98 %\n",
      "Epoch:100/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.31 % AVG Validation Acc 79.98 %\n",
      "Epoch:110/200 AVG Training Loss:0.483 AVG Validation Loss:0.496 AVG Training Acc 80.28 % AVG Validation Acc 79.98 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.29 % AVG Validation Acc 79.98 %\n",
      "Epoch:130/200 AVG Training Loss:0.483 AVG Validation Loss:0.497 AVG Training Acc 80.31 % AVG Validation Acc 79.98 %\n",
      "Epoch:140/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.27 % AVG Validation Acc 79.98 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.483 AVG Validation Loss:0.499 AVG Training Acc 80.32 % AVG Validation Acc 79.98 %\n",
      "Epoch:160/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.34 % AVG Validation Acc 79.98 %\n",
      "Epoch:170/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.32 % AVG Validation Acc 79.98 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.483 AVG Validation Loss:0.499 AVG Training Acc 80.33 % AVG Validation Acc 79.98 %\n",
      "Epoch:190/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.32 % AVG Validation Acc 79.98 %\n",
      "Epoch:200/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.27 % AVG Validation Acc 79.98 %\n",
      "Split 193\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06e2a7d9907e48d9b93b1252b697f88f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.494 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.491 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.489 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.491 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.478 AVG Validation Loss:0.492 AVG Training Acc 80.37 % AVG Validation Acc 80.07 %\n",
      "Epoch:60/200 AVG Training Loss:0.473 AVG Validation Loss:0.494 AVG Training Acc 80.54 % AVG Validation Acc 79.98 %\n",
      "Epoch:70/200 AVG Training Loss:0.469 AVG Validation Loss:0.497 AVG Training Acc 80.67 % AVG Validation Acc 79.71 %\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.466 AVG Validation Loss:0.502 AVG Training Acc 80.73 % AVG Validation Acc 79.98 %\n",
      "Epoch:90/200 AVG Training Loss:0.465 AVG Validation Loss:0.503 AVG Training Acc 80.84 % AVG Validation Acc 79.98 %\n",
      "Epoch:100/200 AVG Training Loss:0.462 AVG Validation Loss:0.506 AVG Training Acc 80.78 % AVG Validation Acc 80.07 %\n",
      "Epoch   106: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.464 AVG Validation Loss:0.502 AVG Training Acc 80.70 % AVG Validation Acc 79.98 %\n",
      "Epoch:120/200 AVG Training Loss:0.464 AVG Validation Loss:0.504 AVG Training Acc 80.85 % AVG Validation Acc 79.98 %\n",
      "Epoch:130/200 AVG Training Loss:0.463 AVG Validation Loss:0.505 AVG Training Acc 80.81 % AVG Validation Acc 79.98 %\n",
      "Epoch   137: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.462 AVG Validation Loss:0.508 AVG Training Acc 80.77 % AVG Validation Acc 79.98 %\n",
      "Epoch:150/200 AVG Training Loss:0.461 AVG Validation Loss:0.506 AVG Training Acc 80.95 % AVG Validation Acc 79.98 %\n",
      "Epoch:160/200 AVG Training Loss:0.465 AVG Validation Loss:0.506 AVG Training Acc 80.87 % AVG Validation Acc 79.89 %\n",
      "Epoch   168: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.463 AVG Validation Loss:0.510 AVG Training Acc 80.77 % AVG Validation Acc 79.71 %\n",
      "Epoch:180/200 AVG Training Loss:0.463 AVG Validation Loss:0.503 AVG Training Acc 80.88 % AVG Validation Acc 79.89 %\n",
      "Epoch:190/200 AVG Training Loss:0.462 AVG Validation Loss:0.503 AVG Training Acc 80.75 % AVG Validation Acc 79.98 %\n",
      "Epoch   199: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.462 AVG Validation Loss:0.504 AVG Training Acc 80.91 % AVG Validation Acc 79.98 %\n",
      "Split 194\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dc1604317c84d2584995c68d5dc8b6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.491 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.491 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.488 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.490 AVG Training Acc 80.28 % AVG Validation Acc 80.16 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.478 AVG Validation Loss:0.500 AVG Training Acc 80.42 % AVG Validation Acc 79.89 %\n",
      "Epoch:70/200 AVG Training Loss:0.467 AVG Validation Loss:0.527 AVG Training Acc 80.76 % AVG Validation Acc 79.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.461 AVG Validation Loss:0.526 AVG Training Acc 81.05 % AVG Validation Acc 79.62 %\n",
      "Epoch:90/200 AVG Training Loss:0.458 AVG Validation Loss:0.530 AVG Training Acc 81.10 % AVG Validation Acc 80.16 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.452 AVG Validation Loss:0.527 AVG Training Acc 81.45 % AVG Validation Acc 79.71 %\n",
      "Epoch:110/200 AVG Training Loss:0.449 AVG Validation Loss:0.530 AVG Training Acc 81.69 % AVG Validation Acc 79.44 %\n",
      "Epoch:120/200 AVG Training Loss:0.449 AVG Validation Loss:0.537 AVG Training Acc 81.40 % AVG Validation Acc 79.44 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.447 AVG Validation Loss:0.537 AVG Training Acc 81.60 % AVG Validation Acc 79.89 %\n",
      "Epoch:140/200 AVG Training Loss:0.446 AVG Validation Loss:0.535 AVG Training Acc 81.53 % AVG Validation Acc 79.62 %\n",
      "Epoch:150/200 AVG Training Loss:0.447 AVG Validation Loss:0.539 AVG Training Acc 81.49 % AVG Validation Acc 79.62 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.447 AVG Validation Loss:0.542 AVG Training Acc 81.52 % AVG Validation Acc 79.80 %\n",
      "Epoch:170/200 AVG Training Loss:0.447 AVG Validation Loss:0.536 AVG Training Acc 81.53 % AVG Validation Acc 79.89 %\n",
      "Epoch:180/200 AVG Training Loss:0.446 AVG Validation Loss:0.537 AVG Training Acc 81.57 % AVG Validation Acc 79.71 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.448 AVG Validation Loss:0.539 AVG Training Acc 81.57 % AVG Validation Acc 79.62 %\n",
      "Epoch:200/200 AVG Training Loss:0.447 AVG Validation Loss:0.538 AVG Training Acc 81.62 % AVG Validation Acc 79.71 %\n",
      "Split 195\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bc29a29f93d4575bc855777b706ecb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.493 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.492 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.24 % AVG Validation Acc 80.07 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.480 AVG Validation Loss:0.493 AVG Training Acc 80.48 % AVG Validation Acc 79.89 %\n",
      "Epoch:50/200 AVG Training Loss:0.475 AVG Validation Loss:0.498 AVG Training Acc 80.57 % AVG Validation Acc 79.71 %\n",
      "Epoch:60/200 AVG Training Loss:0.470 AVG Validation Loss:0.501 AVG Training Acc 80.72 % AVG Validation Acc 79.71 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.466 AVG Validation Loss:0.501 AVG Training Acc 80.83 % AVG Validation Acc 79.80 %\n",
      "Epoch:80/200 AVG Training Loss:0.467 AVG Validation Loss:0.504 AVG Training Acc 80.79 % AVG Validation Acc 79.80 %\n",
      "Epoch:90/200 AVG Training Loss:0.464 AVG Validation Loss:0.503 AVG Training Acc 80.80 % AVG Validation Acc 79.89 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.466 AVG Validation Loss:0.504 AVG Training Acc 80.81 % AVG Validation Acc 79.62 %\n",
      "Epoch:110/200 AVG Training Loss:0.466 AVG Validation Loss:0.503 AVG Training Acc 80.86 % AVG Validation Acc 79.80 %\n",
      "Epoch:120/200 AVG Training Loss:0.464 AVG Validation Loss:0.505 AVG Training Acc 80.92 % AVG Validation Acc 79.80 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.465 AVG Validation Loss:0.504 AVG Training Acc 80.86 % AVG Validation Acc 79.71 %\n",
      "Epoch:140/200 AVG Training Loss:0.463 AVG Validation Loss:0.505 AVG Training Acc 80.84 % AVG Validation Acc 79.80 %\n",
      "Epoch:150/200 AVG Training Loss:0.466 AVG Validation Loss:0.502 AVG Training Acc 80.79 % AVG Validation Acc 79.71 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.465 AVG Validation Loss:0.506 AVG Training Acc 80.90 % AVG Validation Acc 79.80 %\n",
      "Epoch:170/200 AVG Training Loss:0.465 AVG Validation Loss:0.504 AVG Training Acc 80.76 % AVG Validation Acc 79.80 %\n",
      "Epoch:180/200 AVG Training Loss:0.465 AVG Validation Loss:0.504 AVG Training Acc 80.92 % AVG Validation Acc 79.71 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.464 AVG Validation Loss:0.505 AVG Training Acc 80.93 % AVG Validation Acc 79.80 %\n",
      "Epoch:200/200 AVG Training Loss:0.464 AVG Validation Loss:0.505 AVG Training Acc 80.86 % AVG Validation Acc 79.71 %\n",
      "Split 196\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f4028d7fb54af6a72c711cafee5738",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.487 AVG Validation Loss:0.498 AVG Training Acc 80.25 % AVG Validation Acc 79.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.483 AVG Validation Loss:0.502 AVG Training Acc 80.47 % AVG Validation Acc 79.78 %\n",
      "Epoch:50/200 AVG Training Loss:0.477 AVG Validation Loss:0.511 AVG Training Acc 80.71 % AVG Validation Acc 79.60 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.474 AVG Validation Loss:0.521 AVG Training Acc 80.77 % AVG Validation Acc 79.51 %\n",
      "Epoch:70/200 AVG Training Loss:0.471 AVG Validation Loss:0.525 AVG Training Acc 80.81 % AVG Validation Acc 79.51 %\n",
      "Epoch:80/200 AVG Training Loss:0.472 AVG Validation Loss:0.527 AVG Training Acc 80.82 % AVG Validation Acc 79.51 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.470 AVG Validation Loss:0.530 AVG Training Acc 80.99 % AVG Validation Acc 79.60 %\n",
      "Epoch:100/200 AVG Training Loss:0.469 AVG Validation Loss:0.530 AVG Training Acc 80.99 % AVG Validation Acc 79.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.470 AVG Validation Loss:0.530 AVG Training Acc 80.93 % AVG Validation Acc 79.51 %\n",
      "Epoch:120/200 AVG Training Loss:0.469 AVG Validation Loss:0.531 AVG Training Acc 80.94 % AVG Validation Acc 79.51 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.470 AVG Validation Loss:0.526 AVG Training Acc 80.92 % AVG Validation Acc 79.51 %\n",
      "Epoch:140/200 AVG Training Loss:0.469 AVG Validation Loss:0.530 AVG Training Acc 80.94 % AVG Validation Acc 79.60 %\n",
      "Epoch:150/200 AVG Training Loss:0.470 AVG Validation Loss:0.531 AVG Training Acc 80.87 % AVG Validation Acc 79.51 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.470 AVG Validation Loss:0.532 AVG Training Acc 80.88 % AVG Validation Acc 79.51 %\n",
      "Epoch:170/200 AVG Training Loss:0.470 AVG Validation Loss:0.533 AVG Training Acc 81.02 % AVG Validation Acc 79.51 %\n",
      "Epoch:180/200 AVG Training Loss:0.470 AVG Validation Loss:0.531 AVG Training Acc 80.81 % AVG Validation Acc 79.42 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.468 AVG Validation Loss:0.532 AVG Training Acc 80.92 % AVG Validation Acc 79.60 %\n",
      "Epoch:200/200 AVG Training Loss:0.470 AVG Validation Loss:0.531 AVG Training Acc 80.92 % AVG Validation Acc 79.51 %\n",
      "Split 197\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d75e15c656b40d0aa5203bcfbe6c1ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.10 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.477 AVG Validation Loss:0.497 AVG Training Acc 80.50 % AVG Validation Acc 79.60 %\n",
      "Epoch:50/200 AVG Training Loss:0.468 AVG Validation Loss:0.502 AVG Training Acc 80.96 % AVG Validation Acc 79.51 %\n",
      "Epoch:60/200 AVG Training Loss:0.461 AVG Validation Loss:0.508 AVG Training Acc 81.17 % AVG Validation Acc 79.33 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.456 AVG Validation Loss:0.509 AVG Training Acc 81.41 % AVG Validation Acc 79.24 %\n",
      "Epoch:80/200 AVG Training Loss:0.454 AVG Validation Loss:0.511 AVG Training Acc 81.48 % AVG Validation Acc 79.06 %\n",
      "Epoch:90/200 AVG Training Loss:0.454 AVG Validation Loss:0.513 AVG Training Acc 81.56 % AVG Validation Acc 78.79 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.450 AVG Validation Loss:0.517 AVG Training Acc 81.59 % AVG Validation Acc 78.79 %\n",
      "Epoch:110/200 AVG Training Loss:0.453 AVG Validation Loss:0.514 AVG Training Acc 81.57 % AVG Validation Acc 78.88 %\n",
      "Epoch:120/200 AVG Training Loss:0.449 AVG Validation Loss:0.517 AVG Training Acc 81.71 % AVG Validation Acc 78.79 %\n",
      "Epoch:130/200 AVG Training Loss:0.449 AVG Validation Loss:0.516 AVG Training Acc 81.72 % AVG Validation Acc 79.06 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.450 AVG Validation Loss:0.517 AVG Training Acc 81.51 % AVG Validation Acc 78.88 %\n",
      "Epoch:150/200 AVG Training Loss:0.450 AVG Validation Loss:0.521 AVG Training Acc 81.80 % AVG Validation Acc 79.06 %\n",
      "Epoch:160/200 AVG Training Loss:0.451 AVG Validation Loss:0.520 AVG Training Acc 81.71 % AVG Validation Acc 78.97 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.451 AVG Validation Loss:0.519 AVG Training Acc 81.59 % AVG Validation Acc 78.97 %\n",
      "Epoch:180/200 AVG Training Loss:0.452 AVG Validation Loss:0.516 AVG Training Acc 81.58 % AVG Validation Acc 78.97 %\n",
      "Epoch:190/200 AVG Training Loss:0.451 AVG Validation Loss:0.516 AVG Training Acc 81.59 % AVG Validation Acc 78.70 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.450 AVG Validation Loss:0.517 AVG Training Acc 81.62 % AVG Validation Acc 78.97 %\n",
      "Split 198\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc8ea930cfb64ea4b452b5db85c14b44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.34 % AVG Validation Acc 80.32 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.478 AVG Validation Loss:0.497 AVG Training Acc 80.51 % AVG Validation Acc 80.42 %\n",
      "Epoch:50/200 AVG Training Loss:0.473 AVG Validation Loss:0.498 AVG Training Acc 80.72 % AVG Validation Acc 80.78 %\n",
      "New Best Accuracy found: 80.87%\n",
      "Epoch: 53\n",
      "Epoch:60/200 AVG Training Loss:0.467 AVG Validation Loss:0.504 AVG Training Acc 80.82 % AVG Validation Acc 80.78 %\n",
      "New Best Accuracy found: 80.96%\n",
      "Epoch: 62\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.464 AVG Validation Loss:0.507 AVG Training Acc 80.85 % AVG Validation Acc 80.51 %\n",
      "Epoch:80/200 AVG Training Loss:0.464 AVG Validation Loss:0.506 AVG Training Acc 80.99 % AVG Validation Acc 80.51 %\n",
      "Epoch:90/200 AVG Training Loss:0.462 AVG Validation Loss:0.507 AVG Training Acc 80.98 % AVG Validation Acc 80.51 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.461 AVG Validation Loss:0.508 AVG Training Acc 81.00 % AVG Validation Acc 80.42 %\n",
      "Epoch:110/200 AVG Training Loss:0.461 AVG Validation Loss:0.510 AVG Training Acc 81.01 % AVG Validation Acc 80.42 %\n",
      "Epoch:120/200 AVG Training Loss:0.460 AVG Validation Loss:0.506 AVG Training Acc 81.10 % AVG Validation Acc 80.42 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.462 AVG Validation Loss:0.509 AVG Training Acc 80.96 % AVG Validation Acc 80.42 %\n",
      "Epoch:140/200 AVG Training Loss:0.462 AVG Validation Loss:0.507 AVG Training Acc 80.92 % AVG Validation Acc 80.60 %\n",
      "Epoch:150/200 AVG Training Loss:0.461 AVG Validation Loss:0.508 AVG Training Acc 80.91 % AVG Validation Acc 80.42 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.462 AVG Validation Loss:0.506 AVG Training Acc 80.85 % AVG Validation Acc 80.51 %\n",
      "Epoch:170/200 AVG Training Loss:0.460 AVG Validation Loss:0.511 AVG Training Acc 81.13 % AVG Validation Acc 80.51 %\n",
      "Epoch:180/200 AVG Training Loss:0.461 AVG Validation Loss:0.508 AVG Training Acc 80.93 % AVG Validation Acc 80.60 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.461 AVG Validation Loss:0.509 AVG Training Acc 81.00 % AVG Validation Acc 80.51 %\n",
      "Epoch:200/200 AVG Training Loss:0.461 AVG Validation Loss:0.511 AVG Training Acc 80.93 % AVG Validation Acc 80.51 %\n",
      "Split 199\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "699b91d3ce16454e983ed42ac5b48f00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.499 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.488 AVG Validation Loss:0.500 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.485 AVG Validation Loss:0.501 AVG Training Acc 80.27 % AVG Validation Acc 79.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.482 AVG Validation Loss:0.505 AVG Training Acc 80.41 % AVG Validation Acc 79.69 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.478 AVG Validation Loss:0.510 AVG Training Acc 80.49 % AVG Validation Acc 79.42 %\n",
      "Epoch:60/200 AVG Training Loss:0.478 AVG Validation Loss:0.516 AVG Training Acc 80.51 % AVG Validation Acc 79.42 %\n",
      "Epoch:70/200 AVG Training Loss:0.477 AVG Validation Loss:0.516 AVG Training Acc 80.56 % AVG Validation Acc 79.42 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.476 AVG Validation Loss:0.516 AVG Training Acc 80.58 % AVG Validation Acc 79.51 %\n",
      "Epoch:90/200 AVG Training Loss:0.476 AVG Validation Loss:0.518 AVG Training Acc 80.58 % AVG Validation Acc 79.42 %\n",
      "Epoch:100/200 AVG Training Loss:0.477 AVG Validation Loss:0.517 AVG Training Acc 80.61 % AVG Validation Acc 79.51 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.476 AVG Validation Loss:0.517 AVG Training Acc 80.62 % AVG Validation Acc 79.42 %\n",
      "Epoch:120/200 AVG Training Loss:0.476 AVG Validation Loss:0.518 AVG Training Acc 80.62 % AVG Validation Acc 79.42 %\n",
      "Epoch:130/200 AVG Training Loss:0.476 AVG Validation Loss:0.518 AVG Training Acc 80.56 % AVG Validation Acc 79.42 %\n",
      "Epoch:140/200 AVG Training Loss:0.476 AVG Validation Loss:0.518 AVG Training Acc 80.60 % AVG Validation Acc 79.42 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.476 AVG Validation Loss:0.518 AVG Training Acc 80.61 % AVG Validation Acc 79.42 %\n",
      "Epoch:160/200 AVG Training Loss:0.477 AVG Validation Loss:0.518 AVG Training Acc 80.62 % AVG Validation Acc 79.42 %\n",
      "Epoch:170/200 AVG Training Loss:0.476 AVG Validation Loss:0.518 AVG Training Acc 80.62 % AVG Validation Acc 79.42 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.476 AVG Validation Loss:0.519 AVG Training Acc 80.70 % AVG Validation Acc 79.42 %\n",
      "Epoch:190/200 AVG Training Loss:0.475 AVG Validation Loss:0.519 AVG Training Acc 80.59 % AVG Validation Acc 79.42 %\n",
      "Epoch:200/200 AVG Training Loss:0.476 AVG Validation Loss:0.519 AVG Training Acc 80.62 % AVG Validation Acc 79.42 %\n",
      "Split 200\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3b5e49cafd74da290579efc77be9070",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.10 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.21 % AVG Validation Acc 79.96 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.20 % AVG Validation Acc 79.87 %\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.491 AVG Training Acc 80.27 % AVG Validation Acc 80.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.491 AVG Training Acc 80.29 % AVG Validation Acc 79.87 %\n",
      "Epoch:70/200 AVG Training Loss:0.481 AVG Validation Loss:0.494 AVG Training Acc 80.33 % AVG Validation Acc 79.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.478 AVG Validation Loss:0.492 AVG Training Acc 80.53 % AVG Validation Acc 79.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.478 AVG Validation Loss:0.494 AVG Training Acc 80.58 % AVG Validation Acc 79.78 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.475 AVG Validation Loss:0.493 AVG Training Acc 80.47 % AVG Validation Acc 79.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.473 AVG Validation Loss:0.493 AVG Training Acc 80.61 % AVG Validation Acc 79.69 %\n",
      "Epoch:120/200 AVG Training Loss:0.473 AVG Validation Loss:0.494 AVG Training Acc 80.53 % AVG Validation Acc 79.69 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.473 AVG Validation Loss:0.492 AVG Training Acc 80.66 % AVG Validation Acc 79.69 %\n",
      "Epoch:140/200 AVG Training Loss:0.473 AVG Validation Loss:0.493 AVG Training Acc 80.54 % AVG Validation Acc 79.60 %\n",
      "Epoch:150/200 AVG Training Loss:0.473 AVG Validation Loss:0.492 AVG Training Acc 80.56 % AVG Validation Acc 79.60 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.473 AVG Validation Loss:0.495 AVG Training Acc 80.51 % AVG Validation Acc 79.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.472 AVG Validation Loss:0.495 AVG Training Acc 80.62 % AVG Validation Acc 79.60 %\n",
      "Epoch:180/200 AVG Training Loss:0.473 AVG Validation Loss:0.493 AVG Training Acc 80.56 % AVG Validation Acc 79.69 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.472 AVG Validation Loss:0.494 AVG Training Acc 80.54 % AVG Validation Acc 79.60 %\n",
      "Epoch:200/200 AVG Training Loss:0.472 AVG Validation Loss:0.495 AVG Training Acc 80.61 % AVG Validation Acc 79.60 %\n",
      "Split 201\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b2c330b0b8d4c7bb6475a11f0dc38e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.477 AVG Validation Loss:0.505 AVG Training Acc 80.49 % AVG Validation Acc 79.71 %\n",
      "Epoch:50/200 AVG Training Loss:0.470 AVG Validation Loss:0.524 AVG Training Acc 80.60 % AVG Validation Acc 79.26 %\n",
      "Epoch:60/200 AVG Training Loss:0.463 AVG Validation Loss:0.537 AVG Training Acc 80.88 % AVG Validation Acc 79.26 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.459 AVG Validation Loss:0.543 AVG Training Acc 80.90 % AVG Validation Acc 78.90 %\n",
      "Epoch:80/200 AVG Training Loss:0.456 AVG Validation Loss:0.543 AVG Training Acc 81.06 % AVG Validation Acc 78.99 %\n",
      "Epoch:90/200 AVG Training Loss:0.455 AVG Validation Loss:0.545 AVG Training Acc 81.05 % AVG Validation Acc 79.08 %\n",
      "Epoch:100/200 AVG Training Loss:0.456 AVG Validation Loss:0.547 AVG Training Acc 80.88 % AVG Validation Acc 79.08 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.455 AVG Validation Loss:0.547 AVG Training Acc 80.94 % AVG Validation Acc 79.17 %\n",
      "Epoch:120/200 AVG Training Loss:0.456 AVG Validation Loss:0.544 AVG Training Acc 80.92 % AVG Validation Acc 79.35 %\n",
      "Epoch:130/200 AVG Training Loss:0.455 AVG Validation Loss:0.546 AVG Training Acc 81.12 % AVG Validation Acc 79.17 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.454 AVG Validation Loss:0.549 AVG Training Acc 81.10 % AVG Validation Acc 79.08 %\n",
      "Epoch:150/200 AVG Training Loss:0.454 AVG Validation Loss:0.547 AVG Training Acc 81.06 % AVG Validation Acc 79.26 %\n",
      "Epoch:160/200 AVG Training Loss:0.453 AVG Validation Loss:0.543 AVG Training Acc 81.17 % AVG Validation Acc 79.17 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.456 AVG Validation Loss:0.545 AVG Training Acc 81.10 % AVG Validation Acc 79.17 %\n",
      "Epoch:180/200 AVG Training Loss:0.453 AVG Validation Loss:0.547 AVG Training Acc 81.07 % AVG Validation Acc 78.99 %\n",
      "Epoch:190/200 AVG Training Loss:0.454 AVG Validation Loss:0.543 AVG Training Acc 80.98 % AVG Validation Acc 79.17 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.454 AVG Validation Loss:0.549 AVG Training Acc 81.02 % AVG Validation Acc 79.08 %\n",
      "Split 202\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "522730c2536142cfab44a120c97b37d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.22 % AVG Validation Acc 80.16 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.481 AVG Validation Loss:0.495 AVG Training Acc 80.41 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.472 AVG Validation Loss:0.504 AVG Training Acc 80.79 % AVG Validation Acc 79.98 %\n",
      "Epoch:50/200 AVG Training Loss:0.467 AVG Validation Loss:0.511 AVG Training Acc 81.02 % AVG Validation Acc 79.89 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.462 AVG Validation Loss:0.516 AVG Training Acc 81.26 % AVG Validation Acc 80.07 %\n",
      "Epoch:70/200 AVG Training Loss:0.461 AVG Validation Loss:0.528 AVG Training Acc 81.09 % AVG Validation Acc 79.80 %\n",
      "Epoch:80/200 AVG Training Loss:0.461 AVG Validation Loss:0.522 AVG Training Acc 81.28 % AVG Validation Acc 79.71 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.461 AVG Validation Loss:0.517 AVG Training Acc 81.33 % AVG Validation Acc 79.80 %\n",
      "Epoch:100/200 AVG Training Loss:0.462 AVG Validation Loss:0.526 AVG Training Acc 81.18 % AVG Validation Acc 79.71 %\n",
      "Epoch:110/200 AVG Training Loss:0.460 AVG Validation Loss:0.525 AVG Training Acc 81.30 % AVG Validation Acc 79.80 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.459 AVG Validation Loss:0.529 AVG Training Acc 81.40 % AVG Validation Acc 79.80 %\n",
      "Epoch:130/200 AVG Training Loss:0.460 AVG Validation Loss:0.523 AVG Training Acc 81.24 % AVG Validation Acc 79.53 %\n",
      "Epoch:140/200 AVG Training Loss:0.460 AVG Validation Loss:0.524 AVG Training Acc 81.29 % AVG Validation Acc 79.98 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.461 AVG Validation Loss:0.530 AVG Training Acc 81.22 % AVG Validation Acc 79.62 %\n",
      "Epoch:160/200 AVG Training Loss:0.459 AVG Validation Loss:0.527 AVG Training Acc 81.23 % AVG Validation Acc 79.71 %\n",
      "Epoch:170/200 AVG Training Loss:0.460 AVG Validation Loss:0.514 AVG Training Acc 81.29 % AVG Validation Acc 79.62 %\n",
      "Epoch:180/200 AVG Training Loss:0.459 AVG Validation Loss:0.526 AVG Training Acc 81.28 % AVG Validation Acc 79.80 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.460 AVG Validation Loss:0.525 AVG Training Acc 81.34 % AVG Validation Acc 79.80 %\n",
      "Epoch:200/200 AVG Training Loss:0.461 AVG Validation Loss:0.532 AVG Training Acc 81.24 % AVG Validation Acc 79.53 %\n",
      "Split 203\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a922cecf04a047d691b2f1116ca9cc59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.501 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.21 % AVG Validation Acc 80.16 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.479 AVG Validation Loss:0.494 AVG Training Acc 80.38 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.468 AVG Validation Loss:0.497 AVG Training Acc 80.75 % AVG Validation Acc 80.07 %\n",
      "Epoch:70/200 AVG Training Loss:0.463 AVG Validation Loss:0.500 AVG Training Acc 80.76 % AVG Validation Acc 79.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.458 AVG Validation Loss:0.507 AVG Training Acc 81.05 % AVG Validation Acc 79.62 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.453 AVG Validation Loss:0.511 AVG Training Acc 81.15 % AVG Validation Acc 79.80 %\n",
      "Epoch:100/200 AVG Training Loss:0.453 AVG Validation Loss:0.511 AVG Training Acc 81.33 % AVG Validation Acc 80.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.452 AVG Validation Loss:0.513 AVG Training Acc 81.27 % AVG Validation Acc 79.89 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.452 AVG Validation Loss:0.517 AVG Training Acc 81.28 % AVG Validation Acc 79.98 %\n",
      "Epoch:130/200 AVG Training Loss:0.453 AVG Validation Loss:0.515 AVG Training Acc 81.26 % AVG Validation Acc 79.98 %\n",
      "Epoch:140/200 AVG Training Loss:0.454 AVG Validation Loss:0.515 AVG Training Acc 80.92 % AVG Validation Acc 79.89 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.452 AVG Validation Loss:0.515 AVG Training Acc 81.22 % AVG Validation Acc 79.98 %\n",
      "Epoch:160/200 AVG Training Loss:0.451 AVG Validation Loss:0.511 AVG Training Acc 81.29 % AVG Validation Acc 79.80 %\n",
      "Epoch:170/200 AVG Training Loss:0.452 AVG Validation Loss:0.515 AVG Training Acc 81.23 % AVG Validation Acc 79.80 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.451 AVG Validation Loss:0.517 AVG Training Acc 81.42 % AVG Validation Acc 79.89 %\n",
      "Epoch:190/200 AVG Training Loss:0.451 AVG Validation Loss:0.516 AVG Training Acc 81.17 % AVG Validation Acc 79.80 %\n",
      "Epoch:200/200 AVG Training Loss:0.451 AVG Validation Loss:0.514 AVG Training Acc 81.22 % AVG Validation Acc 79.89 %\n",
      "Split 204\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc33fd6f6fec4de8a4887196d5c3d359",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.24 % AVG Validation Acc 80.07 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.481 AVG Validation Loss:0.498 AVG Training Acc 80.33 % AVG Validation Acc 79.44 %\n",
      "Epoch:50/200 AVG Training Loss:0.478 AVG Validation Loss:0.502 AVG Training Acc 80.53 % AVG Validation Acc 79.35 %\n",
      "Epoch:60/200 AVG Training Loss:0.473 AVG Validation Loss:0.511 AVG Training Acc 80.69 % AVG Validation Acc 79.26 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.470 AVG Validation Loss:0.515 AVG Training Acc 80.83 % AVG Validation Acc 79.08 %\n",
      "Epoch:80/200 AVG Training Loss:0.469 AVG Validation Loss:0.514 AVG Training Acc 80.86 % AVG Validation Acc 79.17 %\n",
      "Epoch:90/200 AVG Training Loss:0.468 AVG Validation Loss:0.517 AVG Training Acc 81.03 % AVG Validation Acc 79.17 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.468 AVG Validation Loss:0.517 AVG Training Acc 81.00 % AVG Validation Acc 79.26 %\n",
      "Epoch:110/200 AVG Training Loss:0.469 AVG Validation Loss:0.519 AVG Training Acc 81.04 % AVG Validation Acc 79.17 %\n",
      "Epoch:120/200 AVG Training Loss:0.467 AVG Validation Loss:0.517 AVG Training Acc 80.99 % AVG Validation Acc 79.17 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.467 AVG Validation Loss:0.519 AVG Training Acc 80.94 % AVG Validation Acc 79.17 %\n",
      "Epoch:140/200 AVG Training Loss:0.467 AVG Validation Loss:0.519 AVG Training Acc 80.96 % AVG Validation Acc 79.17 %\n",
      "Epoch:150/200 AVG Training Loss:0.468 AVG Validation Loss:0.517 AVG Training Acc 80.98 % AVG Validation Acc 79.17 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.469 AVG Validation Loss:0.519 AVG Training Acc 80.91 % AVG Validation Acc 79.08 %\n",
      "Epoch:170/200 AVG Training Loss:0.469 AVG Validation Loss:0.519 AVG Training Acc 81.02 % AVG Validation Acc 79.08 %\n",
      "Epoch:180/200 AVG Training Loss:0.468 AVG Validation Loss:0.520 AVG Training Acc 80.97 % AVG Validation Acc 78.99 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.468 AVG Validation Loss:0.518 AVG Training Acc 81.01 % AVG Validation Acc 79.17 %\n",
      "Epoch:200/200 AVG Training Loss:0.468 AVG Validation Loss:0.517 AVG Training Acc 80.98 % AVG Validation Acc 79.17 %\n",
      "Split 205\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b010805c6cfc4c36b1b87aa526a68110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.491 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.31 % AVG Validation Acc 79.98 %\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.488 AVG Training Acc 80.29 % AVG Validation Acc 79.98 %\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.467 AVG Validation Loss:0.497 AVG Training Acc 80.84 % AVG Validation Acc 79.98 %\n",
      "Epoch:60/200 AVG Training Loss:0.460 AVG Validation Loss:0.504 AVG Training Acc 80.97 % AVG Validation Acc 79.62 %\n",
      "Epoch:70/200 AVG Training Loss:0.454 AVG Validation Loss:0.504 AVG Training Acc 81.22 % AVG Validation Acc 79.80 %\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.449 AVG Validation Loss:0.512 AVG Training Acc 81.47 % AVG Validation Acc 79.62 %\n",
      "Epoch:90/200 AVG Training Loss:0.447 AVG Validation Loss:0.514 AVG Training Acc 81.65 % AVG Validation Acc 79.44 %\n",
      "Epoch:100/200 AVG Training Loss:0.448 AVG Validation Loss:0.509 AVG Training Acc 81.53 % AVG Validation Acc 79.62 %\n",
      "Epoch   106: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.448 AVG Validation Loss:0.511 AVG Training Acc 81.39 % AVG Validation Acc 79.80 %\n",
      "Epoch:120/200 AVG Training Loss:0.449 AVG Validation Loss:0.512 AVG Training Acc 81.44 % AVG Validation Acc 79.62 %\n",
      "Epoch:130/200 AVG Training Loss:0.447 AVG Validation Loss:0.510 AVG Training Acc 81.42 % AVG Validation Acc 79.80 %\n",
      "Epoch   137: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.446 AVG Validation Loss:0.515 AVG Training Acc 81.72 % AVG Validation Acc 79.53 %\n",
      "Epoch:150/200 AVG Training Loss:0.447 AVG Validation Loss:0.512 AVG Training Acc 81.56 % AVG Validation Acc 79.89 %\n",
      "Epoch:160/200 AVG Training Loss:0.447 AVG Validation Loss:0.516 AVG Training Acc 81.58 % AVG Validation Acc 79.35 %\n",
      "Epoch   168: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.446 AVG Validation Loss:0.512 AVG Training Acc 81.45 % AVG Validation Acc 79.89 %\n",
      "Epoch:180/200 AVG Training Loss:0.447 AVG Validation Loss:0.512 AVG Training Acc 81.47 % AVG Validation Acc 79.80 %\n",
      "Epoch:190/200 AVG Training Loss:0.448 AVG Validation Loss:0.518 AVG Training Acc 81.51 % AVG Validation Acc 79.71 %\n",
      "Epoch   199: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.446 AVG Validation Loss:0.513 AVG Training Acc 81.46 % AVG Validation Acc 79.80 %\n",
      "Split 206\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a83f4c567fc04a0a84aabbef5dcbcdeb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.497 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.487 AVG Validation Loss:0.499 AVG Training Acc 80.29 % AVG Validation Acc 80.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.482 AVG Validation Loss:0.502 AVG Training Acc 80.54 % AVG Validation Acc 79.96 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.478 AVG Validation Loss:0.499 AVG Training Acc 80.52 % AVG Validation Acc 79.78 %\n",
      "Epoch:60/200 AVG Training Loss:0.465 AVG Validation Loss:0.517 AVG Training Acc 81.23 % AVG Validation Acc 79.60 %\n",
      "Epoch:70/200 AVG Training Loss:0.458 AVG Validation Loss:0.536 AVG Training Acc 81.52 % AVG Validation Acc 79.42 %\n",
      "Epoch:80/200 AVG Training Loss:0.452 AVG Validation Loss:0.540 AVG Training Acc 81.69 % AVG Validation Acc 79.51 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.448 AVG Validation Loss:0.545 AVG Training Acc 81.86 % AVG Validation Acc 78.88 %\n",
      "Epoch:100/200 AVG Training Loss:0.445 AVG Validation Loss:0.550 AVG Training Acc 82.09 % AVG Validation Acc 78.70 %\n",
      "Epoch:110/200 AVG Training Loss:0.447 AVG Validation Loss:0.548 AVG Training Acc 81.88 % AVG Validation Acc 79.06 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.446 AVG Validation Loss:0.547 AVG Training Acc 82.06 % AVG Validation Acc 78.97 %\n",
      "Epoch:130/200 AVG Training Loss:0.445 AVG Validation Loss:0.548 AVG Training Acc 82.04 % AVG Validation Acc 78.88 %\n",
      "Epoch:140/200 AVG Training Loss:0.444 AVG Validation Loss:0.552 AVG Training Acc 82.10 % AVG Validation Acc 78.79 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.445 AVG Validation Loss:0.550 AVG Training Acc 82.02 % AVG Validation Acc 79.06 %\n",
      "Epoch:160/200 AVG Training Loss:0.445 AVG Validation Loss:0.552 AVG Training Acc 82.13 % AVG Validation Acc 78.79 %\n",
      "Epoch:170/200 AVG Training Loss:0.445 AVG Validation Loss:0.555 AVG Training Acc 82.03 % AVG Validation Acc 78.70 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.447 AVG Validation Loss:0.549 AVG Training Acc 81.91 % AVG Validation Acc 79.06 %\n",
      "Epoch:190/200 AVG Training Loss:0.445 AVG Validation Loss:0.555 AVG Training Acc 81.92 % AVG Validation Acc 78.88 %\n",
      "Epoch:200/200 AVG Training Loss:0.444 AVG Validation Loss:0.547 AVG Training Acc 82.02 % AVG Validation Acc 78.97 %\n",
      "Split 207\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0afb37858d2945bab2e88db757e6a9b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.488 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.474 AVG Validation Loss:0.501 AVG Training Acc 80.59 % AVG Validation Acc 79.78 %\n",
      "Epoch:60/200 AVG Training Loss:0.468 AVG Validation Loss:0.506 AVG Training Acc 80.91 % AVG Validation Acc 79.69 %\n",
      "Epoch:70/200 AVG Training Loss:0.463 AVG Validation Loss:0.513 AVG Training Acc 81.04 % AVG Validation Acc 79.51 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.460 AVG Validation Loss:0.523 AVG Training Acc 81.09 % AVG Validation Acc 79.24 %\n",
      "Epoch:90/200 AVG Training Loss:0.457 AVG Validation Loss:0.523 AVG Training Acc 81.35 % AVG Validation Acc 79.06 %\n",
      "Epoch:100/200 AVG Training Loss:0.455 AVG Validation Loss:0.526 AVG Training Acc 81.25 % AVG Validation Acc 79.15 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.455 AVG Validation Loss:0.526 AVG Training Acc 81.34 % AVG Validation Acc 79.24 %\n",
      "Epoch:120/200 AVG Training Loss:0.456 AVG Validation Loss:0.527 AVG Training Acc 81.29 % AVG Validation Acc 78.97 %\n",
      "Epoch:130/200 AVG Training Loss:0.454 AVG Validation Loss:0.529 AVG Training Acc 81.31 % AVG Validation Acc 79.15 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.454 AVG Validation Loss:0.527 AVG Training Acc 81.38 % AVG Validation Acc 79.33 %\n",
      "Epoch:150/200 AVG Training Loss:0.455 AVG Validation Loss:0.530 AVG Training Acc 81.33 % AVG Validation Acc 78.97 %\n",
      "Epoch:160/200 AVG Training Loss:0.454 AVG Validation Loss:0.528 AVG Training Acc 81.30 % AVG Validation Acc 79.06 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.452 AVG Validation Loss:0.527 AVG Training Acc 81.62 % AVG Validation Acc 79.06 %\n",
      "Epoch:180/200 AVG Training Loss:0.453 AVG Validation Loss:0.529 AVG Training Acc 81.47 % AVG Validation Acc 79.24 %\n",
      "Epoch:190/200 AVG Training Loss:0.455 AVG Validation Loss:0.527 AVG Training Acc 81.28 % AVG Validation Acc 79.06 %\n",
      "Epoch:200/200 AVG Training Loss:0.454 AVG Validation Loss:0.529 AVG Training Acc 81.43 % AVG Validation Acc 79.42 %\n",
      "Epoch   200: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Split 208\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1ac0c6319dd441f9967702004430b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.24 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.491 AVG Training Acc 80.31 % AVG Validation Acc 80.23 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.482 AVG Validation Loss:0.494 AVG Training Acc 80.27 % AVG Validation Acc 80.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.472 AVG Validation Loss:0.495 AVG Training Acc 80.70 % AVG Validation Acc 79.78 %\n",
      "Epoch:70/200 AVG Training Loss:0.466 AVG Validation Loss:0.501 AVG Training Acc 80.78 % AVG Validation Acc 79.87 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.462 AVG Validation Loss:0.504 AVG Training Acc 80.99 % AVG Validation Acc 79.24 %\n",
      "Epoch:90/200 AVG Training Loss:0.459 AVG Validation Loss:0.507 AVG Training Acc 81.20 % AVG Validation Acc 79.24 %\n",
      "Epoch:100/200 AVG Training Loss:0.458 AVG Validation Loss:0.511 AVG Training Acc 81.07 % AVG Validation Acc 79.42 %\n",
      "Epoch:110/200 AVG Training Loss:0.457 AVG Validation Loss:0.508 AVG Training Acc 81.29 % AVG Validation Acc 79.78 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.458 AVG Validation Loss:0.508 AVG Training Acc 81.12 % AVG Validation Acc 79.51 %\n",
      "Epoch:130/200 AVG Training Loss:0.456 AVG Validation Loss:0.511 AVG Training Acc 80.98 % AVG Validation Acc 79.51 %\n",
      "Epoch:140/200 AVG Training Loss:0.455 AVG Validation Loss:0.510 AVG Training Acc 81.41 % AVG Validation Acc 79.33 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.458 AVG Validation Loss:0.512 AVG Training Acc 81.22 % AVG Validation Acc 79.42 %\n",
      "Epoch:160/200 AVG Training Loss:0.457 AVG Validation Loss:0.508 AVG Training Acc 81.34 % AVG Validation Acc 79.60 %\n",
      "Epoch:170/200 AVG Training Loss:0.455 AVG Validation Loss:0.508 AVG Training Acc 81.34 % AVG Validation Acc 79.69 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.459 AVG Validation Loss:0.509 AVG Training Acc 81.18 % AVG Validation Acc 79.33 %\n",
      "Epoch:190/200 AVG Training Loss:0.455 AVG Validation Loss:0.509 AVG Training Acc 81.20 % AVG Validation Acc 79.33 %\n",
      "Epoch:200/200 AVG Training Loss:0.455 AVG Validation Loss:0.507 AVG Training Acc 81.37 % AVG Validation Acc 79.33 %\n",
      "Split 209\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9f72c98cc644cd2983cd0918693d477",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.23 % AVG Validation Acc 79.87 %\n",
      "Epoch:40/200 AVG Training Loss:0.483 AVG Validation Loss:0.502 AVG Training Acc 80.30 % AVG Validation Acc 79.78 %\n",
      "Epoch:50/200 AVG Training Loss:0.477 AVG Validation Loss:0.504 AVG Training Acc 80.55 % AVG Validation Acc 79.87 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.473 AVG Validation Loss:0.513 AVG Training Acc 80.76 % AVG Validation Acc 79.69 %\n",
      "Epoch:70/200 AVG Training Loss:0.471 AVG Validation Loss:0.519 AVG Training Acc 80.86 % AVG Validation Acc 79.78 %\n",
      "Epoch:80/200 AVG Training Loss:0.470 AVG Validation Loss:0.521 AVG Training Acc 80.91 % AVG Validation Acc 79.78 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.469 AVG Validation Loss:0.522 AVG Training Acc 80.92 % AVG Validation Acc 79.60 %\n",
      "Epoch:100/200 AVG Training Loss:0.470 AVG Validation Loss:0.520 AVG Training Acc 80.86 % AVG Validation Acc 79.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.470 AVG Validation Loss:0.520 AVG Training Acc 80.92 % AVG Validation Acc 79.69 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.468 AVG Validation Loss:0.522 AVG Training Acc 80.96 % AVG Validation Acc 79.78 %\n",
      "Epoch:130/200 AVG Training Loss:0.470 AVG Validation Loss:0.521 AVG Training Acc 80.92 % AVG Validation Acc 79.60 %\n",
      "Epoch:140/200 AVG Training Loss:0.470 AVG Validation Loss:0.520 AVG Training Acc 80.91 % AVG Validation Acc 79.69 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.469 AVG Validation Loss:0.520 AVG Training Acc 80.94 % AVG Validation Acc 79.69 %\n",
      "Epoch:160/200 AVG Training Loss:0.469 AVG Validation Loss:0.520 AVG Training Acc 80.91 % AVG Validation Acc 79.60 %\n",
      "Epoch:170/200 AVG Training Loss:0.469 AVG Validation Loss:0.521 AVG Training Acc 80.91 % AVG Validation Acc 79.60 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.469 AVG Validation Loss:0.522 AVG Training Acc 80.86 % AVG Validation Acc 79.69 %\n",
      "Epoch:190/200 AVG Training Loss:0.470 AVG Validation Loss:0.522 AVG Training Acc 80.81 % AVG Validation Acc 79.60 %\n",
      "Epoch:200/200 AVG Training Loss:0.470 AVG Validation Loss:0.522 AVG Training Acc 80.88 % AVG Validation Acc 79.69 %\n",
      "Split 210\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6a9c9f5037548e194ad5abb56c6516d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.490 AVG Validation Loss:0.499 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.481 AVG Validation Loss:0.502 AVG Training Acc 80.25 % AVG Validation Acc 79.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.471 AVG Validation Loss:0.511 AVG Training Acc 80.67 % AVG Validation Acc 79.51 %\n",
      "Epoch:50/200 AVG Training Loss:0.464 AVG Validation Loss:0.518 AVG Training Acc 80.93 % AVG Validation Acc 79.15 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.454 AVG Validation Loss:0.529 AVG Training Acc 81.38 % AVG Validation Acc 79.33 %\n",
      "Epoch:70/200 AVG Training Loss:0.451 AVG Validation Loss:0.531 AVG Training Acc 81.48 % AVG Validation Acc 79.06 %\n",
      "Epoch:80/200 AVG Training Loss:0.451 AVG Validation Loss:0.537 AVG Training Acc 81.51 % AVG Validation Acc 78.70 %\n",
      "Epoch:90/200 AVG Training Loss:0.450 AVG Validation Loss:0.538 AVG Training Acc 81.68 % AVG Validation Acc 78.70 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.449 AVG Validation Loss:0.538 AVG Training Acc 81.65 % AVG Validation Acc 78.79 %\n",
      "Epoch:110/200 AVG Training Loss:0.450 AVG Validation Loss:0.539 AVG Training Acc 81.60 % AVG Validation Acc 78.34 %\n",
      "Epoch:120/200 AVG Training Loss:0.450 AVG Validation Loss:0.540 AVG Training Acc 81.50 % AVG Validation Acc 78.16 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.447 AVG Validation Loss:0.538 AVG Training Acc 81.75 % AVG Validation Acc 78.61 %\n",
      "Epoch:140/200 AVG Training Loss:0.447 AVG Validation Loss:0.538 AVG Training Acc 81.58 % AVG Validation Acc 78.79 %\n",
      "Epoch:150/200 AVG Training Loss:0.448 AVG Validation Loss:0.542 AVG Training Acc 81.73 % AVG Validation Acc 78.34 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.447 AVG Validation Loss:0.540 AVG Training Acc 81.74 % AVG Validation Acc 78.61 %\n",
      "Epoch:170/200 AVG Training Loss:0.447 AVG Validation Loss:0.539 AVG Training Acc 81.67 % AVG Validation Acc 78.52 %\n",
      "Epoch:180/200 AVG Training Loss:0.448 AVG Validation Loss:0.539 AVG Training Acc 81.77 % AVG Validation Acc 78.79 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.448 AVG Validation Loss:0.539 AVG Training Acc 81.75 % AVG Validation Acc 78.25 %\n",
      "Epoch:200/200 AVG Training Loss:0.448 AVG Validation Loss:0.539 AVG Training Acc 81.58 % AVG Validation Acc 78.43 %\n",
      "Split 211\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec01ec50408d4520940bf5d8bcdc83fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.20 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.24 % AVG Validation Acc 80.07 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.479 AVG Validation Loss:0.494 AVG Training Acc 80.33 % AVG Validation Acc 80.07 %\n",
      "Epoch:60/200 AVG Training Loss:0.467 AVG Validation Loss:0.501 AVG Training Acc 80.53 % AVG Validation Acc 79.98 %\n",
      "Epoch:70/200 AVG Training Loss:0.462 AVG Validation Loss:0.506 AVG Training Acc 80.68 % AVG Validation Acc 79.71 %\n",
      "Epoch:80/200 AVG Training Loss:0.456 AVG Validation Loss:0.508 AVG Training Acc 80.88 % AVG Validation Acc 79.71 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.454 AVG Validation Loss:0.507 AVG Training Acc 81.01 % AVG Validation Acc 79.80 %\n",
      "Epoch:100/200 AVG Training Loss:0.453 AVG Validation Loss:0.512 AVG Training Acc 80.85 % AVG Validation Acc 79.62 %\n",
      "Epoch:110/200 AVG Training Loss:0.453 AVG Validation Loss:0.509 AVG Training Acc 81.04 % AVG Validation Acc 79.62 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.452 AVG Validation Loss:0.503 AVG Training Acc 81.09 % AVG Validation Acc 79.71 %\n",
      "Epoch:130/200 AVG Training Loss:0.452 AVG Validation Loss:0.515 AVG Training Acc 81.02 % AVG Validation Acc 79.80 %\n",
      "Epoch:140/200 AVG Training Loss:0.452 AVG Validation Loss:0.506 AVG Training Acc 80.95 % AVG Validation Acc 79.44 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.452 AVG Validation Loss:0.505 AVG Training Acc 81.05 % AVG Validation Acc 79.44 %\n",
      "Epoch:160/200 AVG Training Loss:0.453 AVG Validation Loss:0.508 AVG Training Acc 80.94 % AVG Validation Acc 79.53 %\n",
      "Epoch:170/200 AVG Training Loss:0.454 AVG Validation Loss:0.507 AVG Training Acc 81.08 % AVG Validation Acc 79.71 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.451 AVG Validation Loss:0.506 AVG Training Acc 81.13 % AVG Validation Acc 79.53 %\n",
      "Epoch:190/200 AVG Training Loss:0.453 AVG Validation Loss:0.513 AVG Training Acc 81.08 % AVG Validation Acc 79.53 %\n",
      "Epoch:200/200 AVG Training Loss:0.452 AVG Validation Loss:0.515 AVG Training Acc 81.07 % AVG Validation Acc 79.44 %\n",
      "Split 212\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec7cf7853cc04d1fba0b1debbcc88b6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.492 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.490 AVG Training Acc 80.18 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.482 AVG Validation Loss:0.487 AVG Training Acc 80.21 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.477 AVG Validation Loss:0.494 AVG Training Acc 80.40 % AVG Validation Acc 80.25 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.484 AVG Validation Loss:0.489 AVG Training Acc 80.44 % AVG Validation Acc 80.25 %\n",
      "Epoch:70/200 AVG Training Loss:0.476 AVG Validation Loss:0.495 AVG Training Acc 80.73 % AVG Validation Acc 80.34 %\n",
      "Epoch:80/200 AVG Training Loss:0.467 AVG Validation Loss:0.510 AVG Training Acc 81.09 % AVG Validation Acc 80.16 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.462 AVG Validation Loss:0.509 AVG Training Acc 81.09 % AVG Validation Acc 79.98 %\n",
      "Epoch:100/200 AVG Training Loss:0.461 AVG Validation Loss:0.511 AVG Training Acc 81.11 % AVG Validation Acc 79.80 %\n",
      "Epoch:110/200 AVG Training Loss:0.461 AVG Validation Loss:0.519 AVG Training Acc 81.10 % AVG Validation Acc 79.89 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.458 AVG Validation Loss:0.516 AVG Training Acc 81.28 % AVG Validation Acc 79.80 %\n",
      "Epoch:130/200 AVG Training Loss:0.459 AVG Validation Loss:0.514 AVG Training Acc 81.21 % AVG Validation Acc 79.62 %\n",
      "Epoch:140/200 AVG Training Loss:0.458 AVG Validation Loss:0.512 AVG Training Acc 81.28 % AVG Validation Acc 79.89 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.458 AVG Validation Loss:0.520 AVG Training Acc 81.17 % AVG Validation Acc 79.89 %\n",
      "Epoch:160/200 AVG Training Loss:0.458 AVG Validation Loss:0.516 AVG Training Acc 81.31 % AVG Validation Acc 79.71 %\n",
      "Epoch:170/200 AVG Training Loss:0.459 AVG Validation Loss:0.511 AVG Training Acc 81.34 % AVG Validation Acc 79.98 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.459 AVG Validation Loss:0.515 AVG Training Acc 81.19 % AVG Validation Acc 80.07 %\n",
      "Epoch:190/200 AVG Training Loss:0.459 AVG Validation Loss:0.516 AVG Training Acc 81.16 % AVG Validation Acc 79.71 %\n",
      "Epoch:200/200 AVG Training Loss:0.458 AVG Validation Loss:0.514 AVG Training Acc 81.34 % AVG Validation Acc 80.07 %\n",
      "Split 213\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0240a8aedc124331a287fea5c9cc2d52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.18 % AVG Validation Acc 80.16 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.18 % AVG Validation Acc 79.98 %\n",
      "Epoch:40/200 AVG Training Loss:0.477 AVG Validation Loss:0.503 AVG Training Acc 80.34 % AVG Validation Acc 79.89 %\n",
      "Epoch:50/200 AVG Training Loss:0.471 AVG Validation Loss:0.513 AVG Training Acc 80.45 % AVG Validation Acc 79.17 %\n",
      "Epoch:60/200 AVG Training Loss:0.465 AVG Validation Loss:0.533 AVG Training Acc 80.75 % AVG Validation Acc 79.08 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.464 AVG Validation Loss:0.532 AVG Training Acc 80.73 % AVG Validation Acc 79.17 %\n",
      "Epoch:80/200 AVG Training Loss:0.461 AVG Validation Loss:0.534 AVG Training Acc 80.80 % AVG Validation Acc 79.08 %\n",
      "Epoch:90/200 AVG Training Loss:0.461 AVG Validation Loss:0.537 AVG Training Acc 80.71 % AVG Validation Acc 78.99 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.460 AVG Validation Loss:0.538 AVG Training Acc 81.01 % AVG Validation Acc 79.08 %\n",
      "Epoch:110/200 AVG Training Loss:0.460 AVG Validation Loss:0.534 AVG Training Acc 80.81 % AVG Validation Acc 79.08 %\n",
      "Epoch:120/200 AVG Training Loss:0.460 AVG Validation Loss:0.536 AVG Training Acc 81.00 % AVG Validation Acc 79.08 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.460 AVG Validation Loss:0.537 AVG Training Acc 80.91 % AVG Validation Acc 79.17 %\n",
      "Epoch:140/200 AVG Training Loss:0.459 AVG Validation Loss:0.540 AVG Training Acc 80.92 % AVG Validation Acc 78.99 %\n",
      "Epoch:150/200 AVG Training Loss:0.460 AVG Validation Loss:0.537 AVG Training Acc 80.84 % AVG Validation Acc 78.99 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.459 AVG Validation Loss:0.538 AVG Training Acc 80.91 % AVG Validation Acc 78.99 %\n",
      "Epoch:170/200 AVG Training Loss:0.460 AVG Validation Loss:0.539 AVG Training Acc 80.93 % AVG Validation Acc 78.99 %\n",
      "Epoch:180/200 AVG Training Loss:0.460 AVG Validation Loss:0.540 AVG Training Acc 80.89 % AVG Validation Acc 78.99 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.460 AVG Validation Loss:0.537 AVG Training Acc 80.93 % AVG Validation Acc 79.08 %\n",
      "Epoch:200/200 AVG Training Loss:0.460 AVG Validation Loss:0.538 AVG Training Acc 80.94 % AVG Validation Acc 79.08 %\n",
      "Split 214\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "194842a3dfc444a1b068183eb09841a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.31 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.502 AVG Training Acc 80.32 % AVG Validation Acc 79.89 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.469 AVG Validation Loss:0.509 AVG Training Acc 80.96 % AVG Validation Acc 79.53 %\n",
      "Epoch:60/200 AVG Training Loss:0.460 AVG Validation Loss:0.518 AVG Training Acc 81.12 % AVG Validation Acc 78.99 %\n",
      "Epoch:70/200 AVG Training Loss:0.456 AVG Validation Loss:0.528 AVG Training Acc 81.30 % AVG Validation Acc 78.90 %\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.450 AVG Validation Loss:0.530 AVG Training Acc 81.54 % AVG Validation Acc 78.63 %\n",
      "Epoch:90/200 AVG Training Loss:0.447 AVG Validation Loss:0.529 AVG Training Acc 81.75 % AVG Validation Acc 78.63 %\n",
      "Epoch:100/200 AVG Training Loss:0.448 AVG Validation Loss:0.537 AVG Training Acc 81.52 % AVG Validation Acc 78.54 %\n",
      "Epoch   104: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.447 AVG Validation Loss:0.534 AVG Training Acc 81.50 % AVG Validation Acc 78.45 %\n",
      "Epoch:120/200 AVG Training Loss:0.445 AVG Validation Loss:0.534 AVG Training Acc 81.63 % AVG Validation Acc 78.45 %\n",
      "Epoch:130/200 AVG Training Loss:0.449 AVG Validation Loss:0.535 AVG Training Acc 81.63 % AVG Validation Acc 78.36 %\n",
      "Epoch   135: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.447 AVG Validation Loss:0.538 AVG Training Acc 81.68 % AVG Validation Acc 78.36 %\n",
      "Epoch:150/200 AVG Training Loss:0.447 AVG Validation Loss:0.535 AVG Training Acc 81.70 % AVG Validation Acc 78.27 %\n",
      "Epoch:160/200 AVG Training Loss:0.446 AVG Validation Loss:0.535 AVG Training Acc 81.68 % AVG Validation Acc 78.63 %\n",
      "Epoch   166: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.445 AVG Validation Loss:0.538 AVG Training Acc 81.78 % AVG Validation Acc 78.36 %\n",
      "Epoch:180/200 AVG Training Loss:0.447 AVG Validation Loss:0.536 AVG Training Acc 81.64 % AVG Validation Acc 78.18 %\n",
      "Epoch:190/200 AVG Training Loss:0.447 AVG Validation Loss:0.539 AVG Training Acc 81.69 % AVG Validation Acc 78.18 %\n",
      "Epoch   197: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.445 AVG Validation Loss:0.537 AVG Training Acc 81.95 % AVG Validation Acc 78.45 %\n",
      "Split 215\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a75bfc63e8c34387971a47579abef248",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.26 % AVG Validation Acc 80.16 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.482 AVG Validation Loss:0.494 AVG Training Acc 80.47 % AVG Validation Acc 79.80 %\n",
      "Epoch:50/200 AVG Training Loss:0.477 AVG Validation Loss:0.500 AVG Training Acc 80.66 % AVG Validation Acc 79.89 %\n",
      "Epoch:60/200 AVG Training Loss:0.472 AVG Validation Loss:0.510 AVG Training Acc 80.76 % AVG Validation Acc 79.71 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.468 AVG Validation Loss:0.511 AVG Training Acc 80.90 % AVG Validation Acc 79.62 %\n",
      "Epoch:80/200 AVG Training Loss:0.465 AVG Validation Loss:0.513 AVG Training Acc 81.12 % AVG Validation Acc 79.71 %\n",
      "Epoch:90/200 AVG Training Loss:0.466 AVG Validation Loss:0.517 AVG Training Acc 81.10 % AVG Validation Acc 79.44 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.465 AVG Validation Loss:0.518 AVG Training Acc 81.09 % AVG Validation Acc 79.53 %\n",
      "Epoch:110/200 AVG Training Loss:0.465 AVG Validation Loss:0.521 AVG Training Acc 81.02 % AVG Validation Acc 79.53 %\n",
      "Epoch:120/200 AVG Training Loss:0.466 AVG Validation Loss:0.519 AVG Training Acc 81.15 % AVG Validation Acc 79.35 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.464 AVG Validation Loss:0.524 AVG Training Acc 81.28 % AVG Validation Acc 79.44 %\n",
      "Epoch:140/200 AVG Training Loss:0.466 AVG Validation Loss:0.524 AVG Training Acc 81.12 % AVG Validation Acc 79.35 %\n",
      "Epoch:150/200 AVG Training Loss:0.463 AVG Validation Loss:0.521 AVG Training Acc 81.21 % AVG Validation Acc 79.53 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.465 AVG Validation Loss:0.520 AVG Training Acc 81.08 % AVG Validation Acc 79.53 %\n",
      "Epoch:170/200 AVG Training Loss:0.463 AVG Validation Loss:0.520 AVG Training Acc 81.15 % AVG Validation Acc 79.62 %\n",
      "Epoch:180/200 AVG Training Loss:0.464 AVG Validation Loss:0.518 AVG Training Acc 81.13 % AVG Validation Acc 79.53 %\n",
      "Epoch:190/200 AVG Training Loss:0.462 AVG Validation Loss:0.520 AVG Training Acc 81.15 % AVG Validation Acc 79.44 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.464 AVG Validation Loss:0.519 AVG Training Acc 81.21 % AVG Validation Acc 79.53 %\n",
      "Split 216\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4566c5bb783e42c4b29dba5965943007",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.08 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.496 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.482 AVG Validation Loss:0.498 AVG Training Acc 80.33 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.476 AVG Validation Loss:0.500 AVG Training Acc 80.57 % AVG Validation Acc 79.78 %\n",
      "Epoch:60/200 AVG Training Loss:0.473 AVG Validation Loss:0.505 AVG Training Acc 80.79 % AVG Validation Acc 79.60 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.469 AVG Validation Loss:0.507 AVG Training Acc 80.83 % AVG Validation Acc 79.51 %\n",
      "Epoch:80/200 AVG Training Loss:0.468 AVG Validation Loss:0.509 AVG Training Acc 81.01 % AVG Validation Acc 79.33 %\n",
      "Epoch:90/200 AVG Training Loss:0.467 AVG Validation Loss:0.512 AVG Training Acc 81.00 % AVG Validation Acc 79.42 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.468 AVG Validation Loss:0.513 AVG Training Acc 81.06 % AVG Validation Acc 79.33 %\n",
      "Epoch:110/200 AVG Training Loss:0.467 AVG Validation Loss:0.512 AVG Training Acc 80.99 % AVG Validation Acc 79.15 %\n",
      "Epoch:120/200 AVG Training Loss:0.468 AVG Validation Loss:0.512 AVG Training Acc 80.96 % AVG Validation Acc 79.15 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.467 AVG Validation Loss:0.513 AVG Training Acc 80.97 % AVG Validation Acc 79.24 %\n",
      "Epoch:140/200 AVG Training Loss:0.467 AVG Validation Loss:0.512 AVG Training Acc 81.02 % AVG Validation Acc 79.33 %\n",
      "Epoch:150/200 AVG Training Loss:0.468 AVG Validation Loss:0.512 AVG Training Acc 81.00 % AVG Validation Acc 79.15 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.467 AVG Validation Loss:0.512 AVG Training Acc 80.95 % AVG Validation Acc 79.15 %\n",
      "Epoch:170/200 AVG Training Loss:0.468 AVG Validation Loss:0.513 AVG Training Acc 80.98 % AVG Validation Acc 79.24 %\n",
      "Epoch:180/200 AVG Training Loss:0.467 AVG Validation Loss:0.514 AVG Training Acc 81.02 % AVG Validation Acc 79.24 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.467 AVG Validation Loss:0.513 AVG Training Acc 81.03 % AVG Validation Acc 79.42 %\n",
      "Epoch:200/200 AVG Training Loss:0.467 AVG Validation Loss:0.511 AVG Training Acc 81.02 % AVG Validation Acc 79.15 %\n",
      "Split 217\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42a6f81d0a5b4bdeadbe1127fd1f59d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.501 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.498 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.498 AVG Training Acc 80.24 % AVG Validation Acc 80.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.27 % AVG Validation Acc 80.14 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.475 AVG Validation Loss:0.501 AVG Training Acc 80.55 % AVG Validation Acc 79.87 %\n",
      "Epoch:70/200 AVG Training Loss:0.469 AVG Validation Loss:0.512 AVG Training Acc 80.80 % AVG Validation Acc 79.06 %\n",
      "Epoch:80/200 AVG Training Loss:0.464 AVG Validation Loss:0.518 AVG Training Acc 81.06 % AVG Validation Acc 78.97 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.462 AVG Validation Loss:0.521 AVG Training Acc 81.11 % AVG Validation Acc 78.70 %\n",
      "Epoch:100/200 AVG Training Loss:0.460 AVG Validation Loss:0.521 AVG Training Acc 81.27 % AVG Validation Acc 78.88 %\n",
      "Epoch:110/200 AVG Training Loss:0.460 AVG Validation Loss:0.521 AVG Training Acc 81.28 % AVG Validation Acc 78.97 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.461 AVG Validation Loss:0.525 AVG Training Acc 81.23 % AVG Validation Acc 78.97 %\n",
      "Epoch:130/200 AVG Training Loss:0.458 AVG Validation Loss:0.521 AVG Training Acc 81.28 % AVG Validation Acc 79.06 %\n",
      "Epoch:140/200 AVG Training Loss:0.459 AVG Validation Loss:0.524 AVG Training Acc 81.25 % AVG Validation Acc 78.88 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.459 AVG Validation Loss:0.523 AVG Training Acc 81.35 % AVG Validation Acc 78.97 %\n",
      "Epoch:160/200 AVG Training Loss:0.458 AVG Validation Loss:0.525 AVG Training Acc 81.43 % AVG Validation Acc 78.97 %\n",
      "Epoch:170/200 AVG Training Loss:0.459 AVG Validation Loss:0.523 AVG Training Acc 81.17 % AVG Validation Acc 79.06 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.460 AVG Validation Loss:0.523 AVG Training Acc 81.20 % AVG Validation Acc 78.97 %\n",
      "Epoch:190/200 AVG Training Loss:0.458 AVG Validation Loss:0.521 AVG Training Acc 81.24 % AVG Validation Acc 78.79 %\n",
      "Epoch:200/200 AVG Training Loss:0.461 AVG Validation Loss:0.520 AVG Training Acc 81.16 % AVG Validation Acc 79.06 %\n",
      "Split 218\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e13d74c7979444eb9fca4bd62bae4317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.497 AVG Training Acc 80.17 % AVG Validation Acc 80.05 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.481 AVG Validation Loss:0.498 AVG Training Acc 80.31 % AVG Validation Acc 79.96 %\n",
      "Epoch:50/200 AVG Training Loss:0.475 AVG Validation Loss:0.506 AVG Training Acc 80.48 % AVG Validation Acc 79.96 %\n",
      "Epoch:60/200 AVG Training Loss:0.465 AVG Validation Loss:0.515 AVG Training Acc 81.02 % AVG Validation Acc 79.60 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.457 AVG Validation Loss:0.521 AVG Training Acc 81.23 % AVG Validation Acc 79.42 %\n",
      "Epoch:80/200 AVG Training Loss:0.454 AVG Validation Loss:0.527 AVG Training Acc 81.32 % AVG Validation Acc 79.33 %\n",
      "Epoch:90/200 AVG Training Loss:0.455 AVG Validation Loss:0.530 AVG Training Acc 81.23 % AVG Validation Acc 79.24 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.452 AVG Validation Loss:0.528 AVG Training Acc 81.26 % AVG Validation Acc 79.33 %\n",
      "Epoch:110/200 AVG Training Loss:0.450 AVG Validation Loss:0.530 AVG Training Acc 81.51 % AVG Validation Acc 79.24 %\n",
      "Epoch:120/200 AVG Training Loss:0.450 AVG Validation Loss:0.530 AVG Training Acc 81.64 % AVG Validation Acc 79.06 %\n",
      "Epoch:130/200 AVG Training Loss:0.452 AVG Validation Loss:0.530 AVG Training Acc 81.50 % AVG Validation Acc 79.24 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.454 AVG Validation Loss:0.532 AVG Training Acc 81.32 % AVG Validation Acc 79.24 %\n",
      "Epoch:150/200 AVG Training Loss:0.451 AVG Validation Loss:0.533 AVG Training Acc 81.46 % AVG Validation Acc 79.15 %\n",
      "Epoch:160/200 AVG Training Loss:0.450 AVG Validation Loss:0.533 AVG Training Acc 81.55 % AVG Validation Acc 79.06 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.451 AVG Validation Loss:0.529 AVG Training Acc 81.43 % AVG Validation Acc 79.15 %\n",
      "Epoch:180/200 AVG Training Loss:0.451 AVG Validation Loss:0.531 AVG Training Acc 81.57 % AVG Validation Acc 79.24 %\n",
      "Epoch:190/200 AVG Training Loss:0.451 AVG Validation Loss:0.531 AVG Training Acc 81.52 % AVG Validation Acc 79.15 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.450 AVG Validation Loss:0.532 AVG Training Acc 81.36 % AVG Validation Acc 79.15 %\n",
      "Split 219\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03756260986e4404af4a737e2093f795",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.10 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.499 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.485 AVG Validation Loss:0.491 AVG Training Acc 80.37 % AVG Validation Acc 79.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.481 AVG Validation Loss:0.493 AVG Training Acc 80.37 % AVG Validation Acc 80.23 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.475 AVG Validation Loss:0.493 AVG Training Acc 80.62 % AVG Validation Acc 79.87 %\n",
      "Epoch:100/200 AVG Training Loss:0.476 AVG Validation Loss:0.493 AVG Training Acc 80.55 % AVG Validation Acc 79.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.474 AVG Validation Loss:0.495 AVG Training Acc 80.51 % AVG Validation Acc 79.60 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.475 AVG Validation Loss:0.494 AVG Training Acc 80.60 % AVG Validation Acc 79.51 %\n",
      "Epoch:130/200 AVG Training Loss:0.474 AVG Validation Loss:0.494 AVG Training Acc 80.58 % AVG Validation Acc 79.42 %\n",
      "Epoch:140/200 AVG Training Loss:0.474 AVG Validation Loss:0.494 AVG Training Acc 80.61 % AVG Validation Acc 79.51 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.473 AVG Validation Loss:0.493 AVG Training Acc 80.59 % AVG Validation Acc 79.42 %\n",
      "Epoch:160/200 AVG Training Loss:0.474 AVG Validation Loss:0.494 AVG Training Acc 80.71 % AVG Validation Acc 79.51 %\n",
      "Epoch:170/200 AVG Training Loss:0.473 AVG Validation Loss:0.493 AVG Training Acc 80.60 % AVG Validation Acc 79.51 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.473 AVG Validation Loss:0.494 AVG Training Acc 80.53 % AVG Validation Acc 79.51 %\n",
      "Epoch:190/200 AVG Training Loss:0.473 AVG Validation Loss:0.496 AVG Training Acc 80.57 % AVG Validation Acc 79.51 %\n",
      "Epoch:200/200 AVG Training Loss:0.475 AVG Validation Loss:0.494 AVG Training Acc 80.48 % AVG Validation Acc 79.60 %\n",
      "Split 220\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa7ed2facf304cd49e4077d88053546d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.492 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.21 % AVG Validation Acc 80.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.483 AVG Validation Loss:0.495 AVG Training Acc 80.29 % AVG Validation Acc 79.87 %\n",
      "Epoch:50/200 AVG Training Loss:0.480 AVG Validation Loss:0.503 AVG Training Acc 80.35 % AVG Validation Acc 79.78 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.475 AVG Validation Loss:0.514 AVG Training Acc 80.57 % AVG Validation Acc 79.60 %\n",
      "Epoch:70/200 AVG Training Loss:0.474 AVG Validation Loss:0.517 AVG Training Acc 80.67 % AVG Validation Acc 79.51 %\n",
      "Epoch:80/200 AVG Training Loss:0.473 AVG Validation Loss:0.520 AVG Training Acc 80.65 % AVG Validation Acc 79.60 %\n",
      "Epoch:90/200 AVG Training Loss:0.472 AVG Validation Loss:0.521 AVG Training Acc 80.72 % AVG Validation Acc 79.42 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.473 AVG Validation Loss:0.522 AVG Training Acc 80.67 % AVG Validation Acc 79.42 %\n",
      "Epoch:110/200 AVG Training Loss:0.472 AVG Validation Loss:0.524 AVG Training Acc 80.74 % AVG Validation Acc 79.42 %\n",
      "Epoch:120/200 AVG Training Loss:0.472 AVG Validation Loss:0.523 AVG Training Acc 80.69 % AVG Validation Acc 79.42 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.472 AVG Validation Loss:0.523 AVG Training Acc 80.70 % AVG Validation Acc 79.42 %\n",
      "Epoch:140/200 AVG Training Loss:0.472 AVG Validation Loss:0.523 AVG Training Acc 80.61 % AVG Validation Acc 79.42 %\n",
      "Epoch:150/200 AVG Training Loss:0.473 AVG Validation Loss:0.523 AVG Training Acc 80.68 % AVG Validation Acc 79.42 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.471 AVG Validation Loss:0.522 AVG Training Acc 80.68 % AVG Validation Acc 79.42 %\n",
      "Epoch:170/200 AVG Training Loss:0.471 AVG Validation Loss:0.523 AVG Training Acc 80.65 % AVG Validation Acc 79.42 %\n",
      "Epoch:180/200 AVG Training Loss:0.472 AVG Validation Loss:0.522 AVG Training Acc 80.63 % AVG Validation Acc 79.42 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.471 AVG Validation Loss:0.523 AVG Training Acc 80.74 % AVG Validation Acc 79.42 %\n",
      "Epoch:200/200 AVG Training Loss:0.472 AVG Validation Loss:0.523 AVG Training Acc 80.72 % AVG Validation Acc 79.33 %\n",
      "Split 221\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba7e436480146bd848e0c4d6df2faa0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.485 AVG Validation Loss:0.493 AVG Training Acc 80.27 % AVG Validation Acc 79.89 %\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.493 AVG Training Acc 80.30 % AVG Validation Acc 79.89 %\n",
      "Epoch:50/200 AVG Training Loss:0.480 AVG Validation Loss:0.497 AVG Training Acc 80.44 % AVG Validation Acc 80.07 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.476 AVG Validation Loss:0.501 AVG Training Acc 80.62 % AVG Validation Acc 80.07 %\n",
      "Epoch:70/200 AVG Training Loss:0.475 AVG Validation Loss:0.503 AVG Training Acc 80.50 % AVG Validation Acc 80.07 %\n",
      "Epoch:80/200 AVG Training Loss:0.475 AVG Validation Loss:0.503 AVG Training Acc 80.66 % AVG Validation Acc 79.98 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.473 AVG Validation Loss:0.505 AVG Training Acc 80.60 % AVG Validation Acc 79.89 %\n",
      "Epoch:100/200 AVG Training Loss:0.473 AVG Validation Loss:0.504 AVG Training Acc 80.63 % AVG Validation Acc 79.98 %\n",
      "Epoch:110/200 AVG Training Loss:0.474 AVG Validation Loss:0.505 AVG Training Acc 80.66 % AVG Validation Acc 79.98 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.473 AVG Validation Loss:0.505 AVG Training Acc 80.71 % AVG Validation Acc 79.98 %\n",
      "Epoch:130/200 AVG Training Loss:0.474 AVG Validation Loss:0.504 AVG Training Acc 80.68 % AVG Validation Acc 79.98 %\n",
      "Epoch:140/200 AVG Training Loss:0.474 AVG Validation Loss:0.505 AVG Training Acc 80.67 % AVG Validation Acc 79.89 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.474 AVG Validation Loss:0.505 AVG Training Acc 80.62 % AVG Validation Acc 80.07 %\n",
      "Epoch:160/200 AVG Training Loss:0.474 AVG Validation Loss:0.504 AVG Training Acc 80.68 % AVG Validation Acc 79.89 %\n",
      "Epoch:170/200 AVG Training Loss:0.473 AVG Validation Loss:0.505 AVG Training Acc 80.62 % AVG Validation Acc 79.98 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.474 AVG Validation Loss:0.505 AVG Training Acc 80.63 % AVG Validation Acc 79.98 %\n",
      "Epoch:190/200 AVG Training Loss:0.473 AVG Validation Loss:0.505 AVG Training Acc 80.68 % AVG Validation Acc 79.89 %\n",
      "Epoch:200/200 AVG Training Loss:0.472 AVG Validation Loss:0.505 AVG Training Acc 80.62 % AVG Validation Acc 79.98 %\n",
      "Split 222\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6166299a9be34c69a0ed2757e7a5ac60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.493 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.490 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.489 AVG Training Acc 80.18 % AVG Validation Acc 80.16 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.479 AVG Validation Loss:0.486 AVG Training Acc 80.52 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.474 AVG Validation Loss:0.490 AVG Training Acc 80.66 % AVG Validation Acc 79.71 %\n",
      "Epoch:60/200 AVG Training Loss:0.469 AVG Validation Loss:0.493 AVG Training Acc 80.95 % AVG Validation Acc 79.53 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.466 AVG Validation Loss:0.495 AVG Training Acc 80.98 % AVG Validation Acc 79.26 %\n",
      "Epoch:80/200 AVG Training Loss:0.466 AVG Validation Loss:0.500 AVG Training Acc 81.04 % AVG Validation Acc 79.35 %\n",
      "Epoch:90/200 AVG Training Loss:0.465 AVG Validation Loss:0.497 AVG Training Acc 81.05 % AVG Validation Acc 79.53 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.465 AVG Validation Loss:0.498 AVG Training Acc 81.09 % AVG Validation Acc 79.53 %\n",
      "Epoch:110/200 AVG Training Loss:0.464 AVG Validation Loss:0.498 AVG Training Acc 81.10 % AVG Validation Acc 79.44 %\n",
      "Epoch:120/200 AVG Training Loss:0.464 AVG Validation Loss:0.503 AVG Training Acc 81.17 % AVG Validation Acc 79.35 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.463 AVG Validation Loss:0.498 AVG Training Acc 81.10 % AVG Validation Acc 79.44 %\n",
      "Epoch:140/200 AVG Training Loss:0.465 AVG Validation Loss:0.501 AVG Training Acc 81.16 % AVG Validation Acc 79.44 %\n",
      "Epoch:150/200 AVG Training Loss:0.464 AVG Validation Loss:0.496 AVG Training Acc 81.15 % AVG Validation Acc 79.44 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.464 AVG Validation Loss:0.504 AVG Training Acc 81.15 % AVG Validation Acc 79.26 %\n",
      "Epoch:170/200 AVG Training Loss:0.463 AVG Validation Loss:0.499 AVG Training Acc 81.17 % AVG Validation Acc 79.35 %\n",
      "Epoch:180/200 AVG Training Loss:0.464 AVG Validation Loss:0.501 AVG Training Acc 81.14 % AVG Validation Acc 79.35 %\n",
      "Epoch:190/200 AVG Training Loss:0.464 AVG Validation Loss:0.498 AVG Training Acc 81.13 % AVG Validation Acc 79.44 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.464 AVG Validation Loss:0.496 AVG Training Acc 81.05 % AVG Validation Acc 79.35 %\n",
      "Split 223\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3358cb17ee5491989d6d01a495617b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.490 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.504 AVG Validation Loss:0.499 AVG Training Acc 79.84 % AVG Validation Acc 80.16 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.494 AVG Validation Loss:0.493 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.493 AVG Validation Loss:0.492 AVG Training Acc 80.09 % AVG Validation Acc 80.16 %\n",
      "Epoch:80/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.13 % AVG Validation Acc 80.07 %\n",
      "Epoch:90/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.491 AVG Validation Loss:0.492 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.491 AVG Validation Loss:0.493 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:120/200 AVG Training Loss:0.491 AVG Validation Loss:0.493 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.10 % AVG Validation Acc 80.16 %\n",
      "Epoch:140/200 AVG Training Loss:0.491 AVG Validation Loss:0.493 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:150/200 AVG Training Loss:0.491 AVG Validation Loss:0.493 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.491 AVG Validation Loss:0.491 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch:170/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:180/200 AVG Training Loss:0.491 AVG Validation Loss:0.493 AVG Training Acc 80.08 % AVG Validation Acc 80.07 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.491 AVG Validation Loss:0.493 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:200/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Split 224\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0781ac31c1b4cc8a9a7f70ea0baca05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.498 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.496 AVG Training Acc 80.21 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.486 AVG Validation Loss:0.503 AVG Training Acc 80.25 % AVG Validation Acc 79.71 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.476 AVG Validation Loss:0.501 AVG Training Acc 80.53 % AVG Validation Acc 79.98 %\n",
      "Epoch:50/200 AVG Training Loss:0.469 AVG Validation Loss:0.512 AVG Training Acc 80.80 % AVG Validation Acc 79.53 %\n",
      "Epoch:60/200 AVG Training Loss:0.466 AVG Validation Loss:0.510 AVG Training Acc 80.91 % AVG Validation Acc 79.35 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.469 AVG Validation Loss:0.501 AVG Training Acc 80.77 % AVG Validation Acc 79.35 %\n",
      "Epoch:80/200 AVG Training Loss:0.466 AVG Validation Loss:0.507 AVG Training Acc 80.82 % AVG Validation Acc 79.26 %\n",
      "Epoch:90/200 AVG Training Loss:0.466 AVG Validation Loss:0.508 AVG Training Acc 80.80 % AVG Validation Acc 79.53 %\n",
      "Epoch:100/200 AVG Training Loss:0.464 AVG Validation Loss:0.508 AVG Training Acc 80.90 % AVG Validation Acc 79.44 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.463 AVG Validation Loss:0.514 AVG Training Acc 80.89 % AVG Validation Acc 79.26 %\n",
      "Epoch:120/200 AVG Training Loss:0.464 AVG Validation Loss:0.509 AVG Training Acc 80.94 % AVG Validation Acc 79.53 %\n",
      "Epoch:130/200 AVG Training Loss:0.463 AVG Validation Loss:0.509 AVG Training Acc 81.06 % AVG Validation Acc 79.26 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.465 AVG Validation Loss:0.510 AVG Training Acc 80.87 % AVG Validation Acc 79.17 %\n",
      "Epoch:150/200 AVG Training Loss:0.464 AVG Validation Loss:0.510 AVG Training Acc 80.98 % AVG Validation Acc 79.35 %\n",
      "Epoch:160/200 AVG Training Loss:0.463 AVG Validation Loss:0.517 AVG Training Acc 81.01 % AVG Validation Acc 79.26 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.463 AVG Validation Loss:0.511 AVG Training Acc 80.89 % AVG Validation Acc 79.17 %\n",
      "Epoch:180/200 AVG Training Loss:0.462 AVG Validation Loss:0.514 AVG Training Acc 80.96 % AVG Validation Acc 79.26 %\n",
      "Epoch:190/200 AVG Training Loss:0.461 AVG Validation Loss:0.510 AVG Training Acc 81.04 % AVG Validation Acc 79.26 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.464 AVG Validation Loss:0.517 AVG Training Acc 80.83 % AVG Validation Acc 78.99 %\n",
      "Split 225\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcd6d393c1cc4809bcd4dc908d949a3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.491 AVG Training Acc 80.13 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.20 % AVG Validation Acc 80.07 %\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.480 AVG Validation Loss:0.497 AVG Training Acc 80.44 % AVG Validation Acc 79.98 %\n",
      "Epoch:60/200 AVG Training Loss:0.473 AVG Validation Loss:0.504 AVG Training Acc 80.89 % AVG Validation Acc 79.89 %\n",
      "Epoch:70/200 AVG Training Loss:0.467 AVG Validation Loss:0.509 AVG Training Acc 81.21 % AVG Validation Acc 79.44 %\n",
      "Epoch    71: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.466 AVG Validation Loss:0.526 AVG Training Acc 81.20 % AVG Validation Acc 79.17 %\n",
      "Epoch:90/200 AVG Training Loss:0.462 AVG Validation Loss:0.517 AVG Training Acc 81.35 % AVG Validation Acc 78.90 %\n",
      "Epoch:100/200 AVG Training Loss:0.463 AVG Validation Loss:0.518 AVG Training Acc 81.31 % AVG Validation Acc 79.08 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.463 AVG Validation Loss:0.524 AVG Training Acc 81.39 % AVG Validation Acc 79.17 %\n",
      "Epoch:120/200 AVG Training Loss:0.461 AVG Validation Loss:0.521 AVG Training Acc 81.44 % AVG Validation Acc 78.81 %\n",
      "Epoch:130/200 AVG Training Loss:0.463 AVG Validation Loss:0.518 AVG Training Acc 81.41 % AVG Validation Acc 78.99 %\n",
      "Epoch   133: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.462 AVG Validation Loss:0.520 AVG Training Acc 81.42 % AVG Validation Acc 78.90 %\n",
      "Epoch:150/200 AVG Training Loss:0.461 AVG Validation Loss:0.522 AVG Training Acc 81.42 % AVG Validation Acc 78.90 %\n",
      "Epoch:160/200 AVG Training Loss:0.463 AVG Validation Loss:0.525 AVG Training Acc 81.32 % AVG Validation Acc 79.08 %\n",
      "Epoch   164: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.463 AVG Validation Loss:0.529 AVG Training Acc 81.29 % AVG Validation Acc 79.08 %\n",
      "Epoch:180/200 AVG Training Loss:0.461 AVG Validation Loss:0.517 AVG Training Acc 81.28 % AVG Validation Acc 79.08 %\n",
      "Epoch:190/200 AVG Training Loss:0.462 AVG Validation Loss:0.521 AVG Training Acc 81.46 % AVG Validation Acc 78.90 %\n",
      "Epoch   195: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.461 AVG Validation Loss:0.526 AVG Training Acc 81.34 % AVG Validation Acc 78.99 %\n",
      "Split 226\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2aea61f9bb5249c89c1174d2cc802d24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.483 AVG Validation Loss:0.495 AVG Training Acc 80.34 % AVG Validation Acc 79.96 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.468 AVG Validation Loss:0.498 AVG Training Acc 80.61 % AVG Validation Acc 79.69 %\n",
      "Epoch:50/200 AVG Training Loss:0.457 AVG Validation Loss:0.511 AVG Training Acc 81.21 % AVG Validation Acc 79.87 %\n",
      "Epoch:60/200 AVG Training Loss:0.451 AVG Validation Loss:0.515 AVG Training Acc 81.48 % AVG Validation Acc 79.60 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.443 AVG Validation Loss:0.521 AVG Training Acc 81.83 % AVG Validation Acc 79.51 %\n",
      "Epoch:80/200 AVG Training Loss:0.441 AVG Validation Loss:0.521 AVG Training Acc 82.03 % AVG Validation Acc 78.61 %\n",
      "Epoch:90/200 AVG Training Loss:0.443 AVG Validation Loss:0.523 AVG Training Acc 81.76 % AVG Validation Acc 78.43 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.439 AVG Validation Loss:0.540 AVG Training Acc 82.02 % AVG Validation Acc 78.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.442 AVG Validation Loss:0.527 AVG Training Acc 81.97 % AVG Validation Acc 78.07 %\n",
      "Epoch:120/200 AVG Training Loss:0.438 AVG Validation Loss:0.533 AVG Training Acc 82.06 % AVG Validation Acc 78.07 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.440 AVG Validation Loss:0.527 AVG Training Acc 82.10 % AVG Validation Acc 78.16 %\n",
      "Epoch:140/200 AVG Training Loss:0.439 AVG Validation Loss:0.525 AVG Training Acc 81.90 % AVG Validation Acc 78.34 %\n",
      "Epoch:150/200 AVG Training Loss:0.440 AVG Validation Loss:0.526 AVG Training Acc 82.04 % AVG Validation Acc 78.43 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.439 AVG Validation Loss:0.527 AVG Training Acc 82.15 % AVG Validation Acc 78.34 %\n",
      "Epoch:170/200 AVG Training Loss:0.439 AVG Validation Loss:0.524 AVG Training Acc 82.05 % AVG Validation Acc 78.34 %\n",
      "Epoch:180/200 AVG Training Loss:0.439 AVG Validation Loss:0.524 AVG Training Acc 82.10 % AVG Validation Acc 78.88 %\n",
      "Epoch:190/200 AVG Training Loss:0.440 AVG Validation Loss:0.524 AVG Training Acc 82.02 % AVG Validation Acc 78.79 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.440 AVG Validation Loss:0.528 AVG Training Acc 81.92 % AVG Validation Acc 78.16 %\n",
      "Split 227\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f94eb706809f47ff882d2c44526ad255",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.497 AVG Validation Loss:0.499 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.496 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.28 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.500 AVG Training Acc 80.31 % AVG Validation Acc 80.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.483 AVG Validation Loss:0.501 AVG Training Acc 80.35 % AVG Validation Acc 80.05 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.482 AVG Validation Loss:0.502 AVG Training Acc 80.37 % AVG Validation Acc 80.05 %\n",
      "Epoch:90/200 AVG Training Loss:0.483 AVG Validation Loss:0.502 AVG Training Acc 80.28 % AVG Validation Acc 80.05 %\n",
      "Epoch:100/200 AVG Training Loss:0.483 AVG Validation Loss:0.501 AVG Training Acc 80.24 % AVG Validation Acc 80.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.483 AVG Validation Loss:0.502 AVG Training Acc 80.32 % AVG Validation Acc 80.05 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.482 AVG Validation Loss:0.502 AVG Training Acc 80.34 % AVG Validation Acc 80.05 %\n",
      "Epoch:130/200 AVG Training Loss:0.482 AVG Validation Loss:0.502 AVG Training Acc 80.36 % AVG Validation Acc 80.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.482 AVG Validation Loss:0.502 AVG Training Acc 80.27 % AVG Validation Acc 80.05 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.482 AVG Validation Loss:0.502 AVG Training Acc 80.32 % AVG Validation Acc 80.05 %\n",
      "Epoch:160/200 AVG Training Loss:0.482 AVG Validation Loss:0.503 AVG Training Acc 80.33 % AVG Validation Acc 80.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.483 AVG Validation Loss:0.502 AVG Training Acc 80.28 % AVG Validation Acc 80.05 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.482 AVG Validation Loss:0.502 AVG Training Acc 80.29 % AVG Validation Acc 80.05 %\n",
      "Epoch:190/200 AVG Training Loss:0.482 AVG Validation Loss:0.502 AVG Training Acc 80.28 % AVG Validation Acc 80.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.482 AVG Validation Loss:0.502 AVG Training Acc 80.37 % AVG Validation Acc 80.05 %\n",
      "Split 228\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3236ee279e594f72938fded32b59421d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.35 % AVG Validation Acc 80.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.481 AVG Validation Loss:0.495 AVG Training Acc 80.49 % AVG Validation Acc 79.96 %\n",
      "Epoch:50/200 AVG Training Loss:0.480 AVG Validation Loss:0.506 AVG Training Acc 80.58 % AVG Validation Acc 79.78 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.460 AVG Validation Loss:0.509 AVG Training Acc 81.18 % AVG Validation Acc 79.96 %\n",
      "Epoch:70/200 AVG Training Loss:0.453 AVG Validation Loss:0.520 AVG Training Acc 81.41 % AVG Validation Acc 79.60 %\n",
      "Epoch:80/200 AVG Training Loss:0.448 AVG Validation Loss:0.521 AVG Training Acc 81.59 % AVG Validation Acc 79.87 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.442 AVG Validation Loss:0.528 AVG Training Acc 81.92 % AVG Validation Acc 79.15 %\n",
      "Epoch:100/200 AVG Training Loss:0.442 AVG Validation Loss:0.518 AVG Training Acc 81.93 % AVG Validation Acc 78.97 %\n",
      "Epoch:110/200 AVG Training Loss:0.441 AVG Validation Loss:0.530 AVG Training Acc 81.95 % AVG Validation Acc 79.06 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.439 AVG Validation Loss:0.535 AVG Training Acc 82.03 % AVG Validation Acc 79.15 %\n",
      "Epoch:130/200 AVG Training Loss:0.441 AVG Validation Loss:0.537 AVG Training Acc 81.95 % AVG Validation Acc 78.97 %\n",
      "Epoch:140/200 AVG Training Loss:0.441 AVG Validation Loss:0.534 AVG Training Acc 81.84 % AVG Validation Acc 79.33 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.440 AVG Validation Loss:0.537 AVG Training Acc 81.91 % AVG Validation Acc 78.97 %\n",
      "Epoch:160/200 AVG Training Loss:0.440 AVG Validation Loss:0.530 AVG Training Acc 81.97 % AVG Validation Acc 78.79 %\n",
      "Epoch:170/200 AVG Training Loss:0.441 AVG Validation Loss:0.538 AVG Training Acc 81.91 % AVG Validation Acc 79.06 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.440 AVG Validation Loss:0.535 AVG Training Acc 82.03 % AVG Validation Acc 78.97 %\n",
      "Epoch:190/200 AVG Training Loss:0.441 AVG Validation Loss:0.533 AVG Training Acc 81.96 % AVG Validation Acc 78.97 %\n",
      "Epoch:200/200 AVG Training Loss:0.441 AVG Validation Loss:0.531 AVG Training Acc 82.03 % AVG Validation Acc 79.06 %\n",
      "Split 229\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2044b3055314963b5eb91c5d84db88a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.485 AVG Validation Loss:0.494 AVG Training Acc 80.28 % AVG Validation Acc 80.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.497 AVG Validation Loss:0.499 AVG Training Acc 80.03 % AVG Validation Acc 79.24 %\n",
      "Epoch:50/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.25 % AVG Validation Acc 79.78 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.481 AVG Validation Loss:0.497 AVG Training Acc 80.34 % AVG Validation Acc 79.96 %\n",
      "Epoch:70/200 AVG Training Loss:0.481 AVG Validation Loss:0.497 AVG Training Acc 80.44 % AVG Validation Acc 79.78 %\n",
      "Epoch:80/200 AVG Training Loss:0.480 AVG Validation Loss:0.497 AVG Training Acc 80.46 % AVG Validation Acc 79.78 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.479 AVG Validation Loss:0.498 AVG Training Acc 80.57 % AVG Validation Acc 79.69 %\n",
      "Epoch:100/200 AVG Training Loss:0.479 AVG Validation Loss:0.498 AVG Training Acc 80.45 % AVG Validation Acc 79.69 %\n",
      "Epoch:110/200 AVG Training Loss:0.480 AVG Validation Loss:0.498 AVG Training Acc 80.48 % AVG Validation Acc 79.69 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.479 AVG Validation Loss:0.499 AVG Training Acc 80.40 % AVG Validation Acc 79.78 %\n",
      "Epoch:130/200 AVG Training Loss:0.480 AVG Validation Loss:0.498 AVG Training Acc 80.39 % AVG Validation Acc 79.60 %\n",
      "Epoch:140/200 AVG Training Loss:0.479 AVG Validation Loss:0.499 AVG Training Acc 80.50 % AVG Validation Acc 79.78 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.479 AVG Validation Loss:0.498 AVG Training Acc 80.48 % AVG Validation Acc 79.60 %\n",
      "Epoch:160/200 AVG Training Loss:0.480 AVG Validation Loss:0.498 AVG Training Acc 80.44 % AVG Validation Acc 79.60 %\n",
      "Epoch:170/200 AVG Training Loss:0.479 AVG Validation Loss:0.498 AVG Training Acc 80.48 % AVG Validation Acc 79.69 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.479 AVG Validation Loss:0.498 AVG Training Acc 80.52 % AVG Validation Acc 79.60 %\n",
      "Epoch:190/200 AVG Training Loss:0.478 AVG Validation Loss:0.498 AVG Training Acc 80.42 % AVG Validation Acc 79.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.479 AVG Validation Loss:0.499 AVG Training Acc 80.47 % AVG Validation Acc 79.60 %\n",
      "Split 230\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a61a0bb8ff674afe90a18c82e95b930d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.485 AVG Validation Loss:0.492 AVG Training Acc 80.33 % AVG Validation Acc 80.05 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.477 AVG Validation Loss:0.492 AVG Training Acc 80.53 % AVG Validation Acc 79.69 %\n",
      "Epoch:60/200 AVG Training Loss:0.470 AVG Validation Loss:0.492 AVG Training Acc 80.80 % AVG Validation Acc 79.69 %\n",
      "Epoch:70/200 AVG Training Loss:0.463 AVG Validation Loss:0.498 AVG Training Acc 80.86 % AVG Validation Acc 79.60 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.458 AVG Validation Loss:0.497 AVG Training Acc 81.01 % AVG Validation Acc 79.78 %\n",
      "Epoch:90/200 AVG Training Loss:0.456 AVG Validation Loss:0.504 AVG Training Acc 81.15 % AVG Validation Acc 79.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.456 AVG Validation Loss:0.503 AVG Training Acc 81.02 % AVG Validation Acc 79.96 %\n",
      "Epoch:110/200 AVG Training Loss:0.454 AVG Validation Loss:0.509 AVG Training Acc 81.18 % AVG Validation Acc 79.96 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.452 AVG Validation Loss:0.504 AVG Training Acc 81.30 % AVG Validation Acc 80.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.453 AVG Validation Loss:0.507 AVG Training Acc 81.23 % AVG Validation Acc 79.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.454 AVG Validation Loss:0.508 AVG Training Acc 81.10 % AVG Validation Acc 79.78 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.454 AVG Validation Loss:0.504 AVG Training Acc 81.12 % AVG Validation Acc 80.23 %\n",
      "Epoch:160/200 AVG Training Loss:0.453 AVG Validation Loss:0.505 AVG Training Acc 81.14 % AVG Validation Acc 79.96 %\n",
      "Epoch:170/200 AVG Training Loss:0.452 AVG Validation Loss:0.502 AVG Training Acc 81.25 % AVG Validation Acc 79.87 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.454 AVG Validation Loss:0.505 AVG Training Acc 81.12 % AVG Validation Acc 79.96 %\n",
      "Epoch:190/200 AVG Training Loss:0.454 AVG Validation Loss:0.507 AVG Training Acc 81.12 % AVG Validation Acc 80.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.453 AVG Validation Loss:0.506 AVG Training Acc 81.12 % AVG Validation Acc 79.87 %\n",
      "Split 231\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a5807356e547dbaea13ee01e58dc47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 80.25 %\n",
      "Epoch:50/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.18 % AVG Validation Acc 80.16 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.477 AVG Validation Loss:0.501 AVG Training Acc 80.26 % AVG Validation Acc 80.07 %\n",
      "Epoch:70/200 AVG Training Loss:0.476 AVG Validation Loss:0.502 AVG Training Acc 80.20 % AVG Validation Acc 80.07 %\n",
      "Epoch:80/200 AVG Training Loss:0.476 AVG Validation Loss:0.502 AVG Training Acc 80.24 % AVG Validation Acc 80.07 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.476 AVG Validation Loss:0.503 AVG Training Acc 80.20 % AVG Validation Acc 79.98 %\n",
      "Epoch:100/200 AVG Training Loss:0.477 AVG Validation Loss:0.502 AVG Training Acc 80.26 % AVG Validation Acc 79.98 %\n",
      "Epoch:110/200 AVG Training Loss:0.476 AVG Validation Loss:0.501 AVG Training Acc 80.24 % AVG Validation Acc 79.98 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.477 AVG Validation Loss:0.503 AVG Training Acc 80.27 % AVG Validation Acc 79.98 %\n",
      "Epoch:130/200 AVG Training Loss:0.476 AVG Validation Loss:0.501 AVG Training Acc 80.19 % AVG Validation Acc 79.98 %\n",
      "Epoch:140/200 AVG Training Loss:0.477 AVG Validation Loss:0.502 AVG Training Acc 80.24 % AVG Validation Acc 79.98 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.476 AVG Validation Loss:0.503 AVG Training Acc 80.23 % AVG Validation Acc 79.98 %\n",
      "Epoch:160/200 AVG Training Loss:0.476 AVG Validation Loss:0.502 AVG Training Acc 80.26 % AVG Validation Acc 79.98 %\n",
      "Epoch:170/200 AVG Training Loss:0.476 AVG Validation Loss:0.502 AVG Training Acc 80.22 % AVG Validation Acc 79.98 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.476 AVG Validation Loss:0.501 AVG Training Acc 80.24 % AVG Validation Acc 79.98 %\n",
      "Epoch:190/200 AVG Training Loss:0.476 AVG Validation Loss:0.502 AVG Training Acc 80.21 % AVG Validation Acc 79.98 %\n",
      "Epoch:200/200 AVG Training Loss:0.476 AVG Validation Loss:0.502 AVG Training Acc 80.30 % AVG Validation Acc 79.98 %\n",
      "Split 232\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab19922f3b82462a9a603132e273cd27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.491 AVG Training Acc 80.12 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.496 AVG Validation Loss:0.499 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.498 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.498 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.498 AVG Validation Loss:0.498 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.497 AVG Validation Loss:0.497 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:80/200 AVG Training Loss:0.496 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:90/200 AVG Training Loss:0.496 AVG Validation Loss:0.498 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.496 AVG Validation Loss:0.496 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.496 AVG Validation Loss:0.497 AVG Training Acc 80.18 % AVG Validation Acc 80.16 %\n",
      "Epoch:120/200 AVG Training Loss:0.497 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.496 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:140/200 AVG Training Loss:0.496 AVG Validation Loss:0.496 AVG Training Acc 80.18 % AVG Validation Acc 80.16 %\n",
      "Epoch:150/200 AVG Training Loss:0.496 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:170/200 AVG Training Loss:0.496 AVG Validation Loss:0.497 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:180/200 AVG Training Loss:0.496 AVG Validation Loss:0.496 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.496 AVG Validation Loss:0.496 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:200/200 AVG Training Loss:0.497 AVG Validation Loss:0.496 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Split 233\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7ed36a4fdba4883a8fe8f572e5ea50e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.10 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.498 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.28 % AVG Validation Acc 79.98 %\n",
      "Epoch:40/200 AVG Training Loss:0.480 AVG Validation Loss:0.503 AVG Training Acc 80.40 % AVG Validation Acc 79.80 %\n",
      "Epoch:50/200 AVG Training Loss:0.477 AVG Validation Loss:0.504 AVG Training Acc 80.49 % AVG Validation Acc 79.71 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.469 AVG Validation Loss:0.511 AVG Training Acc 80.78 % AVG Validation Acc 79.53 %\n",
      "Epoch:70/200 AVG Training Loss:0.469 AVG Validation Loss:0.512 AVG Training Acc 80.80 % AVG Validation Acc 79.53 %\n",
      "Epoch:80/200 AVG Training Loss:0.468 AVG Validation Loss:0.511 AVG Training Acc 80.79 % AVG Validation Acc 79.53 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.468 AVG Validation Loss:0.515 AVG Training Acc 80.92 % AVG Validation Acc 79.53 %\n",
      "Epoch:100/200 AVG Training Loss:0.467 AVG Validation Loss:0.516 AVG Training Acc 80.93 % AVG Validation Acc 79.53 %\n",
      "Epoch:110/200 AVG Training Loss:0.466 AVG Validation Loss:0.515 AVG Training Acc 80.94 % AVG Validation Acc 79.44 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.467 AVG Validation Loss:0.516 AVG Training Acc 80.93 % AVG Validation Acc 79.53 %\n",
      "Epoch:130/200 AVG Training Loss:0.467 AVG Validation Loss:0.515 AVG Training Acc 80.88 % AVG Validation Acc 79.53 %\n",
      "Epoch:140/200 AVG Training Loss:0.467 AVG Validation Loss:0.515 AVG Training Acc 80.87 % AVG Validation Acc 79.53 %\n",
      "Epoch:150/200 AVG Training Loss:0.466 AVG Validation Loss:0.516 AVG Training Acc 80.95 % AVG Validation Acc 79.53 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.468 AVG Validation Loss:0.516 AVG Training Acc 80.88 % AVG Validation Acc 79.44 %\n",
      "Epoch:170/200 AVG Training Loss:0.467 AVG Validation Loss:0.516 AVG Training Acc 80.85 % AVG Validation Acc 79.53 %\n",
      "Epoch:180/200 AVG Training Loss:0.466 AVG Validation Loss:0.517 AVG Training Acc 81.01 % AVG Validation Acc 79.35 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.467 AVG Validation Loss:0.513 AVG Training Acc 80.95 % AVG Validation Acc 79.62 %\n",
      "Epoch:200/200 AVG Training Loss:0.467 AVG Validation Loss:0.516 AVG Training Acc 80.90 % AVG Validation Acc 79.53 %\n",
      "Split 234\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaff3107030b49989f0d9a423dc7b088",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.495 AVG Training Acc 80.24 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.478 AVG Validation Loss:0.501 AVG Training Acc 80.43 % AVG Validation Acc 79.98 %\n",
      "Epoch:60/200 AVG Training Loss:0.473 AVG Validation Loss:0.503 AVG Training Acc 80.56 % AVG Validation Acc 79.71 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.470 AVG Validation Loss:0.505 AVG Training Acc 80.59 % AVG Validation Acc 79.53 %\n",
      "Epoch:80/200 AVG Training Loss:0.468 AVG Validation Loss:0.506 AVG Training Acc 80.74 % AVG Validation Acc 79.53 %\n",
      "Epoch:90/200 AVG Training Loss:0.467 AVG Validation Loss:0.507 AVG Training Acc 80.83 % AVG Validation Acc 79.53 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.468 AVG Validation Loss:0.507 AVG Training Acc 80.69 % AVG Validation Acc 79.53 %\n",
      "Epoch:110/200 AVG Training Loss:0.469 AVG Validation Loss:0.507 AVG Training Acc 80.76 % AVG Validation Acc 79.62 %\n",
      "Epoch:120/200 AVG Training Loss:0.466 AVG Validation Loss:0.507 AVG Training Acc 80.92 % AVG Validation Acc 79.62 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.468 AVG Validation Loss:0.508 AVG Training Acc 80.70 % AVG Validation Acc 79.62 %\n",
      "Epoch:140/200 AVG Training Loss:0.467 AVG Validation Loss:0.507 AVG Training Acc 80.70 % AVG Validation Acc 79.44 %\n",
      "Epoch:150/200 AVG Training Loss:0.468 AVG Validation Loss:0.507 AVG Training Acc 80.75 % AVG Validation Acc 79.53 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.467 AVG Validation Loss:0.509 AVG Training Acc 80.78 % AVG Validation Acc 79.53 %\n",
      "Epoch:170/200 AVG Training Loss:0.468 AVG Validation Loss:0.507 AVG Training Acc 80.82 % AVG Validation Acc 79.53 %\n",
      "Epoch:180/200 AVG Training Loss:0.468 AVG Validation Loss:0.508 AVG Training Acc 80.79 % AVG Validation Acc 79.53 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.467 AVG Validation Loss:0.511 AVG Training Acc 80.75 % AVG Validation Acc 79.35 %\n",
      "Epoch:200/200 AVG Training Loss:0.468 AVG Validation Loss:0.507 AVG Training Acc 80.78 % AVG Validation Acc 79.44 %\n",
      "Split 235\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "521180972d0644aaade471607b5c4e99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.499 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.499 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.500 AVG Training Acc 80.16 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.501 AVG Training Acc 80.19 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.487 AVG Validation Loss:0.500 AVG Training Acc 80.22 % AVG Validation Acc 80.25 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.483 AVG Validation Loss:0.502 AVG Training Acc 80.38 % AVG Validation Acc 80.07 %\n",
      "Epoch:70/200 AVG Training Loss:0.483 AVG Validation Loss:0.501 AVG Training Acc 80.33 % AVG Validation Acc 79.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.483 AVG Validation Loss:0.503 AVG Training Acc 80.37 % AVG Validation Acc 80.07 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.482 AVG Validation Loss:0.501 AVG Training Acc 80.35 % AVG Validation Acc 80.07 %\n",
      "Epoch:100/200 AVG Training Loss:0.483 AVG Validation Loss:0.502 AVG Training Acc 80.31 % AVG Validation Acc 80.07 %\n",
      "Epoch:110/200 AVG Training Loss:0.482 AVG Validation Loss:0.502 AVG Training Acc 80.37 % AVG Validation Acc 79.98 %\n",
      "Epoch:120/200 AVG Training Loss:0.483 AVG Validation Loss:0.501 AVG Training Acc 80.40 % AVG Validation Acc 80.16 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.481 AVG Validation Loss:0.502 AVG Training Acc 80.42 % AVG Validation Acc 79.98 %\n",
      "Epoch:140/200 AVG Training Loss:0.482 AVG Validation Loss:0.502 AVG Training Acc 80.31 % AVG Validation Acc 80.07 %\n",
      "Epoch:150/200 AVG Training Loss:0.482 AVG Validation Loss:0.503 AVG Training Acc 80.36 % AVG Validation Acc 80.07 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.483 AVG Validation Loss:0.502 AVG Training Acc 80.41 % AVG Validation Acc 80.07 %\n",
      "Epoch:170/200 AVG Training Loss:0.481 AVG Validation Loss:0.500 AVG Training Acc 80.52 % AVG Validation Acc 80.16 %\n",
      "Epoch:180/200 AVG Training Loss:0.482 AVG Validation Loss:0.502 AVG Training Acc 80.37 % AVG Validation Acc 80.07 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.481 AVG Validation Loss:0.502 AVG Training Acc 80.41 % AVG Validation Acc 80.07 %\n",
      "Epoch:200/200 AVG Training Loss:0.483 AVG Validation Loss:0.503 AVG Training Acc 80.39 % AVG Validation Acc 80.07 %\n",
      "Split 236\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7746347355ec44b7ad048676b92cc165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.491 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.485 AVG Validation Loss:0.487 AVG Training Acc 80.18 % AVG Validation Acc 80.23 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.484 AVG Validation Loss:0.491 AVG Training Acc 80.20 % AVG Validation Acc 79.96 %\n",
      "Epoch:60/200 AVG Training Loss:0.478 AVG Validation Loss:0.494 AVG Training Acc 80.20 % AVG Validation Acc 79.96 %\n",
      "Epoch:70/200 AVG Training Loss:0.472 AVG Validation Loss:0.498 AVG Training Acc 80.30 % AVG Validation Acc 79.69 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.465 AVG Validation Loss:0.504 AVG Training Acc 80.45 % AVG Validation Acc 79.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.462 AVG Validation Loss:0.503 AVG Training Acc 80.58 % AVG Validation Acc 79.51 %\n",
      "Epoch:100/200 AVG Training Loss:0.462 AVG Validation Loss:0.505 AVG Training Acc 80.53 % AVG Validation Acc 79.33 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.464 AVG Validation Loss:0.503 AVG Training Acc 80.61 % AVG Validation Acc 79.78 %\n",
      "Epoch:120/200 AVG Training Loss:0.461 AVG Validation Loss:0.503 AVG Training Acc 80.82 % AVG Validation Acc 79.60 %\n",
      "Epoch:130/200 AVG Training Loss:0.462 AVG Validation Loss:0.504 AVG Training Acc 80.67 % AVG Validation Acc 79.60 %\n",
      "Epoch:140/200 AVG Training Loss:0.462 AVG Validation Loss:0.501 AVG Training Acc 80.75 % AVG Validation Acc 79.60 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.462 AVG Validation Loss:0.506 AVG Training Acc 80.55 % AVG Validation Acc 79.51 %\n",
      "Epoch:160/200 AVG Training Loss:0.462 AVG Validation Loss:0.505 AVG Training Acc 80.57 % AVG Validation Acc 79.42 %\n",
      "Epoch:170/200 AVG Training Loss:0.462 AVG Validation Loss:0.503 AVG Training Acc 80.53 % AVG Validation Acc 79.51 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.462 AVG Validation Loss:0.503 AVG Training Acc 80.79 % AVG Validation Acc 79.51 %\n",
      "Epoch:190/200 AVG Training Loss:0.463 AVG Validation Loss:0.504 AVG Training Acc 80.50 % AVG Validation Acc 79.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.462 AVG Validation Loss:0.504 AVG Training Acc 80.60 % AVG Validation Acc 79.69 %\n",
      "Split 237\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6576e96a72db4be3b790b608b8ece950",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.23 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.483 AVG Validation Loss:0.500 AVG Training Acc 80.56 % AVG Validation Acc 79.96 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.482 AVG Validation Loss:0.501 AVG Training Acc 80.56 % AVG Validation Acc 80.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.480 AVG Validation Loss:0.503 AVG Training Acc 80.65 % AVG Validation Acc 79.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.478 AVG Validation Loss:0.502 AVG Training Acc 80.59 % AVG Validation Acc 79.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.477 AVG Validation Loss:0.504 AVG Training Acc 80.67 % AVG Validation Acc 79.78 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.478 AVG Validation Loss:0.503 AVG Training Acc 80.66 % AVG Validation Acc 79.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.478 AVG Validation Loss:0.503 AVG Training Acc 80.64 % AVG Validation Acc 79.96 %\n",
      "Epoch:120/200 AVG Training Loss:0.479 AVG Validation Loss:0.503 AVG Training Acc 80.68 % AVG Validation Acc 80.05 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.478 AVG Validation Loss:0.504 AVG Training Acc 80.68 % AVG Validation Acc 79.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.480 AVG Validation Loss:0.505 AVG Training Acc 80.56 % AVG Validation Acc 79.87 %\n",
      "Epoch:150/200 AVG Training Loss:0.478 AVG Validation Loss:0.504 AVG Training Acc 80.65 % AVG Validation Acc 79.87 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.478 AVG Validation Loss:0.503 AVG Training Acc 80.69 % AVG Validation Acc 79.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.478 AVG Validation Loss:0.504 AVG Training Acc 80.73 % AVG Validation Acc 79.78 %\n",
      "Epoch:180/200 AVG Training Loss:0.479 AVG Validation Loss:0.505 AVG Training Acc 80.68 % AVG Validation Acc 79.96 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.479 AVG Validation Loss:0.505 AVG Training Acc 80.72 % AVG Validation Acc 79.78 %\n",
      "Epoch:200/200 AVG Training Loss:0.479 AVG Validation Loss:0.503 AVG Training Acc 80.67 % AVG Validation Acc 79.78 %\n",
      "Split 238\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94cb884c9c7144d7a1f030f1954fdd86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.489 AVG Training Acc 80.19 % AVG Validation Acc 80.23 %\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.486 AVG Training Acc 80.20 % AVG Validation Acc 80.23 %\n",
      "Epoch:50/200 AVG Training Loss:0.484 AVG Validation Loss:0.491 AVG Training Acc 80.26 % AVG Validation Acc 80.14 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.482 AVG Validation Loss:0.495 AVG Training Acc 80.32 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.482 AVG Validation Loss:0.497 AVG Training Acc 80.35 % AVG Validation Acc 80.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.32 % AVG Validation Acc 80.23 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.480 AVG Validation Loss:0.499 AVG Training Acc 80.30 % AVG Validation Acc 80.23 %\n",
      "Epoch:100/200 AVG Training Loss:0.480 AVG Validation Loss:0.500 AVG Training Acc 80.34 % AVG Validation Acc 80.23 %\n",
      "Epoch:110/200 AVG Training Loss:0.480 AVG Validation Loss:0.500 AVG Training Acc 80.29 % AVG Validation Acc 80.23 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.480 AVG Validation Loss:0.500 AVG Training Acc 80.32 % AVG Validation Acc 80.23 %\n",
      "Epoch:130/200 AVG Training Loss:0.480 AVG Validation Loss:0.500 AVG Training Acc 80.28 % AVG Validation Acc 80.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.482 AVG Validation Loss:0.500 AVG Training Acc 80.24 % AVG Validation Acc 80.23 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.480 AVG Validation Loss:0.500 AVG Training Acc 80.28 % AVG Validation Acc 80.23 %\n",
      "Epoch:160/200 AVG Training Loss:0.480 AVG Validation Loss:0.500 AVG Training Acc 80.39 % AVG Validation Acc 80.23 %\n",
      "Epoch:170/200 AVG Training Loss:0.480 AVG Validation Loss:0.500 AVG Training Acc 80.31 % AVG Validation Acc 80.23 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.480 AVG Validation Loss:0.499 AVG Training Acc 80.36 % AVG Validation Acc 80.23 %\n",
      "Epoch:190/200 AVG Training Loss:0.480 AVG Validation Loss:0.499 AVG Training Acc 80.31 % AVG Validation Acc 80.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.36 % AVG Validation Acc 80.23 %\n",
      "Split 239\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff6be1803824491aa8f4a11359fda75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.494 AVG Validation Loss:0.500 AVG Training Acc 80.09 % AVG Validation Acc 80.14 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.18 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.485 AVG Validation Loss:0.495 AVG Training Acc 80.41 % AVG Validation Acc 79.69 %\n",
      "Epoch:60/200 AVG Training Loss:0.481 AVG Validation Loss:0.502 AVG Training Acc 80.61 % AVG Validation Acc 79.51 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.476 AVG Validation Loss:0.503 AVG Training Acc 80.79 % AVG Validation Acc 79.51 %\n",
      "Epoch:80/200 AVG Training Loss:0.475 AVG Validation Loss:0.504 AVG Training Acc 80.84 % AVG Validation Acc 79.33 %\n",
      "Epoch:90/200 AVG Training Loss:0.475 AVG Validation Loss:0.504 AVG Training Acc 80.89 % AVG Validation Acc 79.42 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.474 AVG Validation Loss:0.506 AVG Training Acc 80.93 % AVG Validation Acc 79.24 %\n",
      "Epoch:110/200 AVG Training Loss:0.472 AVG Validation Loss:0.506 AVG Training Acc 81.01 % AVG Validation Acc 79.15 %\n",
      "Epoch:120/200 AVG Training Loss:0.474 AVG Validation Loss:0.506 AVG Training Acc 80.89 % AVG Validation Acc 79.15 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.474 AVG Validation Loss:0.506 AVG Training Acc 80.95 % AVG Validation Acc 79.06 %\n",
      "Epoch:140/200 AVG Training Loss:0.473 AVG Validation Loss:0.505 AVG Training Acc 80.97 % AVG Validation Acc 79.33 %\n",
      "Epoch:150/200 AVG Training Loss:0.473 AVG Validation Loss:0.506 AVG Training Acc 80.99 % AVG Validation Acc 79.33 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.474 AVG Validation Loss:0.506 AVG Training Acc 80.95 % AVG Validation Acc 78.97 %\n",
      "Epoch:170/200 AVG Training Loss:0.473 AVG Validation Loss:0.506 AVG Training Acc 81.05 % AVG Validation Acc 79.15 %\n",
      "Epoch:180/200 AVG Training Loss:0.474 AVG Validation Loss:0.505 AVG Training Acc 80.88 % AVG Validation Acc 79.24 %\n",
      "Epoch:190/200 AVG Training Loss:0.475 AVG Validation Loss:0.505 AVG Training Acc 80.95 % AVG Validation Acc 79.06 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.474 AVG Validation Loss:0.506 AVG Training Acc 80.82 % AVG Validation Acc 79.15 %\n",
      "Split 240\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9eec5dd3ce414a37a2b68a232f41e069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.486 AVG Validation Loss:0.493 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.485 AVG Validation Loss:0.494 AVG Training Acc 80.24 % AVG Validation Acc 80.23 %\n",
      "Epoch:50/200 AVG Training Loss:0.482 AVG Validation Loss:0.496 AVG Training Acc 80.25 % AVG Validation Acc 80.05 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.479 AVG Validation Loss:0.500 AVG Training Acc 80.31 % AVG Validation Acc 80.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.479 AVG Validation Loss:0.502 AVG Training Acc 80.36 % AVG Validation Acc 80.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.478 AVG Validation Loss:0.502 AVG Training Acc 80.26 % AVG Validation Acc 80.05 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.478 AVG Validation Loss:0.502 AVG Training Acc 80.28 % AVG Validation Acc 80.05 %\n",
      "Epoch:100/200 AVG Training Loss:0.479 AVG Validation Loss:0.502 AVG Training Acc 80.32 % AVG Validation Acc 80.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.478 AVG Validation Loss:0.502 AVG Training Acc 80.27 % AVG Validation Acc 80.05 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.478 AVG Validation Loss:0.502 AVG Training Acc 80.37 % AVG Validation Acc 80.05 %\n",
      "Epoch:130/200 AVG Training Loss:0.478 AVG Validation Loss:0.503 AVG Training Acc 80.28 % AVG Validation Acc 80.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.478 AVG Validation Loss:0.503 AVG Training Acc 80.33 % AVG Validation Acc 80.05 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.478 AVG Validation Loss:0.502 AVG Training Acc 80.28 % AVG Validation Acc 80.05 %\n",
      "Epoch:160/200 AVG Training Loss:0.477 AVG Validation Loss:0.502 AVG Training Acc 80.32 % AVG Validation Acc 80.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.478 AVG Validation Loss:0.502 AVG Training Acc 80.37 % AVG Validation Acc 80.05 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.478 AVG Validation Loss:0.502 AVG Training Acc 80.26 % AVG Validation Acc 80.05 %\n",
      "Epoch:190/200 AVG Training Loss:0.478 AVG Validation Loss:0.501 AVG Training Acc 80.23 % AVG Validation Acc 80.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.478 AVG Validation Loss:0.501 AVG Training Acc 80.17 % AVG Validation Acc 80.05 %\n",
      "Split 241\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db752d02279c4baaa9fe17b602aaca0b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.500 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.495 AVG Validation Loss:0.498 AVG Training Acc 80.10 % AVG Validation Acc 80.16 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.22 % AVG Validation Acc 80.07 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.21 % AVG Validation Acc 80.07 %\n",
      "Epoch:70/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.23 % AVG Validation Acc 80.07 %\n",
      "Epoch:80/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.23 % AVG Validation Acc 80.07 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.486 AVG Validation Loss:0.492 AVG Training Acc 80.23 % AVG Validation Acc 79.98 %\n",
      "Epoch:100/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.18 % AVG Validation Acc 79.98 %\n",
      "Epoch:110/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.25 % AVG Validation Acc 80.07 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.486 AVG Validation Loss:0.492 AVG Training Acc 80.27 % AVG Validation Acc 79.98 %\n",
      "Epoch:130/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.27 % AVG Validation Acc 79.98 %\n",
      "Epoch:140/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.23 % AVG Validation Acc 79.98 %\n",
      "Epoch:150/200 AVG Training Loss:0.486 AVG Validation Loss:0.492 AVG Training Acc 80.23 % AVG Validation Acc 79.98 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.24 % AVG Validation Acc 80.07 %\n",
      "Epoch:170/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.28 % AVG Validation Acc 79.98 %\n",
      "Epoch:180/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.27 % AVG Validation Acc 79.98 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.25 % AVG Validation Acc 79.98 %\n",
      "Epoch:200/200 AVG Training Loss:0.488 AVG Validation Loss:0.492 AVG Training Acc 80.30 % AVG Validation Acc 80.07 %\n",
      "Split 242\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "798f15a56f6e4a47b8f58fd4f21b414b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.497 AVG Validation Loss:0.498 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch    12: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.490 AVG Validation Loss:0.497 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.18 % AVG Validation Acc 80.16 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.486 AVG Validation Loss:0.495 AVG Training Acc 80.20 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.18 % AVG Validation Acc 80.16 %\n",
      "Epoch:90/200 AVG Training Loss:0.486 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:100/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:110/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch:120/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:130/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.18 % AVG Validation Acc 80.16 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:140/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.20 % AVG Validation Acc 80.16 %\n",
      "Epoch:150/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:160/200 AVG Training Loss:0.485 AVG Validation Loss:0.496 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:170/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch:180/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.09 % AVG Validation Acc 80.16 %\n",
      "Epoch:190/200 AVG Training Loss:0.484 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:200/200 AVG Training Loss:0.485 AVG Validation Loss:0.497 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Split 243\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eecd6f75c714184b759377ccc0b1fed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.20 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.493 AVG Training Acc 80.28 % AVG Validation Acc 80.07 %\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.480 AVG Validation Loss:0.497 AVG Training Acc 80.24 % AVG Validation Acc 80.07 %\n",
      "Epoch:60/200 AVG Training Loss:0.474 AVG Validation Loss:0.502 AVG Training Acc 80.41 % AVG Validation Acc 79.80 %\n",
      "Epoch:70/200 AVG Training Loss:0.470 AVG Validation Loss:0.505 AVG Training Acc 80.41 % AVG Validation Acc 79.80 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.468 AVG Validation Loss:0.508 AVG Training Acc 80.45 % AVG Validation Acc 79.80 %\n",
      "Epoch:90/200 AVG Training Loss:0.468 AVG Validation Loss:0.508 AVG Training Acc 80.52 % AVG Validation Acc 79.80 %\n",
      "Epoch:100/200 AVG Training Loss:0.467 AVG Validation Loss:0.508 AVG Training Acc 80.46 % AVG Validation Acc 79.80 %\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.467 AVG Validation Loss:0.509 AVG Training Acc 80.54 % AVG Validation Acc 79.80 %\n",
      "Epoch:120/200 AVG Training Loss:0.466 AVG Validation Loss:0.509 AVG Training Acc 80.50 % AVG Validation Acc 79.80 %\n",
      "Epoch:130/200 AVG Training Loss:0.467 AVG Validation Loss:0.508 AVG Training Acc 80.54 % AVG Validation Acc 79.80 %\n",
      "Epoch   134: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.468 AVG Validation Loss:0.509 AVG Training Acc 80.51 % AVG Validation Acc 79.80 %\n",
      "Epoch:150/200 AVG Training Loss:0.467 AVG Validation Loss:0.509 AVG Training Acc 80.57 % AVG Validation Acc 79.80 %\n",
      "Epoch:160/200 AVG Training Loss:0.467 AVG Validation Loss:0.510 AVG Training Acc 80.60 % AVG Validation Acc 79.80 %\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.467 AVG Validation Loss:0.510 AVG Training Acc 80.45 % AVG Validation Acc 79.80 %\n",
      "Epoch:180/200 AVG Training Loss:0.465 AVG Validation Loss:0.509 AVG Training Acc 80.56 % AVG Validation Acc 79.80 %\n",
      "Epoch:190/200 AVG Training Loss:0.467 AVG Validation Loss:0.509 AVG Training Acc 80.47 % AVG Validation Acc 79.80 %\n",
      "Epoch   196: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.467 AVG Validation Loss:0.509 AVG Training Acc 80.51 % AVG Validation Acc 79.80 %\n",
      "Split 244\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5c1cadd608f4b5ca1173ebfddfb4cfa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.490 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.487 AVG Validation Loss:0.497 AVG Training Acc 80.20 % AVG Validation Acc 79.98 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.481 AVG Validation Loss:0.501 AVG Training Acc 80.24 % AVG Validation Acc 79.98 %\n",
      "Epoch:50/200 AVG Training Loss:0.477 AVG Validation Loss:0.505 AVG Training Acc 80.46 % AVG Validation Acc 79.89 %\n",
      "Epoch:60/200 AVG Training Loss:0.473 AVG Validation Loss:0.506 AVG Training Acc 80.53 % AVG Validation Acc 79.71 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.471 AVG Validation Loss:0.510 AVG Training Acc 80.62 % AVG Validation Acc 79.80 %\n",
      "Epoch:80/200 AVG Training Loss:0.470 AVG Validation Loss:0.510 AVG Training Acc 80.55 % AVG Validation Acc 79.71 %\n",
      "Epoch:90/200 AVG Training Loss:0.469 AVG Validation Loss:0.511 AVG Training Acc 80.65 % AVG Validation Acc 79.80 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.469 AVG Validation Loss:0.509 AVG Training Acc 80.62 % AVG Validation Acc 79.80 %\n",
      "Epoch:110/200 AVG Training Loss:0.468 AVG Validation Loss:0.512 AVG Training Acc 80.75 % AVG Validation Acc 79.71 %\n",
      "Epoch:120/200 AVG Training Loss:0.468 AVG Validation Loss:0.511 AVG Training Acc 80.71 % AVG Validation Acc 79.80 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.468 AVG Validation Loss:0.514 AVG Training Acc 80.62 % AVG Validation Acc 79.71 %\n",
      "Epoch:140/200 AVG Training Loss:0.468 AVG Validation Loss:0.512 AVG Training Acc 80.64 % AVG Validation Acc 79.71 %\n",
      "Epoch:150/200 AVG Training Loss:0.468 AVG Validation Loss:0.510 AVG Training Acc 80.73 % AVG Validation Acc 79.62 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.468 AVG Validation Loss:0.514 AVG Training Acc 80.74 % AVG Validation Acc 79.80 %\n",
      "Epoch:170/200 AVG Training Loss:0.468 AVG Validation Loss:0.511 AVG Training Acc 80.65 % AVG Validation Acc 79.89 %\n",
      "Epoch:180/200 AVG Training Loss:0.468 AVG Validation Loss:0.512 AVG Training Acc 80.67 % AVG Validation Acc 79.62 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.469 AVG Validation Loss:0.509 AVG Training Acc 80.64 % AVG Validation Acc 79.71 %\n",
      "Epoch:200/200 AVG Training Loss:0.469 AVG Validation Loss:0.511 AVG Training Acc 80.70 % AVG Validation Acc 79.71 %\n",
      "Split 245\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7564c92ac3b4b1fbb1bd0f9073ff69c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.12 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.21 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.481 AVG Validation Loss:0.491 AVG Training Acc 80.37 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.475 AVG Validation Loss:0.514 AVG Training Acc 80.70 % AVG Validation Acc 80.07 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.453 AVG Validation Loss:0.515 AVG Training Acc 81.55 % AVG Validation Acc 79.71 %\n",
      "Epoch:70/200 AVG Training Loss:0.445 AVG Validation Loss:0.519 AVG Training Acc 81.84 % AVG Validation Acc 79.89 %\n",
      "Epoch:80/200 AVG Training Loss:0.441 AVG Validation Loss:0.532 AVG Training Acc 81.84 % AVG Validation Acc 79.80 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.436 AVG Validation Loss:0.538 AVG Training Acc 82.20 % AVG Validation Acc 79.53 %\n",
      "Epoch:100/200 AVG Training Loss:0.436 AVG Validation Loss:0.538 AVG Training Acc 82.16 % AVG Validation Acc 79.44 %\n",
      "Epoch:110/200 AVG Training Loss:0.434 AVG Validation Loss:0.547 AVG Training Acc 82.35 % AVG Validation Acc 79.53 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.437 AVG Validation Loss:0.546 AVG Training Acc 82.15 % AVG Validation Acc 79.08 %\n",
      "Epoch:130/200 AVG Training Loss:0.433 AVG Validation Loss:0.550 AVG Training Acc 82.20 % AVG Validation Acc 79.17 %\n",
      "Epoch:140/200 AVG Training Loss:0.436 AVG Validation Loss:0.553 AVG Training Acc 82.18 % AVG Validation Acc 79.62 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.433 AVG Validation Loss:0.539 AVG Training Acc 82.34 % AVG Validation Acc 79.53 %\n",
      "Epoch:160/200 AVG Training Loss:0.433 AVG Validation Loss:0.549 AVG Training Acc 82.26 % AVG Validation Acc 79.44 %\n",
      "Epoch:170/200 AVG Training Loss:0.433 AVG Validation Loss:0.546 AVG Training Acc 82.13 % AVG Validation Acc 79.08 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.435 AVG Validation Loss:0.551 AVG Training Acc 82.11 % AVG Validation Acc 79.17 %\n",
      "Epoch:190/200 AVG Training Loss:0.433 AVG Validation Loss:0.544 AVG Training Acc 82.14 % AVG Validation Acc 79.26 %\n",
      "Epoch:200/200 AVG Training Loss:0.434 AVG Validation Loss:0.549 AVG Training Acc 82.07 % AVG Validation Acc 79.35 %\n",
      "Split 246\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8fe0930784941618ceff48cf9ecc0d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.498 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.19 % AVG Validation Acc 80.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.491 AVG Training Acc 80.22 % AVG Validation Acc 80.23 %\n",
      "Epoch:50/200 AVG Training Loss:0.482 AVG Validation Loss:0.492 AVG Training Acc 80.44 % AVG Validation Acc 80.05 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.480 AVG Validation Loss:0.495 AVG Training Acc 80.38 % AVG Validation Acc 79.87 %\n",
      "Epoch:70/200 AVG Training Loss:0.477 AVG Validation Loss:0.493 AVG Training Acc 80.66 % AVG Validation Acc 79.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.476 AVG Validation Loss:0.494 AVG Training Acc 80.62 % AVG Validation Acc 79.87 %\n",
      "Epoch:90/200 AVG Training Loss:0.476 AVG Validation Loss:0.493 AVG Training Acc 80.59 % AVG Validation Acc 79.78 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.478 AVG Validation Loss:0.493 AVG Training Acc 80.59 % AVG Validation Acc 79.51 %\n",
      "Epoch:110/200 AVG Training Loss:0.475 AVG Validation Loss:0.495 AVG Training Acc 80.71 % AVG Validation Acc 79.60 %\n",
      "Epoch:120/200 AVG Training Loss:0.475 AVG Validation Loss:0.493 AVG Training Acc 80.73 % AVG Validation Acc 79.69 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.476 AVG Validation Loss:0.494 AVG Training Acc 80.53 % AVG Validation Acc 79.60 %\n",
      "Epoch:140/200 AVG Training Loss:0.477 AVG Validation Loss:0.494 AVG Training Acc 80.51 % AVG Validation Acc 79.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.475 AVG Validation Loss:0.492 AVG Training Acc 80.69 % AVG Validation Acc 79.87 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.475 AVG Validation Loss:0.494 AVG Training Acc 80.64 % AVG Validation Acc 79.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.477 AVG Validation Loss:0.493 AVG Training Acc 80.59 % AVG Validation Acc 79.87 %\n",
      "Epoch:180/200 AVG Training Loss:0.474 AVG Validation Loss:0.493 AVG Training Acc 80.61 % AVG Validation Acc 79.78 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.477 AVG Validation Loss:0.493 AVG Training Acc 80.53 % AVG Validation Acc 79.78 %\n",
      "Epoch:200/200 AVG Training Loss:0.475 AVG Validation Loss:0.493 AVG Training Acc 80.72 % AVG Validation Acc 79.60 %\n",
      "Split 247\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d16cf6a45281428c814c0ef0dfac87c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.499 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.490 AVG Validation Loss:0.500 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.484 AVG Validation Loss:0.501 AVG Training Acc 80.25 % AVG Validation Acc 80.14 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.481 AVG Validation Loss:0.503 AVG Training Acc 80.29 % AVG Validation Acc 79.96 %\n",
      "Epoch:50/200 AVG Training Loss:0.474 AVG Validation Loss:0.511 AVG Training Acc 80.56 % AVG Validation Acc 79.69 %\n",
      "Epoch:60/200 AVG Training Loss:0.469 AVG Validation Loss:0.518 AVG Training Acc 80.76 % AVG Validation Acc 79.33 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.466 AVG Validation Loss:0.520 AVG Training Acc 80.99 % AVG Validation Acc 79.24 %\n",
      "Epoch:80/200 AVG Training Loss:0.465 AVG Validation Loss:0.520 AVG Training Acc 81.04 % AVG Validation Acc 79.24 %\n",
      "Epoch:90/200 AVG Training Loss:0.464 AVG Validation Loss:0.522 AVG Training Acc 81.03 % AVG Validation Acc 79.06 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.463 AVG Validation Loss:0.523 AVG Training Acc 81.19 % AVG Validation Acc 79.15 %\n",
      "Epoch:110/200 AVG Training Loss:0.464 AVG Validation Loss:0.522 AVG Training Acc 81.13 % AVG Validation Acc 79.15 %\n",
      "Epoch:120/200 AVG Training Loss:0.464 AVG Validation Loss:0.524 AVG Training Acc 81.01 % AVG Validation Acc 79.24 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.465 AVG Validation Loss:0.523 AVG Training Acc 80.86 % AVG Validation Acc 79.15 %\n",
      "Epoch:140/200 AVG Training Loss:0.462 AVG Validation Loss:0.523 AVG Training Acc 81.17 % AVG Validation Acc 79.15 %\n",
      "Epoch:150/200 AVG Training Loss:0.464 AVG Validation Loss:0.523 AVG Training Acc 81.16 % AVG Validation Acc 79.15 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.463 AVG Validation Loss:0.522 AVG Training Acc 81.05 % AVG Validation Acc 79.06 %\n",
      "Epoch:170/200 AVG Training Loss:0.464 AVG Validation Loss:0.522 AVG Training Acc 81.11 % AVG Validation Acc 79.15 %\n",
      "Epoch:180/200 AVG Training Loss:0.463 AVG Validation Loss:0.522 AVG Training Acc 81.21 % AVG Validation Acc 79.15 %\n",
      "Epoch:190/200 AVG Training Loss:0.464 AVG Validation Loss:0.523 AVG Training Acc 81.03 % AVG Validation Acc 79.15 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.463 AVG Validation Loss:0.522 AVG Training Acc 81.08 % AVG Validation Acc 79.15 %\n",
      "Split 248\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b65db5a9241f4e4bba23e109ddbfa826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.492 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.25 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.483 AVG Validation Loss:0.493 AVG Training Acc 80.44 % AVG Validation Acc 80.05 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.478 AVG Validation Loss:0.502 AVG Training Acc 80.61 % AVG Validation Acc 79.51 %\n",
      "Epoch:60/200 AVG Training Loss:0.460 AVG Validation Loss:0.517 AVG Training Acc 81.45 % AVG Validation Acc 79.06 %\n",
      "Epoch:70/200 AVG Training Loss:0.453 AVG Validation Loss:0.529 AVG Training Acc 81.74 % AVG Validation Acc 78.34 %\n",
      "Epoch:80/200 AVG Training Loss:0.451 AVG Validation Loss:0.540 AVG Training Acc 81.86 % AVG Validation Acc 78.52 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.446 AVG Validation Loss:0.533 AVG Training Acc 81.84 % AVG Validation Acc 78.43 %\n",
      "Epoch:100/200 AVG Training Loss:0.445 AVG Validation Loss:0.534 AVG Training Acc 82.11 % AVG Validation Acc 78.43 %\n",
      "Epoch:110/200 AVG Training Loss:0.444 AVG Validation Loss:0.536 AVG Training Acc 82.08 % AVG Validation Acc 78.25 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.444 AVG Validation Loss:0.542 AVG Training Acc 82.11 % AVG Validation Acc 77.80 %\n",
      "Epoch:130/200 AVG Training Loss:0.444 AVG Validation Loss:0.546 AVG Training Acc 82.15 % AVG Validation Acc 78.25 %\n",
      "Epoch:140/200 AVG Training Loss:0.444 AVG Validation Loss:0.550 AVG Training Acc 82.21 % AVG Validation Acc 78.07 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.444 AVG Validation Loss:0.542 AVG Training Acc 82.16 % AVG Validation Acc 78.07 %\n",
      "Epoch:160/200 AVG Training Loss:0.444 AVG Validation Loss:0.542 AVG Training Acc 82.17 % AVG Validation Acc 78.07 %\n",
      "Epoch:170/200 AVG Training Loss:0.442 AVG Validation Loss:0.549 AVG Training Acc 82.03 % AVG Validation Acc 78.16 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.442 AVG Validation Loss:0.550 AVG Training Acc 82.22 % AVG Validation Acc 77.80 %\n",
      "Epoch:190/200 AVG Training Loss:0.444 AVG Validation Loss:0.545 AVG Training Acc 82.07 % AVG Validation Acc 77.62 %\n",
      "Epoch:200/200 AVG Training Loss:0.443 AVG Validation Loss:0.542 AVG Training Acc 82.36 % AVG Validation Acc 77.89 %\n",
      "Split 249\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d721796014b4389a0e23cf52def5e1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.477 AVG Validation Loss:0.496 AVG Training Acc 80.40 % AVG Validation Acc 79.96 %\n",
      "Epoch:50/200 AVG Training Loss:0.468 AVG Validation Loss:0.507 AVG Training Acc 80.79 % AVG Validation Acc 79.60 %\n",
      "Epoch:60/200 AVG Training Loss:0.459 AVG Validation Loss:0.516 AVG Training Acc 81.10 % AVG Validation Acc 79.51 %\n",
      "Epoch:70/200 AVG Training Loss:0.452 AVG Validation Loss:0.534 AVG Training Acc 81.35 % AVG Validation Acc 79.24 %\n",
      "Epoch    70: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.446 AVG Validation Loss:0.540 AVG Training Acc 81.64 % AVG Validation Acc 78.97 %\n",
      "Epoch:90/200 AVG Training Loss:0.445 AVG Validation Loss:0.540 AVG Training Acc 81.60 % AVG Validation Acc 78.97 %\n",
      "Epoch:100/200 AVG Training Loss:0.447 AVG Validation Loss:0.539 AVG Training Acc 81.55 % AVG Validation Acc 78.88 %\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.446 AVG Validation Loss:0.535 AVG Training Acc 81.57 % AVG Validation Acc 78.88 %\n",
      "Epoch:120/200 AVG Training Loss:0.444 AVG Validation Loss:0.544 AVG Training Acc 81.54 % AVG Validation Acc 78.97 %\n",
      "Epoch:130/200 AVG Training Loss:0.446 AVG Validation Loss:0.543 AVG Training Acc 81.53 % AVG Validation Acc 78.79 %\n",
      "Epoch   132: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.444 AVG Validation Loss:0.542 AVG Training Acc 81.61 % AVG Validation Acc 78.97 %\n",
      "Epoch:150/200 AVG Training Loss:0.445 AVG Validation Loss:0.543 AVG Training Acc 81.55 % AVG Validation Acc 79.06 %\n",
      "Epoch:160/200 AVG Training Loss:0.445 AVG Validation Loss:0.546 AVG Training Acc 81.61 % AVG Validation Acc 78.97 %\n",
      "Epoch   163: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.445 AVG Validation Loss:0.544 AVG Training Acc 81.53 % AVG Validation Acc 78.88 %\n",
      "Epoch:180/200 AVG Training Loss:0.443 AVG Validation Loss:0.549 AVG Training Acc 81.71 % AVG Validation Acc 78.97 %\n",
      "Epoch:190/200 AVG Training Loss:0.445 AVG Validation Loss:0.543 AVG Training Acc 81.60 % AVG Validation Acc 79.15 %\n",
      "Epoch   194: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.442 AVG Validation Loss:0.540 AVG Training Acc 81.72 % AVG Validation Acc 79.06 %\n",
      "Split 250\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b40d957a1440508e683a47b3b94c99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.499 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.23 % AVG Validation Acc 80.14 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.481 AVG Validation Loss:0.493 AVG Training Acc 80.44 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.473 AVG Validation Loss:0.498 AVG Training Acc 80.77 % AVG Validation Acc 79.78 %\n",
      "Epoch:60/200 AVG Training Loss:0.470 AVG Validation Loss:0.502 AVG Training Acc 80.94 % AVG Validation Acc 79.69 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.464 AVG Validation Loss:0.510 AVG Training Acc 81.19 % AVG Validation Acc 79.87 %\n",
      "Epoch:80/200 AVG Training Loss:0.463 AVG Validation Loss:0.517 AVG Training Acc 81.16 % AVG Validation Acc 79.69 %\n",
      "Epoch:90/200 AVG Training Loss:0.462 AVG Validation Loss:0.521 AVG Training Acc 81.31 % AVG Validation Acc 79.78 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.460 AVG Validation Loss:0.524 AVG Training Acc 81.30 % AVG Validation Acc 79.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.462 AVG Validation Loss:0.521 AVG Training Acc 81.23 % AVG Validation Acc 79.51 %\n",
      "Epoch:120/200 AVG Training Loss:0.461 AVG Validation Loss:0.524 AVG Training Acc 81.29 % AVG Validation Acc 79.51 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.463 AVG Validation Loss:0.521 AVG Training Acc 81.25 % AVG Validation Acc 79.51 %\n",
      "Epoch:140/200 AVG Training Loss:0.462 AVG Validation Loss:0.524 AVG Training Acc 81.29 % AVG Validation Acc 79.42 %\n",
      "Epoch:150/200 AVG Training Loss:0.460 AVG Validation Loss:0.521 AVG Training Acc 81.34 % AVG Validation Acc 79.60 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.461 AVG Validation Loss:0.520 AVG Training Acc 81.32 % AVG Validation Acc 79.51 %\n",
      "Epoch:170/200 AVG Training Loss:0.460 AVG Validation Loss:0.521 AVG Training Acc 81.31 % AVG Validation Acc 79.69 %\n",
      "Epoch:180/200 AVG Training Loss:0.462 AVG Validation Loss:0.520 AVG Training Acc 81.26 % AVG Validation Acc 79.60 %\n",
      "Epoch:190/200 AVG Training Loss:0.461 AVG Validation Loss:0.524 AVG Training Acc 81.28 % AVG Validation Acc 79.51 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.462 AVG Validation Loss:0.522 AVG Training Acc 81.22 % AVG Validation Acc 79.51 %\n",
      "Split 251\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6492c92ede6b4ea9ac219a0830944f60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.499 AVG Training Acc 80.18 % AVG Validation Acc 79.98 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.475 AVG Validation Loss:0.500 AVG Training Acc 80.43 % AVG Validation Acc 79.89 %\n",
      "Epoch:50/200 AVG Training Loss:0.467 AVG Validation Loss:0.511 AVG Training Acc 80.64 % AVG Validation Acc 79.80 %\n",
      "Epoch:60/200 AVG Training Loss:0.460 AVG Validation Loss:0.520 AVG Training Acc 80.81 % AVG Validation Acc 79.53 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.456 AVG Validation Loss:0.525 AVG Training Acc 80.92 % AVG Validation Acc 79.35 %\n",
      "Epoch:80/200 AVG Training Loss:0.454 AVG Validation Loss:0.535 AVG Training Acc 80.93 % AVG Validation Acc 79.17 %\n",
      "Epoch:90/200 AVG Training Loss:0.453 AVG Validation Loss:0.534 AVG Training Acc 81.11 % AVG Validation Acc 79.08 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.452 AVG Validation Loss:0.533 AVG Training Acc 80.98 % AVG Validation Acc 79.35 %\n",
      "Epoch:110/200 AVG Training Loss:0.450 AVG Validation Loss:0.539 AVG Training Acc 81.04 % AVG Validation Acc 79.17 %\n",
      "Epoch:120/200 AVG Training Loss:0.452 AVG Validation Loss:0.537 AVG Training Acc 80.96 % AVG Validation Acc 79.17 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.453 AVG Validation Loss:0.535 AVG Training Acc 81.16 % AVG Validation Acc 79.26 %\n",
      "Epoch:140/200 AVG Training Loss:0.451 AVG Validation Loss:0.537 AVG Training Acc 81.08 % AVG Validation Acc 79.35 %\n",
      "Epoch:150/200 AVG Training Loss:0.453 AVG Validation Loss:0.539 AVG Training Acc 81.07 % AVG Validation Acc 79.26 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.453 AVG Validation Loss:0.535 AVG Training Acc 81.04 % AVG Validation Acc 79.17 %\n",
      "Epoch:170/200 AVG Training Loss:0.451 AVG Validation Loss:0.533 AVG Training Acc 81.04 % AVG Validation Acc 79.26 %\n",
      "Epoch:180/200 AVG Training Loss:0.451 AVG Validation Loss:0.537 AVG Training Acc 81.06 % AVG Validation Acc 79.35 %\n",
      "Epoch:190/200 AVG Training Loss:0.451 AVG Validation Loss:0.537 AVG Training Acc 81.01 % AVG Validation Acc 79.35 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.451 AVG Validation Loss:0.534 AVG Training Acc 81.06 % AVG Validation Acc 79.35 %\n",
      "Split 252\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f60953f8878b44278a4270b148bf0be6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.494 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.18 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.506 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.490 AVG Validation Loss:0.501 AVG Training Acc 80.30 % AVG Validation Acc 79.98 %\n",
      "Epoch:60/200 AVG Training Loss:0.488 AVG Validation Loss:0.504 AVG Training Acc 80.34 % AVG Validation Acc 79.89 %\n",
      "Epoch:70/200 AVG Training Loss:0.484 AVG Validation Loss:0.508 AVG Training Acc 80.40 % AVG Validation Acc 79.89 %\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.482 AVG Validation Loss:0.512 AVG Training Acc 80.45 % AVG Validation Acc 79.89 %\n",
      "Epoch:90/200 AVG Training Loss:0.482 AVG Validation Loss:0.514 AVG Training Acc 80.40 % AVG Validation Acc 79.89 %\n",
      "Epoch:100/200 AVG Training Loss:0.482 AVG Validation Loss:0.514 AVG Training Acc 80.43 % AVG Validation Acc 79.89 %\n",
      "Epoch   104: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.481 AVG Validation Loss:0.515 AVG Training Acc 80.47 % AVG Validation Acc 79.89 %\n",
      "Epoch:120/200 AVG Training Loss:0.482 AVG Validation Loss:0.516 AVG Training Acc 80.40 % AVG Validation Acc 79.89 %\n",
      "Epoch:130/200 AVG Training Loss:0.481 AVG Validation Loss:0.516 AVG Training Acc 80.46 % AVG Validation Acc 79.80 %\n",
      "Epoch   135: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.480 AVG Validation Loss:0.515 AVG Training Acc 80.51 % AVG Validation Acc 79.89 %\n",
      "Epoch:150/200 AVG Training Loss:0.481 AVG Validation Loss:0.516 AVG Training Acc 80.44 % AVG Validation Acc 79.89 %\n",
      "Epoch:160/200 AVG Training Loss:0.482 AVG Validation Loss:0.515 AVG Training Acc 80.48 % AVG Validation Acc 79.89 %\n",
      "Epoch   166: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.481 AVG Validation Loss:0.515 AVG Training Acc 80.47 % AVG Validation Acc 79.89 %\n",
      "Epoch:180/200 AVG Training Loss:0.479 AVG Validation Loss:0.516 AVG Training Acc 80.48 % AVG Validation Acc 79.89 %\n",
      "Epoch:190/200 AVG Training Loss:0.482 AVG Validation Loss:0.516 AVG Training Acc 80.44 % AVG Validation Acc 79.89 %\n",
      "Epoch   197: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.481 AVG Validation Loss:0.515 AVG Training Acc 80.47 % AVG Validation Acc 79.89 %\n",
      "Split 253\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc0becba5cb046a1bd0f34a7514b050f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.497 AVG Training Acc 80.16 % AVG Validation Acc 80.07 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.484 AVG Validation Loss:0.498 AVG Training Acc 80.40 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.478 AVG Validation Loss:0.499 AVG Training Acc 80.51 % AVG Validation Acc 79.98 %\n",
      "Epoch:50/200 AVG Training Loss:0.475 AVG Validation Loss:0.498 AVG Training Acc 80.80 % AVG Validation Acc 80.25 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.472 AVG Validation Loss:0.504 AVG Training Acc 80.91 % AVG Validation Acc 79.80 %\n",
      "Epoch:70/200 AVG Training Loss:0.470 AVG Validation Loss:0.506 AVG Training Acc 81.01 % AVG Validation Acc 79.80 %\n",
      "Epoch:80/200 AVG Training Loss:0.469 AVG Validation Loss:0.505 AVG Training Acc 81.16 % AVG Validation Acc 79.80 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.469 AVG Validation Loss:0.507 AVG Training Acc 80.97 % AVG Validation Acc 79.80 %\n",
      "Epoch:100/200 AVG Training Loss:0.470 AVG Validation Loss:0.509 AVG Training Acc 80.99 % AVG Validation Acc 79.71 %\n",
      "Epoch:110/200 AVG Training Loss:0.467 AVG Validation Loss:0.507 AVG Training Acc 81.05 % AVG Validation Acc 79.71 %\n",
      "Epoch:120/200 AVG Training Loss:0.469 AVG Validation Loss:0.507 AVG Training Acc 81.06 % AVG Validation Acc 79.71 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.469 AVG Validation Loss:0.507 AVG Training Acc 81.15 % AVG Validation Acc 79.89 %\n",
      "Epoch:140/200 AVG Training Loss:0.469 AVG Validation Loss:0.508 AVG Training Acc 81.11 % AVG Validation Acc 79.80 %\n",
      "Epoch:150/200 AVG Training Loss:0.468 AVG Validation Loss:0.506 AVG Training Acc 81.07 % AVG Validation Acc 80.07 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.469 AVG Validation Loss:0.508 AVG Training Acc 81.02 % AVG Validation Acc 79.89 %\n",
      "Epoch:170/200 AVG Training Loss:0.468 AVG Validation Loss:0.507 AVG Training Acc 81.10 % AVG Validation Acc 79.80 %\n",
      "Epoch:180/200 AVG Training Loss:0.468 AVG Validation Loss:0.508 AVG Training Acc 81.10 % AVG Validation Acc 79.62 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.468 AVG Validation Loss:0.507 AVG Training Acc 81.12 % AVG Validation Acc 79.89 %\n",
      "Epoch:200/200 AVG Training Loss:0.468 AVG Validation Loss:0.510 AVG Training Acc 81.14 % AVG Validation Acc 79.98 %\n",
      "Split 254\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b0c05c5c0b746da971f0ff07e7c8e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.498 AVG Training Acc 80.15 % AVG Validation Acc 79.98 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.479 AVG Validation Loss:0.496 AVG Training Acc 80.18 % AVG Validation Acc 79.89 %\n",
      "Epoch:50/200 AVG Training Loss:0.473 AVG Validation Loss:0.502 AVG Training Acc 80.52 % AVG Validation Acc 79.89 %\n",
      "Epoch:60/200 AVG Training Loss:0.467 AVG Validation Loss:0.509 AVG Training Acc 80.86 % AVG Validation Acc 79.98 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.463 AVG Validation Loss:0.509 AVG Training Acc 80.93 % AVG Validation Acc 79.89 %\n",
      "Epoch:80/200 AVG Training Loss:0.462 AVG Validation Loss:0.508 AVG Training Acc 80.99 % AVG Validation Acc 79.71 %\n",
      "Epoch:90/200 AVG Training Loss:0.461 AVG Validation Loss:0.509 AVG Training Acc 80.83 % AVG Validation Acc 79.71 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.461 AVG Validation Loss:0.510 AVG Training Acc 80.87 % AVG Validation Acc 79.71 %\n",
      "Epoch:110/200 AVG Training Loss:0.461 AVG Validation Loss:0.509 AVG Training Acc 80.97 % AVG Validation Acc 79.71 %\n",
      "Epoch:120/200 AVG Training Loss:0.460 AVG Validation Loss:0.510 AVG Training Acc 81.09 % AVG Validation Acc 79.80 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.461 AVG Validation Loss:0.509 AVG Training Acc 80.87 % AVG Validation Acc 79.80 %\n",
      "Epoch:140/200 AVG Training Loss:0.463 AVG Validation Loss:0.510 AVG Training Acc 80.91 % AVG Validation Acc 79.71 %\n",
      "Epoch:150/200 AVG Training Loss:0.462 AVG Validation Loss:0.510 AVG Training Acc 81.07 % AVG Validation Acc 79.71 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.459 AVG Validation Loss:0.511 AVG Training Acc 81.14 % AVG Validation Acc 79.62 %\n",
      "Epoch:170/200 AVG Training Loss:0.461 AVG Validation Loss:0.510 AVG Training Acc 81.04 % AVG Validation Acc 79.71 %\n",
      "Epoch:180/200 AVG Training Loss:0.461 AVG Validation Loss:0.510 AVG Training Acc 80.98 % AVG Validation Acc 79.80 %\n",
      "Epoch   187: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.461 AVG Validation Loss:0.511 AVG Training Acc 81.04 % AVG Validation Acc 79.53 %\n",
      "Epoch:200/200 AVG Training Loss:0.460 AVG Validation Loss:0.509 AVG Training Acc 81.00 % AVG Validation Acc 79.62 %\n",
      "Split 255\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9de5d8a4c751434a90390ff2f5934464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.499 AVG Training Acc 80.11 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.496 AVG Training Acc 80.11 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.502 AVG Training Acc 80.18 % AVG Validation Acc 80.07 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.503 AVG Training Acc 80.39 % AVG Validation Acc 79.71 %\n",
      "Epoch:50/200 AVG Training Loss:0.483 AVG Validation Loss:0.506 AVG Training Acc 80.48 % AVG Validation Acc 79.53 %\n",
      "Epoch:60/200 AVG Training Loss:0.477 AVG Validation Loss:0.515 AVG Training Acc 80.68 % AVG Validation Acc 79.44 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.476 AVG Validation Loss:0.510 AVG Training Acc 80.86 % AVG Validation Acc 79.26 %\n",
      "Epoch:80/200 AVG Training Loss:0.476 AVG Validation Loss:0.511 AVG Training Acc 80.80 % AVG Validation Acc 79.53 %\n",
      "Epoch:90/200 AVG Training Loss:0.474 AVG Validation Loss:0.511 AVG Training Acc 80.84 % AVG Validation Acc 79.53 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.473 AVG Validation Loss:0.512 AVG Training Acc 80.87 % AVG Validation Acc 79.62 %\n",
      "Epoch:110/200 AVG Training Loss:0.474 AVG Validation Loss:0.512 AVG Training Acc 80.85 % AVG Validation Acc 79.62 %\n",
      "Epoch:120/200 AVG Training Loss:0.473 AVG Validation Loss:0.512 AVG Training Acc 80.91 % AVG Validation Acc 79.62 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.473 AVG Validation Loss:0.513 AVG Training Acc 80.92 % AVG Validation Acc 79.53 %\n",
      "Epoch:140/200 AVG Training Loss:0.474 AVG Validation Loss:0.513 AVG Training Acc 80.91 % AVG Validation Acc 79.62 %\n",
      "Epoch:150/200 AVG Training Loss:0.474 AVG Validation Loss:0.512 AVG Training Acc 80.87 % AVG Validation Acc 79.62 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.474 AVG Validation Loss:0.513 AVG Training Acc 80.87 % AVG Validation Acc 79.53 %\n",
      "Epoch:170/200 AVG Training Loss:0.474 AVG Validation Loss:0.514 AVG Training Acc 80.77 % AVG Validation Acc 79.53 %\n",
      "Epoch:180/200 AVG Training Loss:0.475 AVG Validation Loss:0.516 AVG Training Acc 80.78 % AVG Validation Acc 79.53 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.474 AVG Validation Loss:0.512 AVG Training Acc 80.93 % AVG Validation Acc 79.53 %\n",
      "Epoch:200/200 AVG Training Loss:0.474 AVG Validation Loss:0.517 AVG Training Acc 80.81 % AVG Validation Acc 79.62 %\n",
      "Split 256\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb546bb56cd4d309d6343e756babcc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.489 AVG Validation Loss:0.497 AVG Training Acc 80.18 % AVG Validation Acc 80.14 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.483 AVG Validation Loss:0.498 AVG Training Acc 80.25 % AVG Validation Acc 80.23 %\n",
      "Epoch:40/200 AVG Training Loss:0.478 AVG Validation Loss:0.501 AVG Training Acc 80.54 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.474 AVG Validation Loss:0.513 AVG Training Acc 80.67 % AVG Validation Acc 79.42 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.469 AVG Validation Loss:0.512 AVG Training Acc 80.86 % AVG Validation Acc 79.24 %\n",
      "Epoch:70/200 AVG Training Loss:0.467 AVG Validation Loss:0.518 AVG Training Acc 81.00 % AVG Validation Acc 79.06 %\n",
      "Epoch:80/200 AVG Training Loss:0.465 AVG Validation Loss:0.526 AVG Training Acc 81.08 % AVG Validation Acc 79.15 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.467 AVG Validation Loss:0.517 AVG Training Acc 81.01 % AVG Validation Acc 79.60 %\n",
      "Epoch:100/200 AVG Training Loss:0.465 AVG Validation Loss:0.521 AVG Training Acc 81.15 % AVG Validation Acc 79.42 %\n",
      "Epoch:110/200 AVG Training Loss:0.465 AVG Validation Loss:0.517 AVG Training Acc 80.99 % AVG Validation Acc 79.51 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.465 AVG Validation Loss:0.521 AVG Training Acc 81.09 % AVG Validation Acc 79.33 %\n",
      "Epoch:130/200 AVG Training Loss:0.465 AVG Validation Loss:0.519 AVG Training Acc 81.00 % AVG Validation Acc 79.24 %\n",
      "Epoch:140/200 AVG Training Loss:0.465 AVG Validation Loss:0.518 AVG Training Acc 81.07 % AVG Validation Acc 79.42 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.465 AVG Validation Loss:0.530 AVG Training Acc 81.06 % AVG Validation Acc 79.15 %\n",
      "Epoch:160/200 AVG Training Loss:0.464 AVG Validation Loss:0.518 AVG Training Acc 80.97 % AVG Validation Acc 79.51 %\n",
      "Epoch:170/200 AVG Training Loss:0.465 AVG Validation Loss:0.521 AVG Training Acc 81.07 % AVG Validation Acc 79.24 %\n",
      "Epoch:180/200 AVG Training Loss:0.467 AVG Validation Loss:0.519 AVG Training Acc 80.99 % AVG Validation Acc 79.51 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.465 AVG Validation Loss:0.516 AVG Training Acc 81.08 % AVG Validation Acc 79.51 %\n",
      "Epoch:200/200 AVG Training Loss:0.464 AVG Validation Loss:0.520 AVG Training Acc 81.11 % AVG Validation Acc 79.51 %\n",
      "Split 257\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c3d27487cf641e7a226eba07dcc20a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.29 % AVG Validation Acc 80.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.27 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.482 AVG Validation Loss:0.497 AVG Training Acc 80.42 % AVG Validation Acc 79.87 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.464 AVG Validation Loss:0.506 AVG Training Acc 80.56 % AVG Validation Acc 79.87 %\n",
      "Epoch:70/200 AVG Training Loss:0.458 AVG Validation Loss:0.520 AVG Training Acc 80.86 % AVG Validation Acc 79.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.453 AVG Validation Loss:0.528 AVG Training Acc 80.94 % AVG Validation Acc 79.15 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.447 AVG Validation Loss:0.536 AVG Training Acc 81.34 % AVG Validation Acc 78.79 %\n",
      "Epoch:100/200 AVG Training Loss:0.445 AVG Validation Loss:0.537 AVG Training Acc 81.23 % AVG Validation Acc 79.06 %\n",
      "Epoch:110/200 AVG Training Loss:0.444 AVG Validation Loss:0.536 AVG Training Acc 81.37 % AVG Validation Acc 78.88 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.442 AVG Validation Loss:0.535 AVG Training Acc 81.57 % AVG Validation Acc 79.06 %\n",
      "Epoch:130/200 AVG Training Loss:0.443 AVG Validation Loss:0.532 AVG Training Acc 81.49 % AVG Validation Acc 78.79 %\n",
      "Epoch:140/200 AVG Training Loss:0.442 AVG Validation Loss:0.534 AVG Training Acc 81.47 % AVG Validation Acc 78.97 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.441 AVG Validation Loss:0.536 AVG Training Acc 81.39 % AVG Validation Acc 79.06 %\n",
      "Epoch:160/200 AVG Training Loss:0.443 AVG Validation Loss:0.536 AVG Training Acc 81.45 % AVG Validation Acc 79.06 %\n",
      "Epoch:170/200 AVG Training Loss:0.441 AVG Validation Loss:0.539 AVG Training Acc 81.44 % AVG Validation Acc 78.79 %\n",
      "Epoch:180/200 AVG Training Loss:0.441 AVG Validation Loss:0.538 AVG Training Acc 81.55 % AVG Validation Acc 78.52 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.442 AVG Validation Loss:0.539 AVG Training Acc 81.49 % AVG Validation Acc 79.15 %\n",
      "Epoch:200/200 AVG Training Loss:0.440 AVG Validation Loss:0.536 AVG Training Acc 81.59 % AVG Validation Acc 78.97 %\n",
      "Split 258\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5b17747c35f45e892e16b1ab83c4ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.497 AVG Validation Loss:0.499 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.497 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.489 AVG Training Acc 80.30 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.479 AVG Validation Loss:0.493 AVG Training Acc 80.44 % AVG Validation Acc 80.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.476 AVG Validation Loss:0.499 AVG Training Acc 80.61 % AVG Validation Acc 80.14 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.471 AVG Validation Loss:0.507 AVG Training Acc 80.78 % AVG Validation Acc 79.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.470 AVG Validation Loss:0.509 AVG Training Acc 80.78 % AVG Validation Acc 79.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.470 AVG Validation Loss:0.511 AVG Training Acc 80.84 % AVG Validation Acc 79.87 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.468 AVG Validation Loss:0.511 AVG Training Acc 80.86 % AVG Validation Acc 79.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.470 AVG Validation Loss:0.513 AVG Training Acc 80.86 % AVG Validation Acc 79.69 %\n",
      "Epoch:120/200 AVG Training Loss:0.469 AVG Validation Loss:0.513 AVG Training Acc 80.91 % AVG Validation Acc 79.78 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.469 AVG Validation Loss:0.512 AVG Training Acc 80.88 % AVG Validation Acc 79.69 %\n",
      "Epoch:140/200 AVG Training Loss:0.469 AVG Validation Loss:0.510 AVG Training Acc 80.80 % AVG Validation Acc 79.87 %\n",
      "Epoch:150/200 AVG Training Loss:0.467 AVG Validation Loss:0.512 AVG Training Acc 80.86 % AVG Validation Acc 79.87 %\n",
      "Epoch:160/200 AVG Training Loss:0.469 AVG Validation Loss:0.512 AVG Training Acc 80.82 % AVG Validation Acc 79.78 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.470 AVG Validation Loss:0.512 AVG Training Acc 80.78 % AVG Validation Acc 79.60 %\n",
      "Epoch:180/200 AVG Training Loss:0.469 AVG Validation Loss:0.513 AVG Training Acc 80.89 % AVG Validation Acc 79.87 %\n",
      "Epoch:190/200 AVG Training Loss:0.470 AVG Validation Loss:0.513 AVG Training Acc 80.92 % AVG Validation Acc 79.87 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.469 AVG Validation Loss:0.513 AVG Training Acc 80.91 % AVG Validation Acc 79.78 %\n",
      "Split 259\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf638f647f2145f4946f0ceb721a843b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.31 % AVG Validation Acc 79.78 %\n",
      "Epoch:40/200 AVG Training Loss:0.477 AVG Validation Loss:0.501 AVG Training Acc 80.71 % AVG Validation Acc 79.87 %\n",
      "Epoch:50/200 AVG Training Loss:0.472 AVG Validation Loss:0.512 AVG Training Acc 80.96 % AVG Validation Acc 80.14 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.468 AVG Validation Loss:0.518 AVG Training Acc 81.16 % AVG Validation Acc 79.69 %\n",
      "Epoch:70/200 AVG Training Loss:0.466 AVG Validation Loss:0.519 AVG Training Acc 81.25 % AVG Validation Acc 79.69 %\n",
      "Epoch:80/200 AVG Training Loss:0.465 AVG Validation Loss:0.521 AVG Training Acc 81.33 % AVG Validation Acc 79.78 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.465 AVG Validation Loss:0.522 AVG Training Acc 81.35 % AVG Validation Acc 79.78 %\n",
      "Epoch:100/200 AVG Training Loss:0.466 AVG Validation Loss:0.521 AVG Training Acc 81.19 % AVG Validation Acc 79.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.464 AVG Validation Loss:0.522 AVG Training Acc 81.38 % AVG Validation Acc 79.69 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.465 AVG Validation Loss:0.521 AVG Training Acc 81.26 % AVG Validation Acc 79.78 %\n",
      "Epoch:130/200 AVG Training Loss:0.465 AVG Validation Loss:0.524 AVG Training Acc 81.35 % AVG Validation Acc 79.69 %\n",
      "Epoch:140/200 AVG Training Loss:0.463 AVG Validation Loss:0.522 AVG Training Acc 81.31 % AVG Validation Acc 79.87 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.465 AVG Validation Loss:0.524 AVG Training Acc 81.37 % AVG Validation Acc 79.69 %\n",
      "Epoch:160/200 AVG Training Loss:0.464 AVG Validation Loss:0.521 AVG Training Acc 81.35 % AVG Validation Acc 79.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.464 AVG Validation Loss:0.523 AVG Training Acc 81.36 % AVG Validation Acc 79.69 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.463 AVG Validation Loss:0.523 AVG Training Acc 81.34 % AVG Validation Acc 79.60 %\n",
      "Epoch:190/200 AVG Training Loss:0.464 AVG Validation Loss:0.521 AVG Training Acc 81.40 % AVG Validation Acc 79.87 %\n",
      "Epoch:200/200 AVG Training Loss:0.463 AVG Validation Loss:0.522 AVG Training Acc 81.41 % AVG Validation Acc 79.87 %\n",
      "Split 260\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d3157f43e9248b896a1e1e971cfe1a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.492 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.494 AVG Training Acc 80.12 % AVG Validation Acc 80.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.483 AVG Validation Loss:0.502 AVG Training Acc 80.42 % AVG Validation Acc 80.23 %\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.475 AVG Validation Loss:0.509 AVG Training Acc 80.63 % AVG Validation Acc 79.24 %\n",
      "Epoch:60/200 AVG Training Loss:0.467 AVG Validation Loss:0.519 AVG Training Acc 80.80 % AVG Validation Acc 78.97 %\n",
      "Epoch:70/200 AVG Training Loss:0.460 AVG Validation Loss:0.526 AVG Training Acc 81.07 % AVG Validation Acc 78.70 %\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.457 AVG Validation Loss:0.532 AVG Training Acc 81.19 % AVG Validation Acc 78.88 %\n",
      "Epoch:90/200 AVG Training Loss:0.456 AVG Validation Loss:0.535 AVG Training Acc 81.08 % AVG Validation Acc 78.79 %\n",
      "Epoch:100/200 AVG Training Loss:0.456 AVG Validation Loss:0.537 AVG Training Acc 81.26 % AVG Validation Acc 78.79 %\n",
      "Epoch   106: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.455 AVG Validation Loss:0.533 AVG Training Acc 81.20 % AVG Validation Acc 78.79 %\n",
      "Epoch:120/200 AVG Training Loss:0.456 AVG Validation Loss:0.530 AVG Training Acc 81.18 % AVG Validation Acc 78.88 %\n",
      "Epoch:130/200 AVG Training Loss:0.456 AVG Validation Loss:0.534 AVG Training Acc 81.19 % AVG Validation Acc 78.61 %\n",
      "Epoch   137: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.455 AVG Validation Loss:0.533 AVG Training Acc 81.25 % AVG Validation Acc 78.97 %\n",
      "Epoch:150/200 AVG Training Loss:0.454 AVG Validation Loss:0.536 AVG Training Acc 81.16 % AVG Validation Acc 78.70 %\n",
      "Epoch:160/200 AVG Training Loss:0.454 AVG Validation Loss:0.535 AVG Training Acc 81.25 % AVG Validation Acc 78.61 %\n",
      "Epoch   168: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.455 AVG Validation Loss:0.537 AVG Training Acc 81.23 % AVG Validation Acc 78.61 %\n",
      "Epoch:180/200 AVG Training Loss:0.454 AVG Validation Loss:0.538 AVG Training Acc 81.29 % AVG Validation Acc 78.70 %\n",
      "Epoch:190/200 AVG Training Loss:0.455 AVG Validation Loss:0.536 AVG Training Acc 81.19 % AVG Validation Acc 78.88 %\n",
      "Epoch   199: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.455 AVG Validation Loss:0.531 AVG Training Acc 81.25 % AVG Validation Acc 78.88 %\n",
      "Split 261\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf204861dc1e4c54a52347bf489bf34c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.500 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.490 AVG Validation Loss:0.497 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.484 AVG Validation Loss:0.503 AVG Training Acc 80.32 % AVG Validation Acc 79.62 %\n",
      "Epoch:40/200 AVG Training Loss:0.480 AVG Validation Loss:0.506 AVG Training Acc 80.37 % AVG Validation Acc 79.53 %\n",
      "Epoch:50/200 AVG Training Loss:0.476 AVG Validation Loss:0.501 AVG Training Acc 80.57 % AVG Validation Acc 79.71 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.473 AVG Validation Loss:0.505 AVG Training Acc 80.64 % AVG Validation Acc 79.53 %\n",
      "Epoch:70/200 AVG Training Loss:0.471 AVG Validation Loss:0.507 AVG Training Acc 80.67 % AVG Validation Acc 79.62 %\n",
      "Epoch:80/200 AVG Training Loss:0.470 AVG Validation Loss:0.508 AVG Training Acc 80.76 % AVG Validation Acc 79.62 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.470 AVG Validation Loss:0.507 AVG Training Acc 80.76 % AVG Validation Acc 79.62 %\n",
      "Epoch:100/200 AVG Training Loss:0.470 AVG Validation Loss:0.508 AVG Training Acc 80.65 % AVG Validation Acc 79.53 %\n",
      "Epoch:110/200 AVG Training Loss:0.470 AVG Validation Loss:0.508 AVG Training Acc 80.76 % AVG Validation Acc 79.44 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.468 AVG Validation Loss:0.506 AVG Training Acc 80.61 % AVG Validation Acc 79.80 %\n",
      "Epoch:130/200 AVG Training Loss:0.470 AVG Validation Loss:0.508 AVG Training Acc 80.64 % AVG Validation Acc 79.62 %\n",
      "Epoch:140/200 AVG Training Loss:0.468 AVG Validation Loss:0.508 AVG Training Acc 80.69 % AVG Validation Acc 79.53 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.469 AVG Validation Loss:0.508 AVG Training Acc 80.66 % AVG Validation Acc 79.71 %\n",
      "Epoch:160/200 AVG Training Loss:0.467 AVG Validation Loss:0.509 AVG Training Acc 80.76 % AVG Validation Acc 79.44 %\n",
      "Epoch:170/200 AVG Training Loss:0.467 AVG Validation Loss:0.509 AVG Training Acc 80.73 % AVG Validation Acc 79.53 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.469 AVG Validation Loss:0.509 AVG Training Acc 80.67 % AVG Validation Acc 79.53 %\n",
      "Epoch:190/200 AVG Training Loss:0.469 AVG Validation Loss:0.510 AVG Training Acc 80.67 % AVG Validation Acc 79.53 %\n",
      "Epoch:200/200 AVG Training Loss:0.468 AVG Validation Loss:0.509 AVG Training Acc 80.78 % AVG Validation Acc 79.44 %\n",
      "Split 262\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e332e0ebfaa8425e8e72897a53957129",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.493 AVG Training Acc 80.18 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.29 % AVG Validation Acc 80.07 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.475 AVG Validation Loss:0.499 AVG Training Acc 80.35 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.472 AVG Validation Loss:0.504 AVG Training Acc 80.52 % AVG Validation Acc 80.07 %\n",
      "Epoch:60/200 AVG Training Loss:0.470 AVG Validation Loss:0.506 AVG Training Acc 80.48 % AVG Validation Acc 79.89 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.468 AVG Validation Loss:0.515 AVG Training Acc 80.55 % AVG Validation Acc 79.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.467 AVG Validation Loss:0.518 AVG Training Acc 80.55 % AVG Validation Acc 79.98 %\n",
      "Epoch:90/200 AVG Training Loss:0.466 AVG Validation Loss:0.519 AVG Training Acc 80.56 % AVG Validation Acc 79.98 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.465 AVG Validation Loss:0.521 AVG Training Acc 80.63 % AVG Validation Acc 79.89 %\n",
      "Epoch:110/200 AVG Training Loss:0.466 AVG Validation Loss:0.522 AVG Training Acc 80.60 % AVG Validation Acc 79.98 %\n",
      "Epoch:120/200 AVG Training Loss:0.466 AVG Validation Loss:0.522 AVG Training Acc 80.60 % AVG Validation Acc 79.98 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.466 AVG Validation Loss:0.523 AVG Training Acc 80.54 % AVG Validation Acc 79.89 %\n",
      "Epoch:140/200 AVG Training Loss:0.467 AVG Validation Loss:0.520 AVG Training Acc 80.58 % AVG Validation Acc 79.98 %\n",
      "Epoch:150/200 AVG Training Loss:0.467 AVG Validation Loss:0.520 AVG Training Acc 80.57 % AVG Validation Acc 79.98 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.466 AVG Validation Loss:0.519 AVG Training Acc 80.60 % AVG Validation Acc 79.98 %\n",
      "Epoch:170/200 AVG Training Loss:0.466 AVG Validation Loss:0.520 AVG Training Acc 80.58 % AVG Validation Acc 79.98 %\n",
      "Epoch:180/200 AVG Training Loss:0.465 AVG Validation Loss:0.521 AVG Training Acc 80.61 % AVG Validation Acc 79.89 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.466 AVG Validation Loss:0.521 AVG Training Acc 80.68 % AVG Validation Acc 79.98 %\n",
      "Epoch:200/200 AVG Training Loss:0.466 AVG Validation Loss:0.521 AVG Training Acc 80.53 % AVG Validation Acc 79.98 %\n",
      "Split 263\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "610316aa2d5f4763b55b0429e5920f5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.491 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.491 AVG Training Acc 80.19 % AVG Validation Acc 80.16 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.484 AVG Validation Loss:0.491 AVG Training Acc 80.25 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.485 AVG Validation Loss:0.492 AVG Training Acc 80.24 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.484 AVG Validation Loss:0.491 AVG Training Acc 80.32 % AVG Validation Acc 80.07 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.484 AVG Validation Loss:0.493 AVG Training Acc 80.26 % AVG Validation Acc 79.98 %\n",
      "Epoch:90/200 AVG Training Loss:0.484 AVG Validation Loss:0.492 AVG Training Acc 80.27 % AVG Validation Acc 79.98 %\n",
      "Epoch:100/200 AVG Training Loss:0.484 AVG Validation Loss:0.493 AVG Training Acc 80.31 % AVG Validation Acc 79.98 %\n",
      "Epoch:110/200 AVG Training Loss:0.484 AVG Validation Loss:0.492 AVG Training Acc 80.29 % AVG Validation Acc 79.98 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.483 AVG Validation Loss:0.493 AVG Training Acc 80.32 % AVG Validation Acc 79.98 %\n",
      "Epoch:130/200 AVG Training Loss:0.484 AVG Validation Loss:0.493 AVG Training Acc 80.34 % AVG Validation Acc 79.98 %\n",
      "Epoch:140/200 AVG Training Loss:0.484 AVG Validation Loss:0.492 AVG Training Acc 80.29 % AVG Validation Acc 79.98 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.484 AVG Validation Loss:0.492 AVG Training Acc 80.31 % AVG Validation Acc 79.98 %\n",
      "Epoch:160/200 AVG Training Loss:0.484 AVG Validation Loss:0.492 AVG Training Acc 80.31 % AVG Validation Acc 79.98 %\n",
      "Epoch:170/200 AVG Training Loss:0.483 AVG Validation Loss:0.493 AVG Training Acc 80.35 % AVG Validation Acc 79.98 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.484 AVG Validation Loss:0.492 AVG Training Acc 80.23 % AVG Validation Acc 79.98 %\n",
      "Epoch:190/200 AVG Training Loss:0.484 AVG Validation Loss:0.492 AVG Training Acc 80.30 % AVG Validation Acc 79.98 %\n",
      "Epoch:200/200 AVG Training Loss:0.484 AVG Validation Loss:0.492 AVG Training Acc 80.28 % AVG Validation Acc 79.98 %\n",
      "Split 264\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a06a6e3e94e04651aa1ee31a0f7c9949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.18 % AVG Validation Acc 80.07 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.478 AVG Validation Loss:0.498 AVG Training Acc 80.52 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.474 AVG Validation Loss:0.501 AVG Training Acc 80.45 % AVG Validation Acc 80.25 %\n",
      "Epoch:60/200 AVG Training Loss:0.467 AVG Validation Loss:0.504 AVG Training Acc 80.76 % AVG Validation Acc 80.16 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.462 AVG Validation Loss:0.507 AVG Training Acc 80.76 % AVG Validation Acc 80.34 %\n",
      "Epoch:80/200 AVG Training Loss:0.462 AVG Validation Loss:0.508 AVG Training Acc 80.93 % AVG Validation Acc 80.07 %\n",
      "Epoch:90/200 AVG Training Loss:0.459 AVG Validation Loss:0.509 AVG Training Acc 80.97 % AVG Validation Acc 80.16 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.458 AVG Validation Loss:0.509 AVG Training Acc 81.04 % AVG Validation Acc 80.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.459 AVG Validation Loss:0.508 AVG Training Acc 81.00 % AVG Validation Acc 79.98 %\n",
      "Epoch:120/200 AVG Training Loss:0.460 AVG Validation Loss:0.508 AVG Training Acc 80.97 % AVG Validation Acc 80.07 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.458 AVG Validation Loss:0.508 AVG Training Acc 81.04 % AVG Validation Acc 79.98 %\n",
      "Epoch:140/200 AVG Training Loss:0.459 AVG Validation Loss:0.509 AVG Training Acc 80.93 % AVG Validation Acc 79.98 %\n",
      "Epoch:150/200 AVG Training Loss:0.460 AVG Validation Loss:0.512 AVG Training Acc 81.06 % AVG Validation Acc 80.07 %\n",
      "Epoch   159: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.459 AVG Validation Loss:0.508 AVG Training Acc 81.05 % AVG Validation Acc 80.07 %\n",
      "Epoch:170/200 AVG Training Loss:0.459 AVG Validation Loss:0.510 AVG Training Acc 81.03 % AVG Validation Acc 80.16 %\n",
      "Epoch:180/200 AVG Training Loss:0.458 AVG Validation Loss:0.508 AVG Training Acc 80.86 % AVG Validation Acc 80.16 %\n",
      "Epoch:190/200 AVG Training Loss:0.458 AVG Validation Loss:0.510 AVG Training Acc 81.14 % AVG Validation Acc 80.07 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.460 AVG Validation Loss:0.510 AVG Training Acc 80.95 % AVG Validation Acc 80.07 %\n",
      "Split 265\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4223a5a52d044c89f07559cd6fb413a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.496 AVG Training Acc 80.20 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.492 AVG Training Acc 80.34 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.496 AVG Training Acc 80.24 % AVG Validation Acc 79.89 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.477 AVG Validation Loss:0.506 AVG Training Acc 80.71 % AVG Validation Acc 79.44 %\n",
      "Epoch:70/200 AVG Training Loss:0.472 AVG Validation Loss:0.521 AVG Training Acc 80.86 % AVG Validation Acc 79.62 %\n",
      "Epoch:80/200 AVG Training Loss:0.468 AVG Validation Loss:0.534 AVG Training Acc 81.00 % AVG Validation Acc 79.35 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.465 AVG Validation Loss:0.527 AVG Training Acc 81.07 % AVG Validation Acc 79.53 %\n",
      "Epoch:100/200 AVG Training Loss:0.466 AVG Validation Loss:0.526 AVG Training Acc 81.03 % AVG Validation Acc 79.35 %\n",
      "Epoch:110/200 AVG Training Loss:0.464 AVG Validation Loss:0.537 AVG Training Acc 81.05 % AVG Validation Acc 78.90 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.464 AVG Validation Loss:0.542 AVG Training Acc 80.98 % AVG Validation Acc 78.99 %\n",
      "Epoch:130/200 AVG Training Loss:0.463 AVG Validation Loss:0.534 AVG Training Acc 81.11 % AVG Validation Acc 78.90 %\n",
      "Epoch:140/200 AVG Training Loss:0.465 AVG Validation Loss:0.540 AVG Training Acc 81.08 % AVG Validation Acc 79.17 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.463 AVG Validation Loss:0.534 AVG Training Acc 81.03 % AVG Validation Acc 79.17 %\n",
      "Epoch:160/200 AVG Training Loss:0.464 AVG Validation Loss:0.537 AVG Training Acc 81.09 % AVG Validation Acc 79.08 %\n",
      "Epoch:170/200 AVG Training Loss:0.462 AVG Validation Loss:0.538 AVG Training Acc 81.19 % AVG Validation Acc 78.99 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.464 AVG Validation Loss:0.538 AVG Training Acc 81.11 % AVG Validation Acc 79.08 %\n",
      "Epoch:190/200 AVG Training Loss:0.462 AVG Validation Loss:0.537 AVG Training Acc 81.22 % AVG Validation Acc 79.08 %\n",
      "Epoch:200/200 AVG Training Loss:0.460 AVG Validation Loss:0.538 AVG Training Acc 81.16 % AVG Validation Acc 78.90 %\n",
      "Split 266\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b58096cac1964d03aa772617327b9504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.492 AVG Training Acc 80.22 % AVG Validation Acc 80.23 %\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.39 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.498 AVG Validation Loss:0.494 AVG Training Acc 80.04 % AVG Validation Acc 80.14 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.486 AVG Validation Loss:0.486 AVG Training Acc 80.31 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.485 AVG Validation Loss:0.486 AVG Training Acc 80.37 % AVG Validation Acc 80.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.480 AVG Validation Loss:0.489 AVG Training Acc 80.52 % AVG Validation Acc 79.96 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.478 AVG Validation Loss:0.490 AVG Training Acc 80.62 % AVG Validation Acc 79.87 %\n",
      "Epoch:100/200 AVG Training Loss:0.478 AVG Validation Loss:0.489 AVG Training Acc 80.66 % AVG Validation Acc 79.96 %\n",
      "Epoch:110/200 AVG Training Loss:0.479 AVG Validation Loss:0.489 AVG Training Acc 80.63 % AVG Validation Acc 79.69 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.479 AVG Validation Loss:0.487 AVG Training Acc 80.49 % AVG Validation Acc 80.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.478 AVG Validation Loss:0.489 AVG Training Acc 80.69 % AVG Validation Acc 79.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.477 AVG Validation Loss:0.489 AVG Training Acc 80.72 % AVG Validation Acc 79.78 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.479 AVG Validation Loss:0.488 AVG Training Acc 80.67 % AVG Validation Acc 79.69 %\n",
      "Epoch:160/200 AVG Training Loss:0.478 AVG Validation Loss:0.491 AVG Training Acc 80.74 % AVG Validation Acc 79.96 %\n",
      "Epoch:170/200 AVG Training Loss:0.478 AVG Validation Loss:0.489 AVG Training Acc 80.66 % AVG Validation Acc 79.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.478 AVG Validation Loss:0.489 AVG Training Acc 80.75 % AVG Validation Acc 79.87 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.477 AVG Validation Loss:0.489 AVG Training Acc 80.67 % AVG Validation Acc 79.87 %\n",
      "Epoch:200/200 AVG Training Loss:0.478 AVG Validation Loss:0.489 AVG Training Acc 80.71 % AVG Validation Acc 79.87 %\n",
      "Split 267\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc7bf022fe28430daa6e0ca610714e6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.499 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.498 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.486 AVG Validation Loss:0.498 AVG Training Acc 80.27 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.35 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.477 AVG Validation Loss:0.499 AVG Training Acc 80.37 % AVG Validation Acc 80.14 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.471 AVG Validation Loss:0.501 AVG Training Acc 80.79 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.469 AVG Validation Loss:0.504 AVG Training Acc 80.86 % AVG Validation Acc 80.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.469 AVG Validation Loss:0.504 AVG Training Acc 80.77 % AVG Validation Acc 80.14 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.468 AVG Validation Loss:0.503 AVG Training Acc 80.87 % AVG Validation Acc 80.23 %\n",
      "Epoch:100/200 AVG Training Loss:0.469 AVG Validation Loss:0.503 AVG Training Acc 80.78 % AVG Validation Acc 80.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.469 AVG Validation Loss:0.502 AVG Training Acc 80.88 % AVG Validation Acc 80.23 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.468 AVG Validation Loss:0.505 AVG Training Acc 80.81 % AVG Validation Acc 80.23 %\n",
      "Epoch:130/200 AVG Training Loss:0.469 AVG Validation Loss:0.503 AVG Training Acc 80.88 % AVG Validation Acc 80.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.469 AVG Validation Loss:0.503 AVG Training Acc 80.84 % AVG Validation Acc 80.23 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.470 AVG Validation Loss:0.502 AVG Training Acc 80.78 % AVG Validation Acc 80.32 %\n",
      "Epoch:160/200 AVG Training Loss:0.469 AVG Validation Loss:0.502 AVG Training Acc 80.81 % AVG Validation Acc 80.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.467 AVG Validation Loss:0.503 AVG Training Acc 80.74 % AVG Validation Acc 80.14 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.467 AVG Validation Loss:0.501 AVG Training Acc 80.86 % AVG Validation Acc 80.23 %\n",
      "Epoch:190/200 AVG Training Loss:0.469 AVG Validation Loss:0.502 AVG Training Acc 80.82 % AVG Validation Acc 80.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.468 AVG Validation Loss:0.501 AVG Training Acc 80.87 % AVG Validation Acc 80.32 %\n",
      "Split 268\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "898749a85aa04b22a95f3322dd6f60ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.493 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.485 AVG Validation Loss:0.492 AVG Training Acc 80.16 % AVG Validation Acc 80.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.480 AVG Validation Loss:0.497 AVG Training Acc 80.35 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.476 AVG Validation Loss:0.503 AVG Training Acc 80.35 % AVG Validation Acc 80.14 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.469 AVG Validation Loss:0.511 AVG Training Acc 80.54 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.468 AVG Validation Loss:0.514 AVG Training Acc 80.58 % AVG Validation Acc 80.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.467 AVG Validation Loss:0.516 AVG Training Acc 80.69 % AVG Validation Acc 79.69 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.467 AVG Validation Loss:0.519 AVG Training Acc 80.77 % AVG Validation Acc 79.78 %\n",
      "Epoch:100/200 AVG Training Loss:0.466 AVG Validation Loss:0.524 AVG Training Acc 80.74 % AVG Validation Acc 79.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.466 AVG Validation Loss:0.520 AVG Training Acc 80.70 % AVG Validation Acc 79.69 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.467 AVG Validation Loss:0.524 AVG Training Acc 80.80 % AVG Validation Acc 79.69 %\n",
      "Epoch:130/200 AVG Training Loss:0.466 AVG Validation Loss:0.522 AVG Training Acc 80.80 % AVG Validation Acc 79.60 %\n",
      "Epoch:140/200 AVG Training Loss:0.467 AVG Validation Loss:0.524 AVG Training Acc 80.72 % AVG Validation Acc 79.60 %\n",
      "Epoch:150/200 AVG Training Loss:0.466 AVG Validation Loss:0.523 AVG Training Acc 80.78 % AVG Validation Acc 79.69 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.466 AVG Validation Loss:0.519 AVG Training Acc 80.83 % AVG Validation Acc 79.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.467 AVG Validation Loss:0.522 AVG Training Acc 80.80 % AVG Validation Acc 79.69 %\n",
      "Epoch:180/200 AVG Training Loss:0.466 AVG Validation Loss:0.523 AVG Training Acc 80.79 % AVG Validation Acc 79.69 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.466 AVG Validation Loss:0.521 AVG Training Acc 80.75 % AVG Validation Acc 79.78 %\n",
      "Epoch:200/200 AVG Training Loss:0.467 AVG Validation Loss:0.524 AVG Training Acc 80.73 % AVG Validation Acc 79.69 %\n",
      "Split 269\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b76ac972c06442729472fb4db51d6c2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.492 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.487 AVG Validation Loss:0.489 AVG Training Acc 80.26 % AVG Validation Acc 80.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.483 AVG Validation Loss:0.495 AVG Training Acc 80.47 % AVG Validation Acc 79.96 %\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.468 AVG Validation Loss:0.507 AVG Training Acc 81.11 % AVG Validation Acc 79.15 %\n",
      "Epoch:60/200 AVG Training Loss:0.460 AVG Validation Loss:0.516 AVG Training Acc 81.44 % AVG Validation Acc 78.61 %\n",
      "Epoch:70/200 AVG Training Loss:0.450 AVG Validation Loss:0.525 AVG Training Acc 81.98 % AVG Validation Acc 78.97 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.449 AVG Validation Loss:0.528 AVG Training Acc 81.94 % AVG Validation Acc 78.79 %\n",
      "Epoch:90/200 AVG Training Loss:0.448 AVG Validation Loss:0.531 AVG Training Acc 81.91 % AVG Validation Acc 78.52 %\n",
      "Epoch:100/200 AVG Training Loss:0.446 AVG Validation Loss:0.536 AVG Training Acc 81.98 % AVG Validation Acc 78.61 %\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.445 AVG Validation Loss:0.534 AVG Training Acc 82.00 % AVG Validation Acc 78.43 %\n",
      "Epoch:120/200 AVG Training Loss:0.445 AVG Validation Loss:0.533 AVG Training Acc 82.26 % AVG Validation Acc 78.25 %\n",
      "Epoch:130/200 AVG Training Loss:0.446 AVG Validation Loss:0.536 AVG Training Acc 82.11 % AVG Validation Acc 78.70 %\n",
      "Epoch   134: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.445 AVG Validation Loss:0.534 AVG Training Acc 82.10 % AVG Validation Acc 78.88 %\n",
      "Epoch:150/200 AVG Training Loss:0.444 AVG Validation Loss:0.534 AVG Training Acc 82.11 % AVG Validation Acc 78.43 %\n",
      "Epoch:160/200 AVG Training Loss:0.444 AVG Validation Loss:0.536 AVG Training Acc 82.15 % AVG Validation Acc 78.52 %\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.446 AVG Validation Loss:0.539 AVG Training Acc 81.96 % AVG Validation Acc 78.61 %\n",
      "Epoch:180/200 AVG Training Loss:0.445 AVG Validation Loss:0.537 AVG Training Acc 82.12 % AVG Validation Acc 78.34 %\n",
      "Epoch:190/200 AVG Training Loss:0.446 AVG Validation Loss:0.538 AVG Training Acc 82.30 % AVG Validation Acc 78.61 %\n",
      "Epoch   196: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.444 AVG Validation Loss:0.537 AVG Training Acc 82.13 % AVG Validation Acc 78.70 %\n",
      "Split 270\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c8a30adeb254553879195519abd4977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.492 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.478 AVG Validation Loss:0.511 AVG Training Acc 80.59 % AVG Validation Acc 79.42 %\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.464 AVG Validation Loss:0.516 AVG Training Acc 80.91 % AVG Validation Acc 79.24 %\n",
      "Epoch:60/200 AVG Training Loss:0.456 AVG Validation Loss:0.521 AVG Training Acc 81.24 % AVG Validation Acc 78.70 %\n",
      "Epoch:70/200 AVG Training Loss:0.449 AVG Validation Loss:0.528 AVG Training Acc 81.55 % AVG Validation Acc 78.43 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.447 AVG Validation Loss:0.539 AVG Training Acc 81.76 % AVG Validation Acc 77.98 %\n",
      "Epoch:90/200 AVG Training Loss:0.445 AVG Validation Loss:0.541 AVG Training Acc 81.72 % AVG Validation Acc 78.07 %\n",
      "Epoch:100/200 AVG Training Loss:0.443 AVG Validation Loss:0.538 AVG Training Acc 81.81 % AVG Validation Acc 77.89 %\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.442 AVG Validation Loss:0.542 AVG Training Acc 81.88 % AVG Validation Acc 77.80 %\n",
      "Epoch:120/200 AVG Training Loss:0.440 AVG Validation Loss:0.536 AVG Training Acc 81.96 % AVG Validation Acc 78.07 %\n",
      "Epoch:130/200 AVG Training Loss:0.442 AVG Validation Loss:0.545 AVG Training Acc 81.91 % AVG Validation Acc 77.80 %\n",
      "Epoch   134: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.442 AVG Validation Loss:0.545 AVG Training Acc 81.82 % AVG Validation Acc 77.89 %\n",
      "Epoch:150/200 AVG Training Loss:0.441 AVG Validation Loss:0.544 AVG Training Acc 81.82 % AVG Validation Acc 77.89 %\n",
      "Epoch:160/200 AVG Training Loss:0.442 AVG Validation Loss:0.542 AVG Training Acc 81.92 % AVG Validation Acc 77.80 %\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.440 AVG Validation Loss:0.544 AVG Training Acc 81.86 % AVG Validation Acc 77.89 %\n",
      "Epoch:180/200 AVG Training Loss:0.443 AVG Validation Loss:0.542 AVG Training Acc 81.81 % AVG Validation Acc 77.71 %\n",
      "Epoch:190/200 AVG Training Loss:0.444 AVG Validation Loss:0.540 AVG Training Acc 81.83 % AVG Validation Acc 77.80 %\n",
      "Epoch   196: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.442 AVG Validation Loss:0.541 AVG Training Acc 81.79 % AVG Validation Acc 77.80 %\n",
      "Split 271\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be385017d0141688a118cb2265b1c35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.497 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.499 AVG Training Acc 80.14 % AVG Validation Acc 79.98 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.501 AVG Training Acc 80.30 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.478 AVG Validation Loss:0.503 AVG Training Acc 80.38 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.473 AVG Validation Loss:0.507 AVG Training Acc 80.45 % AVG Validation Acc 80.16 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.468 AVG Validation Loss:0.509 AVG Training Acc 80.69 % AVG Validation Acc 80.07 %\n",
      "Epoch:80/200 AVG Training Loss:0.466 AVG Validation Loss:0.509 AVG Training Acc 80.72 % AVG Validation Acc 80.07 %\n",
      "Epoch:90/200 AVG Training Loss:0.466 AVG Validation Loss:0.509 AVG Training Acc 80.68 % AVG Validation Acc 80.07 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.465 AVG Validation Loss:0.510 AVG Training Acc 80.81 % AVG Validation Acc 80.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.464 AVG Validation Loss:0.509 AVG Training Acc 80.89 % AVG Validation Acc 80.07 %\n",
      "Epoch:120/200 AVG Training Loss:0.466 AVG Validation Loss:0.510 AVG Training Acc 80.82 % AVG Validation Acc 80.07 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.464 AVG Validation Loss:0.510 AVG Training Acc 80.78 % AVG Validation Acc 80.16 %\n",
      "Epoch:140/200 AVG Training Loss:0.464 AVG Validation Loss:0.509 AVG Training Acc 80.85 % AVG Validation Acc 80.07 %\n",
      "Epoch:150/200 AVG Training Loss:0.465 AVG Validation Loss:0.508 AVG Training Acc 80.85 % AVG Validation Acc 80.07 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.464 AVG Validation Loss:0.511 AVG Training Acc 80.75 % AVG Validation Acc 80.16 %\n",
      "Epoch:170/200 AVG Training Loss:0.466 AVG Validation Loss:0.510 AVG Training Acc 80.77 % AVG Validation Acc 80.16 %\n",
      "Epoch:180/200 AVG Training Loss:0.465 AVG Validation Loss:0.511 AVG Training Acc 80.85 % AVG Validation Acc 80.07 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.465 AVG Validation Loss:0.509 AVG Training Acc 80.79 % AVG Validation Acc 80.16 %\n",
      "Epoch:200/200 AVG Training Loss:0.463 AVG Validation Loss:0.509 AVG Training Acc 80.95 % AVG Validation Acc 80.07 %\n",
      "Split 272\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f531adb411f4df48b5ea0e20c25c75e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.487 AVG Validation Loss:0.494 AVG Training Acc 80.23 % AVG Validation Acc 80.16 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.477 AVG Validation Loss:0.501 AVG Training Acc 80.48 % AVG Validation Acc 79.89 %\n",
      "Epoch:50/200 AVG Training Loss:0.469 AVG Validation Loss:0.512 AVG Training Acc 80.92 % AVG Validation Acc 79.80 %\n",
      "Epoch:60/200 AVG Training Loss:0.466 AVG Validation Loss:0.515 AVG Training Acc 81.01 % AVG Validation Acc 79.71 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.465 AVG Validation Loss:0.520 AVG Training Acc 80.96 % AVG Validation Acc 79.89 %\n",
      "Epoch:80/200 AVG Training Loss:0.464 AVG Validation Loss:0.523 AVG Training Acc 81.10 % AVG Validation Acc 79.53 %\n",
      "Epoch:90/200 AVG Training Loss:0.462 AVG Validation Loss:0.530 AVG Training Acc 81.24 % AVG Validation Acc 79.62 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.462 AVG Validation Loss:0.529 AVG Training Acc 81.23 % AVG Validation Acc 79.62 %\n",
      "Epoch:110/200 AVG Training Loss:0.462 AVG Validation Loss:0.529 AVG Training Acc 81.11 % AVG Validation Acc 79.62 %\n",
      "Epoch:120/200 AVG Training Loss:0.460 AVG Validation Loss:0.530 AVG Training Acc 81.18 % AVG Validation Acc 79.71 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.461 AVG Validation Loss:0.530 AVG Training Acc 81.14 % AVG Validation Acc 79.71 %\n",
      "Epoch:140/200 AVG Training Loss:0.462 AVG Validation Loss:0.532 AVG Training Acc 81.03 % AVG Validation Acc 79.62 %\n",
      "Epoch:150/200 AVG Training Loss:0.460 AVG Validation Loss:0.527 AVG Training Acc 81.23 % AVG Validation Acc 79.80 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.461 AVG Validation Loss:0.531 AVG Training Acc 81.29 % AVG Validation Acc 79.62 %\n",
      "Epoch:170/200 AVG Training Loss:0.461 AVG Validation Loss:0.525 AVG Training Acc 81.20 % AVG Validation Acc 79.71 %\n",
      "Epoch:180/200 AVG Training Loss:0.462 AVG Validation Loss:0.531 AVG Training Acc 81.10 % AVG Validation Acc 79.71 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.462 AVG Validation Loss:0.531 AVG Training Acc 81.17 % AVG Validation Acc 79.62 %\n",
      "Epoch:200/200 AVG Training Loss:0.462 AVG Validation Loss:0.531 AVG Training Acc 81.21 % AVG Validation Acc 79.53 %\n",
      "Split 273\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95c1fc7fb4a84760884c9a17398283f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.493 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.20 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.492 AVG Training Acc 80.35 % AVG Validation Acc 80.07 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.471 AVG Validation Loss:0.505 AVG Training Acc 80.77 % AVG Validation Acc 79.89 %\n",
      "Epoch:60/200 AVG Training Loss:0.463 AVG Validation Loss:0.523 AVG Training Acc 80.98 % AVG Validation Acc 79.53 %\n",
      "Epoch:70/200 AVG Training Loss:0.458 AVG Validation Loss:0.551 AVG Training Acc 81.24 % AVG Validation Acc 79.53 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.454 AVG Validation Loss:0.563 AVG Training Acc 81.28 % AVG Validation Acc 79.26 %\n",
      "Epoch:90/200 AVG Training Loss:0.452 AVG Validation Loss:0.558 AVG Training Acc 81.47 % AVG Validation Acc 79.26 %\n",
      "Epoch:100/200 AVG Training Loss:0.454 AVG Validation Loss:0.560 AVG Training Acc 81.33 % AVG Validation Acc 79.26 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.453 AVG Validation Loss:0.563 AVG Training Acc 81.38 % AVG Validation Acc 79.35 %\n",
      "Epoch:120/200 AVG Training Loss:0.453 AVG Validation Loss:0.568 AVG Training Acc 81.40 % AVG Validation Acc 79.26 %\n",
      "Epoch:130/200 AVG Training Loss:0.452 AVG Validation Loss:0.563 AVG Training Acc 81.36 % AVG Validation Acc 79.26 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.452 AVG Validation Loss:0.566 AVG Training Acc 81.45 % AVG Validation Acc 79.17 %\n",
      "Epoch:150/200 AVG Training Loss:0.452 AVG Validation Loss:0.566 AVG Training Acc 81.32 % AVG Validation Acc 79.26 %\n",
      "Epoch:160/200 AVG Training Loss:0.452 AVG Validation Loss:0.560 AVG Training Acc 81.45 % AVG Validation Acc 79.35 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.453 AVG Validation Loss:0.564 AVG Training Acc 81.43 % AVG Validation Acc 79.35 %\n",
      "Epoch:180/200 AVG Training Loss:0.452 AVG Validation Loss:0.565 AVG Training Acc 81.42 % AVG Validation Acc 79.44 %\n",
      "Epoch:190/200 AVG Training Loss:0.453 AVG Validation Loss:0.562 AVG Training Acc 81.36 % AVG Validation Acc 79.26 %\n",
      "Epoch   198: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.453 AVG Validation Loss:0.564 AVG Training Acc 81.31 % AVG Validation Acc 79.35 %\n",
      "Split 274\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3609b4ff8fe5411c8813488899801fef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.491 AVG Training Acc 80.10 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.488 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.482 AVG Validation Loss:0.495 AVG Training Acc 80.22 % AVG Validation Acc 79.80 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.468 AVG Validation Loss:0.494 AVG Training Acc 80.43 % AVG Validation Acc 79.71 %\n",
      "Epoch:60/200 AVG Training Loss:0.461 AVG Validation Loss:0.495 AVG Training Acc 80.71 % AVG Validation Acc 79.71 %\n",
      "Epoch:70/200 AVG Training Loss:0.461 AVG Validation Loss:0.494 AVG Training Acc 80.51 % AVG Validation Acc 79.62 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.454 AVG Validation Loss:0.499 AVG Training Acc 80.92 % AVG Validation Acc 79.80 %\n",
      "Epoch:90/200 AVG Training Loss:0.454 AVG Validation Loss:0.503 AVG Training Acc 81.02 % AVG Validation Acc 79.53 %\n",
      "Epoch:100/200 AVG Training Loss:0.454 AVG Validation Loss:0.504 AVG Training Acc 80.93 % AVG Validation Acc 79.44 %\n",
      "Epoch   105: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.454 AVG Validation Loss:0.505 AVG Training Acc 80.99 % AVG Validation Acc 79.35 %\n",
      "Epoch:120/200 AVG Training Loss:0.453 AVG Validation Loss:0.505 AVG Training Acc 80.98 % AVG Validation Acc 79.17 %\n",
      "Epoch:130/200 AVG Training Loss:0.453 AVG Validation Loss:0.502 AVG Training Acc 80.91 % AVG Validation Acc 79.35 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.452 AVG Validation Loss:0.507 AVG Training Acc 81.15 % AVG Validation Acc 79.08 %\n",
      "Epoch:150/200 AVG Training Loss:0.451 AVG Validation Loss:0.506 AVG Training Acc 81.01 % AVG Validation Acc 79.35 %\n",
      "Epoch:160/200 AVG Training Loss:0.452 AVG Validation Loss:0.507 AVG Training Acc 81.02 % AVG Validation Acc 79.26 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.453 AVG Validation Loss:0.507 AVG Training Acc 81.02 % AVG Validation Acc 79.44 %\n",
      "Epoch:180/200 AVG Training Loss:0.452 AVG Validation Loss:0.505 AVG Training Acc 80.96 % AVG Validation Acc 79.35 %\n",
      "Epoch:190/200 AVG Training Loss:0.453 AVG Validation Loss:0.501 AVG Training Acc 80.94 % AVG Validation Acc 79.35 %\n",
      "Epoch   198: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.452 AVG Validation Loss:0.506 AVG Training Acc 80.96 % AVG Validation Acc 79.44 %\n",
      "Split 275\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85d2d207df40412b8e17b67aa8755ce3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.16 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.498 AVG Training Acc 80.21 % AVG Validation Acc 80.07 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.480 AVG Validation Loss:0.499 AVG Training Acc 80.38 % AVG Validation Acc 79.98 %\n",
      "Epoch:50/200 AVG Training Loss:0.472 AVG Validation Loss:0.506 AVG Training Acc 80.67 % AVG Validation Acc 79.89 %\n",
      "Epoch:60/200 AVG Training Loss:0.468 AVG Validation Loss:0.508 AVG Training Acc 81.02 % AVG Validation Acc 79.80 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.462 AVG Validation Loss:0.516 AVG Training Acc 81.20 % AVG Validation Acc 79.44 %\n",
      "Epoch:80/200 AVG Training Loss:0.461 AVG Validation Loss:0.517 AVG Training Acc 81.16 % AVG Validation Acc 79.62 %\n",
      "Epoch:90/200 AVG Training Loss:0.460 AVG Validation Loss:0.517 AVG Training Acc 81.10 % AVG Validation Acc 79.53 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.459 AVG Validation Loss:0.518 AVG Training Acc 81.24 % AVG Validation Acc 79.35 %\n",
      "Epoch:110/200 AVG Training Loss:0.460 AVG Validation Loss:0.518 AVG Training Acc 81.22 % AVG Validation Acc 79.44 %\n",
      "Epoch:120/200 AVG Training Loss:0.458 AVG Validation Loss:0.517 AVG Training Acc 81.28 % AVG Validation Acc 79.44 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.459 AVG Validation Loss:0.518 AVG Training Acc 81.34 % AVG Validation Acc 79.44 %\n",
      "Epoch:140/200 AVG Training Loss:0.458 AVG Validation Loss:0.518 AVG Training Acc 81.26 % AVG Validation Acc 79.44 %\n",
      "Epoch:150/200 AVG Training Loss:0.459 AVG Validation Loss:0.518 AVG Training Acc 81.22 % AVG Validation Acc 79.44 %\n",
      "Epoch:160/200 AVG Training Loss:0.459 AVG Validation Loss:0.518 AVG Training Acc 81.24 % AVG Validation Acc 79.44 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.459 AVG Validation Loss:0.519 AVG Training Acc 81.34 % AVG Validation Acc 79.35 %\n",
      "Epoch:180/200 AVG Training Loss:0.460 AVG Validation Loss:0.518 AVG Training Acc 81.22 % AVG Validation Acc 79.44 %\n",
      "Epoch:190/200 AVG Training Loss:0.458 AVG Validation Loss:0.518 AVG Training Acc 81.16 % AVG Validation Acc 79.44 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.458 AVG Validation Loss:0.518 AVG Training Acc 81.32 % AVG Validation Acc 79.53 %\n",
      "Split 276\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0577e1db70e420b82dfad3e22c4bb9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.496 AVG Training Acc 80.16 % AVG Validation Acc 80.23 %\n",
      "Epoch:30/200 AVG Training Loss:0.485 AVG Validation Loss:0.494 AVG Training Acc 80.23 % AVG Validation Acc 79.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.491 AVG Validation Loss:0.497 AVG Training Acc 80.20 % AVG Validation Acc 80.23 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.498 AVG Validation Loss:0.506 AVG Training Acc 80.05 % AVG Validation Acc 79.78 %\n",
      "Epoch:60/200 AVG Training Loss:0.495 AVG Validation Loss:0.503 AVG Training Acc 80.19 % AVG Validation Acc 79.87 %\n",
      "Epoch:70/200 AVG Training Loss:0.494 AVG Validation Loss:0.501 AVG Training Acc 80.19 % AVG Validation Acc 79.78 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.492 AVG Validation Loss:0.502 AVG Training Acc 80.22 % AVG Validation Acc 79.78 %\n",
      "Epoch:90/200 AVG Training Loss:0.491 AVG Validation Loss:0.502 AVG Training Acc 80.21 % AVG Validation Acc 79.78 %\n",
      "Epoch:100/200 AVG Training Loss:0.490 AVG Validation Loss:0.503 AVG Training Acc 80.24 % AVG Validation Acc 79.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.488 AVG Validation Loss:0.501 AVG Training Acc 80.21 % AVG Validation Acc 79.87 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.489 AVG Validation Loss:0.501 AVG Training Acc 80.21 % AVG Validation Acc 79.87 %\n",
      "Epoch:130/200 AVG Training Loss:0.490 AVG Validation Loss:0.501 AVG Training Acc 80.20 % AVG Validation Acc 79.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.489 AVG Validation Loss:0.502 AVG Training Acc 80.24 % AVG Validation Acc 79.78 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.490 AVG Validation Loss:0.501 AVG Training Acc 80.25 % AVG Validation Acc 79.78 %\n",
      "Epoch:160/200 AVG Training Loss:0.489 AVG Validation Loss:0.502 AVG Training Acc 80.26 % AVG Validation Acc 79.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.488 AVG Validation Loss:0.502 AVG Training Acc 80.25 % AVG Validation Acc 79.78 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.489 AVG Validation Loss:0.502 AVG Training Acc 80.23 % AVG Validation Acc 79.87 %\n",
      "Epoch:190/200 AVG Training Loss:0.488 AVG Validation Loss:0.502 AVG Training Acc 80.26 % AVG Validation Acc 79.87 %\n",
      "Epoch:200/200 AVG Training Loss:0.489 AVG Validation Loss:0.501 AVG Training Acc 80.23 % AVG Validation Acc 79.87 %\n",
      "Split 277\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b0d0236c0f649408db1783673148f10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.09 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.495 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.478 AVG Validation Loss:0.498 AVG Training Acc 80.49 % AVG Validation Acc 79.78 %\n",
      "Epoch:50/200 AVG Training Loss:0.469 AVG Validation Loss:0.511 AVG Training Acc 80.86 % AVG Validation Acc 79.69 %\n",
      "Epoch:60/200 AVG Training Loss:0.462 AVG Validation Loss:0.517 AVG Training Acc 81.13 % AVG Validation Acc 80.23 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.455 AVG Validation Loss:0.523 AVG Training Acc 81.54 % AVG Validation Acc 79.69 %\n",
      "Epoch:80/200 AVG Training Loss:0.453 AVG Validation Loss:0.522 AVG Training Acc 81.58 % AVG Validation Acc 79.87 %\n",
      "Epoch:90/200 AVG Training Loss:0.453 AVG Validation Loss:0.524 AVG Training Acc 81.53 % AVG Validation Acc 79.69 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.453 AVG Validation Loss:0.528 AVG Training Acc 81.52 % AVG Validation Acc 79.42 %\n",
      "Epoch:110/200 AVG Training Loss:0.452 AVG Validation Loss:0.523 AVG Training Acc 81.45 % AVG Validation Acc 79.51 %\n",
      "Epoch:120/200 AVG Training Loss:0.453 AVG Validation Loss:0.529 AVG Training Acc 81.46 % AVG Validation Acc 79.69 %\n",
      "Epoch:130/200 AVG Training Loss:0.452 AVG Validation Loss:0.525 AVG Training Acc 81.61 % AVG Validation Acc 79.78 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.450 AVG Validation Loss:0.524 AVG Training Acc 81.67 % AVG Validation Acc 79.42 %\n",
      "Epoch:150/200 AVG Training Loss:0.452 AVG Validation Loss:0.530 AVG Training Acc 81.49 % AVG Validation Acc 79.60 %\n",
      "Epoch:160/200 AVG Training Loss:0.452 AVG Validation Loss:0.532 AVG Training Acc 81.61 % AVG Validation Acc 79.51 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.450 AVG Validation Loss:0.533 AVG Training Acc 81.64 % AVG Validation Acc 79.51 %\n",
      "Epoch:180/200 AVG Training Loss:0.453 AVG Validation Loss:0.530 AVG Training Acc 81.51 % AVG Validation Acc 79.42 %\n",
      "Epoch:190/200 AVG Training Loss:0.450 AVG Validation Loss:0.528 AVG Training Acc 81.67 % AVG Validation Acc 79.24 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.453 AVG Validation Loss:0.531 AVG Training Acc 81.63 % AVG Validation Acc 79.51 %\n",
      "Split 278\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158d309c5133483f995f4472aa752d5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.05 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.491 AVG Training Acc 80.31 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.480 AVG Validation Loss:0.492 AVG Training Acc 80.37 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.474 AVG Validation Loss:0.497 AVG Training Acc 80.55 % AVG Validation Acc 80.32 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.473 AVG Validation Loss:0.497 AVG Training Acc 80.55 % AVG Validation Acc 80.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.471 AVG Validation Loss:0.498 AVG Training Acc 80.53 % AVG Validation Acc 79.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.468 AVG Validation Loss:0.499 AVG Training Acc 80.57 % AVG Validation Acc 80.05 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.469 AVG Validation Loss:0.499 AVG Training Acc 80.59 % AVG Validation Acc 80.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.470 AVG Validation Loss:0.498 AVG Training Acc 80.58 % AVG Validation Acc 79.96 %\n",
      "Epoch:120/200 AVG Training Loss:0.470 AVG Validation Loss:0.499 AVG Training Acc 80.57 % AVG Validation Acc 79.96 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.469 AVG Validation Loss:0.499 AVG Training Acc 80.66 % AVG Validation Acc 79.96 %\n",
      "Epoch:140/200 AVG Training Loss:0.470 AVG Validation Loss:0.499 AVG Training Acc 80.47 % AVG Validation Acc 79.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.469 AVG Validation Loss:0.498 AVG Training Acc 80.54 % AVG Validation Acc 79.96 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.469 AVG Validation Loss:0.498 AVG Training Acc 80.59 % AVG Validation Acc 79.96 %\n",
      "Epoch:170/200 AVG Training Loss:0.469 AVG Validation Loss:0.498 AVG Training Acc 80.58 % AVG Validation Acc 79.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.469 AVG Validation Loss:0.499 AVG Training Acc 80.60 % AVG Validation Acc 79.96 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.468 AVG Validation Loss:0.498 AVG Training Acc 80.57 % AVG Validation Acc 80.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.469 AVG Validation Loss:0.498 AVG Training Acc 80.63 % AVG Validation Acc 79.96 %\n",
      "Split 279\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af5e2299ba7d47b68a18119c00700671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.494 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.492 AVG Training Acc 80.36 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.478 AVG Validation Loss:0.492 AVG Training Acc 80.54 % AVG Validation Acc 79.96 %\n",
      "Epoch:60/200 AVG Training Loss:0.473 AVG Validation Loss:0.493 AVG Training Acc 80.67 % AVG Validation Acc 79.78 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.467 AVG Validation Loss:0.493 AVG Training Acc 80.90 % AVG Validation Acc 79.87 %\n",
      "Epoch:80/200 AVG Training Loss:0.468 AVG Validation Loss:0.493 AVG Training Acc 80.92 % AVG Validation Acc 79.87 %\n",
      "Epoch:90/200 AVG Training Loss:0.464 AVG Validation Loss:0.494 AVG Training Acc 80.85 % AVG Validation Acc 79.69 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.464 AVG Validation Loss:0.495 AVG Training Acc 81.11 % AVG Validation Acc 79.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.464 AVG Validation Loss:0.494 AVG Training Acc 81.04 % AVG Validation Acc 79.69 %\n",
      "Epoch:120/200 AVG Training Loss:0.465 AVG Validation Loss:0.493 AVG Training Acc 81.16 % AVG Validation Acc 79.69 %\n",
      "Epoch:130/200 AVG Training Loss:0.463 AVG Validation Loss:0.493 AVG Training Acc 81.11 % AVG Validation Acc 79.69 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.463 AVG Validation Loss:0.494 AVG Training Acc 81.03 % AVG Validation Acc 79.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.463 AVG Validation Loss:0.495 AVG Training Acc 81.03 % AVG Validation Acc 79.69 %\n",
      "Epoch:160/200 AVG Training Loss:0.463 AVG Validation Loss:0.493 AVG Training Acc 81.09 % AVG Validation Acc 79.69 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.464 AVG Validation Loss:0.494 AVG Training Acc 81.15 % AVG Validation Acc 79.69 %\n",
      "Epoch:180/200 AVG Training Loss:0.464 AVG Validation Loss:0.496 AVG Training Acc 81.03 % AVG Validation Acc 79.51 %\n",
      "Epoch:190/200 AVG Training Loss:0.464 AVG Validation Loss:0.496 AVG Training Acc 81.03 % AVG Validation Acc 79.51 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.464 AVG Validation Loss:0.494 AVG Training Acc 81.06 % AVG Validation Acc 79.42 %\n",
      "Split 280\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3e257bebf34ad9bc75a3914d08283d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.16 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.493 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.501 AVG Training Acc 80.29 % AVG Validation Acc 80.14 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.480 AVG Validation Loss:0.493 AVG Training Acc 80.53 % AVG Validation Acc 80.23 %\n",
      "Epoch:50/200 AVG Training Loss:0.475 AVG Validation Loss:0.497 AVG Training Acc 80.77 % AVG Validation Acc 79.69 %\n",
      "Epoch:60/200 AVG Training Loss:0.471 AVG Validation Loss:0.495 AVG Training Acc 80.87 % AVG Validation Acc 79.87 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.469 AVG Validation Loss:0.501 AVG Training Acc 81.02 % AVG Validation Acc 79.87 %\n",
      "Epoch:80/200 AVG Training Loss:0.468 AVG Validation Loss:0.502 AVG Training Acc 81.07 % AVG Validation Acc 79.78 %\n",
      "Epoch:90/200 AVG Training Loss:0.465 AVG Validation Loss:0.504 AVG Training Acc 81.13 % AVG Validation Acc 79.78 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.466 AVG Validation Loss:0.504 AVG Training Acc 81.14 % AVG Validation Acc 79.69 %\n",
      "Epoch:110/200 AVG Training Loss:0.465 AVG Validation Loss:0.505 AVG Training Acc 81.22 % AVG Validation Acc 79.51 %\n",
      "Epoch:120/200 AVG Training Loss:0.466 AVG Validation Loss:0.505 AVG Training Acc 81.14 % AVG Validation Acc 79.69 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.466 AVG Validation Loss:0.505 AVG Training Acc 81.21 % AVG Validation Acc 79.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.465 AVG Validation Loss:0.505 AVG Training Acc 81.19 % AVG Validation Acc 79.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.465 AVG Validation Loss:0.504 AVG Training Acc 81.12 % AVG Validation Acc 79.60 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.466 AVG Validation Loss:0.505 AVG Training Acc 81.19 % AVG Validation Acc 79.60 %\n",
      "Epoch:170/200 AVG Training Loss:0.468 AVG Validation Loss:0.503 AVG Training Acc 81.18 % AVG Validation Acc 79.69 %\n",
      "Epoch:180/200 AVG Training Loss:0.466 AVG Validation Loss:0.502 AVG Training Acc 81.04 % AVG Validation Acc 79.78 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.465 AVG Validation Loss:0.505 AVG Training Acc 81.20 % AVG Validation Acc 79.51 %\n",
      "Epoch:200/200 AVG Training Loss:0.466 AVG Validation Loss:0.507 AVG Training Acc 81.11 % AVG Validation Acc 79.51 %\n",
      "Split 281\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecfb767ba9864006a0c38267061c6f2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.493 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.486 AVG Validation Loss:0.493 AVG Training Acc 80.23 % AVG Validation Acc 80.25 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.477 AVG Validation Loss:0.495 AVG Training Acc 80.43 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.469 AVG Validation Loss:0.507 AVG Training Acc 80.67 % AVG Validation Acc 79.98 %\n",
      "Epoch:60/200 AVG Training Loss:0.463 AVG Validation Loss:0.517 AVG Training Acc 80.87 % AVG Validation Acc 79.80 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.460 AVG Validation Loss:0.522 AVG Training Acc 80.95 % AVG Validation Acc 79.89 %\n",
      "Epoch:80/200 AVG Training Loss:0.459 AVG Validation Loss:0.524 AVG Training Acc 80.97 % AVG Validation Acc 79.80 %\n",
      "Epoch:90/200 AVG Training Loss:0.456 AVG Validation Loss:0.523 AVG Training Acc 81.14 % AVG Validation Acc 79.71 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.457 AVG Validation Loss:0.524 AVG Training Acc 81.17 % AVG Validation Acc 79.71 %\n",
      "Epoch:110/200 AVG Training Loss:0.455 AVG Validation Loss:0.521 AVG Training Acc 81.19 % AVG Validation Acc 79.80 %\n",
      "Epoch:120/200 AVG Training Loss:0.455 AVG Validation Loss:0.521 AVG Training Acc 81.29 % AVG Validation Acc 79.71 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.455 AVG Validation Loss:0.522 AVG Training Acc 81.22 % AVG Validation Acc 79.80 %\n",
      "Epoch:140/200 AVG Training Loss:0.455 AVG Validation Loss:0.520 AVG Training Acc 81.22 % AVG Validation Acc 79.71 %\n",
      "Epoch:150/200 AVG Training Loss:0.456 AVG Validation Loss:0.522 AVG Training Acc 81.10 % AVG Validation Acc 79.71 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.456 AVG Validation Loss:0.528 AVG Training Acc 81.13 % AVG Validation Acc 79.71 %\n",
      "Epoch:170/200 AVG Training Loss:0.457 AVG Validation Loss:0.526 AVG Training Acc 81.19 % AVG Validation Acc 79.89 %\n",
      "Epoch:180/200 AVG Training Loss:0.457 AVG Validation Loss:0.525 AVG Training Acc 81.10 % AVG Validation Acc 79.71 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.457 AVG Validation Loss:0.525 AVG Training Acc 81.06 % AVG Validation Acc 79.80 %\n",
      "Epoch:200/200 AVG Training Loss:0.455 AVG Validation Loss:0.521 AVG Training Acc 81.22 % AVG Validation Acc 79.80 %\n",
      "Split 282\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27906b71ed384a75910fa0071fe6269c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.482 AVG Validation Loss:0.501 AVG Training Acc 80.27 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.474 AVG Validation Loss:0.511 AVG Training Acc 80.44 % AVG Validation Acc 79.98 %\n",
      "Epoch:60/200 AVG Training Loss:0.465 AVG Validation Loss:0.518 AVG Training Acc 80.80 % AVG Validation Acc 79.89 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.459 AVG Validation Loss:0.531 AVG Training Acc 81.05 % AVG Validation Acc 79.62 %\n",
      "Epoch:80/200 AVG Training Loss:0.457 AVG Validation Loss:0.534 AVG Training Acc 80.94 % AVG Validation Acc 79.53 %\n",
      "Epoch:90/200 AVG Training Loss:0.456 AVG Validation Loss:0.536 AVG Training Acc 81.03 % AVG Validation Acc 79.62 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.455 AVG Validation Loss:0.542 AVG Training Acc 81.11 % AVG Validation Acc 79.62 %\n",
      "Epoch:110/200 AVG Training Loss:0.455 AVG Validation Loss:0.539 AVG Training Acc 81.20 % AVG Validation Acc 79.62 %\n",
      "Epoch:120/200 AVG Training Loss:0.454 AVG Validation Loss:0.539 AVG Training Acc 81.14 % AVG Validation Acc 79.71 %\n",
      "Epoch:130/200 AVG Training Loss:0.456 AVG Validation Loss:0.539 AVG Training Acc 80.98 % AVG Validation Acc 79.62 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.456 AVG Validation Loss:0.538 AVG Training Acc 81.05 % AVG Validation Acc 79.53 %\n",
      "Epoch:150/200 AVG Training Loss:0.455 AVG Validation Loss:0.540 AVG Training Acc 80.98 % AVG Validation Acc 79.71 %\n",
      "Epoch:160/200 AVG Training Loss:0.455 AVG Validation Loss:0.540 AVG Training Acc 81.11 % AVG Validation Acc 79.62 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.456 AVG Validation Loss:0.539 AVG Training Acc 81.01 % AVG Validation Acc 79.53 %\n",
      "Epoch:180/200 AVG Training Loss:0.457 AVG Validation Loss:0.539 AVG Training Acc 81.09 % AVG Validation Acc 79.53 %\n",
      "Epoch:190/200 AVG Training Loss:0.454 AVG Validation Loss:0.537 AVG Training Acc 81.22 % AVG Validation Acc 79.53 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.456 AVG Validation Loss:0.538 AVG Training Acc 81.06 % AVG Validation Acc 79.53 %\n",
      "Split 283\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5808423a7ccc491e87356076fc0a476e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.499 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.11 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.21 % AVG Validation Acc 80.16 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.28 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.482 AVG Validation Loss:0.501 AVG Training Acc 80.39 % AVG Validation Acc 79.80 %\n",
      "Epoch:60/200 AVG Training Loss:0.479 AVG Validation Loss:0.503 AVG Training Acc 80.49 % AVG Validation Acc 79.80 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.477 AVG Validation Loss:0.503 AVG Training Acc 80.54 % AVG Validation Acc 79.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.476 AVG Validation Loss:0.505 AVG Training Acc 80.62 % AVG Validation Acc 79.89 %\n",
      "Epoch:90/200 AVG Training Loss:0.477 AVG Validation Loss:0.505 AVG Training Acc 80.51 % AVG Validation Acc 79.80 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.474 AVG Validation Loss:0.507 AVG Training Acc 80.67 % AVG Validation Acc 79.80 %\n",
      "Epoch:110/200 AVG Training Loss:0.475 AVG Validation Loss:0.506 AVG Training Acc 80.71 % AVG Validation Acc 79.80 %\n",
      "Epoch:120/200 AVG Training Loss:0.475 AVG Validation Loss:0.506 AVG Training Acc 80.68 % AVG Validation Acc 79.80 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.476 AVG Validation Loss:0.507 AVG Training Acc 80.59 % AVG Validation Acc 79.89 %\n",
      "Epoch:140/200 AVG Training Loss:0.474 AVG Validation Loss:0.506 AVG Training Acc 80.62 % AVG Validation Acc 79.89 %\n",
      "Epoch:150/200 AVG Training Loss:0.475 AVG Validation Loss:0.507 AVG Training Acc 80.60 % AVG Validation Acc 79.80 %\n",
      "Epoch:160/200 AVG Training Loss:0.475 AVG Validation Loss:0.507 AVG Training Acc 80.68 % AVG Validation Acc 79.80 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.475 AVG Validation Loss:0.507 AVG Training Acc 80.67 % AVG Validation Acc 79.80 %\n",
      "Epoch:180/200 AVG Training Loss:0.476 AVG Validation Loss:0.507 AVG Training Acc 80.61 % AVG Validation Acc 79.71 %\n",
      "Epoch:190/200 AVG Training Loss:0.475 AVG Validation Loss:0.507 AVG Training Acc 80.64 % AVG Validation Acc 79.80 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.476 AVG Validation Loss:0.507 AVG Training Acc 80.60 % AVG Validation Acc 79.80 %\n",
      "Split 284\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4622163c65e5430799798f9691681895",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.492 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.492 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.497 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.475 AVG Validation Loss:0.493 AVG Training Acc 80.32 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.468 AVG Validation Loss:0.500 AVG Training Acc 80.45 % AVG Validation Acc 80.52 %\n",
      "Epoch:60/200 AVG Training Loss:0.461 AVG Validation Loss:0.508 AVG Training Acc 80.55 % AVG Validation Acc 80.07 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.456 AVG Validation Loss:0.517 AVG Training Acc 80.65 % AVG Validation Acc 79.89 %\n",
      "Epoch:80/200 AVG Training Loss:0.454 AVG Validation Loss:0.519 AVG Training Acc 80.79 % AVG Validation Acc 79.53 %\n",
      "Epoch:90/200 AVG Training Loss:0.452 AVG Validation Loss:0.520 AVG Training Acc 80.80 % AVG Validation Acc 79.44 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.451 AVG Validation Loss:0.524 AVG Training Acc 80.76 % AVG Validation Acc 79.44 %\n",
      "Epoch:110/200 AVG Training Loss:0.450 AVG Validation Loss:0.527 AVG Training Acc 80.90 % AVG Validation Acc 79.44 %\n",
      "Epoch:120/200 AVG Training Loss:0.452 AVG Validation Loss:0.522 AVG Training Acc 80.87 % AVG Validation Acc 79.35 %\n",
      "Epoch:130/200 AVG Training Loss:0.452 AVG Validation Loss:0.524 AVG Training Acc 80.82 % AVG Validation Acc 79.26 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.451 AVG Validation Loss:0.521 AVG Training Acc 80.80 % AVG Validation Acc 79.44 %\n",
      "Epoch:150/200 AVG Training Loss:0.450 AVG Validation Loss:0.524 AVG Training Acc 80.87 % AVG Validation Acc 79.26 %\n",
      "Epoch:160/200 AVG Training Loss:0.451 AVG Validation Loss:0.525 AVG Training Acc 80.73 % AVG Validation Acc 79.35 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.452 AVG Validation Loss:0.525 AVG Training Acc 80.85 % AVG Validation Acc 79.26 %\n",
      "Epoch:180/200 AVG Training Loss:0.452 AVG Validation Loss:0.522 AVG Training Acc 80.72 % AVG Validation Acc 79.26 %\n",
      "Epoch:190/200 AVG Training Loss:0.451 AVG Validation Loss:0.525 AVG Training Acc 80.85 % AVG Validation Acc 79.26 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.452 AVG Validation Loss:0.524 AVG Training Acc 80.80 % AVG Validation Acc 79.17 %\n",
      "Split 285\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03af0bb652544263b10bb90caecbbfee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.493 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.16 % AVG Validation Acc 80.07 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.482 AVG Validation Loss:0.494 AVG Training Acc 80.32 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.471 AVG Validation Loss:0.502 AVG Training Acc 80.71 % AVG Validation Acc 80.07 %\n",
      "Epoch:60/200 AVG Training Loss:0.463 AVG Validation Loss:0.508 AVG Training Acc 81.11 % AVG Validation Acc 79.44 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.456 AVG Validation Loss:0.509 AVG Training Acc 81.47 % AVG Validation Acc 79.71 %\n",
      "Epoch:80/200 AVG Training Loss:0.455 AVG Validation Loss:0.512 AVG Training Acc 81.56 % AVG Validation Acc 79.71 %\n",
      "Epoch:90/200 AVG Training Loss:0.453 AVG Validation Loss:0.512 AVG Training Acc 81.57 % AVG Validation Acc 79.62 %\n",
      "Epoch:100/200 AVG Training Loss:0.452 AVG Validation Loss:0.516 AVG Training Acc 81.67 % AVG Validation Acc 79.26 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.453 AVG Validation Loss:0.516 AVG Training Acc 81.63 % AVG Validation Acc 79.80 %\n",
      "Epoch:120/200 AVG Training Loss:0.452 AVG Validation Loss:0.517 AVG Training Acc 81.60 % AVG Validation Acc 79.44 %\n",
      "Epoch:130/200 AVG Training Loss:0.454 AVG Validation Loss:0.517 AVG Training Acc 81.66 % AVG Validation Acc 79.35 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.453 AVG Validation Loss:0.517 AVG Training Acc 81.74 % AVG Validation Acc 79.17 %\n",
      "Epoch:150/200 AVG Training Loss:0.452 AVG Validation Loss:0.516 AVG Training Acc 81.66 % AVG Validation Acc 79.53 %\n",
      "Epoch:160/200 AVG Training Loss:0.453 AVG Validation Loss:0.514 AVG Training Acc 81.70 % AVG Validation Acc 79.62 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.450 AVG Validation Loss:0.516 AVG Training Acc 81.87 % AVG Validation Acc 79.35 %\n",
      "Epoch:180/200 AVG Training Loss:0.452 AVG Validation Loss:0.519 AVG Training Acc 81.69 % AVG Validation Acc 79.44 %\n",
      "Epoch:190/200 AVG Training Loss:0.452 AVG Validation Loss:0.514 AVG Training Acc 81.78 % AVG Validation Acc 79.26 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.451 AVG Validation Loss:0.515 AVG Training Acc 81.77 % AVG Validation Acc 79.62 %\n",
      "Split 286\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff8f78a763f41659cb93855338b5647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.511 AVG Validation Loss:0.497 AVG Training Acc 80.03 % AVG Validation Acc 80.14 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.499 AVG Training Acc 80.32 % AVG Validation Acc 79.69 %\n",
      "Epoch:50/200 AVG Training Loss:0.486 AVG Validation Loss:0.508 AVG Training Acc 80.48 % AVG Validation Acc 79.33 %\n",
      "Epoch:60/200 AVG Training Loss:0.480 AVG Validation Loss:0.518 AVG Training Acc 80.65 % AVG Validation Acc 79.33 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.476 AVG Validation Loss:0.531 AVG Training Acc 80.88 % AVG Validation Acc 79.06 %\n",
      "Epoch:80/200 AVG Training Loss:0.474 AVG Validation Loss:0.536 AVG Training Acc 80.91 % AVG Validation Acc 78.88 %\n",
      "Epoch:90/200 AVG Training Loss:0.473 AVG Validation Loss:0.534 AVG Training Acc 81.01 % AVG Validation Acc 78.97 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.472 AVG Validation Loss:0.542 AVG Training Acc 81.15 % AVG Validation Acc 78.88 %\n",
      "Epoch:110/200 AVG Training Loss:0.472 AVG Validation Loss:0.539 AVG Training Acc 81.17 % AVG Validation Acc 78.88 %\n",
      "Epoch:120/200 AVG Training Loss:0.471 AVG Validation Loss:0.539 AVG Training Acc 81.02 % AVG Validation Acc 78.79 %\n",
      "Epoch:130/200 AVG Training Loss:0.472 AVG Validation Loss:0.539 AVG Training Acc 81.00 % AVG Validation Acc 78.88 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.471 AVG Validation Loss:0.538 AVG Training Acc 81.06 % AVG Validation Acc 78.88 %\n",
      "Epoch:150/200 AVG Training Loss:0.471 AVG Validation Loss:0.540 AVG Training Acc 81.18 % AVG Validation Acc 78.97 %\n",
      "Epoch:160/200 AVG Training Loss:0.473 AVG Validation Loss:0.540 AVG Training Acc 81.04 % AVG Validation Acc 78.97 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.471 AVG Validation Loss:0.535 AVG Training Acc 81.00 % AVG Validation Acc 79.06 %\n",
      "Epoch:180/200 AVG Training Loss:0.470 AVG Validation Loss:0.541 AVG Training Acc 80.99 % AVG Validation Acc 78.97 %\n",
      "Epoch:190/200 AVG Training Loss:0.472 AVG Validation Loss:0.538 AVG Training Acc 81.02 % AVG Validation Acc 78.97 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.471 AVG Validation Loss:0.539 AVG Training Acc 81.13 % AVG Validation Acc 78.79 %\n",
      "Split 287\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e85943fb30ff446b942ce86f6b97094f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.501 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.498 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.485 AVG Validation Loss:0.498 AVG Training Acc 80.28 % AVG Validation Acc 80.05 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.482 AVG Validation Loss:0.499 AVG Training Acc 80.39 % AVG Validation Acc 79.87 %\n",
      "Epoch:60/200 AVG Training Loss:0.481 AVG Validation Loss:0.500 AVG Training Acc 80.42 % AVG Validation Acc 79.78 %\n",
      "Epoch:70/200 AVG Training Loss:0.482 AVG Validation Loss:0.500 AVG Training Acc 80.39 % AVG Validation Acc 79.78 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:80/200 AVG Training Loss:0.480 AVG Validation Loss:0.501 AVG Training Acc 80.44 % AVG Validation Acc 79.78 %\n",
      "Epoch:90/200 AVG Training Loss:0.481 AVG Validation Loss:0.501 AVG Training Acc 80.50 % AVG Validation Acc 79.78 %\n",
      "Epoch:100/200 AVG Training Loss:0.480 AVG Validation Loss:0.501 AVG Training Acc 80.46 % AVG Validation Acc 79.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.480 AVG Validation Loss:0.501 AVG Training Acc 80.39 % AVG Validation Acc 79.78 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.480 AVG Validation Loss:0.501 AVG Training Acc 80.48 % AVG Validation Acc 79.78 %\n",
      "Epoch:130/200 AVG Training Loss:0.480 AVG Validation Loss:0.501 AVG Training Acc 80.50 % AVG Validation Acc 79.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.480 AVG Validation Loss:0.501 AVG Training Acc 80.50 % AVG Validation Acc 79.78 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.480 AVG Validation Loss:0.501 AVG Training Acc 80.47 % AVG Validation Acc 79.78 %\n",
      "Epoch:160/200 AVG Training Loss:0.480 AVG Validation Loss:0.501 AVG Training Acc 80.45 % AVG Validation Acc 79.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.480 AVG Validation Loss:0.501 AVG Training Acc 80.52 % AVG Validation Acc 79.78 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.480 AVG Validation Loss:0.501 AVG Training Acc 80.44 % AVG Validation Acc 79.78 %\n",
      "Epoch:190/200 AVG Training Loss:0.481 AVG Validation Loss:0.501 AVG Training Acc 80.42 % AVG Validation Acc 79.78 %\n",
      "Epoch:200/200 AVG Training Loss:0.480 AVG Validation Loss:0.501 AVG Training Acc 80.36 % AVG Validation Acc 79.78 %\n",
      "Split 288\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "771d7c66c7b84587b27ed3cbc1d80b2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.499 AVG Validation Loss:0.500 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.499 AVG Training Acc 80.17 % AVG Validation Acc 80.14 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.25 % AVG Validation Acc 80.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.484 AVG Validation Loss:0.496 AVG Training Acc 80.25 % AVG Validation Acc 79.96 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.481 AVG Validation Loss:0.498 AVG Training Acc 80.27 % AVG Validation Acc 80.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.482 AVG Validation Loss:0.498 AVG Training Acc 80.20 % AVG Validation Acc 79.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.30 % AVG Validation Acc 79.96 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.480 AVG Validation Loss:0.500 AVG Training Acc 80.24 % AVG Validation Acc 79.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.479 AVG Validation Loss:0.498 AVG Training Acc 80.30 % AVG Validation Acc 79.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.481 AVG Validation Loss:0.499 AVG Training Acc 80.23 % AVG Validation Acc 79.87 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.480 AVG Validation Loss:0.499 AVG Training Acc 80.30 % AVG Validation Acc 79.87 %\n",
      "Epoch:130/200 AVG Training Loss:0.481 AVG Validation Loss:0.500 AVG Training Acc 80.27 % AVG Validation Acc 79.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.479 AVG Validation Loss:0.500 AVG Training Acc 80.30 % AVG Validation Acc 79.96 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:150/200 AVG Training Loss:0.480 AVG Validation Loss:0.498 AVG Training Acc 80.28 % AVG Validation Acc 79.96 %\n",
      "Epoch:160/200 AVG Training Loss:0.479 AVG Validation Loss:0.500 AVG Training Acc 80.29 % AVG Validation Acc 79.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.479 AVG Validation Loss:0.499 AVG Training Acc 80.40 % AVG Validation Acc 79.96 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:180/200 AVG Training Loss:0.480 AVG Validation Loss:0.499 AVG Training Acc 80.27 % AVG Validation Acc 79.87 %\n",
      "Epoch:190/200 AVG Training Loss:0.480 AVG Validation Loss:0.499 AVG Training Acc 80.33 % AVG Validation Acc 79.87 %\n",
      "Epoch:200/200 AVG Training Loss:0.479 AVG Validation Loss:0.499 AVG Training Acc 80.35 % AVG Validation Acc 79.96 %\n",
      "Split 289\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26be7a94ef0e4be39183071c3d86c4f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.493 AVG Training Acc 80.15 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.491 AVG Training Acc 80.20 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.487 AVG Validation Loss:0.493 AVG Training Acc 80.24 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.483 AVG Validation Loss:0.492 AVG Training Acc 80.41 % AVG Validation Acc 80.05 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.465 AVG Validation Loss:0.505 AVG Training Acc 80.73 % AVG Validation Acc 79.51 %\n",
      "Epoch:70/200 AVG Training Loss:0.460 AVG Validation Loss:0.513 AVG Training Acc 80.90 % AVG Validation Acc 79.60 %\n",
      "Epoch:80/200 AVG Training Loss:0.454 AVG Validation Loss:0.521 AVG Training Acc 81.16 % AVG Validation Acc 79.42 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.452 AVG Validation Loss:0.518 AVG Training Acc 81.30 % AVG Validation Acc 79.42 %\n",
      "Epoch:100/200 AVG Training Loss:0.451 AVG Validation Loss:0.528 AVG Training Acc 81.16 % AVG Validation Acc 79.06 %\n",
      "Epoch:110/200 AVG Training Loss:0.450 AVG Validation Loss:0.521 AVG Training Acc 81.18 % AVG Validation Acc 79.06 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.448 AVG Validation Loss:0.527 AVG Training Acc 81.35 % AVG Validation Acc 79.24 %\n",
      "Epoch:130/200 AVG Training Loss:0.449 AVG Validation Loss:0.528 AVG Training Acc 81.38 % AVG Validation Acc 79.51 %\n",
      "Epoch:140/200 AVG Training Loss:0.450 AVG Validation Loss:0.523 AVG Training Acc 81.34 % AVG Validation Acc 79.24 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.448 AVG Validation Loss:0.524 AVG Training Acc 81.37 % AVG Validation Acc 79.06 %\n",
      "Epoch:160/200 AVG Training Loss:0.448 AVG Validation Loss:0.523 AVG Training Acc 81.35 % AVG Validation Acc 79.42 %\n",
      "Epoch:170/200 AVG Training Loss:0.450 AVG Validation Loss:0.522 AVG Training Acc 81.35 % AVG Validation Acc 79.60 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.449 AVG Validation Loss:0.526 AVG Training Acc 81.32 % AVG Validation Acc 79.33 %\n",
      "Epoch:190/200 AVG Training Loss:0.450 AVG Validation Loss:0.522 AVG Training Acc 81.37 % AVG Validation Acc 79.51 %\n",
      "Epoch:200/200 AVG Training Loss:0.448 AVG Validation Loss:0.525 AVG Training Acc 81.39 % AVG Validation Acc 79.06 %\n",
      "Split 290\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4af8ea9dcc2f49d3b48e8c5444041671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.498 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.19 % AVG Validation Acc 79.96 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.479 AVG Validation Loss:0.504 AVG Training Acc 80.47 % AVG Validation Acc 79.42 %\n",
      "Epoch:50/200 AVG Training Loss:0.475 AVG Validation Loss:0.508 AVG Training Acc 80.59 % AVG Validation Acc 79.51 %\n",
      "Epoch:60/200 AVG Training Loss:0.469 AVG Validation Loss:0.514 AVG Training Acc 80.90 % AVG Validation Acc 79.24 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.464 AVG Validation Loss:0.518 AVG Training Acc 81.05 % AVG Validation Acc 78.88 %\n",
      "Epoch:80/200 AVG Training Loss:0.462 AVG Validation Loss:0.520 AVG Training Acc 81.10 % AVG Validation Acc 79.15 %\n",
      "Epoch:90/200 AVG Training Loss:0.464 AVG Validation Loss:0.523 AVG Training Acc 80.97 % AVG Validation Acc 78.97 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.462 AVG Validation Loss:0.521 AVG Training Acc 81.06 % AVG Validation Acc 79.24 %\n",
      "Epoch:110/200 AVG Training Loss:0.461 AVG Validation Loss:0.523 AVG Training Acc 81.12 % AVG Validation Acc 78.97 %\n",
      "Epoch:120/200 AVG Training Loss:0.460 AVG Validation Loss:0.523 AVG Training Acc 81.10 % AVG Validation Acc 78.88 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.462 AVG Validation Loss:0.522 AVG Training Acc 80.92 % AVG Validation Acc 79.06 %\n",
      "Epoch:140/200 AVG Training Loss:0.463 AVG Validation Loss:0.522 AVG Training Acc 81.03 % AVG Validation Acc 78.88 %\n",
      "Epoch:150/200 AVG Training Loss:0.462 AVG Validation Loss:0.522 AVG Training Acc 81.05 % AVG Validation Acc 78.97 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.463 AVG Validation Loss:0.522 AVG Training Acc 81.05 % AVG Validation Acc 78.88 %\n",
      "Epoch:170/200 AVG Training Loss:0.460 AVG Validation Loss:0.522 AVG Training Acc 81.15 % AVG Validation Acc 78.79 %\n",
      "Epoch:180/200 AVG Training Loss:0.461 AVG Validation Loss:0.522 AVG Training Acc 81.07 % AVG Validation Acc 78.88 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.461 AVG Validation Loss:0.523 AVG Training Acc 81.12 % AVG Validation Acc 78.97 %\n",
      "Epoch:200/200 AVG Training Loss:0.462 AVG Validation Loss:0.523 AVG Training Acc 81.14 % AVG Validation Acc 78.70 %\n",
      "Split 291\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d740aa193bbe484ebb1620058c1a2091",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.497 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.18 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.483 AVG Validation Loss:0.500 AVG Training Acc 80.21 % AVG Validation Acc 79.89 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.495 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.17 % AVG Validation Acc 80.16 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.18 % AVG Validation Acc 80.07 %\n",
      "Epoch:90/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.18 % AVG Validation Acc 80.07 %\n",
      "Epoch:100/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.493 AVG Validation Loss:0.496 AVG Training Acc 80.16 % AVG Validation Acc 80.07 %\n",
      "Epoch:120/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.20 % AVG Validation Acc 80.07 %\n",
      "Epoch:130/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.16 % AVG Validation Acc 80.16 %\n",
      "Epoch:140/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch:160/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.18 % AVG Validation Acc 80.07 %\n",
      "Epoch:170/200 AVG Training Loss:0.493 AVG Validation Loss:0.494 AVG Training Acc 80.16 % AVG Validation Acc 80.07 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.18 % AVG Validation Acc 80.07 %\n",
      "Epoch:190/200 AVG Training Loss:0.491 AVG Validation Loss:0.492 AVG Training Acc 80.18 % AVG Validation Acc 80.16 %\n",
      "Epoch:200/200 AVG Training Loss:0.491 AVG Validation Loss:0.495 AVG Training Acc 80.19 % AVG Validation Acc 80.07 %\n",
      "Split 292\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd265734fb84b59a3fa8104821d1ed2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.497 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.09 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.25 % AVG Validation Acc 80.16 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.477 AVG Validation Loss:0.504 AVG Training Acc 80.42 % AVG Validation Acc 80.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.470 AVG Validation Loss:0.519 AVG Training Acc 80.90 % AVG Validation Acc 79.53 %\n",
      "Epoch:60/200 AVG Training Loss:0.464 AVG Validation Loss:0.527 AVG Training Acc 81.16 % AVG Validation Acc 79.35 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.458 AVG Validation Loss:0.524 AVG Training Acc 81.27 % AVG Validation Acc 79.53 %\n",
      "Epoch:80/200 AVG Training Loss:0.458 AVG Validation Loss:0.532 AVG Training Acc 81.23 % AVG Validation Acc 79.26 %\n",
      "Epoch:90/200 AVG Training Loss:0.457 AVG Validation Loss:0.530 AVG Training Acc 81.39 % AVG Validation Acc 79.35 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.456 AVG Validation Loss:0.532 AVG Training Acc 81.32 % AVG Validation Acc 79.62 %\n",
      "Epoch:110/200 AVG Training Loss:0.455 AVG Validation Loss:0.534 AVG Training Acc 81.32 % AVG Validation Acc 79.44 %\n",
      "Epoch:120/200 AVG Training Loss:0.455 AVG Validation Loss:0.534 AVG Training Acc 81.40 % AVG Validation Acc 79.08 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.454 AVG Validation Loss:0.535 AVG Training Acc 81.54 % AVG Validation Acc 79.26 %\n",
      "Epoch:140/200 AVG Training Loss:0.457 AVG Validation Loss:0.535 AVG Training Acc 81.35 % AVG Validation Acc 79.17 %\n",
      "Epoch:150/200 AVG Training Loss:0.456 AVG Validation Loss:0.537 AVG Training Acc 81.31 % AVG Validation Acc 79.26 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.455 AVG Validation Loss:0.535 AVG Training Acc 81.43 % AVG Validation Acc 79.35 %\n",
      "Epoch:170/200 AVG Training Loss:0.456 AVG Validation Loss:0.535 AVG Training Acc 81.36 % AVG Validation Acc 79.35 %\n",
      "Epoch:180/200 AVG Training Loss:0.455 AVG Validation Loss:0.536 AVG Training Acc 81.38 % AVG Validation Acc 79.44 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.456 AVG Validation Loss:0.534 AVG Training Acc 81.37 % AVG Validation Acc 79.44 %\n",
      "Epoch:200/200 AVG Training Loss:0.455 AVG Validation Loss:0.542 AVG Training Acc 81.40 % AVG Validation Acc 79.26 %\n",
      "Split 293\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fa17b6da38e42ddbe6fcf1f710beeec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.493 AVG Validation Loss:0.493 AVG Training Acc 80.14 % AVG Validation Acc 80.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.495 AVG Training Acc 80.15 % AVG Validation Acc 80.16 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.486 AVG Validation Loss:0.497 AVG Training Acc 80.22 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.478 AVG Validation Loss:0.509 AVG Training Acc 80.45 % AVG Validation Acc 80.07 %\n",
      "Epoch:60/200 AVG Training Loss:0.474 AVG Validation Loss:0.519 AVG Training Acc 80.52 % AVG Validation Acc 79.89 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.470 AVG Validation Loss:0.523 AVG Training Acc 80.64 % AVG Validation Acc 79.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.469 AVG Validation Loss:0.523 AVG Training Acc 80.72 % AVG Validation Acc 79.80 %\n",
      "Epoch:90/200 AVG Training Loss:0.469 AVG Validation Loss:0.523 AVG Training Acc 80.69 % AVG Validation Acc 79.89 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.469 AVG Validation Loss:0.525 AVG Training Acc 80.79 % AVG Validation Acc 79.89 %\n",
      "Epoch:110/200 AVG Training Loss:0.470 AVG Validation Loss:0.524 AVG Training Acc 80.64 % AVG Validation Acc 79.89 %\n",
      "Epoch:120/200 AVG Training Loss:0.470 AVG Validation Loss:0.525 AVG Training Acc 80.79 % AVG Validation Acc 79.80 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.470 AVG Validation Loss:0.525 AVG Training Acc 80.66 % AVG Validation Acc 79.80 %\n",
      "Epoch:140/200 AVG Training Loss:0.468 AVG Validation Loss:0.526 AVG Training Acc 80.83 % AVG Validation Acc 79.89 %\n",
      "Epoch:150/200 AVG Training Loss:0.470 AVG Validation Loss:0.523 AVG Training Acc 80.77 % AVG Validation Acc 79.89 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.469 AVG Validation Loss:0.525 AVG Training Acc 80.84 % AVG Validation Acc 79.89 %\n",
      "Epoch:170/200 AVG Training Loss:0.470 AVG Validation Loss:0.521 AVG Training Acc 80.71 % AVG Validation Acc 79.89 %\n",
      "Epoch:180/200 AVG Training Loss:0.469 AVG Validation Loss:0.519 AVG Training Acc 80.76 % AVG Validation Acc 79.89 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.471 AVG Validation Loss:0.526 AVG Training Acc 80.76 % AVG Validation Acc 79.89 %\n",
      "Epoch:200/200 AVG Training Loss:0.468 AVG Validation Loss:0.521 AVG Training Acc 80.75 % AVG Validation Acc 79.89 %\n",
      "Split 294\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77bcebd27cf84e039adcda45153ea7c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.497 AVG Validation Loss:0.495 AVG Training Acc 80.12 % AVG Validation Acc 80.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.492 AVG Training Acc 80.20 % AVG Validation Acc 80.25 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.480 AVG Validation Loss:0.494 AVG Training Acc 80.42 % AVG Validation Acc 79.62 %\n",
      "Epoch:40/200 AVG Training Loss:0.473 AVG Validation Loss:0.500 AVG Training Acc 80.75 % AVG Validation Acc 79.71 %\n",
      "Epoch:50/200 AVG Training Loss:0.467 AVG Validation Loss:0.509 AVG Training Acc 80.97 % AVG Validation Acc 79.53 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.465 AVG Validation Loss:0.512 AVG Training Acc 80.97 % AVG Validation Acc 79.53 %\n",
      "Epoch:70/200 AVG Training Loss:0.463 AVG Validation Loss:0.517 AVG Training Acc 81.04 % AVG Validation Acc 79.44 %\n",
      "Epoch:80/200 AVG Training Loss:0.462 AVG Validation Loss:0.517 AVG Training Acc 81.07 % AVG Validation Acc 78.99 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.460 AVG Validation Loss:0.521 AVG Training Acc 81.23 % AVG Validation Acc 79.53 %\n",
      "Epoch:100/200 AVG Training Loss:0.462 AVG Validation Loss:0.519 AVG Training Acc 81.01 % AVG Validation Acc 79.17 %\n",
      "Epoch:110/200 AVG Training Loss:0.460 AVG Validation Loss:0.517 AVG Training Acc 81.19 % AVG Validation Acc 79.35 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:120/200 AVG Training Loss:0.461 AVG Validation Loss:0.520 AVG Training Acc 81.20 % AVG Validation Acc 79.35 %\n",
      "Epoch:130/200 AVG Training Loss:0.460 AVG Validation Loss:0.518 AVG Training Acc 81.14 % AVG Validation Acc 79.44 %\n",
      "Epoch:140/200 AVG Training Loss:0.462 AVG Validation Loss:0.520 AVG Training Acc 81.15 % AVG Validation Acc 79.26 %\n",
      "Epoch:150/200 AVG Training Loss:0.460 AVG Validation Loss:0.522 AVG Training Acc 81.17 % AVG Validation Acc 79.26 %\n",
      "Epoch   150: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.459 AVG Validation Loss:0.521 AVG Training Acc 81.27 % AVG Validation Acc 79.26 %\n",
      "Epoch:170/200 AVG Training Loss:0.461 AVG Validation Loss:0.516 AVG Training Acc 81.00 % AVG Validation Acc 79.35 %\n",
      "Epoch:180/200 AVG Training Loss:0.460 AVG Validation Loss:0.522 AVG Training Acc 81.13 % AVG Validation Acc 79.26 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.461 AVG Validation Loss:0.520 AVG Training Acc 81.13 % AVG Validation Acc 79.26 %\n",
      "Epoch:200/200 AVG Training Loss:0.460 AVG Validation Loss:0.520 AVG Training Acc 81.16 % AVG Validation Acc 79.53 %\n",
      "Split 295\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cef55cf32964356a680e6f3358c336f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.493 AVG Validation Loss:0.498 AVG Training Acc 80.15 % AVG Validation Acc 80.07 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.07 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.498 AVG Training Acc 80.17 % AVG Validation Acc 80.07 %\n",
      "Epoch:40/200 AVG Training Loss:0.482 AVG Validation Loss:0.509 AVG Training Acc 80.29 % AVG Validation Acc 80.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.492 AVG Validation Loss:0.498 AVG Training Acc 80.27 % AVG Validation Acc 80.07 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.484 AVG Validation Loss:0.499 AVG Training Acc 80.34 % AVG Validation Acc 79.98 %\n",
      "Epoch:70/200 AVG Training Loss:0.482 AVG Validation Loss:0.501 AVG Training Acc 80.45 % AVG Validation Acc 79.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.478 AVG Validation Loss:0.499 AVG Training Acc 80.57 % AVG Validation Acc 80.16 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.474 AVG Validation Loss:0.503 AVG Training Acc 80.72 % AVG Validation Acc 79.80 %\n",
      "Epoch:100/200 AVG Training Loss:0.473 AVG Validation Loss:0.504 AVG Training Acc 80.71 % AVG Validation Acc 79.89 %\n",
      "Epoch:110/200 AVG Training Loss:0.473 AVG Validation Loss:0.502 AVG Training Acc 80.78 % AVG Validation Acc 79.89 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.473 AVG Validation Loss:0.505 AVG Training Acc 80.71 % AVG Validation Acc 79.62 %\n",
      "Epoch:130/200 AVG Training Loss:0.472 AVG Validation Loss:0.500 AVG Training Acc 80.75 % AVG Validation Acc 79.89 %\n",
      "Epoch:140/200 AVG Training Loss:0.472 AVG Validation Loss:0.504 AVG Training Acc 80.73 % AVG Validation Acc 79.62 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.473 AVG Validation Loss:0.502 AVG Training Acc 80.76 % AVG Validation Acc 79.80 %\n",
      "Epoch:160/200 AVG Training Loss:0.473 AVG Validation Loss:0.504 AVG Training Acc 80.73 % AVG Validation Acc 79.71 %\n",
      "Epoch:170/200 AVG Training Loss:0.474 AVG Validation Loss:0.504 AVG Training Acc 80.69 % AVG Validation Acc 79.89 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.473 AVG Validation Loss:0.504 AVG Training Acc 80.63 % AVG Validation Acc 79.44 %\n",
      "Epoch:190/200 AVG Training Loss:0.473 AVG Validation Loss:0.503 AVG Training Acc 80.73 % AVG Validation Acc 79.71 %\n",
      "Epoch:200/200 AVG Training Loss:0.472 AVG Validation Loss:0.502 AVG Training Acc 80.66 % AVG Validation Acc 79.71 %\n",
      "Split 296\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5e6012f9f5544899fb3a3731c48dd08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.19 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.478 AVG Validation Loss:0.497 AVG Training Acc 80.69 % AVG Validation Acc 79.69 %\n",
      "Epoch:50/200 AVG Training Loss:0.471 AVG Validation Loss:0.500 AVG Training Acc 81.05 % AVG Validation Acc 79.51 %\n",
      "Epoch:60/200 AVG Training Loss:0.467 AVG Validation Loss:0.503 AVG Training Acc 81.16 % AVG Validation Acc 79.33 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.465 AVG Validation Loss:0.504 AVG Training Acc 81.27 % AVG Validation Acc 79.24 %\n",
      "Epoch:80/200 AVG Training Loss:0.465 AVG Validation Loss:0.505 AVG Training Acc 81.33 % AVG Validation Acc 79.33 %\n",
      "Epoch:90/200 AVG Training Loss:0.466 AVG Validation Loss:0.504 AVG Training Acc 81.27 % AVG Validation Acc 79.33 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.465 AVG Validation Loss:0.504 AVG Training Acc 81.37 % AVG Validation Acc 79.33 %\n",
      "Epoch:110/200 AVG Training Loss:0.464 AVG Validation Loss:0.504 AVG Training Acc 81.31 % AVG Validation Acc 79.33 %\n",
      "Epoch:120/200 AVG Training Loss:0.464 AVG Validation Loss:0.505 AVG Training Acc 81.36 % AVG Validation Acc 79.33 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:130/200 AVG Training Loss:0.464 AVG Validation Loss:0.504 AVG Training Acc 81.43 % AVG Validation Acc 79.24 %\n",
      "Epoch:140/200 AVG Training Loss:0.464 AVG Validation Loss:0.504 AVG Training Acc 81.33 % AVG Validation Acc 79.33 %\n",
      "Epoch:150/200 AVG Training Loss:0.465 AVG Validation Loss:0.505 AVG Training Acc 81.30 % AVG Validation Acc 79.33 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:160/200 AVG Training Loss:0.463 AVG Validation Loss:0.504 AVG Training Acc 81.42 % AVG Validation Acc 79.24 %\n",
      "Epoch:170/200 AVG Training Loss:0.464 AVG Validation Loss:0.505 AVG Training Acc 81.28 % AVG Validation Acc 79.42 %\n",
      "Epoch:180/200 AVG Training Loss:0.462 AVG Validation Loss:0.505 AVG Training Acc 81.42 % AVG Validation Acc 79.33 %\n",
      "Epoch   184: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:190/200 AVG Training Loss:0.465 AVG Validation Loss:0.505 AVG Training Acc 81.37 % AVG Validation Acc 79.33 %\n",
      "Epoch:200/200 AVG Training Loss:0.463 AVG Validation Loss:0.505 AVG Training Acc 81.36 % AVG Validation Acc 79.33 %\n",
      "Split 297\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ac721123cb7450ea81bf71bbeee2b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.495 AVG Training Acc 80.12 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.490 AVG Validation Loss:0.493 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.481 AVG Validation Loss:0.495 AVG Training Acc 80.22 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.477 AVG Validation Loss:0.497 AVG Training Acc 80.38 % AVG Validation Acc 80.32 %\n",
      "Epoch:60/200 AVG Training Loss:0.474 AVG Validation Loss:0.499 AVG Training Acc 80.55 % AVG Validation Acc 80.14 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.471 AVG Validation Loss:0.500 AVG Training Acc 80.53 % AVG Validation Acc 79.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.470 AVG Validation Loss:0.504 AVG Training Acc 80.64 % AVG Validation Acc 79.87 %\n",
      "Epoch:90/200 AVG Training Loss:0.469 AVG Validation Loss:0.505 AVG Training Acc 80.57 % AVG Validation Acc 79.96 %\n",
      "Epoch:100/200 AVG Training Loss:0.468 AVG Validation Loss:0.501 AVG Training Acc 80.58 % AVG Validation Acc 80.05 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.469 AVG Validation Loss:0.504 AVG Training Acc 80.63 % AVG Validation Acc 79.96 %\n",
      "Epoch:120/200 AVG Training Loss:0.469 AVG Validation Loss:0.502 AVG Training Acc 80.65 % AVG Validation Acc 79.96 %\n",
      "Epoch:130/200 AVG Training Loss:0.467 AVG Validation Loss:0.502 AVG Training Acc 80.67 % AVG Validation Acc 80.05 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.468 AVG Validation Loss:0.503 AVG Training Acc 80.70 % AVG Validation Acc 79.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.468 AVG Validation Loss:0.506 AVG Training Acc 80.61 % AVG Validation Acc 79.87 %\n",
      "Epoch:160/200 AVG Training Loss:0.468 AVG Validation Loss:0.507 AVG Training Acc 80.63 % AVG Validation Acc 79.87 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.468 AVG Validation Loss:0.507 AVG Training Acc 80.74 % AVG Validation Acc 79.96 %\n",
      "Epoch:180/200 AVG Training Loss:0.468 AVG Validation Loss:0.502 AVG Training Acc 80.61 % AVG Validation Acc 79.96 %\n",
      "Epoch:190/200 AVG Training Loss:0.469 AVG Validation Loss:0.503 AVG Training Acc 80.67 % AVG Validation Acc 79.96 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.468 AVG Validation Loss:0.505 AVG Training Acc 80.67 % AVG Validation Acc 79.87 %\n",
      "Split 298\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b474999355984fdab63e3c60c961dc6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.496 AVG Validation Loss:0.497 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.492 AVG Validation Loss:0.496 AVG Training Acc 80.11 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.490 AVG Validation Loss:0.495 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.489 AVG Validation Loss:0.490 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.485 AVG Validation Loss:0.488 AVG Training Acc 80.21 % AVG Validation Acc 80.14 %\n",
      "Epoch:70/200 AVG Training Loss:0.479 AVG Validation Loss:0.485 AVG Training Acc 80.34 % AVG Validation Acc 80.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.478 AVG Validation Loss:0.489 AVG Training Acc 80.34 % AVG Validation Acc 79.87 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.476 AVG Validation Loss:0.490 AVG Training Acc 80.41 % AVG Validation Acc 79.78 %\n",
      "Epoch:100/200 AVG Training Loss:0.475 AVG Validation Loss:0.488 AVG Training Acc 80.52 % AVG Validation Acc 79.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.475 AVG Validation Loss:0.489 AVG Training Acc 80.41 % AVG Validation Acc 79.78 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.475 AVG Validation Loss:0.490 AVG Training Acc 80.44 % AVG Validation Acc 79.96 %\n",
      "Epoch:130/200 AVG Training Loss:0.475 AVG Validation Loss:0.490 AVG Training Acc 80.42 % AVG Validation Acc 79.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.473 AVG Validation Loss:0.491 AVG Training Acc 80.46 % AVG Validation Acc 79.96 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.475 AVG Validation Loss:0.493 AVG Training Acc 80.51 % AVG Validation Acc 79.96 %\n",
      "Epoch:160/200 AVG Training Loss:0.475 AVG Validation Loss:0.492 AVG Training Acc 80.39 % AVG Validation Acc 79.96 %\n",
      "Epoch:170/200 AVG Training Loss:0.474 AVG Validation Loss:0.491 AVG Training Acc 80.38 % AVG Validation Acc 79.96 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.475 AVG Validation Loss:0.489 AVG Training Acc 80.44 % AVG Validation Acc 79.87 %\n",
      "Epoch:190/200 AVG Training Loss:0.475 AVG Validation Loss:0.494 AVG Training Acc 80.38 % AVG Validation Acc 79.96 %\n",
      "Epoch:200/200 AVG Training Loss:0.474 AVG Validation Loss:0.489 AVG Training Acc 80.46 % AVG Validation Acc 79.87 %\n",
      "Split 299\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec7e52f44d541fd84156b943a8e0994",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.494 AVG Validation Loss:0.496 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.494 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.489 AVG Validation Loss:0.491 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:40/200 AVG Training Loss:0.488 AVG Validation Loss:0.491 AVG Training Acc 80.23 % AVG Validation Acc 80.14 %\n",
      "Epoch:50/200 AVG Training Loss:0.477 AVG Validation Loss:0.499 AVG Training Acc 80.42 % AVG Validation Acc 80.14 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.460 AVG Validation Loss:0.501 AVG Training Acc 80.69 % AVG Validation Acc 79.96 %\n",
      "Epoch:70/200 AVG Training Loss:0.451 AVG Validation Loss:0.513 AVG Training Acc 80.96 % AVG Validation Acc 79.87 %\n",
      "Epoch:80/200 AVG Training Loss:0.441 AVG Validation Loss:0.524 AVG Training Acc 81.15 % AVG Validation Acc 79.78 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.436 AVG Validation Loss:0.539 AVG Training Acc 81.51 % AVG Validation Acc 79.60 %\n",
      "Epoch:100/200 AVG Training Loss:0.432 AVG Validation Loss:0.531 AVG Training Acc 81.68 % AVG Validation Acc 79.24 %\n",
      "Epoch:110/200 AVG Training Loss:0.433 AVG Validation Loss:0.536 AVG Training Acc 81.50 % AVG Validation Acc 79.15 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.431 AVG Validation Loss:0.544 AVG Training Acc 81.55 % AVG Validation Acc 79.15 %\n",
      "Epoch:130/200 AVG Training Loss:0.433 AVG Validation Loss:0.539 AVG Training Acc 81.56 % AVG Validation Acc 79.06 %\n",
      "Epoch:140/200 AVG Training Loss:0.430 AVG Validation Loss:0.540 AVG Training Acc 81.86 % AVG Validation Acc 79.06 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.429 AVG Validation Loss:0.542 AVG Training Acc 81.79 % AVG Validation Acc 78.97 %\n",
      "Epoch:160/200 AVG Training Loss:0.432 AVG Validation Loss:0.545 AVG Training Acc 81.32 % AVG Validation Acc 79.24 %\n",
      "Epoch:170/200 AVG Training Loss:0.429 AVG Validation Loss:0.538 AVG Training Acc 81.90 % AVG Validation Acc 78.97 %\n",
      "Epoch:180/200 AVG Training Loss:0.431 AVG Validation Loss:0.537 AVG Training Acc 81.69 % AVG Validation Acc 79.33 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.430 AVG Validation Loss:0.546 AVG Training Acc 81.75 % AVG Validation Acc 79.42 %\n",
      "Epoch:200/200 AVG Training Loss:0.432 AVG Validation Loss:0.543 AVG Training Acc 81.69 % AVG Validation Acc 78.79 %\n",
      "Split 300\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dabd911b97b43a6b35d9a9c2eab0bd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:0.496 AVG Training Acc 80.13 % AVG Validation Acc 80.14 %\n",
      "Epoch:20/200 AVG Training Loss:0.491 AVG Validation Loss:0.494 AVG Training Acc 80.14 % AVG Validation Acc 80.14 %\n",
      "Epoch:30/200 AVG Training Loss:0.488 AVG Validation Loss:0.493 AVG Training Acc 80.18 % AVG Validation Acc 80.05 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.478 AVG Validation Loss:0.494 AVG Training Acc 80.45 % AVG Validation Acc 79.87 %\n",
      "Epoch:50/200 AVG Training Loss:0.468 AVG Validation Loss:0.500 AVG Training Acc 80.82 % AVG Validation Acc 79.51 %\n",
      "Epoch:60/200 AVG Training Loss:0.461 AVG Validation Loss:0.508 AVG Training Acc 81.17 % AVG Validation Acc 79.69 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.454 AVG Validation Loss:0.520 AVG Training Acc 81.38 % AVG Validation Acc 79.42 %\n",
      "Epoch:80/200 AVG Training Loss:0.452 AVG Validation Loss:0.517 AVG Training Acc 81.27 % AVG Validation Acc 79.15 %\n",
      "Epoch:90/200 AVG Training Loss:0.452 AVG Validation Loss:0.515 AVG Training Acc 81.58 % AVG Validation Acc 79.06 %\n",
      "Epoch:100/200 AVG Training Loss:0.449 AVG Validation Loss:0.520 AVG Training Acc 81.59 % AVG Validation Acc 79.06 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.450 AVG Validation Loss:0.515 AVG Training Acc 81.40 % AVG Validation Acc 78.97 %\n",
      "Epoch:120/200 AVG Training Loss:0.451 AVG Validation Loss:0.514 AVG Training Acc 81.56 % AVG Validation Acc 78.79 %\n",
      "Epoch:130/200 AVG Training Loss:0.452 AVG Validation Loss:0.516 AVG Training Acc 81.43 % AVG Validation Acc 78.79 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:140/200 AVG Training Loss:0.450 AVG Validation Loss:0.511 AVG Training Acc 81.50 % AVG Validation Acc 78.97 %\n",
      "Epoch:150/200 AVG Training Loss:0.451 AVG Validation Loss:0.516 AVG Training Acc 81.46 % AVG Validation Acc 78.97 %\n",
      "Epoch:160/200 AVG Training Loss:0.450 AVG Validation Loss:0.516 AVG Training Acc 81.26 % AVG Validation Acc 79.06 %\n",
      "Epoch   162: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:170/200 AVG Training Loss:0.449 AVG Validation Loss:0.515 AVG Training Acc 81.36 % AVG Validation Acc 79.15 %\n",
      "Epoch:180/200 AVG Training Loss:0.450 AVG Validation Loss:0.514 AVG Training Acc 81.56 % AVG Validation Acc 79.06 %\n",
      "Epoch:190/200 AVG Training Loss:0.451 AVG Validation Loss:0.516 AVG Training Acc 81.33 % AVG Validation Acc 79.06 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-08.\n",
      "Epoch:200/200 AVG Training Loss:0.449 AVG Validation Loss:0.516 AVG Training Acc 81.53 % AVG Validation Acc 79.06 %\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(list(course_programs.keys())[3:]):\n",
    "    \n",
    "    print(i)\n",
    "    threshold_dict = {} #dict to store information in for each threshold\n",
    "    data = deepcopy(course_programs[i])\n",
    "    \n",
    "    data.set_index(['course', 'userid'], drop = True, inplace = True)\n",
    "    data.fillna(0, inplace = True)\n",
    "    \n",
    "    #set X and Y columns\n",
    "    X = data[data.columns[:25]] #different timesteps\n",
    "    y = data[data.columns[-2:]] #the 4 different putative targets\n",
    "    \n",
    "    for k in tqdm(targets):\n",
    "        print(k)\n",
    "        \n",
    "        #Start with train test split\n",
    "        X_train_val, X_test, y_train_val, y_test, = train_test_split(\n",
    "                                    X,\n",
    "                                   y[k], #replace when going for multi-target \n",
    "                                   test_size = 0.20,\n",
    "                                   random_state = 15,\n",
    "                                   shuffle=True,\n",
    "                                   stratify = y[k] #replace when going for multi-target\n",
    "                                    )\n",
    "        \n",
    "        #create dict to store fold performance\n",
    "        foldperf={}\n",
    "        \n",
    "        #reset \"best accuracy for treshold i and target k\"\n",
    "        best_accuracy = 0\n",
    "\n",
    "        #make train_val split\n",
    "        for fold, (train_idx,val_idx) in tqdm(enumerate(splits.split(X_train_val, y_train_val))):\n",
    "\n",
    "            print('Split {}'.format(fold + 1))\n",
    "            \n",
    "            #make split between train and Val\n",
    "            X_train, y_train = X_train_val.iloc[train_idx], y_train_val.iloc[train_idx]\n",
    "            X_val, y_val = X_train_val.iloc[val_idx], y_train_val.iloc[val_idx]\n",
    "            \n",
    "            #apply scaling after \n",
    "            X_train, X_val = normalize(X_train, X_val, 'Standard')\n",
    "            \n",
    "            #second, convert everything to pytorch tensor - we will convert to tensor dataset and \n",
    "            X_train_tensors = Variable(torch.Tensor(X_train.values))\n",
    "            X_val_tensors = Variable(torch.Tensor(X_val.values))\n",
    "\n",
    "            y_train_tensors = Variable(torch.Tensor(y_train.values))\n",
    "            y_val_tensors = Variable(torch.Tensor(y_val.values)) \n",
    "\n",
    "            #reshaping to rows, timestamps, features \n",
    "            X_train_tensors = torch.reshape(X_train_tensors,   (X_train_tensors.shape[0], X_train_tensors.shape[1], 1))\n",
    "            X_val_tensors = torch.reshape(X_val_tensors,  (X_val_tensors.shape[0], X_val_tensors.shape[1], 1))\n",
    "        \n",
    "            #convert y tensors to format longtensor\n",
    "            y_train_tensors = y_train_tensors.type(torch.cuda.LongTensor)\n",
    "            y_val_tensors = y_val_tensors.type(torch.cuda.LongTensor)\n",
    "            \n",
    "            #create Tensor Datasets and dataloaders for both Train and Val\n",
    "            train_dataset = TensorDataset(X_train_tensors, y_train_tensors)\n",
    "            val_dataset = TensorDataset(X_val_tensors, y_val_tensors)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "            #creates new model for each \n",
    "            model = LSTM_Uni(num_classes, input_size, hidden_size, num_layers, X_train_tensors.shape[1]).to('cuda') #our lstm class\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "            scheduler = ReduceLROnPlateau(optimizer, \n",
    "                                  'min', \n",
    "                                  patience = 10,\n",
    "                                  cooldown = 20,\n",
    "                                 verbose = True)\n",
    "    \n",
    "            history = {'train_loss': [], 'val_loss': [],'train_acc':[],'val_acc':[], 'precision': [],\n",
    "                      'recall' : [], 'auroc': []}\n",
    "\n",
    "            for epoch in tqdm(range(num_epochs)):\n",
    "                train_loss, train_correct=train_epoch(model,train_loader,criterion,optimizer)\n",
    "                val_loss, val_correct, precision, recall, auroc = valid_epoch(model,val_loader,criterion)\n",
    "\n",
    "                train_loss = train_loss / len(train_loader.sampler)\n",
    "                train_acc = train_correct / len(train_loader.sampler) * 100\n",
    "                val_loss = val_loss / len(val_loader.sampler)\n",
    "                val_acc = val_correct / len(val_loader.sampler) * 100\n",
    "        \n",
    "        \n",
    "                if (epoch+1) % 10 == 0: \n",
    "                    print(\"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Validation Loss:{:.3f} AVG Training Acc {:.2f} % AVG Validation Acc {:.2f} %\".format(epoch + 1,\n",
    "                                                                                                             num_epochs,\n",
    "                                                                                                             train_loss,\n",
    "                                                                                                             val_loss,\n",
    "                                                                                                             train_acc,\n",
    "                                                                                                             val_acc))\n",
    "                history['train_loss'].append(train_loss)\n",
    "                history['val_loss'].append(val_loss)\n",
    "                history['train_acc'].append(train_acc)\n",
    "                history['val_acc'].append(val_acc)\n",
    "                history['precision'].append(precision)\n",
    "                history['recall'].append(recall)\n",
    "                history['auroc'].append(auroc)\n",
    "                scheduler.step(val_loss)\n",
    "    \n",
    "                if val_acc > best_accuracy:\n",
    "            \n",
    "                #replace best accuracy and save best model\n",
    "                    print(f'New Best Accuracy found: {val_acc:.2f}%\\nEpoch: {epoch + 1}')\n",
    "                    best_accuracy = val_acc\n",
    "                    best = deepcopy(model)\n",
    "                    curr_epoch = epoch + 1\n",
    "                    \n",
    "            #store fold performance\n",
    "            foldperf['fold{}'.format(fold+1)] = history\n",
    "        \n",
    "        #saves fold performance for target \n",
    "        threshold_dict[k] = pd.DataFrame.from_dict(foldperf, orient='index') # convert dict to dataframe\n",
    "        \n",
    "        #explode to get eacxh epoch as a row\n",
    "        threshold_dict[k] = threshold_dict[k].explode(list(threshold_dict[k].columns))\n",
    "        torch.save(best,f\"../Models/{i}/R_Gonz_best_{k}_{curr_epoch}_epochs_relative_clicks.h\")\n",
    "        \n",
    "    # from pandas.io.parsers import ExcelWriter\n",
    "    with pd.ExcelWriter(f\"../Data/Modeling Stage/Results/R_Gonz/Clicks per % duration/25_splits_{i}_{replicas}_replicas_relative_clicks.xlsx\") as writer:  \n",
    "        for sheet in targets:\n",
    "                threshold_dict[sheet].to_excel(writer, sheet_name=str(sheet))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
