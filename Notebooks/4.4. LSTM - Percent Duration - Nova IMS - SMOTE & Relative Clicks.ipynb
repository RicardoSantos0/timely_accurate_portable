{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84eda90e",
   "metadata": {},
   "source": [
    "### Thesis notebook 4.4. - NOVA IMS\n",
    "\n",
    "#### LSTM - Temporal data representation\n",
    "\n",
    "In this notebook, we will finally start our application of temporal representation using LSTMs and bi-directional LSTMs.\n",
    "The argument for the usage of Deep Learning stems from the fact that sequences themselves encode information that can be extracted using Recurrent Neural Networks and, more specifically, Long Short Term Memory Units.\n",
    "\n",
    "#### First Step: Setup a PyTorch environment that enables the use of GPU for training. \n",
    "\n",
    "The following cell wll confirm that the GPU will be the default device to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f27844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pycuda.driver as cuda\n",
    "\n",
    "cuda.init()\n",
    "## Get Id of default device\n",
    "torch.cuda.current_device()\n",
    "# 0\n",
    "cuda.Device(0).name() # '0' is the id of your GPU\n",
    "\n",
    "#set all tensors to gpu\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d95429e",
   "metadata": {},
   "source": [
    "#### Second Step: Import the relevant packages and declare global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6c2d97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary modules/libraries\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "#tqdm to monitor progress\n",
    "from tqdm.notebook import tqdm, trange\n",
    "tqdm.pandas(desc=\"Progress\")\n",
    "\n",
    "#time related features\n",
    "from datetime import timedelta\n",
    "from copy import copy, deepcopy\n",
    "\n",
    "#vizualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#imblearn, scalers, kfold and metrics\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, QuantileTransformer,PowerTransformer\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold, RepeatedStratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, recall_score, classification_report, average_precision_score, precision_recall_curve\n",
    "\n",
    "#import torch related\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable \n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "\n",
    "#and optimizer of learning rate\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "#import pytorch modules\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6c3f1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variables that may come in handy\n",
    "#course threshold sets the % duration that will be considered (1 = 100%)\n",
    "duration_threshold = [0.1, 0.25, 0.33, 0.5, 1]\n",
    "\n",
    "#colors for vizualizations\n",
    "nova_ims_colors = ['#BFD72F', '#5C666C']\n",
    "\n",
    "#standard color for student aggregates\n",
    "student_color = '#474838'\n",
    "\n",
    "#standard color for course aggragates\n",
    "course_color = '#1B3D2F'\n",
    "\n",
    "#standard continuous colormap\n",
    "standard_cmap = 'viridis_r'\n",
    "\n",
    "#Function designed to deal with multiindex and flatten it\n",
    "def flattenHierarchicalCol(col,sep = '_'):\n",
    "    '''converts multiindex columns into single index columns while retaining the hierarchical components'''\n",
    "    if not type(col) is tuple:\n",
    "        return col\n",
    "    else:\n",
    "        new_col = ''\n",
    "        for leveli,level in enumerate(col):\n",
    "            if not level == '':\n",
    "                if not leveli == 0:\n",
    "                    new_col += sep\n",
    "                new_col += level\n",
    "        return new_col\n",
    "    \n",
    "#number of replicas - number of repeats of stratified k fold - in this case 10\n",
    "replicas = 30\n",
    "\n",
    "#names to display on result figures\n",
    "date_names = {\n",
    "             'Date_threshold_10': '10% of Course Duration',   \n",
    "             'Date_threshold_25': '25% of Course Duration', \n",
    "             'Date_threshold_33': '33% of Course Duration', \n",
    "             'Date_threshold_50': '50% of Course Duration', \n",
    "             'Date_threshold_100':'100% of Course Duration', \n",
    "            }\n",
    "\n",
    "target_names = {\n",
    "                'exam_fail' : 'At risk - Exam Grade',\n",
    "                'final_fail' : 'At risk - Final Grade', \n",
    "                'exam_gifted' : 'High performer - Exam Grade', \n",
    "                'final_gifted': 'High performer - Final Grade'\n",
    "                }\n",
    "\n",
    "#targets\n",
    "targets = ['exam_fail' , 'final_fail' , 'exam_gifted' , 'final_gifted']\n",
    "temporal_columns = ['0 to 4%', '4 to 8%', '8 to 12%', '12 to 16%', '16 to 20%', '20 to 24%',\n",
    "       '24 to 28%', '28 to 32%', '32 to 36%', '36 to 40%', '40 to 44%',\n",
    "       '44 to 48%', '48 to 52%', '52 to 56%', '56 to 60%', '60 to 64%',\n",
    "       '64 to 68%', '68 to 72%', '72 to 76%', '76 to 80%', '80 to 84%',\n",
    "       '84 to 88%', '88 to 92%', '92 to 96%', '96 to 100%']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c5ddb6",
   "metadata": {},
   "source": [
    "#### Step 3: Import data and take a preliminary look at it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8a23ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports dataframes\n",
    "course_programs = pd.read_excel(\"../Data/Modeling Stage/Nova_IMS_Temporal_Datasets_25_splits.xlsx\", \n",
    "                                dtype = {\n",
    "                                    'course_encoding' : int,\n",
    "                                    'userid' : int},\n",
    "                               sheet_name = None)\n",
    "\n",
    "#save tables \n",
    "student_list = pd.read_csv('../Data/Modeling Stage/Nova_IMS_Filtered_targets.csv', \n",
    "                         dtype = {\n",
    "                                   'course_encoding': int,\n",
    "                                   'userid' : int,\n",
    "                                   })\n",
    "\n",
    "#drop unnamed 0 column\n",
    "for i in course_programs:\n",
    "        \n",
    "    #merge with the targets we calculated on the other \n",
    "    course_programs[i] = course_programs[i].merge(student_list, on = ['course_encoding', 'userid'], how = 'inner')\n",
    "    course_programs[i].drop(['Unnamed: 0', 'exam_mark', 'final_mark'], axis = 1, inplace = True)\n",
    "    \n",
    "    #convert results to object\n",
    "    course_programs[i]['course_encoding'], course_programs[i]['userid'] = course_programs[i]['course_encoding'].astype(object), course_programs[i]['userid'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bc3c84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9296 entries, 0 to 9295\n",
      "Data columns (total 31 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   course_encoding  9296 non-null   object\n",
      " 1   userid           9296 non-null   object\n",
      " 2   0 to 4%          9296 non-null   int64 \n",
      " 3   4 to 8%          9296 non-null   int64 \n",
      " 4   8 to 12%         9296 non-null   int64 \n",
      " 5   12 to 16%        9296 non-null   int64 \n",
      " 6   16 to 20%        9296 non-null   int64 \n",
      " 7   20 to 24%        9296 non-null   int64 \n",
      " 8   24 to 28%        9296 non-null   int64 \n",
      " 9   28 to 32%        9296 non-null   int64 \n",
      " 10  32 to 36%        9296 non-null   int64 \n",
      " 11  36 to 40%        9296 non-null   int64 \n",
      " 12  40 to 44%        9296 non-null   int64 \n",
      " 13  44 to 48%        9296 non-null   int64 \n",
      " 14  48 to 52%        9296 non-null   int64 \n",
      " 15  52 to 56%        9296 non-null   int64 \n",
      " 16  56 to 60%        9296 non-null   int64 \n",
      " 17  60 to 64%        9296 non-null   int64 \n",
      " 18  64 to 68%        9296 non-null   int64 \n",
      " 19  68 to 72%        9296 non-null   int64 \n",
      " 20  72 to 76%        9296 non-null   int64 \n",
      " 21  76 to 80%        9296 non-null   int64 \n",
      " 22  80 to 84%        9296 non-null   int64 \n",
      " 23  84 to 88%        9296 non-null   int64 \n",
      " 24  88 to 92%        9296 non-null   int64 \n",
      " 25  92 to 96%        9296 non-null   int64 \n",
      " 26  96 to 100%       9296 non-null   int64 \n",
      " 27  exam_fail        9296 non-null   int64 \n",
      " 28  final_fail       9296 non-null   int64 \n",
      " 29  exam_gifted      9296 non-null   int64 \n",
      " 30  final_gifted     9296 non-null   int64 \n",
      "dtypes: int64(29), object(2)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "course_programs['Date_threshold_100'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4a751ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_encoding</th>\n",
       "      <th>userid</th>\n",
       "      <th>0 to 4%</th>\n",
       "      <th>4 to 8%</th>\n",
       "      <th>8 to 12%</th>\n",
       "      <th>12 to 16%</th>\n",
       "      <th>16 to 20%</th>\n",
       "      <th>20 to 24%</th>\n",
       "      <th>24 to 28%</th>\n",
       "      <th>28 to 32%</th>\n",
       "      <th>...</th>\n",
       "      <th>76 to 80%</th>\n",
       "      <th>80 to 84%</th>\n",
       "      <th>84 to 88%</th>\n",
       "      <th>88 to 92%</th>\n",
       "      <th>92 to 96%</th>\n",
       "      <th>96 to 100%</th>\n",
       "      <th>exam_fail</th>\n",
       "      <th>final_fail</th>\n",
       "      <th>exam_gifted</th>\n",
       "      <th>final_gifted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9296.0</td>\n",
       "      <td>9296.0</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.0</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>138.0</td>\n",
       "      <td>1590.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>150.0</td>\n",
       "      <td>3178.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>178.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.081863</td>\n",
       "      <td>8.307874</td>\n",
       "      <td>10.752797</td>\n",
       "      <td>11.193739</td>\n",
       "      <td>10.127797</td>\n",
       "      <td>8.966652</td>\n",
       "      <td>10.545396</td>\n",
       "      <td>11.445245</td>\n",
       "      <td>...</td>\n",
       "      <td>11.718051</td>\n",
       "      <td>13.136403</td>\n",
       "      <td>22.827883</td>\n",
       "      <td>27.341007</td>\n",
       "      <td>12.599613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.201377</td>\n",
       "      <td>0.149957</td>\n",
       "      <td>0.276893</td>\n",
       "      <td>0.308090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.526351</td>\n",
       "      <td>13.580025</td>\n",
       "      <td>13.626754</td>\n",
       "      <td>16.400023</td>\n",
       "      <td>14.291254</td>\n",
       "      <td>12.180177</td>\n",
       "      <td>13.507892</td>\n",
       "      <td>15.932226</td>\n",
       "      <td>...</td>\n",
       "      <td>28.186874</td>\n",
       "      <td>36.690068</td>\n",
       "      <td>47.158607</td>\n",
       "      <td>54.963959</td>\n",
       "      <td>35.194597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.401051</td>\n",
       "      <td>0.357048</td>\n",
       "      <td>0.447487</td>\n",
       "      <td>0.461729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>619.000000</td>\n",
       "      <td>315.000000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>1091.000000</td>\n",
       "      <td>604.000000</td>\n",
       "      <td>747.000000</td>\n",
       "      <td>407.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        course_encoding  userid      0 to 4%      4 to 8%     8 to 12%  \\\n",
       "count            9296.0  9296.0  9296.000000  9296.000000  9296.000000   \n",
       "unique            138.0  1590.0          NaN          NaN          NaN   \n",
       "top               150.0  3178.0          NaN          NaN          NaN   \n",
       "freq              178.0    14.0          NaN          NaN          NaN   \n",
       "mean                NaN     NaN     1.081863     8.307874    10.752797   \n",
       "std                 NaN     NaN     3.526351    13.580025    13.626754   \n",
       "min                 NaN     NaN     0.000000     0.000000     0.000000   \n",
       "25%                 NaN     NaN     0.000000     0.000000     1.000000   \n",
       "50%                 NaN     NaN     0.000000     2.000000     7.000000   \n",
       "75%                 NaN     NaN     1.000000    12.000000    15.000000   \n",
       "max                 NaN     NaN    66.000000   269.000000   360.000000   \n",
       "\n",
       "          12 to 16%    16 to 20%    20 to 24%    24 to 28%    28 to 32%  ...  \\\n",
       "count   9296.000000  9296.000000  9296.000000  9296.000000  9296.000000  ...   \n",
       "unique          NaN          NaN          NaN          NaN          NaN  ...   \n",
       "top             NaN          NaN          NaN          NaN          NaN  ...   \n",
       "freq            NaN          NaN          NaN          NaN          NaN  ...   \n",
       "mean      11.193739    10.127797     8.966652    10.545396    11.445245  ...   \n",
       "std       16.400023    14.291254    12.180177    13.507892    15.932226  ...   \n",
       "min        0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%        2.000000     2.000000     1.000000     2.000000     3.000000  ...   \n",
       "50%        7.000000     6.000000     5.000000     7.000000     7.000000  ...   \n",
       "75%       15.000000    13.000000    13.000000    14.000000    14.000000  ...   \n",
       "max      619.000000   315.000000   248.000000   268.000000   237.000000  ...   \n",
       "\n",
       "          76 to 80%    80 to 84%    84 to 88%    88 to 92%    92 to 96%  \\\n",
       "count   9296.000000  9296.000000  9296.000000  9296.000000  9296.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      11.718051    13.136403    22.827883    27.341007    12.599613   \n",
       "std       28.186874    36.690068    47.158607    54.963959    35.194597   \n",
       "min        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%        2.000000     2.000000     4.000000     2.000000     0.000000   \n",
       "75%       10.000000    10.000000    23.000000    27.000000     5.000000   \n",
       "max      614.000000  1091.000000   604.000000   747.000000   407.000000   \n",
       "\n",
       "        96 to 100%    exam_fail   final_fail  exam_gifted  final_gifted  \n",
       "count       9296.0  9296.000000  9296.000000  9296.000000   9296.000000  \n",
       "unique         NaN          NaN          NaN          NaN           NaN  \n",
       "top            NaN          NaN          NaN          NaN           NaN  \n",
       "freq           NaN          NaN          NaN          NaN           NaN  \n",
       "mean           0.0     0.201377     0.149957     0.276893      0.308090  \n",
       "std            0.0     0.401051     0.357048     0.447487      0.461729  \n",
       "min            0.0     0.000000     0.000000     0.000000      0.000000  \n",
       "25%            0.0     0.000000     0.000000     0.000000      0.000000  \n",
       "50%            0.0     0.000000     0.000000     0.000000      0.000000  \n",
       "75%            0.0     0.000000     0.000000     1.000000      1.000000  \n",
       "max            0.0     1.000000     1.000000     1.000000      1.000000  \n",
       "\n",
       "[11 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "course_programs['Date_threshold_100'].describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3291817",
   "metadata": {},
   "source": [
    "In our second attempt, we are looking to obtain a different result. Instead of using the absolute number of clicks used in each instance, we are instead looking to use the percent number of clicks made by each student relative to the the total number of clicks performed in the curricular unit.\n",
    "\n",
    "For that we will use transform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ea43db1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cf0d9aa3d4c42e2a70ab0b571daf426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "944e318e14604a60bf00b893c22662f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63ae01365f424dfc8412c25d724b30b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5065661795aa41df9e421f1495df6c56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c5f758d5cb4887a39c4220b13b1533",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c5038bca9d4c069da9e3a9a64e637c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in tqdm(course_programs.keys()):\n",
    "    \n",
    "    for j in tqdm(temporal_columns):\n",
    "            course_programs[i][j] = np.where(course_programs[i].fillna(0).groupby('course_encoding')[j].transform('sum') != 0, #where valid operations occur\n",
    "                                             course_programs[i][j].fillna(0) / course_programs[i].fillna(0).groupby('course_encoding')[j].transform('sum') * 100, #calculate percentage\n",
    "                                             0) #otherwise, its 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be722ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function for scalers\n",
    "def normalize(dataset,scaler):\n",
    "    \n",
    "    if scaler == 'MinMax':\n",
    "        pt = MinMaxScaler()\n",
    "    elif scaler == 'Standard':\n",
    "        pt = StandardScaler()\n",
    "    elif scaler == 'Robust':\n",
    "        pt = RobustScaler()\n",
    "    elif scaler == 'Quantile':\n",
    "        pt = QuantileTransformer()\n",
    "    else:\n",
    "        pt = PowerTransformer(method='yeo-johnson')\n",
    "    \n",
    "    data = pt.fit_transform(dataset)\n",
    "    \n",
    "    # convert the array back to a dataframe\n",
    "    normalized_df = pd.DataFrame(data,columns=dataset.columns)\n",
    "    return normalized_df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ea7510e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb32caeb33314333862816231a4d865f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create backup\n",
    "normalized_data = deepcopy(course_programs)\n",
    "\n",
    "#convert index\n",
    "for i in tqdm(normalized_data):\n",
    "    normalized_data[i].set_index(['course_encoding', 'userid'], drop = True, inplace = True)\n",
    "    normalized_data[i].fillna(0, inplace = True)\n",
    "    #Then, apply normalize function to rescale the train columns\n",
    "    normalized_data[i] = normalize(normalized_data[i].filter(temporal_columns),'Standard')\n",
    "    \n",
    "    #and remerge target columns\n",
    "    normalized_data[i][targets] =  deepcopy(course_programs[i][targets])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4d5475",
   "metadata": {},
   "source": [
    "#### Implementing Cross-Validation with Deep Learning Model\n",
    "\n",
    "**1. Create the Deep Learning Model**\n",
    "\n",
    "In this instance, we will follow-up with on the approach used in Chen & Cui - CrossEntropyLoss with applied over a softmax layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a16bd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Uni(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(LSTM_Uni, self).__init__()\n",
    "        self.num_classes = num_classes #number of classes\n",
    "        self.num_layers = num_layers #number of layers\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size = hidden_size #hidden state\n",
    "        self.seq_length = seq_length #sequence length\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first = True) #lstm\n",
    "        \n",
    "        self.dropout = nn.Dropout(p = 0.5)\n",
    "    \n",
    "        self.fc = nn.Linear(self.hidden_size, num_classes) #fully connected last layer\n",
    "\n",
    "    def forward(self,x):\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) #hidden state\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) #internal state\n",
    "        \n",
    "        #Xavier_init for both H_0 and C_0\n",
    "        torch.nn.init.xavier_normal_(h_0)\n",
    "        torch.nn.init.xavier_normal_(c_0)\n",
    "        \n",
    "        # Propagate input through LSTM\n",
    "        lstm_out, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
    "        last_output = hn.view(-1, self.hidden_size) #reshaping the data for Dense layer next\n",
    "        \n",
    "        drop_out = self.dropout(last_output)\n",
    "        pre_softmax = self.fc(drop_out) #Final Output - dense\n",
    "        return pre_softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c356bd",
   "metadata": {},
   "source": [
    "**2. Define the train and validation Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "25b29a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model,dataloader,loss_fn,optimizer):\n",
    "    \n",
    "    train_loss,train_correct=0.0,0 \n",
    "    model.train()\n",
    "    for X, labels in dataloader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)\n",
    "        loss = loss_fn(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * X.size(0)\n",
    "        scores, predictions = torch.max(F.log_softmax(output.data), 1)\n",
    "        train_correct += (predictions == labels).sum().item()\n",
    "        \n",
    "    return train_loss,train_correct\n",
    "  \n",
    "def valid_epoch(model,dataloader,loss_fn):\n",
    "    valid_loss, val_correct = 0.0, 0\n",
    "    targets = []\n",
    "    y_pred = []\n",
    "    probability_1 = []\n",
    "    \n",
    "    model.eval()\n",
    "    for X, labels in dataloader:\n",
    "\n",
    "        output = model(X)\n",
    "        loss=loss_fn(output,labels)\n",
    "        valid_loss+=loss.item()*X.size(0)\n",
    "        probability_1.append(F.softmax(output.data)[:,1])\n",
    "        predictions = torch.argmax(output, dim=1)\n",
    "        val_correct+=(predictions == labels).sum().item()\n",
    "        targets.append(labels)\n",
    "        y_pred.append(predictions)\n",
    "    \n",
    "    #concat all results\n",
    "    targets = torch.cat(targets).data.cpu().numpy()\n",
    "    y_pred = torch.cat(y_pred).data.cpu().numpy()\n",
    "    probability_1 = torch.cat(probability_1).data.cpu().numpy()\n",
    "    \n",
    "    #calculate precision, recall and AUC score\n",
    "    \n",
    "    precision = precision_score(targets, y_pred)\n",
    "    recall = recall_score(targets, y_pred)\n",
    "    auroc = roc_auc_score(targets, probability_1)\n",
    "    \n",
    "    #return all\n",
    "    return valid_loss,val_correct, precision, recall, auroc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4543fb3",
   "metadata": {},
   "source": [
    "**3. Define main hyperparameters of the model, including splits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fcbbef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "num_epochs = 100 #50 epochs\n",
    "learning_rate = 0.01 #0.001 lr\n",
    "input_size = 1 #number of features\n",
    "hidden_size = 40 #number of features in hidden state\n",
    "num_layers = 1 #number of stacked lstm layers\n",
    "\n",
    "#Shape of Output as required for SoftMax Classifier\n",
    "num_classes = 2 #output shape\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "k=10\n",
    "splits= RepeatedStratifiedKFold(n_splits=k, n_repeats=replicas, random_state=15) #kfold of 10 with 30 replicas\n",
    "criterion = nn.CrossEntropyLoss()    # cross-entropy for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20713d9",
   "metadata": {},
   "source": [
    "**4. Make the splits and Start Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45544589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8147aa25f7ca40dcbe70cc0e783b96e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date_threshold_10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44eb02846e68441e95016a733b91d995",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exam_fail\n",
      "Before reshaping:\n",
      "Training Shape torch.Size([11878, 25]) torch.Size([11878])\n",
      "Testing Shape torch.Size([1860, 25]) torch.Size([1860])\n",
      "\n",
      "After reshaping:\n",
      "Training Shape torch.Size([11878, 25, 1]) torch.Size([11878])\n",
      "Testing Shape torch.Size([1860, 25, 1]) torch.Size([1860])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0365506eecb841439095abb2baf67f81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49320dc0affd47e4a6982b190df8cfb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best Accuracy found: 49.66%\n",
      "Epoch: 1\n",
      "New Best Accuracy found: 57.83%\n",
      "Epoch: 3\n",
      "New Best Accuracy found: 59.68%\n",
      "Epoch: 4\n",
      "New Best Accuracy found: 60.77%\n",
      "Epoch: 6\n",
      "New Best Accuracy found: 60.86%\n",
      "Epoch: 7\n",
      "New Best Accuracy found: 61.78%\n",
      "Epoch: 8\n",
      "New Best Accuracy found: 62.46%\n",
      "Epoch: 9\n",
      "Epoch:10/100 AVG Training Loss:0.669 AVG Validation Loss:0.661 AVG Training Acc 59.53 % AVG Validation Acc 61.20 %\n",
      "New Best Accuracy found: 62.96%\n",
      "Epoch: 12\n",
      "New Best Accuracy found: 63.13%\n",
      "Epoch: 14\n",
      "New Best Accuracy found: 64.90%\n",
      "Epoch: 15\n",
      "New Best Accuracy found: 65.07%\n",
      "Epoch: 19\n",
      "Epoch:20/100 AVG Training Loss:0.639 AVG Validation Loss:0.633 AVG Training Acc 63.28 % AVG Validation Acc 64.65 %\n",
      "New Best Accuracy found: 66.25%\n",
      "Epoch: 22\n",
      "New Best Accuracy found: 67.34%\n",
      "Epoch: 24\n",
      "Epoch:30/100 AVG Training Loss:0.631 AVG Validation Loss:0.649 AVG Training Acc 64.86 % AVG Validation Acc 62.12 %\n",
      "New Best Accuracy found: 67.59%\n",
      "Epoch: 36\n",
      "Epoch:40/100 AVG Training Loss:0.620 AVG Validation Loss:0.619 AVG Training Acc 66.41 % AVG Validation Acc 66.67 %\n",
      "New Best Accuracy found: 68.10%\n",
      "Epoch: 44\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-03.\n",
      "New Best Accuracy found: 68.18%\n",
      "Epoch: 49\n",
      "Epoch:50/100 AVG Training Loss:0.559 AVG Validation Loss:0.614 AVG Training Acc 71.58 % AVG Validation Acc 67.76 %\n",
      "New Best Accuracy found: 68.94%\n",
      "Epoch: 52\n",
      "Epoch:60/100 AVG Training Loss:0.529 AVG Validation Loss:0.618 AVG Training Acc 73.02 % AVG Validation Acc 67.59 %\n",
      "New Best Accuracy found: 69.02%\n",
      "Epoch: 67\n",
      "Epoch:70/100 AVG Training Loss:0.511 AVG Validation Loss:0.619 AVG Training Acc 74.48 % AVG Validation Acc 68.77 %\n",
      "New Best Accuracy found: 69.28%\n",
      "Epoch: 73\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/100 AVG Training Loss:0.499 AVG Validation Loss:0.641 AVG Training Acc 75.13 % AVG Validation Acc 68.10 %\n",
      "Epoch:90/100 AVG Training Loss:0.494 AVG Validation Loss:0.633 AVG Training Acc 75.47 % AVG Validation Acc 68.18 %\n",
      "New Best Accuracy found: 69.53%\n",
      "Epoch: 91\n",
      "Epoch:100/100 AVG Training Loss:0.485 AVG Validation Loss:0.638 AVG Training Acc 76.32 % AVG Validation Acc 68.35 %\n",
      "Split 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f662d85f3a61474e92988abc18a6fda5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.666 AVG Validation Loss:0.666 AVG Training Acc 59.84 % AVG Validation Acc 61.62 %\n",
      "Epoch:20/100 AVG Training Loss:0.633 AVG Validation Loss:0.653 AVG Training Acc 63.96 % AVG Validation Acc 61.87 %\n",
      "Epoch:30/100 AVG Training Loss:0.605 AVG Validation Loss:0.633 AVG Training Acc 67.64 % AVG Validation Acc 65.57 %\n",
      "Epoch:40/100 AVG Training Loss:0.605 AVG Validation Loss:0.642 AVG Training Acc 67.66 % AVG Validation Acc 65.07 %\n",
      "Epoch:50/100 AVG Training Loss:0.589 AVG Validation Loss:0.628 AVG Training Acc 69.01 % AVG Validation Acc 64.81 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/100 AVG Training Loss:0.517 AVG Validation Loss:0.600 AVG Training Acc 73.73 % AVG Validation Acc 68.01 %\n",
      "New Best Accuracy found: 69.87%\n",
      "Epoch: 64\n",
      "New Best Accuracy found: 69.95%\n",
      "Epoch: 66\n",
      "Epoch:70/100 AVG Training Loss:0.478 AVG Validation Loss:0.596 AVG Training Acc 76.86 % AVG Validation Acc 70.79 %\n",
      "New Best Accuracy found: 70.79%\n",
      "Epoch: 70\n",
      "Epoch:80/100 AVG Training Loss:0.459 AVG Validation Loss:0.605 AVG Training Acc 77.72 % AVG Validation Acc 70.96 %\n",
      "New Best Accuracy found: 70.96%\n",
      "Epoch: 80\n",
      "New Best Accuracy found: 71.30%\n",
      "Epoch: 83\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/100 AVG Training Loss:0.445 AVG Validation Loss:0.605 AVG Training Acc 78.69 % AVG Validation Acc 70.29 %\n",
      "Epoch:100/100 AVG Training Loss:0.440 AVG Validation Loss:0.611 AVG Training Acc 78.99 % AVG Validation Acc 70.96 %\n",
      "Split 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d92c25995e9440bba68b51c48be44d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.672 AVG Validation Loss:0.689 AVG Training Acc 59.30 % AVG Validation Acc 50.34 %\n",
      "Epoch:20/100 AVG Training Loss:0.657 AVG Validation Loss:0.659 AVG Training Acc 60.44 % AVG Validation Acc 61.45 %\n",
      "Epoch:30/100 AVG Training Loss:0.633 AVG Validation Loss:0.641 AVG Training Acc 64.20 % AVG Validation Acc 64.65 %\n",
      "Epoch:40/100 AVG Training Loss:0.621 AVG Validation Loss:0.635 AVG Training Acc 65.70 % AVG Validation Acc 65.49 %\n",
      "Epoch:50/100 AVG Training Loss:0.603 AVG Validation Loss:0.635 AVG Training Acc 67.60 % AVG Validation Acc 65.32 %\n",
      "Epoch:60/100 AVG Training Loss:0.579 AVG Validation Loss:0.632 AVG Training Acc 69.98 % AVG Validation Acc 66.08 %\n",
      "Epoch:70/100 AVG Training Loss:0.571 AVG Validation Loss:0.628 AVG Training Acc 69.94 % AVG Validation Acc 66.08 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:80/100 AVG Training Loss:0.545 AVG Validation Loss:0.607 AVG Training Acc 72.10 % AVG Validation Acc 68.86 %\n",
      "Epoch:90/100 AVG Training Loss:0.511 AVG Validation Loss:0.619 AVG Training Acc 74.63 % AVG Validation Acc 67.76 %\n",
      "Epoch:100/100 AVG Training Loss:0.486 AVG Validation Loss:0.634 AVG Training Acc 76.23 % AVG Validation Acc 67.76 %\n",
      "Split 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d0c68d948cf459bba3e1f406b8257f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.668 AVG Validation Loss:0.669 AVG Training Acc 59.58 % AVG Validation Acc 58.50 %\n",
      "Epoch:20/100 AVG Training Loss:0.642 AVG Validation Loss:0.644 AVG Training Acc 62.97 % AVG Validation Acc 62.88 %\n",
      "Epoch:30/100 AVG Training Loss:0.631 AVG Validation Loss:0.642 AVG Training Acc 64.79 % AVG Validation Acc 63.55 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/100 AVG Training Loss:0.584 AVG Validation Loss:0.636 AVG Training Acc 68.49 % AVG Validation Acc 66.84 %\n",
      "Epoch:50/100 AVG Training Loss:0.561 AVG Validation Loss:0.637 AVG Training Acc 70.04 % AVG Validation Acc 66.75 %\n",
      "Epoch:60/100 AVG Training Loss:0.549 AVG Validation Loss:0.628 AVG Training Acc 71.23 % AVG Validation Acc 66.58 %\n",
      "Epoch:70/100 AVG Training Loss:0.544 AVG Validation Loss:0.629 AVG Training Acc 71.12 % AVG Validation Acc 66.41 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/100 AVG Training Loss:0.530 AVG Validation Loss:0.632 AVG Training Acc 72.09 % AVG Validation Acc 66.08 %\n",
      "Epoch:90/100 AVG Training Loss:0.529 AVG Validation Loss:0.633 AVG Training Acc 72.70 % AVG Validation Acc 66.33 %\n",
      "Epoch:100/100 AVG Training Loss:0.525 AVG Validation Loss:0.639 AVG Training Acc 72.62 % AVG Validation Acc 67.26 %\n",
      "Split 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1dd28cf3e3c43298211d6baa2409b41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.663 AVG Validation Loss:0.669 AVG Training Acc 61.01 % AVG Validation Acc 58.67 %\n",
      "Epoch:20/100 AVG Training Loss:0.645 AVG Validation Loss:0.680 AVG Training Acc 63.00 % AVG Validation Acc 60.02 %\n",
      "Epoch:30/100 AVG Training Loss:0.628 AVG Validation Loss:0.631 AVG Training Acc 64.98 % AVG Validation Acc 64.48 %\n",
      "Epoch:40/100 AVG Training Loss:0.604 AVG Validation Loss:0.611 AVG Training Acc 67.42 % AVG Validation Acc 65.82 %\n",
      "Epoch:50/100 AVG Training Loss:0.585 AVG Validation Loss:0.624 AVG Training Acc 69.41 % AVG Validation Acc 65.57 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/100 AVG Training Loss:0.518 AVG Validation Loss:0.623 AVG Training Acc 73.83 % AVG Validation Acc 67.93 %\n",
      "Epoch:70/100 AVG Training Loss:0.501 AVG Validation Loss:0.625 AVG Training Acc 75.08 % AVG Validation Acc 68.60 %\n",
      "Epoch:80/100 AVG Training Loss:0.486 AVG Validation Loss:0.639 AVG Training Acc 75.90 % AVG Validation Acc 68.69 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/100 AVG Training Loss:0.479 AVG Validation Loss:0.648 AVG Training Acc 76.16 % AVG Validation Acc 68.60 %\n",
      "Epoch:100/100 AVG Training Loss:0.475 AVG Validation Loss:0.630 AVG Training Acc 76.39 % AVG Validation Acc 69.36 %\n",
      "Split 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "780cbbe03fb4415e861c08e0b470c079",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.666 AVG Validation Loss:0.671 AVG Training Acc 60.26 % AVG Validation Acc 59.09 %\n",
      "Epoch:20/100 AVG Training Loss:0.654 AVG Validation Loss:0.667 AVG Training Acc 61.95 % AVG Validation Acc 59.85 %\n",
      "Epoch:30/100 AVG Training Loss:0.645 AVG Validation Loss:0.664 AVG Training Acc 63.07 % AVG Validation Acc 60.02 %\n",
      "Epoch:40/100 AVG Training Loss:0.628 AVG Validation Loss:0.642 AVG Training Acc 65.20 % AVG Validation Acc 61.70 %\n",
      "Epoch:50/100 AVG Training Loss:0.626 AVG Validation Loss:0.633 AVG Training Acc 65.93 % AVG Validation Acc 63.30 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/100 AVG Training Loss:0.584 AVG Validation Loss:0.631 AVG Training Acc 69.81 % AVG Validation Acc 64.65 %\n",
      "Epoch:70/100 AVG Training Loss:0.553 AVG Validation Loss:0.638 AVG Training Acc 71.90 % AVG Validation Acc 65.57 %\n",
      "Epoch:80/100 AVG Training Loss:0.536 AVG Validation Loss:0.640 AVG Training Acc 73.00 % AVG Validation Acc 65.66 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/100 AVG Training Loss:0.518 AVG Validation Loss:0.656 AVG Training Acc 74.28 % AVG Validation Acc 66.50 %\n",
      "Epoch:100/100 AVG Training Loss:0.514 AVG Validation Loss:0.652 AVG Training Acc 74.72 % AVG Validation Acc 65.40 %\n",
      "Split 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "733d139d6c6f412b89f8e29aaaf395ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.670 AVG Validation Loss:0.660 AVG Training Acc 59.49 % AVG Validation Acc 60.94 %\n",
      "Epoch:20/100 AVG Training Loss:0.645 AVG Validation Loss:0.652 AVG Training Acc 62.68 % AVG Validation Acc 62.46 %\n",
      "Epoch:30/100 AVG Training Loss:0.622 AVG Validation Loss:0.631 AVG Training Acc 65.81 % AVG Validation Acc 65.15 %\n",
      "Epoch:40/100 AVG Training Loss:0.606 AVG Validation Loss:0.622 AVG Training Acc 66.82 % AVG Validation Acc 66.67 %\n",
      "Epoch:50/100 AVG Training Loss:0.593 AVG Validation Loss:0.622 AVG Training Acc 68.48 % AVG Validation Acc 67.42 %\n",
      "Epoch:60/100 AVG Training Loss:0.586 AVG Validation Loss:0.636 AVG Training Acc 69.15 % AVG Validation Acc 67.34 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:70/100 AVG Training Loss:0.537 AVG Validation Loss:0.617 AVG Training Acc 73.06 % AVG Validation Acc 66.92 %\n",
      "Epoch:80/100 AVG Training Loss:0.503 AVG Validation Loss:0.632 AVG Training Acc 75.08 % AVG Validation Acc 67.26 %\n",
      "Epoch:90/100 AVG Training Loss:0.490 AVG Validation Loss:0.644 AVG Training Acc 75.67 % AVG Validation Acc 67.26 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/100 AVG Training Loss:0.470 AVG Validation Loss:0.648 AVG Training Acc 77.00 % AVG Validation Acc 67.51 %\n",
      "Split 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6d2a800a1fb4e519153b3689a6e5a64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.662 AVG Validation Loss:0.662 AVG Training Acc 60.72 % AVG Validation Acc 61.03 %\n",
      "Epoch:20/100 AVG Training Loss:0.624 AVG Validation Loss:0.626 AVG Training Acc 65.86 % AVG Validation Acc 64.90 %\n",
      "Epoch:30/100 AVG Training Loss:0.592 AVG Validation Loss:0.636 AVG Training Acc 69.03 % AVG Validation Acc 65.24 %\n",
      "Epoch:40/100 AVG Training Loss:0.591 AVG Validation Loss:0.633 AVG Training Acc 69.18 % AVG Validation Acc 65.82 %\n",
      "Epoch:50/100 AVG Training Loss:0.573 AVG Validation Loss:0.605 AVG Training Acc 70.25 % AVG Validation Acc 68.01 %\n",
      "Epoch:60/100 AVG Training Loss:0.555 AVG Validation Loss:0.621 AVG Training Acc 72.07 % AVG Validation Acc 67.51 %\n",
      "Epoch:70/100 AVG Training Loss:0.549 AVG Validation Loss:0.600 AVG Training Acc 72.71 % AVG Validation Acc 69.70 %\n",
      "Epoch:80/100 AVG Training Loss:0.567 AVG Validation Loss:0.607 AVG Training Acc 71.38 % AVG Validation Acc 67.17 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:90/100 AVG Training Loss:0.507 AVG Validation Loss:0.605 AVG Training Acc 75.50 % AVG Validation Acc 68.86 %\n",
      "Epoch:100/100 AVG Training Loss:0.454 AVG Validation Loss:0.624 AVG Training Acc 78.49 % AVG Validation Acc 69.11 %\n",
      "Split 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee36337fa1864ad4a0bfa798ae7852f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.664 AVG Validation Loss:0.669 AVG Training Acc 60.35 % AVG Validation Acc 57.79 %\n",
      "Epoch:20/100 AVG Training Loss:0.627 AVG Validation Loss:0.651 AVG Training Acc 65.82 % AVG Validation Acc 63.44 %\n",
      "Epoch:30/100 AVG Training Loss:0.603 AVG Validation Loss:0.636 AVG Training Acc 67.33 % AVG Validation Acc 64.20 %\n",
      "Epoch:40/100 AVG Training Loss:0.574 AVG Validation Loss:0.604 AVG Training Acc 70.50 % AVG Validation Acc 66.55 %\n",
      "Epoch:50/100 AVG Training Loss:0.570 AVG Validation Loss:0.604 AVG Training Acc 70.92 % AVG Validation Acc 67.48 %\n",
      "Epoch:60/100 AVG Training Loss:0.556 AVG Validation Loss:0.590 AVG Training Acc 71.62 % AVG Validation Acc 67.57 %\n",
      "Epoch:70/100 AVG Training Loss:0.539 AVG Validation Loss:0.602 AVG Training Acc 73.02 % AVG Validation Acc 67.31 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:80/100 AVG Training Loss:0.478 AVG Validation Loss:0.592 AVG Training Acc 76.68 % AVG Validation Acc 69.00 %\n",
      "New Best Accuracy found: 71.44%\n",
      "Epoch: 86\n",
      "Epoch:90/100 AVG Training Loss:0.453 AVG Validation Loss:0.596 AVG Training Acc 78.31 % AVG Validation Acc 70.01 %\n",
      "Epoch:100/100 AVG Training Loss:0.433 AVG Validation Loss:0.599 AVG Training Acc 79.70 % AVG Validation Acc 70.51 %\n",
      "Split 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "005088d740124743ac1e717912653e33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.661 AVG Validation Loss:0.658 AVG Training Acc 60.45 % AVG Validation Acc 61.16 %\n",
      "Epoch:20/100 AVG Training Loss:0.639 AVG Validation Loss:0.638 AVG Training Acc 64.04 % AVG Validation Acc 63.69 %\n",
      "Epoch:30/100 AVG Training Loss:0.612 AVG Validation Loss:0.633 AVG Training Acc 66.92 % AVG Validation Acc 65.54 %\n",
      "Epoch:40/100 AVG Training Loss:0.596 AVG Validation Loss:0.625 AVG Training Acc 68.71 % AVG Validation Acc 66.30 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/100 AVG Training Loss:0.533 AVG Validation Loss:0.624 AVG Training Acc 72.79 % AVG Validation Acc 67.06 %\n",
      "Epoch:60/100 AVG Training Loss:0.501 AVG Validation Loss:0.635 AVG Training Acc 75.21 % AVG Validation Acc 67.40 %\n",
      "Epoch:70/100 AVG Training Loss:0.484 AVG Validation Loss:0.655 AVG Training Acc 76.23 % AVG Validation Acc 67.31 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/100 AVG Training Loss:0.465 AVG Validation Loss:0.657 AVG Training Acc 77.68 % AVG Validation Acc 68.83 %\n",
      "Epoch:90/100 AVG Training Loss:0.463 AVG Validation Loss:0.656 AVG Training Acc 77.82 % AVG Validation Acc 68.32 %\n",
      "Epoch:100/100 AVG Training Loss:0.461 AVG Validation Loss:0.668 AVG Training Acc 78.13 % AVG Validation Acc 68.07 %\n",
      "final_fail\n",
      "Before reshaping:\n",
      "Training Shape torch.Size([12642, 25]) torch.Size([12642])\n",
      "Testing Shape torch.Size([1860, 25]) torch.Size([1860])\n",
      "\n",
      "After reshaping:\n",
      "Training Shape torch.Size([12642, 25, 1]) torch.Size([12642])\n",
      "Testing Shape torch.Size([1860, 25, 1]) torch.Size([1860])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c42e7ffae9c427a88b13c278815d9bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "353a43eedb814a55b9e901f600bd8de4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best Accuracy found: 47.91%\n",
      "Epoch: 1\n",
      "New Best Accuracy found: 57.15%\n",
      "Epoch: 2\n",
      "New Best Accuracy found: 60.55%\n",
      "Epoch: 3\n",
      "New Best Accuracy found: 61.03%\n",
      "Epoch: 5\n",
      "New Best Accuracy found: 61.98%\n",
      "Epoch: 9\n",
      "Epoch:10/100 AVG Training Loss:0.655 AVG Validation Loss:0.642 AVG Training Acc 61.77 % AVG Validation Acc 62.69 %\n",
      "New Best Accuracy found: 62.69%\n",
      "Epoch: 10\n",
      "New Best Accuracy found: 64.51%\n",
      "Epoch: 11\n",
      "New Best Accuracy found: 64.66%\n",
      "Epoch: 12\n",
      "New Best Accuracy found: 66.96%\n",
      "Epoch: 13\n",
      "New Best Accuracy found: 67.51%\n",
      "Epoch: 15\n",
      "New Best Accuracy found: 69.72%\n",
      "Epoch: 17\n",
      "New Best Accuracy found: 69.88%\n",
      "Epoch: 18\n",
      "Epoch:20/100 AVG Training Loss:0.588 AVG Validation Loss:0.601 AVG Training Acc 69.10 % AVG Validation Acc 66.88 %\n",
      "New Best Accuracy found: 70.99%\n",
      "Epoch: 21\n",
      "New Best Accuracy found: 71.46%\n",
      "Epoch: 26\n",
      "New Best Accuracy found: 72.73%\n",
      "Epoch: 29\n",
      "Epoch:30/100 AVG Training Loss:0.539 AVG Validation Loss:0.571 AVG Training Acc 73.07 % AVG Validation Acc 70.99 %\n",
      "New Best Accuracy found: 73.04%\n",
      "Epoch: 35\n",
      "Epoch:40/100 AVG Training Loss:0.511 AVG Validation Loss:0.530 AVG Training Acc 75.30 % AVG Validation Acc 74.47 %\n",
      "New Best Accuracy found: 74.47%\n",
      "Epoch: 40\n",
      "Epoch:50/100 AVG Training Loss:0.494 AVG Validation Loss:0.562 AVG Training Acc 76.57 % AVG Validation Acc 72.81 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-03.\n",
      "New Best Accuracy found: 75.26%\n",
      "Epoch: 52\n",
      "New Best Accuracy found: 75.73%\n",
      "Epoch: 53\n",
      "Epoch:60/100 AVG Training Loss:0.379 AVG Validation Loss:0.572 AVG Training Acc 83.06 % AVG Validation Acc 75.97 %\n",
      "New Best Accuracy found: 75.97%\n",
      "Epoch: 60\n",
      "New Best Accuracy found: 76.05%\n",
      "Epoch: 61\n",
      "New Best Accuracy found: 76.68%\n",
      "Epoch: 64\n",
      "New Best Accuracy found: 76.92%\n",
      "Epoch: 66\n",
      "New Best Accuracy found: 77.23%\n",
      "Epoch: 69\n",
      "Epoch:70/100 AVG Training Loss:0.354 AVG Validation Loss:0.611 AVG Training Acc 84.65 % AVG Validation Acc 76.05 %\n",
      "Epoch:80/100 AVG Training Loss:0.333 AVG Validation Loss:0.631 AVG Training Acc 85.39 % AVG Validation Acc 77.15 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-04.\n",
      "New Best Accuracy found: 77.79%\n",
      "Epoch: 82\n",
      "Epoch:90/100 AVG Training Loss:0.325 AVG Validation Loss:0.647 AVG Training Acc 85.80 % AVG Validation Acc 76.92 %\n",
      "Epoch:100/100 AVG Training Loss:0.318 AVG Validation Loss:0.643 AVG Training Acc 86.28 % AVG Validation Acc 76.44 %\n",
      "Split 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ed1f271ef7e490dab67b92c392b370c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.646 AVG Validation Loss:0.629 AVG Training Acc 63.54 % AVG Validation Acc 65.69 %\n",
      "Epoch:20/100 AVG Training Loss:0.589 AVG Validation Loss:0.579 AVG Training Acc 69.29 % AVG Validation Acc 70.51 %\n",
      "Epoch:30/100 AVG Training Loss:0.547 AVG Validation Loss:0.565 AVG Training Acc 72.66 % AVG Validation Acc 70.67 %\n",
      "Epoch:40/100 AVG Training Loss:0.527 AVG Validation Loss:0.562 AVG Training Acc 73.82 % AVG Validation Acc 70.91 %\n",
      "Epoch:50/100 AVG Training Loss:0.501 AVG Validation Loss:0.564 AVG Training Acc 76.02 % AVG Validation Acc 72.65 %\n",
      "Epoch:60/100 AVG Training Loss:0.488 AVG Validation Loss:0.548 AVG Training Acc 76.72 % AVG Validation Acc 73.20 %\n",
      "Epoch:70/100 AVG Training Loss:0.467 AVG Validation Loss:0.538 AVG Training Acc 77.98 % AVG Validation Acc 73.68 %\n",
      "Epoch:80/100 AVG Training Loss:0.458 AVG Validation Loss:0.574 AVG Training Acc 78.64 % AVG Validation Acc 73.28 %\n",
      "Epoch:90/100 AVG Training Loss:0.439 AVG Validation Loss:0.542 AVG Training Acc 79.90 % AVG Validation Acc 74.70 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:100/100 AVG Training Loss:0.338 AVG Validation Loss:0.576 AVG Training Acc 84.98 % AVG Validation Acc 76.68 %\n",
      "Split 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca52cb1ab9384ec08cd98c7a3a34bdd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.654 AVG Validation Loss:0.678 AVG Training Acc 61.70 % AVG Validation Acc 61.63 %\n",
      "Epoch:20/100 AVG Training Loss:0.604 AVG Validation Loss:0.624 AVG Training Acc 68.23 % AVG Validation Acc 65.66 %\n",
      "Epoch:30/100 AVG Training Loss:0.565 AVG Validation Loss:0.606 AVG Training Acc 70.67 % AVG Validation Acc 68.59 %\n",
      "Epoch:40/100 AVG Training Loss:0.577 AVG Validation Loss:0.624 AVG Training Acc 70.17 % AVG Validation Acc 66.61 %\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/100 AVG Training Loss:0.467 AVG Validation Loss:0.597 AVG Training Acc 77.85 % AVG Validation Acc 70.73 %\n",
      "Epoch:60/100 AVG Training Loss:0.443 AVG Validation Loss:0.609 AVG Training Acc 79.75 % AVG Validation Acc 70.73 %\n",
      "Epoch:70/100 AVG Training Loss:0.426 AVG Validation Loss:0.613 AVG Training Acc 80.59 % AVG Validation Acc 70.89 %\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/100 AVG Training Loss:0.411 AVG Validation Loss:0.616 AVG Training Acc 81.10 % AVG Validation Acc 72.15 %\n",
      "Epoch:90/100 AVG Training Loss:0.408 AVG Validation Loss:0.625 AVG Training Acc 81.50 % AVG Validation Acc 71.52 %\n",
      "Epoch:100/100 AVG Training Loss:0.403 AVG Validation Loss:0.626 AVG Training Acc 81.70 % AVG Validation Acc 71.68 %\n",
      "Split 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9899a36ef8e242e7809e46e53b9f47e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.654 AVG Validation Loss:0.644 AVG Training Acc 61.70 % AVG Validation Acc 61.79 %\n",
      "Epoch:20/100 AVG Training Loss:0.594 AVG Validation Loss:0.617 AVG Training Acc 68.39 % AVG Validation Acc 66.61 %\n",
      "Epoch:30/100 AVG Training Loss:0.561 AVG Validation Loss:0.575 AVG Training Acc 71.51 % AVG Validation Acc 69.46 %\n",
      "Epoch:40/100 AVG Training Loss:0.532 AVG Validation Loss:0.562 AVG Training Acc 73.83 % AVG Validation Acc 70.89 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/100 AVG Training Loss:0.434 AVG Validation Loss:0.552 AVG Training Acc 80.14 % AVG Validation Acc 72.63 %\n",
      "Epoch:60/100 AVG Training Loss:0.392 AVG Validation Loss:0.565 AVG Training Acc 82.24 % AVG Validation Acc 74.68 %\n",
      "Epoch:70/100 AVG Training Loss:0.369 AVG Validation Loss:0.596 AVG Training Acc 83.64 % AVG Validation Acc 74.92 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/100 AVG Training Loss:0.342 AVG Validation Loss:0.611 AVG Training Acc 84.74 % AVG Validation Acc 74.29 %\n",
      "Epoch:90/100 AVG Training Loss:0.339 AVG Validation Loss:0.601 AVG Training Acc 85.09 % AVG Validation Acc 74.68 %\n",
      "Epoch:100/100 AVG Training Loss:0.337 AVG Validation Loss:0.622 AVG Training Acc 85.14 % AVG Validation Acc 74.05 %\n",
      "Split 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0a4d844c70486683715a810c287fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.650 AVG Validation Loss:0.660 AVG Training Acc 61.86 % AVG Validation Acc 59.18 %\n",
      "Epoch:20/100 AVG Training Loss:0.639 AVG Validation Loss:0.629 AVG Training Acc 63.24 % AVG Validation Acc 62.97 %\n",
      "Epoch:30/100 AVG Training Loss:0.587 AVG Validation Loss:0.616 AVG Training Acc 69.35 % AVG Validation Acc 65.03 %\n",
      "Epoch:40/100 AVG Training Loss:0.549 AVG Validation Loss:0.614 AVG Training Acc 72.69 % AVG Validation Acc 66.38 %\n",
      "Epoch:50/100 AVG Training Loss:0.506 AVG Validation Loss:0.578 AVG Training Acc 75.52 % AVG Validation Acc 70.81 %\n",
      "Epoch:60/100 AVG Training Loss:0.502 AVG Validation Loss:0.583 AVG Training Acc 76.17 % AVG Validation Acc 71.76 %\n",
      "Epoch:70/100 AVG Training Loss:0.465 AVG Validation Loss:0.578 AVG Training Acc 78.48 % AVG Validation Acc 70.97 %\n",
      "Epoch:80/100 AVG Training Loss:0.487 AVG Validation Loss:0.553 AVG Training Acc 77.28 % AVG Validation Acc 71.36 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:90/100 AVG Training Loss:0.371 AVG Validation Loss:0.569 AVG Training Acc 83.81 % AVG Validation Acc 74.76 %\n",
      "Epoch:100/100 AVG Training Loss:0.351 AVG Validation Loss:0.601 AVG Training Acc 84.65 % AVG Validation Acc 75.16 %\n",
      "Split 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32635727b65e44c7a1078dcd0ac79ee3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.646 AVG Validation Loss:0.630 AVG Training Acc 63.92 % AVG Validation Acc 63.92 %\n",
      "Epoch:20/100 AVG Training Loss:0.583 AVG Validation Loss:0.599 AVG Training Acc 69.78 % AVG Validation Acc 68.67 %\n",
      "Epoch:30/100 AVG Training Loss:0.540 AVG Validation Loss:0.573 AVG Training Acc 73.49 % AVG Validation Acc 69.46 %\n",
      "Epoch:40/100 AVG Training Loss:0.503 AVG Validation Loss:0.564 AVG Training Acc 76.29 % AVG Validation Acc 72.07 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/100 AVG Training Loss:0.432 AVG Validation Loss:0.541 AVG Training Acc 80.12 % AVG Validation Acc 73.97 %\n",
      "Epoch:60/100 AVG Training Loss:0.384 AVG Validation Loss:0.576 AVG Training Acc 82.84 % AVG Validation Acc 75.16 %\n",
      "Epoch:70/100 AVG Training Loss:0.357 AVG Validation Loss:0.593 AVG Training Acc 84.00 % AVG Validation Acc 74.60 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/100 AVG Training Loss:0.347 AVG Validation Loss:0.614 AVG Training Acc 84.42 % AVG Validation Acc 75.08 %\n",
      "Epoch:90/100 AVG Training Loss:0.330 AVG Validation Loss:0.619 AVG Training Acc 85.52 % AVG Validation Acc 75.55 %\n",
      "Epoch:100/100 AVG Training Loss:0.329 AVG Validation Loss:0.609 AVG Training Acc 85.67 % AVG Validation Acc 75.55 %\n",
      "Split 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47b736d6cbfd40348651da32e78de2eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.657 AVG Validation Loss:0.650 AVG Training Acc 60.54 % AVG Validation Acc 63.45 %\n",
      "Epoch:20/100 AVG Training Loss:0.613 AVG Validation Loss:0.624 AVG Training Acc 67.04 % AVG Validation Acc 66.14 %\n",
      "Epoch:30/100 AVG Training Loss:0.579 AVG Validation Loss:0.587 AVG Training Acc 70.50 % AVG Validation Acc 69.07 %\n",
      "Epoch:40/100 AVG Training Loss:0.550 AVG Validation Loss:0.587 AVG Training Acc 72.47 % AVG Validation Acc 69.22 %\n",
      "Epoch:50/100 AVG Training Loss:0.527 AVG Validation Loss:0.574 AVG Training Acc 74.14 % AVG Validation Acc 72.23 %\n",
      "Epoch:60/100 AVG Training Loss:0.516 AVG Validation Loss:0.578 AVG Training Acc 75.41 % AVG Validation Acc 71.99 %\n",
      "Epoch:70/100 AVG Training Loss:0.507 AVG Validation Loss:0.573 AVG Training Acc 76.11 % AVG Validation Acc 71.60 %\n",
      "Epoch:80/100 AVG Training Loss:0.488 AVG Validation Loss:0.579 AVG Training Acc 77.27 % AVG Validation Acc 72.07 %\n",
      "Epoch:90/100 AVG Training Loss:0.493 AVG Validation Loss:0.538 AVG Training Acc 76.67 % AVG Validation Acc 73.58 %\n",
      "Epoch:100/100 AVG Training Loss:0.520 AVG Validation Loss:0.563 AVG Training Acc 75.42 % AVG Validation Acc 72.31 %\n",
      "Split 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b03defcf4afd4ea58c9feea739eca28b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.652 AVG Validation Loss:0.651 AVG Training Acc 61.89 % AVG Validation Acc 62.03 %\n",
      "Epoch:20/100 AVG Training Loss:0.673 AVG Validation Loss:0.672 AVG Training Acc 58.31 % AVG Validation Acc 56.57 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/100 AVG Training Loss:0.655 AVG Validation Loss:0.667 AVG Training Acc 61.33 % AVG Validation Acc 59.81 %\n",
      "Epoch:40/100 AVG Training Loss:0.648 AVG Validation Loss:0.662 AVG Training Acc 62.27 % AVG Validation Acc 61.16 %\n",
      "Epoch:50/100 AVG Training Loss:0.636 AVG Validation Loss:0.660 AVG Training Acc 63.32 % AVG Validation Acc 61.71 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/100 AVG Training Loss:0.626 AVG Validation Loss:0.663 AVG Training Acc 64.42 % AVG Validation Acc 61.39 %\n",
      "Epoch:70/100 AVG Training Loss:0.623 AVG Validation Loss:0.662 AVG Training Acc 64.50 % AVG Validation Acc 61.95 %\n",
      "Epoch:80/100 AVG Training Loss:0.621 AVG Validation Loss:0.658 AVG Training Acc 64.72 % AVG Validation Acc 62.10 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/100 AVG Training Loss:0.620 AVG Validation Loss:0.661 AVG Training Acc 64.48 % AVG Validation Acc 61.63 %\n",
      "Epoch:100/100 AVG Training Loss:0.621 AVG Validation Loss:0.659 AVG Training Acc 64.71 % AVG Validation Acc 61.63 %\n",
      "Split 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a3fadead9af415d81c55fee7bf1a746",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.662 AVG Validation Loss:0.668 AVG Training Acc 60.75 % AVG Validation Acc 57.99 %\n",
      "Epoch:20/100 AVG Training Loss:0.619 AVG Validation Loss:0.630 AVG Training Acc 66.15 % AVG Validation Acc 65.74 %\n",
      "Epoch:30/100 AVG Training Loss:0.562 AVG Validation Loss:0.590 AVG Training Acc 71.80 % AVG Validation Acc 68.12 %\n",
      "Epoch:40/100 AVG Training Loss:0.541 AVG Validation Loss:0.579 AVG Training Acc 73.64 % AVG Validation Acc 68.99 %\n",
      "Epoch:50/100 AVG Training Loss:0.517 AVG Validation Loss:0.560 AVG Training Acc 74.71 % AVG Validation Acc 71.91 %\n",
      "Epoch:60/100 AVG Training Loss:0.496 AVG Validation Loss:0.556 AVG Training Acc 76.64 % AVG Validation Acc 72.47 %\n",
      "Epoch:70/100 AVG Training Loss:0.485 AVG Validation Loss:0.556 AVG Training Acc 76.84 % AVG Validation Acc 73.10 %\n",
      "Epoch:80/100 AVG Training Loss:0.476 AVG Validation Loss:0.547 AVG Training Acc 77.33 % AVG Validation Acc 72.39 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:90/100 AVG Training Loss:0.429 AVG Validation Loss:0.557 AVG Training Acc 80.45 % AVG Validation Acc 73.81 %\n",
      "Epoch:100/100 AVG Training Loss:0.368 AVG Validation Loss:0.572 AVG Training Acc 83.53 % AVG Validation Acc 75.87 %\n",
      "Split 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c46e442c97540cbb3b3cd0c25ab98a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.654 AVG Validation Loss:0.650 AVG Training Acc 61.83 % AVG Validation Acc 61.87 %\n",
      "Epoch:20/100 AVG Training Loss:0.618 AVG Validation Loss:0.617 AVG Training Acc 66.12 % AVG Validation Acc 65.66 %\n",
      "Epoch:30/100 AVG Training Loss:0.578 AVG Validation Loss:0.596 AVG Training Acc 70.24 % AVG Validation Acc 67.48 %\n",
      "Epoch:40/100 AVG Training Loss:0.538 AVG Validation Loss:0.552 AVG Training Acc 73.81 % AVG Validation Acc 70.65 %\n",
      "Epoch:50/100 AVG Training Loss:0.507 AVG Validation Loss:0.528 AVG Training Acc 75.76 % AVG Validation Acc 73.89 %\n",
      "Epoch:60/100 AVG Training Loss:0.486 AVG Validation Loss:0.519 AVG Training Acc 77.45 % AVG Validation Acc 74.13 %\n",
      "Epoch:70/100 AVG Training Loss:0.456 AVG Validation Loss:0.529 AVG Training Acc 79.09 % AVG Validation Acc 72.86 %\n",
      "Epoch    71: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:80/100 AVG Training Loss:0.358 AVG Validation Loss:0.548 AVG Training Acc 84.18 % AVG Validation Acc 75.16 %\n",
      "Epoch:90/100 AVG Training Loss:0.332 AVG Validation Loss:0.559 AVG Training Acc 85.50 % AVG Validation Acc 76.19 %\n",
      "Epoch:100/100 AVG Training Loss:0.315 AVG Validation Loss:0.585 AVG Training Acc 86.22 % AVG Validation Acc 75.63 %\n",
      "exam_gifted\n",
      "Before reshaping:\n",
      "Training Shape torch.Size([10754, 25]) torch.Size([10754])\n",
      "Testing Shape torch.Size([1860, 25]) torch.Size([1860])\n",
      "\n",
      "After reshaping:\n",
      "Training Shape torch.Size([10754, 25, 1]) torch.Size([10754])\n",
      "Testing Shape torch.Size([1860, 25, 1]) torch.Size([1860])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3be566b87e04ec2a99c6b36c6b15786",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35feb9b5de44415b9a67dd0040db9c9f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best Accuracy found: 52.79%\n",
      "Epoch: 1\n",
      "New Best Accuracy found: 55.02%\n",
      "Epoch: 4\n",
      "Epoch:10/100 AVG Training Loss:0.688 AVG Validation Loss:0.682 AVG Training Acc 53.65 % AVG Validation Acc 57.99 %\n",
      "New Best Accuracy found: 57.99%\n",
      "Epoch: 10\n",
      "New Best Accuracy found: 58.92%\n",
      "Epoch: 13\n",
      "New Best Accuracy found: 59.20%\n",
      "Epoch: 15\n",
      "New Best Accuracy found: 59.94%\n",
      "Epoch: 18\n",
      "Epoch:20/100 AVG Training Loss:0.672 AVG Validation Loss:0.671 AVG Training Acc 58.16 % AVG Validation Acc 59.76 %\n",
      "New Best Accuracy found: 61.34%\n",
      "Epoch: 23\n",
      "Epoch:30/100 AVG Training Loss:0.687 AVG Validation Loss:0.685 AVG Training Acc 53.89 % AVG Validation Acc 57.53 %\n",
      "Epoch:40/100 AVG Training Loss:0.657 AVG Validation Loss:0.664 AVG Training Acc 60.16 % AVG Validation Acc 60.69 %\n",
      "New Best Accuracy found: 61.52%\n",
      "Epoch: 47\n",
      "Epoch:50/100 AVG Training Loss:0.653 AVG Validation Loss:0.663 AVG Training Acc 61.41 % AVG Validation Acc 58.27 %\n",
      "New Best Accuracy found: 62.27%\n",
      "Epoch: 54\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/100 AVG Training Loss:0.631 AVG Validation Loss:0.652 AVG Training Acc 63.10 % AVG Validation Acc 60.69 %\n",
      "New Best Accuracy found: 62.36%\n",
      "Epoch: 65\n",
      "Epoch:70/100 AVG Training Loss:0.620 AVG Validation Loss:0.660 AVG Training Acc 64.37 % AVG Validation Acc 61.15 %\n",
      "Epoch:80/100 AVG Training Loss:0.611 AVG Validation Loss:0.669 AVG Training Acc 64.83 % AVG Validation Acc 61.62 %\n",
      "New Best Accuracy found: 62.55%\n",
      "Epoch: 86\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/100 AVG Training Loss:0.604 AVG Validation Loss:0.661 AVG Training Acc 65.53 % AVG Validation Acc 61.90 %\n",
      "Epoch:100/100 AVG Training Loss:0.601 AVG Validation Loss:0.669 AVG Training Acc 65.66 % AVG Validation Acc 61.25 %\n",
      "Split 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72ee329e431d446db8ca0c84037f5ba8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.690 AVG Validation Loss:0.694 AVG Training Acc 53.89 % AVG Validation Acc 51.86 %\n",
      "Epoch:20/100 AVG Training Loss:0.675 AVG Validation Loss:0.683 AVG Training Acc 57.49 % AVG Validation Acc 57.62 %\n",
      "Epoch:30/100 AVG Training Loss:0.659 AVG Validation Loss:0.678 AVG Training Acc 59.98 % AVG Validation Acc 59.48 %\n",
      "Epoch:40/100 AVG Training Loss:0.645 AVG Validation Loss:0.670 AVG Training Acc 61.41 % AVG Validation Acc 61.43 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/100 AVG Training Loss:0.623 AVG Validation Loss:0.672 AVG Training Acc 64.19 % AVG Validation Acc 61.34 %\n",
      "New Best Accuracy found: 63.20%\n",
      "Epoch: 56\n",
      "Epoch:60/100 AVG Training Loss:0.604 AVG Validation Loss:0.683 AVG Training Acc 65.86 % AVG Validation Acc 60.78 %\n",
      "New Best Accuracy found: 63.48%\n",
      "Epoch: 62\n",
      "Epoch:70/100 AVG Training Loss:0.592 AVG Validation Loss:0.695 AVG Training Acc 66.86 % AVG Validation Acc 62.64 %\n",
      "New Best Accuracy found: 63.94%\n",
      "Epoch: 79\n",
      "Epoch:80/100 AVG Training Loss:0.589 AVG Validation Loss:0.703 AVG Training Acc 66.87 % AVG Validation Acc 61.99 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/100 AVG Training Loss:0.583 AVG Validation Loss:0.698 AVG Training Acc 67.48 % AVG Validation Acc 63.75 %\n",
      "Epoch:100/100 AVG Training Loss:0.580 AVG Validation Loss:0.699 AVG Training Acc 67.75 % AVG Validation Acc 63.29 %\n",
      "Split 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da4866d6b6eb4466b6b83714e9596a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.688 AVG Validation Loss:0.692 AVG Training Acc 53.94 % AVG Validation Acc 51.12 %\n",
      "Epoch:20/100 AVG Training Loss:0.667 AVG Validation Loss:0.701 AVG Training Acc 59.03 % AVG Validation Acc 52.04 %\n",
      "Epoch:30/100 AVG Training Loss:0.654 AVG Validation Loss:0.673 AVG Training Acc 60.72 % AVG Validation Acc 59.29 %\n",
      "Epoch:40/100 AVG Training Loss:0.657 AVG Validation Loss:0.663 AVG Training Acc 59.72 % AVG Validation Acc 58.64 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/100 AVG Training Loss:0.625 AVG Validation Loss:0.663 AVG Training Acc 64.10 % AVG Validation Acc 59.85 %\n",
      "Epoch:60/100 AVG Training Loss:0.611 AVG Validation Loss:0.664 AVG Training Acc 65.74 % AVG Validation Acc 62.08 %\n",
      "Epoch:70/100 AVG Training Loss:0.601 AVG Validation Loss:0.678 AVG Training Acc 65.57 % AVG Validation Acc 62.17 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/100 AVG Training Loss:0.590 AVG Validation Loss:0.671 AVG Training Acc 67.07 % AVG Validation Acc 62.55 %\n",
      "Epoch:90/100 AVG Training Loss:0.590 AVG Validation Loss:0.675 AVG Training Acc 67.39 % AVG Validation Acc 62.92 %\n",
      "Epoch:100/100 AVG Training Loss:0.592 AVG Validation Loss:0.674 AVG Training Acc 67.30 % AVG Validation Acc 62.64 %\n",
      "Split 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddec0f42dab24185a64defbb84c90f9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.686 AVG Validation Loss:0.687 AVG Training Acc 54.75 % AVG Validation Acc 58.18 %\n",
      "Epoch:20/100 AVG Training Loss:0.674 AVG Validation Loss:0.670 AVG Training Acc 58.40 % AVG Validation Acc 60.41 %\n",
      "Epoch:30/100 AVG Training Loss:0.658 AVG Validation Loss:0.655 AVG Training Acc 60.63 % AVG Validation Acc 60.04 %\n",
      "Epoch:40/100 AVG Training Loss:0.652 AVG Validation Loss:0.645 AVG Training Acc 60.81 % AVG Validation Acc 63.20 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "New Best Accuracy found: 64.59%\n",
      "Epoch: 48\n",
      "Epoch:50/100 AVG Training Loss:0.629 AVG Validation Loss:0.639 AVG Training Acc 62.92 % AVG Validation Acc 63.29 %\n",
      "New Best Accuracy found: 64.68%\n",
      "Epoch: 52\n",
      "Epoch:60/100 AVG Training Loss:0.621 AVG Validation Loss:0.650 AVG Training Acc 63.75 % AVG Validation Acc 62.92 %\n",
      "Epoch:70/100 AVG Training Loss:0.616 AVG Validation Loss:0.651 AVG Training Acc 64.43 % AVG Validation Acc 63.38 %\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/100 AVG Training Loss:0.611 AVG Validation Loss:0.649 AVG Training Acc 64.89 % AVG Validation Acc 63.29 %\n",
      "Epoch:90/100 AVG Training Loss:0.611 AVG Validation Loss:0.651 AVG Training Acc 65.05 % AVG Validation Acc 62.55 %\n",
      "Epoch:100/100 AVG Training Loss:0.609 AVG Validation Loss:0.650 AVG Training Acc 65.19 % AVG Validation Acc 63.66 %\n",
      "Split 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a47e8a4678f14e5891a2c96187ebf8be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.692 AVG Validation Loss:0.685 AVG Training Acc 52.58 % AVG Validation Acc 53.30 %\n",
      "Epoch:20/100 AVG Training Loss:0.674 AVG Validation Loss:0.672 AVG Training Acc 58.47 % AVG Validation Acc 58.60 %\n",
      "Epoch:30/100 AVG Training Loss:0.666 AVG Validation Loss:0.656 AVG Training Acc 58.88 % AVG Validation Acc 61.49 %\n",
      "Epoch:40/100 AVG Training Loss:0.658 AVG Validation Loss:0.653 AVG Training Acc 60.75 % AVG Validation Acc 61.40 %\n",
      "Epoch:50/100 AVG Training Loss:0.658 AVG Validation Loss:0.646 AVG Training Acc 60.30 % AVG Validation Acc 62.42 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/100 AVG Training Loss:0.631 AVG Validation Loss:0.652 AVG Training Acc 63.06 % AVG Validation Acc 63.72 %\n",
      "Epoch:70/100 AVG Training Loss:0.623 AVG Validation Loss:0.659 AVG Training Acc 63.70 % AVG Validation Acc 63.35 %\n",
      "Epoch:80/100 AVG Training Loss:0.622 AVG Validation Loss:0.660 AVG Training Acc 63.98 % AVG Validation Acc 63.35 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/100 AVG Training Loss:0.616 AVG Validation Loss:0.659 AVG Training Acc 64.80 % AVG Validation Acc 62.70 %\n",
      "Epoch:100/100 AVG Training Loss:0.614 AVG Validation Loss:0.663 AVG Training Acc 64.84 % AVG Validation Acc 62.42 %\n",
      "Split 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e8b8b0b42a48569e14971aa8c66847",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.689 AVG Validation Loss:0.690 AVG Training Acc 54.03 % AVG Validation Acc 54.05 %\n",
      "Epoch:20/100 AVG Training Loss:0.675 AVG Validation Loss:0.676 AVG Training Acc 58.40 % AVG Validation Acc 57.30 %\n",
      "Epoch:30/100 AVG Training Loss:0.662 AVG Validation Loss:0.669 AVG Training Acc 60.13 % AVG Validation Acc 58.88 %\n",
      "Epoch:40/100 AVG Training Loss:0.653 AVG Validation Loss:0.663 AVG Training Acc 61.52 % AVG Validation Acc 57.77 %\n",
      "Epoch:50/100 AVG Training Loss:0.643 AVG Validation Loss:0.663 AVG Training Acc 61.44 % AVG Validation Acc 60.09 %\n",
      "Epoch:60/100 AVG Training Loss:0.640 AVG Validation Loss:0.659 AVG Training Acc 62.71 % AVG Validation Acc 59.16 %\n",
      "Epoch:70/100 AVG Training Loss:0.637 AVG Validation Loss:0.659 AVG Training Acc 62.62 % AVG Validation Acc 58.51 %\n",
      "Epoch:80/100 AVG Training Loss:0.633 AVG Validation Loss:0.662 AVG Training Acc 63.63 % AVG Validation Acc 59.07 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:90/100 AVG Training Loss:0.607 AVG Validation Loss:0.657 AVG Training Acc 66.05 % AVG Validation Acc 60.47 %\n",
      "Epoch:100/100 AVG Training Loss:0.600 AVG Validation Loss:0.665 AVG Training Acc 66.46 % AVG Validation Acc 59.91 %\n",
      "Split 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5be73b4aa4b047d183d34c8f76ed45ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.689 AVG Validation Loss:0.687 AVG Training Acc 53.70 % AVG Validation Acc 57.21 %\n",
      "Epoch:20/100 AVG Training Loss:0.667 AVG Validation Loss:0.666 AVG Training Acc 59.55 % AVG Validation Acc 60.84 %\n",
      "Epoch:30/100 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 60.46 % AVG Validation Acc 62.14 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/100 AVG Training Loss:0.640 AVG Validation Loss:0.654 AVG Training Acc 62.82 % AVG Validation Acc 62.79 %\n",
      "Epoch:50/100 AVG Training Loss:0.627 AVG Validation Loss:0.664 AVG Training Acc 64.11 % AVG Validation Acc 62.98 %\n",
      "Epoch:60/100 AVG Training Loss:0.616 AVG Validation Loss:0.664 AVG Training Acc 65.15 % AVG Validation Acc 63.35 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/100 AVG Training Loss:0.609 AVG Validation Loss:0.667 AVG Training Acc 65.59 % AVG Validation Acc 64.93 %\n",
      "New Best Accuracy found: 64.93%\n",
      "Epoch: 70\n",
      "Epoch:80/100 AVG Training Loss:0.607 AVG Validation Loss:0.668 AVG Training Acc 65.78 % AVG Validation Acc 64.37 %\n",
      "Epoch:90/100 AVG Training Loss:0.607 AVG Validation Loss:0.668 AVG Training Acc 65.68 % AVG Validation Acc 64.37 %\n",
      "New Best Accuracy found: 65.30%\n",
      "Epoch: 94\n",
      "Epoch:100/100 AVG Training Loss:0.607 AVG Validation Loss:0.665 AVG Training Acc 65.49 % AVG Validation Acc 64.65 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Split 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a53dfee4fa642118e4d226accc87399",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.687 AVG Validation Loss:0.689 AVG Training Acc 54.90 % AVG Validation Acc 52.74 %\n",
      "Epoch:20/100 AVG Training Loss:0.671 AVG Validation Loss:0.669 AVG Training Acc 58.43 % AVG Validation Acc 60.28 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/100 AVG Training Loss:0.644 AVG Validation Loss:0.665 AVG Training Acc 62.05 % AVG Validation Acc 62.14 %\n",
      "Epoch:40/100 AVG Training Loss:0.634 AVG Validation Loss:0.670 AVG Training Acc 62.83 % AVG Validation Acc 60.84 %\n",
      "Epoch:50/100 AVG Training Loss:0.630 AVG Validation Loss:0.675 AVG Training Acc 63.36 % AVG Validation Acc 61.67 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/100 AVG Training Loss:0.621 AVG Validation Loss:0.681 AVG Training Acc 63.60 % AVG Validation Acc 61.12 %\n",
      "Epoch:70/100 AVG Training Loss:0.622 AVG Validation Loss:0.686 AVG Training Acc 63.91 % AVG Validation Acc 60.09 %\n",
      "Epoch:80/100 AVG Training Loss:0.622 AVG Validation Loss:0.687 AVG Training Acc 63.65 % AVG Validation Acc 59.91 %\n",
      "Epoch:90/100 AVG Training Loss:0.621 AVG Validation Loss:0.687 AVG Training Acc 64.21 % AVG Validation Acc 60.74 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/100 AVG Training Loss:0.621 AVG Validation Loss:0.688 AVG Training Acc 63.74 % AVG Validation Acc 60.19 %\n",
      "Split 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78fe776c75d64be2a9c78190948dbdb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.685 AVG Validation Loss:0.682 AVG Training Acc 55.46 % AVG Validation Acc 57.49 %\n",
      "Epoch:20/100 AVG Training Loss:0.669 AVG Validation Loss:0.671 AVG Training Acc 59.24 % AVG Validation Acc 58.79 %\n",
      "Epoch:30/100 AVG Training Loss:0.673 AVG Validation Loss:0.672 AVG Training Acc 58.31 % AVG Validation Acc 57.77 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/100 AVG Training Loss:0.658 AVG Validation Loss:0.665 AVG Training Acc 60.76 % AVG Validation Acc 60.28 %\n",
      "Epoch:50/100 AVG Training Loss:0.654 AVG Validation Loss:0.659 AVG Training Acc 60.93 % AVG Validation Acc 62.05 %\n",
      "Epoch:60/100 AVG Training Loss:0.651 AVG Validation Loss:0.667 AVG Training Acc 61.25 % AVG Validation Acc 60.09 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/100 AVG Training Loss:0.646 AVG Validation Loss:0.664 AVG Training Acc 62.03 % AVG Validation Acc 60.19 %\n",
      "Epoch:80/100 AVG Training Loss:0.646 AVG Validation Loss:0.665 AVG Training Acc 61.95 % AVG Validation Acc 61.21 %\n",
      "Epoch:90/100 AVG Training Loss:0.645 AVG Validation Loss:0.664 AVG Training Acc 62.04 % AVG Validation Acc 60.65 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/100 AVG Training Loss:0.646 AVG Validation Loss:0.663 AVG Training Acc 61.78 % AVG Validation Acc 61.21 %\n",
      "Split 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9afebedf5784a6daaec7ab26700299a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.687 AVG Validation Loss:0.683 AVG Training Acc 54.82 % AVG Validation Acc 57.67 %\n",
      "Epoch:20/100 AVG Training Loss:0.669 AVG Validation Loss:0.672 AVG Training Acc 58.99 % AVG Validation Acc 58.88 %\n",
      "Epoch:30/100 AVG Training Loss:0.657 AVG Validation Loss:0.663 AVG Training Acc 60.68 % AVG Validation Acc 61.02 %\n",
      "Epoch:40/100 AVG Training Loss:0.644 AVG Validation Loss:0.671 AVG Training Acc 61.93 % AVG Validation Acc 59.07 %\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/100 AVG Training Loss:0.621 AVG Validation Loss:0.669 AVG Training Acc 64.65 % AVG Validation Acc 59.26 %\n",
      "Epoch:60/100 AVG Training Loss:0.615 AVG Validation Loss:0.678 AVG Training Acc 64.94 % AVG Validation Acc 60.84 %\n",
      "Epoch:70/100 AVG Training Loss:0.608 AVG Validation Loss:0.684 AVG Training Acc 65.06 % AVG Validation Acc 61.49 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/100 AVG Training Loss:0.607 AVG Validation Loss:0.680 AVG Training Acc 65.78 % AVG Validation Acc 61.40 %\n",
      "Epoch:90/100 AVG Training Loss:0.605 AVG Validation Loss:0.685 AVG Training Acc 65.18 % AVG Validation Acc 61.40 %\n",
      "Epoch:100/100 AVG Training Loss:0.605 AVG Validation Loss:0.685 AVG Training Acc 65.65 % AVG Validation Acc 61.49 %\n",
      "final_gifted\n",
      "Before reshaping:\n",
      "Training Shape torch.Size([10290, 25]) torch.Size([10290])\n",
      "Testing Shape torch.Size([1860, 25]) torch.Size([1860])\n",
      "\n",
      "After reshaping:\n",
      "Training Shape torch.Size([10290, 25, 1]) torch.Size([10290])\n",
      "Testing Shape torch.Size([1860, 25, 1]) torch.Size([1860])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00fb314ffbc1408f8ccef1ad1515d39b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a42129bfa60d4d56b49d8c815d376c3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best Accuracy found: 48.98%\n",
      "Epoch: 1\n",
      "New Best Accuracy found: 49.27%\n",
      "Epoch: 5\n",
      "New Best Accuracy found: 51.12%\n",
      "Epoch: 6\n",
      "New Best Accuracy found: 51.70%\n",
      "Epoch: 7\n",
      "Epoch:10/100 AVG Training Loss:0.693 AVG Validation Loss:0.691 AVG Training Acc 50.84 % AVG Validation Acc 51.80 %\n",
      "New Best Accuracy found: 51.80%\n",
      "Epoch: 10\n",
      "New Best Accuracy found: 51.90%\n",
      "Epoch: 12\n",
      "New Best Accuracy found: 54.71%\n",
      "Epoch: 13\n",
      "New Best Accuracy found: 55.59%\n",
      "Epoch: 14\n",
      "New Best Accuracy found: 55.69%\n",
      "Epoch: 15\n",
      "New Best Accuracy found: 56.46%\n",
      "Epoch: 16\n",
      "New Best Accuracy found: 56.56%\n",
      "Epoch: 18\n",
      "Epoch:20/100 AVG Training Loss:0.683 AVG Validation Loss:0.683 AVG Training Acc 56.78 % AVG Validation Acc 55.00 %\n",
      "New Best Accuracy found: 57.43%\n",
      "Epoch: 22\n",
      "New Best Accuracy found: 58.21%\n",
      "Epoch: 27\n",
      "Epoch:30/100 AVG Training Loss:0.673 AVG Validation Loss:0.669 AVG Training Acc 58.13 % AVG Validation Acc 57.53 %\n",
      "New Best Accuracy found: 58.41%\n",
      "Epoch: 33\n",
      "New Best Accuracy found: 58.70%\n",
      "Epoch: 39\n",
      "Epoch:40/100 AVG Training Loss:0.662 AVG Validation Loss:0.668 AVG Training Acc 59.28 % AVG Validation Acc 58.70 %\n",
      "New Best Accuracy found: 59.28%\n",
      "Epoch: 41\n",
      "New Best Accuracy found: 59.48%\n",
      "Epoch: 43\n",
      "New Best Accuracy found: 60.16%\n",
      "Epoch: 44\n",
      "New Best Accuracy found: 60.35%\n",
      "Epoch: 45\n",
      "Epoch:50/100 AVG Training Loss:0.664 AVG Validation Loss:0.662 AVG Training Acc 59.09 % AVG Validation Acc 58.41 %\n",
      "Epoch:60/100 AVG Training Loss:0.652 AVG Validation Loss:0.664 AVG Training Acc 60.82 % AVG Validation Acc 60.06 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-03.\n",
      "New Best Accuracy found: 60.45%\n",
      "Epoch: 62\n",
      "New Best Accuracy found: 60.64%\n",
      "Epoch: 63\n",
      "New Best Accuracy found: 61.32%\n",
      "Epoch: 64\n",
      "New Best Accuracy found: 61.90%\n",
      "Epoch: 65\n",
      "Epoch:70/100 AVG Training Loss:0.628 AVG Validation Loss:0.673 AVG Training Acc 63.37 % AVG Validation Acc 60.54 %\n",
      "New Best Accuracy found: 62.00%\n",
      "Epoch: 76\n",
      "Epoch:80/100 AVG Training Loss:0.619 AVG Validation Loss:0.671 AVG Training Acc 64.06 % AVG Validation Acc 61.61 %\n",
      "New Best Accuracy found: 62.68%\n",
      "Epoch: 84\n",
      "Epoch:90/100 AVG Training Loss:0.614 AVG Validation Loss:0.669 AVG Training Acc 64.50 % AVG Validation Acc 61.52 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/100 AVG Training Loss:0.611 AVG Validation Loss:0.673 AVG Training Acc 65.05 % AVG Validation Acc 62.10 %\n",
      "Split 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ec45ac8a4004f649611b9222c54d27d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.693 AVG Validation Loss:0.693 AVG Training Acc 50.19 % AVG Validation Acc 51.12 %\n",
      "Epoch:20/100 AVG Training Loss:0.691 AVG Validation Loss:0.691 AVG Training Acc 51.96 % AVG Validation Acc 52.67 %\n",
      "Epoch:30/100 AVG Training Loss:0.680 AVG Validation Loss:0.685 AVG Training Acc 56.52 % AVG Validation Acc 54.13 %\n",
      "Epoch:40/100 AVG Training Loss:0.668 AVG Validation Loss:0.678 AVG Training Acc 58.44 % AVG Validation Acc 56.17 %\n",
      "Epoch:50/100 AVG Training Loss:0.664 AVG Validation Loss:0.678 AVG Training Acc 59.40 % AVG Validation Acc 56.66 %\n",
      "Epoch:60/100 AVG Training Loss:0.656 AVG Validation Loss:0.666 AVG Training Acc 60.48 % AVG Validation Acc 60.16 %\n",
      "Epoch:70/100 AVG Training Loss:0.652 AVG Validation Loss:0.677 AVG Training Acc 60.73 % AVG Validation Acc 58.11 %\n",
      "Epoch    71: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:80/100 AVG Training Loss:0.630 AVG Validation Loss:0.670 AVG Training Acc 63.10 % AVG Validation Acc 59.48 %\n",
      "Epoch:90/100 AVG Training Loss:0.625 AVG Validation Loss:0.677 AVG Training Acc 63.68 % AVG Validation Acc 59.67 %\n",
      "Epoch:100/100 AVG Training Loss:0.620 AVG Validation Loss:0.681 AVG Training Acc 63.92 % AVG Validation Acc 60.16 %\n",
      "Split 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e21fd5baca12420c9af3299ea837ffc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.694 AVG Validation Loss:0.693 AVG Training Acc 50.08 % AVG Validation Acc 49.95 %\n",
      "Epoch:20/100 AVG Training Loss:0.691 AVG Validation Loss:0.685 AVG Training Acc 52.65 % AVG Validation Acc 55.59 %\n",
      "Epoch:30/100 AVG Training Loss:0.677 AVG Validation Loss:0.678 AVG Training Acc 57.25 % AVG Validation Acc 58.02 %\n",
      "Epoch:40/100 AVG Training Loss:0.669 AVG Validation Loss:0.676 AVG Training Acc 58.29 % AVG Validation Acc 58.60 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/100 AVG Training Loss:0.652 AVG Validation Loss:0.687 AVG Training Acc 60.17 % AVG Validation Acc 58.70 %\n",
      "Epoch:60/100 AVG Training Loss:0.646 AVG Validation Loss:0.697 AVG Training Acc 60.24 % AVG Validation Acc 56.75 %\n",
      "Epoch:70/100 AVG Training Loss:0.638 AVG Validation Loss:0.725 AVG Training Acc 61.34 % AVG Validation Acc 58.70 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/100 AVG Training Loss:0.635 AVG Validation Loss:0.722 AVG Training Acc 61.59 % AVG Validation Acc 58.60 %\n",
      "Epoch:90/100 AVG Training Loss:0.634 AVG Validation Loss:0.726 AVG Training Acc 61.84 % AVG Validation Acc 57.24 %\n",
      "Epoch:100/100 AVG Training Loss:0.633 AVG Validation Loss:0.741 AVG Training Acc 61.90 % AVG Validation Acc 58.99 %\n",
      "Split 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33c15491e2b94185b2bcffc4e8dd3b87",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.692 AVG Validation Loss:0.690 AVG Training Acc 51.46 % AVG Validation Acc 55.49 %\n",
      "Epoch:20/100 AVG Training Loss:0.687 AVG Validation Loss:0.685 AVG Training Acc 55.22 % AVG Validation Acc 58.89 %\n",
      "Epoch:30/100 AVG Training Loss:0.674 AVG Validation Loss:0.678 AVG Training Acc 57.56 % AVG Validation Acc 57.05 %\n",
      "Epoch:40/100 AVG Training Loss:0.662 AVG Validation Loss:0.684 AVG Training Acc 59.42 % AVG Validation Acc 56.95 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/100 AVG Training Loss:0.635 AVG Validation Loss:0.694 AVG Training Acc 62.08 % AVG Validation Acc 58.21 %\n",
      "Epoch:60/100 AVG Training Loss:0.624 AVG Validation Loss:0.701 AVG Training Acc 63.20 % AVG Validation Acc 58.02 %\n",
      "Epoch:70/100 AVG Training Loss:0.621 AVG Validation Loss:0.711 AVG Training Acc 63.65 % AVG Validation Acc 58.70 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/100 AVG Training Loss:0.615 AVG Validation Loss:0.710 AVG Training Acc 64.35 % AVG Validation Acc 58.11 %\n",
      "Epoch:90/100 AVG Training Loss:0.615 AVG Validation Loss:0.720 AVG Training Acc 64.55 % AVG Validation Acc 57.82 %\n",
      "Epoch:100/100 AVG Training Loss:0.610 AVG Validation Loss:0.718 AVG Training Acc 64.46 % AVG Validation Acc 57.14 %\n",
      "Split 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46fccbf7348343d198dc0f5140bf79c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.693 AVG Validation Loss:0.693 AVG Training Acc 50.89 % AVG Validation Acc 50.24 %\n",
      "Epoch:20/100 AVG Training Loss:0.680 AVG Validation Loss:0.681 AVG Training Acc 56.95 % AVG Validation Acc 55.88 %\n",
      "Epoch:30/100 AVG Training Loss:0.674 AVG Validation Loss:0.682 AVG Training Acc 57.33 % AVG Validation Acc 56.46 %\n",
      "Epoch:40/100 AVG Training Loss:0.664 AVG Validation Loss:0.684 AVG Training Acc 59.21 % AVG Validation Acc 56.85 %\n",
      "Epoch:50/100 AVG Training Loss:0.663 AVG Validation Loss:0.692 AVG Training Acc 59.46 % AVG Validation Acc 54.71 %\n",
      "Epoch:60/100 AVG Training Loss:0.656 AVG Validation Loss:0.672 AVG Training Acc 60.24 % AVG Validation Acc 58.02 %\n",
      "Epoch:70/100 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 61.28 % AVG Validation Acc 59.57 %\n",
      "Epoch    70: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:80/100 AVG Training Loss:0.617 AVG Validation Loss:0.675 AVG Training Acc 64.54 % AVG Validation Acc 60.84 %\n",
      "Epoch:90/100 AVG Training Loss:0.614 AVG Validation Loss:0.677 AVG Training Acc 65.26 % AVG Validation Acc 61.03 %\n",
      "Epoch:100/100 AVG Training Loss:0.605 AVG Validation Loss:0.678 AVG Training Acc 65.93 % AVG Validation Acc 61.81 %\n",
      "Split 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d554c07dc44a40049bd0c686d394651b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.693 AVG Validation Loss:0.694 AVG Training Acc 49.82 % AVG Validation Acc 49.17 %\n",
      "Epoch:20/100 AVG Training Loss:0.685 AVG Validation Loss:0.690 AVG Training Acc 55.65 % AVG Validation Acc 53.55 %\n",
      "Epoch:30/100 AVG Training Loss:0.675 AVG Validation Loss:0.677 AVG Training Acc 57.34 % AVG Validation Acc 56.95 %\n",
      "Epoch:40/100 AVG Training Loss:0.667 AVG Validation Loss:0.688 AVG Training Acc 58.77 % AVG Validation Acc 57.24 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/100 AVG Training Loss:0.655 AVG Validation Loss:0.681 AVG Training Acc 61.24 % AVG Validation Acc 59.77 %\n",
      "Epoch:60/100 AVG Training Loss:0.646 AVG Validation Loss:0.686 AVG Training Acc 62.35 % AVG Validation Acc 59.96 %\n",
      "Epoch:70/100 AVG Training Loss:0.642 AVG Validation Loss:0.687 AVG Training Acc 62.44 % AVG Validation Acc 61.03 %\n",
      "Epoch:80/100 AVG Training Loss:0.639 AVG Validation Loss:0.695 AVG Training Acc 62.95 % AVG Validation Acc 60.16 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/100 AVG Training Loss:0.638 AVG Validation Loss:0.698 AVG Training Acc 62.75 % AVG Validation Acc 61.13 %\n",
      "Epoch:100/100 AVG Training Loss:0.635 AVG Validation Loss:0.690 AVG Training Acc 62.79 % AVG Validation Acc 60.54 %\n",
      "Split 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "889070c59f984557b6e16b04aa751234",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.693 AVG Validation Loss:0.692 AVG Training Acc 51.09 % AVG Validation Acc 52.19 %\n",
      "Epoch:20/100 AVG Training Loss:0.688 AVG Validation Loss:0.682 AVG Training Acc 54.18 % AVG Validation Acc 56.56 %\n",
      "Epoch:30/100 AVG Training Loss:0.680 AVG Validation Loss:0.686 AVG Training Acc 56.33 % AVG Validation Acc 54.71 %\n",
      "Epoch:40/100 AVG Training Loss:0.672 AVG Validation Loss:0.680 AVG Training Acc 58.32 % AVG Validation Acc 56.17 %\n",
      "Epoch:50/100 AVG Training Loss:0.667 AVG Validation Loss:0.674 AVG Training Acc 58.97 % AVG Validation Acc 58.50 %\n",
      "Epoch:60/100 AVG Training Loss:0.661 AVG Validation Loss:0.666 AVG Training Acc 59.59 % AVG Validation Acc 59.28 %\n",
      "Epoch:70/100 AVG Training Loss:0.649 AVG Validation Loss:0.670 AVG Training Acc 62.15 % AVG Validation Acc 60.64 %\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:80/100 AVG Training Loss:0.622 AVG Validation Loss:0.674 AVG Training Acc 64.36 % AVG Validation Acc 60.74 %\n",
      "Epoch:90/100 AVG Training Loss:0.608 AVG Validation Loss:0.683 AVG Training Acc 65.77 % AVG Validation Acc 61.90 %\n",
      "Epoch:100/100 AVG Training Loss:0.600 AVG Validation Loss:0.691 AVG Training Acc 65.94 % AVG Validation Acc 61.42 %\n",
      "Split 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79ca972e83904dfe838b7ae12196dda3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.693 AVG Validation Loss:0.692 AVG Training Acc 51.73 % AVG Validation Acc 49.76 %\n",
      "Epoch:20/100 AVG Training Loss:0.687 AVG Validation Loss:0.685 AVG Training Acc 54.10 % AVG Validation Acc 56.46 %\n",
      "Epoch:30/100 AVG Training Loss:0.681 AVG Validation Loss:0.679 AVG Training Acc 56.76 % AVG Validation Acc 57.05 %\n",
      "Epoch:40/100 AVG Training Loss:0.672 AVG Validation Loss:0.675 AVG Training Acc 58.18 % AVG Validation Acc 59.67 %\n",
      "Epoch:50/100 AVG Training Loss:0.658 AVG Validation Loss:0.664 AVG Training Acc 60.07 % AVG Validation Acc 61.90 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/100 AVG Training Loss:0.639 AVG Validation Loss:0.662 AVG Training Acc 61.85 % AVG Validation Acc 61.81 %\n",
      "Epoch:70/100 AVG Training Loss:0.630 AVG Validation Loss:0.660 AVG Training Acc 62.57 % AVG Validation Acc 61.61 %\n",
      "Epoch:80/100 AVG Training Loss:0.621 AVG Validation Loss:0.663 AVG Training Acc 63.50 % AVG Validation Acc 62.29 %\n",
      "Epoch:90/100 AVG Training Loss:0.620 AVG Validation Loss:0.654 AVG Training Acc 63.49 % AVG Validation Acc 62.10 %\n",
      "Epoch:100/100 AVG Training Loss:0.616 AVG Validation Loss:0.657 AVG Training Acc 63.81 % AVG Validation Acc 62.59 %\n",
      "Split 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e4ed7e6d8a3458cb2e7fb5c638a74d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.693 AVG Validation Loss:0.692 AVG Training Acc 50.89 % AVG Validation Acc 53.74 %\n",
      "Epoch:20/100 AVG Training Loss:0.682 AVG Validation Loss:0.688 AVG Training Acc 56.20 % AVG Validation Acc 53.74 %\n",
      "Epoch:30/100 AVG Training Loss:0.671 AVG Validation Loss:0.670 AVG Training Acc 58.43 % AVG Validation Acc 58.50 %\n",
      "Epoch:40/100 AVG Training Loss:0.665 AVG Validation Loss:0.670 AVG Training Acc 58.84 % AVG Validation Acc 59.77 %\n",
      "Epoch:50/100 AVG Training Loss:0.660 AVG Validation Loss:0.676 AVG Training Acc 59.42 % AVG Validation Acc 57.53 %\n",
      "Epoch:60/100 AVG Training Loss:0.663 AVG Validation Loss:0.670 AVG Training Acc 58.84 % AVG Validation Acc 58.50 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:70/100 AVG Training Loss:0.660 AVG Validation Loss:0.673 AVG Training Acc 59.19 % AVG Validation Acc 58.41 %\n",
      "Epoch:80/100 AVG Training Loss:0.650 AVG Validation Loss:0.666 AVG Training Acc 60.40 % AVG Validation Acc 59.96 %\n",
      "Epoch:90/100 AVG Training Loss:0.644 AVG Validation Loss:0.664 AVG Training Acc 61.11 % AVG Validation Acc 61.52 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/100 AVG Training Loss:0.643 AVG Validation Loss:0.667 AVG Training Acc 61.60 % AVG Validation Acc 61.52 %\n",
      "Split 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32851ad023974a458534583cb8c06c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.693 AVG Validation Loss:0.692 AVG Training Acc 50.78 % AVG Validation Acc 51.21 %\n",
      "Epoch:20/100 AVG Training Loss:0.682 AVG Validation Loss:0.705 AVG Training Acc 56.05 % AVG Validation Acc 50.24 %\n",
      "Epoch:30/100 AVG Training Loss:0.674 AVG Validation Loss:0.677 AVG Training Acc 57.56 % AVG Validation Acc 57.92 %\n",
      "Epoch:40/100 AVG Training Loss:0.662 AVG Validation Loss:0.682 AVG Training Acc 59.19 % AVG Validation Acc 57.43 %\n",
      "Epoch:50/100 AVG Training Loss:0.659 AVG Validation Loss:0.687 AVG Training Acc 60.11 % AVG Validation Acc 58.99 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/100 AVG Training Loss:0.635 AVG Validation Loss:0.689 AVG Training Acc 62.66 % AVG Validation Acc 59.48 %\n",
      "Epoch:70/100 AVG Training Loss:0.623 AVG Validation Loss:0.689 AVG Training Acc 63.48 % AVG Validation Acc 59.57 %\n",
      "Epoch:80/100 AVG Training Loss:0.618 AVG Validation Loss:0.701 AVG Training Acc 63.79 % AVG Validation Acc 59.09 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/100 AVG Training Loss:0.612 AVG Validation Loss:0.703 AVG Training Acc 64.12 % AVG Validation Acc 60.45 %\n",
      "Epoch:100/100 AVG Training Loss:0.611 AVG Validation Loss:0.708 AVG Training Acc 64.60 % AVG Validation Acc 60.06 %\n",
      "Date_threshold_25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34b2bb04a98c44938a2176c2e97728fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exam_fail\n",
      "Before reshaping:\n",
      "Training Shape torch.Size([11878, 25]) torch.Size([11878])\n",
      "Testing Shape torch.Size([1860, 25]) torch.Size([1860])\n",
      "\n",
      "After reshaping:\n",
      "Training Shape torch.Size([11878, 25, 1]) torch.Size([11878])\n",
      "Testing Shape torch.Size([1860, 25, 1]) torch.Size([1860])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d1dc8ca09e04b00a81d7acc2de6738f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d6499651c12413c934dd5ed3c1b6772",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best Accuracy found: 55.22%\n",
      "Epoch: 1\n",
      "New Best Accuracy found: 55.30%\n",
      "Epoch: 2\n",
      "New Best Accuracy found: 57.07%\n",
      "Epoch: 5\n",
      "New Best Accuracy found: 57.74%\n",
      "Epoch: 8\n",
      "New Best Accuracy found: 58.75%\n",
      "Epoch: 9\n",
      "Epoch:10/100 AVG Training Loss:0.665 AVG Validation Loss:0.660 AVG Training Acc 58.69 % AVG Validation Acc 56.82 %\n",
      "New Best Accuracy found: 61.78%\n",
      "Epoch: 13\n",
      "New Best Accuracy found: 62.54%\n",
      "Epoch: 14\n",
      "New Best Accuracy found: 64.39%\n",
      "Epoch: 15\n",
      "New Best Accuracy found: 65.49%\n",
      "Epoch: 17\n",
      "New Best Accuracy found: 66.92%\n",
      "Epoch: 19\n",
      "Epoch:20/100 AVG Training Loss:0.619 AVG Validation Loss:0.629 AVG Training Acc 65.70 % AVG Validation Acc 64.06 %\n",
      "New Best Accuracy found: 68.10%\n",
      "Epoch: 26\n",
      "Epoch:30/100 AVG Training Loss:0.591 AVG Validation Loss:0.630 AVG Training Acc 68.24 % AVG Validation Acc 64.98 %\n",
      "New Best Accuracy found: 68.35%\n",
      "Epoch: 31\n",
      "New Best Accuracy found: 69.11%\n",
      "Epoch: 36\n",
      "New Best Accuracy found: 69.36%\n",
      "Epoch: 37\n",
      "New Best Accuracy found: 69.70%\n",
      "Epoch: 38\n",
      "New Best Accuracy found: 70.29%\n",
      "Epoch: 39\n",
      "Epoch:40/100 AVG Training Loss:0.565 AVG Validation Loss:0.602 AVG Training Acc 70.02 % AVG Validation Acc 68.94 %\n",
      "Epoch:50/100 AVG Training Loss:0.667 AVG Validation Loss:0.653 AVG Training Acc 58.65 % AVG Validation Acc 62.04 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/100 AVG Training Loss:0.640 AVG Validation Loss:0.642 AVG Training Acc 63.55 % AVG Validation Acc 62.63 %\n",
      "Epoch:70/100 AVG Training Loss:0.623 AVG Validation Loss:0.623 AVG Training Acc 66.26 % AVG Validation Acc 65.99 %\n",
      "Epoch:80/100 AVG Training Loss:0.606 AVG Validation Loss:0.614 AVG Training Acc 67.58 % AVG Validation Acc 67.17 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/100 AVG Training Loss:0.595 AVG Validation Loss:0.610 AVG Training Acc 68.01 % AVG Validation Acc 68.35 %\n",
      "Epoch:100/100 AVG Training Loss:0.593 AVG Validation Loss:0.612 AVG Training Acc 68.72 % AVG Validation Acc 67.85 %\n",
      "Split 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14507e30e1e14d95bde490f2350ff602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.663 AVG Validation Loss:0.647 AVG Training Acc 59.51 % AVG Validation Acc 61.87 %\n",
      "Epoch:20/100 AVG Training Loss:0.623 AVG Validation Loss:0.628 AVG Training Acc 65.61 % AVG Validation Acc 64.98 %\n",
      "Epoch:30/100 AVG Training Loss:0.584 AVG Validation Loss:0.621 AVG Training Acc 69.68 % AVG Validation Acc 65.49 %\n",
      "Epoch:40/100 AVG Training Loss:0.545 AVG Validation Loss:0.601 AVG Training Acc 73.01 % AVG Validation Acc 66.67 %\n",
      "Epoch:50/100 AVG Training Loss:0.628 AVG Validation Loss:0.624 AVG Training Acc 64.73 % AVG Validation Acc 64.73 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-03.\n",
      "New Best Accuracy found: 70.79%\n",
      "Epoch: 59\n",
      "Epoch:60/100 AVG Training Loss:0.456 AVG Validation Loss:0.584 AVG Training Acc 79.08 % AVG Validation Acc 70.71 %\n",
      "New Best Accuracy found: 70.96%\n",
      "Epoch: 62\n",
      "New Best Accuracy found: 71.04%\n",
      "Epoch: 64\n",
      "New Best Accuracy found: 71.30%\n",
      "Epoch: 67\n",
      "Epoch:70/100 AVG Training Loss:0.416 AVG Validation Loss:0.595 AVG Training Acc 81.72 % AVG Validation Acc 71.30 %\n",
      "New Best Accuracy found: 71.55%\n",
      "Epoch: 72\n",
      "New Best Accuracy found: 72.05%\n",
      "Epoch: 75\n",
      "Epoch:80/100 AVG Training Loss:0.401 AVG Validation Loss:0.621 AVG Training Acc 82.23 % AVG Validation Acc 72.05 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/100 AVG Training Loss:0.371 AVG Validation Loss:0.631 AVG Training Acc 83.94 % AVG Validation Acc 72.22 %\n",
      "New Best Accuracy found: 72.22%\n",
      "Epoch: 90\n",
      "New Best Accuracy found: 72.39%\n",
      "Epoch: 94\n",
      "Epoch:100/100 AVG Training Loss:0.363 AVG Validation Loss:0.652 AVG Training Acc 84.42 % AVG Validation Acc 71.80 %\n",
      "Split 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9514f50a58c04bb1b69d09801cddbf9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.662 AVG Validation Loss:0.667 AVG Training Acc 59.74 % AVG Validation Acc 59.68 %\n",
      "Epoch:20/100 AVG Training Loss:0.616 AVG Validation Loss:0.619 AVG Training Acc 66.53 % AVG Validation Acc 66.16 %\n",
      "Epoch:30/100 AVG Training Loss:0.582 AVG Validation Loss:0.620 AVG Training Acc 69.73 % AVG Validation Acc 65.74 %\n",
      "Epoch:40/100 AVG Training Loss:0.571 AVG Validation Loss:0.606 AVG Training Acc 70.78 % AVG Validation Acc 68.60 %\n",
      "Epoch:50/100 AVG Training Loss:0.532 AVG Validation Loss:0.622 AVG Training Acc 73.83 % AVG Validation Acc 66.75 %\n",
      "Epoch:60/100 AVG Training Loss:0.535 AVG Validation Loss:0.590 AVG Training Acc 73.35 % AVG Validation Acc 68.86 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:70/100 AVG Training Loss:0.447 AVG Validation Loss:0.605 AVG Training Acc 79.13 % AVG Validation Acc 69.61 %\n",
      "Epoch:80/100 AVG Training Loss:0.418 AVG Validation Loss:0.607 AVG Training Acc 81.13 % AVG Validation Acc 71.30 %\n",
      "Epoch:90/100 AVG Training Loss:0.393 AVG Validation Loss:0.633 AVG Training Acc 82.11 % AVG Validation Acc 71.89 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/100 AVG Training Loss:0.382 AVG Validation Loss:0.628 AVG Training Acc 83.16 % AVG Validation Acc 72.14 %\n",
      "Split 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33e0dd95e8fd400bb42cc42378c416f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.660 AVG Validation Loss:0.646 AVG Training Acc 60.64 % AVG Validation Acc 62.29 %\n",
      "Epoch:20/100 AVG Training Loss:0.624 AVG Validation Loss:0.626 AVG Training Acc 64.92 % AVG Validation Acc 64.90 %\n",
      "Epoch:30/100 AVG Training Loss:0.592 AVG Validation Loss:0.641 AVG Training Acc 68.62 % AVG Validation Acc 64.48 %\n",
      "Epoch:40/100 AVG Training Loss:0.558 AVG Validation Loss:0.601 AVG Training Acc 71.29 % AVG Validation Acc 69.61 %\n",
      "Epoch:50/100 AVG Training Loss:0.548 AVG Validation Loss:0.600 AVG Training Acc 71.97 % AVG Validation Acc 67.09 %\n",
      "Epoch:60/100 AVG Training Loss:0.553 AVG Validation Loss:0.576 AVG Training Acc 71.61 % AVG Validation Acc 69.28 %\n",
      "Epoch:70/100 AVG Training Loss:0.532 AVG Validation Loss:0.601 AVG Training Acc 73.59 % AVG Validation Acc 68.01 %\n",
      "Epoch    71: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:80/100 AVG Training Loss:0.439 AVG Validation Loss:0.590 AVG Training Acc 79.93 % AVG Validation Acc 70.88 %\n",
      "Epoch:90/100 AVG Training Loss:0.419 AVG Validation Loss:0.596 AVG Training Acc 80.94 % AVG Validation Acc 71.30 %\n",
      "New Best Accuracy found: 72.47%\n",
      "Epoch: 92\n",
      "Epoch:100/100 AVG Training Loss:0.402 AVG Validation Loss:0.611 AVG Training Acc 81.82 % AVG Validation Acc 72.05 %\n",
      "Split 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec4b8e19879c47938fe2ae26e270138a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.656 AVG Validation Loss:0.672 AVG Training Acc 60.69 % AVG Validation Acc 59.93 %\n",
      "Epoch:20/100 AVG Training Loss:0.611 AVG Validation Loss:0.643 AVG Training Acc 67.11 % AVG Validation Acc 65.49 %\n",
      "Epoch:30/100 AVG Training Loss:0.561 AVG Validation Loss:0.616 AVG Training Acc 71.35 % AVG Validation Acc 67.51 %\n",
      "Epoch:40/100 AVG Training Loss:0.524 AVG Validation Loss:0.579 AVG Training Acc 74.36 % AVG Validation Acc 70.20 %\n",
      "Epoch:50/100 AVG Training Loss:0.522 AVG Validation Loss:0.584 AVG Training Acc 74.89 % AVG Validation Acc 70.71 %\n",
      "Epoch:60/100 AVG Training Loss:0.481 AVG Validation Loss:0.567 AVG Training Acc 77.43 % AVG Validation Acc 72.22 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-03.\n",
      "New Best Accuracy found: 73.40%\n",
      "Epoch: 65\n",
      "New Best Accuracy found: 73.57%\n",
      "Epoch: 66\n",
      "Epoch:70/100 AVG Training Loss:0.393 AVG Validation Loss:0.599 AVG Training Acc 82.59 % AVG Validation Acc 72.47 %\n",
      "New Best Accuracy found: 73.65%\n",
      "Epoch: 71\n",
      "New Best Accuracy found: 74.24%\n",
      "Epoch: 73\n",
      "Epoch:80/100 AVG Training Loss:0.364 AVG Validation Loss:0.613 AVG Training Acc 84.28 % AVG Validation Acc 73.91 %\n",
      "Epoch:90/100 AVG Training Loss:0.350 AVG Validation Loss:0.614 AVG Training Acc 85.27 % AVG Validation Acc 73.74 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-04.\n",
      "New Best Accuracy found: 74.33%\n",
      "Epoch: 95\n",
      "New Best Accuracy found: 74.41%\n",
      "Epoch: 98\n",
      "Epoch:100/100 AVG Training Loss:0.334 AVG Validation Loss:0.636 AVG Training Acc 86.01 % AVG Validation Acc 73.74 %\n",
      "Split 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26e0ba6f7321410c8decc455bb8e811f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.671 AVG Validation Loss:0.667 AVG Training Acc 57.86 % AVG Validation Acc 59.68 %\n",
      "Epoch:20/100 AVG Training Loss:0.626 AVG Validation Loss:0.634 AVG Training Acc 65.27 % AVG Validation Acc 62.71 %\n",
      "Epoch:30/100 AVG Training Loss:0.593 AVG Validation Loss:0.597 AVG Training Acc 68.62 % AVG Validation Acc 67.34 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/100 AVG Training Loss:0.615 AVG Validation Loss:0.618 AVG Training Acc 66.88 % AVG Validation Acc 64.90 %\n",
      "Epoch:50/100 AVG Training Loss:0.601 AVG Validation Loss:0.621 AVG Training Acc 68.19 % AVG Validation Acc 65.66 %\n",
      "Epoch:60/100 AVG Training Loss:0.587 AVG Validation Loss:0.613 AVG Training Acc 68.45 % AVG Validation Acc 66.84 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/100 AVG Training Loss:0.568 AVG Validation Loss:0.605 AVG Training Acc 70.76 % AVG Validation Acc 67.09 %\n",
      "Epoch:80/100 AVG Training Loss:0.563 AVG Validation Loss:0.612 AVG Training Acc 70.55 % AVG Validation Acc 66.67 %\n",
      "Epoch:90/100 AVG Training Loss:0.557 AVG Validation Loss:0.608 AVG Training Acc 70.75 % AVG Validation Acc 67.85 %\n",
      "Epoch:100/100 AVG Training Loss:0.557 AVG Validation Loss:0.607 AVG Training Acc 71.38 % AVG Validation Acc 67.34 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Split 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6365ffc9ace04065a3fe3257e7b5e8fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.640 AVG Validation Loss:0.635 AVG Training Acc 63.55 % AVG Validation Acc 65.15 %\n",
      "Epoch:20/100 AVG Training Loss:0.586 AVG Validation Loss:0.617 AVG Training Acc 69.57 % AVG Validation Acc 66.84 %\n",
      "Epoch:30/100 AVG Training Loss:0.552 AVG Validation Loss:0.603 AVG Training Acc 73.17 % AVG Validation Acc 66.92 %\n",
      "Epoch:40/100 AVG Training Loss:0.514 AVG Validation Loss:0.633 AVG Training Acc 74.95 % AVG Validation Acc 66.08 %\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/100 AVG Training Loss:0.438 AVG Validation Loss:0.615 AVG Training Acc 79.92 % AVG Validation Acc 70.37 %\n",
      "Epoch:60/100 AVG Training Loss:0.407 AVG Validation Loss:0.636 AVG Training Acc 81.72 % AVG Validation Acc 70.96 %\n",
      "Epoch:70/100 AVG Training Loss:0.385 AVG Validation Loss:0.654 AVG Training Acc 82.88 % AVG Validation Acc 70.88 %\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/100 AVG Training Loss:0.368 AVG Validation Loss:0.679 AVG Training Acc 84.05 % AVG Validation Acc 70.37 %\n",
      "Epoch:90/100 AVG Training Loss:0.359 AVG Validation Loss:0.684 AVG Training Acc 84.41 % AVG Validation Acc 71.80 %\n",
      "Epoch:100/100 AVG Training Loss:0.362 AVG Validation Loss:0.680 AVG Training Acc 84.41 % AVG Validation Acc 71.04 %\n",
      "Split 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cd409e2a52d4284a8f1dde9bfa54791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.673 AVG Validation Loss:0.683 AVG Training Acc 57.27 % AVG Validation Acc 57.83 %\n",
      "Epoch:20/100 AVG Training Loss:0.625 AVG Validation Loss:0.680 AVG Training Acc 64.91 % AVG Validation Acc 61.53 %\n",
      "Epoch:30/100 AVG Training Loss:0.593 AVG Validation Loss:0.613 AVG Training Acc 68.00 % AVG Validation Acc 67.85 %\n",
      "Epoch:40/100 AVG Training Loss:0.563 AVG Validation Loss:0.621 AVG Training Acc 70.75 % AVG Validation Acc 69.36 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/100 AVG Training Loss:0.485 AVG Validation Loss:0.598 AVG Training Acc 76.46 % AVG Validation Acc 71.04 %\n",
      "Epoch:60/100 AVG Training Loss:0.461 AVG Validation Loss:0.620 AVG Training Acc 77.72 % AVG Validation Acc 70.79 %\n",
      "Epoch:70/100 AVG Training Loss:0.442 AVG Validation Loss:0.629 AVG Training Acc 79.02 % AVG Validation Acc 71.13 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/100 AVG Training Loss:0.429 AVG Validation Loss:0.642 AVG Training Acc 79.92 % AVG Validation Acc 72.56 %\n",
      "Epoch:90/100 AVG Training Loss:0.422 AVG Validation Loss:0.642 AVG Training Acc 80.45 % AVG Validation Acc 71.80 %\n",
      "Epoch:100/100 AVG Training Loss:0.423 AVG Validation Loss:0.646 AVG Training Acc 80.66 % AVG Validation Acc 72.22 %\n",
      "Split 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95ff03a162dd4a79bcef02860cf48709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.661 AVG Validation Loss:0.661 AVG Training Acc 59.61 % AVG Validation Acc 59.06 %\n",
      "Epoch:20/100 AVG Training Loss:0.624 AVG Validation Loss:0.629 AVG Training Acc 64.95 % AVG Validation Acc 64.87 %\n",
      "Epoch:30/100 AVG Training Loss:0.585 AVG Validation Loss:0.611 AVG Training Acc 69.33 % AVG Validation Acc 67.31 %\n",
      "Epoch:40/100 AVG Training Loss:0.560 AVG Validation Loss:0.606 AVG Training Acc 71.45 % AVG Validation Acc 68.32 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/100 AVG Training Loss:0.471 AVG Validation Loss:0.583 AVG Training Acc 78.08 % AVG Validation Acc 72.11 %\n",
      "Epoch:60/100 AVG Training Loss:0.448 AVG Validation Loss:0.578 AVG Training Acc 79.53 % AVG Validation Acc 71.10 %\n",
      "Epoch:70/100 AVG Training Loss:0.428 AVG Validation Loss:0.590 AVG Training Acc 80.63 % AVG Validation Acc 72.20 %\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/100 AVG Training Loss:0.415 AVG Validation Loss:0.596 AVG Training Acc 81.09 % AVG Validation Acc 72.11 %\n",
      "Epoch:90/100 AVG Training Loss:0.413 AVG Validation Loss:0.588 AVG Training Acc 81.07 % AVG Validation Acc 72.45 %\n",
      "Epoch:100/100 AVG Training Loss:0.411 AVG Validation Loss:0.609 AVG Training Acc 81.41 % AVG Validation Acc 71.36 %\n",
      "Split 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44830c985a0a4bf08bfa175aea017e29",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/100 AVG Training Loss:0.669 AVG Validation Loss:0.653 AVG Training Acc 58.17 % AVG Validation Acc 59.31 %\n",
      "Epoch:20/100 AVG Training Loss:0.634 AVG Validation Loss:0.624 AVG Training Acc 63.58 % AVG Validation Acc 65.54 %\n",
      "Epoch:30/100 AVG Training Loss:0.608 AVG Validation Loss:0.612 AVG Training Acc 66.54 % AVG Validation Acc 65.37 %\n",
      "Epoch:40/100 AVG Training Loss:0.585 AVG Validation Loss:0.591 AVG Training Acc 68.70 % AVG Validation Acc 68.83 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/100 AVG Training Loss:0.532 AVG Validation Loss:0.596 AVG Training Acc 73.82 % AVG Validation Acc 67.99 %\n",
      "Epoch:60/100 AVG Training Loss:0.497 AVG Validation Loss:0.603 AVG Training Acc 75.47 % AVG Validation Acc 69.50 %\n",
      "Epoch:70/100 AVG Training Loss:0.484 AVG Validation Loss:0.602 AVG Training Acc 76.51 % AVG Validation Acc 68.74 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/100 AVG Training Loss:0.466 AVG Validation Loss:0.595 AVG Training Acc 77.99 % AVG Validation Acc 69.08 %\n",
      "Epoch:90/100 AVG Training Loss:0.460 AVG Validation Loss:0.594 AVG Training Acc 78.08 % AVG Validation Acc 69.59 %\n",
      "Epoch:100/100 AVG Training Loss:0.461 AVG Validation Loss:0.592 AVG Training Acc 78.10 % AVG Validation Acc 69.00 %\n",
      "final_fail\n",
      "Before reshaping:\n",
      "Training Shape torch.Size([12642, 25]) torch.Size([12642])\n",
      "Testing Shape torch.Size([1860, 25]) torch.Size([1860])\n",
      "\n",
      "After reshaping:\n",
      "Training Shape torch.Size([12642, 25, 1]) torch.Size([12642])\n",
      "Testing Shape torch.Size([1860, 25, 1]) torch.Size([1860])\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36541b73d17f4ae79165b692f6c01fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "384565d88a0445808305b63299ad02fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best Accuracy found: 56.68%\n",
      "Epoch: 1\n",
      "New Best Accuracy found: 57.94%\n",
      "Epoch: 3\n",
      "New Best Accuracy found: 58.74%\n",
      "Epoch: 8\n",
      "New Best Accuracy found: 61.66%\n",
      "Epoch: 9\n",
      "Epoch:10/100 AVG Training Loss:0.654 AVG Validation Loss:0.636 AVG Training Acc 60.85 % AVG Validation Acc 63.48 %\n",
      "New Best Accuracy found: 63.48%\n",
      "Epoch: 10\n",
      "New Best Accuracy found: 64.19%\n",
      "Epoch: 12\n",
      "New Best Accuracy found: 65.53%\n",
      "Epoch: 13\n",
      "New Best Accuracy found: 66.96%\n",
      "Epoch: 14\n",
      "New Best Accuracy found: 67.59%\n",
      "Epoch: 17\n",
      "New Best Accuracy found: 67.83%\n",
      "Epoch: 19\n",
      "Epoch:20/100 AVG Training Loss:0.592 AVG Validation Loss:0.604 AVG Training Acc 68.52 % AVG Validation Acc 66.40 %\n",
      "New Best Accuracy found: 70.59%\n",
      "Epoch: 21\n",
      "New Best Accuracy found: 71.38%\n",
      "Epoch: 27\n",
      "Epoch:30/100 AVG Training Loss:0.542 AVG Validation Loss:0.560 AVG Training Acc 72.67 % AVG Validation Acc 71.38 %\n",
      "New Best Accuracy found: 72.65%\n",
      "Epoch: 31\n",
      "New Best Accuracy found: 73.28%\n",
      "Epoch: 35\n",
      "New Best Accuracy found: 73.44%\n",
      "Epoch: 37\n",
      "Epoch:40/100 AVG Training Loss:0.507 AVG Validation Loss:0.565 AVG Training Acc 75.40 % AVG Validation Acc 71.38 %\n",
      "New Best Accuracy found: 74.15%\n",
      "Epoch: 43\n",
      "Epoch:50/100 AVG Training Loss:0.488 AVG Validation Loss:0.531 AVG Training Acc 76.56 % AVG Validation Acc 72.96 %\n",
      "New Best Accuracy found: 74.94%\n",
      "Epoch: 53\n",
      "New Best Accuracy found: 76.28%\n",
      "Epoch: 54\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(normalized_data.keys()):\n",
    "    \n",
    "    print(i)\n",
    "    threshold_dict = {} #dict to store information in for each threshold\n",
    "    data = deepcopy(normalized_data[i])\n",
    "    \n",
    "    #set X and Y columns\n",
    "    X = data[data.columns[:25]] #different timesteps\n",
    "    y = data[data.columns[-4:]] #the 4 different putative targets\n",
    "    \n",
    "    for k in tqdm(targets):\n",
    "        print(k)\n",
    "        \n",
    "        #Start with train test split\n",
    "        X_train_val, X_test, y_train_val, y_test, = train_test_split(\n",
    "                                    X,\n",
    "                                   y[k], #replace when going for multi-target \n",
    "                                   test_size = 0.20,\n",
    "                                   random_state = 15,\n",
    "                                   shuffle=True,\n",
    "                                   stratify = y[k] #replace when going for multi-target\n",
    "                                    )\n",
    "        \n",
    "        #create dict to store fold performance\n",
    "        foldperf={}\n",
    "        \n",
    "        #reset \"best accuracy for treshold i and target k\"\n",
    "        best_accuracy = 0\n",
    "\n",
    "        #make train_val split\n",
    "        for fold, (train_idx,val_idx) in tqdm(enumerate(splits.split(X_train_val, y_train_val))):\n",
    "\n",
    "            print('Split {}'.format(fold + 1))\n",
    "            \n",
    "            #make split between train and Val\n",
    "            X_train, y_train = X_train_val.iloc[train_idx], y_train_val.iloc[train_idx]\n",
    "            X_val, y_val = X_train_val.iloc[val_idx], y_train_val.iloc[val_idx]\n",
    "            \n",
    "            #apply SMOTE to training split\n",
    "            over = SMOTE()\n",
    "            X_train, y_train = over.fit_resample(X_train, y_train)\n",
    "            \n",
    "            #second, convert everything to pytorch tensor - we will convert to tensor dataset and \n",
    "            X_train_tensors = Variable(torch.Tensor(X_train.values))\n",
    "            X_val_tensors = Variable(torch.Tensor(X_val.values))\n",
    "\n",
    "            y_train_tensors = Variable(torch.Tensor(y_train.values))\n",
    "            y_val_tensors = Variable(torch.Tensor(y_val.values)) \n",
    "\n",
    "            #reshaping to rows, timestamps, features \n",
    "            X_train_tensors = torch.reshape(X_train_tensors,   (X_train_tensors.shape[0], X_train_tensors.shape[1], 1))\n",
    "            X_val_tensors = torch.reshape(X_val_tensors,  (X_val_tensors.shape[0], X_val_tensors.shape[1], 1))\n",
    "        \n",
    "            #convert y tensors to format longtensor\n",
    "            y_train_tensors = y_train_tensors.type(torch.cuda.LongTensor)\n",
    "            y_val_tensors = y_val_tensors.type(torch.cuda.LongTensor)\n",
    "            \n",
    "            #create Tensor Datasets and dataloaders for both Train and Val\n",
    "            train_dataset = TensorDataset(X_train_tensors, y_train_tensors)\n",
    "            val_dataset = TensorDataset(X_val_tensors, y_val_tensors)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "            #creates new model for each \n",
    "            model = LSTM_Uni(num_classes, input_size, hidden_size, num_layers, X_train_tensors.shape[1]).to('cuda') #our lstm class\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "            scheduler = ReduceLROnPlateau(optimizer, \n",
    "                                  'min', \n",
    "                                  patience = 10,\n",
    "                                  cooldown = 20,\n",
    "                                 verbose = True)\n",
    "    \n",
    "            history = {'train_loss': [], 'val_loss': [],'train_acc':[],'val_acc':[], 'precision': [],\n",
    "                      'recall' : [], 'auroc': []}\n",
    "\n",
    "            for epoch in tqdm(range(num_epochs)):\n",
    "                train_loss, train_correct=train_epoch(model,train_loader,criterion,optimizer)\n",
    "                val_loss, val_correct, precision, recall, auroc = valid_epoch(model,val_loader,criterion)\n",
    "\n",
    "                train_loss = train_loss / len(train_loader.sampler)\n",
    "                train_acc = train_correct / len(train_loader.sampler) * 100\n",
    "                val_loss = val_loss / len(val_loader.sampler)\n",
    "                val_acc = val_correct / len(val_loader.sampler) * 100\n",
    "        \n",
    "        \n",
    "                if (epoch+1) % 10 == 0: \n",
    "                    print(\"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Validation Loss:{:.3f} AVG Training Acc {:.2f} % AVG Validation Acc {:.2f} %\".format(epoch + 1,\n",
    "                                                                                                             num_epochs,\n",
    "                                                                                                             train_loss,\n",
    "                                                                                                             val_loss,\n",
    "                                                                                                             train_acc,\n",
    "                                                                                                             val_acc))\n",
    "                history['train_loss'].append(train_loss)\n",
    "                history['val_loss'].append(val_loss)\n",
    "                history['train_acc'].append(train_acc)\n",
    "                history['val_acc'].append(val_acc)\n",
    "                history['precision'].append(precision)\n",
    "                history['recall'].append(recall)\n",
    "                history['auroc'].append(auroc)\n",
    "                scheduler.step(val_loss)\n",
    "    \n",
    "                if val_acc > best_accuracy:\n",
    "            \n",
    "                #replace best accuracy and save best model\n",
    "                    print(f'New Best Accuracy found: {val_acc:.2f}%\\nEpoch: {epoch + 1}')\n",
    "                    best_accuracy = val_acc\n",
    "                    best = deepcopy(model)\n",
    "                    curr_epoch = epoch + 1\n",
    "                    \n",
    "            #store fold performance\n",
    "            foldperf['fold{}'.format(fold+1)] = history\n",
    "        \n",
    "        #saves fold performance for target \n",
    "        threshold_dict[k] = pd.DataFrame.from_dict(foldperf, orient='index') # convert dict to dataframe\n",
    "        \n",
    "        #explode to get eacxh epoch as a row\n",
    "        threshold_dict[k] = threshold_dict[k].explode(list(threshold_dict[k].columns))\n",
    "        torch.save(best,f\"../Models/{i}/SMOTE_Nova_IMS_relative_clicks_best_{k}_{curr_epoch}_epochs.h\")\n",
    "        \n",
    "    # from pandas.io.parsers import ExcelWriter\n",
    "    with pd.ExcelWriter(f\"../Data/Modeling Stage/Results/IMS/Clicks_duration_relative/SMOTE_25_splits_{i}_{replicas}_replicas.xlsx\") as writer:  \n",
    "        for sheet in targets:\n",
    "                threshold_dict[sheet].to_excel(writer, sheet_name=str(sheet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cef94d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
