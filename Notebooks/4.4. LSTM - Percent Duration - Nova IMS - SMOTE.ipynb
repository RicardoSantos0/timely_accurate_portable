{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84eda90e",
   "metadata": {},
   "source": [
    "### Thesis notebook 4.4. - NOVA IMS\n",
    "\n",
    "#### LSTM - Temporal data representation\n",
    "\n",
    "In this notebook, we will finally start our application of temporal representation using LSTMs and bi-directional LSTMs.\n",
    "The argument for the usage of Deep Learning stems from the fact that sequences themselves encode information that can be extracted using Recurrent Neural Networks and, more specifically, Long Short Term Memory Units.\n",
    "\n",
    "#### First Step: Setup a PyTorch environment that enables the use of GPU for training. \n",
    "\n",
    "The following cell wll confirm that the GPU will be the default device to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4f27844c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pycuda.driver as cuda\n",
    "\n",
    "cuda.init()\n",
    "## Get Id of default device\n",
    "torch.cuda.current_device()\n",
    "# 0\n",
    "cuda.Device(0).name() # '0' is the id of your GPU\n",
    "\n",
    "#set all tensors to gpu\n",
    "torch.set_default_tensor_type('torch.cuda.FloatTensor')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d95429e",
   "metadata": {},
   "source": [
    "#### Second Step: Import the relevant packages and declare global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6c2d97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import necessary modules/libraries\n",
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "import warnings\n",
    "import time\n",
    "\n",
    "#tqdm to monitor progress\n",
    "from tqdm.notebook import tqdm, trange\n",
    "tqdm.pandas(desc=\"Progress\")\n",
    "\n",
    "#time related features\n",
    "from datetime import timedelta\n",
    "from copy import copy, deepcopy\n",
    "\n",
    "#vizualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "#imblearn, scalers, kfold and metrics\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler, RobustScaler, QuantileTransformer,PowerTransformer\n",
    "from sklearn.model_selection import train_test_split, RepeatedKFold, RepeatedStratifiedKFold, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, recall_score, classification_report, average_precision_score, precision_recall_curve\n",
    "\n",
    "#import torch related\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.autograd import Variable \n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "\n",
    "#and optimizer of learning rate\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "#import pytorch modules\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c6c3f1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variables that may come in handy\n",
    "#course threshold sets the % duration that will be considered (1 = 100%)\n",
    "duration_threshold = [0.1, 0.25, 0.33, 0.5, 1]\n",
    "\n",
    "#colors for vizualizations\n",
    "nova_ims_colors = ['#BFD72F', '#5C666C']\n",
    "\n",
    "#standard color for student aggregates\n",
    "student_color = '#474838'\n",
    "\n",
    "#standard color for course aggragates\n",
    "course_color = '#1B3D2F'\n",
    "\n",
    "#standard continuous colormap\n",
    "standard_cmap = 'viridis_r'\n",
    "\n",
    "#Function designed to deal with multiindex and flatten it\n",
    "def flattenHierarchicalCol(col,sep = '_'):\n",
    "    '''converts multiindex columns into single index columns while retaining the hierarchical components'''\n",
    "    if not type(col) is tuple:\n",
    "        return col\n",
    "    else:\n",
    "        new_col = ''\n",
    "        for leveli,level in enumerate(col):\n",
    "            if not level == '':\n",
    "                if not leveli == 0:\n",
    "                    new_col += sep\n",
    "                new_col += level\n",
    "        return new_col\n",
    "    \n",
    "#number of replicas - number of repeats of stratified k fold - in this case 10\n",
    "replicas = 30\n",
    "\n",
    "#names to display on result figures\n",
    "date_names = {\n",
    "             'Date_threshold_10': '10% of Course Duration',   \n",
    "             'Date_threshold_25': '25% of Course Duration', \n",
    "             'Date_threshold_33': '33% of Course Duration', \n",
    "             'Date_threshold_50': '50% of Course Duration', \n",
    "             'Date_threshold_100':'100% of Course Duration', \n",
    "            }\n",
    "\n",
    "target_names = {\n",
    "                'exam_fail' : 'At risk - Exam Grade',\n",
    "                'final_fail' : 'At risk - Final Grade', \n",
    "                'exam_gifted' : 'High performer - Exam Grade', \n",
    "                'final_gifted': 'High performer - Final Grade'\n",
    "                }\n",
    "\n",
    "#targets\n",
    "targets = ['exam_fail' , 'final_fail' , 'exam_gifted' , 'final_gifted']\n",
    "temporal_columns = ['0 to 4%', '4 to 8%', '8 to 12%', '12 to 16%', '16 to 20%', '20 to 24%',\n",
    "       '24 to 28%', '28 to 32%', '32 to 36%', '36 to 40%', '40 to 44%',\n",
    "       '44 to 48%', '48 to 52%', '52 to 56%', '56 to 60%', '60 to 64%',\n",
    "       '64 to 68%', '68 to 72%', '72 to 76%', '76 to 80%', '80 to 84%',\n",
    "       '84 to 88%', '88 to 92%', '92 to 96%', '96 to 100%']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60c5ddb6",
   "metadata": {},
   "source": [
    "#### Step 3: Import data and take a preliminary look at it "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8a23ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports dataframes\n",
    "course_programs = pd.read_excel(\"../Data/Modeling Stage/Nova_IMS_Temporal_Datasets_25_splits.xlsx\", \n",
    "                                dtype = {\n",
    "                                    'course_encoding' : int,\n",
    "                                    'userid' : int},\n",
    "                               sheet_name = None)\n",
    "\n",
    "#save tables \n",
    "student_list = pd.read_csv('../Data/Modeling Stage/Nova_IMS_Filtered_targets.csv', \n",
    "                         dtype = {\n",
    "                                   'course_encoding': int,\n",
    "                                   'userid' : int,\n",
    "                                   })\n",
    "\n",
    "#drop unnamed 0 column\n",
    "for i in course_programs:\n",
    "        \n",
    "    #merge with the targets we calculated on the other \n",
    "    course_programs[i] = course_programs[i].merge(student_list, on = ['course_encoding', 'userid'], how = 'inner')\n",
    "    course_programs[i].drop(['Unnamed: 0', 'exam_mark', 'final_mark'], axis = 1, inplace = True)\n",
    "    \n",
    "    #convert results to object\n",
    "    course_programs[i]['course_encoding'], course_programs[i]['userid'] = course_programs[i]['course_encoding'].astype(object), course_programs[i]['userid'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bc3c84f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 9296 entries, 0 to 9295\n",
      "Data columns (total 31 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   course_encoding  9296 non-null   object\n",
      " 1   userid           9296 non-null   object\n",
      " 2   0 to 4%          9296 non-null   int64 \n",
      " 3   4 to 8%          9296 non-null   int64 \n",
      " 4   8 to 12%         9296 non-null   int64 \n",
      " 5   12 to 16%        9296 non-null   int64 \n",
      " 6   16 to 20%        9296 non-null   int64 \n",
      " 7   20 to 24%        9296 non-null   int64 \n",
      " 8   24 to 28%        9296 non-null   int64 \n",
      " 9   28 to 32%        9296 non-null   int64 \n",
      " 10  32 to 36%        9296 non-null   int64 \n",
      " 11  36 to 40%        9296 non-null   int64 \n",
      " 12  40 to 44%        9296 non-null   int64 \n",
      " 13  44 to 48%        9296 non-null   int64 \n",
      " 14  48 to 52%        9296 non-null   int64 \n",
      " 15  52 to 56%        9296 non-null   int64 \n",
      " 16  56 to 60%        9296 non-null   int64 \n",
      " 17  60 to 64%        9296 non-null   int64 \n",
      " 18  64 to 68%        9296 non-null   int64 \n",
      " 19  68 to 72%        9296 non-null   int64 \n",
      " 20  72 to 76%        9296 non-null   int64 \n",
      " 21  76 to 80%        9296 non-null   int64 \n",
      " 22  80 to 84%        9296 non-null   int64 \n",
      " 23  84 to 88%        9296 non-null   int64 \n",
      " 24  88 to 92%        9296 non-null   int64 \n",
      " 25  92 to 96%        9296 non-null   int64 \n",
      " 26  96 to 100%       9296 non-null   int64 \n",
      " 27  exam_fail        9296 non-null   int64 \n",
      " 28  final_fail       9296 non-null   int64 \n",
      " 29  exam_gifted      9296 non-null   int64 \n",
      " 30  final_gifted     9296 non-null   int64 \n",
      "dtypes: int64(29), object(2)\n",
      "memory usage: 2.3+ MB\n"
     ]
    }
   ],
   "source": [
    "course_programs['Date_threshold_100'].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4a751ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>course_encoding</th>\n",
       "      <th>userid</th>\n",
       "      <th>0 to 4%</th>\n",
       "      <th>4 to 8%</th>\n",
       "      <th>8 to 12%</th>\n",
       "      <th>12 to 16%</th>\n",
       "      <th>16 to 20%</th>\n",
       "      <th>20 to 24%</th>\n",
       "      <th>24 to 28%</th>\n",
       "      <th>28 to 32%</th>\n",
       "      <th>...</th>\n",
       "      <th>76 to 80%</th>\n",
       "      <th>80 to 84%</th>\n",
       "      <th>84 to 88%</th>\n",
       "      <th>88 to 92%</th>\n",
       "      <th>92 to 96%</th>\n",
       "      <th>96 to 100%</th>\n",
       "      <th>exam_fail</th>\n",
       "      <th>final_fail</th>\n",
       "      <th>exam_gifted</th>\n",
       "      <th>final_gifted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>9296.0</td>\n",
       "      <td>9296.0</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.0</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "      <td>9296.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>138.0</td>\n",
       "      <td>1590.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>150.0</td>\n",
       "      <td>3178.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>178.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.081863</td>\n",
       "      <td>8.307874</td>\n",
       "      <td>10.752797</td>\n",
       "      <td>11.193739</td>\n",
       "      <td>10.127797</td>\n",
       "      <td>8.966652</td>\n",
       "      <td>10.545396</td>\n",
       "      <td>11.445245</td>\n",
       "      <td>...</td>\n",
       "      <td>11.718051</td>\n",
       "      <td>13.136403</td>\n",
       "      <td>22.827883</td>\n",
       "      <td>27.341007</td>\n",
       "      <td>12.599613</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.201377</td>\n",
       "      <td>0.149957</td>\n",
       "      <td>0.276893</td>\n",
       "      <td>0.308090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.526351</td>\n",
       "      <td>13.580025</td>\n",
       "      <td>13.626754</td>\n",
       "      <td>16.400023</td>\n",
       "      <td>14.291254</td>\n",
       "      <td>12.180177</td>\n",
       "      <td>13.507892</td>\n",
       "      <td>15.932226</td>\n",
       "      <td>...</td>\n",
       "      <td>28.186874</td>\n",
       "      <td>36.690068</td>\n",
       "      <td>47.158607</td>\n",
       "      <td>54.963959</td>\n",
       "      <td>35.194597</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.401051</td>\n",
       "      <td>0.357048</td>\n",
       "      <td>0.447487</td>\n",
       "      <td>0.461729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>269.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>619.000000</td>\n",
       "      <td>315.000000</td>\n",
       "      <td>248.000000</td>\n",
       "      <td>268.000000</td>\n",
       "      <td>237.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>614.000000</td>\n",
       "      <td>1091.000000</td>\n",
       "      <td>604.000000</td>\n",
       "      <td>747.000000</td>\n",
       "      <td>407.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        course_encoding  userid      0 to 4%      4 to 8%     8 to 12%  \\\n",
       "count            9296.0  9296.0  9296.000000  9296.000000  9296.000000   \n",
       "unique            138.0  1590.0          NaN          NaN          NaN   \n",
       "top               150.0  3178.0          NaN          NaN          NaN   \n",
       "freq              178.0    14.0          NaN          NaN          NaN   \n",
       "mean                NaN     NaN     1.081863     8.307874    10.752797   \n",
       "std                 NaN     NaN     3.526351    13.580025    13.626754   \n",
       "min                 NaN     NaN     0.000000     0.000000     0.000000   \n",
       "25%                 NaN     NaN     0.000000     0.000000     1.000000   \n",
       "50%                 NaN     NaN     0.000000     2.000000     7.000000   \n",
       "75%                 NaN     NaN     1.000000    12.000000    15.000000   \n",
       "max                 NaN     NaN    66.000000   269.000000   360.000000   \n",
       "\n",
       "          12 to 16%    16 to 20%    20 to 24%    24 to 28%    28 to 32%  ...  \\\n",
       "count   9296.000000  9296.000000  9296.000000  9296.000000  9296.000000  ...   \n",
       "unique          NaN          NaN          NaN          NaN          NaN  ...   \n",
       "top             NaN          NaN          NaN          NaN          NaN  ...   \n",
       "freq            NaN          NaN          NaN          NaN          NaN  ...   \n",
       "mean      11.193739    10.127797     8.966652    10.545396    11.445245  ...   \n",
       "std       16.400023    14.291254    12.180177    13.507892    15.932226  ...   \n",
       "min        0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%        2.000000     2.000000     1.000000     2.000000     3.000000  ...   \n",
       "50%        7.000000     6.000000     5.000000     7.000000     7.000000  ...   \n",
       "75%       15.000000    13.000000    13.000000    14.000000    14.000000  ...   \n",
       "max      619.000000   315.000000   248.000000   268.000000   237.000000  ...   \n",
       "\n",
       "          76 to 80%    80 to 84%    84 to 88%    88 to 92%    92 to 96%  \\\n",
       "count   9296.000000  9296.000000  9296.000000  9296.000000  9296.000000   \n",
       "unique          NaN          NaN          NaN          NaN          NaN   \n",
       "top             NaN          NaN          NaN          NaN          NaN   \n",
       "freq            NaN          NaN          NaN          NaN          NaN   \n",
       "mean      11.718051    13.136403    22.827883    27.341007    12.599613   \n",
       "std       28.186874    36.690068    47.158607    54.963959    35.194597   \n",
       "min        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%        0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "50%        2.000000     2.000000     4.000000     2.000000     0.000000   \n",
       "75%       10.000000    10.000000    23.000000    27.000000     5.000000   \n",
       "max      614.000000  1091.000000   604.000000   747.000000   407.000000   \n",
       "\n",
       "        96 to 100%    exam_fail   final_fail  exam_gifted  final_gifted  \n",
       "count       9296.0  9296.000000  9296.000000  9296.000000   9296.000000  \n",
       "unique         NaN          NaN          NaN          NaN           NaN  \n",
       "top            NaN          NaN          NaN          NaN           NaN  \n",
       "freq           NaN          NaN          NaN          NaN           NaN  \n",
       "mean           0.0     0.201377     0.149957     0.276893      0.308090  \n",
       "std            0.0     0.401051     0.357048     0.447487      0.461729  \n",
       "min            0.0     0.000000     0.000000     0.000000      0.000000  \n",
       "25%            0.0     0.000000     0.000000     0.000000      0.000000  \n",
       "50%            0.0     0.000000     0.000000     0.000000      0.000000  \n",
       "75%            0.0     0.000000     0.000000     1.000000      1.000000  \n",
       "max            0.0     1.000000     1.000000     1.000000      1.000000  \n",
       "\n",
       "[11 rows x 31 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "course_programs['Date_threshold_100'].describe(include = 'all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3291817",
   "metadata": {},
   "source": [
    "In our first attempt, we will use the absolute number of clicks made by each student - scaled using standard scaler. \n",
    "Therefore, we can start by immediately placing our course encoding/userid pairings into the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be722ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(train, test, scaler):\n",
    "    \n",
    "    if scaler == 'MinMax':\n",
    "        pt = MinMaxScaler()\n",
    "    elif scaler == 'Standard':\n",
    "        pt = StandardScaler()\n",
    "    elif scaler == 'Robust':\n",
    "        pt = RobustScaler()\n",
    "    elif scaler == 'Quantile':\n",
    "        pt = QuantileTransformer()\n",
    "    else:\n",
    "        pt = PowerTransformer(method='yeo-johnson')\n",
    "    \n",
    "    data_train = pt.fit_transform(train)\n",
    "    data_test = pt.transform(test)\n",
    "    # convert the array back to a dataframe\n",
    "    normalized_train = pd.DataFrame(data_train,columns=train.columns)\n",
    "    normalized_test = pd.DataFrame(data_test,columns=test.columns)\n",
    "        \n",
    "    return normalized_train, normalized_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4d5475",
   "metadata": {},
   "source": [
    "#### Implementing Cross-Validation with Deep Learning Model\n",
    "\n",
    "**1. Create the Deep Learning Model**\n",
    "\n",
    "In this instance, we will follow-up with on the approach used in Chen & Cui - CrossEntropyLoss with applied over a softmax layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a16bd5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM_Uni(nn.Module):\n",
    "    def __init__(self, num_classes, input_size, hidden_size, num_layers, seq_length):\n",
    "        super(LSTM_Uni, self).__init__()\n",
    "        self.num_classes = num_classes #number of classes\n",
    "        self.num_layers = num_layers #number of layers\n",
    "        self.input_size = input_size #input size\n",
    "        self.hidden_size = hidden_size #hidden state\n",
    "        self.seq_length = seq_length #sequence length\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=input_size, hidden_size=hidden_size,\n",
    "                          num_layers=num_layers, batch_first = True) #lstm\n",
    "        \n",
    "        self.dropout = nn.Dropout(p = 0.5)\n",
    "    \n",
    "        self.fc = nn.Linear(self.hidden_size, num_classes) #fully connected last layer\n",
    "\n",
    "    def forward(self,x):\n",
    "        h_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) #hidden state\n",
    "        c_0 = Variable(torch.zeros(self.num_layers, x.size(0), self.hidden_size)) #internal state\n",
    "        \n",
    "        #Xavier_init for both H_0 and C_0\n",
    "        torch.nn.init.xavier_normal_(h_0)\n",
    "        torch.nn.init.xavier_normal_(c_0)\n",
    "        \n",
    "        # Propagate input through LSTM\n",
    "        lstm_out, (hn, cn) = self.lstm(x, (h_0, c_0)) #lstm with input, hidden, and internal state\n",
    "        last_output = hn.view(-1, self.hidden_size) #reshaping the data for Dense layer next\n",
    "        \n",
    "        drop_out = self.dropout(last_output)\n",
    "        pre_softmax = self.fc(drop_out) #Final Output - dense\n",
    "        return pre_softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c356bd",
   "metadata": {},
   "source": [
    "**2. Define the train and validation Functions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25b29a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model,dataloader,loss_fn,optimizer):\n",
    "    \n",
    "    train_loss,train_correct=0.0,0 \n",
    "    model.train()\n",
    "    for X, labels in dataloader:\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X)\n",
    "        loss = loss_fn(output,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * X.size(0)\n",
    "        scores, predictions = torch.max(F.log_softmax(output.data), 1)\n",
    "        train_correct += (predictions == labels).sum().item()\n",
    "        \n",
    "    return train_loss,train_correct\n",
    "  \n",
    "def valid_epoch(model,dataloader,loss_fn):\n",
    "    valid_loss, val_correct = 0.0, 0\n",
    "    targets = []\n",
    "    y_pred = []\n",
    "    probability_1 = []\n",
    "    \n",
    "    model.eval()\n",
    "    for X, labels in dataloader:\n",
    "\n",
    "        output = model(X)\n",
    "        loss=loss_fn(output,labels)\n",
    "        valid_loss+=loss.item()*X.size(0)\n",
    "        probability_1.append(F.softmax(output.data)[:,1])\n",
    "        predictions = torch.argmax(output, dim=1)\n",
    "        val_correct+=(predictions == labels).sum().item()\n",
    "        targets.append(labels)\n",
    "        y_pred.append(predictions)\n",
    "    \n",
    "    #concat all results\n",
    "    targets = torch.cat(targets).data.cpu().numpy()\n",
    "    y_pred = torch.cat(y_pred).data.cpu().numpy()\n",
    "    probability_1 = torch.cat(probability_1).data.cpu().numpy()\n",
    "    \n",
    "    #calculate precision, recall and AUC score\n",
    "    \n",
    "    precision = precision_score(targets, y_pred)\n",
    "    recall = recall_score(targets, y_pred)\n",
    "    auroc = roc_auc_score(targets, probability_1)\n",
    "    \n",
    "    #return all\n",
    "    return valid_loss,val_correct, precision, recall, auroc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4543fb3",
   "metadata": {},
   "source": [
    "**3. Define main hyperparameters of the model, including splits**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcbbef20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "num_epochs = 200 #50 epochs\n",
    "learning_rate = 0.01 #0.001 lr\n",
    "input_size = 1 #number of features\n",
    "hidden_size = 40 #number of features in hidden state\n",
    "num_layers = 1 #number of stacked lstm layers\n",
    "\n",
    "#Shape of Output as required for SoftMax Classifier\n",
    "num_classes = 2 #output shape\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "k=10\n",
    "splits= RepeatedStratifiedKFold(n_splits=k, n_repeats=replicas, random_state=15) #kfold of 10 with 30 replicas\n",
    "criterion = nn.CrossEntropyLoss()    # cross-entropy for classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a20713d9",
   "metadata": {},
   "source": [
    "**4. Make the splits and Start Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45544589",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "450bcbc58da4436d8252b227106d5d1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date_threshold_10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36ef74abbf124fdd87c489cd6de8f91e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exam_fail\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ac65fb255bb4e5cb82b2989f0d0d971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c865e548b3dc4ab4bf9ab1a245c4ba2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New Best Accuracy found: 20.16%\n",
      "Epoch: 1\n",
      "Epoch:10/200 AVG Training Loss:0.553 AVG Validation Loss:3.652 AVG Training Acc 78.41 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.529 AVG Validation Loss:5.340 AVG Training Acc 79.28 % AVG Validation Acc 20.16 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "New Best Accuracy found: 20.43%\n",
      "Epoch: 23\n",
      "New Best Accuracy found: 21.91%\n",
      "Epoch: 25\n",
      "New Best Accuracy found: 22.31%\n",
      "Epoch: 26\n",
      "Epoch:30/200 AVG Training Loss:0.689 AVG Validation Loss:0.965 AVG Training Acc 57.90 % AVG Validation Acc 21.77 %\n",
      "Epoch:40/200 AVG Training Loss:0.536 AVG Validation Loss:1.750 AVG Training Acc 77.32 % AVG Validation Acc 20.03 %\n",
      "Epoch:50/200 AVG Training Loss:0.692 AVG Validation Loss:0.888 AVG Training Acc 55.39 % AVG Validation Acc 20.83 %\n",
      "New Best Accuracy found: 23.66%\n",
      "Epoch: 59\n",
      "Epoch:60/200 AVG Training Loss:0.682 AVG Validation Loss:0.833 AVG Training Acc 56.56 % AVG Validation Acc 23.79 %\n",
      "New Best Accuracy found: 23.79%\n",
      "Epoch: 60\n",
      "New Best Accuracy found: 24.06%\n",
      "Epoch: 66\n",
      "New Best Accuracy found: 26.08%\n",
      "Epoch: 68\n",
      "Epoch:70/200 AVG Training Loss:0.679 AVG Validation Loss:0.826 AVG Training Acc 57.52 % AVG Validation Acc 23.66 %\n",
      "New Best Accuracy found: 26.34%\n",
      "Epoch: 75\n",
      "New Best Accuracy found: 26.88%\n",
      "Epoch: 79\n",
      "Epoch:80/200 AVG Training Loss:0.672 AVG Validation Loss:0.814 AVG Training Acc 59.69 % AVG Validation Acc 25.00 %\n",
      "Epoch:90/200 AVG Training Loss:0.667 AVG Validation Loss:0.848 AVG Training Acc 60.00 % AVG Validation Acc 25.81 %\n",
      "New Best Accuracy found: 28.09%\n",
      "Epoch: 95\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.708 AVG Validation Loss:0.813 AVG Training Acc 53.32 % AVG Validation Acc 32.53 %\n",
      "New Best Accuracy found: 32.53%\n",
      "Epoch: 100\n",
      "New Best Accuracy found: 39.65%\n",
      "Epoch: 101\n",
      "New Best Accuracy found: 44.49%\n",
      "Epoch: 102\n",
      "New Best Accuracy found: 48.12%\n",
      "Epoch: 103\n",
      "New Best Accuracy found: 48.39%\n",
      "Epoch: 104\n",
      "New Best Accuracy found: 51.88%\n",
      "Epoch: 105\n",
      "New Best Accuracy found: 52.96%\n",
      "Epoch: 106\n",
      "New Best Accuracy found: 55.51%\n",
      "Epoch: 107\n",
      "New Best Accuracy found: 55.78%\n",
      "Epoch: 108\n",
      "New Best Accuracy found: 56.85%\n",
      "Epoch: 109\n",
      "Epoch:110/200 AVG Training Loss:0.659 AVG Validation Loss:0.690 AVG Training Acc 60.81 % AVG Validation Acc 56.99 %\n",
      "New Best Accuracy found: 56.99%\n",
      "Epoch: 110\n",
      "New Best Accuracy found: 57.26%\n",
      "Epoch: 111\n",
      "New Best Accuracy found: 57.53%\n",
      "Epoch: 112\n",
      "New Best Accuracy found: 57.80%\n",
      "Epoch: 113\n",
      "New Best Accuracy found: 58.33%\n",
      "Epoch: 114\n",
      "New Best Accuracy found: 58.87%\n",
      "Epoch: 115\n",
      "New Best Accuracy found: 59.68%\n",
      "Epoch: 116\n",
      "New Best Accuracy found: 60.08%\n",
      "Epoch: 118\n",
      "Epoch:120/200 AVG Training Loss:0.658 AVG Validation Loss:0.672 AVG Training Acc 60.98 % AVG Validation Acc 60.35 %\n",
      "New Best Accuracy found: 60.35%\n",
      "Epoch: 120\n",
      "New Best Accuracy found: 60.75%\n",
      "Epoch: 123\n",
      "New Best Accuracy found: 61.16%\n",
      "Epoch: 126\n",
      "Epoch:130/200 AVG Training Loss:0.657 AVG Validation Loss:0.666 AVG Training Acc 61.47 % AVG Validation Acc 60.35 %\n",
      "New Best Accuracy found: 61.29%\n",
      "Epoch: 135\n",
      "Epoch:140/200 AVG Training Loss:0.654 AVG Validation Loss:0.666 AVG Training Acc 61.90 % AVG Validation Acc 61.29 %\n",
      "Epoch:150/200 AVG Training Loss:0.652 AVG Validation Loss:0.666 AVG Training Acc 62.16 % AVG Validation Acc 60.08 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:160/200 AVG Training Loss:0.648 AVG Validation Loss:0.662 AVG Training Acc 62.39 % AVG Validation Acc 60.89 %\n",
      "Epoch:170/200 AVG Training Loss:0.651 AVG Validation Loss:0.660 AVG Training Acc 62.26 % AVG Validation Acc 60.89 %\n",
      "New Best Accuracy found: 61.42%\n",
      "Epoch: 177\n",
      "Epoch:180/200 AVG Training Loss:0.651 AVG Validation Loss:0.657 AVG Training Acc 62.37 % AVG Validation Acc 61.16 %\n",
      "New Best Accuracy found: 61.83%\n",
      "Epoch: 186\n",
      "New Best Accuracy found: 62.10%\n",
      "Epoch: 188\n",
      "Epoch:190/200 AVG Training Loss:0.651 AVG Validation Loss:0.655 AVG Training Acc 61.75 % AVG Validation Acc 61.83 %\n",
      "Epoch:200/200 AVG Training Loss:0.648 AVG Validation Loss:0.652 AVG Training Acc 62.88 % AVG Validation Acc 61.83 %\n",
      "Split 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbf18d3fee704b9a9834410c10bae48c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.547 AVG Validation Loss:4.701 AVG Training Acc 78.32 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.631 AVG Validation Loss:1.753 AVG Training Acc 68.33 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.622 AVG Validation Loss:2.936 AVG Training Acc 78.31 % AVG Validation Acc 20.16 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.694 AVG Validation Loss:0.759 AVG Training Acc 50.86 % AVG Validation Acc 25.54 %\n",
      "Epoch:50/200 AVG Training Loss:0.684 AVG Validation Loss:0.764 AVG Training Acc 55.32 % AVG Validation Acc 27.96 %\n",
      "Epoch:60/200 AVG Training Loss:0.674 AVG Validation Loss:0.765 AVG Training Acc 58.90 % AVG Validation Acc 38.04 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.668 AVG Validation Loss:0.715 AVG Training Acc 59.19 % AVG Validation Acc 51.34 %\n",
      "Epoch:80/200 AVG Training Loss:0.664 AVG Validation Loss:0.686 AVG Training Acc 60.24 % AVG Validation Acc 58.06 %\n",
      "Epoch:90/200 AVG Training Loss:0.663 AVG Validation Loss:0.678 AVG Training Acc 60.85 % AVG Validation Acc 58.87 %\n",
      "Epoch:100/200 AVG Training Loss:0.662 AVG Validation Loss:0.675 AVG Training Acc 61.57 % AVG Validation Acc 58.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.661 AVG Validation Loss:0.674 AVG Training Acc 61.55 % AVG Validation Acc 58.74 %\n",
      "Epoch:120/200 AVG Training Loss:0.660 AVG Validation Loss:0.674 AVG Training Acc 61.61 % AVG Validation Acc 58.87 %\n",
      "Epoch:130/200 AVG Training Loss:0.658 AVG Validation Loss:0.674 AVG Training Acc 61.61 % AVG Validation Acc 58.60 %\n",
      "Epoch:140/200 AVG Training Loss:0.660 AVG Validation Loss:0.674 AVG Training Acc 61.74 % AVG Validation Acc 58.60 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.656 AVG Validation Loss:0.673 AVG Training Acc 61.71 % AVG Validation Acc 58.60 %\n",
      "Epoch:160/200 AVG Training Loss:0.656 AVG Validation Loss:0.672 AVG Training Acc 61.93 % AVG Validation Acc 58.60 %\n",
      "Epoch:170/200 AVG Training Loss:0.659 AVG Validation Loss:0.671 AVG Training Acc 61.46 % AVG Validation Acc 58.74 %\n",
      "Epoch:180/200 AVG Training Loss:0.657 AVG Validation Loss:0.670 AVG Training Acc 62.11 % AVG Validation Acc 58.87 %\n",
      "Epoch:190/200 AVG Training Loss:0.657 AVG Validation Loss:0.669 AVG Training Acc 61.57 % AVG Validation Acc 58.60 %\n",
      "Epoch:200/200 AVG Training Loss:0.658 AVG Validation Loss:0.669 AVG Training Acc 61.84 % AVG Validation Acc 58.87 %\n",
      "Split 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6344fcf0ccd944ce93c697f4cbcae4ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.558 AVG Validation Loss:3.272 AVG Training Acc 80.70 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.570 AVG Validation Loss:3.045 AVG Training Acc 74.70 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.556 AVG Validation Loss:6.364 AVG Training Acc 78.53 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.659 AVG Validation Loss:1.482 AVG Training Acc 64.26 % AVG Validation Acc 20.43 %\n",
      "Epoch:50/200 AVG Training Loss:0.649 AVG Validation Loss:1.587 AVG Training Acc 65.67 % AVG Validation Acc 20.43 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.689 AVG Validation Loss:0.757 AVG Training Acc 54.71 % AVG Validation Acc 22.58 %\n",
      "Epoch:70/200 AVG Training Loss:0.681 AVG Validation Loss:0.765 AVG Training Acc 56.90 % AVG Validation Acc 29.03 %\n",
      "Epoch:80/200 AVG Training Loss:0.675 AVG Validation Loss:0.766 AVG Training Acc 58.06 % AVG Validation Acc 39.52 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.672 AVG Validation Loss:0.721 AVG Training Acc 58.14 % AVG Validation Acc 51.48 %\n",
      "Epoch:100/200 AVG Training Loss:0.669 AVG Validation Loss:0.693 AVG Training Acc 59.55 % AVG Validation Acc 57.12 %\n",
      "Epoch:110/200 AVG Training Loss:0.667 AVG Validation Loss:0.684 AVG Training Acc 59.69 % AVG Validation Acc 59.27 %\n",
      "Epoch:120/200 AVG Training Loss:0.668 AVG Validation Loss:0.681 AVG Training Acc 59.72 % AVG Validation Acc 59.81 %\n",
      "Epoch:130/200 AVG Training Loss:0.667 AVG Validation Loss:0.680 AVG Training Acc 59.93 % AVG Validation Acc 60.08 %\n",
      "Epoch:140/200 AVG Training Loss:0.666 AVG Validation Loss:0.679 AVG Training Acc 60.12 % AVG Validation Acc 60.22 %\n",
      "Epoch:150/200 AVG Training Loss:0.666 AVG Validation Loss:0.678 AVG Training Acc 60.13 % AVG Validation Acc 60.62 %\n",
      "Epoch:160/200 AVG Training Loss:0.667 AVG Validation Loss:0.678 AVG Training Acc 59.75 % AVG Validation Acc 59.95 %\n",
      "Epoch:170/200 AVG Training Loss:0.664 AVG Validation Loss:0.678 AVG Training Acc 60.33 % AVG Validation Acc 60.35 %\n",
      "Epoch:180/200 AVG Training Loss:0.666 AVG Validation Loss:0.677 AVG Training Acc 60.02 % AVG Validation Acc 60.48 %\n",
      "Epoch:190/200 AVG Training Loss:0.665 AVG Validation Loss:0.677 AVG Training Acc 60.42 % AVG Validation Acc 60.22 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:200/200 AVG Training Loss:0.664 AVG Validation Loss:0.676 AVG Training Acc 60.07 % AVG Validation Acc 60.35 %\n",
      "Split 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a80778d421146d889d445bfdd893f3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.508 AVG Validation Loss:5.314 AVG Training Acc 81.48 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.631 AVG Validation Loss:1.810 AVG Training Acc 68.46 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.546 AVG Validation Loss:12.762 AVG Training Acc 69.09 % AVG Validation Acc 20.16 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.698 AVG Validation Loss:0.782 AVG Training Acc 50.55 % AVG Validation Acc 22.72 %\n",
      "Epoch:50/200 AVG Training Loss:0.681 AVG Validation Loss:0.782 AVG Training Acc 57.30 % AVG Validation Acc 25.54 %\n",
      "Epoch:60/200 AVG Training Loss:0.677 AVG Validation Loss:0.789 AVG Training Acc 57.83 % AVG Validation Acc 28.36 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.673 AVG Validation Loss:0.748 AVG Training Acc 57.16 % AVG Validation Acc 38.44 %\n",
      "Epoch:80/200 AVG Training Loss:0.665 AVG Validation Loss:0.709 AVG Training Acc 59.73 % AVG Validation Acc 47.18 %\n",
      "Epoch:90/200 AVG Training Loss:0.663 AVG Validation Loss:0.700 AVG Training Acc 59.43 % AVG Validation Acc 49.60 %\n",
      "Epoch:100/200 AVG Training Loss:0.664 AVG Validation Loss:0.698 AVG Training Acc 60.21 % AVG Validation Acc 50.00 %\n",
      "Epoch:110/200 AVG Training Loss:0.662 AVG Validation Loss:0.697 AVG Training Acc 59.64 % AVG Validation Acc 50.67 %\n",
      "Epoch:120/200 AVG Training Loss:0.661 AVG Validation Loss:0.697 AVG Training Acc 59.69 % AVG Validation Acc 50.27 %\n",
      "Epoch:130/200 AVG Training Loss:0.660 AVG Validation Loss:0.697 AVG Training Acc 60.22 % AVG Validation Acc 50.13 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:140/200 AVG Training Loss:0.658 AVG Validation Loss:0.695 AVG Training Acc 60.24 % AVG Validation Acc 51.21 %\n",
      "Epoch:150/200 AVG Training Loss:0.656 AVG Validation Loss:0.694 AVG Training Acc 60.30 % AVG Validation Acc 50.94 %\n",
      "Epoch:160/200 AVG Training Loss:0.657 AVG Validation Loss:0.693 AVG Training Acc 60.64 % AVG Validation Acc 52.02 %\n",
      "Epoch:170/200 AVG Training Loss:0.657 AVG Validation Loss:0.691 AVG Training Acc 60.40 % AVG Validation Acc 51.88 %\n",
      "Epoch:180/200 AVG Training Loss:0.658 AVG Validation Loss:0.691 AVG Training Acc 60.77 % AVG Validation Acc 52.28 %\n",
      "Epoch:190/200 AVG Training Loss:0.659 AVG Validation Loss:0.691 AVG Training Acc 60.25 % AVG Validation Acc 52.42 %\n",
      "Epoch:200/200 AVG Training Loss:0.658 AVG Validation Loss:0.690 AVG Training Acc 60.62 % AVG Validation Acc 52.55 %\n",
      "Split 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc281f641b084c57a0d7c5feca70e3c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.430 AVG Validation Loss:6.441 AVG Training Acc 84.06 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.517 AVG Validation Loss:4.429 AVG Training Acc 77.63 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.497 AVG Validation Loss:10.092 AVG Training Acc 79.41 % AVG Validation Acc 20.16 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.707 AVG Validation Loss:0.810 AVG Training Acc 51.23 % AVG Validation Acc 21.51 %\n",
      "Epoch:50/200 AVG Training Loss:0.681 AVG Validation Loss:0.877 AVG Training Acc 56.93 % AVG Validation Acc 26.21 %\n",
      "Epoch:60/200 AVG Training Loss:0.677 AVG Validation Loss:0.857 AVG Training Acc 58.10 % AVG Validation Acc 37.10 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.677 AVG Validation Loss:0.767 AVG Training Acc 57.73 % AVG Validation Acc 47.72 %\n",
      "Epoch:80/200 AVG Training Loss:0.664 AVG Validation Loss:0.708 AVG Training Acc 61.12 % AVG Validation Acc 56.99 %\n",
      "Epoch:90/200 AVG Training Loss:0.661 AVG Validation Loss:0.696 AVG Training Acc 61.34 % AVG Validation Acc 58.33 %\n",
      "Epoch:100/200 AVG Training Loss:0.661 AVG Validation Loss:0.696 AVG Training Acc 61.69 % AVG Validation Acc 58.06 %\n",
      "Epoch:110/200 AVG Training Loss:0.662 AVG Validation Loss:0.694 AVG Training Acc 61.21 % AVG Validation Acc 57.39 %\n",
      "Epoch:120/200 AVG Training Loss:0.658 AVG Validation Loss:0.695 AVG Training Acc 61.33 % AVG Validation Acc 57.53 %\n",
      "Epoch:130/200 AVG Training Loss:0.660 AVG Validation Loss:0.694 AVG Training Acc 61.86 % AVG Validation Acc 57.66 %\n",
      "Epoch   132: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:140/200 AVG Training Loss:0.656 AVG Validation Loss:0.693 AVG Training Acc 61.87 % AVG Validation Acc 58.06 %\n",
      "Epoch:150/200 AVG Training Loss:0.654 AVG Validation Loss:0.690 AVG Training Acc 62.39 % AVG Validation Acc 58.33 %\n",
      "Epoch:160/200 AVG Training Loss:0.656 AVG Validation Loss:0.687 AVG Training Acc 62.52 % AVG Validation Acc 58.47 %\n",
      "Epoch:170/200 AVG Training Loss:0.657 AVG Validation Loss:0.687 AVG Training Acc 61.62 % AVG Validation Acc 58.47 %\n",
      "Epoch:180/200 AVG Training Loss:0.656 AVG Validation Loss:0.685 AVG Training Acc 61.75 % AVG Validation Acc 58.47 %\n",
      "Epoch:190/200 AVG Training Loss:0.655 AVG Validation Loss:0.684 AVG Training Acc 62.21 % AVG Validation Acc 58.74 %\n",
      "Epoch:200/200 AVG Training Loss:0.653 AVG Validation Loss:0.684 AVG Training Acc 62.16 % AVG Validation Acc 58.33 %\n",
      "Split 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c53d6b9f2401421689dd5d2f7c479194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.571 AVG Validation Loss:2.994 AVG Training Acc 77.01 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.641 AVG Validation Loss:1.679 AVG Training Acc 67.02 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.604 AVG Validation Loss:2.239 AVG Training Acc 72.47 % AVG Validation Acc 20.16 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.685 AVG Validation Loss:0.933 AVG Training Acc 57.51 % AVG Validation Acc 20.43 %\n",
      "Epoch:50/200 AVG Training Loss:0.673 AVG Validation Loss:0.917 AVG Training Acc 59.33 % AVG Validation Acc 20.97 %\n",
      "Epoch:60/200 AVG Training Loss:0.665 AVG Validation Loss:0.919 AVG Training Acc 60.93 % AVG Validation Acc 20.83 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.678 AVG Validation Loss:0.775 AVG Training Acc 57.06 % AVG Validation Acc 36.56 %\n",
      "Epoch:80/200 AVG Training Loss:0.657 AVG Validation Loss:0.699 AVG Training Acc 61.25 % AVG Validation Acc 53.76 %\n",
      "Epoch:90/200 AVG Training Loss:0.656 AVG Validation Loss:0.692 AVG Training Acc 61.48 % AVG Validation Acc 54.44 %\n",
      "Epoch:100/200 AVG Training Loss:0.652 AVG Validation Loss:0.691 AVG Training Acc 61.25 % AVG Validation Acc 53.90 %\n",
      "Epoch:110/200 AVG Training Loss:0.653 AVG Validation Loss:0.691 AVG Training Acc 62.12 % AVG Validation Acc 53.36 %\n",
      "Epoch:120/200 AVG Training Loss:0.652 AVG Validation Loss:0.689 AVG Training Acc 61.96 % AVG Validation Acc 53.49 %\n",
      "Epoch:130/200 AVG Training Loss:0.647 AVG Validation Loss:0.689 AVG Training Acc 62.32 % AVG Validation Acc 53.36 %\n",
      "Epoch   135: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:140/200 AVG Training Loss:0.647 AVG Validation Loss:0.686 AVG Training Acc 62.61 % AVG Validation Acc 53.76 %\n",
      "Epoch:150/200 AVG Training Loss:0.646 AVG Validation Loss:0.680 AVG Training Acc 62.64 % AVG Validation Acc 54.70 %\n",
      "Epoch:160/200 AVG Training Loss:0.645 AVG Validation Loss:0.676 AVG Training Acc 62.92 % AVG Validation Acc 55.24 %\n",
      "Epoch:170/200 AVG Training Loss:0.645 AVG Validation Loss:0.673 AVG Training Acc 62.56 % AVG Validation Acc 55.38 %\n",
      "Epoch:180/200 AVG Training Loss:0.644 AVG Validation Loss:0.672 AVG Training Acc 62.73 % AVG Validation Acc 55.38 %\n",
      "Epoch:190/200 AVG Training Loss:0.644 AVG Validation Loss:0.671 AVG Training Acc 62.90 % AVG Validation Acc 55.51 %\n",
      "Epoch:200/200 AVG Training Loss:0.644 AVG Validation Loss:0.670 AVG Training Acc 62.68 % AVG Validation Acc 55.78 %\n",
      "Split 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f8cbf495953456fb94a5af7756e41dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.471 AVG Validation Loss:4.614 AVG Training Acc 80.36 % AVG Validation Acc 20.19 %\n",
      "Epoch:20/200 AVG Training Loss:0.520 AVG Validation Loss:4.074 AVG Training Acc 81.68 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.535 AVG Validation Loss:6.961 AVG Training Acc 78.62 % AVG Validation Acc 20.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.548 AVG Validation Loss:4.741 AVG Training Acc 77.10 % AVG Validation Acc 20.19 %\n",
      "Epoch:50/200 AVG Training Loss:0.552 AVG Validation Loss:3.604 AVG Training Acc 79.57 % AVG Validation Acc 20.05 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.701 AVG Validation Loss:0.866 AVG Training Acc 52.12 % AVG Validation Acc 20.32 %\n",
      "Epoch:70/200 AVG Training Loss:0.693 AVG Validation Loss:0.889 AVG Training Acc 54.59 % AVG Validation Acc 21.00 %\n",
      "Epoch:80/200 AVG Training Loss:0.684 AVG Validation Loss:0.861 AVG Training Acc 56.36 % AVG Validation Acc 24.09 %\n",
      "Epoch:90/200 AVG Training Loss:0.677 AVG Validation Loss:0.867 AVG Training Acc 58.00 % AVG Validation Acc 25.30 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.701 AVG Validation Loss:0.838 AVG Training Acc 53.94 % AVG Validation Acc 28.94 %\n",
      "Epoch:110/200 AVG Training Loss:0.668 AVG Validation Loss:0.720 AVG Training Acc 60.11 % AVG Validation Acc 51.68 %\n",
      "Epoch:120/200 AVG Training Loss:0.665 AVG Validation Loss:0.698 AVG Training Acc 60.07 % AVG Validation Acc 54.51 %\n",
      "Epoch:130/200 AVG Training Loss:0.663 AVG Validation Loss:0.697 AVG Training Acc 60.81 % AVG Validation Acc 54.37 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:140/200 AVG Training Loss:0.662 AVG Validation Loss:0.694 AVG Training Acc 60.76 % AVG Validation Acc 54.24 %\n",
      "Epoch:150/200 AVG Training Loss:0.662 AVG Validation Loss:0.691 AVG Training Acc 60.65 % AVG Validation Acc 54.91 %\n",
      "Epoch:160/200 AVG Training Loss:0.661 AVG Validation Loss:0.692 AVG Training Acc 60.98 % AVG Validation Acc 55.85 %\n",
      "Epoch:170/200 AVG Training Loss:0.662 AVG Validation Loss:0.684 AVG Training Acc 61.36 % AVG Validation Acc 55.72 %\n",
      "Epoch:180/200 AVG Training Loss:0.661 AVG Validation Loss:0.686 AVG Training Acc 61.07 % AVG Validation Acc 55.85 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:190/200 AVG Training Loss:0.658 AVG Validation Loss:0.684 AVG Training Acc 61.50 % AVG Validation Acc 55.59 %\n",
      "Epoch:200/200 AVG Training Loss:0.660 AVG Validation Loss:0.683 AVG Training Acc 60.92 % AVG Validation Acc 56.53 %\n",
      "Split 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8732035ed13e4cf1a6f577ea2997317a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.546 AVG Validation Loss:3.184 AVG Training Acc 79.61 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:1.638 AVG Training Acc 66.13 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.655 AVG Validation Loss:2.991 AVG Training Acc 70.25 % AVG Validation Acc 20.05 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.731 AVG Validation Loss:0.851 AVG Training Acc 49.95 % AVG Validation Acc 20.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.677 AVG Validation Loss:0.764 AVG Training Acc 57.81 % AVG Validation Acc 36.20 %\n",
      "Epoch:60/200 AVG Training Loss:0.673 AVG Validation Loss:0.758 AVG Training Acc 59.10 % AVG Validation Acc 39.97 %\n",
      "Epoch:70/200 AVG Training Loss:0.670 AVG Validation Loss:0.756 AVG Training Acc 59.56 % AVG Validation Acc 41.86 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.673 AVG Validation Loss:0.746 AVG Training Acc 57.75 % AVG Validation Acc 45.90 %\n",
      "Epoch:90/200 AVG Training Loss:0.662 AVG Validation Loss:0.692 AVG Training Acc 60.66 % AVG Validation Acc 59.22 %\n",
      "Epoch:100/200 AVG Training Loss:0.660 AVG Validation Loss:0.675 AVG Training Acc 61.04 % AVG Validation Acc 61.37 %\n",
      "Epoch:110/200 AVG Training Loss:0.660 AVG Validation Loss:0.670 AVG Training Acc 61.04 % AVG Validation Acc 61.91 %\n",
      "New Best Accuracy found: 62.18%\n",
      "Epoch: 114\n",
      "New Best Accuracy found: 62.31%\n",
      "Epoch: 117\n",
      "Epoch:120/200 AVG Training Loss:0.658 AVG Validation Loss:0.668 AVG Training Acc 61.02 % AVG Validation Acc 61.91 %\n",
      "Epoch:130/200 AVG Training Loss:0.658 AVG Validation Loss:0.667 AVG Training Acc 61.38 % AVG Validation Acc 62.58 %\n",
      "New Best Accuracy found: 62.58%\n",
      "Epoch: 130\n",
      "Epoch:140/200 AVG Training Loss:0.658 AVG Validation Loss:0.667 AVG Training Acc 61.39 % AVG Validation Acc 62.18 %\n",
      "Epoch:150/200 AVG Training Loss:0.659 AVG Validation Loss:0.666 AVG Training Acc 61.27 % AVG Validation Acc 62.45 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:160/200 AVG Training Loss:0.659 AVG Validation Loss:0.666 AVG Training Acc 61.21 % AVG Validation Acc 62.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.657 AVG Validation Loss:0.665 AVG Training Acc 61.38 % AVG Validation Acc 62.45 %\n",
      "New Best Accuracy found: 62.72%\n",
      "Epoch: 174\n",
      "Epoch:180/200 AVG Training Loss:0.657 AVG Validation Loss:0.664 AVG Training Acc 61.31 % AVG Validation Acc 62.45 %\n",
      "Epoch:190/200 AVG Training Loss:0.659 AVG Validation Loss:0.663 AVG Training Acc 61.41 % AVG Validation Acc 62.58 %\n",
      "New Best Accuracy found: 62.85%\n",
      "Epoch: 196\n",
      "Epoch:200/200 AVG Training Loss:0.659 AVG Validation Loss:0.663 AVG Training Acc 61.53 % AVG Validation Acc 62.58 %\n",
      "Split 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39dec825db134d75b21cc24717df16c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.544 AVG Validation Loss:8.257 AVG Training Acc 78.16 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.593 AVG Validation Loss:2.260 AVG Training Acc 74.15 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.535 AVG Validation Loss:7.991 AVG Training Acc 80.34 % AVG Validation Acc 20.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.531 AVG Validation Loss:5.921 AVG Training Acc 79.58 % AVG Validation Acc 20.05 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.699 AVG Validation Loss:0.843 AVG Training Acc 52.65 % AVG Validation Acc 22.88 %\n",
      "Epoch:60/200 AVG Training Loss:0.684 AVG Validation Loss:0.798 AVG Training Acc 55.82 % AVG Validation Acc 27.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.680 AVG Validation Loss:0.788 AVG Training Acc 56.55 % AVG Validation Acc 29.07 %\n",
      "Epoch:80/200 AVG Training Loss:0.678 AVG Validation Loss:0.784 AVG Training Acc 57.61 % AVG Validation Acc 33.78 %\n",
      "Epoch:90/200 AVG Training Loss:0.669 AVG Validation Loss:0.788 AVG Training Acc 59.64 % AVG Validation Acc 36.20 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.664 AVG Validation Loss:0.700 AVG Training Acc 60.47 % AVG Validation Acc 58.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.662 AVG Validation Loss:0.675 AVG Training Acc 60.80 % AVG Validation Acc 61.64 %\n",
      "Epoch:120/200 AVG Training Loss:0.659 AVG Validation Loss:0.671 AVG Training Acc 61.06 % AVG Validation Acc 61.37 %\n",
      "Epoch:130/200 AVG Training Loss:0.659 AVG Validation Loss:0.669 AVG Training Acc 60.94 % AVG Validation Acc 61.51 %\n",
      "Epoch:140/200 AVG Training Loss:0.659 AVG Validation Loss:0.668 AVG Training Acc 61.38 % AVG Validation Acc 61.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.658 AVG Validation Loss:0.667 AVG Training Acc 61.01 % AVG Validation Acc 61.24 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:160/200 AVG Training Loss:0.658 AVG Validation Loss:0.666 AVG Training Acc 61.00 % AVG Validation Acc 61.91 %\n",
      "Epoch:170/200 AVG Training Loss:0.658 AVG Validation Loss:0.665 AVG Training Acc 61.07 % AVG Validation Acc 62.05 %\n",
      "Epoch:180/200 AVG Training Loss:0.655 AVG Validation Loss:0.663 AVG Training Acc 61.64 % AVG Validation Acc 61.37 %\n",
      "Epoch:190/200 AVG Training Loss:0.657 AVG Validation Loss:0.662 AVG Training Acc 60.96 % AVG Validation Acc 62.18 %\n",
      "Epoch:200/200 AVG Training Loss:0.657 AVG Validation Loss:0.661 AVG Training Acc 61.59 % AVG Validation Acc 62.31 %\n",
      "Split 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c03f821c464ac0b1dac43b101e21b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.557 AVG Validation Loss:2.895 AVG Training Acc 77.52 % AVG Validation Acc 20.19 %\n",
      "Epoch:20/200 AVG Training Loss:0.417 AVG Validation Loss:7.181 AVG Training Acc 83.44 % AVG Validation Acc 20.19 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.707 AVG Validation Loss:1.329 AVG Training Acc 58.93 % AVG Validation Acc 20.32 %\n",
      "Epoch:40/200 AVG Training Loss:0.672 AVG Validation Loss:1.037 AVG Training Acc 62.03 % AVG Validation Acc 20.19 %\n",
      "Epoch:50/200 AVG Training Loss:0.671 AVG Validation Loss:0.949 AVG Training Acc 61.72 % AVG Validation Acc 20.59 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.691 AVG Validation Loss:0.759 AVG Training Acc 54.84 % AVG Validation Acc 38.09 %\n",
      "Epoch:70/200 AVG Training Loss:0.678 AVG Validation Loss:0.714 AVG Training Acc 57.79 % AVG Validation Acc 45.49 %\n",
      "Epoch:80/200 AVG Training Loss:0.675 AVG Validation Loss:0.703 AVG Training Acc 58.11 % AVG Validation Acc 49.13 %\n",
      "Epoch:90/200 AVG Training Loss:0.675 AVG Validation Loss:0.703 AVG Training Acc 58.69 % AVG Validation Acc 47.64 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.672 AVG Validation Loss:0.696 AVG Training Acc 58.72 % AVG Validation Acc 50.20 %\n",
      "Epoch:110/200 AVG Training Loss:0.670 AVG Validation Loss:0.688 AVG Training Acc 59.00 % AVG Validation Acc 51.82 %\n",
      "Epoch:120/200 AVG Training Loss:0.671 AVG Validation Loss:0.683 AVG Training Acc 59.03 % AVG Validation Acc 53.16 %\n",
      "Epoch:130/200 AVG Training Loss:0.673 AVG Validation Loss:0.677 AVG Training Acc 58.92 % AVG Validation Acc 54.91 %\n",
      "Epoch:140/200 AVG Training Loss:0.670 AVG Validation Loss:0.675 AVG Training Acc 58.68 % AVG Validation Acc 55.59 %\n",
      "Epoch:150/200 AVG Training Loss:0.670 AVG Validation Loss:0.674 AVG Training Acc 59.11 % AVG Validation Acc 56.12 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.670 AVG Validation Loss:0.672 AVG Training Acc 59.23 % AVG Validation Acc 56.80 %\n",
      "Epoch:170/200 AVG Training Loss:0.670 AVG Validation Loss:0.674 AVG Training Acc 59.27 % AVG Validation Acc 56.66 %\n",
      "Epoch:180/200 AVG Training Loss:0.668 AVG Validation Loss:0.674 AVG Training Acc 59.75 % AVG Validation Acc 55.45 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.670 AVG Validation Loss:0.673 AVG Training Acc 59.16 % AVG Validation Acc 55.85 %\n",
      "Epoch:200/200 AVG Training Loss:0.671 AVG Validation Loss:0.671 AVG Training Acc 59.26 % AVG Validation Acc 56.39 %\n",
      "Split 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc80a501e879495aa3bb98787b5dd1de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.560 AVG Validation Loss:5.751 AVG Training Acc 76.22 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.622 AVG Validation Loss:1.996 AVG Training Acc 72.13 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.638 AVG Validation Loss:2.676 AVG Training Acc 66.11 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.636 AVG Validation Loss:1.644 AVG Training Acc 66.99 % AVG Validation Acc 20.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.644 AVG Validation Loss:2.813 AVG Training Acc 72.39 % AVG Validation Acc 20.16 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.684 AVG Validation Loss:0.785 AVG Training Acc 54.90 % AVG Validation Acc 32.26 %\n",
      "Epoch:70/200 AVG Training Loss:0.668 AVG Validation Loss:0.782 AVG Training Acc 60.39 % AVG Validation Acc 47.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.669 AVG Validation Loss:0.765 AVG Training Acc 60.67 % AVG Validation Acc 49.46 %\n",
      "Epoch:90/200 AVG Training Loss:0.662 AVG Validation Loss:0.766 AVG Training Acc 60.87 % AVG Validation Acc 49.73 %\n",
      "Epoch:100/200 AVG Training Loss:0.662 AVG Validation Loss:0.755 AVG Training Acc 61.27 % AVG Validation Acc 48.52 %\n",
      "Epoch:110/200 AVG Training Loss:0.658 AVG Validation Loss:0.755 AVG Training Acc 61.67 % AVG Validation Acc 46.77 %\n",
      "Epoch:120/200 AVG Training Loss:0.655 AVG Validation Loss:0.753 AVG Training Acc 62.00 % AVG Validation Acc 46.37 %\n",
      "Epoch:130/200 AVG Training Loss:0.647 AVG Validation Loss:0.751 AVG Training Acc 62.59 % AVG Validation Acc 46.51 %\n",
      "Epoch   132: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:140/200 AVG Training Loss:0.644 AVG Validation Loss:0.698 AVG Training Acc 63.31 % AVG Validation Acc 53.49 %\n",
      "Epoch:150/200 AVG Training Loss:0.640 AVG Validation Loss:0.676 AVG Training Acc 63.32 % AVG Validation Acc 54.70 %\n",
      "Epoch:160/200 AVG Training Loss:0.641 AVG Validation Loss:0.670 AVG Training Acc 63.39 % AVG Validation Acc 55.65 %\n",
      "Epoch:170/200 AVG Training Loss:0.638 AVG Validation Loss:0.668 AVG Training Acc 63.82 % AVG Validation Acc 55.78 %\n",
      "Epoch:180/200 AVG Training Loss:0.636 AVG Validation Loss:0.668 AVG Training Acc 64.00 % AVG Validation Acc 55.65 %\n",
      "Epoch:190/200 AVG Training Loss:0.635 AVG Validation Loss:0.667 AVG Training Acc 63.88 % AVG Validation Acc 55.78 %\n",
      "Epoch:200/200 AVG Training Loss:0.634 AVG Validation Loss:0.668 AVG Training Acc 64.13 % AVG Validation Acc 55.78 %\n",
      "Split 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f08d8042081c4d12833de7e93f8c667e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.500 AVG Validation Loss:6.197 AVG Training Acc 82.93 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.518 AVG Validation Loss:5.039 AVG Training Acc 76.06 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.626 AVG Validation Loss:1.814 AVG Training Acc 70.24 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.543 AVG Validation Loss:3.871 AVG Training Acc 77.69 % AVG Validation Acc 20.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.607 AVG Validation Loss:6.042 AVG Training Acc 76.35 % AVG Validation Acc 20.16 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.748 AVG Validation Loss:1.002 AVG Training Acc 51.90 % AVG Validation Acc 22.04 %\n",
      "Epoch:70/200 AVG Training Loss:0.684 AVG Validation Loss:0.931 AVG Training Acc 55.27 % AVG Validation Acc 21.91 %\n",
      "Epoch:80/200 AVG Training Loss:0.685 AVG Validation Loss:0.878 AVG Training Acc 56.43 % AVG Validation Acc 24.73 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.719 AVG Validation Loss:0.854 AVG Training Acc 53.43 % AVG Validation Acc 28.36 %\n",
      "Epoch:100/200 AVG Training Loss:0.672 AVG Validation Loss:0.701 AVG Training Acc 57.59 % AVG Validation Acc 44.76 %\n",
      "Epoch:110/200 AVG Training Loss:0.668 AVG Validation Loss:0.689 AVG Training Acc 58.69 % AVG Validation Acc 48.66 %\n",
      "Epoch:120/200 AVG Training Loss:0.665 AVG Validation Loss:0.687 AVG Training Acc 58.84 % AVG Validation Acc 48.52 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.665 AVG Validation Loss:0.686 AVG Training Acc 58.52 % AVG Validation Acc 50.00 %\n",
      "Epoch:140/200 AVG Training Loss:0.663 AVG Validation Loss:0.679 AVG Training Acc 59.06 % AVG Validation Acc 51.34 %\n",
      "Epoch:150/200 AVG Training Loss:0.663 AVG Validation Loss:0.676 AVG Training Acc 59.26 % AVG Validation Acc 51.88 %\n",
      "Epoch:160/200 AVG Training Loss:0.662 AVG Validation Loss:0.673 AVG Training Acc 59.49 % AVG Validation Acc 52.28 %\n",
      "Epoch:170/200 AVG Training Loss:0.664 AVG Validation Loss:0.673 AVG Training Acc 59.10 % AVG Validation Acc 52.82 %\n",
      "Epoch:180/200 AVG Training Loss:0.661 AVG Validation Loss:0.673 AVG Training Acc 59.67 % AVG Validation Acc 52.42 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:190/200 AVG Training Loss:0.663 AVG Validation Loss:0.670 AVG Training Acc 59.34 % AVG Validation Acc 53.76 %\n",
      "Epoch:200/200 AVG Training Loss:0.662 AVG Validation Loss:0.672 AVG Training Acc 59.21 % AVG Validation Acc 53.36 %\n",
      "Split 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cf7e7eeaa284e46884e9108669a6888",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.556 AVG Validation Loss:4.295 AVG Training Acc 77.98 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.534 AVG Validation Loss:9.608 AVG Training Acc 80.51 % AVG Validation Acc 20.16 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.719 AVG Validation Loss:0.827 AVG Training Acc 50.35 % AVG Validation Acc 20.30 %\n",
      "Epoch:40/200 AVG Training Loss:0.665 AVG Validation Loss:0.969 AVG Training Acc 61.15 % AVG Validation Acc 22.31 %\n",
      "Epoch:50/200 AVG Training Loss:0.665 AVG Validation Loss:0.934 AVG Training Acc 61.40 % AVG Validation Acc 22.31 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.684 AVG Validation Loss:0.798 AVG Training Acc 56.31 % AVG Validation Acc 36.56 %\n",
      "Epoch:70/200 AVG Training Loss:0.657 AVG Validation Loss:0.703 AVG Training Acc 61.67 % AVG Validation Acc 56.59 %\n",
      "Epoch:80/200 AVG Training Loss:0.653 AVG Validation Loss:0.696 AVG Training Acc 62.15 % AVG Validation Acc 56.99 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.653 AVG Validation Loss:0.694 AVG Training Acc 62.35 % AVG Validation Acc 55.91 %\n",
      "Epoch:100/200 AVG Training Loss:0.650 AVG Validation Loss:0.686 AVG Training Acc 61.87 % AVG Validation Acc 57.80 %\n",
      "Epoch:110/200 AVG Training Loss:0.650 AVG Validation Loss:0.680 AVG Training Acc 62.16 % AVG Validation Acc 58.20 %\n",
      "Epoch:120/200 AVG Training Loss:0.649 AVG Validation Loss:0.677 AVG Training Acc 62.17 % AVG Validation Acc 58.60 %\n",
      "Epoch:130/200 AVG Training Loss:0.648 AVG Validation Loss:0.675 AVG Training Acc 62.05 % AVG Validation Acc 59.27 %\n",
      "Epoch:140/200 AVG Training Loss:0.648 AVG Validation Loss:0.674 AVG Training Acc 62.71 % AVG Validation Acc 59.81 %\n",
      "Epoch:150/200 AVG Training Loss:0.649 AVG Validation Loss:0.672 AVG Training Acc 62.11 % AVG Validation Acc 59.27 %\n",
      "Epoch:160/200 AVG Training Loss:0.649 AVG Validation Loss:0.671 AVG Training Acc 62.45 % AVG Validation Acc 59.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.650 AVG Validation Loss:0.670 AVG Training Acc 62.34 % AVG Validation Acc 59.54 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:180/200 AVG Training Loss:0.648 AVG Validation Loss:0.671 AVG Training Acc 62.71 % AVG Validation Acc 59.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.646 AVG Validation Loss:0.669 AVG Training Acc 62.42 % AVG Validation Acc 59.27 %\n",
      "Epoch:200/200 AVG Training Loss:0.649 AVG Validation Loss:0.670 AVG Training Acc 62.39 % AVG Validation Acc 59.27 %\n",
      "Split 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3c04774beb374c0e87f07dc732ffa8ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.544 AVG Validation Loss:4.187 AVG Training Acc 80.26 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.594 AVG Validation Loss:2.346 AVG Training Acc 73.02 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.593 AVG Validation Loss:2.636 AVG Training Acc 75.73 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.545 AVG Validation Loss:4.171 AVG Training Acc 81.50 % AVG Validation Acc 20.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.656 AVG Validation Loss:1.664 AVG Training Acc 64.57 % AVG Validation Acc 20.16 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:1.032 AVG Validation Loss:1.283 AVG Training Acc 50.01 % AVG Validation Acc 20.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.690 AVG Validation Loss:0.782 AVG Training Acc 54.34 % AVG Validation Acc 22.31 %\n",
      "Epoch:80/200 AVG Training Loss:0.675 AVG Validation Loss:0.792 AVG Training Acc 57.98 % AVG Validation Acc 33.20 %\n",
      "Epoch:90/200 AVG Training Loss:0.672 AVG Validation Loss:0.787 AVG Training Acc 59.73 % AVG Validation Acc 42.61 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.666 AVG Validation Loss:0.715 AVG Training Acc 60.56 % AVG Validation Acc 55.11 %\n",
      "Epoch:110/200 AVG Training Loss:0.663 AVG Validation Loss:0.694 AVG Training Acc 61.12 % AVG Validation Acc 57.66 %\n",
      "Epoch:120/200 AVG Training Loss:0.660 AVG Validation Loss:0.687 AVG Training Acc 61.67 % AVG Validation Acc 58.33 %\n",
      "Epoch:130/200 AVG Training Loss:0.658 AVG Validation Loss:0.685 AVG Training Acc 61.83 % AVG Validation Acc 58.60 %\n",
      "Epoch:140/200 AVG Training Loss:0.661 AVG Validation Loss:0.684 AVG Training Acc 61.94 % AVG Validation Acc 59.14 %\n",
      "Epoch:150/200 AVG Training Loss:0.658 AVG Validation Loss:0.683 AVG Training Acc 62.05 % AVG Validation Acc 58.87 %\n",
      "Epoch:160/200 AVG Training Loss:0.657 AVG Validation Loss:0.683 AVG Training Acc 62.04 % AVG Validation Acc 58.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.657 AVG Validation Loss:0.683 AVG Training Acc 61.93 % AVG Validation Acc 58.74 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:180/200 AVG Training Loss:0.656 AVG Validation Loss:0.682 AVG Training Acc 61.90 % AVG Validation Acc 59.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.656 AVG Validation Loss:0.681 AVG Training Acc 62.27 % AVG Validation Acc 58.87 %\n",
      "Epoch:200/200 AVG Training Loss:0.657 AVG Validation Loss:0.680 AVG Training Acc 62.02 % AVG Validation Acc 59.14 %\n",
      "Split 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c87c37904ac1430197ea5f668964d8c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.536 AVG Validation Loss:7.521 AVG Training Acc 77.69 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.645 AVG Validation Loss:1.662 AVG Training Acc 66.60 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.657 AVG Validation Loss:1.534 AVG Training Acc 64.82 % AVG Validation Acc 20.30 %\n",
      "Epoch:40/200 AVG Training Loss:0.578 AVG Validation Loss:10.919 AVG Training Acc 70.00 % AVG Validation Acc 20.16 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.700 AVG Validation Loss:0.924 AVG Training Acc 52.95 % AVG Validation Acc 20.43 %\n",
      "Epoch:60/200 AVG Training Loss:0.677 AVG Validation Loss:0.891 AVG Training Acc 57.49 % AVG Validation Acc 22.72 %\n",
      "Epoch:70/200 AVG Training Loss:0.672 AVG Validation Loss:0.873 AVG Training Acc 59.18 % AVG Validation Acc 24.06 %\n",
      "Epoch:80/200 AVG Training Loss:0.667 AVG Validation Loss:0.878 AVG Training Acc 59.51 % AVG Validation Acc 25.27 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.668 AVG Validation Loss:0.733 AVG Training Acc 58.55 % AVG Validation Acc 42.61 %\n",
      "Epoch:100/200 AVG Training Loss:0.658 AVG Validation Loss:0.690 AVG Training Acc 61.17 % AVG Validation Acc 51.48 %\n",
      "Epoch:110/200 AVG Training Loss:0.658 AVG Validation Loss:0.689 AVG Training Acc 61.67 % AVG Validation Acc 52.69 %\n",
      "Epoch:120/200 AVG Training Loss:0.658 AVG Validation Loss:0.686 AVG Training Acc 60.88 % AVG Validation Acc 52.82 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.652 AVG Validation Loss:0.686 AVG Training Acc 61.17 % AVG Validation Acc 53.49 %\n",
      "Epoch:140/200 AVG Training Loss:0.655 AVG Validation Loss:0.682 AVG Training Acc 61.49 % AVG Validation Acc 52.69 %\n",
      "Epoch:150/200 AVG Training Loss:0.655 AVG Validation Loss:0.679 AVG Training Acc 61.81 % AVG Validation Acc 54.03 %\n",
      "Epoch:160/200 AVG Training Loss:0.651 AVG Validation Loss:0.677 AVG Training Acc 62.30 % AVG Validation Acc 54.57 %\n",
      "Epoch:170/200 AVG Training Loss:0.653 AVG Validation Loss:0.676 AVG Training Acc 61.72 % AVG Validation Acc 55.38 %\n",
      "Epoch:180/200 AVG Training Loss:0.652 AVG Validation Loss:0.674 AVG Training Acc 62.09 % AVG Validation Acc 55.78 %\n",
      "Epoch:190/200 AVG Training Loss:0.654 AVG Validation Loss:0.673 AVG Training Acc 62.03 % AVG Validation Acc 55.38 %\n",
      "Epoch   197: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:200/200 AVG Training Loss:0.652 AVG Validation Loss:0.671 AVG Training Acc 61.97 % AVG Validation Acc 56.05 %\n",
      "Split 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7369bec615e4c6793e966491f456bd1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.538 AVG Validation Loss:3.724 AVG Training Acc 77.38 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.645 AVG Validation Loss:4.982 AVG Training Acc 71.65 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.658 AVG Validation Loss:2.694 AVG Training Acc 75.67 % AVG Validation Acc 20.16 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.733 AVG Validation Loss:1.205 AVG Training Acc 61.98 % AVG Validation Acc 20.30 %\n",
      "Epoch:50/200 AVG Training Loss:0.644 AVG Validation Loss:1.126 AVG Training Acc 65.68 % AVG Validation Acc 21.51 %\n",
      "Epoch:60/200 AVG Training Loss:0.670 AVG Validation Loss:0.968 AVG Training Acc 60.93 % AVG Validation Acc 21.51 %\n",
      "Epoch:70/200 AVG Training Loss:0.641 AVG Validation Loss:1.081 AVG Training Acc 65.59 % AVG Validation Acc 21.24 %\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.679 AVG Validation Loss:0.763 AVG Training Acc 56.74 % AVG Validation Acc 38.58 %\n",
      "Epoch:90/200 AVG Training Loss:0.664 AVG Validation Loss:0.694 AVG Training Acc 60.49 % AVG Validation Acc 51.88 %\n",
      "Epoch:100/200 AVG Training Loss:0.659 AVG Validation Loss:0.690 AVG Training Acc 61.38 % AVG Validation Acc 52.82 %\n",
      "Epoch:110/200 AVG Training Loss:0.661 AVG Validation Loss:0.693 AVG Training Acc 60.88 % AVG Validation Acc 52.55 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.656 AVG Validation Loss:0.685 AVG Training Acc 61.09 % AVG Validation Acc 52.82 %\n",
      "Epoch:130/200 AVG Training Loss:0.656 AVG Validation Loss:0.679 AVG Training Acc 61.18 % AVG Validation Acc 53.63 %\n",
      "Epoch:140/200 AVG Training Loss:0.654 AVG Validation Loss:0.672 AVG Training Acc 61.59 % AVG Validation Acc 54.57 %\n",
      "Epoch:150/200 AVG Training Loss:0.656 AVG Validation Loss:0.674 AVG Training Acc 61.25 % AVG Validation Acc 54.44 %\n",
      "Epoch:160/200 AVG Training Loss:0.655 AVG Validation Loss:0.672 AVG Training Acc 62.29 % AVG Validation Acc 54.30 %\n",
      "Epoch:170/200 AVG Training Loss:0.655 AVG Validation Loss:0.669 AVG Training Acc 61.76 % AVG Validation Acc 55.11 %\n",
      "Epoch:180/200 AVG Training Loss:0.654 AVG Validation Loss:0.668 AVG Training Acc 61.63 % AVG Validation Acc 54.97 %\n",
      "Epoch:190/200 AVG Training Loss:0.653 AVG Validation Loss:0.667 AVG Training Acc 62.06 % AVG Validation Acc 54.70 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:200/200 AVG Training Loss:0.654 AVG Validation Loss:0.666 AVG Training Acc 61.96 % AVG Validation Acc 55.91 %\n",
      "Split 17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "757aa19c233b4592be38ee62855f605e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.548 AVG Validation Loss:3.392 AVG Training Acc 79.84 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.637 AVG Validation Loss:1.718 AVG Training Acc 67.98 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.594 AVG Validation Loss:2.565 AVG Training Acc 75.43 % AVG Validation Acc 20.32 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.699 AVG Validation Loss:0.831 AVG Training Acc 51.56 % AVG Validation Acc 20.73 %\n",
      "Epoch:50/200 AVG Training Loss:0.693 AVG Validation Loss:0.833 AVG Training Acc 52.77 % AVG Validation Acc 21.13 %\n",
      "Epoch:60/200 AVG Training Loss:0.681 AVG Validation Loss:0.863 AVG Training Acc 57.33 % AVG Validation Acc 31.22 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.680 AVG Validation Loss:0.734 AVG Training Acc 58.14 % AVG Validation Acc 51.41 %\n",
      "Epoch:80/200 AVG Training Loss:0.670 AVG Validation Loss:0.689 AVG Training Acc 59.11 % AVG Validation Acc 60.16 %\n",
      "Epoch:90/200 AVG Training Loss:0.670 AVG Validation Loss:0.678 AVG Training Acc 58.98 % AVG Validation Acc 62.18 %\n",
      "New Best Accuracy found: 62.99%\n",
      "Epoch: 98\n",
      "New Best Accuracy found: 63.12%\n",
      "Epoch: 99\n",
      "Epoch:100/200 AVG Training Loss:0.668 AVG Validation Loss:0.675 AVG Training Acc 59.39 % AVG Validation Acc 63.12 %\n",
      "Epoch:110/200 AVG Training Loss:0.668 AVG Validation Loss:0.674 AVG Training Acc 59.53 % AVG Validation Acc 62.99 %\n",
      "New Best Accuracy found: 63.26%\n",
      "Epoch: 111\n",
      "New Best Accuracy found: 63.53%\n",
      "Epoch: 115\n",
      "New Best Accuracy found: 63.66%\n",
      "Epoch: 116\n",
      "Epoch:120/200 AVG Training Loss:0.668 AVG Validation Loss:0.673 AVG Training Acc 59.62 % AVG Validation Acc 63.39 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.666 AVG Validation Loss:0.673 AVG Training Acc 60.12 % AVG Validation Acc 63.12 %\n",
      "New Best Accuracy found: 63.80%\n",
      "Epoch: 139\n",
      "Epoch:140/200 AVG Training Loss:0.666 AVG Validation Loss:0.671 AVG Training Acc 60.78 % AVG Validation Acc 63.80 %\n",
      "New Best Accuracy found: 63.93%\n",
      "Epoch: 143\n",
      "New Best Accuracy found: 64.06%\n",
      "Epoch: 145\n",
      "New Best Accuracy found: 64.20%\n",
      "Epoch: 146\n",
      "New Best Accuracy found: 64.47%\n",
      "Epoch: 147\n",
      "Epoch:150/200 AVG Training Loss:0.665 AVG Validation Loss:0.669 AVG Training Acc 59.66 % AVG Validation Acc 64.20 %\n",
      "New Best Accuracy found: 64.60%\n",
      "Epoch: 154\n",
      "Epoch:160/200 AVG Training Loss:0.667 AVG Validation Loss:0.668 AVG Training Acc 59.87 % AVG Validation Acc 64.74 %\n",
      "New Best Accuracy found: 64.74%\n",
      "Epoch: 160\n",
      "New Best Accuracy found: 65.01%\n",
      "Epoch: 163\n",
      "Epoch:170/200 AVG Training Loss:0.663 AVG Validation Loss:0.667 AVG Training Acc 60.53 % AVG Validation Acc 64.74 %\n",
      "Epoch:180/200 AVG Training Loss:0.666 AVG Validation Loss:0.666 AVG Training Acc 60.00 % AVG Validation Acc 65.01 %\n",
      "Epoch:190/200 AVG Training Loss:0.666 AVG Validation Loss:0.665 AVG Training Acc 60.04 % AVG Validation Acc 65.01 %\n",
      "Epoch:200/200 AVG Training Loss:0.664 AVG Validation Loss:0.664 AVG Training Acc 60.14 % AVG Validation Acc 64.87 %\n",
      "Split 18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f30589cd3dc34c149a09a5dbdc613bb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.528 AVG Validation Loss:5.139 AVG Training Acc 80.85 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.590 AVG Validation Loss:5.784 AVG Training Acc 69.06 % AVG Validation Acc 20.05 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.703 AVG Validation Loss:1.143 AVG Training Acc 58.19 % AVG Validation Acc 20.86 %\n",
      "Epoch:40/200 AVG Training Loss:0.682 AVG Validation Loss:0.983 AVG Training Acc 58.56 % AVG Validation Acc 20.86 %\n",
      "Epoch:50/200 AVG Training Loss:0.674 AVG Validation Loss:0.950 AVG Training Acc 59.69 % AVG Validation Acc 21.13 %\n",
      "Epoch:60/200 AVG Training Loss:0.666 AVG Validation Loss:0.912 AVG Training Acc 60.04 % AVG Validation Acc 21.94 %\n",
      "Epoch:70/200 AVG Training Loss:0.661 AVG Validation Loss:0.896 AVG Training Acc 60.22 % AVG Validation Acc 22.21 %\n",
      "Epoch:80/200 AVG Training Loss:0.654 AVG Validation Loss:0.870 AVG Training Acc 61.29 % AVG Validation Acc 23.96 %\n",
      "Epoch:90/200 AVG Training Loss:0.648 AVG Validation Loss:0.885 AVG Training Acc 61.90 % AVG Validation Acc 23.55 %\n",
      "Epoch    90: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.648 AVG Validation Loss:0.707 AVG Training Acc 61.08 % AVG Validation Acc 55.85 %\n",
      "Epoch:110/200 AVG Training Loss:0.646 AVG Validation Loss:0.695 AVG Training Acc 61.21 % AVG Validation Acc 58.41 %\n",
      "Epoch:120/200 AVG Training Loss:0.645 AVG Validation Loss:0.690 AVG Training Acc 61.38 % AVG Validation Acc 59.22 %\n",
      "Epoch:130/200 AVG Training Loss:0.641 AVG Validation Loss:0.689 AVG Training Acc 61.75 % AVG Validation Acc 59.35 %\n",
      "Epoch:140/200 AVG Training Loss:0.639 AVG Validation Loss:0.692 AVG Training Acc 61.81 % AVG Validation Acc 59.08 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.640 AVG Validation Loss:0.688 AVG Training Acc 62.18 % AVG Validation Acc 59.62 %\n",
      "Epoch:160/200 AVG Training Loss:0.639 AVG Validation Loss:0.684 AVG Training Acc 62.13 % AVG Validation Acc 60.03 %\n",
      "Epoch:170/200 AVG Training Loss:0.638 AVG Validation Loss:0.681 AVG Training Acc 62.06 % AVG Validation Acc 60.70 %\n",
      "Epoch:180/200 AVG Training Loss:0.638 AVG Validation Loss:0.680 AVG Training Acc 62.53 % AVG Validation Acc 60.97 %\n",
      "Epoch:190/200 AVG Training Loss:0.640 AVG Validation Loss:0.679 AVG Training Acc 61.78 % AVG Validation Acc 61.37 %\n",
      "Epoch:200/200 AVG Training Loss:0.638 AVG Validation Loss:0.678 AVG Training Acc 62.10 % AVG Validation Acc 61.64 %\n",
      "Split 19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "406e214fb7d44763bdeb4be2836d05ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.560 AVG Validation Loss:4.000 AVG Training Acc 77.83 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.553 AVG Validation Loss:6.521 AVG Training Acc 79.29 % AVG Validation Acc 20.05 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.728 AVG Validation Loss:0.853 AVG Training Acc 50.24 % AVG Validation Acc 21.00 %\n",
      "Epoch:40/200 AVG Training Loss:0.694 AVG Validation Loss:0.778 AVG Training Acc 51.64 % AVG Validation Acc 23.15 %\n",
      "Epoch:50/200 AVG Training Loss:0.691 AVG Validation Loss:0.776 AVG Training Acc 52.59 % AVG Validation Acc 23.96 %\n",
      "Epoch:60/200 AVG Training Loss:0.686 AVG Validation Loss:0.785 AVG Training Acc 55.18 % AVG Validation Acc 26.38 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.678 AVG Validation Loss:0.723 AVG Training Acc 55.72 % AVG Validation Acc 38.36 %\n",
      "Epoch:80/200 AVG Training Loss:0.677 AVG Validation Loss:0.698 AVG Training Acc 56.64 % AVG Validation Acc 43.07 %\n",
      "Epoch:90/200 AVG Training Loss:0.673 AVG Validation Loss:0.690 AVG Training Acc 58.58 % AVG Validation Acc 45.49 %\n",
      "Epoch:100/200 AVG Training Loss:0.672 AVG Validation Loss:0.689 AVG Training Acc 58.12 % AVG Validation Acc 47.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.672 AVG Validation Loss:0.688 AVG Training Acc 58.93 % AVG Validation Acc 50.61 %\n",
      "Epoch:120/200 AVG Training Loss:0.671 AVG Validation Loss:0.689 AVG Training Acc 58.64 % AVG Validation Acc 50.87 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.670 AVG Validation Loss:0.687 AVG Training Acc 59.10 % AVG Validation Acc 51.82 %\n",
      "Epoch:140/200 AVG Training Loss:0.670 AVG Validation Loss:0.686 AVG Training Acc 58.69 % AVG Validation Acc 52.36 %\n",
      "Epoch:150/200 AVG Training Loss:0.669 AVG Validation Loss:0.684 AVG Training Acc 59.04 % AVG Validation Acc 53.16 %\n",
      "Epoch:160/200 AVG Training Loss:0.670 AVG Validation Loss:0.683 AVG Training Acc 59.00 % AVG Validation Acc 53.97 %\n",
      "Epoch:170/200 AVG Training Loss:0.669 AVG Validation Loss:0.683 AVG Training Acc 59.51 % AVG Validation Acc 54.10 %\n",
      "Epoch:180/200 AVG Training Loss:0.668 AVG Validation Loss:0.682 AVG Training Acc 58.86 % AVG Validation Acc 54.10 %\n",
      "Epoch:190/200 AVG Training Loss:0.668 AVG Validation Loss:0.681 AVG Training Acc 59.10 % AVG Validation Acc 54.24 %\n",
      "Epoch:200/200 AVG Training Loss:0.668 AVG Validation Loss:0.681 AVG Training Acc 58.86 % AVG Validation Acc 54.37 %\n",
      "Split 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa8cfb64e46b470087a7b85a4602e7e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.589 AVG Validation Loss:2.788 AVG Training Acc 74.37 % AVG Validation Acc 20.19 %\n",
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.696 AVG Validation Loss:0.821 AVG Training Acc 52.24 % AVG Validation Acc 20.32 %\n",
      "Epoch:30/200 AVG Training Loss:0.686 AVG Validation Loss:0.827 AVG Training Acc 56.24 % AVG Validation Acc 23.69 %\n",
      "Epoch:40/200 AVG Training Loss:0.681 AVG Validation Loss:0.838 AVG Training Acc 57.76 % AVG Validation Acc 23.82 %\n",
      "Epoch    45: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.680 AVG Validation Loss:0.751 AVG Training Acc 56.17 % AVG Validation Acc 43.74 %\n",
      "Epoch:60/200 AVG Training Loss:0.671 AVG Validation Loss:0.696 AVG Training Acc 58.68 % AVG Validation Acc 57.74 %\n",
      "Epoch:70/200 AVG Training Loss:0.670 AVG Validation Loss:0.685 AVG Training Acc 58.96 % AVG Validation Acc 59.76 %\n",
      "Epoch:80/200 AVG Training Loss:0.670 AVG Validation Loss:0.681 AVG Training Acc 58.89 % AVG Validation Acc 60.30 %\n",
      "Epoch:90/200 AVG Training Loss:0.669 AVG Validation Loss:0.681 AVG Training Acc 59.83 % AVG Validation Acc 60.70 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.667 AVG Validation Loss:0.680 AVG Training Acc 59.90 % AVG Validation Acc 60.70 %\n",
      "Epoch:110/200 AVG Training Loss:0.667 AVG Validation Loss:0.678 AVG Training Acc 59.80 % AVG Validation Acc 60.70 %\n",
      "Epoch:120/200 AVG Training Loss:0.665 AVG Validation Loss:0.676 AVG Training Acc 59.82 % AVG Validation Acc 60.97 %\n",
      "Epoch:130/200 AVG Training Loss:0.666 AVG Validation Loss:0.674 AVG Training Acc 59.87 % AVG Validation Acc 61.91 %\n",
      "Epoch:140/200 AVG Training Loss:0.666 AVG Validation Loss:0.673 AVG Training Acc 60.03 % AVG Validation Acc 61.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.666 AVG Validation Loss:0.672 AVG Training Acc 59.60 % AVG Validation Acc 61.91 %\n",
      "Epoch:160/200 AVG Training Loss:0.666 AVG Validation Loss:0.671 AVG Training Acc 59.79 % AVG Validation Acc 61.91 %\n",
      "Epoch:170/200 AVG Training Loss:0.665 AVG Validation Loss:0.671 AVG Training Acc 59.99 % AVG Validation Acc 61.91 %\n",
      "Epoch:180/200 AVG Training Loss:0.664 AVG Validation Loss:0.670 AVG Training Acc 60.20 % AVG Validation Acc 62.05 %\n",
      "Epoch:190/200 AVG Training Loss:0.665 AVG Validation Loss:0.670 AVG Training Acc 60.36 % AVG Validation Acc 62.31 %\n",
      "Epoch:200/200 AVG Training Loss:0.666 AVG Validation Loss:0.669 AVG Training Acc 59.89 % AVG Validation Acc 62.45 %\n",
      "Split 21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60c2ce9828b14a7f981ff69aa8c4af2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.522 AVG Validation Loss:4.231 AVG Training Acc 81.61 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.526 AVG Validation Loss:6.850 AVG Training Acc 77.91 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.643 AVG Validation Loss:1.662 AVG Training Acc 66.80 % AVG Validation Acc 20.30 %\n",
      "Epoch:40/200 AVG Training Loss:0.650 AVG Validation Loss:1.641 AVG Training Acc 66.30 % AVG Validation Acc 20.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.532 AVG Validation Loss:3.875 AVG Training Acc 80.98 % AVG Validation Acc 20.16 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.677 AVG Validation Loss:1.208 AVG Training Acc 55.58 % AVG Validation Acc 22.45 %\n",
      "Epoch:70/200 AVG Training Loss:0.682 AVG Validation Loss:0.877 AVG Training Acc 57.08 % AVG Validation Acc 22.45 %\n",
      "Epoch:80/200 AVG Training Loss:0.677 AVG Validation Loss:0.869 AVG Training Acc 58.17 % AVG Validation Acc 22.85 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.682 AVG Validation Loss:0.763 AVG Training Acc 55.58 % AVG Validation Acc 40.05 %\n",
      "Epoch:100/200 AVG Training Loss:0.669 AVG Validation Loss:0.694 AVG Training Acc 59.65 % AVG Validation Acc 57.93 %\n",
      "Epoch:110/200 AVG Training Loss:0.666 AVG Validation Loss:0.685 AVG Training Acc 60.19 % AVG Validation Acc 59.54 %\n",
      "Epoch:120/200 AVG Training Loss:0.668 AVG Validation Loss:0.683 AVG Training Acc 59.78 % AVG Validation Acc 59.95 %\n",
      "Epoch:130/200 AVG Training Loss:0.663 AVG Validation Loss:0.684 AVG Training Acc 60.29 % AVG Validation Acc 59.41 %\n",
      "Epoch   132: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:140/200 AVG Training Loss:0.662 AVG Validation Loss:0.681 AVG Training Acc 60.76 % AVG Validation Acc 59.68 %\n",
      "Epoch:150/200 AVG Training Loss:0.660 AVG Validation Loss:0.678 AVG Training Acc 61.25 % AVG Validation Acc 60.75 %\n",
      "Epoch:160/200 AVG Training Loss:0.662 AVG Validation Loss:0.675 AVG Training Acc 60.71 % AVG Validation Acc 61.29 %\n",
      "Epoch:170/200 AVG Training Loss:0.661 AVG Validation Loss:0.673 AVG Training Acc 61.03 % AVG Validation Acc 61.83 %\n",
      "Epoch:180/200 AVG Training Loss:0.662 AVG Validation Loss:0.671 AVG Training Acc 60.91 % AVG Validation Acc 62.10 %\n",
      "Epoch:190/200 AVG Training Loss:0.659 AVG Validation Loss:0.670 AVG Training Acc 60.86 % AVG Validation Acc 62.10 %\n",
      "Epoch:200/200 AVG Training Loss:0.662 AVG Validation Loss:0.669 AVG Training Acc 60.94 % AVG Validation Acc 62.37 %\n",
      "Split 22\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "015d14b3707a4a7aa9c7545b8601aff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.423 AVG Validation Loss:7.986 AVG Training Acc 84.82 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.608 AVG Validation Loss:2.521 AVG Training Acc 73.11 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.565 AVG Validation Loss:3.601 AVG Training Acc 77.20 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.525 AVG Validation Loss:4.101 AVG Training Acc 78.24 % AVG Validation Acc 20.16 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.752 AVG Validation Loss:1.084 AVG Training Acc 55.37 % AVG Validation Acc 20.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.695 AVG Validation Loss:0.966 AVG Training Acc 55.43 % AVG Validation Acc 20.70 %\n",
      "Epoch:70/200 AVG Training Loss:0.672 AVG Validation Loss:1.039 AVG Training Acc 59.66 % AVG Validation Acc 22.45 %\n",
      "Epoch:80/200 AVG Training Loss:0.665 AVG Validation Loss:0.970 AVG Training Acc 60.79 % AVG Validation Acc 25.00 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.667 AVG Validation Loss:0.707 AVG Training Acc 59.79 % AVG Validation Acc 52.42 %\n",
      "Epoch:100/200 AVG Training Loss:0.662 AVG Validation Loss:0.682 AVG Training Acc 60.41 % AVG Validation Acc 58.20 %\n",
      "Epoch:110/200 AVG Training Loss:0.660 AVG Validation Loss:0.680 AVG Training Acc 60.85 % AVG Validation Acc 58.33 %\n",
      "Epoch:120/200 AVG Training Loss:0.658 AVG Validation Loss:0.679 AVG Training Acc 61.12 % AVG Validation Acc 58.74 %\n",
      "Epoch:130/200 AVG Training Loss:0.657 AVG Validation Loss:0.680 AVG Training Acc 61.13 % AVG Validation Acc 57.93 %\n",
      "Epoch   132: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:140/200 AVG Training Loss:0.654 AVG Validation Loss:0.674 AVG Training Acc 62.01 % AVG Validation Acc 58.47 %\n",
      "Epoch:150/200 AVG Training Loss:0.655 AVG Validation Loss:0.669 AVG Training Acc 61.81 % AVG Validation Acc 59.54 %\n",
      "Epoch:160/200 AVG Training Loss:0.654 AVG Validation Loss:0.665 AVG Training Acc 61.83 % AVG Validation Acc 59.95 %\n",
      "Epoch:170/200 AVG Training Loss:0.654 AVG Validation Loss:0.662 AVG Training Acc 61.81 % AVG Validation Acc 60.75 %\n",
      "Epoch:180/200 AVG Training Loss:0.654 AVG Validation Loss:0.660 AVG Training Acc 61.67 % AVG Validation Acc 61.02 %\n",
      "Epoch:190/200 AVG Training Loss:0.652 AVG Validation Loss:0.659 AVG Training Acc 62.02 % AVG Validation Acc 61.29 %\n",
      "Epoch:200/200 AVG Training Loss:0.652 AVG Validation Loss:0.658 AVG Training Acc 62.06 % AVG Validation Acc 61.16 %\n",
      "Split 23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71124db36ba746749527f5e845f666b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.528 AVG Validation Loss:3.571 AVG Training Acc 78.90 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.560 AVG Validation Loss:4.867 AVG Training Acc 80.74 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.651 AVG Validation Loss:1.521 AVG Training Acc 64.92 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.640 AVG Validation Loss:1.800 AVG Training Acc 67.17 % AVG Validation Acc 20.16 %\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.638 AVG Validation Loss:1.483 AVG Training Acc 62.15 % AVG Validation Acc 20.83 %\n",
      "Epoch:60/200 AVG Training Loss:0.662 AVG Validation Loss:1.511 AVG Training Acc 63.15 % AVG Validation Acc 20.30 %\n",
      "Epoch:70/200 AVG Training Loss:0.677 AVG Validation Loss:1.132 AVG Training Acc 60.37 % AVG Validation Acc 20.56 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.679 AVG Validation Loss:0.734 AVG Training Acc 57.42 % AVG Validation Acc 40.46 %\n",
      "Epoch:90/200 AVG Training Loss:0.674 AVG Validation Loss:0.720 AVG Training Acc 59.21 % AVG Validation Acc 49.60 %\n",
      "Epoch:100/200 AVG Training Loss:0.671 AVG Validation Loss:0.719 AVG Training Acc 58.93 % AVG Validation Acc 50.54 %\n",
      "Epoch:110/200 AVG Training Loss:0.669 AVG Validation Loss:0.716 AVG Training Acc 59.97 % AVG Validation Acc 51.88 %\n",
      "Epoch:120/200 AVG Training Loss:0.668 AVG Validation Loss:0.717 AVG Training Acc 59.75 % AVG Validation Acc 52.28 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.663 AVG Validation Loss:0.694 AVG Training Acc 60.73 % AVG Validation Acc 55.91 %\n",
      "Epoch:140/200 AVG Training Loss:0.662 AVG Validation Loss:0.679 AVG Training Acc 60.80 % AVG Validation Acc 57.93 %\n",
      "Epoch:150/200 AVG Training Loss:0.663 AVG Validation Loss:0.673 AVG Training Acc 60.88 % AVG Validation Acc 58.87 %\n",
      "Epoch:160/200 AVG Training Loss:0.662 AVG Validation Loss:0.671 AVG Training Acc 61.32 % AVG Validation Acc 59.41 %\n",
      "Epoch:170/200 AVG Training Loss:0.664 AVG Validation Loss:0.668 AVG Training Acc 61.34 % AVG Validation Acc 59.41 %\n",
      "Epoch:180/200 AVG Training Loss:0.662 AVG Validation Loss:0.669 AVG Training Acc 60.91 % AVG Validation Acc 59.68 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:190/200 AVG Training Loss:0.660 AVG Validation Loss:0.668 AVG Training Acc 61.11 % AVG Validation Acc 60.08 %\n",
      "Epoch:200/200 AVG Training Loss:0.661 AVG Validation Loss:0.667 AVG Training Acc 60.79 % AVG Validation Acc 59.54 %\n",
      "Split 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c140f4e932e4a7db3cb4e85c3f93a8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.508 AVG Validation Loss:5.223 AVG Training Acc 79.55 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.629 AVG Validation Loss:1.765 AVG Training Acc 68.92 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.620 AVG Validation Loss:6.642 AVG Training Acc 66.69 % AVG Validation Acc 20.30 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.715 AVG Validation Loss:1.806 AVG Training Acc 61.39 % AVG Validation Acc 20.56 %\n",
      "Epoch:50/200 AVG Training Loss:0.693 AVG Validation Loss:0.938 AVG Training Acc 55.51 % AVG Validation Acc 23.66 %\n",
      "Epoch:60/200 AVG Training Loss:0.688 AVG Validation Loss:0.838 AVG Training Acc 55.92 % AVG Validation Acc 34.27 %\n",
      "Epoch:70/200 AVG Training Loss:0.679 AVG Validation Loss:0.814 AVG Training Acc 57.59 % AVG Validation Acc 39.38 %\n",
      "Epoch:80/200 AVG Training Loss:0.665 AVG Validation Loss:0.833 AVG Training Acc 59.53 % AVG Validation Acc 39.78 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.662 AVG Validation Loss:0.721 AVG Training Acc 60.02 % AVG Validation Acc 53.23 %\n",
      "Epoch:100/200 AVG Training Loss:0.660 AVG Validation Loss:0.701 AVG Training Acc 61.35 % AVG Validation Acc 56.59 %\n",
      "Epoch:110/200 AVG Training Loss:0.657 AVG Validation Loss:0.698 AVG Training Acc 61.62 % AVG Validation Acc 56.59 %\n",
      "Epoch:120/200 AVG Training Loss:0.655 AVG Validation Loss:0.698 AVG Training Acc 61.72 % AVG Validation Acc 56.45 %\n",
      "Epoch:130/200 AVG Training Loss:0.654 AVG Validation Loss:0.695 AVG Training Acc 61.63 % AVG Validation Acc 57.12 %\n",
      "Epoch:140/200 AVG Training Loss:0.656 AVG Validation Loss:0.692 AVG Training Acc 61.50 % AVG Validation Acc 57.66 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.653 AVG Validation Loss:0.691 AVG Training Acc 62.10 % AVG Validation Acc 58.06 %\n",
      "Epoch:160/200 AVG Training Loss:0.650 AVG Validation Loss:0.690 AVG Training Acc 61.80 % AVG Validation Acc 57.80 %\n",
      "Epoch:170/200 AVG Training Loss:0.651 AVG Validation Loss:0.689 AVG Training Acc 62.08 % AVG Validation Acc 58.06 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:180/200 AVG Training Loss:0.651 AVG Validation Loss:0.687 AVG Training Acc 61.86 % AVG Validation Acc 58.20 %\n",
      "Epoch:190/200 AVG Training Loss:0.653 AVG Validation Loss:0.685 AVG Training Acc 61.88 % AVG Validation Acc 57.80 %\n",
      "Epoch:200/200 AVG Training Loss:0.651 AVG Validation Loss:0.689 AVG Training Acc 62.02 % AVG Validation Acc 58.60 %\n",
      "Split 25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a88bd271a3eb49bd8c42f78f59a9c67f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.432 AVG Validation Loss:6.842 AVG Training Acc 84.13 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.585 AVG Validation Loss:2.605 AVG Training Acc 74.27 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.621 AVG Validation Loss:7.325 AVG Training Acc 80.11 % AVG Validation Acc 20.16 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.726 AVG Validation Loss:0.843 AVG Training Acc 50.19 % AVG Validation Acc 20.83 %\n",
      "Epoch:50/200 AVG Training Loss:0.686 AVG Validation Loss:0.757 AVG Training Acc 55.01 % AVG Validation Acc 25.27 %\n",
      "Epoch:60/200 AVG Training Loss:0.678 AVG Validation Loss:0.759 AVG Training Acc 57.43 % AVG Validation Acc 30.91 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.676 AVG Validation Loss:0.742 AVG Training Acc 57.26 % AVG Validation Acc 42.88 %\n",
      "Epoch:80/200 AVG Training Loss:0.669 AVG Validation Loss:0.692 AVG Training Acc 59.18 % AVG Validation Acc 59.14 %\n",
      "Epoch:90/200 AVG Training Loss:0.665 AVG Validation Loss:0.679 AVG Training Acc 59.90 % AVG Validation Acc 60.75 %\n",
      "Epoch:100/200 AVG Training Loss:0.662 AVG Validation Loss:0.677 AVG Training Acc 60.22 % AVG Validation Acc 60.75 %\n",
      "Epoch:110/200 AVG Training Loss:0.663 AVG Validation Loss:0.675 AVG Training Acc 60.48 % AVG Validation Acc 60.75 %\n",
      "Epoch:120/200 AVG Training Loss:0.664 AVG Validation Loss:0.675 AVG Training Acc 60.41 % AVG Validation Acc 60.35 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.660 AVG Validation Loss:0.674 AVG Training Acc 60.86 % AVG Validation Acc 60.48 %\n",
      "Epoch:140/200 AVG Training Loss:0.661 AVG Validation Loss:0.672 AVG Training Acc 60.65 % AVG Validation Acc 61.16 %\n",
      "Epoch:150/200 AVG Training Loss:0.661 AVG Validation Loss:0.671 AVG Training Acc 60.77 % AVG Validation Acc 61.29 %\n",
      "Epoch:160/200 AVG Training Loss:0.660 AVG Validation Loss:0.670 AVG Training Acc 60.94 % AVG Validation Acc 61.29 %\n",
      "Epoch:170/200 AVG Training Loss:0.663 AVG Validation Loss:0.669 AVG Training Acc 60.07 % AVG Validation Acc 61.56 %\n",
      "Epoch:180/200 AVG Training Loss:0.663 AVG Validation Loss:0.668 AVG Training Acc 60.27 % AVG Validation Acc 61.69 %\n",
      "Epoch:190/200 AVG Training Loss:0.661 AVG Validation Loss:0.668 AVG Training Acc 60.74 % AVG Validation Acc 61.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.659 AVG Validation Loss:0.667 AVG Training Acc 61.21 % AVG Validation Acc 61.69 %\n",
      "Split 26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b77ce236da943f096253c31269ce46f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.562 AVG Validation Loss:6.577 AVG Training Acc 76.91 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.649 AVG Validation Loss:1.618 AVG Training Acc 66.01 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.576 AVG Validation Loss:7.086 AVG Training Acc 78.39 % AVG Validation Acc 20.16 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.701 AVG Validation Loss:0.838 AVG Training Acc 52.02 % AVG Validation Acc 20.70 %\n",
      "Epoch:50/200 AVG Training Loss:0.678 AVG Validation Loss:0.830 AVG Training Acc 57.90 % AVG Validation Acc 21.10 %\n",
      "Epoch:60/200 AVG Training Loss:0.673 AVG Validation Loss:0.834 AVG Training Acc 59.02 % AVG Validation Acc 21.64 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.685 AVG Validation Loss:0.794 AVG Training Acc 54.83 % AVG Validation Acc 28.36 %\n",
      "Epoch:80/200 AVG Training Loss:0.665 AVG Validation Loss:0.702 AVG Training Acc 60.03 % AVG Validation Acc 56.18 %\n",
      "Epoch:90/200 AVG Training Loss:0.662 AVG Validation Loss:0.688 AVG Training Acc 61.14 % AVG Validation Acc 57.39 %\n",
      "Epoch:100/200 AVG Training Loss:0.663 AVG Validation Loss:0.686 AVG Training Acc 60.89 % AVG Validation Acc 57.12 %\n",
      "Epoch:110/200 AVG Training Loss:0.660 AVG Validation Loss:0.684 AVG Training Acc 61.43 % AVG Validation Acc 56.99 %\n",
      "Epoch:120/200 AVG Training Loss:0.659 AVG Validation Loss:0.684 AVG Training Acc 61.33 % AVG Validation Acc 56.85 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.658 AVG Validation Loss:0.683 AVG Training Acc 61.43 % AVG Validation Acc 56.99 %\n",
      "Epoch:140/200 AVG Training Loss:0.659 AVG Validation Loss:0.680 AVG Training Acc 61.58 % AVG Validation Acc 57.39 %\n",
      "Epoch:150/200 AVG Training Loss:0.659 AVG Validation Loss:0.678 AVG Training Acc 61.42 % AVG Validation Acc 57.53 %\n",
      "Epoch:160/200 AVG Training Loss:0.660 AVG Validation Loss:0.676 AVG Training Acc 61.61 % AVG Validation Acc 57.66 %\n",
      "Epoch:170/200 AVG Training Loss:0.659 AVG Validation Loss:0.675 AVG Training Acc 61.23 % AVG Validation Acc 57.80 %\n",
      "Epoch:180/200 AVG Training Loss:0.659 AVG Validation Loss:0.674 AVG Training Acc 61.22 % AVG Validation Acc 57.53 %\n",
      "Epoch:190/200 AVG Training Loss:0.658 AVG Validation Loss:0.673 AVG Training Acc 61.61 % AVG Validation Acc 57.66 %\n",
      "Epoch:200/200 AVG Training Loss:0.657 AVG Validation Loss:0.673 AVG Training Acc 61.45 % AVG Validation Acc 57.80 %\n",
      "Split 27\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8dd6295ce3f46a388003db92f266d38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.514 AVG Validation Loss:3.718 AVG Training Acc 81.69 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.601 AVG Validation Loss:2.501 AVG Training Acc 78.95 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.652 AVG Validation Loss:1.711 AVG Training Acc 67.12 % AVG Validation Acc 20.05 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.707 AVG Validation Loss:0.801 AVG Training Acc 50.75 % AVG Validation Acc 21.94 %\n",
      "Epoch:50/200 AVG Training Loss:0.678 AVG Validation Loss:0.780 AVG Training Acc 56.90 % AVG Validation Acc 33.38 %\n",
      "Epoch:60/200 AVG Training Loss:0.676 AVG Validation Loss:0.771 AVG Training Acc 58.51 % AVG Validation Acc 40.65 %\n",
      "Epoch:70/200 AVG Training Loss:0.672 AVG Validation Loss:0.777 AVG Training Acc 59.39 % AVG Validation Acc 44.01 %\n",
      "Epoch    71: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.665 AVG Validation Loss:0.726 AVG Training Acc 60.16 % AVG Validation Acc 56.26 %\n",
      "Epoch:90/200 AVG Training Loss:0.663 AVG Validation Loss:0.704 AVG Training Acc 61.65 % AVG Validation Acc 58.28 %\n",
      "Epoch:100/200 AVG Training Loss:0.660 AVG Validation Loss:0.696 AVG Training Acc 61.59 % AVG Validation Acc 59.49 %\n",
      "Epoch:110/200 AVG Training Loss:0.664 AVG Validation Loss:0.693 AVG Training Acc 60.94 % AVG Validation Acc 59.35 %\n",
      "Epoch:120/200 AVG Training Loss:0.661 AVG Validation Loss:0.693 AVG Training Acc 61.24 % AVG Validation Acc 58.82 %\n",
      "Epoch:130/200 AVG Training Loss:0.659 AVG Validation Loss:0.692 AVG Training Acc 61.46 % AVG Validation Acc 58.95 %\n",
      "Epoch:140/200 AVG Training Loss:0.659 AVG Validation Loss:0.692 AVG Training Acc 61.77 % AVG Validation Acc 58.68 %\n",
      "Epoch:150/200 AVG Training Loss:0.658 AVG Validation Loss:0.693 AVG Training Acc 61.75 % AVG Validation Acc 58.41 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:160/200 AVG Training Loss:0.656 AVG Validation Loss:0.693 AVG Training Acc 61.93 % AVG Validation Acc 58.68 %\n",
      "Epoch:170/200 AVG Training Loss:0.657 AVG Validation Loss:0.692 AVG Training Acc 61.66 % AVG Validation Acc 58.28 %\n",
      "Epoch:180/200 AVG Training Loss:0.655 AVG Validation Loss:0.691 AVG Training Acc 62.26 % AVG Validation Acc 58.68 %\n",
      "Epoch:190/200 AVG Training Loss:0.658 AVG Validation Loss:0.690 AVG Training Acc 61.65 % AVG Validation Acc 58.68 %\n",
      "Epoch:200/200 AVG Training Loss:0.657 AVG Validation Loss:0.690 AVG Training Acc 62.12 % AVG Validation Acc 58.55 %\n",
      "Split 28\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1108d29cbc464a87acee0952bed31ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.498 AVG Validation Loss:5.891 AVG Training Acc 80.63 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.557 AVG Validation Loss:4.594 AVG Training Acc 79.21 % AVG Validation Acc 20.05 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:1.024 AVG Validation Loss:1.052 AVG Training Acc 48.54 % AVG Validation Acc 20.46 %\n",
      "Epoch:40/200 AVG Training Loss:0.680 AVG Validation Loss:0.874 AVG Training Acc 56.76 % AVG Validation Acc 21.80 %\n",
      "Epoch:50/200 AVG Training Loss:0.676 AVG Validation Loss:0.877 AVG Training Acc 57.80 % AVG Validation Acc 21.94 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.685 AVG Validation Loss:0.783 AVG Training Acc 54.94 % AVG Validation Acc 30.96 %\n",
      "Epoch:70/200 AVG Training Loss:0.669 AVG Validation Loss:0.711 AVG Training Acc 58.57 % AVG Validation Acc 43.47 %\n",
      "Epoch:80/200 AVG Training Loss:0.666 AVG Validation Loss:0.703 AVG Training Acc 58.73 % AVG Validation Acc 45.22 %\n",
      "Epoch:90/200 AVG Training Loss:0.665 AVG Validation Loss:0.701 AVG Training Acc 59.30 % AVG Validation Acc 44.95 %\n",
      "Epoch:100/200 AVG Training Loss:0.664 AVG Validation Loss:0.701 AVG Training Acc 58.92 % AVG Validation Acc 45.49 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.661 AVG Validation Loss:0.697 AVG Training Acc 59.83 % AVG Validation Acc 46.43 %\n",
      "Epoch:120/200 AVG Training Loss:0.661 AVG Validation Loss:0.692 AVG Training Acc 59.70 % AVG Validation Acc 47.51 %\n",
      "Epoch:130/200 AVG Training Loss:0.661 AVG Validation Loss:0.690 AVG Training Acc 60.09 % AVG Validation Acc 48.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.658 AVG Validation Loss:0.688 AVG Training Acc 59.75 % AVG Validation Acc 48.59 %\n",
      "Epoch:150/200 AVG Training Loss:0.660 AVG Validation Loss:0.686 AVG Training Acc 59.69 % AVG Validation Acc 48.86 %\n",
      "Epoch:160/200 AVG Training Loss:0.660 AVG Validation Loss:0.686 AVG Training Acc 59.79 % AVG Validation Acc 48.86 %\n",
      "Epoch:170/200 AVG Training Loss:0.661 AVG Validation Loss:0.685 AVG Training Acc 59.34 % AVG Validation Acc 49.13 %\n",
      "Epoch:180/200 AVG Training Loss:0.659 AVG Validation Loss:0.684 AVG Training Acc 60.02 % AVG Validation Acc 49.26 %\n",
      "Epoch:190/200 AVG Training Loss:0.660 AVG Validation Loss:0.683 AVG Training Acc 60.10 % AVG Validation Acc 49.39 %\n",
      "Epoch:200/200 AVG Training Loss:0.660 AVG Validation Loss:0.684 AVG Training Acc 59.62 % AVG Validation Acc 49.26 %\n",
      "Split 29\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "893750195847438da7bbf1056476ee73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.551 AVG Validation Loss:3.904 AVG Training Acc 79.64 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.565 AVG Validation Loss:3.162 AVG Training Acc 74.55 % AVG Validation Acc 20.05 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.743 AVG Validation Loss:0.876 AVG Training Acc 50.20 % AVG Validation Acc 20.73 %\n",
      "Epoch:40/200 AVG Training Loss:0.689 AVG Validation Loss:0.799 AVG Training Acc 55.21 % AVG Validation Acc 22.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.683 AVG Validation Loss:0.822 AVG Training Acc 55.33 % AVG Validation Acc 22.34 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.684 AVG Validation Loss:0.779 AVG Training Acc 56.30 % AVG Validation Acc 42.40 %\n",
      "Epoch:70/200 AVG Training Loss:0.669 AVG Validation Loss:0.704 AVG Training Acc 60.12 % AVG Validation Acc 55.59 %\n",
      "Epoch:80/200 AVG Training Loss:0.666 AVG Validation Loss:0.687 AVG Training Acc 60.71 % AVG Validation Acc 59.08 %\n",
      "Epoch:90/200 AVG Training Loss:0.664 AVG Validation Loss:0.685 AVG Training Acc 60.87 % AVG Validation Acc 59.35 %\n",
      "Epoch:100/200 AVG Training Loss:0.662 AVG Validation Loss:0.683 AVG Training Acc 60.92 % AVG Validation Acc 60.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.663 AVG Validation Loss:0.683 AVG Training Acc 60.91 % AVG Validation Acc 59.89 %\n",
      "Epoch:120/200 AVG Training Loss:0.662 AVG Validation Loss:0.683 AVG Training Acc 61.31 % AVG Validation Acc 59.89 %\n",
      "Epoch:130/200 AVG Training Loss:0.662 AVG Validation Loss:0.680 AVG Training Acc 61.28 % AVG Validation Acc 60.57 %\n",
      "Epoch:140/200 AVG Training Loss:0.660 AVG Validation Loss:0.677 AVG Training Acc 61.59 % AVG Validation Acc 61.10 %\n",
      "Epoch:150/200 AVG Training Loss:0.657 AVG Validation Loss:0.676 AVG Training Acc 61.79 % AVG Validation Acc 60.97 %\n",
      "Epoch:160/200 AVG Training Loss:0.655 AVG Validation Loss:0.674 AVG Training Acc 61.90 % AVG Validation Acc 60.70 %\n",
      "Epoch:170/200 AVG Training Loss:0.655 AVG Validation Loss:0.677 AVG Training Acc 61.69 % AVG Validation Acc 59.76 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:180/200 AVG Training Loss:0.652 AVG Validation Loss:0.672 AVG Training Acc 62.28 % AVG Validation Acc 60.57 %\n",
      "Epoch:190/200 AVG Training Loss:0.652 AVG Validation Loss:0.670 AVG Training Acc 62.25 % AVG Validation Acc 61.37 %\n",
      "Epoch:200/200 AVG Training Loss:0.651 AVG Validation Loss:0.667 AVG Training Acc 62.61 % AVG Validation Acc 61.51 %\n",
      "Split 30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a6eaea136b04fa398bef0a5defc77b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.577 AVG Validation Loss:3.386 AVG Training Acc 78.58 % AVG Validation Acc 20.19 %\n",
      "Epoch:20/200 AVG Training Loss:0.527 AVG Validation Loss:5.003 AVG Training Acc 81.26 % AVG Validation Acc 20.19 %\n",
      "Epoch:30/200 AVG Training Loss:0.635 AVG Validation Loss:2.272 AVG Training Acc 65.68 % AVG Validation Acc 20.19 %\n",
      "Epoch:40/200 AVG Training Loss:0.626 AVG Validation Loss:5.395 AVG Training Acc 65.82 % AVG Validation Acc 20.19 %\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.688 AVG Validation Loss:1.131 AVG Training Acc 59.78 % AVG Validation Acc 21.00 %\n",
      "Epoch:60/200 AVG Training Loss:0.686 AVG Validation Loss:0.985 AVG Training Acc 57.98 % AVG Validation Acc 21.27 %\n",
      "Epoch:70/200 AVG Training Loss:0.684 AVG Validation Loss:0.915 AVG Training Acc 58.04 % AVG Validation Acc 22.34 %\n",
      "Epoch:80/200 AVG Training Loss:0.672 AVG Validation Loss:0.907 AVG Training Acc 59.18 % AVG Validation Acc 23.01 %\n",
      "Epoch:90/200 AVG Training Loss:0.669 AVG Validation Loss:0.891 AVG Training Acc 59.08 % AVG Validation Acc 23.69 %\n",
      "Epoch:100/200 AVG Training Loss:0.665 AVG Validation Loss:0.876 AVG Training Acc 60.12 % AVG Validation Acc 25.44 %\n",
      "Epoch:110/200 AVG Training Loss:0.663 AVG Validation Loss:0.869 AVG Training Acc 59.88 % AVG Validation Acc 25.44 %\n",
      "Epoch:120/200 AVG Training Loss:0.658 AVG Validation Loss:0.874 AVG Training Acc 60.86 % AVG Validation Acc 26.65 %\n",
      "Epoch:130/200 AVG Training Loss:0.655 AVG Validation Loss:0.874 AVG Training Acc 61.20 % AVG Validation Acc 26.78 %\n",
      "Epoch   137: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:140/200 AVG Training Loss:0.682 AVG Validation Loss:0.798 AVG Training Acc 57.06 % AVG Validation Acc 35.53 %\n",
      "Epoch:150/200 AVG Training Loss:0.656 AVG Validation Loss:0.704 AVG Training Acc 60.04 % AVG Validation Acc 49.39 %\n",
      "Epoch:160/200 AVG Training Loss:0.650 AVG Validation Loss:0.676 AVG Training Acc 61.00 % AVG Validation Acc 55.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.646 AVG Validation Loss:0.674 AVG Training Acc 61.95 % AVG Validation Acc 55.72 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:180/200 AVG Training Loss:0.645 AVG Validation Loss:0.673 AVG Training Acc 61.78 % AVG Validation Acc 56.26 %\n",
      "Epoch:190/200 AVG Training Loss:0.643 AVG Validation Loss:0.670 AVG Training Acc 61.76 % AVG Validation Acc 56.80 %\n",
      "Epoch:200/200 AVG Training Loss:0.645 AVG Validation Loss:0.669 AVG Training Acc 62.17 % AVG Validation Acc 57.07 %\n",
      "Split 31\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98e2e7ca33c84d89853f0fea85b3d9fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.498 AVG Validation Loss:8.559 AVG Training Acc 78.77 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:1.548 AVG Training Acc 65.06 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.634 AVG Validation Loss:7.130 AVG Training Acc 65.09 % AVG Validation Acc 20.30 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.689 AVG Validation Loss:0.785 AVG Training Acc 53.59 % AVG Validation Acc 24.33 %\n",
      "Epoch:50/200 AVG Training Loss:0.675 AVG Validation Loss:0.780 AVG Training Acc 58.38 % AVG Validation Acc 33.47 %\n",
      "Epoch:60/200 AVG Training Loss:0.672 AVG Validation Loss:0.773 AVG Training Acc 58.95 % AVG Validation Acc 39.52 %\n",
      "Epoch:70/200 AVG Training Loss:0.664 AVG Validation Loss:0.780 AVG Training Acc 60.66 % AVG Validation Acc 43.55 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.659 AVG Validation Loss:0.721 AVG Training Acc 60.69 % AVG Validation Acc 54.30 %\n",
      "Epoch:90/200 AVG Training Loss:0.654 AVG Validation Loss:0.689 AVG Training Acc 61.76 % AVG Validation Acc 55.91 %\n",
      "Epoch:100/200 AVG Training Loss:0.654 AVG Validation Loss:0.680 AVG Training Acc 62.06 % AVG Validation Acc 57.12 %\n",
      "Epoch:110/200 AVG Training Loss:0.654 AVG Validation Loss:0.677 AVG Training Acc 61.90 % AVG Validation Acc 57.12 %\n",
      "Epoch:120/200 AVG Training Loss:0.650 AVG Validation Loss:0.675 AVG Training Acc 62.08 % AVG Validation Acc 57.39 %\n",
      "Epoch:130/200 AVG Training Loss:0.652 AVG Validation Loss:0.675 AVG Training Acc 61.89 % AVG Validation Acc 57.12 %\n",
      "Epoch:140/200 AVG Training Loss:0.650 AVG Validation Loss:0.674 AVG Training Acc 62.32 % AVG Validation Acc 57.80 %\n",
      "Epoch:150/200 AVG Training Loss:0.652 AVG Validation Loss:0.673 AVG Training Acc 61.78 % AVG Validation Acc 56.99 %\n",
      "Epoch:160/200 AVG Training Loss:0.649 AVG Validation Loss:0.672 AVG Training Acc 62.09 % AVG Validation Acc 57.80 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:170/200 AVG Training Loss:0.649 AVG Validation Loss:0.672 AVG Training Acc 62.25 % AVG Validation Acc 57.66 %\n",
      "Epoch:180/200 AVG Training Loss:0.648 AVG Validation Loss:0.670 AVG Training Acc 62.63 % AVG Validation Acc 57.26 %\n",
      "Epoch:190/200 AVG Training Loss:0.649 AVG Validation Loss:0.669 AVG Training Acc 62.28 % AVG Validation Acc 57.93 %\n",
      "Epoch:200/200 AVG Training Loss:0.649 AVG Validation Loss:0.668 AVG Training Acc 62.54 % AVG Validation Acc 57.93 %\n",
      "Split 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a61e29b8df246e7919cf0f42fffd499",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.608 AVG Validation Loss:1.956 AVG Training Acc 70.79 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.474 AVG Validation Loss:5.462 AVG Training Acc 83.55 % AVG Validation Acc 20.16 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.699 AVG Validation Loss:0.798 AVG Training Acc 50.70 % AVG Validation Acc 20.30 %\n",
      "Epoch:40/200 AVG Training Loss:0.690 AVG Validation Loss:0.817 AVG Training Acc 53.09 % AVG Validation Acc 22.45 %\n",
      "Epoch:50/200 AVG Training Loss:0.681 AVG Validation Loss:0.838 AVG Training Acc 56.73 % AVG Validation Acc 31.45 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.673 AVG Validation Loss:0.728 AVG Training Acc 58.44 % AVG Validation Acc 51.48 %\n",
      "Epoch:70/200 AVG Training Loss:0.669 AVG Validation Loss:0.697 AVG Training Acc 59.17 % AVG Validation Acc 59.95 %\n",
      "Epoch:80/200 AVG Training Loss:0.665 AVG Validation Loss:0.689 AVG Training Acc 59.74 % AVG Validation Acc 62.10 %\n",
      "Epoch:90/200 AVG Training Loss:0.665 AVG Validation Loss:0.688 AVG Training Acc 59.44 % AVG Validation Acc 61.69 %\n",
      "Epoch:100/200 AVG Training Loss:0.665 AVG Validation Loss:0.687 AVG Training Acc 60.06 % AVG Validation Acc 60.89 %\n",
      "Epoch:110/200 AVG Training Loss:0.664 AVG Validation Loss:0.686 AVG Training Acc 60.15 % AVG Validation Acc 60.48 %\n",
      "Epoch:120/200 AVG Training Loss:0.662 AVG Validation Loss:0.687 AVG Training Acc 60.21 % AVG Validation Acc 60.48 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.662 AVG Validation Loss:0.685 AVG Training Acc 60.80 % AVG Validation Acc 60.35 %\n",
      "Epoch:140/200 AVG Training Loss:0.660 AVG Validation Loss:0.683 AVG Training Acc 60.59 % AVG Validation Acc 60.35 %\n",
      "Epoch:150/200 AVG Training Loss:0.662 AVG Validation Loss:0.682 AVG Training Acc 60.07 % AVG Validation Acc 60.89 %\n",
      "Epoch:160/200 AVG Training Loss:0.661 AVG Validation Loss:0.680 AVG Training Acc 60.74 % AVG Validation Acc 60.89 %\n",
      "Epoch:170/200 AVG Training Loss:0.663 AVG Validation Loss:0.680 AVG Training Acc 60.22 % AVG Validation Acc 61.29 %\n",
      "Epoch:180/200 AVG Training Loss:0.662 AVG Validation Loss:0.679 AVG Training Acc 60.89 % AVG Validation Acc 61.29 %\n",
      "Epoch:190/200 AVG Training Loss:0.661 AVG Validation Loss:0.678 AVG Training Acc 60.41 % AVG Validation Acc 61.29 %\n",
      "Epoch:200/200 AVG Training Loss:0.661 AVG Validation Loss:0.677 AVG Training Acc 60.31 % AVG Validation Acc 61.96 %\n",
      "Split 33\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eff584379e1842cfa765a3379a2c48d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.529 AVG Validation Loss:3.697 AVG Training Acc 80.46 % AVG Validation Acc 20.16 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.734 AVG Validation Loss:0.909 AVG Training Acc 50.37 % AVG Validation Acc 21.64 %\n",
      "Epoch:30/200 AVG Training Loss:0.693 AVG Validation Loss:0.821 AVG Training Acc 53.73 % AVG Validation Acc 21.51 %\n",
      "Epoch:40/200 AVG Training Loss:0.687 AVG Validation Loss:0.824 AVG Training Acc 55.27 % AVG Validation Acc 23.66 %\n",
      "Epoch:50/200 AVG Training Loss:0.675 AVG Validation Loss:0.827 AVG Training Acc 58.53 % AVG Validation Acc 28.36 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.671 AVG Validation Loss:0.721 AVG Training Acc 58.71 % AVG Validation Acc 50.40 %\n",
      "Epoch:70/200 AVG Training Loss:0.667 AVG Validation Loss:0.696 AVG Training Acc 60.15 % AVG Validation Acc 54.17 %\n",
      "Epoch:80/200 AVG Training Loss:0.665 AVG Validation Loss:0.692 AVG Training Acc 59.59 % AVG Validation Acc 54.57 %\n",
      "Epoch:90/200 AVG Training Loss:0.665 AVG Validation Loss:0.690 AVG Training Acc 60.23 % AVG Validation Acc 55.11 %\n",
      "Epoch:100/200 AVG Training Loss:0.664 AVG Validation Loss:0.689 AVG Training Acc 59.96 % AVG Validation Acc 55.11 %\n",
      "Epoch:110/200 AVG Training Loss:0.664 AVG Validation Loss:0.688 AVG Training Acc 60.09 % AVG Validation Acc 54.44 %\n",
      "Epoch:120/200 AVG Training Loss:0.664 AVG Validation Loss:0.687 AVG Training Acc 60.22 % AVG Validation Acc 54.70 %\n",
      "Epoch:130/200 AVG Training Loss:0.662 AVG Validation Loss:0.686 AVG Training Acc 60.60 % AVG Validation Acc 54.97 %\n",
      "Epoch:140/200 AVG Training Loss:0.661 AVG Validation Loss:0.685 AVG Training Acc 60.95 % AVG Validation Acc 55.11 %\n",
      "Epoch:150/200 AVG Training Loss:0.661 AVG Validation Loss:0.685 AVG Training Acc 60.47 % AVG Validation Acc 55.11 %\n",
      "Epoch:160/200 AVG Training Loss:0.661 AVG Validation Loss:0.684 AVG Training Acc 61.20 % AVG Validation Acc 55.11 %\n",
      "Epoch:170/200 AVG Training Loss:0.660 AVG Validation Loss:0.685 AVG Training Acc 60.90 % AVG Validation Acc 54.57 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:180/200 AVG Training Loss:0.657 AVG Validation Loss:0.683 AVG Training Acc 61.36 % AVG Validation Acc 55.24 %\n",
      "Epoch:190/200 AVG Training Loss:0.658 AVG Validation Loss:0.680 AVG Training Acc 61.40 % AVG Validation Acc 55.38 %\n",
      "Epoch:200/200 AVG Training Loss:0.658 AVG Validation Loss:0.677 AVG Training Acc 61.31 % AVG Validation Acc 55.51 %\n",
      "Split 34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35c4e561bf054ba68f5659a8218a6d6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.504 AVG Validation Loss:5.026 AVG Training Acc 80.65 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.532 AVG Validation Loss:5.688 AVG Training Acc 83.42 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.634 AVG Validation Loss:2.823 AVG Training Acc 68.23 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.634 AVG Validation Loss:1.789 AVG Training Acc 66.91 % AVG Validation Acc 20.30 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.700 AVG Validation Loss:0.990 AVG Training Acc 53.98 % AVG Validation Acc 27.55 %\n",
      "Epoch:60/200 AVG Training Loss:0.686 AVG Validation Loss:0.795 AVG Training Acc 54.05 % AVG Validation Acc 27.02 %\n",
      "Epoch:70/200 AVG Training Loss:0.681 AVG Validation Loss:0.806 AVG Training Acc 56.22 % AVG Validation Acc 27.02 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.690 AVG Validation Loss:0.777 AVG Training Acc 53.36 % AVG Validation Acc 27.15 %\n",
      "Epoch:90/200 AVG Training Loss:0.676 AVG Validation Loss:0.720 AVG Training Acc 57.24 % AVG Validation Acc 40.19 %\n",
      "Epoch:100/200 AVG Training Loss:0.674 AVG Validation Loss:0.705 AVG Training Acc 58.00 % AVG Validation Acc 45.03 %\n",
      "Epoch:110/200 AVG Training Loss:0.672 AVG Validation Loss:0.698 AVG Training Acc 58.19 % AVG Validation Acc 46.64 %\n",
      "Epoch:120/200 AVG Training Loss:0.672 AVG Validation Loss:0.694 AVG Training Acc 58.48 % AVG Validation Acc 48.66 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.671 AVG Validation Loss:0.694 AVG Training Acc 58.54 % AVG Validation Acc 50.40 %\n",
      "Epoch:140/200 AVG Training Loss:0.670 AVG Validation Loss:0.690 AVG Training Acc 58.94 % AVG Validation Acc 51.08 %\n",
      "Epoch:150/200 AVG Training Loss:0.671 AVG Validation Loss:0.686 AVG Training Acc 58.73 % AVG Validation Acc 51.61 %\n",
      "Epoch:160/200 AVG Training Loss:0.670 AVG Validation Loss:0.683 AVG Training Acc 58.86 % AVG Validation Acc 51.88 %\n",
      "Epoch:170/200 AVG Training Loss:0.668 AVG Validation Loss:0.681 AVG Training Acc 59.23 % AVG Validation Acc 52.82 %\n",
      "Epoch:180/200 AVG Training Loss:0.668 AVG Validation Loss:0.681 AVG Training Acc 59.30 % AVG Validation Acc 52.96 %\n",
      "Epoch:190/200 AVG Training Loss:0.671 AVG Validation Loss:0.680 AVG Training Acc 59.29 % AVG Validation Acc 53.76 %\n",
      "Epoch:200/200 AVG Training Loss:0.668 AVG Validation Loss:0.679 AVG Training Acc 58.89 % AVG Validation Acc 53.63 %\n",
      "Split 35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "646f6e9e67d741e0baa3da4847076ca2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.459 AVG Validation Loss:4.857 AVG Training Acc 80.96 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.460 AVG Validation Loss:6.981 AVG Training Acc 80.07 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.611 AVG Validation Loss:4.613 AVG Training Acc 68.77 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.619 AVG Validation Loss:1.806 AVG Training Acc 69.24 % AVG Validation Acc 20.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.473 AVG Validation Loss:6.549 AVG Training Acc 83.51 % AVG Validation Acc 20.16 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.671 AVG Validation Loss:1.437 AVG Training Acc 64.52 % AVG Validation Acc 20.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.670 AVG Validation Loss:1.215 AVG Training Acc 61.41 % AVG Validation Acc 20.30 %\n",
      "Epoch:80/200 AVG Training Loss:0.615 AVG Validation Loss:1.541 AVG Training Acc 66.48 % AVG Validation Acc 20.83 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.681 AVG Validation Loss:0.731 AVG Training Acc 57.77 % AVG Validation Acc 46.77 %\n",
      "Epoch:100/200 AVG Training Loss:0.675 AVG Validation Loss:0.708 AVG Training Acc 59.07 % AVG Validation Acc 50.94 %\n",
      "Epoch:110/200 AVG Training Loss:0.673 AVG Validation Loss:0.703 AVG Training Acc 59.35 % AVG Validation Acc 54.30 %\n",
      "Epoch:120/200 AVG Training Loss:0.669 AVG Validation Loss:0.702 AVG Training Acc 60.07 % AVG Validation Acc 55.78 %\n",
      "Epoch:130/200 AVG Training Loss:0.667 AVG Validation Loss:0.700 AVG Training Acc 59.94 % AVG Validation Acc 55.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.669 AVG Validation Loss:0.702 AVG Training Acc 60.11 % AVG Validation Acc 56.18 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.664 AVG Validation Loss:0.692 AVG Training Acc 60.62 % AVG Validation Acc 56.72 %\n",
      "Epoch:160/200 AVG Training Loss:0.662 AVG Validation Loss:0.684 AVG Training Acc 60.64 % AVG Validation Acc 57.66 %\n",
      "Epoch:170/200 AVG Training Loss:0.663 AVG Validation Loss:0.680 AVG Training Acc 60.38 % AVG Validation Acc 57.93 %\n",
      "Epoch:180/200 AVG Training Loss:0.662 AVG Validation Loss:0.677 AVG Training Acc 60.70 % AVG Validation Acc 58.60 %\n",
      "Epoch:190/200 AVG Training Loss:0.663 AVG Validation Loss:0.674 AVG Training Acc 60.51 % AVG Validation Acc 58.74 %\n",
      "Epoch:200/200 AVG Training Loss:0.663 AVG Validation Loss:0.673 AVG Training Acc 60.65 % AVG Validation Acc 59.01 %\n",
      "Split 36\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66dca2f26018429db0c547c329d84060",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.509 AVG Validation Loss:7.275 AVG Training Acc 80.44 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.615 AVG Validation Loss:2.332 AVG Training Acc 68.62 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.662 AVG Validation Loss:4.225 AVG Training Acc 81.34 % AVG Validation Acc 20.16 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.703 AVG Validation Loss:1.168 AVG Training Acc 59.60 % AVG Validation Acc 20.30 %\n",
      "Epoch:50/200 AVG Training Loss:0.663 AVG Validation Loss:1.171 AVG Training Acc 63.37 % AVG Validation Acc 21.24 %\n",
      "Epoch:60/200 AVG Training Loss:0.649 AVG Validation Loss:1.232 AVG Training Acc 64.72 % AVG Validation Acc 21.37 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.674 AVG Validation Loss:0.738 AVG Training Acc 58.34 % AVG Validation Acc 42.07 %\n",
      "Epoch:80/200 AVG Training Loss:0.670 AVG Validation Loss:0.705 AVG Training Acc 59.53 % AVG Validation Acc 47.85 %\n",
      "Epoch:90/200 AVG Training Loss:0.666 AVG Validation Loss:0.710 AVG Training Acc 60.17 % AVG Validation Acc 50.54 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.665 AVG Validation Loss:0.700 AVG Training Acc 60.34 % AVG Validation Acc 51.21 %\n",
      "Epoch:110/200 AVG Training Loss:0.661 AVG Validation Loss:0.691 AVG Training Acc 60.88 % AVG Validation Acc 54.17 %\n",
      "Epoch:120/200 AVG Training Loss:0.661 AVG Validation Loss:0.685 AVG Training Acc 61.13 % AVG Validation Acc 55.11 %\n",
      "Epoch:130/200 AVG Training Loss:0.660 AVG Validation Loss:0.683 AVG Training Acc 60.96 % AVG Validation Acc 55.91 %\n",
      "Epoch:140/200 AVG Training Loss:0.662 AVG Validation Loss:0.680 AVG Training Acc 61.50 % AVG Validation Acc 56.05 %\n",
      "Epoch:150/200 AVG Training Loss:0.661 AVG Validation Loss:0.679 AVG Training Acc 61.09 % AVG Validation Acc 56.45 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.662 AVG Validation Loss:0.679 AVG Training Acc 61.69 % AVG Validation Acc 56.45 %\n",
      "Epoch:170/200 AVG Training Loss:0.661 AVG Validation Loss:0.677 AVG Training Acc 61.25 % AVG Validation Acc 56.72 %\n",
      "Epoch:180/200 AVG Training Loss:0.660 AVG Validation Loss:0.677 AVG Training Acc 61.00 % AVG Validation Acc 56.45 %\n",
      "Epoch   186: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.660 AVG Validation Loss:0.677 AVG Training Acc 61.27 % AVG Validation Acc 56.99 %\n",
      "Epoch:200/200 AVG Training Loss:0.661 AVG Validation Loss:0.680 AVG Training Acc 60.84 % AVG Validation Acc 56.85 %\n",
      "Split 37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfba607595b24bfc833bd6624b42130c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.572 AVG Validation Loss:4.377 AVG Training Acc 75.84 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.496 AVG Validation Loss:6.569 AVG Training Acc 83.16 % AVG Validation Acc 20.05 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.685 AVG Validation Loss:1.298 AVG Training Acc 54.13 % AVG Validation Acc 22.61 %\n",
      "Epoch:40/200 AVG Training Loss:0.634 AVG Validation Loss:0.965 AVG Training Acc 66.26 % AVG Validation Acc 21.67 %\n",
      "Epoch:50/200 AVG Training Loss:0.626 AVG Validation Loss:1.192 AVG Training Acc 67.32 % AVG Validation Acc 22.21 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.692 AVG Validation Loss:0.812 AVG Training Acc 53.65 % AVG Validation Acc 27.32 %\n",
      "Epoch:70/200 AVG Training Loss:0.664 AVG Validation Loss:0.719 AVG Training Acc 60.35 % AVG Validation Acc 54.10 %\n",
      "Epoch:80/200 AVG Training Loss:0.661 AVG Validation Loss:0.712 AVG Training Acc 60.90 % AVG Validation Acc 55.45 %\n",
      "Epoch:90/200 AVG Training Loss:0.662 AVG Validation Loss:0.714 AVG Training Acc 61.39 % AVG Validation Acc 54.10 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.656 AVG Validation Loss:0.707 AVG Training Acc 61.01 % AVG Validation Acc 54.64 %\n",
      "Epoch:110/200 AVG Training Loss:0.656 AVG Validation Loss:0.695 AVG Training Acc 61.81 % AVG Validation Acc 56.80 %\n",
      "Epoch:120/200 AVG Training Loss:0.656 AVG Validation Loss:0.690 AVG Training Acc 61.87 % AVG Validation Acc 57.20 %\n",
      "Epoch:130/200 AVG Training Loss:0.652 AVG Validation Loss:0.687 AVG Training Acc 61.90 % AVG Validation Acc 58.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.655 AVG Validation Loss:0.684 AVG Training Acc 61.60 % AVG Validation Acc 58.41 %\n",
      "Epoch:150/200 AVG Training Loss:0.655 AVG Validation Loss:0.683 AVG Training Acc 61.67 % AVG Validation Acc 57.87 %\n",
      "Epoch:160/200 AVG Training Loss:0.653 AVG Validation Loss:0.682 AVG Training Acc 62.25 % AVG Validation Acc 58.68 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:170/200 AVG Training Loss:0.655 AVG Validation Loss:0.684 AVG Training Acc 62.25 % AVG Validation Acc 58.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.653 AVG Validation Loss:0.683 AVG Training Acc 61.83 % AVG Validation Acc 58.28 %\n",
      "Epoch:190/200 AVG Training Loss:0.654 AVG Validation Loss:0.682 AVG Training Acc 61.71 % AVG Validation Acc 57.87 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:200/200 AVG Training Loss:0.654 AVG Validation Loss:0.681 AVG Training Acc 61.79 % AVG Validation Acc 58.68 %\n",
      "Split 38\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cf77be4a81b49b3b269ce361cb190ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.434 AVG Validation Loss:5.688 AVG Training Acc 83.41 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.496 AVG Validation Loss:4.818 AVG Training Acc 80.47 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.635 AVG Validation Loss:1.755 AVG Training Acc 68.20 % AVG Validation Acc 20.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.642 AVG Validation Loss:5.260 AVG Training Acc 74.34 % AVG Validation Acc 20.05 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.950 AVG Validation Loss:1.201 AVG Training Acc 50.20 % AVG Validation Acc 20.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.681 AVG Validation Loss:0.744 AVG Training Acc 56.72 % AVG Validation Acc 36.07 %\n",
      "Epoch:70/200 AVG Training Loss:0.675 AVG Validation Loss:0.746 AVG Training Acc 58.03 % AVG Validation Acc 42.40 %\n",
      "Epoch:80/200 AVG Training Loss:0.671 AVG Validation Loss:0.747 AVG Training Acc 59.53 % AVG Validation Acc 49.26 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.669 AVG Validation Loss:0.698 AVG Training Acc 58.74 % AVG Validation Acc 58.82 %\n",
      "Epoch:100/200 AVG Training Loss:0.666 AVG Validation Loss:0.679 AVG Training Acc 60.28 % AVG Validation Acc 61.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.666 AVG Validation Loss:0.671 AVG Training Acc 60.42 % AVG Validation Acc 62.45 %\n",
      "Epoch:120/200 AVG Training Loss:0.666 AVG Validation Loss:0.668 AVG Training Acc 60.43 % AVG Validation Acc 62.58 %\n",
      "Epoch:130/200 AVG Training Loss:0.665 AVG Validation Loss:0.667 AVG Training Acc 60.96 % AVG Validation Acc 62.85 %\n",
      "Epoch:140/200 AVG Training Loss:0.664 AVG Validation Loss:0.666 AVG Training Acc 60.96 % AVG Validation Acc 62.99 %\n",
      "Epoch   148: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.661 AVG Validation Loss:0.666 AVG Training Acc 61.38 % AVG Validation Acc 62.85 %\n",
      "Epoch:160/200 AVG Training Loss:0.662 AVG Validation Loss:0.665 AVG Training Acc 61.40 % AVG Validation Acc 63.12 %\n",
      "Epoch:170/200 AVG Training Loss:0.663 AVG Validation Loss:0.664 AVG Training Acc 61.04 % AVG Validation Acc 63.26 %\n",
      "Epoch:180/200 AVG Training Loss:0.662 AVG Validation Loss:0.664 AVG Training Acc 61.17 % AVG Validation Acc 63.26 %\n",
      "Epoch:190/200 AVG Training Loss:0.663 AVG Validation Loss:0.663 AVG Training Acc 60.76 % AVG Validation Acc 63.53 %\n",
      "Epoch:200/200 AVG Training Loss:0.660 AVG Validation Loss:0.662 AVG Training Acc 61.21 % AVG Validation Acc 63.39 %\n",
      "Split 39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4f2412f97f349f0abb482523b471356",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.524 AVG Validation Loss:4.709 AVG Training Acc 78.25 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.504 AVG Validation Loss:3.962 AVG Training Acc 80.62 % AVG Validation Acc 20.05 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.704 AVG Validation Loss:0.876 AVG Training Acc 52.35 % AVG Validation Acc 20.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.569 AVG Validation Loss:1.579 AVG Training Acc 75.44 % AVG Validation Acc 21.40 %\n",
      "Epoch:50/200 AVG Training Loss:0.686 AVG Validation Loss:0.967 AVG Training Acc 57.64 % AVG Validation Acc 23.69 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.677 AVG Validation Loss:0.724 AVG Training Acc 57.79 % AVG Validation Acc 48.99 %\n",
      "Epoch:70/200 AVG Training Loss:0.672 AVG Validation Loss:0.711 AVG Training Acc 58.82 % AVG Validation Acc 51.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.671 AVG Validation Loss:0.707 AVG Training Acc 58.75 % AVG Validation Acc 51.28 %\n",
      "Epoch:90/200 AVG Training Loss:0.669 AVG Validation Loss:0.704 AVG Training Acc 59.00 % AVG Validation Acc 51.41 %\n",
      "Epoch:100/200 AVG Training Loss:0.670 AVG Validation Loss:0.705 AVG Training Acc 59.04 % AVG Validation Acc 51.41 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.668 AVG Validation Loss:0.699 AVG Training Acc 59.59 % AVG Validation Acc 53.30 %\n",
      "Epoch:120/200 AVG Training Loss:0.668 AVG Validation Loss:0.693 AVG Training Acc 58.98 % AVG Validation Acc 54.37 %\n",
      "Epoch:130/200 AVG Training Loss:0.666 AVG Validation Loss:0.690 AVG Training Acc 59.64 % AVG Validation Acc 54.91 %\n",
      "Epoch:140/200 AVG Training Loss:0.665 AVG Validation Loss:0.690 AVG Training Acc 60.13 % AVG Validation Acc 54.91 %\n",
      "Epoch:150/200 AVG Training Loss:0.666 AVG Validation Loss:0.687 AVG Training Acc 59.49 % AVG Validation Acc 55.59 %\n",
      "Epoch:160/200 AVG Training Loss:0.666 AVG Validation Loss:0.686 AVG Training Acc 59.62 % AVG Validation Acc 55.32 %\n",
      "Epoch:170/200 AVG Training Loss:0.665 AVG Validation Loss:0.686 AVG Training Acc 59.71 % AVG Validation Acc 55.05 %\n",
      "Epoch   177: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:180/200 AVG Training Loss:0.668 AVG Validation Loss:0.687 AVG Training Acc 59.82 % AVG Validation Acc 54.64 %\n",
      "Epoch:190/200 AVG Training Loss:0.666 AVG Validation Loss:0.684 AVG Training Acc 59.35 % AVG Validation Acc 55.59 %\n",
      "Epoch:200/200 AVG Training Loss:0.667 AVG Validation Loss:0.686 AVG Training Acc 59.90 % AVG Validation Acc 54.91 %\n",
      "Split 40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e980675178eb4482a78bbc3bdafcd971",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.559 AVG Validation Loss:3.310 AVG Training Acc 78.62 % AVG Validation Acc 20.19 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:1.372 AVG Validation Loss:1.236 AVG Training Acc 50.00 % AVG Validation Acc 20.19 %\n",
      "Epoch:30/200 AVG Training Loss:0.693 AVG Validation Loss:0.790 AVG Training Acc 52.07 % AVG Validation Acc 21.94 %\n",
      "Epoch:40/200 AVG Training Loss:0.680 AVG Validation Loss:0.811 AVG Training Acc 56.64 % AVG Validation Acc 33.38 %\n",
      "Epoch:50/200 AVG Training Loss:0.675 AVG Validation Loss:0.802 AVG Training Acc 58.57 % AVG Validation Acc 37.42 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.670 AVG Validation Loss:0.704 AVG Training Acc 60.01 % AVG Validation Acc 54.91 %\n",
      "Epoch:70/200 AVG Training Loss:0.668 AVG Validation Loss:0.683 AVG Training Acc 60.59 % AVG Validation Acc 59.22 %\n",
      "Epoch:80/200 AVG Training Loss:0.666 AVG Validation Loss:0.679 AVG Training Acc 60.95 % AVG Validation Acc 59.89 %\n",
      "Epoch:90/200 AVG Training Loss:0.665 AVG Validation Loss:0.676 AVG Training Acc 60.77 % AVG Validation Acc 60.16 %\n",
      "Epoch:100/200 AVG Training Loss:0.665 AVG Validation Loss:0.676 AVG Training Acc 60.88 % AVG Validation Acc 59.62 %\n",
      "Epoch:110/200 AVG Training Loss:0.663 AVG Validation Loss:0.677 AVG Training Acc 61.33 % AVG Validation Acc 59.35 %\n",
      "Epoch   110: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.661 AVG Validation Loss:0.675 AVG Training Acc 60.84 % AVG Validation Acc 59.76 %\n",
      "Epoch:130/200 AVG Training Loss:0.662 AVG Validation Loss:0.673 AVG Training Acc 60.87 % AVG Validation Acc 60.43 %\n",
      "Epoch:140/200 AVG Training Loss:0.661 AVG Validation Loss:0.672 AVG Training Acc 60.88 % AVG Validation Acc 60.57 %\n",
      "Epoch:150/200 AVG Training Loss:0.662 AVG Validation Loss:0.671 AVG Training Acc 60.81 % AVG Validation Acc 60.70 %\n",
      "Epoch:160/200 AVG Training Loss:0.662 AVG Validation Loss:0.670 AVG Training Acc 61.13 % AVG Validation Acc 60.97 %\n",
      "Epoch:170/200 AVG Training Loss:0.661 AVG Validation Loss:0.669 AVG Training Acc 61.16 % AVG Validation Acc 60.97 %\n",
      "Epoch:180/200 AVG Training Loss:0.662 AVG Validation Loss:0.669 AVG Training Acc 61.35 % AVG Validation Acc 60.97 %\n",
      "Epoch:190/200 AVG Training Loss:0.660 AVG Validation Loss:0.668 AVG Training Acc 61.20 % AVG Validation Acc 60.97 %\n",
      "Epoch:200/200 AVG Training Loss:0.661 AVG Validation Loss:0.668 AVG Training Acc 61.34 % AVG Validation Acc 61.24 %\n",
      "Split 41\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa4d643048f0451e8507e831070657e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.547 AVG Validation Loss:3.912 AVG Training Acc 78.10 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.579 AVG Validation Loss:2.935 AVG Training Acc 77.96 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.653 AVG Validation Loss:1.632 AVG Training Acc 66.16 % AVG Validation Acc 20.16 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.700 AVG Validation Loss:0.900 AVG Training Acc 54.60 % AVG Validation Acc 20.30 %\n",
      "Epoch:50/200 AVG Training Loss:0.689 AVG Validation Loss:0.865 AVG Training Acc 55.28 % AVG Validation Acc 21.24 %\n",
      "Epoch:60/200 AVG Training Loss:0.680 AVG Validation Loss:0.907 AVG Training Acc 57.48 % AVG Validation Acc 22.85 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.683 AVG Validation Loss:0.766 AVG Training Acc 55.89 % AVG Validation Acc 41.94 %\n",
      "Epoch:80/200 AVG Training Loss:0.671 AVG Validation Loss:0.702 AVG Training Acc 59.17 % AVG Validation Acc 56.05 %\n",
      "Epoch:90/200 AVG Training Loss:0.667 AVG Validation Loss:0.691 AVG Training Acc 59.55 % AVG Validation Acc 57.53 %\n",
      "Epoch:100/200 AVG Training Loss:0.668 AVG Validation Loss:0.691 AVG Training Acc 59.64 % AVG Validation Acc 57.26 %\n",
      "Epoch:110/200 AVG Training Loss:0.666 AVG Validation Loss:0.689 AVG Training Acc 59.61 % AVG Validation Acc 57.39 %\n",
      "Epoch:120/200 AVG Training Loss:0.668 AVG Validation Loss:0.688 AVG Training Acc 59.75 % AVG Validation Acc 57.53 %\n",
      "Epoch:130/200 AVG Training Loss:0.665 AVG Validation Loss:0.687 AVG Training Acc 59.79 % AVG Validation Acc 57.39 %\n",
      "Epoch:140/200 AVG Training Loss:0.665 AVG Validation Loss:0.688 AVG Training Acc 60.02 % AVG Validation Acc 57.26 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.663 AVG Validation Loss:0.685 AVG Training Acc 60.49 % AVG Validation Acc 57.93 %\n",
      "Epoch:160/200 AVG Training Loss:0.664 AVG Validation Loss:0.682 AVG Training Acc 60.72 % AVG Validation Acc 58.47 %\n",
      "Epoch:170/200 AVG Training Loss:0.664 AVG Validation Loss:0.680 AVG Training Acc 60.55 % AVG Validation Acc 58.87 %\n",
      "Epoch:180/200 AVG Training Loss:0.665 AVG Validation Loss:0.678 AVG Training Acc 60.65 % AVG Validation Acc 59.01 %\n",
      "Epoch:190/200 AVG Training Loss:0.663 AVG Validation Loss:0.677 AVG Training Acc 60.72 % AVG Validation Acc 59.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.665 AVG Validation Loss:0.676 AVG Training Acc 60.36 % AVG Validation Acc 59.27 %\n",
      "Split 42\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0867ec12d2641afa3d79959469aaa96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.552 AVG Validation Loss:3.917 AVG Training Acc 77.76 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.581 AVG Validation Loss:5.759 AVG Training Acc 70.86 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.583 AVG Validation Loss:2.295 AVG Training Acc 76.69 % AVG Validation Acc 20.16 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.700 AVG Validation Loss:0.786 AVG Training Acc 49.93 % AVG Validation Acc 20.97 %\n",
      "Epoch:50/200 AVG Training Loss:0.693 AVG Validation Loss:0.796 AVG Training Acc 52.83 % AVG Validation Acc 21.24 %\n",
      "Epoch:60/200 AVG Training Loss:0.685 AVG Validation Loss:0.805 AVG Training Acc 55.94 % AVG Validation Acc 26.34 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.680 AVG Validation Loss:0.728 AVG Training Acc 56.10 % AVG Validation Acc 40.99 %\n",
      "Epoch:80/200 AVG Training Loss:0.676 AVG Validation Loss:0.701 AVG Training Acc 57.23 % AVG Validation Acc 48.12 %\n",
      "Epoch:90/200 AVG Training Loss:0.674 AVG Validation Loss:0.695 AVG Training Acc 58.49 % AVG Validation Acc 50.00 %\n",
      "Epoch:100/200 AVG Training Loss:0.672 AVG Validation Loss:0.693 AVG Training Acc 58.21 % AVG Validation Acc 50.54 %\n",
      "Epoch:110/200 AVG Training Loss:0.672 AVG Validation Loss:0.693 AVG Training Acc 58.47 % AVG Validation Acc 52.02 %\n",
      "Epoch:120/200 AVG Training Loss:0.670 AVG Validation Loss:0.692 AVG Training Acc 59.07 % AVG Validation Acc 52.02 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.668 AVG Validation Loss:0.692 AVG Training Acc 58.79 % AVG Validation Acc 52.55 %\n",
      "Epoch:140/200 AVG Training Loss:0.669 AVG Validation Loss:0.689 AVG Training Acc 58.98 % AVG Validation Acc 53.36 %\n",
      "Epoch:150/200 AVG Training Loss:0.670 AVG Validation Loss:0.687 AVG Training Acc 59.10 % AVG Validation Acc 53.90 %\n",
      "Epoch:160/200 AVG Training Loss:0.668 AVG Validation Loss:0.686 AVG Training Acc 59.02 % AVG Validation Acc 53.76 %\n",
      "Epoch:170/200 AVG Training Loss:0.668 AVG Validation Loss:0.684 AVG Training Acc 59.00 % AVG Validation Acc 55.38 %\n",
      "Epoch:180/200 AVG Training Loss:0.670 AVG Validation Loss:0.684 AVG Training Acc 58.90 % AVG Validation Acc 55.38 %\n",
      "Epoch:190/200 AVG Training Loss:0.668 AVG Validation Loss:0.683 AVG Training Acc 59.72 % AVG Validation Acc 55.11 %\n",
      "Epoch:200/200 AVG Training Loss:0.668 AVG Validation Loss:0.682 AVG Training Acc 59.15 % AVG Validation Acc 55.51 %\n",
      "Split 43\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4309f48f34540508da6e3409910e78d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.542 AVG Validation Loss:4.057 AVG Training Acc 79.80 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.648 AVG Validation Loss:1.629 AVG Training Acc 66.20 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.658 AVG Validation Loss:7.304 AVG Training Acc 82.05 % AVG Validation Acc 20.16 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.691 AVG Validation Loss:0.792 AVG Training Acc 52.45 % AVG Validation Acc 24.87 %\n",
      "Epoch:50/200 AVG Training Loss:0.684 AVG Validation Loss:0.787 AVG Training Acc 56.17 % AVG Validation Acc 37.37 %\n",
      "Epoch:60/200 AVG Training Loss:0.676 AVG Validation Loss:0.786 AVG Training Acc 58.63 % AVG Validation Acc 45.16 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.672 AVG Validation Loss:0.717 AVG Training Acc 59.15 % AVG Validation Acc 56.59 %\n",
      "Epoch:80/200 AVG Training Loss:0.670 AVG Validation Loss:0.685 AVG Training Acc 59.93 % AVG Validation Acc 59.01 %\n",
      "Epoch:90/200 AVG Training Loss:0.669 AVG Validation Loss:0.676 AVG Training Acc 60.37 % AVG Validation Acc 59.95 %\n",
      "Epoch:100/200 AVG Training Loss:0.668 AVG Validation Loss:0.673 AVG Training Acc 60.59 % AVG Validation Acc 60.62 %\n",
      "Epoch:110/200 AVG Training Loss:0.669 AVG Validation Loss:0.671 AVG Training Acc 60.34 % AVG Validation Acc 60.35 %\n",
      "Epoch:120/200 AVG Training Loss:0.669 AVG Validation Loss:0.671 AVG Training Acc 60.51 % AVG Validation Acc 60.75 %\n",
      "Epoch:130/200 AVG Training Loss:0.667 AVG Validation Loss:0.671 AVG Training Acc 60.06 % AVG Validation Acc 60.35 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:140/200 AVG Training Loss:0.665 AVG Validation Loss:0.670 AVG Training Acc 60.76 % AVG Validation Acc 60.08 %\n",
      "Epoch:150/200 AVG Training Loss:0.666 AVG Validation Loss:0.669 AVG Training Acc 60.95 % AVG Validation Acc 60.35 %\n",
      "Epoch:160/200 AVG Training Loss:0.664 AVG Validation Loss:0.668 AVG Training Acc 60.99 % AVG Validation Acc 60.48 %\n",
      "Epoch:170/200 AVG Training Loss:0.668 AVG Validation Loss:0.667 AVG Training Acc 60.73 % AVG Validation Acc 60.89 %\n",
      "Epoch:180/200 AVG Training Loss:0.665 AVG Validation Loss:0.666 AVG Training Acc 60.72 % AVG Validation Acc 61.02 %\n",
      "Epoch:190/200 AVG Training Loss:0.664 AVG Validation Loss:0.666 AVG Training Acc 60.75 % AVG Validation Acc 61.16 %\n",
      "Epoch:200/200 AVG Training Loss:0.665 AVG Validation Loss:0.665 AVG Training Acc 60.56 % AVG Validation Acc 61.16 %\n",
      "Split 44\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f08105beecdc4d8bbe7cb7ac786e8758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.547 AVG Validation Loss:7.468 AVG Training Acc 75.53 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.643 AVG Validation Loss:1.704 AVG Training Acc 67.44 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.633 AVG Validation Loss:1.771 AVG Training Acc 68.80 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.564 AVG Validation Loss:3.718 AVG Training Acc 80.62 % AVG Validation Acc 20.16 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.697 AVG Validation Loss:1.010 AVG Training Acc 56.58 % AVG Validation Acc 21.51 %\n",
      "Epoch:60/200 AVG Training Loss:0.675 AVG Validation Loss:0.992 AVG Training Acc 58.18 % AVG Validation Acc 21.64 %\n",
      "Epoch:70/200 AVG Training Loss:0.670 AVG Validation Loss:0.994 AVG Training Acc 60.67 % AVG Validation Acc 22.45 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.672 AVG Validation Loss:0.758 AVG Training Acc 57.80 % AVG Validation Acc 38.58 %\n",
      "Epoch:90/200 AVG Training Loss:0.668 AVG Validation Loss:0.723 AVG Training Acc 59.18 % AVG Validation Acc 44.76 %\n",
      "Epoch:100/200 AVG Training Loss:0.665 AVG Validation Loss:0.719 AVG Training Acc 59.79 % AVG Validation Acc 45.83 %\n",
      "Epoch:110/200 AVG Training Loss:0.662 AVG Validation Loss:0.720 AVG Training Acc 60.32 % AVG Validation Acc 46.64 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.661 AVG Validation Loss:0.718 AVG Training Acc 60.11 % AVG Validation Acc 48.52 %\n",
      "Epoch:130/200 AVG Training Loss:0.661 AVG Validation Loss:0.712 AVG Training Acc 60.51 % AVG Validation Acc 49.46 %\n",
      "Epoch:140/200 AVG Training Loss:0.661 AVG Validation Loss:0.710 AVG Training Acc 60.92 % AVG Validation Acc 49.73 %\n",
      "Epoch:150/200 AVG Training Loss:0.659 AVG Validation Loss:0.707 AVG Training Acc 60.97 % AVG Validation Acc 51.21 %\n",
      "Epoch:160/200 AVG Training Loss:0.659 AVG Validation Loss:0.705 AVG Training Acc 61.08 % AVG Validation Acc 52.02 %\n",
      "Epoch:170/200 AVG Training Loss:0.660 AVG Validation Loss:0.704 AVG Training Acc 60.91 % AVG Validation Acc 52.02 %\n",
      "Epoch:180/200 AVG Training Loss:0.660 AVG Validation Loss:0.702 AVG Training Acc 60.33 % AVG Validation Acc 52.42 %\n",
      "Epoch:190/200 AVG Training Loss:0.660 AVG Validation Loss:0.703 AVG Training Acc 61.03 % AVG Validation Acc 52.69 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:200/200 AVG Training Loss:0.661 AVG Validation Loss:0.703 AVG Training Acc 60.26 % AVG Validation Acc 52.55 %\n",
      "Split 45\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d32a051ac88d4828832362932cd17e86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.451 AVG Validation Loss:3.701 AVG Training Acc 83.26 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.478 AVG Validation Loss:6.690 AVG Training Acc 82.55 % AVG Validation Acc 20.30 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.868 AVG Validation Loss:1.116 AVG Training Acc 62.12 % AVG Validation Acc 24.60 %\n",
      "Epoch:40/200 AVG Training Loss:0.700 AVG Validation Loss:0.828 AVG Training Acc 52.84 % AVG Validation Acc 25.00 %\n",
      "Epoch:50/200 AVG Training Loss:0.697 AVG Validation Loss:0.847 AVG Training Acc 53.82 % AVG Validation Acc 27.69 %\n",
      "Epoch:60/200 AVG Training Loss:0.686 AVG Validation Loss:0.850 AVG Training Acc 57.21 % AVG Validation Acc 26.75 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.675 AVG Validation Loss:0.720 AVG Training Acc 58.02 % AVG Validation Acc 49.33 %\n",
      "Epoch:80/200 AVG Training Loss:0.672 AVG Validation Loss:0.698 AVG Training Acc 59.06 % AVG Validation Acc 52.82 %\n",
      "Epoch:90/200 AVG Training Loss:0.670 AVG Validation Loss:0.700 AVG Training Acc 59.43 % AVG Validation Acc 53.09 %\n",
      "Epoch:100/200 AVG Training Loss:0.668 AVG Validation Loss:0.697 AVG Training Acc 59.75 % AVG Validation Acc 53.63 %\n",
      "Epoch:110/200 AVG Training Loss:0.669 AVG Validation Loss:0.694 AVG Training Acc 59.93 % AVG Validation Acc 54.70 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.666 AVG Validation Loss:0.694 AVG Training Acc 60.19 % AVG Validation Acc 53.90 %\n",
      "Epoch:130/200 AVG Training Loss:0.664 AVG Validation Loss:0.688 AVG Training Acc 59.97 % AVG Validation Acc 55.24 %\n",
      "Epoch:140/200 AVG Training Loss:0.666 AVG Validation Loss:0.685 AVG Training Acc 59.72 % AVG Validation Acc 55.51 %\n",
      "Epoch:150/200 AVG Training Loss:0.667 AVG Validation Loss:0.681 AVG Training Acc 59.82 % AVG Validation Acc 57.12 %\n",
      "Epoch:160/200 AVG Training Loss:0.664 AVG Validation Loss:0.681 AVG Training Acc 59.93 % AVG Validation Acc 57.12 %\n",
      "Epoch:170/200 AVG Training Loss:0.663 AVG Validation Loss:0.678 AVG Training Acc 60.32 % AVG Validation Acc 57.12 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:180/200 AVG Training Loss:0.664 AVG Validation Loss:0.680 AVG Training Acc 60.13 % AVG Validation Acc 57.53 %\n",
      "Epoch:190/200 AVG Training Loss:0.665 AVG Validation Loss:0.679 AVG Training Acc 60.23 % AVG Validation Acc 57.26 %\n",
      "Epoch:200/200 AVG Training Loss:0.663 AVG Validation Loss:0.680 AVG Training Acc 59.93 % AVG Validation Acc 57.39 %\n",
      "Split 46\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e7eb0e4ca434755af36c200e5d6d93a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.567 AVG Validation Loss:3.167 AVG Training Acc 77.32 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.567 AVG Validation Loss:6.804 AVG Training Acc 72.54 % AVG Validation Acc 20.16 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:1.255 AVG Validation Loss:1.323 AVG Training Acc 50.00 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.701 AVG Validation Loss:0.808 AVG Training Acc 50.51 % AVG Validation Acc 20.70 %\n",
      "Epoch:50/200 AVG Training Loss:0.689 AVG Validation Loss:0.810 AVG Training Acc 54.72 % AVG Validation Acc 20.97 %\n",
      "Epoch:60/200 AVG Training Loss:0.680 AVG Validation Loss:0.825 AVG Training Acc 57.44 % AVG Validation Acc 20.97 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.673 AVG Validation Loss:0.698 AVG Training Acc 58.44 % AVG Validation Acc 56.45 %\n",
      "Epoch:80/200 AVG Training Loss:0.670 AVG Validation Loss:0.673 AVG Training Acc 59.06 % AVG Validation Acc 59.27 %\n",
      "Epoch:90/200 AVG Training Loss:0.669 AVG Validation Loss:0.669 AVG Training Acc 59.58 % AVG Validation Acc 60.08 %\n",
      "Epoch:100/200 AVG Training Loss:0.669 AVG Validation Loss:0.668 AVG Training Acc 59.42 % AVG Validation Acc 60.35 %\n",
      "Epoch:110/200 AVG Training Loss:0.669 AVG Validation Loss:0.668 AVG Training Acc 59.54 % AVG Validation Acc 59.95 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.666 AVG Validation Loss:0.666 AVG Training Acc 59.67 % AVG Validation Acc 60.89 %\n",
      "Epoch:130/200 AVG Training Loss:0.666 AVG Validation Loss:0.664 AVG Training Acc 59.64 % AVG Validation Acc 60.75 %\n",
      "Epoch:140/200 AVG Training Loss:0.666 AVG Validation Loss:0.662 AVG Training Acc 60.02 % AVG Validation Acc 61.16 %\n",
      "Epoch:150/200 AVG Training Loss:0.666 AVG Validation Loss:0.661 AVG Training Acc 59.84 % AVG Validation Acc 61.56 %\n",
      "Epoch:160/200 AVG Training Loss:0.666 AVG Validation Loss:0.660 AVG Training Acc 60.06 % AVG Validation Acc 61.42 %\n",
      "Epoch:170/200 AVG Training Loss:0.666 AVG Validation Loss:0.659 AVG Training Acc 59.74 % AVG Validation Acc 61.83 %\n",
      "Epoch:180/200 AVG Training Loss:0.667 AVG Validation Loss:0.658 AVG Training Acc 59.87 % AVG Validation Acc 62.37 %\n",
      "Epoch:190/200 AVG Training Loss:0.665 AVG Validation Loss:0.658 AVG Training Acc 59.72 % AVG Validation Acc 62.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.666 AVG Validation Loss:0.657 AVG Training Acc 59.45 % AVG Validation Acc 62.50 %\n",
      "Split 47\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4326cf175f8249049346e9677d9b14df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.553 AVG Validation Loss:5.084 AVG Training Acc 77.52 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.609 AVG Validation Loss:7.141 AVG Training Acc 70.78 % AVG Validation Acc 20.05 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.762 AVG Validation Loss:0.946 AVG Training Acc 50.98 % AVG Validation Acc 20.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.691 AVG Validation Loss:0.888 AVG Training Acc 54.60 % AVG Validation Acc 21.53 %\n",
      "Epoch:50/200 AVG Training Loss:0.683 AVG Validation Loss:0.949 AVG Training Acc 57.37 % AVG Validation Acc 21.27 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.782 AVG Validation Loss:0.985 AVG Training Acc 51.22 % AVG Validation Acc 21.00 %\n",
      "Epoch:70/200 AVG Training Loss:0.673 AVG Validation Loss:0.722 AVG Training Acc 57.17 % AVG Validation Acc 49.80 %\n",
      "Epoch:80/200 AVG Training Loss:0.670 AVG Validation Loss:0.703 AVG Training Acc 58.78 % AVG Validation Acc 55.18 %\n",
      "Epoch:90/200 AVG Training Loss:0.664 AVG Validation Loss:0.694 AVG Training Acc 59.95 % AVG Validation Acc 55.85 %\n",
      "Epoch:100/200 AVG Training Loss:0.663 AVG Validation Loss:0.690 AVG Training Acc 60.78 % AVG Validation Acc 56.39 %\n",
      "Epoch:110/200 AVG Training Loss:0.660 AVG Validation Loss:0.689 AVG Training Acc 60.47 % AVG Validation Acc 56.39 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.659 AVG Validation Loss:0.688 AVG Training Acc 61.17 % AVG Validation Acc 56.26 %\n",
      "Epoch:130/200 AVG Training Loss:0.656 AVG Validation Loss:0.679 AVG Training Acc 61.45 % AVG Validation Acc 58.01 %\n",
      "Epoch:140/200 AVG Training Loss:0.656 AVG Validation Loss:0.673 AVG Training Acc 61.22 % AVG Validation Acc 58.41 %\n",
      "Epoch:150/200 AVG Training Loss:0.656 AVG Validation Loss:0.671 AVG Training Acc 61.24 % AVG Validation Acc 58.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.657 AVG Validation Loss:0.667 AVG Training Acc 61.28 % AVG Validation Acc 59.35 %\n",
      "Epoch:170/200 AVG Training Loss:0.656 AVG Validation Loss:0.665 AVG Training Acc 61.06 % AVG Validation Acc 59.35 %\n",
      "Epoch:180/200 AVG Training Loss:0.654 AVG Validation Loss:0.664 AVG Training Acc 61.61 % AVG Validation Acc 59.62 %\n",
      "Epoch:190/200 AVG Training Loss:0.655 AVG Validation Loss:0.662 AVG Training Acc 61.46 % AVG Validation Acc 59.89 %\n",
      "Epoch:200/200 AVG Training Loss:0.654 AVG Validation Loss:0.662 AVG Training Acc 62.07 % AVG Validation Acc 59.49 %\n",
      "Split 48\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9fbead8e83b4453cbac76ce7b21ee430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.500 AVG Validation Loss:7.725 AVG Training Acc 81.95 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.562 AVG Validation Loss:4.960 AVG Training Acc 82.28 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.530 AVG Validation Loss:4.008 AVG Training Acc 79.88 % AVG Validation Acc 20.05 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.709 AVG Validation Loss:0.816 AVG Training Acc 48.46 % AVG Validation Acc 20.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.695 AVG Validation Loss:0.787 AVG Training Acc 52.12 % AVG Validation Acc 25.44 %\n",
      "Epoch:60/200 AVG Training Loss:0.681 AVG Validation Loss:0.810 AVG Training Acc 56.93 % AVG Validation Acc 32.17 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.684 AVG Validation Loss:0.767 AVG Training Acc 55.43 % AVG Validation Acc 37.69 %\n",
      "Epoch:80/200 AVG Training Loss:0.672 AVG Validation Loss:0.713 AVG Training Acc 58.71 % AVG Validation Acc 53.84 %\n",
      "Epoch:90/200 AVG Training Loss:0.669 AVG Validation Loss:0.698 AVG Training Acc 59.58 % AVG Validation Acc 58.95 %\n",
      "Epoch:100/200 AVG Training Loss:0.669 AVG Validation Loss:0.695 AVG Training Acc 59.64 % AVG Validation Acc 60.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.669 AVG Validation Loss:0.694 AVG Training Acc 59.55 % AVG Validation Acc 60.57 %\n",
      "Epoch:120/200 AVG Training Loss:0.668 AVG Validation Loss:0.694 AVG Training Acc 59.11 % AVG Validation Acc 60.83 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.667 AVG Validation Loss:0.695 AVG Training Acc 60.08 % AVG Validation Acc 60.70 %\n",
      "Epoch:140/200 AVG Training Loss:0.666 AVG Validation Loss:0.694 AVG Training Acc 59.81 % AVG Validation Acc 60.70 %\n",
      "Epoch:150/200 AVG Training Loss:0.664 AVG Validation Loss:0.693 AVG Training Acc 59.96 % AVG Validation Acc 60.70 %\n",
      "Epoch:160/200 AVG Training Loss:0.668 AVG Validation Loss:0.692 AVG Training Acc 59.63 % AVG Validation Acc 61.24 %\n",
      "Epoch:170/200 AVG Training Loss:0.668 AVG Validation Loss:0.691 AVG Training Acc 60.00 % AVG Validation Acc 61.37 %\n",
      "Epoch:180/200 AVG Training Loss:0.667 AVG Validation Loss:0.690 AVG Training Acc 60.12 % AVG Validation Acc 61.37 %\n",
      "Epoch:190/200 AVG Training Loss:0.666 AVG Validation Loss:0.690 AVG Training Acc 60.13 % AVG Validation Acc 61.64 %\n",
      "Epoch:200/200 AVG Training Loss:0.666 AVG Validation Loss:0.689 AVG Training Acc 59.94 % AVG Validation Acc 61.64 %\n",
      "Split 49\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b3e8ab91ed44a5e82103a034172d9d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.498 AVG Validation Loss:7.922 AVG Training Acc 78.96 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.635 AVG Validation Loss:2.270 AVG Training Acc 66.81 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.597 AVG Validation Loss:1.985 AVG Training Acc 76.56 % AVG Validation Acc 20.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:1.976 AVG Training Acc 64.34 % AVG Validation Acc 20.05 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:2.553 AVG Validation Loss:3.064 AVG Training Acc 60.16 % AVG Validation Acc 20.46 %\n",
      "Epoch:60/200 AVG Training Loss:0.654 AVG Validation Loss:1.200 AVG Training Acc 63.63 % AVG Validation Acc 20.19 %\n",
      "Epoch:70/200 AVG Training Loss:0.650 AVG Validation Loss:1.165 AVG Training Acc 62.97 % AVG Validation Acc 20.59 %\n",
      "Epoch:80/200 AVG Training Loss:0.634 AVG Validation Loss:1.178 AVG Training Acc 65.02 % AVG Validation Acc 20.86 %\n",
      "Epoch:90/200 AVG Training Loss:0.627 AVG Validation Loss:1.170 AVG Training Acc 64.75 % AVG Validation Acc 21.40 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.713 AVG Validation Loss:0.864 AVG Training Acc 55.94 % AVG Validation Acc 32.17 %\n",
      "Epoch:110/200 AVG Training Loss:0.633 AVG Validation Loss:0.695 AVG Training Acc 63.05 % AVG Validation Acc 50.61 %\n",
      "Epoch:120/200 AVG Training Loss:0.634 AVG Validation Loss:0.692 AVG Training Acc 63.05 % AVG Validation Acc 50.47 %\n",
      "Epoch:130/200 AVG Training Loss:0.628 AVG Validation Loss:0.689 AVG Training Acc 63.70 % AVG Validation Acc 51.01 %\n",
      "Epoch:140/200 AVG Training Loss:0.627 AVG Validation Loss:0.686 AVG Training Acc 63.59 % AVG Validation Acc 51.41 %\n",
      "Epoch:150/200 AVG Training Loss:0.623 AVG Validation Loss:0.690 AVG Training Acc 63.84 % AVG Validation Acc 51.01 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:160/200 AVG Training Loss:0.621 AVG Validation Loss:0.679 AVG Training Acc 64.51 % AVG Validation Acc 52.62 %\n",
      "Epoch:170/200 AVG Training Loss:0.622 AVG Validation Loss:0.675 AVG Training Acc 64.12 % AVG Validation Acc 52.89 %\n",
      "Epoch:180/200 AVG Training Loss:0.621 AVG Validation Loss:0.671 AVG Training Acc 64.17 % AVG Validation Acc 53.03 %\n",
      "Epoch:190/200 AVG Training Loss:0.618 AVG Validation Loss:0.668 AVG Training Acc 64.19 % AVG Validation Acc 53.97 %\n",
      "Epoch:200/200 AVG Training Loss:0.619 AVG Validation Loss:0.666 AVG Training Acc 64.56 % AVG Validation Acc 53.97 %\n",
      "Split 50\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05c6411ffb9a4f87a7a911688e51b403",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.564 AVG Validation Loss:5.143 AVG Training Acc 74.78 % AVG Validation Acc 20.19 %\n",
      "Epoch:20/200 AVG Training Loss:0.557 AVG Validation Loss:8.039 AVG Training Acc 80.55 % AVG Validation Acc 20.19 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.585 AVG Validation Loss:1.783 AVG Training Acc 71.17 % AVG Validation Acc 20.19 %\n",
      "Epoch:40/200 AVG Training Loss:0.646 AVG Validation Loss:1.291 AVG Training Acc 65.38 % AVG Validation Acc 20.19 %\n",
      "Epoch:50/200 AVG Training Loss:0.663 AVG Validation Loss:1.061 AVG Training Acc 61.63 % AVG Validation Acc 20.46 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.714 AVG Validation Loss:0.836 AVG Training Acc 52.28 % AVG Validation Acc 23.15 %\n",
      "Epoch:70/200 AVG Training Loss:0.677 AVG Validation Loss:0.727 AVG Training Acc 57.13 % AVG Validation Acc 39.70 %\n",
      "Epoch:80/200 AVG Training Loss:0.672 AVG Validation Loss:0.725 AVG Training Acc 58.67 % AVG Validation Acc 40.51 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.671 AVG Validation Loss:0.722 AVG Training Acc 58.31 % AVG Validation Acc 41.59 %\n",
      "Epoch:100/200 AVG Training Loss:0.672 AVG Validation Loss:0.709 AVG Training Acc 57.89 % AVG Validation Acc 44.01 %\n",
      "Epoch:110/200 AVG Training Loss:0.670 AVG Validation Loss:0.702 AVG Training Acc 58.78 % AVG Validation Acc 46.16 %\n",
      "Epoch:120/200 AVG Training Loss:0.669 AVG Validation Loss:0.697 AVG Training Acc 59.02 % AVG Validation Acc 46.97 %\n",
      "Epoch:130/200 AVG Training Loss:0.669 AVG Validation Loss:0.694 AVG Training Acc 59.01 % AVG Validation Acc 48.59 %\n",
      "Epoch:140/200 AVG Training Loss:0.668 AVG Validation Loss:0.693 AVG Training Acc 58.85 % AVG Validation Acc 47.91 %\n",
      "Epoch:150/200 AVG Training Loss:0.669 AVG Validation Loss:0.691 AVG Training Acc 59.28 % AVG Validation Acc 48.45 %\n",
      "Epoch:160/200 AVG Training Loss:0.668 AVG Validation Loss:0.690 AVG Training Acc 58.95 % AVG Validation Acc 49.26 %\n",
      "Epoch:170/200 AVG Training Loss:0.670 AVG Validation Loss:0.690 AVG Training Acc 58.78 % AVG Validation Acc 49.26 %\n",
      "Epoch:180/200 AVG Training Loss:0.667 AVG Validation Loss:0.689 AVG Training Acc 59.24 % AVG Validation Acc 49.80 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:190/200 AVG Training Loss:0.669 AVG Validation Loss:0.690 AVG Training Acc 59.07 % AVG Validation Acc 49.93 %\n",
      "Epoch:200/200 AVG Training Loss:0.667 AVG Validation Loss:0.688 AVG Training Acc 59.02 % AVG Validation Acc 49.80 %\n",
      "Split 51\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b942961319934607ac37f991be4c26cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.555 AVG Validation Loss:5.289 AVG Training Acc 77.77 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.572 AVG Validation Loss:6.244 AVG Training Acc 78.41 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.652 AVG Validation Loss:1.581 AVG Training Acc 65.55 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.613 AVG Validation Loss:5.448 AVG Training Acc 82.32 % AVG Validation Acc 20.43 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.706 AVG Validation Loss:0.990 AVG Training Acc 56.48 % AVG Validation Acc 23.25 %\n",
      "Epoch:60/200 AVG Training Loss:0.680 AVG Validation Loss:0.922 AVG Training Acc 56.84 % AVG Validation Acc 24.19 %\n",
      "Epoch:70/200 AVG Training Loss:0.670 AVG Validation Loss:0.945 AVG Training Acc 58.43 % AVG Validation Acc 25.13 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.703 AVG Validation Loss:0.794 AVG Training Acc 54.63 % AVG Validation Acc 36.56 %\n",
      "Epoch:90/200 AVG Training Loss:0.670 AVG Validation Loss:0.690 AVG Training Acc 58.70 % AVG Validation Acc 57.12 %\n",
      "Epoch:100/200 AVG Training Loss:0.665 AVG Validation Loss:0.680 AVG Training Acc 59.78 % AVG Validation Acc 59.27 %\n",
      "Epoch:110/200 AVG Training Loss:0.666 AVG Validation Loss:0.678 AVG Training Acc 59.82 % AVG Validation Acc 60.08 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.667 AVG Validation Loss:0.678 AVG Training Acc 59.90 % AVG Validation Acc 60.08 %\n",
      "Epoch:130/200 AVG Training Loss:0.666 AVG Validation Loss:0.675 AVG Training Acc 59.57 % AVG Validation Acc 61.56 %\n",
      "Epoch:140/200 AVG Training Loss:0.664 AVG Validation Loss:0.671 AVG Training Acc 59.99 % AVG Validation Acc 62.23 %\n",
      "Epoch:150/200 AVG Training Loss:0.662 AVG Validation Loss:0.667 AVG Training Acc 60.07 % AVG Validation Acc 63.04 %\n",
      "Epoch:160/200 AVG Training Loss:0.663 AVG Validation Loss:0.669 AVG Training Acc 59.79 % AVG Validation Acc 63.17 %\n",
      "Epoch:170/200 AVG Training Loss:0.662 AVG Validation Loss:0.670 AVG Training Acc 60.43 % AVG Validation Acc 63.17 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:180/200 AVG Training Loss:0.662 AVG Validation Loss:0.667 AVG Training Acc 60.03 % AVG Validation Acc 63.98 %\n",
      "Epoch:190/200 AVG Training Loss:0.663 AVG Validation Loss:0.667 AVG Training Acc 60.14 % AVG Validation Acc 63.58 %\n",
      "Epoch:200/200 AVG Training Loss:0.662 AVG Validation Loss:0.669 AVG Training Acc 60.27 % AVG Validation Acc 63.17 %\n",
      "Split 52\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4266b69e47434521b10575331dc94ac9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.510 AVG Validation Loss:5.375 AVG Training Acc 79.37 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.623 AVG Validation Loss:2.298 AVG Training Acc 78.93 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.566 AVG Validation Loss:9.792 AVG Training Acc 68.20 % AVG Validation Acc 20.43 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.688 AVG Validation Loss:0.793 AVG Training Acc 55.36 % AVG Validation Acc 24.33 %\n",
      "Epoch:50/200 AVG Training Loss:0.680 AVG Validation Loss:0.791 AVG Training Acc 57.30 % AVG Validation Acc 25.81 %\n",
      "Epoch:60/200 AVG Training Loss:0.675 AVG Validation Loss:0.794 AVG Training Acc 58.15 % AVG Validation Acc 33.33 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.671 AVG Validation Loss:0.741 AVG Training Acc 58.49 % AVG Validation Acc 46.51 %\n",
      "Epoch:80/200 AVG Training Loss:0.665 AVG Validation Loss:0.707 AVG Training Acc 60.11 % AVG Validation Acc 53.63 %\n",
      "Epoch:90/200 AVG Training Loss:0.665 AVG Validation Loss:0.696 AVG Training Acc 60.12 % AVG Validation Acc 55.51 %\n",
      "Epoch:100/200 AVG Training Loss:0.664 AVG Validation Loss:0.693 AVG Training Acc 60.38 % AVG Validation Acc 56.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.662 AVG Validation Loss:0.692 AVG Training Acc 60.22 % AVG Validation Acc 56.99 %\n",
      "Epoch:120/200 AVG Training Loss:0.664 AVG Validation Loss:0.691 AVG Training Acc 60.33 % AVG Validation Acc 56.72 %\n",
      "Epoch:130/200 AVG Training Loss:0.663 AVG Validation Loss:0.692 AVG Training Acc 60.66 % AVG Validation Acc 56.45 %\n",
      "Epoch   136: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:140/200 AVG Training Loss:0.662 AVG Validation Loss:0.690 AVG Training Acc 60.72 % AVG Validation Acc 56.85 %\n",
      "Epoch:150/200 AVG Training Loss:0.660 AVG Validation Loss:0.689 AVG Training Acc 61.06 % AVG Validation Acc 56.99 %\n",
      "Epoch:160/200 AVG Training Loss:0.662 AVG Validation Loss:0.688 AVG Training Acc 61.08 % AVG Validation Acc 57.12 %\n",
      "Epoch:170/200 AVG Training Loss:0.661 AVG Validation Loss:0.688 AVG Training Acc 61.07 % AVG Validation Acc 57.26 %\n",
      "Epoch:180/200 AVG Training Loss:0.662 AVG Validation Loss:0.687 AVG Training Acc 60.32 % AVG Validation Acc 57.39 %\n",
      "Epoch:190/200 AVG Training Loss:0.662 AVG Validation Loss:0.686 AVG Training Acc 60.73 % AVG Validation Acc 57.53 %\n",
      "Epoch:200/200 AVG Training Loss:0.662 AVG Validation Loss:0.686 AVG Training Acc 60.80 % AVG Validation Acc 57.53 %\n",
      "Split 53\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "104419259f0d41098c7e28c126cbdaaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.610 AVG Validation Loss:1.955 AVG Training Acc 72.38 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.619 AVG Validation Loss:1.868 AVG Training Acc 70.79 % AVG Validation Acc 20.16 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.695 AVG Validation Loss:0.849 AVG Training Acc 54.72 % AVG Validation Acc 23.39 %\n",
      "Epoch:40/200 AVG Training Loss:0.683 AVG Validation Loss:0.808 AVG Training Acc 57.71 % AVG Validation Acc 27.15 %\n",
      "Epoch:50/200 AVG Training Loss:0.678 AVG Validation Loss:0.788 AVG Training Acc 57.73 % AVG Validation Acc 33.87 %\n",
      "Epoch:60/200 AVG Training Loss:0.672 AVG Validation Loss:0.779 AVG Training Acc 58.51 % AVG Validation Acc 36.96 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.676 AVG Validation Loss:0.764 AVG Training Acc 57.34 % AVG Validation Acc 45.56 %\n",
      "Epoch:80/200 AVG Training Loss:0.661 AVG Validation Loss:0.695 AVG Training Acc 60.81 % AVG Validation Acc 58.33 %\n",
      "Epoch:90/200 AVG Training Loss:0.659 AVG Validation Loss:0.675 AVG Training Acc 60.76 % AVG Validation Acc 62.50 %\n",
      "Epoch:100/200 AVG Training Loss:0.657 AVG Validation Loss:0.670 AVG Training Acc 62.03 % AVG Validation Acc 63.17 %\n",
      "Epoch:110/200 AVG Training Loss:0.659 AVG Validation Loss:0.668 AVG Training Acc 61.25 % AVG Validation Acc 63.31 %\n",
      "Epoch:120/200 AVG Training Loss:0.657 AVG Validation Loss:0.667 AVG Training Acc 61.16 % AVG Validation Acc 63.58 %\n",
      "Epoch:130/200 AVG Training Loss:0.653 AVG Validation Loss:0.666 AVG Training Acc 61.83 % AVG Validation Acc 63.71 %\n",
      "Epoch:140/200 AVG Training Loss:0.652 AVG Validation Loss:0.666 AVG Training Acc 61.65 % AVG Validation Acc 63.58 %\n",
      "Epoch:150/200 AVG Training Loss:0.653 AVG Validation Loss:0.664 AVG Training Acc 61.57 % AVG Validation Acc 63.58 %\n",
      "Epoch:160/200 AVG Training Loss:0.651 AVG Validation Loss:0.662 AVG Training Acc 61.51 % AVG Validation Acc 63.31 %\n",
      "Epoch:170/200 AVG Training Loss:0.651 AVG Validation Loss:0.662 AVG Training Acc 61.47 % AVG Validation Acc 63.31 %\n",
      "Epoch:180/200 AVG Training Loss:0.648 AVG Validation Loss:0.661 AVG Training Acc 62.30 % AVG Validation Acc 63.31 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:190/200 AVG Training Loss:0.646 AVG Validation Loss:0.661 AVG Training Acc 62.86 % AVG Validation Acc 62.90 %\n",
      "Epoch:200/200 AVG Training Loss:0.646 AVG Validation Loss:0.659 AVG Training Acc 62.51 % AVG Validation Acc 63.04 %\n",
      "Split 54\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2f8a0ccf8894f7ba1a349c61fb75110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.531 AVG Validation Loss:6.309 AVG Training Acc 80.26 % AVG Validation Acc 20.16 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.582 AVG Validation Loss:2.652 AVG Training Acc 75.98 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.660 AVG Validation Loss:1.128 AVG Training Acc 62.62 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.655 AVG Validation Loss:1.121 AVG Training Acc 63.67 % AVG Validation Acc 21.37 %\n",
      "Epoch:50/200 AVG Training Loss:0.659 AVG Validation Loss:1.044 AVG Training Acc 62.03 % AVG Validation Acc 23.66 %\n",
      "Epoch:60/200 AVG Training Loss:0.651 AVG Validation Loss:1.052 AVG Training Acc 63.55 % AVG Validation Acc 23.79 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.669 AVG Validation Loss:0.730 AVG Training Acc 59.56 % AVG Validation Acc 44.22 %\n",
      "Epoch:80/200 AVG Training Loss:0.661 AVG Validation Loss:0.707 AVG Training Acc 61.25 % AVG Validation Acc 49.87 %\n",
      "Epoch:90/200 AVG Training Loss:0.660 AVG Validation Loss:0.709 AVG Training Acc 61.33 % AVG Validation Acc 50.67 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.657 AVG Validation Loss:0.706 AVG Training Acc 61.25 % AVG Validation Acc 51.34 %\n",
      "Epoch:110/200 AVG Training Loss:0.655 AVG Validation Loss:0.698 AVG Training Acc 61.53 % AVG Validation Acc 53.09 %\n",
      "Epoch:120/200 AVG Training Loss:0.655 AVG Validation Loss:0.694 AVG Training Acc 62.08 % AVG Validation Acc 53.76 %\n",
      "Epoch:130/200 AVG Training Loss:0.655 AVG Validation Loss:0.691 AVG Training Acc 61.86 % AVG Validation Acc 55.38 %\n",
      "Epoch:140/200 AVG Training Loss:0.655 AVG Validation Loss:0.690 AVG Training Acc 61.84 % AVG Validation Acc 54.70 %\n",
      "Epoch:150/200 AVG Training Loss:0.655 AVG Validation Loss:0.690 AVG Training Acc 61.91 % AVG Validation Acc 55.78 %\n",
      "Epoch:160/200 AVG Training Loss:0.655 AVG Validation Loss:0.689 AVG Training Acc 62.58 % AVG Validation Acc 56.59 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:170/200 AVG Training Loss:0.653 AVG Validation Loss:0.689 AVG Training Acc 62.16 % AVG Validation Acc 55.51 %\n",
      "Epoch:180/200 AVG Training Loss:0.655 AVG Validation Loss:0.690 AVG Training Acc 62.40 % AVG Validation Acc 55.38 %\n",
      "Epoch:190/200 AVG Training Loss:0.653 AVG Validation Loss:0.688 AVG Training Acc 62.53 % AVG Validation Acc 56.32 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:200/200 AVG Training Loss:0.655 AVG Validation Loss:0.688 AVG Training Acc 61.99 % AVG Validation Acc 55.91 %\n",
      "Split 55\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9383c61a7dcc47d09ded9b7a55c1d5ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.410 AVG Validation Loss:5.799 AVG Training Acc 83.93 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.546 AVG Validation Loss:3.573 AVG Training Acc 79.93 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.587 AVG Validation Loss:2.197 AVG Training Acc 72.43 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.626 AVG Validation Loss:2.646 AVG Training Acc 73.57 % AVG Validation Acc 20.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.616 AVG Validation Loss:2.731 AVG Training Acc 75.78 % AVG Validation Acc 20.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.640 AVG Validation Loss:2.179 AVG Training Acc 66.59 % AVG Validation Acc 20.16 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:70/200 AVG Training Loss:0.749 AVG Validation Loss:0.882 AVG Training Acc 50.31 % AVG Validation Acc 20.83 %\n",
      "Epoch:80/200 AVG Training Loss:0.687 AVG Validation Loss:0.791 AVG Training Acc 55.29 % AVG Validation Acc 22.58 %\n",
      "Epoch:90/200 AVG Training Loss:0.685 AVG Validation Loss:0.795 AVG Training Acc 56.37 % AVG Validation Acc 25.13 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.687 AVG Validation Loss:0.777 AVG Training Acc 54.64 % AVG Validation Acc 33.06 %\n",
      "Epoch:110/200 AVG Training Loss:0.670 AVG Validation Loss:0.706 AVG Training Acc 58.51 % AVG Validation Acc 53.09 %\n",
      "Epoch:120/200 AVG Training Loss:0.667 AVG Validation Loss:0.688 AVG Training Acc 59.25 % AVG Validation Acc 57.53 %\n",
      "Epoch:130/200 AVG Training Loss:0.665 AVG Validation Loss:0.685 AVG Training Acc 59.68 % AVG Validation Acc 57.39 %\n",
      "Epoch:140/200 AVG Training Loss:0.665 AVG Validation Loss:0.684 AVG Training Acc 59.91 % AVG Validation Acc 57.66 %\n",
      "Epoch:150/200 AVG Training Loss:0.662 AVG Validation Loss:0.682 AVG Training Acc 60.64 % AVG Validation Acc 57.80 %\n",
      "Epoch:160/200 AVG Training Loss:0.662 AVG Validation Loss:0.683 AVG Training Acc 60.43 % AVG Validation Acc 57.53 %\n",
      "Epoch   161: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:170/200 AVG Training Loss:0.658 AVG Validation Loss:0.681 AVG Training Acc 60.39 % AVG Validation Acc 57.80 %\n",
      "Epoch:180/200 AVG Training Loss:0.661 AVG Validation Loss:0.679 AVG Training Acc 60.80 % AVG Validation Acc 58.06 %\n",
      "Epoch:190/200 AVG Training Loss:0.658 AVG Validation Loss:0.678 AVG Training Acc 60.94 % AVG Validation Acc 58.33 %\n",
      "Epoch:200/200 AVG Training Loss:0.661 AVG Validation Loss:0.677 AVG Training Acc 60.51 % AVG Validation Acc 58.20 %\n",
      "Split 56\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5316d6a680a943e49a3f269ccdbccd51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.562 AVG Validation Loss:5.264 AVG Training Acc 75.23 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.631 AVG Validation Loss:1.803 AVG Training Acc 68.52 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.558 AVG Validation Loss:3.201 AVG Training Acc 78.36 % AVG Validation Acc 20.16 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.638 AVG Validation Loss:1.133 AVG Training Acc 66.94 % AVG Validation Acc 21.37 %\n",
      "Epoch:50/200 AVG Training Loss:0.686 AVG Validation Loss:0.925 AVG Training Acc 59.57 % AVG Validation Acc 24.19 %\n",
      "Epoch:60/200 AVG Training Loss:0.669 AVG Validation Loss:1.406 AVG Training Acc 64.43 % AVG Validation Acc 20.16 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.705 AVG Validation Loss:0.810 AVG Training Acc 52.43 % AVG Validation Acc 21.64 %\n",
      "Epoch:80/200 AVG Training Loss:0.681 AVG Validation Loss:0.711 AVG Training Acc 55.27 % AVG Validation Acc 51.88 %\n",
      "Epoch:90/200 AVG Training Loss:0.678 AVG Validation Loss:0.705 AVG Training Acc 56.13 % AVG Validation Acc 52.69 %\n",
      "Epoch:100/200 AVG Training Loss:0.676 AVG Validation Loss:0.702 AVG Training Acc 57.22 % AVG Validation Acc 53.63 %\n",
      "Epoch:110/200 AVG Training Loss:0.676 AVG Validation Loss:0.703 AVG Training Acc 57.95 % AVG Validation Acc 53.36 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.673 AVG Validation Loss:0.695 AVG Training Acc 57.17 % AVG Validation Acc 53.76 %\n",
      "Epoch:130/200 AVG Training Loss:0.669 AVG Validation Loss:0.686 AVG Training Acc 58.53 % AVG Validation Acc 55.24 %\n",
      "Epoch:140/200 AVG Training Loss:0.669 AVG Validation Loss:0.680 AVG Training Acc 58.21 % AVG Validation Acc 57.12 %\n",
      "Epoch:150/200 AVG Training Loss:0.672 AVG Validation Loss:0.676 AVG Training Acc 58.76 % AVG Validation Acc 56.99 %\n",
      "Epoch:160/200 AVG Training Loss:0.670 AVG Validation Loss:0.674 AVG Training Acc 58.91 % AVG Validation Acc 57.26 %\n",
      "Epoch:170/200 AVG Training Loss:0.670 AVG Validation Loss:0.672 AVG Training Acc 58.74 % AVG Validation Acc 56.99 %\n",
      "Epoch:180/200 AVG Training Loss:0.671 AVG Validation Loss:0.671 AVG Training Acc 58.52 % AVG Validation Acc 57.12 %\n",
      "Epoch:190/200 AVG Training Loss:0.669 AVG Validation Loss:0.670 AVG Training Acc 58.96 % AVG Validation Acc 57.26 %\n",
      "Epoch:200/200 AVG Training Loss:0.668 AVG Validation Loss:0.669 AVG Training Acc 58.72 % AVG Validation Acc 57.12 %\n",
      "Split 57\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e198b5eee9a47f19b7f9740f61c0e46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.536 AVG Validation Loss:4.467 AVG Training Acc 81.59 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.609 AVG Validation Loss:1.901 AVG Training Acc 75.09 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.663 AVG Validation Loss:1.484 AVG Training Acc 63.85 % AVG Validation Acc 20.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.654 AVG Validation Loss:1.602 AVG Training Acc 65.25 % AVG Validation Acc 20.05 %\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.697 AVG Validation Loss:0.757 AVG Training Acc 48.46 % AVG Validation Acc 20.86 %\n",
      "Epoch:60/200 AVG Training Loss:0.687 AVG Validation Loss:0.761 AVG Training Acc 52.93 % AVG Validation Acc 25.03 %\n",
      "Epoch:70/200 AVG Training Loss:0.677 AVG Validation Loss:0.755 AVG Training Acc 57.41 % AVG Validation Acc 45.76 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.672 AVG Validation Loss:0.713 AVG Training Acc 58.99 % AVG Validation Acc 55.99 %\n",
      "Epoch:90/200 AVG Training Loss:0.669 AVG Validation Loss:0.690 AVG Training Acc 59.75 % AVG Validation Acc 61.10 %\n",
      "Epoch:100/200 AVG Training Loss:0.669 AVG Validation Loss:0.681 AVG Training Acc 59.67 % AVG Validation Acc 61.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.669 AVG Validation Loss:0.678 AVG Training Acc 59.41 % AVG Validation Acc 62.05 %\n",
      "Epoch:120/200 AVG Training Loss:0.667 AVG Validation Loss:0.675 AVG Training Acc 59.65 % AVG Validation Acc 62.18 %\n",
      "Epoch:130/200 AVG Training Loss:0.667 AVG Validation Loss:0.675 AVG Training Acc 60.18 % AVG Validation Acc 62.05 %\n",
      "Epoch:140/200 AVG Training Loss:0.667 AVG Validation Loss:0.674 AVG Training Acc 60.70 % AVG Validation Acc 62.05 %\n",
      "Epoch:150/200 AVG Training Loss:0.665 AVG Validation Loss:0.673 AVG Training Acc 60.59 % AVG Validation Acc 62.31 %\n",
      "Epoch:160/200 AVG Training Loss:0.665 AVG Validation Loss:0.673 AVG Training Acc 60.51 % AVG Validation Acc 61.91 %\n",
      "Epoch:170/200 AVG Training Loss:0.667 AVG Validation Loss:0.672 AVG Training Acc 59.64 % AVG Validation Acc 62.05 %\n",
      "Epoch:180/200 AVG Training Loss:0.664 AVG Validation Loss:0.672 AVG Training Acc 60.56 % AVG Validation Acc 61.64 %\n",
      "Epoch:190/200 AVG Training Loss:0.666 AVG Validation Loss:0.672 AVG Training Acc 59.88 % AVG Validation Acc 61.91 %\n",
      "Epoch:200/200 AVG Training Loss:0.664 AVG Validation Loss:0.672 AVG Training Acc 60.37 % AVG Validation Acc 61.64 %\n",
      "Split 58\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5516b762ab14114ad507085698d7ab6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.551 AVG Validation Loss:4.364 AVG Training Acc 80.47 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.617 AVG Validation Loss:3.174 AVG Training Acc 72.50 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.548 AVG Validation Loss:3.679 AVG Training Acc 80.51 % AVG Validation Acc 20.05 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.727 AVG Validation Loss:0.877 AVG Training Acc 48.83 % AVG Validation Acc 20.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.696 AVG Validation Loss:0.801 AVG Training Acc 52.91 % AVG Validation Acc 21.94 %\n",
      "Epoch:60/200 AVG Training Loss:0.682 AVG Validation Loss:0.781 AVG Training Acc 56.99 % AVG Validation Acc 26.51 %\n",
      "Epoch:70/200 AVG Training Loss:0.688 AVG Validation Loss:0.772 AVG Training Acc 56.20 % AVG Validation Acc 34.59 %\n",
      "Epoch    70: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.684 AVG Validation Loss:0.696 AVG Training Acc 57.52 % AVG Validation Acc 51.55 %\n",
      "Epoch:90/200 AVG Training Loss:0.670 AVG Validation Loss:0.683 AVG Training Acc 59.45 % AVG Validation Acc 56.26 %\n",
      "Epoch:100/200 AVG Training Loss:0.670 AVG Validation Loss:0.680 AVG Training Acc 59.72 % AVG Validation Acc 56.80 %\n",
      "Epoch:110/200 AVG Training Loss:0.666 AVG Validation Loss:0.681 AVG Training Acc 60.32 % AVG Validation Acc 56.66 %\n",
      "Epoch:120/200 AVG Training Loss:0.666 AVG Validation Loss:0.681 AVG Training Acc 60.04 % AVG Validation Acc 57.47 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.664 AVG Validation Loss:0.689 AVG Training Acc 60.00 % AVG Validation Acc 57.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.662 AVG Validation Loss:0.687 AVG Training Acc 59.96 % AVG Validation Acc 58.28 %\n",
      "Epoch:150/200 AVG Training Loss:0.662 AVG Validation Loss:0.685 AVG Training Acc 60.35 % AVG Validation Acc 58.01 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.662 AVG Validation Loss:0.681 AVG Training Acc 59.92 % AVG Validation Acc 58.01 %\n",
      "Epoch:170/200 AVG Training Loss:0.663 AVG Validation Loss:0.685 AVG Training Acc 60.19 % AVG Validation Acc 58.41 %\n",
      "Epoch:180/200 AVG Training Loss:0.660 AVG Validation Loss:0.684 AVG Training Acc 59.91 % AVG Validation Acc 58.41 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.661 AVG Validation Loss:0.682 AVG Training Acc 60.33 % AVG Validation Acc 58.01 %\n",
      "Epoch:200/200 AVG Training Loss:0.662 AVG Validation Loss:0.683 AVG Training Acc 59.86 % AVG Validation Acc 58.01 %\n",
      "Split 59\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ca4db6315274f30832669c0a47391df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.488 AVG Validation Loss:4.781 AVG Training Acc 82.78 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.638 AVG Validation Loss:1.731 AVG Training Acc 67.53 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:9.452 AVG Training Acc 72.79 % AVG Validation Acc 20.05 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.818 AVG Validation Loss:0.879 AVG Training Acc 48.16 % AVG Validation Acc 20.46 %\n",
      "Epoch:50/200 AVG Training Loss:0.694 AVG Validation Loss:0.776 AVG Training Acc 52.34 % AVG Validation Acc 22.21 %\n",
      "Epoch:60/200 AVG Training Loss:0.687 AVG Validation Loss:0.786 AVG Training Acc 55.14 % AVG Validation Acc 23.28 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.686 AVG Validation Loss:0.766 AVG Training Acc 55.67 % AVG Validation Acc 44.41 %\n",
      "Epoch:80/200 AVG Training Loss:0.672 AVG Validation Loss:0.699 AVG Training Acc 59.29 % AVG Validation Acc 55.72 %\n",
      "Epoch:90/200 AVG Training Loss:0.670 AVG Validation Loss:0.679 AVG Training Acc 59.90 % AVG Validation Acc 58.95 %\n",
      "Epoch:100/200 AVG Training Loss:0.669 AVG Validation Loss:0.672 AVG Training Acc 59.94 % AVG Validation Acc 60.43 %\n",
      "Epoch:110/200 AVG Training Loss:0.668 AVG Validation Loss:0.670 AVG Training Acc 60.13 % AVG Validation Acc 60.70 %\n",
      "Epoch:120/200 AVG Training Loss:0.668 AVG Validation Loss:0.669 AVG Training Acc 59.93 % AVG Validation Acc 60.70 %\n",
      "Epoch:130/200 AVG Training Loss:0.669 AVG Validation Loss:0.668 AVG Training Acc 59.55 % AVG Validation Acc 60.57 %\n",
      "Epoch   137: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:140/200 AVG Training Loss:0.665 AVG Validation Loss:0.669 AVG Training Acc 60.23 % AVG Validation Acc 60.30 %\n",
      "Epoch:150/200 AVG Training Loss:0.665 AVG Validation Loss:0.667 AVG Training Acc 60.49 % AVG Validation Acc 60.57 %\n",
      "Epoch:160/200 AVG Training Loss:0.666 AVG Validation Loss:0.666 AVG Training Acc 60.57 % AVG Validation Acc 60.83 %\n",
      "Epoch:170/200 AVG Training Loss:0.667 AVG Validation Loss:0.665 AVG Training Acc 59.85 % AVG Validation Acc 60.70 %\n",
      "Epoch:180/200 AVG Training Loss:0.665 AVG Validation Loss:0.665 AVG Training Acc 60.51 % AVG Validation Acc 60.83 %\n",
      "Epoch:190/200 AVG Training Loss:0.666 AVG Validation Loss:0.664 AVG Training Acc 60.36 % AVG Validation Acc 60.70 %\n",
      "Epoch:200/200 AVG Training Loss:0.666 AVG Validation Loss:0.663 AVG Training Acc 60.65 % AVG Validation Acc 60.83 %\n",
      "Split 60\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22ac8f5b1f53495096de43e670c76e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.549 AVG Validation Loss:6.221 AVG Training Acc 84.24 % AVG Validation Acc 20.19 %\n",
      "Epoch:20/200 AVG Training Loss:0.543 AVG Validation Loss:3.042 AVG Training Acc 79.67 % AVG Validation Acc 20.19 %\n",
      "Epoch:30/200 AVG Training Loss:0.538 AVG Validation Loss:11.313 AVG Training Acc 79.78 % AVG Validation Acc 20.19 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.672 AVG Validation Loss:1.362 AVG Training Acc 63.21 % AVG Validation Acc 20.19 %\n",
      "Epoch:50/200 AVG Training Loss:0.687 AVG Validation Loss:1.166 AVG Training Acc 59.14 % AVG Validation Acc 20.19 %\n",
      "Epoch:60/200 AVG Training Loss:0.669 AVG Validation Loss:1.237 AVG Training Acc 62.07 % AVG Validation Acc 20.59 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.679 AVG Validation Loss:0.740 AVG Training Acc 58.15 % AVG Validation Acc 49.93 %\n",
      "Epoch:80/200 AVG Training Loss:0.667 AVG Validation Loss:0.696 AVG Training Acc 60.71 % AVG Validation Acc 55.05 %\n",
      "Epoch:90/200 AVG Training Loss:0.668 AVG Validation Loss:0.694 AVG Training Acc 60.82 % AVG Validation Acc 55.32 %\n",
      "Epoch:100/200 AVG Training Loss:0.666 AVG Validation Loss:0.695 AVG Training Acc 61.10 % AVG Validation Acc 55.32 %\n",
      "Epoch:110/200 AVG Training Loss:0.664 AVG Validation Loss:0.695 AVG Training Acc 61.32 % AVG Validation Acc 55.99 %\n",
      "Epoch   113: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.661 AVG Validation Loss:0.687 AVG Training Acc 61.43 % AVG Validation Acc 56.26 %\n",
      "Epoch:130/200 AVG Training Loss:0.661 AVG Validation Loss:0.680 AVG Training Acc 62.07 % AVG Validation Acc 56.66 %\n",
      "Epoch:140/200 AVG Training Loss:0.663 AVG Validation Loss:0.674 AVG Training Acc 61.82 % AVG Validation Acc 56.66 %\n",
      "Epoch:150/200 AVG Training Loss:0.658 AVG Validation Loss:0.671 AVG Training Acc 61.76 % AVG Validation Acc 57.34 %\n",
      "Epoch:160/200 AVG Training Loss:0.659 AVG Validation Loss:0.669 AVG Training Acc 61.90 % AVG Validation Acc 57.34 %\n",
      "Epoch:170/200 AVG Training Loss:0.662 AVG Validation Loss:0.667 AVG Training Acc 61.62 % AVG Validation Acc 57.74 %\n",
      "Epoch:180/200 AVG Training Loss:0.659 AVG Validation Loss:0.667 AVG Training Acc 61.77 % AVG Validation Acc 58.01 %\n",
      "Epoch:190/200 AVG Training Loss:0.662 AVG Validation Loss:0.666 AVG Training Acc 61.49 % AVG Validation Acc 57.87 %\n",
      "Epoch:200/200 AVG Training Loss:0.659 AVG Validation Loss:0.665 AVG Training Acc 61.78 % AVG Validation Acc 58.14 %\n",
      "Split 61\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f357d5c31c94202a6343288e3f33edb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.486 AVG Validation Loss:4.108 AVG Training Acc 81.23 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.619 AVG Validation Loss:2.452 AVG Training Acc 69.09 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.689 AVG Validation Loss:3.638 AVG Training Acc 74.57 % AVG Validation Acc 20.16 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.726 AVG Validation Loss:0.845 AVG Training Acc 49.49 % AVG Validation Acc 20.97 %\n",
      "Epoch:50/200 AVG Training Loss:0.694 AVG Validation Loss:0.777 AVG Training Acc 51.85 % AVG Validation Acc 22.85 %\n",
      "Epoch:60/200 AVG Training Loss:0.688 AVG Validation Loss:0.772 AVG Training Acc 54.24 % AVG Validation Acc 24.06 %\n",
      "Epoch:70/200 AVG Training Loss:0.677 AVG Validation Loss:0.775 AVG Training Acc 57.24 % AVG Validation Acc 28.09 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.675 AVG Validation Loss:0.740 AVG Training Acc 56.83 % AVG Validation Acc 41.67 %\n",
      "Epoch:90/200 AVG Training Loss:0.665 AVG Validation Loss:0.696 AVG Training Acc 59.15 % AVG Validation Acc 54.70 %\n",
      "Epoch:100/200 AVG Training Loss:0.664 AVG Validation Loss:0.682 AVG Training Acc 59.58 % AVG Validation Acc 58.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.663 AVG Validation Loss:0.678 AVG Training Acc 59.95 % AVG Validation Acc 59.14 %\n",
      "Epoch:120/200 AVG Training Loss:0.662 AVG Validation Loss:0.676 AVG Training Acc 60.28 % AVG Validation Acc 59.27 %\n",
      "Epoch:130/200 AVG Training Loss:0.659 AVG Validation Loss:0.674 AVG Training Acc 60.39 % AVG Validation Acc 59.81 %\n",
      "Epoch:140/200 AVG Training Loss:0.657 AVG Validation Loss:0.674 AVG Training Acc 60.84 % AVG Validation Acc 59.54 %\n",
      "Epoch:150/200 AVG Training Loss:0.658 AVG Validation Loss:0.674 AVG Training Acc 60.88 % AVG Validation Acc 59.27 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:160/200 AVG Training Loss:0.657 AVG Validation Loss:0.673 AVG Training Acc 60.32 % AVG Validation Acc 59.27 %\n",
      "Epoch:170/200 AVG Training Loss:0.657 AVG Validation Loss:0.672 AVG Training Acc 60.48 % AVG Validation Acc 59.41 %\n",
      "Epoch:180/200 AVG Training Loss:0.654 AVG Validation Loss:0.671 AVG Training Acc 60.85 % AVG Validation Acc 59.81 %\n",
      "Epoch:190/200 AVG Training Loss:0.657 AVG Validation Loss:0.671 AVG Training Acc 60.43 % AVG Validation Acc 59.95 %\n",
      "Epoch:200/200 AVG Training Loss:0.656 AVG Validation Loss:0.670 AVG Training Acc 60.95 % AVG Validation Acc 59.95 %\n",
      "Split 62\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f66f81e0b3f74fe7abe63cbb35b128f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.526 AVG Validation Loss:3.917 AVG Training Acc 80.11 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.656 AVG Validation Loss:1.556 AVG Training Acc 65.03 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.644 AVG Validation Loss:3.627 AVG Training Acc 67.75 % AVG Validation Acc 20.16 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.705 AVG Validation Loss:0.756 AVG Training Acc 50.66 % AVG Validation Acc 25.40 %\n",
      "Epoch:50/200 AVG Training Loss:0.684 AVG Validation Loss:0.773 AVG Training Acc 55.91 % AVG Validation Acc 28.09 %\n",
      "Epoch:60/200 AVG Training Loss:0.676 AVG Validation Loss:0.784 AVG Training Acc 59.22 % AVG Validation Acc 36.56 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.671 AVG Validation Loss:0.724 AVG Training Acc 59.39 % AVG Validation Acc 54.17 %\n",
      "Epoch:80/200 AVG Training Loss:0.665 AVG Validation Loss:0.689 AVG Training Acc 60.66 % AVG Validation Acc 59.41 %\n",
      "Epoch:90/200 AVG Training Loss:0.666 AVG Validation Loss:0.681 AVG Training Acc 60.54 % AVG Validation Acc 60.35 %\n",
      "Epoch:100/200 AVG Training Loss:0.666 AVG Validation Loss:0.678 AVG Training Acc 60.89 % AVG Validation Acc 60.35 %\n",
      "Epoch:110/200 AVG Training Loss:0.663 AVG Validation Loss:0.678 AVG Training Acc 60.51 % AVG Validation Acc 60.22 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.662 AVG Validation Loss:0.678 AVG Training Acc 60.85 % AVG Validation Acc 60.48 %\n",
      "Epoch:130/200 AVG Training Loss:0.659 AVG Validation Loss:0.676 AVG Training Acc 61.01 % AVG Validation Acc 60.35 %\n",
      "Epoch:140/200 AVG Training Loss:0.662 AVG Validation Loss:0.675 AVG Training Acc 61.06 % AVG Validation Acc 60.62 %\n",
      "Epoch:150/200 AVG Training Loss:0.662 AVG Validation Loss:0.674 AVG Training Acc 61.10 % AVG Validation Acc 60.75 %\n",
      "Epoch:160/200 AVG Training Loss:0.660 AVG Validation Loss:0.674 AVG Training Acc 61.20 % AVG Validation Acc 60.75 %\n",
      "Epoch:170/200 AVG Training Loss:0.660 AVG Validation Loss:0.673 AVG Training Acc 61.00 % AVG Validation Acc 61.02 %\n",
      "Epoch:180/200 AVG Training Loss:0.660 AVG Validation Loss:0.673 AVG Training Acc 61.04 % AVG Validation Acc 61.02 %\n",
      "Epoch:190/200 AVG Training Loss:0.659 AVG Validation Loss:0.672 AVG Training Acc 61.28 % AVG Validation Acc 60.75 %\n",
      "Epoch:200/200 AVG Training Loss:0.660 AVG Validation Loss:0.672 AVG Training Acc 61.13 % AVG Validation Acc 61.02 %\n",
      "Split 63\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f6a9778434c4c40916db7200605b737",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.576 AVG Validation Loss:5.848 AVG Training Acc 75.49 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.552 AVG Validation Loss:4.705 AVG Training Acc 78.14 % AVG Validation Acc 20.16 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:1.700 AVG Validation Loss:1.501 AVG Training Acc 49.93 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.681 AVG Validation Loss:0.830 AVG Training Acc 57.31 % AVG Validation Acc 31.85 %\n",
      "Epoch:50/200 AVG Training Loss:0.674 AVG Validation Loss:0.816 AVG Training Acc 58.09 % AVG Validation Acc 37.90 %\n",
      "Epoch:60/200 AVG Training Loss:0.671 AVG Validation Loss:0.806 AVG Training Acc 59.68 % AVG Validation Acc 41.80 %\n",
      "Epoch:70/200 AVG Training Loss:0.666 AVG Validation Loss:0.811 AVG Training Acc 60.30 % AVG Validation Acc 46.37 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.661 AVG Validation Loss:0.724 AVG Training Acc 61.40 % AVG Validation Acc 55.11 %\n",
      "Epoch:90/200 AVG Training Loss:0.656 AVG Validation Loss:0.698 AVG Training Acc 62.16 % AVG Validation Acc 57.39 %\n",
      "Epoch:100/200 AVG Training Loss:0.657 AVG Validation Loss:0.691 AVG Training Acc 62.27 % AVG Validation Acc 58.06 %\n",
      "Epoch:110/200 AVG Training Loss:0.654 AVG Validation Loss:0.691 AVG Training Acc 62.54 % AVG Validation Acc 57.66 %\n",
      "Epoch:120/200 AVG Training Loss:0.654 AVG Validation Loss:0.690 AVG Training Acc 62.22 % AVG Validation Acc 58.87 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.652 AVG Validation Loss:0.690 AVG Training Acc 62.39 % AVG Validation Acc 58.47 %\n",
      "Epoch:140/200 AVG Training Loss:0.652 AVG Validation Loss:0.688 AVG Training Acc 62.18 % AVG Validation Acc 59.01 %\n",
      "Epoch:150/200 AVG Training Loss:0.654 AVG Validation Loss:0.688 AVG Training Acc 62.23 % AVG Validation Acc 58.74 %\n",
      "Epoch:160/200 AVG Training Loss:0.652 AVG Validation Loss:0.686 AVG Training Acc 62.35 % AVG Validation Acc 59.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.653 AVG Validation Loss:0.686 AVG Training Acc 62.27 % AVG Validation Acc 59.14 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:180/200 AVG Training Loss:0.653 AVG Validation Loss:0.686 AVG Training Acc 62.22 % AVG Validation Acc 59.68 %\n",
      "Epoch:190/200 AVG Training Loss:0.653 AVG Validation Loss:0.686 AVG Training Acc 62.73 % AVG Validation Acc 59.68 %\n",
      "Epoch:200/200 AVG Training Loss:0.654 AVG Validation Loss:0.686 AVG Training Acc 62.46 % AVG Validation Acc 59.27 %\n",
      "Split 64\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f481c6f437f14eef9374b9cbb57c0f17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.463 AVG Validation Loss:3.728 AVG Training Acc 82.14 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.521 AVG Validation Loss:5.083 AVG Training Acc 78.07 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.565 AVG Validation Loss:2.517 AVG Training Acc 76.52 % AVG Validation Acc 20.16 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.779 AVG Validation Loss:1.376 AVG Training Acc 48.95 % AVG Validation Acc 20.56 %\n",
      "Epoch:50/200 AVG Training Loss:0.684 AVG Validation Loss:0.953 AVG Training Acc 57.77 % AVG Validation Acc 20.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.647 AVG Validation Loss:1.449 AVG Training Acc 61.96 % AVG Validation Acc 20.16 %\n",
      "Epoch:70/200 AVG Training Loss:0.675 AVG Validation Loss:0.799 AVG Training Acc 58.75 % AVG Validation Acc 38.31 %\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.671 AVG Validation Loss:0.727 AVG Training Acc 59.01 % AVG Validation Acc 49.73 %\n",
      "Epoch:90/200 AVG Training Loss:0.667 AVG Validation Loss:0.696 AVG Training Acc 60.51 % AVG Validation Acc 55.51 %\n",
      "Epoch:100/200 AVG Training Loss:0.665 AVG Validation Loss:0.687 AVG Training Acc 60.79 % AVG Validation Acc 56.85 %\n",
      "Epoch:110/200 AVG Training Loss:0.664 AVG Validation Loss:0.685 AVG Training Acc 60.89 % AVG Validation Acc 57.12 %\n",
      "Epoch:120/200 AVG Training Loss:0.664 AVG Validation Loss:0.685 AVG Training Acc 60.98 % AVG Validation Acc 56.05 %\n",
      "Epoch:130/200 AVG Training Loss:0.663 AVG Validation Loss:0.683 AVG Training Acc 61.03 % AVG Validation Acc 56.59 %\n",
      "Epoch:140/200 AVG Training Loss:0.661 AVG Validation Loss:0.683 AVG Training Acc 61.15 % AVG Validation Acc 56.85 %\n",
      "Epoch:150/200 AVG Training Loss:0.659 AVG Validation Loss:0.683 AVG Training Acc 61.27 % AVG Validation Acc 56.45 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:160/200 AVG Training Loss:0.659 AVG Validation Loss:0.682 AVG Training Acc 61.68 % AVG Validation Acc 55.91 %\n",
      "Epoch:170/200 AVG Training Loss:0.659 AVG Validation Loss:0.682 AVG Training Acc 61.67 % AVG Validation Acc 56.32 %\n",
      "Epoch:180/200 AVG Training Loss:0.660 AVG Validation Loss:0.679 AVG Training Acc 61.60 % AVG Validation Acc 56.72 %\n",
      "Epoch:190/200 AVG Training Loss:0.660 AVG Validation Loss:0.678 AVG Training Acc 61.29 % AVG Validation Acc 56.85 %\n",
      "Epoch:200/200 AVG Training Loss:0.660 AVG Validation Loss:0.679 AVG Training Acc 61.64 % AVG Validation Acc 57.53 %\n",
      "Split 65\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77220062568747d5af5b3a26027f9ed1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.540 AVG Validation Loss:4.986 AVG Training Acc 79.30 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.535 AVG Validation Loss:3.385 AVG Training Acc 77.84 % AVG Validation Acc 20.16 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.710 AVG Validation Loss:0.900 AVG Training Acc 52.83 % AVG Validation Acc 21.10 %\n",
      "Epoch:40/200 AVG Training Loss:0.665 AVG Validation Loss:0.990 AVG Training Acc 61.81 % AVG Validation Acc 22.31 %\n",
      "Epoch:50/200 AVG Training Loss:0.777 AVG Validation Loss:0.968 AVG Training Acc 57.63 % AVG Validation Acc 22.58 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.700 AVG Validation Loss:0.771 AVG Training Acc 54.28 % AVG Validation Acc 35.62 %\n",
      "Epoch:70/200 AVG Training Loss:0.681 AVG Validation Loss:0.721 AVG Training Acc 56.17 % AVG Validation Acc 45.70 %\n",
      "Epoch:80/200 AVG Training Loss:0.677 AVG Validation Loss:0.726 AVG Training Acc 57.68 % AVG Validation Acc 50.00 %\n",
      "Epoch:90/200 AVG Training Loss:0.678 AVG Validation Loss:0.719 AVG Training Acc 57.61 % AVG Validation Acc 52.28 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.674 AVG Validation Loss:0.712 AVG Training Acc 59.33 % AVG Validation Acc 53.76 %\n",
      "Epoch:110/200 AVG Training Loss:0.669 AVG Validation Loss:0.692 AVG Training Acc 59.80 % AVG Validation Acc 56.85 %\n",
      "Epoch:120/200 AVG Training Loss:0.671 AVG Validation Loss:0.684 AVG Training Acc 59.56 % AVG Validation Acc 58.60 %\n",
      "Epoch:130/200 AVG Training Loss:0.668 AVG Validation Loss:0.680 AVG Training Acc 59.72 % AVG Validation Acc 59.41 %\n",
      "Epoch:140/200 AVG Training Loss:0.670 AVG Validation Loss:0.677 AVG Training Acc 59.67 % AVG Validation Acc 60.48 %\n",
      "Epoch:150/200 AVG Training Loss:0.670 AVG Validation Loss:0.675 AVG Training Acc 59.57 % AVG Validation Acc 60.75 %\n",
      "Epoch:160/200 AVG Training Loss:0.670 AVG Validation Loss:0.674 AVG Training Acc 59.59 % AVG Validation Acc 61.83 %\n",
      "Epoch:170/200 AVG Training Loss:0.669 AVG Validation Loss:0.673 AVG Training Acc 59.26 % AVG Validation Acc 61.56 %\n",
      "Epoch:180/200 AVG Training Loss:0.669 AVG Validation Loss:0.673 AVG Training Acc 59.94 % AVG Validation Acc 61.69 %\n",
      "Epoch:190/200 AVG Training Loss:0.668 AVG Validation Loss:0.672 AVG Training Acc 59.97 % AVG Validation Acc 61.29 %\n",
      "Epoch:200/200 AVG Training Loss:0.670 AVG Validation Loss:0.671 AVG Training Acc 59.11 % AVG Validation Acc 61.96 %\n",
      "Split 66\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20842d90e1614dd4a953c2b1650416a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.604 AVG Validation Loss:2.174 AVG Training Acc 71.20 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.526 AVG Validation Loss:4.112 AVG Training Acc 80.77 % AVG Validation Acc 20.16 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.697 AVG Validation Loss:0.968 AVG Training Acc 55.31 % AVG Validation Acc 20.83 %\n",
      "Epoch:40/200 AVG Training Loss:0.696 AVG Validation Loss:0.962 AVG Training Acc 55.40 % AVG Validation Acc 21.24 %\n",
      "Epoch:50/200 AVG Training Loss:0.693 AVG Validation Loss:0.955 AVG Training Acc 56.20 % AVG Validation Acc 21.51 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.882 AVG Validation Loss:1.072 AVG Training Acc 50.93 % AVG Validation Acc 23.25 %\n",
      "Epoch:70/200 AVG Training Loss:0.682 AVG Validation Loss:0.714 AVG Training Acc 56.83 % AVG Validation Acc 51.48 %\n",
      "Epoch:80/200 AVG Training Loss:0.680 AVG Validation Loss:0.707 AVG Training Acc 56.23 % AVG Validation Acc 55.24 %\n",
      "Epoch:90/200 AVG Training Loss:0.679 AVG Validation Loss:0.703 AVG Training Acc 56.69 % AVG Validation Acc 56.72 %\n",
      "Epoch:100/200 AVG Training Loss:0.677 AVG Validation Loss:0.700 AVG Training Acc 57.75 % AVG Validation Acc 57.80 %\n",
      "Epoch   109: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.677 AVG Validation Loss:0.701 AVG Training Acc 58.38 % AVG Validation Acc 56.72 %\n",
      "Epoch:120/200 AVG Training Loss:0.675 AVG Validation Loss:0.692 AVG Training Acc 58.46 % AVG Validation Acc 59.81 %\n",
      "Epoch:130/200 AVG Training Loss:0.674 AVG Validation Loss:0.686 AVG Training Acc 58.11 % AVG Validation Acc 60.89 %\n",
      "Epoch:140/200 AVG Training Loss:0.673 AVG Validation Loss:0.681 AVG Training Acc 58.77 % AVG Validation Acc 61.96 %\n",
      "Epoch:150/200 AVG Training Loss:0.674 AVG Validation Loss:0.678 AVG Training Acc 58.76 % AVG Validation Acc 62.23 %\n",
      "Epoch:160/200 AVG Training Loss:0.675 AVG Validation Loss:0.678 AVG Training Acc 58.13 % AVG Validation Acc 62.90 %\n",
      "Epoch:170/200 AVG Training Loss:0.673 AVG Validation Loss:0.676 AVG Training Acc 58.77 % AVG Validation Acc 63.04 %\n",
      "Epoch:180/200 AVG Training Loss:0.673 AVG Validation Loss:0.674 AVG Training Acc 58.85 % AVG Validation Acc 63.71 %\n",
      "Epoch:190/200 AVG Training Loss:0.674 AVG Validation Loss:0.674 AVG Training Acc 58.81 % AVG Validation Acc 63.98 %\n",
      "Epoch:200/200 AVG Training Loss:0.674 AVG Validation Loss:0.674 AVG Training Acc 58.56 % AVG Validation Acc 63.44 %\n",
      "Epoch   200: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Split 67\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "784309f9565141188d34cd90af51401e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.528 AVG Validation Loss:6.440 AVG Training Acc 79.26 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.585 AVG Validation Loss:5.260 AVG Training Acc 74.43 % AVG Validation Acc 20.05 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.696 AVG Validation Loss:0.879 AVG Training Acc 56.27 % AVG Validation Acc 30.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.684 AVG Validation Loss:0.872 AVG Training Acc 56.63 % AVG Validation Acc 24.50 %\n",
      "Epoch:50/200 AVG Training Loss:0.687 AVG Validation Loss:0.864 AVG Training Acc 55.84 % AVG Validation Acc 25.03 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.688 AVG Validation Loss:0.765 AVG Training Acc 54.73 % AVG Validation Acc 35.80 %\n",
      "Epoch:70/200 AVG Training Loss:0.675 AVG Validation Loss:0.693 AVG Training Acc 57.40 % AVG Validation Acc 53.03 %\n",
      "Epoch:80/200 AVG Training Loss:0.672 AVG Validation Loss:0.689 AVG Training Acc 57.86 % AVG Validation Acc 54.24 %\n",
      "Epoch:90/200 AVG Training Loss:0.670 AVG Validation Loss:0.685 AVG Training Acc 58.65 % AVG Validation Acc 54.78 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.666 AVG Validation Loss:0.683 AVG Training Acc 58.98 % AVG Validation Acc 55.59 %\n",
      "Epoch:110/200 AVG Training Loss:0.666 AVG Validation Loss:0.679 AVG Training Acc 58.18 % AVG Validation Acc 56.66 %\n",
      "Epoch:120/200 AVG Training Loss:0.666 AVG Validation Loss:0.674 AVG Training Acc 59.40 % AVG Validation Acc 56.39 %\n",
      "Epoch:130/200 AVG Training Loss:0.667 AVG Validation Loss:0.673 AVG Training Acc 58.77 % AVG Validation Acc 57.07 %\n",
      "Epoch:140/200 AVG Training Loss:0.664 AVG Validation Loss:0.670 AVG Training Acc 58.50 % AVG Validation Acc 57.34 %\n",
      "Epoch:150/200 AVG Training Loss:0.664 AVG Validation Loss:0.671 AVG Training Acc 59.03 % AVG Validation Acc 57.60 %\n",
      "Epoch:160/200 AVG Training Loss:0.665 AVG Validation Loss:0.669 AVG Training Acc 58.66 % AVG Validation Acc 58.14 %\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:170/200 AVG Training Loss:0.666 AVG Validation Loss:0.668 AVG Training Acc 58.55 % AVG Validation Acc 58.41 %\n",
      "Epoch:180/200 AVG Training Loss:0.666 AVG Validation Loss:0.667 AVG Training Acc 59.38 % AVG Validation Acc 58.28 %\n",
      "Epoch:190/200 AVG Training Loss:0.667 AVG Validation Loss:0.667 AVG Training Acc 58.75 % AVG Validation Acc 58.68 %\n",
      "Epoch:200/200 AVG Training Loss:0.665 AVG Validation Loss:0.667 AVG Training Acc 58.51 % AVG Validation Acc 58.14 %\n",
      "Split 68\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40855b0b974f4266be45181bcf9f9f89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.448 AVG Validation Loss:6.559 AVG Training Acc 83.45 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.533 AVG Validation Loss:4.525 AVG Training Acc 80.28 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.533 AVG Validation Loss:3.292 AVG Training Acc 79.38 % AVG Validation Acc 20.05 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.728 AVG Validation Loss:0.837 AVG Training Acc 49.19 % AVG Validation Acc 22.07 %\n",
      "Epoch:50/200 AVG Training Loss:0.696 AVG Validation Loss:0.757 AVG Training Acc 50.66 % AVG Validation Acc 24.23 %\n",
      "Epoch:60/200 AVG Training Loss:0.690 AVG Validation Loss:0.758 AVG Training Acc 52.88 % AVG Validation Acc 25.44 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.693 AVG Validation Loss:0.754 AVG Training Acc 52.40 % AVG Validation Acc 25.84 %\n",
      "Epoch:80/200 AVG Training Loss:0.682 AVG Validation Loss:0.706 AVG Training Acc 55.94 % AVG Validation Acc 40.38 %\n",
      "Epoch:90/200 AVG Training Loss:0.681 AVG Validation Loss:0.691 AVG Training Acc 56.53 % AVG Validation Acc 43.20 %\n",
      "Epoch:100/200 AVG Training Loss:0.679 AVG Validation Loss:0.684 AVG Training Acc 56.76 % AVG Validation Acc 46.43 %\n",
      "Epoch:110/200 AVG Training Loss:0.677 AVG Validation Loss:0.681 AVG Training Acc 57.34 % AVG Validation Acc 49.26 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.676 AVG Validation Loss:0.682 AVG Training Acc 57.60 % AVG Validation Acc 49.53 %\n",
      "Epoch:130/200 AVG Training Loss:0.677 AVG Validation Loss:0.681 AVG Training Acc 56.76 % AVG Validation Acc 50.07 %\n",
      "Epoch:140/200 AVG Training Loss:0.676 AVG Validation Loss:0.680 AVG Training Acc 57.30 % AVG Validation Acc 50.07 %\n",
      "Epoch:150/200 AVG Training Loss:0.676 AVG Validation Loss:0.679 AVG Training Acc 57.15 % AVG Validation Acc 50.61 %\n",
      "Epoch:160/200 AVG Training Loss:0.675 AVG Validation Loss:0.678 AVG Training Acc 57.39 % AVG Validation Acc 51.68 %\n",
      "Epoch   168: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:170/200 AVG Training Loss:0.677 AVG Validation Loss:0.678 AVG Training Acc 57.05 % AVG Validation Acc 51.68 %\n",
      "Epoch:180/200 AVG Training Loss:0.676 AVG Validation Loss:0.677 AVG Training Acc 57.24 % AVG Validation Acc 51.68 %\n",
      "Epoch:190/200 AVG Training Loss:0.675 AVG Validation Loss:0.678 AVG Training Acc 57.51 % AVG Validation Acc 51.68 %\n",
      "Epoch   199: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:200/200 AVG Training Loss:0.675 AVG Validation Loss:0.678 AVG Training Acc 57.46 % AVG Validation Acc 51.68 %\n",
      "Split 69\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33a71ff3e26a40e18d453368898be5ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.539 AVG Validation Loss:4.383 AVG Training Acc 80.43 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.574 AVG Validation Loss:3.843 AVG Training Acc 73.84 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.599 AVG Validation Loss:3.123 AVG Training Acc 74.50 % AVG Validation Acc 20.05 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.688 AVG Validation Loss:0.804 AVG Training Acc 55.58 % AVG Validation Acc 23.28 %\n",
      "Epoch:50/200 AVG Training Loss:0.674 AVG Validation Loss:0.801 AVG Training Acc 58.07 % AVG Validation Acc 31.63 %\n",
      "Epoch:60/200 AVG Training Loss:0.670 AVG Validation Loss:0.803 AVG Training Acc 60.00 % AVG Validation Acc 31.90 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.664 AVG Validation Loss:0.710 AVG Training Acc 60.35 % AVG Validation Acc 53.70 %\n",
      "Epoch:80/200 AVG Training Loss:0.659 AVG Validation Loss:0.683 AVG Training Acc 61.11 % AVG Validation Acc 57.60 %\n",
      "Epoch:90/200 AVG Training Loss:0.658 AVG Validation Loss:0.678 AVG Training Acc 61.54 % AVG Validation Acc 57.74 %\n",
      "Epoch:100/200 AVG Training Loss:0.658 AVG Validation Loss:0.676 AVG Training Acc 61.10 % AVG Validation Acc 58.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.658 AVG Validation Loss:0.676 AVG Training Acc 61.21 % AVG Validation Acc 58.01 %\n",
      "Epoch:120/200 AVG Training Loss:0.657 AVG Validation Loss:0.675 AVG Training Acc 61.61 % AVG Validation Acc 58.01 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.656 AVG Validation Loss:0.675 AVG Training Acc 61.54 % AVG Validation Acc 58.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.654 AVG Validation Loss:0.673 AVG Training Acc 61.96 % AVG Validation Acc 58.55 %\n",
      "Epoch:150/200 AVG Training Loss:0.654 AVG Validation Loss:0.672 AVG Training Acc 61.64 % AVG Validation Acc 58.68 %\n",
      "Epoch:160/200 AVG Training Loss:0.656 AVG Validation Loss:0.671 AVG Training Acc 61.74 % AVG Validation Acc 58.41 %\n",
      "Epoch:170/200 AVG Training Loss:0.653 AVG Validation Loss:0.670 AVG Training Acc 61.67 % AVG Validation Acc 58.55 %\n",
      "Epoch:180/200 AVG Training Loss:0.655 AVG Validation Loss:0.669 AVG Training Acc 61.46 % AVG Validation Acc 58.68 %\n",
      "Epoch:190/200 AVG Training Loss:0.652 AVG Validation Loss:0.669 AVG Training Acc 61.64 % AVG Validation Acc 58.82 %\n",
      "Epoch:200/200 AVG Training Loss:0.653 AVG Validation Loss:0.668 AVG Training Acc 61.59 % AVG Validation Acc 59.35 %\n",
      "Split 70\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "160ebbeb4e3b49f19a0231223a662b24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.499 AVG Validation Loss:6.349 AVG Training Acc 80.27 % AVG Validation Acc 20.19 %\n",
      "Epoch:20/200 AVG Training Loss:0.541 AVG Validation Loss:4.111 AVG Training Acc 74.49 % AVG Validation Acc 20.19 %\n",
      "Epoch:30/200 AVG Training Loss:0.626 AVG Validation Loss:1.915 AVG Training Acc 69.18 % AVG Validation Acc 20.19 %\n",
      "Epoch:40/200 AVG Training Loss:0.837 AVG Validation Loss:1.775 AVG Training Acc 74.82 % AVG Validation Acc 20.19 %\n",
      "Epoch:50/200 AVG Training Loss:0.630 AVG Validation Loss:7.035 AVG Training Acc 83.41 % AVG Validation Acc 20.46 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.757 AVG Validation Loss:0.906 AVG Training Acc 50.23 % AVG Validation Acc 20.73 %\n",
      "Epoch:70/200 AVG Training Loss:0.685 AVG Validation Loss:0.749 AVG Training Acc 54.80 % AVG Validation Acc 29.48 %\n",
      "Epoch:80/200 AVG Training Loss:0.679 AVG Validation Loss:0.756 AVG Training Acc 56.65 % AVG Validation Acc 32.97 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.674 AVG Validation Loss:0.748 AVG Training Acc 56.88 % AVG Validation Acc 41.32 %\n",
      "Epoch:100/200 AVG Training Loss:0.666 AVG Validation Loss:0.710 AVG Training Acc 59.74 % AVG Validation Acc 53.03 %\n",
      "Epoch:110/200 AVG Training Loss:0.666 AVG Validation Loss:0.696 AVG Training Acc 59.58 % AVG Validation Acc 56.12 %\n",
      "Epoch:120/200 AVG Training Loss:0.663 AVG Validation Loss:0.690 AVG Training Acc 60.15 % AVG Validation Acc 58.01 %\n",
      "Epoch:130/200 AVG Training Loss:0.663 AVG Validation Loss:0.688 AVG Training Acc 60.08 % AVG Validation Acc 57.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.662 AVG Validation Loss:0.687 AVG Training Acc 60.77 % AVG Validation Acc 58.55 %\n",
      "Epoch:150/200 AVG Training Loss:0.663 AVG Validation Loss:0.687 AVG Training Acc 60.28 % AVG Validation Acc 58.82 %\n",
      "Epoch:160/200 AVG Training Loss:0.662 AVG Validation Loss:0.687 AVG Training Acc 60.58 % AVG Validation Acc 58.82 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:170/200 AVG Training Loss:0.662 AVG Validation Loss:0.687 AVG Training Acc 60.80 % AVG Validation Acc 58.82 %\n",
      "Epoch:180/200 AVG Training Loss:0.661 AVG Validation Loss:0.686 AVG Training Acc 61.18 % AVG Validation Acc 59.35 %\n",
      "Epoch:190/200 AVG Training Loss:0.661 AVG Validation Loss:0.685 AVG Training Acc 60.68 % AVG Validation Acc 59.22 %\n",
      "Epoch:200/200 AVG Training Loss:0.660 AVG Validation Loss:0.685 AVG Training Acc 60.90 % AVG Validation Acc 59.08 %\n",
      "Split 71\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8890ac1b9c484d3a84cae73ab4b784be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.527 AVG Validation Loss:5.416 AVG Training Acc 77.81 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.575 AVG Validation Loss:6.012 AVG Training Acc 79.09 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.625 AVG Validation Loss:1.883 AVG Training Acc 74.71 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.651 AVG Validation Loss:3.359 AVG Training Acc 64.21 % AVG Validation Acc 20.97 %\n",
      "Epoch:50/200 AVG Training Loss:0.647 AVG Validation Loss:1.645 AVG Training Acc 67.98 % AVG Validation Acc 20.16 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.681 AVG Validation Loss:0.763 AVG Training Acc 56.85 % AVG Validation Acc 33.74 %\n",
      "Epoch:70/200 AVG Training Loss:0.674 AVG Validation Loss:0.773 AVG Training Acc 58.77 % AVG Validation Acc 38.17 %\n",
      "Epoch:80/200 AVG Training Loss:0.670 AVG Validation Loss:0.771 AVG Training Acc 59.58 % AVG Validation Acc 42.34 %\n",
      "Epoch    81: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.667 AVG Validation Loss:0.712 AVG Training Acc 59.26 % AVG Validation Acc 52.69 %\n",
      "Epoch:100/200 AVG Training Loss:0.663 AVG Validation Loss:0.689 AVG Training Acc 60.25 % AVG Validation Acc 55.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.663 AVG Validation Loss:0.683 AVG Training Acc 60.09 % AVG Validation Acc 57.80 %\n",
      "Epoch:120/200 AVG Training Loss:0.662 AVG Validation Loss:0.680 AVG Training Acc 60.84 % AVG Validation Acc 58.06 %\n",
      "Epoch:130/200 AVG Training Loss:0.662 AVG Validation Loss:0.679 AVG Training Acc 60.71 % AVG Validation Acc 57.93 %\n",
      "Epoch:140/200 AVG Training Loss:0.662 AVG Validation Loss:0.677 AVG Training Acc 60.91 % AVG Validation Acc 57.66 %\n",
      "Epoch:150/200 AVG Training Loss:0.660 AVG Validation Loss:0.677 AVG Training Acc 61.05 % AVG Validation Acc 58.20 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:160/200 AVG Training Loss:0.660 AVG Validation Loss:0.677 AVG Training Acc 60.96 % AVG Validation Acc 57.93 %\n",
      "Epoch:170/200 AVG Training Loss:0.659 AVG Validation Loss:0.676 AVG Training Acc 60.87 % AVG Validation Acc 57.80 %\n",
      "Epoch:180/200 AVG Training Loss:0.658 AVG Validation Loss:0.675 AVG Training Acc 61.41 % AVG Validation Acc 57.80 %\n",
      "Epoch:190/200 AVG Training Loss:0.660 AVG Validation Loss:0.674 AVG Training Acc 61.28 % AVG Validation Acc 58.06 %\n",
      "Epoch:200/200 AVG Training Loss:0.661 AVG Validation Loss:0.674 AVG Training Acc 60.87 % AVG Validation Acc 57.93 %\n",
      "Split 72\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af6847de81db47c485a6b206f89c1cd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.536 AVG Validation Loss:5.179 AVG Training Acc 81.11 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.567 AVG Validation Loss:5.591 AVG Training Acc 79.79 % AVG Validation Acc 20.16 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.701 AVG Validation Loss:0.837 AVG Training Acc 51.34 % AVG Validation Acc 20.30 %\n",
      "Epoch:40/200 AVG Training Loss:0.692 AVG Validation Loss:0.799 AVG Training Acc 53.32 % AVG Validation Acc 22.04 %\n",
      "Epoch:50/200 AVG Training Loss:0.686 AVG Validation Loss:0.808 AVG Training Acc 55.98 % AVG Validation Acc 24.06 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.688 AVG Validation Loss:0.762 AVG Training Acc 54.11 % AVG Validation Acc 31.18 %\n",
      "Epoch:70/200 AVG Training Loss:0.676 AVG Validation Loss:0.700 AVG Training Acc 57.35 % AVG Validation Acc 53.36 %\n",
      "Epoch:80/200 AVG Training Loss:0.675 AVG Validation Loss:0.688 AVG Training Acc 57.89 % AVG Validation Acc 58.60 %\n",
      "Epoch:90/200 AVG Training Loss:0.673 AVG Validation Loss:0.686 AVG Training Acc 57.87 % AVG Validation Acc 59.27 %\n",
      "Epoch:100/200 AVG Training Loss:0.673 AVG Validation Loss:0.686 AVG Training Acc 58.09 % AVG Validation Acc 61.42 %\n",
      "Epoch   106: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.671 AVG Validation Loss:0.685 AVG Training Acc 58.07 % AVG Validation Acc 61.42 %\n",
      "Epoch:120/200 AVG Training Loss:0.669 AVG Validation Loss:0.683 AVG Training Acc 58.83 % AVG Validation Acc 62.63 %\n",
      "Epoch:130/200 AVG Training Loss:0.669 AVG Validation Loss:0.680 AVG Training Acc 58.63 % AVG Validation Acc 63.04 %\n",
      "Epoch:140/200 AVG Training Loss:0.668 AVG Validation Loss:0.679 AVG Training Acc 57.88 % AVG Validation Acc 63.04 %\n",
      "Epoch:150/200 AVG Training Loss:0.669 AVG Validation Loss:0.677 AVG Training Acc 58.73 % AVG Validation Acc 63.58 %\n",
      "Epoch:160/200 AVG Training Loss:0.669 AVG Validation Loss:0.676 AVG Training Acc 58.18 % AVG Validation Acc 63.58 %\n",
      "Epoch:170/200 AVG Training Loss:0.668 AVG Validation Loss:0.675 AVG Training Acc 59.04 % AVG Validation Acc 63.58 %\n",
      "Epoch:180/200 AVG Training Loss:0.669 AVG Validation Loss:0.674 AVG Training Acc 58.89 % AVG Validation Acc 63.58 %\n",
      "Epoch:190/200 AVG Training Loss:0.669 AVG Validation Loss:0.674 AVG Training Acc 58.63 % AVG Validation Acc 63.58 %\n",
      "Epoch:200/200 AVG Training Loss:0.669 AVG Validation Loss:0.674 AVG Training Acc 58.98 % AVG Validation Acc 63.84 %\n",
      "Split 73\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8b92ec4a42c44a28fda4162fa5a66f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.481 AVG Validation Loss:6.968 AVG Training Acc 81.96 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.602 AVG Validation Loss:8.259 AVG Training Acc 65.62 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.637 AVG Validation Loss:1.887 AVG Training Acc 68.92 % AVG Validation Acc 20.16 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.694 AVG Validation Loss:0.761 AVG Training Acc 52.66 % AVG Validation Acc 25.40 %\n",
      "Epoch:50/200 AVG Training Loss:0.681 AVG Validation Loss:0.778 AVG Training Acc 57.17 % AVG Validation Acc 30.65 %\n",
      "Epoch:60/200 AVG Training Loss:0.678 AVG Validation Loss:0.768 AVG Training Acc 57.50 % AVG Validation Acc 36.42 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.672 AVG Validation Loss:0.713 AVG Training Acc 59.18 % AVG Validation Acc 52.69 %\n",
      "Epoch:80/200 AVG Training Loss:0.671 AVG Validation Loss:0.691 AVG Training Acc 59.78 % AVG Validation Acc 56.32 %\n",
      "Epoch:90/200 AVG Training Loss:0.668 AVG Validation Loss:0.684 AVG Training Acc 59.89 % AVG Validation Acc 57.53 %\n",
      "Epoch:100/200 AVG Training Loss:0.668 AVG Validation Loss:0.681 AVG Training Acc 60.01 % AVG Validation Acc 57.66 %\n",
      "Epoch:110/200 AVG Training Loss:0.668 AVG Validation Loss:0.680 AVG Training Acc 60.21 % AVG Validation Acc 58.20 %\n",
      "Epoch:120/200 AVG Training Loss:0.666 AVG Validation Loss:0.680 AVG Training Acc 60.33 % AVG Validation Acc 57.93 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.666 AVG Validation Loss:0.679 AVG Training Acc 60.55 % AVG Validation Acc 58.33 %\n",
      "Epoch:140/200 AVG Training Loss:0.666 AVG Validation Loss:0.678 AVG Training Acc 60.41 % AVG Validation Acc 58.20 %\n",
      "Epoch:150/200 AVG Training Loss:0.666 AVG Validation Loss:0.678 AVG Training Acc 60.67 % AVG Validation Acc 58.20 %\n",
      "Epoch:160/200 AVG Training Loss:0.666 AVG Validation Loss:0.677 AVG Training Acc 60.43 % AVG Validation Acc 58.06 %\n",
      "Epoch:170/200 AVG Training Loss:0.667 AVG Validation Loss:0.676 AVG Training Acc 60.55 % AVG Validation Acc 58.06 %\n",
      "Epoch:180/200 AVG Training Loss:0.666 AVG Validation Loss:0.676 AVG Training Acc 61.05 % AVG Validation Acc 58.47 %\n",
      "Epoch:190/200 AVG Training Loss:0.665 AVG Validation Loss:0.676 AVG Training Acc 60.62 % AVG Validation Acc 58.20 %\n",
      "Epoch:200/200 AVG Training Loss:0.664 AVG Validation Loss:0.675 AVG Training Acc 60.86 % AVG Validation Acc 58.20 %\n",
      "Split 74\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9a7611abf9048e5b3f5e662bb7206aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.504 AVG Validation Loss:3.560 AVG Training Acc 79.46 % AVG Validation Acc 20.16 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.655 AVG Validation Loss:4.359 AVG Training Acc 71.61 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.663 AVG Validation Loss:1.330 AVG Training Acc 62.47 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.677 AVG Validation Loss:1.071 AVG Training Acc 60.36 % AVG Validation Acc 20.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.674 AVG Validation Loss:1.042 AVG Training Acc 60.91 % AVG Validation Acc 20.56 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.671 AVG Validation Loss:0.709 AVG Training Acc 59.04 % AVG Validation Acc 49.33 %\n",
      "Epoch:70/200 AVG Training Loss:0.666 AVG Validation Loss:0.692 AVG Training Acc 59.86 % AVG Validation Acc 52.28 %\n",
      "Epoch:80/200 AVG Training Loss:0.666 AVG Validation Loss:0.693 AVG Training Acc 60.03 % AVG Validation Acc 51.75 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.663 AVG Validation Loss:0.686 AVG Training Acc 60.80 % AVG Validation Acc 52.55 %\n",
      "Epoch:100/200 AVG Training Loss:0.662 AVG Validation Loss:0.680 AVG Training Acc 61.21 % AVG Validation Acc 52.96 %\n",
      "Epoch:110/200 AVG Training Loss:0.660 AVG Validation Loss:0.674 AVG Training Acc 61.23 % AVG Validation Acc 55.91 %\n",
      "Epoch:120/200 AVG Training Loss:0.661 AVG Validation Loss:0.672 AVG Training Acc 61.26 % AVG Validation Acc 55.51 %\n",
      "Epoch:130/200 AVG Training Loss:0.661 AVG Validation Loss:0.669 AVG Training Acc 61.10 % AVG Validation Acc 55.65 %\n",
      "Epoch:140/200 AVG Training Loss:0.660 AVG Validation Loss:0.668 AVG Training Acc 60.94 % AVG Validation Acc 55.91 %\n",
      "Epoch:150/200 AVG Training Loss:0.660 AVG Validation Loss:0.668 AVG Training Acc 61.01 % AVG Validation Acc 55.51 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:160/200 AVG Training Loss:0.661 AVG Validation Loss:0.667 AVG Training Acc 61.13 % AVG Validation Acc 55.51 %\n",
      "Epoch:170/200 AVG Training Loss:0.659 AVG Validation Loss:0.669 AVG Training Acc 61.34 % AVG Validation Acc 55.24 %\n",
      "Epoch:180/200 AVG Training Loss:0.660 AVG Validation Loss:0.669 AVG Training Acc 61.28 % AVG Validation Acc 54.57 %\n",
      "Epoch   183: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:190/200 AVG Training Loss:0.661 AVG Validation Loss:0.667 AVG Training Acc 61.26 % AVG Validation Acc 56.32 %\n",
      "Epoch:200/200 AVG Training Loss:0.661 AVG Validation Loss:0.667 AVG Training Acc 60.97 % AVG Validation Acc 55.78 %\n",
      "Split 75\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a2b870be4064f63bfa7570dcb7d8350",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.495 AVG Validation Loss:4.307 AVG Training Acc 81.05 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.595 AVG Validation Loss:2.023 AVG Training Acc 76.70 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.640 AVG Validation Loss:3.745 AVG Training Acc 65.23 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.626 AVG Validation Loss:1.885 AVG Training Acc 69.92 % AVG Validation Acc 20.16 %\n",
      "Epoch    40: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.690 AVG Validation Loss:0.789 AVG Training Acc 53.84 % AVG Validation Acc 24.87 %\n",
      "Epoch:60/200 AVG Training Loss:0.678 AVG Validation Loss:0.816 AVG Training Acc 58.28 % AVG Validation Acc 35.89 %\n",
      "Epoch:70/200 AVG Training Loss:0.674 AVG Validation Loss:0.795 AVG Training Acc 59.46 % AVG Validation Acc 41.26 %\n",
      "Epoch    71: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.670 AVG Validation Loss:0.709 AVG Training Acc 59.77 % AVG Validation Acc 57.12 %\n",
      "Epoch:90/200 AVG Training Loss:0.666 AVG Validation Loss:0.684 AVG Training Acc 60.64 % AVG Validation Acc 59.68 %\n",
      "Epoch:100/200 AVG Training Loss:0.664 AVG Validation Loss:0.678 AVG Training Acc 60.88 % AVG Validation Acc 61.02 %\n",
      "Epoch:110/200 AVG Training Loss:0.663 AVG Validation Loss:0.676 AVG Training Acc 60.94 % AVG Validation Acc 60.62 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.661 AVG Validation Loss:0.676 AVG Training Acc 61.43 % AVG Validation Acc 61.02 %\n",
      "Epoch:130/200 AVG Training Loss:0.661 AVG Validation Loss:0.675 AVG Training Acc 61.58 % AVG Validation Acc 60.62 %\n",
      "Epoch:140/200 AVG Training Loss:0.660 AVG Validation Loss:0.673 AVG Training Acc 61.53 % AVG Validation Acc 60.75 %\n",
      "Epoch:150/200 AVG Training Loss:0.661 AVG Validation Loss:0.672 AVG Training Acc 61.05 % AVG Validation Acc 61.02 %\n",
      "Epoch:160/200 AVG Training Loss:0.663 AVG Validation Loss:0.671 AVG Training Acc 61.23 % AVG Validation Acc 60.75 %\n",
      "Epoch:170/200 AVG Training Loss:0.661 AVG Validation Loss:0.670 AVG Training Acc 61.23 % AVG Validation Acc 60.62 %\n",
      "Epoch:180/200 AVG Training Loss:0.660 AVG Validation Loss:0.669 AVG Training Acc 61.48 % AVG Validation Acc 61.02 %\n",
      "Epoch:190/200 AVG Training Loss:0.662 AVG Validation Loss:0.669 AVG Training Acc 61.39 % AVG Validation Acc 61.02 %\n",
      "Epoch:200/200 AVG Training Loss:0.662 AVG Validation Loss:0.668 AVG Training Acc 61.37 % AVG Validation Acc 60.89 %\n",
      "Split 76\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d1cf608d77d4d71b9212bdf1704327b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.558 AVG Validation Loss:3.344 AVG Training Acc 78.09 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.543 AVG Validation Loss:3.320 AVG Training Acc 78.48 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.508 AVG Validation Loss:7.484 AVG Training Acc 83.25 % AVG Validation Acc 20.16 %\n",
      "Epoch    39: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:2.179 AVG Validation Loss:1.203 AVG Training Acc 50.06 % AVG Validation Acc 20.30 %\n",
      "Epoch:50/200 AVG Training Loss:0.680 AVG Validation Loss:0.817 AVG Training Acc 56.14 % AVG Validation Acc 26.88 %\n",
      "Epoch:60/200 AVG Training Loss:0.674 AVG Validation Loss:0.794 AVG Training Acc 59.24 % AVG Validation Acc 42.47 %\n",
      "Epoch:70/200 AVG Training Loss:0.669 AVG Validation Loss:0.783 AVG Training Acc 59.86 % AVG Validation Acc 42.61 %\n",
      "Epoch:80/200 AVG Training Loss:0.666 AVG Validation Loss:0.774 AVG Training Acc 60.56 % AVG Validation Acc 42.20 %\n",
      "Epoch:90/200 AVG Training Loss:0.655 AVG Validation Loss:0.783 AVG Training Acc 61.62 % AVG Validation Acc 39.92 %\n",
      "Epoch:100/200 AVG Training Loss:0.650 AVG Validation Loss:0.785 AVG Training Acc 62.71 % AVG Validation Acc 38.44 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:110/200 AVG Training Loss:0.648 AVG Validation Loss:0.712 AVG Training Acc 62.41 % AVG Validation Acc 53.23 %\n",
      "Epoch:120/200 AVG Training Loss:0.642 AVG Validation Loss:0.693 AVG Training Acc 63.13 % AVG Validation Acc 56.85 %\n",
      "Epoch:130/200 AVG Training Loss:0.642 AVG Validation Loss:0.689 AVG Training Acc 62.78 % AVG Validation Acc 57.26 %\n",
      "Epoch:140/200 AVG Training Loss:0.641 AVG Validation Loss:0.687 AVG Training Acc 63.42 % AVG Validation Acc 56.72 %\n",
      "Epoch:150/200 AVG Training Loss:0.638 AVG Validation Loss:0.685 AVG Training Acc 63.27 % AVG Validation Acc 57.12 %\n",
      "Epoch:160/200 AVG Training Loss:0.637 AVG Validation Loss:0.683 AVG Training Acc 63.57 % AVG Validation Acc 57.12 %\n",
      "Epoch:170/200 AVG Training Loss:0.635 AVG Validation Loss:0.683 AVG Training Acc 63.59 % AVG Validation Acc 56.99 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:180/200 AVG Training Loss:0.633 AVG Validation Loss:0.683 AVG Training Acc 64.00 % AVG Validation Acc 56.59 %\n",
      "Epoch:190/200 AVG Training Loss:0.635 AVG Validation Loss:0.680 AVG Training Acc 63.81 % AVG Validation Acc 57.12 %\n",
      "Epoch:200/200 AVG Training Loss:0.632 AVG Validation Loss:0.678 AVG Training Acc 63.84 % AVG Validation Acc 57.26 %\n",
      "Split 77\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db09e338e68d442cb993a08622025764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.555 AVG Validation Loss:3.428 AVG Training Acc 78.18 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.533 AVG Validation Loss:5.836 AVG Training Acc 80.80 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.648 AVG Validation Loss:1.752 AVG Training Acc 67.05 % AVG Validation Acc 20.32 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.842 AVG Validation Loss:1.047 AVG Training Acc 50.25 % AVG Validation Acc 20.73 %\n",
      "Epoch:50/200 AVG Training Loss:0.688 AVG Validation Loss:0.771 AVG Training Acc 54.05 % AVG Validation Acc 26.92 %\n",
      "Epoch:60/200 AVG Training Loss:0.676 AVG Validation Loss:0.779 AVG Training Acc 58.16 % AVG Validation Acc 34.32 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.678 AVG Validation Loss:0.765 AVG Training Acc 56.72 % AVG Validation Acc 40.65 %\n",
      "Epoch:80/200 AVG Training Loss:0.667 AVG Validation Loss:0.701 AVG Training Acc 60.35 % AVG Validation Acc 55.99 %\n",
      "Epoch:90/200 AVG Training Loss:0.662 AVG Validation Loss:0.681 AVG Training Acc 60.82 % AVG Validation Acc 58.68 %\n",
      "Epoch:100/200 AVG Training Loss:0.663 AVG Validation Loss:0.676 AVG Training Acc 60.94 % AVG Validation Acc 59.62 %\n",
      "Epoch:110/200 AVG Training Loss:0.663 AVG Validation Loss:0.673 AVG Training Acc 60.94 % AVG Validation Acc 60.30 %\n",
      "Epoch:120/200 AVG Training Loss:0.661 AVG Validation Loss:0.672 AVG Training Acc 61.42 % AVG Validation Acc 60.30 %\n",
      "Epoch:130/200 AVG Training Loss:0.660 AVG Validation Loss:0.671 AVG Training Acc 60.92 % AVG Validation Acc 60.16 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:140/200 AVG Training Loss:0.661 AVG Validation Loss:0.671 AVG Training Acc 61.38 % AVG Validation Acc 60.03 %\n",
      "Epoch:150/200 AVG Training Loss:0.660 AVG Validation Loss:0.670 AVG Training Acc 61.09 % AVG Validation Acc 60.30 %\n",
      "Epoch:160/200 AVG Training Loss:0.659 AVG Validation Loss:0.669 AVG Training Acc 61.34 % AVG Validation Acc 60.30 %\n",
      "Epoch:170/200 AVG Training Loss:0.659 AVG Validation Loss:0.668 AVG Training Acc 61.18 % AVG Validation Acc 60.43 %\n",
      "Epoch:180/200 AVG Training Loss:0.661 AVG Validation Loss:0.667 AVG Training Acc 61.03 % AVG Validation Acc 60.97 %\n",
      "Epoch:190/200 AVG Training Loss:0.658 AVG Validation Loss:0.666 AVG Training Acc 61.54 % AVG Validation Acc 60.83 %\n",
      "Epoch:200/200 AVG Training Loss:0.659 AVG Validation Loss:0.665 AVG Training Acc 61.86 % AVG Validation Acc 60.57 %\n",
      "Split 78\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a03b466339fd48b598a4e5ecde40603d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.547 AVG Validation Loss:4.575 AVG Training Acc 79.16 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.534 AVG Validation Loss:8.454 AVG Training Acc 80.02 % AVG Validation Acc 20.05 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.688 AVG Validation Loss:0.809 AVG Training Acc 55.96 % AVG Validation Acc 26.65 %\n",
      "Epoch:40/200 AVG Training Loss:0.680 AVG Validation Loss:0.805 AVG Training Acc 58.04 % AVG Validation Acc 26.38 %\n",
      "Epoch:50/200 AVG Training Loss:0.673 AVG Validation Loss:0.804 AVG Training Acc 59.13 % AVG Validation Acc 26.51 %\n",
      "Epoch:60/200 AVG Training Loss:0.669 AVG Validation Loss:0.803 AVG Training Acc 59.20 % AVG Validation Acc 28.13 %\n",
      "Epoch:70/200 AVG Training Loss:0.666 AVG Validation Loss:0.791 AVG Training Acc 59.89 % AVG Validation Acc 32.30 %\n",
      "Epoch:80/200 AVG Training Loss:0.664 AVG Validation Loss:0.787 AVG Training Acc 60.07 % AVG Validation Acc 32.44 %\n",
      "Epoch:90/200 AVG Training Loss:0.658 AVG Validation Loss:0.784 AVG Training Acc 60.54 % AVG Validation Acc 35.13 %\n",
      "Epoch:100/200 AVG Training Loss:0.655 AVG Validation Loss:0.780 AVG Training Acc 61.29 % AVG Validation Acc 37.15 %\n",
      "Epoch:110/200 AVG Training Loss:0.646 AVG Validation Loss:0.798 AVG Training Acc 62.21 % AVG Validation Acc 35.26 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:120/200 AVG Training Loss:0.641 AVG Validation Loss:0.703 AVG Training Acc 62.07 % AVG Validation Acc 52.76 %\n",
      "Epoch:130/200 AVG Training Loss:0.639 AVG Validation Loss:0.686 AVG Training Acc 62.65 % AVG Validation Acc 54.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.637 AVG Validation Loss:0.681 AVG Training Acc 62.42 % AVG Validation Acc 55.59 %\n",
      "Epoch:150/200 AVG Training Loss:0.635 AVG Validation Loss:0.678 AVG Training Acc 62.49 % AVG Validation Acc 55.85 %\n",
      "Epoch:160/200 AVG Training Loss:0.633 AVG Validation Loss:0.677 AVG Training Acc 62.89 % AVG Validation Acc 55.99 %\n",
      "Epoch   168: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:170/200 AVG Training Loss:0.632 AVG Validation Loss:0.675 AVG Training Acc 62.73 % AVG Validation Acc 56.39 %\n",
      "Epoch:180/200 AVG Training Loss:0.633 AVG Validation Loss:0.675 AVG Training Acc 63.31 % AVG Validation Acc 56.93 %\n",
      "Epoch:190/200 AVG Training Loss:0.633 AVG Validation Loss:0.671 AVG Training Acc 62.65 % AVG Validation Acc 57.34 %\n",
      "Epoch:200/200 AVG Training Loss:0.632 AVG Validation Loss:0.672 AVG Training Acc 62.93 % AVG Validation Acc 57.07 %\n",
      "Split 79\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "887020cabfb14637b6ca0a6a3d392f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.561 AVG Validation Loss:2.728 AVG Training Acc 76.96 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.456 AVG Validation Loss:6.056 AVG Training Acc 81.49 % AVG Validation Acc 20.46 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.649 AVG Validation Loss:2.729 AVG Training Acc 59.47 % AVG Validation Acc 20.19 %\n",
      "Epoch:40/200 AVG Training Loss:0.716 AVG Validation Loss:0.764 AVG Training Acc 53.72 % AVG Validation Acc 40.11 %\n",
      "Epoch:50/200 AVG Training Loss:0.671 AVG Validation Loss:0.906 AVG Training Acc 59.06 % AVG Validation Acc 26.24 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.678 AVG Validation Loss:0.732 AVG Training Acc 57.28 % AVG Validation Acc 50.61 %\n",
      "Epoch:70/200 AVG Training Loss:0.673 AVG Validation Loss:0.696 AVG Training Acc 58.71 % AVG Validation Acc 58.14 %\n",
      "Epoch:80/200 AVG Training Loss:0.669 AVG Validation Loss:0.687 AVG Training Acc 59.71 % AVG Validation Acc 59.76 %\n",
      "Epoch:90/200 AVG Training Loss:0.665 AVG Validation Loss:0.683 AVG Training Acc 60.18 % AVG Validation Acc 59.62 %\n",
      "Epoch:100/200 AVG Training Loss:0.666 AVG Validation Loss:0.682 AVG Training Acc 60.51 % AVG Validation Acc 60.30 %\n",
      "Epoch:110/200 AVG Training Loss:0.665 AVG Validation Loss:0.682 AVG Training Acc 60.21 % AVG Validation Acc 59.89 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.664 AVG Validation Loss:0.679 AVG Training Acc 60.37 % AVG Validation Acc 60.16 %\n",
      "Epoch:130/200 AVG Training Loss:0.664 AVG Validation Loss:0.672 AVG Training Acc 60.43 % AVG Validation Acc 61.37 %\n",
      "Epoch:140/200 AVG Training Loss:0.662 AVG Validation Loss:0.669 AVG Training Acc 60.51 % AVG Validation Acc 60.97 %\n",
      "Epoch:150/200 AVG Training Loss:0.662 AVG Validation Loss:0.668 AVG Training Acc 60.51 % AVG Validation Acc 61.10 %\n",
      "Epoch:160/200 AVG Training Loss:0.663 AVG Validation Loss:0.667 AVG Training Acc 60.80 % AVG Validation Acc 61.37 %\n",
      "Epoch:170/200 AVG Training Loss:0.662 AVG Validation Loss:0.664 AVG Training Acc 61.04 % AVG Validation Acc 61.78 %\n",
      "Epoch:180/200 AVG Training Loss:0.664 AVG Validation Loss:0.664 AVG Training Acc 60.52 % AVG Validation Acc 61.78 %\n",
      "Epoch:190/200 AVG Training Loss:0.662 AVG Validation Loss:0.666 AVG Training Acc 60.81 % AVG Validation Acc 61.24 %\n",
      "Epoch   199: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:200/200 AVG Training Loss:0.661 AVG Validation Loss:0.665 AVG Training Acc 61.02 % AVG Validation Acc 61.78 %\n",
      "Split 80\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72d2978c47bb4c41810ef19a34c55ca3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.593 AVG Validation Loss:2.469 AVG Training Acc 74.08 % AVG Validation Acc 20.19 %\n",
      "Epoch:20/200 AVG Training Loss:0.596 AVG Validation Loss:1.886 AVG Training Acc 72.78 % AVG Validation Acc 20.19 %\n",
      "Epoch:30/200 AVG Training Loss:0.642 AVG Validation Loss:1.651 AVG Training Acc 66.60 % AVG Validation Acc 20.19 %\n",
      "Epoch:40/200 AVG Training Loss:0.618 AVG Validation Loss:2.624 AVG Training Acc 78.54 % AVG Validation Acc 20.19 %\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.685 AVG Validation Loss:0.842 AVG Training Acc 55.86 % AVG Validation Acc 22.34 %\n",
      "Epoch:60/200 AVG Training Loss:0.678 AVG Validation Loss:0.849 AVG Training Acc 57.88 % AVG Validation Acc 24.50 %\n",
      "Epoch:70/200 AVG Training Loss:0.676 AVG Validation Loss:0.852 AVG Training Acc 57.72 % AVG Validation Acc 24.23 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.673 AVG Validation Loss:0.731 AVG Training Acc 57.36 % AVG Validation Acc 48.45 %\n",
      "Epoch:90/200 AVG Training Loss:0.668 AVG Validation Loss:0.697 AVG Training Acc 59.01 % AVG Validation Acc 56.53 %\n",
      "Epoch:100/200 AVG Training Loss:0.667 AVG Validation Loss:0.691 AVG Training Acc 59.40 % AVG Validation Acc 58.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.667 AVG Validation Loss:0.690 AVG Training Acc 59.28 % AVG Validation Acc 58.41 %\n",
      "Epoch:120/200 AVG Training Loss:0.666 AVG Validation Loss:0.690 AVG Training Acc 59.79 % AVG Validation Acc 58.41 %\n",
      "Epoch   123: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.662 AVG Validation Loss:0.688 AVG Training Acc 59.80 % AVG Validation Acc 58.55 %\n",
      "Epoch:140/200 AVG Training Loss:0.663 AVG Validation Loss:0.686 AVG Training Acc 59.93 % AVG Validation Acc 58.55 %\n",
      "Epoch:150/200 AVG Training Loss:0.663 AVG Validation Loss:0.684 AVG Training Acc 59.79 % AVG Validation Acc 58.95 %\n",
      "Epoch:160/200 AVG Training Loss:0.663 AVG Validation Loss:0.682 AVG Training Acc 59.70 % AVG Validation Acc 59.22 %\n",
      "Epoch:170/200 AVG Training Loss:0.662 AVG Validation Loss:0.681 AVG Training Acc 60.02 % AVG Validation Acc 59.22 %\n",
      "Epoch:180/200 AVG Training Loss:0.663 AVG Validation Loss:0.680 AVG Training Acc 59.89 % AVG Validation Acc 60.03 %\n",
      "Epoch:190/200 AVG Training Loss:0.664 AVG Validation Loss:0.679 AVG Training Acc 59.87 % AVG Validation Acc 59.89 %\n",
      "Epoch:200/200 AVG Training Loss:0.662 AVG Validation Loss:0.678 AVG Training Acc 59.68 % AVG Validation Acc 59.89 %\n",
      "Split 81\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13b91509c093491180051c6a34deb06a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.529 AVG Validation Loss:10.041 AVG Training Acc 78.95 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.527 AVG Validation Loss:5.092 AVG Training Acc 82.32 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.595 AVG Validation Loss:2.396 AVG Training Acc 73.70 % AVG Validation Acc 20.16 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.697 AVG Validation Loss:0.780 AVG Training Acc 50.80 % AVG Validation Acc 22.58 %\n",
      "Epoch:50/200 AVG Training Loss:0.694 AVG Validation Loss:0.790 AVG Training Acc 51.83 % AVG Validation Acc 24.46 %\n",
      "Epoch:60/200 AVG Training Loss:0.685 AVG Validation Loss:0.804 AVG Training Acc 54.64 % AVG Validation Acc 25.13 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.680 AVG Validation Loss:0.736 AVG Training Acc 55.79 % AVG Validation Acc 40.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.676 AVG Validation Loss:0.702 AVG Training Acc 57.17 % AVG Validation Acc 51.34 %\n",
      "Epoch:90/200 AVG Training Loss:0.674 AVG Validation Loss:0.693 AVG Training Acc 57.94 % AVG Validation Acc 54.70 %\n",
      "Epoch:100/200 AVG Training Loss:0.672 AVG Validation Loss:0.690 AVG Training Acc 57.91 % AVG Validation Acc 55.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.671 AVG Validation Loss:0.689 AVG Training Acc 57.78 % AVG Validation Acc 56.32 %\n",
      "Epoch:120/200 AVG Training Loss:0.671 AVG Validation Loss:0.690 AVG Training Acc 57.94 % AVG Validation Acc 57.12 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.668 AVG Validation Loss:0.689 AVG Training Acc 58.82 % AVG Validation Acc 56.99 %\n",
      "Epoch:140/200 AVG Training Loss:0.669 AVG Validation Loss:0.688 AVG Training Acc 59.09 % AVG Validation Acc 56.99 %\n",
      "Epoch:150/200 AVG Training Loss:0.668 AVG Validation Loss:0.686 AVG Training Acc 59.18 % AVG Validation Acc 57.26 %\n",
      "Epoch:160/200 AVG Training Loss:0.670 AVG Validation Loss:0.686 AVG Training Acc 58.74 % AVG Validation Acc 57.39 %\n",
      "Epoch:170/200 AVG Training Loss:0.669 AVG Validation Loss:0.685 AVG Training Acc 58.58 % AVG Validation Acc 57.66 %\n",
      "Epoch:180/200 AVG Training Loss:0.668 AVG Validation Loss:0.684 AVG Training Acc 58.75 % AVG Validation Acc 58.06 %\n",
      "Epoch:190/200 AVG Training Loss:0.671 AVG Validation Loss:0.683 AVG Training Acc 58.52 % AVG Validation Acc 57.93 %\n",
      "Epoch:200/200 AVG Training Loss:0.670 AVG Validation Loss:0.683 AVG Training Acc 58.74 % AVG Validation Acc 58.20 %\n",
      "Split 82\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7d6ec123eed4c81b8afc85f65183c79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.510 AVG Validation Loss:4.831 AVG Training Acc 77.93 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.517 AVG Validation Loss:6.031 AVG Training Acc 80.72 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.662 AVG Validation Loss:1.491 AVG Training Acc 63.97 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.650 AVG Validation Loss:1.611 AVG Training Acc 65.72 % AVG Validation Acc 20.16 %\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.687 AVG Validation Loss:0.758 AVG Training Acc 54.95 % AVG Validation Acc 27.96 %\n",
      "Epoch:60/200 AVG Training Loss:0.678 AVG Validation Loss:0.753 AVG Training Acc 57.11 % AVG Validation Acc 33.74 %\n",
      "Epoch:70/200 AVG Training Loss:0.676 AVG Validation Loss:0.751 AVG Training Acc 58.22 % AVG Validation Acc 38.31 %\n",
      "Epoch:80/200 AVG Training Loss:0.672 AVG Validation Loss:0.750 AVG Training Acc 58.97 % AVG Validation Acc 41.94 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.666 AVG Validation Loss:0.700 AVG Training Acc 59.92 % AVG Validation Acc 57.80 %\n",
      "Epoch:100/200 AVG Training Loss:0.664 AVG Validation Loss:0.670 AVG Training Acc 60.40 % AVG Validation Acc 61.02 %\n",
      "Epoch:110/200 AVG Training Loss:0.662 AVG Validation Loss:0.662 AVG Training Acc 60.40 % AVG Validation Acc 61.69 %\n",
      "Epoch:120/200 AVG Training Loss:0.661 AVG Validation Loss:0.660 AVG Training Acc 60.54 % AVG Validation Acc 61.69 %\n",
      "Epoch:130/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 60.79 % AVG Validation Acc 61.69 %\n",
      "Epoch:140/200 AVG Training Loss:0.660 AVG Validation Loss:0.658 AVG Training Acc 60.88 % AVG Validation Acc 62.10 %\n",
      "Epoch:150/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 60.92 % AVG Validation Acc 61.83 %\n",
      "Epoch:160/200 AVG Training Loss:0.658 AVG Validation Loss:0.657 AVG Training Acc 61.38 % AVG Validation Acc 61.96 %\n",
      "Epoch:170/200 AVG Training Loss:0.659 AVG Validation Loss:0.658 AVG Training Acc 61.31 % AVG Validation Acc 61.56 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:180/200 AVG Training Loss:0.656 AVG Validation Loss:0.656 AVG Training Acc 61.44 % AVG Validation Acc 61.96 %\n",
      "Epoch:190/200 AVG Training Loss:0.656 AVG Validation Loss:0.655 AVG Training Acc 61.18 % AVG Validation Acc 62.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.658 AVG Validation Loss:0.654 AVG Training Acc 61.41 % AVG Validation Acc 62.23 %\n",
      "Split 83\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e37ee04eb034ba584eeb4c969328293",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.561 AVG Validation Loss:5.955 AVG Training Acc 78.07 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.563 AVG Validation Loss:5.916 AVG Training Acc 78.30 % AVG Validation Acc 20.16 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.704 AVG Validation Loss:0.797 AVG Training Acc 49.99 % AVG Validation Acc 22.18 %\n",
      "Epoch:40/200 AVG Training Loss:0.689 AVG Validation Loss:0.801 AVG Training Acc 55.05 % AVG Validation Acc 23.92 %\n",
      "Epoch:50/200 AVG Training Loss:0.681 AVG Validation Loss:0.819 AVG Training Acc 56.83 % AVG Validation Acc 26.61 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.683 AVG Validation Loss:0.759 AVG Training Acc 54.71 % AVG Validation Acc 36.83 %\n",
      "Epoch:70/200 AVG Training Loss:0.671 AVG Validation Loss:0.698 AVG Training Acc 58.25 % AVG Validation Acc 55.38 %\n",
      "Epoch:80/200 AVG Training Loss:0.669 AVG Validation Loss:0.686 AVG Training Acc 58.68 % AVG Validation Acc 59.81 %\n",
      "Epoch:90/200 AVG Training Loss:0.668 AVG Validation Loss:0.684 AVG Training Acc 59.36 % AVG Validation Acc 60.35 %\n",
      "Epoch:100/200 AVG Training Loss:0.667 AVG Validation Loss:0.684 AVG Training Acc 59.52 % AVG Validation Acc 60.08 %\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.665 AVG Validation Loss:0.681 AVG Training Acc 59.79 % AVG Validation Acc 60.62 %\n",
      "Epoch:120/200 AVG Training Loss:0.664 AVG Validation Loss:0.679 AVG Training Acc 59.78 % AVG Validation Acc 60.89 %\n",
      "Epoch:130/200 AVG Training Loss:0.666 AVG Validation Loss:0.678 AVG Training Acc 59.30 % AVG Validation Acc 61.16 %\n",
      "Epoch:140/200 AVG Training Loss:0.665 AVG Validation Loss:0.676 AVG Training Acc 59.93 % AVG Validation Acc 61.29 %\n",
      "Epoch:150/200 AVG Training Loss:0.665 AVG Validation Loss:0.675 AVG Training Acc 59.72 % AVG Validation Acc 61.56 %\n",
      "Epoch:160/200 AVG Training Loss:0.664 AVG Validation Loss:0.674 AVG Training Acc 59.63 % AVG Validation Acc 61.83 %\n",
      "Epoch:170/200 AVG Training Loss:0.665 AVG Validation Loss:0.673 AVG Training Acc 59.79 % AVG Validation Acc 62.10 %\n",
      "Epoch:180/200 AVG Training Loss:0.665 AVG Validation Loss:0.673 AVG Training Acc 59.60 % AVG Validation Acc 62.50 %\n",
      "Epoch:190/200 AVG Training Loss:0.664 AVG Validation Loss:0.672 AVG Training Acc 59.08 % AVG Validation Acc 62.23 %\n",
      "Epoch:200/200 AVG Training Loss:0.662 AVG Validation Loss:0.672 AVG Training Acc 60.11 % AVG Validation Acc 62.37 %\n",
      "Split 84\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff3152477f7541a7aea1390cf6c86c25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.555 AVG Validation Loss:9.784 AVG Training Acc 76.92 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.573 AVG Validation Loss:2.448 AVG Training Acc 77.20 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.545 AVG Validation Loss:5.229 AVG Training Acc 81.95 % AVG Validation Acc 20.16 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.854 AVG Validation Loss:1.055 AVG Training Acc 50.02 % AVG Validation Acc 20.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.679 AVG Validation Loss:0.772 AVG Training Acc 57.27 % AVG Validation Acc 28.23 %\n",
      "Epoch:60/200 AVG Training Loss:0.677 AVG Validation Loss:0.772 AVG Training Acc 58.52 % AVG Validation Acc 41.40 %\n",
      "Epoch:70/200 AVG Training Loss:0.674 AVG Validation Loss:0.770 AVG Training Acc 58.95 % AVG Validation Acc 45.83 %\n",
      "Epoch:80/200 AVG Training Loss:0.669 AVG Validation Loss:0.765 AVG Training Acc 59.80 % AVG Validation Acc 47.58 %\n",
      "Epoch:90/200 AVG Training Loss:0.667 AVG Validation Loss:0.754 AVG Training Acc 60.30 % AVG Validation Acc 47.45 %\n",
      "Epoch:100/200 AVG Training Loss:0.658 AVG Validation Loss:0.749 AVG Training Acc 61.10 % AVG Validation Acc 47.45 %\n",
      "Epoch:110/200 AVG Training Loss:0.664 AVG Validation Loss:0.751 AVG Training Acc 61.56 % AVG Validation Acc 45.70 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:120/200 AVG Training Loss:0.645 AVG Validation Loss:0.703 AVG Training Acc 62.28 % AVG Validation Acc 54.97 %\n",
      "Epoch:130/200 AVG Training Loss:0.640 AVG Validation Loss:0.669 AVG Training Acc 62.97 % AVG Validation Acc 59.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.640 AVG Validation Loss:0.661 AVG Training Acc 63.36 % AVG Validation Acc 59.41 %\n",
      "Epoch:150/200 AVG Training Loss:0.637 AVG Validation Loss:0.655 AVG Training Acc 63.72 % AVG Validation Acc 60.08 %\n",
      "Epoch:160/200 AVG Training Loss:0.633 AVG Validation Loss:0.656 AVG Training Acc 64.13 % AVG Validation Acc 59.95 %\n",
      "Epoch:170/200 AVG Training Loss:0.632 AVG Validation Loss:0.652 AVG Training Acc 64.35 % AVG Validation Acc 59.68 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:180/200 AVG Training Loss:0.630 AVG Validation Loss:0.653 AVG Training Acc 64.18 % AVG Validation Acc 60.48 %\n",
      "Epoch:190/200 AVG Training Loss:0.628 AVG Validation Loss:0.652 AVG Training Acc 64.38 % AVG Validation Acc 60.35 %\n",
      "Epoch:200/200 AVG Training Loss:0.629 AVG Validation Loss:0.650 AVG Training Acc 64.68 % AVG Validation Acc 60.75 %\n",
      "Split 85\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7398969ee8f644f19f93af45038c9e17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.528 AVG Validation Loss:3.484 AVG Training Acc 78.04 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.588 AVG Validation Loss:4.062 AVG Training Acc 80.03 % AVG Validation Acc 20.16 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.683 AVG Validation Loss:1.234 AVG Training Acc 63.90 % AVG Validation Acc 21.10 %\n",
      "Epoch:40/200 AVG Training Loss:0.674 AVG Validation Loss:0.937 AVG Training Acc 60.57 % AVG Validation Acc 22.45 %\n",
      "Epoch:50/200 AVG Training Loss:0.669 AVG Validation Loss:0.918 AVG Training Acc 60.39 % AVG Validation Acc 23.52 %\n",
      "Epoch:60/200 AVG Training Loss:0.663 AVG Validation Loss:0.934 AVG Training Acc 61.61 % AVG Validation Acc 22.85 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.664 AVG Validation Loss:0.727 AVG Training Acc 60.04 % AVG Validation Acc 46.64 %\n",
      "Epoch:80/200 AVG Training Loss:0.663 AVG Validation Loss:0.707 AVG Training Acc 60.50 % AVG Validation Acc 49.33 %\n",
      "Epoch:90/200 AVG Training Loss:0.661 AVG Validation Loss:0.705 AVG Training Acc 60.56 % AVG Validation Acc 48.25 %\n",
      "Epoch:100/200 AVG Training Loss:0.660 AVG Validation Loss:0.705 AVG Training Acc 61.14 % AVG Validation Acc 49.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.660 AVG Validation Loss:0.704 AVG Training Acc 61.06 % AVG Validation Acc 48.79 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.658 AVG Validation Loss:0.702 AVG Training Acc 60.90 % AVG Validation Acc 48.79 %\n",
      "Epoch:130/200 AVG Training Loss:0.655 AVG Validation Loss:0.695 AVG Training Acc 61.64 % AVG Validation Acc 50.81 %\n",
      "Epoch:140/200 AVG Training Loss:0.658 AVG Validation Loss:0.690 AVG Training Acc 60.97 % AVG Validation Acc 51.21 %\n",
      "Epoch:150/200 AVG Training Loss:0.655 AVG Validation Loss:0.690 AVG Training Acc 61.33 % AVG Validation Acc 50.94 %\n",
      "Epoch:160/200 AVG Training Loss:0.655 AVG Validation Loss:0.685 AVG Training Acc 61.68 % AVG Validation Acc 52.69 %\n",
      "Epoch:170/200 AVG Training Loss:0.655 AVG Validation Loss:0.686 AVG Training Acc 61.38 % AVG Validation Acc 52.69 %\n",
      "Epoch:180/200 AVG Training Loss:0.653 AVG Validation Loss:0.684 AVG Training Acc 61.50 % AVG Validation Acc 52.15 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:190/200 AVG Training Loss:0.656 AVG Validation Loss:0.682 AVG Training Acc 61.25 % AVG Validation Acc 52.96 %\n",
      "Epoch:200/200 AVG Training Loss:0.655 AVG Validation Loss:0.686 AVG Training Acc 61.39 % AVG Validation Acc 52.02 %\n",
      "Split 86\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d023ddd15419444b90731ea2c21ff1de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.512 AVG Validation Loss:5.587 AVG Training Acc 79.80 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.627 AVG Validation Loss:1.829 AVG Training Acc 70.25 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.572 AVG Validation Loss:7.511 AVG Training Acc 81.38 % AVG Validation Acc 20.16 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.689 AVG Validation Loss:1.213 AVG Training Acc 57.71 % AVG Validation Acc 20.43 %\n",
      "Epoch:50/200 AVG Training Loss:0.680 AVG Validation Loss:1.075 AVG Training Acc 58.97 % AVG Validation Acc 21.37 %\n",
      "Epoch:60/200 AVG Training Loss:0.679 AVG Validation Loss:0.979 AVG Training Acc 58.62 % AVG Validation Acc 22.18 %\n",
      "Epoch:70/200 AVG Training Loss:0.677 AVG Validation Loss:0.892 AVG Training Acc 57.99 % AVG Validation Acc 23.79 %\n",
      "Epoch:80/200 AVG Training Loss:0.675 AVG Validation Loss:0.869 AVG Training Acc 59.06 % AVG Validation Acc 25.40 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.688 AVG Validation Loss:0.786 AVG Training Acc 55.43 % AVG Validation Acc 36.02 %\n",
      "Epoch:100/200 AVG Training Loss:0.666 AVG Validation Loss:0.700 AVG Training Acc 59.18 % AVG Validation Acc 48.25 %\n",
      "Epoch:110/200 AVG Training Loss:0.666 AVG Validation Loss:0.687 AVG Training Acc 59.82 % AVG Validation Acc 52.28 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.663 AVG Validation Loss:0.685 AVG Training Acc 59.82 % AVG Validation Acc 53.36 %\n",
      "Epoch:130/200 AVG Training Loss:0.663 AVG Validation Loss:0.681 AVG Training Acc 59.73 % AVG Validation Acc 53.49 %\n",
      "Epoch:140/200 AVG Training Loss:0.663 AVG Validation Loss:0.678 AVG Training Acc 59.84 % AVG Validation Acc 53.63 %\n",
      "Epoch:150/200 AVG Training Loss:0.660 AVG Validation Loss:0.678 AVG Training Acc 60.76 % AVG Validation Acc 53.76 %\n",
      "Epoch:160/200 AVG Training Loss:0.662 AVG Validation Loss:0.676 AVG Training Acc 59.83 % AVG Validation Acc 54.57 %\n",
      "Epoch:170/200 AVG Training Loss:0.662 AVG Validation Loss:0.678 AVG Training Acc 60.57 % AVG Validation Acc 55.11 %\n",
      "Epoch:180/200 AVG Training Loss:0.663 AVG Validation Loss:0.673 AVG Training Acc 60.45 % AVG Validation Acc 54.57 %\n",
      "Epoch   188: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:190/200 AVG Training Loss:0.661 AVG Validation Loss:0.674 AVG Training Acc 60.23 % AVG Validation Acc 54.70 %\n",
      "Epoch:200/200 AVG Training Loss:0.660 AVG Validation Loss:0.674 AVG Training Acc 59.88 % AVG Validation Acc 54.30 %\n",
      "Split 87\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aca4949bafd4a8cbc1b5f40340b7a8d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.480 AVG Validation Loss:4.895 AVG Training Acc 80.27 % AVG Validation Acc 20.19 %\n",
      "Epoch:20/200 AVG Training Loss:0.427 AVG Validation Loss:4.669 AVG Training Acc 82.86 % AVG Validation Acc 20.05 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.688 AVG Validation Loss:0.917 AVG Training Acc 58.45 % AVG Validation Acc 20.46 %\n",
      "Epoch:40/200 AVG Training Loss:0.652 AVG Validation Loss:0.916 AVG Training Acc 63.33 % AVG Validation Acc 20.59 %\n",
      "Epoch:50/200 AVG Training Loss:0.700 AVG Validation Loss:0.884 AVG Training Acc 56.92 % AVG Validation Acc 29.34 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.697 AVG Validation Loss:0.822 AVG Training Acc 55.50 % AVG Validation Acc 34.19 %\n",
      "Epoch:70/200 AVG Training Loss:0.671 AVG Validation Loss:0.734 AVG Training Acc 58.96 % AVG Validation Acc 48.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.668 AVG Validation Loss:0.717 AVG Training Acc 59.06 % AVG Validation Acc 51.41 %\n",
      "Epoch:90/200 AVG Training Loss:0.667 AVG Validation Loss:0.711 AVG Training Acc 59.44 % AVG Validation Acc 52.36 %\n",
      "Epoch:100/200 AVG Training Loss:0.664 AVG Validation Loss:0.704 AVG Training Acc 60.21 % AVG Validation Acc 54.37 %\n",
      "Epoch:110/200 AVG Training Loss:0.665 AVG Validation Loss:0.704 AVG Training Acc 59.77 % AVG Validation Acc 55.18 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.663 AVG Validation Loss:0.699 AVG Training Acc 60.47 % AVG Validation Acc 55.85 %\n",
      "Epoch:130/200 AVG Training Loss:0.659 AVG Validation Loss:0.697 AVG Training Acc 60.80 % AVG Validation Acc 55.85 %\n",
      "Epoch:140/200 AVG Training Loss:0.661 AVG Validation Loss:0.692 AVG Training Acc 60.65 % AVG Validation Acc 56.26 %\n",
      "Epoch:150/200 AVG Training Loss:0.661 AVG Validation Loss:0.690 AVG Training Acc 60.86 % AVG Validation Acc 56.80 %\n",
      "Epoch:160/200 AVG Training Loss:0.660 AVG Validation Loss:0.685 AVG Training Acc 60.27 % AVG Validation Acc 56.66 %\n",
      "Epoch:170/200 AVG Training Loss:0.661 AVG Validation Loss:0.689 AVG Training Acc 60.32 % AVG Validation Acc 57.47 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:180/200 AVG Training Loss:0.660 AVG Validation Loss:0.687 AVG Training Acc 61.02 % AVG Validation Acc 57.87 %\n",
      "Epoch:190/200 AVG Training Loss:0.661 AVG Validation Loss:0.687 AVG Training Acc 61.05 % AVG Validation Acc 57.34 %\n",
      "Epoch:200/200 AVG Training Loss:0.660 AVG Validation Loss:0.688 AVG Training Acc 60.51 % AVG Validation Acc 57.47 %\n",
      "Split 88\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c31aad68a34d07a0b687110f65b8a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.503 AVG Validation Loss:6.223 AVG Training Acc 81.44 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.553 AVG Validation Loss:4.584 AVG Training Acc 78.23 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.647 AVG Validation Loss:1.612 AVG Training Acc 66.25 % AVG Validation Acc 20.32 %\n",
      "Epoch:40/200 AVG Training Loss:0.660 AVG Validation Loss:1.603 AVG Training Acc 67.04 % AVG Validation Acc 20.46 %\n",
      "Epoch:50/200 AVG Training Loss:0.657 AVG Validation Loss:1.516 AVG Training Acc 64.68 % AVG Validation Acc 20.46 %\n",
      "Epoch:60/200 AVG Training Loss:0.812 AVG Validation Loss:2.087 AVG Training Acc 76.45 % AVG Validation Acc 20.46 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:70/200 AVG Training Loss:0.703 AVG Validation Loss:0.794 AVG Training Acc 50.78 % AVG Validation Acc 21.40 %\n",
      "Epoch:80/200 AVG Training Loss:0.675 AVG Validation Loss:0.776 AVG Training Acc 57.75 % AVG Validation Acc 46.30 %\n",
      "Epoch:90/200 AVG Training Loss:0.673 AVG Validation Loss:0.780 AVG Training Acc 58.52 % AVG Validation Acc 47.64 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.668 AVG Validation Loss:0.739 AVG Training Acc 58.72 % AVG Validation Acc 52.89 %\n",
      "Epoch:110/200 AVG Training Loss:0.665 AVG Validation Loss:0.705 AVG Training Acc 59.96 % AVG Validation Acc 57.34 %\n",
      "Epoch:120/200 AVG Training Loss:0.663 AVG Validation Loss:0.694 AVG Training Acc 60.47 % AVG Validation Acc 59.35 %\n",
      "Epoch:130/200 AVG Training Loss:0.661 AVG Validation Loss:0.690 AVG Training Acc 60.15 % AVG Validation Acc 60.70 %\n",
      "Epoch:140/200 AVG Training Loss:0.663 AVG Validation Loss:0.687 AVG Training Acc 60.22 % AVG Validation Acc 60.97 %\n",
      "Epoch:150/200 AVG Training Loss:0.662 AVG Validation Loss:0.686 AVG Training Acc 60.61 % AVG Validation Acc 60.57 %\n",
      "Epoch:160/200 AVG Training Loss:0.662 AVG Validation Loss:0.686 AVG Training Acc 60.45 % AVG Validation Acc 61.10 %\n",
      "Epoch:170/200 AVG Training Loss:0.659 AVG Validation Loss:0.686 AVG Training Acc 60.95 % AVG Validation Acc 60.70 %\n",
      "Epoch:180/200 AVG Training Loss:0.658 AVG Validation Loss:0.685 AVG Training Acc 60.83 % AVG Validation Acc 60.57 %\n",
      "Epoch:190/200 AVG Training Loss:0.658 AVG Validation Loss:0.685 AVG Training Acc 60.99 % AVG Validation Acc 60.43 %\n",
      "Epoch:200/200 AVG Training Loss:0.659 AVG Validation Loss:0.684 AVG Training Acc 60.67 % AVG Validation Acc 60.83 %\n",
      "Split 89\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0006e2efb10d4649bd813569df642143",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.583 AVG Validation Loss:4.705 AVG Training Acc 73.45 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.613 AVG Validation Loss:1.947 AVG Training Acc 70.67 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.552 AVG Validation Loss:6.720 AVG Training Acc 81.99 % AVG Validation Acc 20.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.642 AVG Validation Loss:1.684 AVG Training Acc 68.55 % AVG Validation Acc 20.05 %\n",
      "Epoch    46: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.721 AVG Validation Loss:0.834 AVG Training Acc 50.28 % AVG Validation Acc 20.59 %\n",
      "Epoch:60/200 AVG Training Loss:0.678 AVG Validation Loss:0.765 AVG Training Acc 57.67 % AVG Validation Acc 35.40 %\n",
      "Epoch:70/200 AVG Training Loss:0.676 AVG Validation Loss:0.761 AVG Training Acc 58.28 % AVG Validation Acc 41.99 %\n",
      "Epoch:80/200 AVG Training Loss:0.673 AVG Validation Loss:0.756 AVG Training Acc 58.93 % AVG Validation Acc 46.57 %\n",
      "Epoch:90/200 AVG Training Loss:0.671 AVG Validation Loss:0.743 AVG Training Acc 59.36 % AVG Validation Acc 48.32 %\n",
      "Epoch    94: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.668 AVG Validation Loss:0.714 AVG Training Acc 59.34 % AVG Validation Acc 54.78 %\n",
      "Epoch:110/200 AVG Training Loss:0.664 AVG Validation Loss:0.687 AVG Training Acc 60.45 % AVG Validation Acc 59.62 %\n",
      "Epoch:120/200 AVG Training Loss:0.663 AVG Validation Loss:0.677 AVG Training Acc 60.54 % AVG Validation Acc 60.83 %\n",
      "Epoch:130/200 AVG Training Loss:0.661 AVG Validation Loss:0.673 AVG Training Acc 60.76 % AVG Validation Acc 61.37 %\n",
      "Epoch:140/200 AVG Training Loss:0.664 AVG Validation Loss:0.671 AVG Training Acc 60.66 % AVG Validation Acc 61.37 %\n",
      "Epoch:150/200 AVG Training Loss:0.664 AVG Validation Loss:0.671 AVG Training Acc 60.55 % AVG Validation Acc 61.24 %\n",
      "Epoch   153: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:160/200 AVG Training Loss:0.663 AVG Validation Loss:0.670 AVG Training Acc 61.07 % AVG Validation Acc 61.24 %\n",
      "Epoch:170/200 AVG Training Loss:0.660 AVG Validation Loss:0.669 AVG Training Acc 61.31 % AVG Validation Acc 61.64 %\n",
      "Epoch:180/200 AVG Training Loss:0.662 AVG Validation Loss:0.669 AVG Training Acc 60.83 % AVG Validation Acc 61.64 %\n",
      "Epoch:190/200 AVG Training Loss:0.661 AVG Validation Loss:0.668 AVG Training Acc 61.39 % AVG Validation Acc 61.78 %\n",
      "Epoch:200/200 AVG Training Loss:0.662 AVG Validation Loss:0.668 AVG Training Acc 60.70 % AVG Validation Acc 61.91 %\n",
      "Split 90\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3846597c63cc4338be7e1be735d8b84c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.547 AVG Validation Loss:4.966 AVG Training Acc 79.24 % AVG Validation Acc 20.19 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:1.621 AVG Validation Loss:1.267 AVG Training Acc 49.88 % AVG Validation Acc 20.19 %\n",
      "Epoch:30/200 AVG Training Loss:0.692 AVG Validation Loss:0.846 AVG Training Acc 53.99 % AVG Validation Acc 23.96 %\n",
      "Epoch:40/200 AVG Training Loss:0.684 AVG Validation Loss:0.856 AVG Training Acc 56.02 % AVG Validation Acc 24.36 %\n",
      "Epoch:50/200 AVG Training Loss:0.680 AVG Validation Loss:0.852 AVG Training Acc 57.26 % AVG Validation Acc 25.17 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.673 AVG Validation Loss:0.728 AVG Training Acc 57.79 % AVG Validation Acc 43.47 %\n",
      "Epoch:70/200 AVG Training Loss:0.669 AVG Validation Loss:0.705 AVG Training Acc 58.73 % AVG Validation Acc 51.55 %\n",
      "Epoch:80/200 AVG Training Loss:0.668 AVG Validation Loss:0.701 AVG Training Acc 59.29 % AVG Validation Acc 54.37 %\n",
      "Epoch:90/200 AVG Training Loss:0.668 AVG Validation Loss:0.700 AVG Training Acc 59.27 % AVG Validation Acc 55.32 %\n",
      "Epoch:100/200 AVG Training Loss:0.667 AVG Validation Loss:0.699 AVG Training Acc 59.69 % AVG Validation Acc 55.45 %\n",
      "Epoch:110/200 AVG Training Loss:0.666 AVG Validation Loss:0.697 AVG Training Acc 59.43 % AVG Validation Acc 55.85 %\n",
      "Epoch:120/200 AVG Training Loss:0.667 AVG Validation Loss:0.698 AVG Training Acc 59.59 % AVG Validation Acc 55.59 %\n",
      "Epoch   122: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.662 AVG Validation Loss:0.694 AVG Training Acc 59.96 % AVG Validation Acc 56.39 %\n",
      "Epoch:140/200 AVG Training Loss:0.662 AVG Validation Loss:0.692 AVG Training Acc 59.90 % AVG Validation Acc 56.39 %\n",
      "Epoch:150/200 AVG Training Loss:0.663 AVG Validation Loss:0.689 AVG Training Acc 59.92 % AVG Validation Acc 57.34 %\n",
      "Epoch:160/200 AVG Training Loss:0.660 AVG Validation Loss:0.687 AVG Training Acc 60.20 % AVG Validation Acc 57.60 %\n",
      "Epoch:170/200 AVG Training Loss:0.662 AVG Validation Loss:0.686 AVG Training Acc 60.19 % AVG Validation Acc 57.47 %\n",
      "Epoch:180/200 AVG Training Loss:0.661 AVG Validation Loss:0.685 AVG Training Acc 60.36 % AVG Validation Acc 57.34 %\n",
      "Epoch:190/200 AVG Training Loss:0.663 AVG Validation Loss:0.683 AVG Training Acc 60.26 % AVG Validation Acc 57.34 %\n",
      "Epoch:200/200 AVG Training Loss:0.661 AVG Validation Loss:0.683 AVG Training Acc 59.97 % AVG Validation Acc 57.34 %\n",
      "Split 91\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19011906b9154b6a82fa0750ec56c144",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.556 AVG Validation Loss:3.553 AVG Training Acc 78.18 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.621 AVG Validation Loss:1.775 AVG Training Acc 68.89 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.694 AVG Validation Loss:5.227 AVG Training Acc 79.59 % AVG Validation Acc 20.16 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.688 AVG Validation Loss:0.783 AVG Training Acc 55.53 % AVG Validation Acc 26.75 %\n",
      "Epoch:50/200 AVG Training Loss:0.679 AVG Validation Loss:0.790 AVG Training Acc 57.36 % AVG Validation Acc 28.63 %\n",
      "Epoch:60/200 AVG Training Loss:0.675 AVG Validation Loss:0.783 AVG Training Acc 58.59 % AVG Validation Acc 35.22 %\n",
      "Epoch:70/200 AVG Training Loss:0.673 AVG Validation Loss:0.781 AVG Training Acc 59.80 % AVG Validation Acc 37.63 %\n",
      "Epoch:80/200 AVG Training Loss:0.671 AVG Validation Loss:0.782 AVG Training Acc 59.36 % AVG Validation Acc 39.92 %\n",
      "Epoch:90/200 AVG Training Loss:0.668 AVG Validation Loss:0.781 AVG Training Acc 59.59 % AVG Validation Acc 42.07 %\n",
      "Epoch:100/200 AVG Training Loss:0.664 AVG Validation Loss:0.787 AVG Training Acc 60.53 % AVG Validation Acc 43.41 %\n",
      "Epoch   106: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:110/200 AVG Training Loss:0.665 AVG Validation Loss:0.738 AVG Training Acc 60.12 % AVG Validation Acc 48.92 %\n",
      "Epoch:120/200 AVG Training Loss:0.656 AVG Validation Loss:0.695 AVG Training Acc 61.39 % AVG Validation Acc 57.53 %\n",
      "Epoch:130/200 AVG Training Loss:0.657 AVG Validation Loss:0.681 AVG Training Acc 61.98 % AVG Validation Acc 59.95 %\n",
      "Epoch:140/200 AVG Training Loss:0.653 AVG Validation Loss:0.678 AVG Training Acc 61.80 % AVG Validation Acc 60.35 %\n",
      "Epoch:150/200 AVG Training Loss:0.654 AVG Validation Loss:0.676 AVG Training Acc 61.75 % AVG Validation Acc 60.75 %\n",
      "Epoch:160/200 AVG Training Loss:0.654 AVG Validation Loss:0.674 AVG Training Acc 62.26 % AVG Validation Acc 60.62 %\n",
      "Epoch:170/200 AVG Training Loss:0.651 AVG Validation Loss:0.675 AVG Training Acc 62.07 % AVG Validation Acc 60.48 %\n",
      "Epoch   171: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:180/200 AVG Training Loss:0.652 AVG Validation Loss:0.673 AVG Training Acc 61.95 % AVG Validation Acc 60.48 %\n",
      "Epoch:190/200 AVG Training Loss:0.652 AVG Validation Loss:0.672 AVG Training Acc 62.23 % AVG Validation Acc 61.02 %\n",
      "Epoch:200/200 AVG Training Loss:0.650 AVG Validation Loss:0.671 AVG Training Acc 62.47 % AVG Validation Acc 61.29 %\n",
      "Split 92\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46c49f2cbde247dfac35f62d6814e7b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.497 AVG Validation Loss:5.918 AVG Training Acc 79.73 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.569 AVG Validation Loss:5.099 AVG Training Acc 77.81 % AVG Validation Acc 20.16 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:1.112 AVG Validation Loss:1.336 AVG Training Acc 50.04 % AVG Validation Acc 20.30 %\n",
      "Epoch:40/200 AVG Training Loss:0.696 AVG Validation Loss:0.779 AVG Training Acc 50.34 % AVG Validation Acc 22.04 %\n",
      "Epoch:50/200 AVG Training Loss:0.690 AVG Validation Loss:0.786 AVG Training Acc 54.09 % AVG Validation Acc 23.66 %\n",
      "Epoch:60/200 AVG Training Loss:0.680 AVG Validation Loss:0.791 AVG Training Acc 57.39 % AVG Validation Acc 34.01 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.672 AVG Validation Loss:0.715 AVG Training Acc 58.48 % AVG Validation Acc 52.96 %\n",
      "Epoch:80/200 AVG Training Loss:0.669 AVG Validation Loss:0.691 AVG Training Acc 59.71 % AVG Validation Acc 55.65 %\n",
      "Epoch:90/200 AVG Training Loss:0.670 AVG Validation Loss:0.685 AVG Training Acc 59.41 % AVG Validation Acc 56.85 %\n",
      "Epoch:100/200 AVG Training Loss:0.668 AVG Validation Loss:0.683 AVG Training Acc 59.85 % AVG Validation Acc 57.80 %\n",
      "Epoch:110/200 AVG Training Loss:0.668 AVG Validation Loss:0.682 AVG Training Acc 59.85 % AVG Validation Acc 58.06 %\n",
      "Epoch:120/200 AVG Training Loss:0.667 AVG Validation Loss:0.681 AVG Training Acc 60.02 % AVG Validation Acc 57.93 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.667 AVG Validation Loss:0.680 AVG Training Acc 60.33 % AVG Validation Acc 57.93 %\n",
      "Epoch:140/200 AVG Training Loss:0.667 AVG Validation Loss:0.679 AVG Training Acc 59.75 % AVG Validation Acc 58.20 %\n",
      "Epoch:150/200 AVG Training Loss:0.665 AVG Validation Loss:0.678 AVG Training Acc 60.36 % AVG Validation Acc 58.33 %\n",
      "Epoch:160/200 AVG Training Loss:0.666 AVG Validation Loss:0.677 AVG Training Acc 60.24 % AVG Validation Acc 58.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.666 AVG Validation Loss:0.676 AVG Training Acc 60.22 % AVG Validation Acc 59.01 %\n",
      "Epoch:180/200 AVG Training Loss:0.666 AVG Validation Loss:0.676 AVG Training Acc 60.56 % AVG Validation Acc 59.41 %\n",
      "Epoch:190/200 AVG Training Loss:0.665 AVG Validation Loss:0.675 AVG Training Acc 60.61 % AVG Validation Acc 59.41 %\n",
      "Epoch:200/200 AVG Training Loss:0.664 AVG Validation Loss:0.674 AVG Training Acc 60.75 % AVG Validation Acc 59.41 %\n",
      "Split 93\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "763f750b05044f8aa2ac665e3b60aeef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.534 AVG Validation Loss:3.607 AVG Training Acc 80.86 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.497 AVG Validation Loss:4.441 AVG Training Acc 83.10 % AVG Validation Acc 20.16 %\n",
      "Epoch    26: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.704 AVG Validation Loss:0.837 AVG Training Acc 53.27 % AVG Validation Acc 24.19 %\n",
      "Epoch:40/200 AVG Training Loss:0.681 AVG Validation Loss:0.832 AVG Training Acc 56.95 % AVG Validation Acc 23.92 %\n",
      "Epoch:50/200 AVG Training Loss:0.673 AVG Validation Loss:0.850 AVG Training Acc 58.89 % AVG Validation Acc 29.17 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.673 AVG Validation Loss:0.794 AVG Training Acc 57.80 % AVG Validation Acc 41.40 %\n",
      "Epoch:70/200 AVG Training Loss:0.662 AVG Validation Loss:0.735 AVG Training Acc 60.30 % AVG Validation Acc 57.93 %\n",
      "Epoch:80/200 AVG Training Loss:0.660 AVG Validation Loss:0.721 AVG Training Acc 60.76 % AVG Validation Acc 60.35 %\n",
      "Epoch:90/200 AVG Training Loss:0.659 AVG Validation Loss:0.719 AVG Training Acc 60.89 % AVG Validation Acc 60.22 %\n",
      "Epoch:100/200 AVG Training Loss:0.656 AVG Validation Loss:0.719 AVG Training Acc 61.42 % AVG Validation Acc 60.08 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.656 AVG Validation Loss:0.719 AVG Training Acc 61.41 % AVG Validation Acc 59.95 %\n",
      "Epoch:120/200 AVG Training Loss:0.659 AVG Validation Loss:0.717 AVG Training Acc 60.78 % AVG Validation Acc 60.48 %\n",
      "Epoch:130/200 AVG Training Loss:0.656 AVG Validation Loss:0.716 AVG Training Acc 61.52 % AVG Validation Acc 60.89 %\n",
      "Epoch:140/200 AVG Training Loss:0.655 AVG Validation Loss:0.715 AVG Training Acc 61.40 % AVG Validation Acc 61.02 %\n",
      "Epoch:150/200 AVG Training Loss:0.656 AVG Validation Loss:0.714 AVG Training Acc 61.83 % AVG Validation Acc 61.16 %\n",
      "Epoch:160/200 AVG Training Loss:0.657 AVG Validation Loss:0.713 AVG Training Acc 61.09 % AVG Validation Acc 61.42 %\n",
      "Epoch:170/200 AVG Training Loss:0.657 AVG Validation Loss:0.713 AVG Training Acc 60.81 % AVG Validation Acc 61.56 %\n",
      "Epoch:180/200 AVG Training Loss:0.656 AVG Validation Loss:0.712 AVG Training Acc 61.38 % AVG Validation Acc 61.69 %\n",
      "Epoch:190/200 AVG Training Loss:0.656 AVG Validation Loss:0.712 AVG Training Acc 61.02 % AVG Validation Acc 61.69 %\n",
      "Epoch:200/200 AVG Training Loss:0.654 AVG Validation Loss:0.711 AVG Training Acc 61.28 % AVG Validation Acc 62.10 %\n",
      "Split 94\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa5c7cab9a3b4dda9d0f3e09c8a2c3f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.528 AVG Validation Loss:6.708 AVG Training Acc 78.16 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:1.568 AVG Training Acc 65.42 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.541 AVG Validation Loss:6.212 AVG Training Acc 78.36 % AVG Validation Acc 20.16 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.711 AVG Validation Loss:0.801 AVG Training Acc 49.64 % AVG Validation Acc 21.10 %\n",
      "Epoch:50/200 AVG Training Loss:0.688 AVG Validation Loss:0.752 AVG Training Acc 54.76 % AVG Validation Acc 23.12 %\n",
      "Epoch:60/200 AVG Training Loss:0.682 AVG Validation Loss:0.766 AVG Training Acc 56.57 % AVG Validation Acc 29.97 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.679 AVG Validation Loss:0.747 AVG Training Acc 57.03 % AVG Validation Acc 41.53 %\n",
      "Epoch:80/200 AVG Training Loss:0.676 AVG Validation Loss:0.715 AVG Training Acc 58.63 % AVG Validation Acc 53.49 %\n",
      "Epoch:90/200 AVG Training Loss:0.674 AVG Validation Loss:0.700 AVG Training Acc 58.52 % AVG Validation Acc 56.59 %\n",
      "Epoch:100/200 AVG Training Loss:0.676 AVG Validation Loss:0.693 AVG Training Acc 58.81 % AVG Validation Acc 57.80 %\n",
      "Epoch:110/200 AVG Training Loss:0.671 AVG Validation Loss:0.689 AVG Training Acc 59.14 % AVG Validation Acc 58.06 %\n",
      "Epoch:120/200 AVG Training Loss:0.672 AVG Validation Loss:0.687 AVG Training Acc 59.14 % AVG Validation Acc 58.06 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.671 AVG Validation Loss:0.687 AVG Training Acc 59.22 % AVG Validation Acc 57.93 %\n",
      "Epoch:140/200 AVG Training Loss:0.669 AVG Validation Loss:0.687 AVG Training Acc 59.08 % AVG Validation Acc 57.93 %\n",
      "Epoch:150/200 AVG Training Loss:0.672 AVG Validation Loss:0.686 AVG Training Acc 59.37 % AVG Validation Acc 57.80 %\n",
      "Epoch:160/200 AVG Training Loss:0.671 AVG Validation Loss:0.686 AVG Training Acc 59.93 % AVG Validation Acc 58.06 %\n",
      "Epoch:170/200 AVG Training Loss:0.673 AVG Validation Loss:0.685 AVG Training Acc 59.35 % AVG Validation Acc 57.93 %\n",
      "Epoch:180/200 AVG Training Loss:0.670 AVG Validation Loss:0.685 AVG Training Acc 59.06 % AVG Validation Acc 57.93 %\n",
      "Epoch:190/200 AVG Training Loss:0.668 AVG Validation Loss:0.684 AVG Training Acc 59.44 % AVG Validation Acc 58.06 %\n",
      "Epoch:200/200 AVG Training Loss:0.670 AVG Validation Loss:0.684 AVG Training Acc 59.64 % AVG Validation Acc 58.06 %\n",
      "Split 95\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28f8ccb3c2ff435fb40291ca1d34836b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.437 AVG Validation Loss:4.981 AVG Training Acc 82.10 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.520 AVG Validation Loss:3.511 AVG Training Acc 77.75 % AVG Validation Acc 20.16 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.697 AVG Validation Loss:1.144 AVG Training Acc 58.48 % AVG Validation Acc 20.30 %\n",
      "Epoch:40/200 AVG Training Loss:0.691 AVG Validation Loss:0.925 AVG Training Acc 56.35 % AVG Validation Acc 20.56 %\n",
      "Epoch:50/200 AVG Training Loss:0.668 AVG Validation Loss:1.001 AVG Training Acc 59.30 % AVG Validation Acc 20.70 %\n",
      "Epoch    55: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.684 AVG Validation Loss:0.751 AVG Training Acc 54.75 % AVG Validation Acc 34.27 %\n",
      "Epoch:70/200 AVG Training Loss:0.670 AVG Validation Loss:0.694 AVG Training Acc 58.41 % AVG Validation Acc 49.73 %\n",
      "Epoch:80/200 AVG Training Loss:0.667 AVG Validation Loss:0.694 AVG Training Acc 59.10 % AVG Validation Acc 50.67 %\n",
      "Epoch:90/200 AVG Training Loss:0.665 AVG Validation Loss:0.693 AVG Training Acc 59.02 % AVG Validation Acc 52.55 %\n",
      "Epoch    96: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.664 AVG Validation Loss:0.687 AVG Training Acc 59.18 % AVG Validation Acc 54.84 %\n",
      "Epoch:110/200 AVG Training Loss:0.665 AVG Validation Loss:0.681 AVG Training Acc 59.25 % AVG Validation Acc 56.72 %\n",
      "Epoch:120/200 AVG Training Loss:0.662 AVG Validation Loss:0.677 AVG Training Acc 59.52 % AVG Validation Acc 56.59 %\n",
      "Epoch:130/200 AVG Training Loss:0.662 AVG Validation Loss:0.674 AVG Training Acc 59.92 % AVG Validation Acc 57.53 %\n",
      "Epoch:140/200 AVG Training Loss:0.660 AVG Validation Loss:0.673 AVG Training Acc 59.88 % AVG Validation Acc 58.06 %\n",
      "Epoch:150/200 AVG Training Loss:0.662 AVG Validation Loss:0.671 AVG Training Acc 59.77 % AVG Validation Acc 57.93 %\n",
      "Epoch:160/200 AVG Training Loss:0.663 AVG Validation Loss:0.671 AVG Training Acc 59.87 % AVG Validation Acc 58.20 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:170/200 AVG Training Loss:0.663 AVG Validation Loss:0.669 AVG Training Acc 59.46 % AVG Validation Acc 57.80 %\n",
      "Epoch:180/200 AVG Training Loss:0.662 AVG Validation Loss:0.674 AVG Training Acc 60.06 % AVG Validation Acc 58.20 %\n",
      "Epoch:190/200 AVG Training Loss:0.662 AVG Validation Loss:0.673 AVG Training Acc 59.78 % AVG Validation Acc 58.74 %\n",
      "Epoch:200/200 AVG Training Loss:0.661 AVG Validation Loss:0.671 AVG Training Acc 59.85 % AVG Validation Acc 58.20 %\n",
      "Split 96\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2bfcfa34834082b6d9b68f4db373c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.512 AVG Validation Loss:3.916 AVG Training Acc 79.99 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.578 AVG Validation Loss:4.918 AVG Training Acc 75.22 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.645 AVG Validation Loss:1.644 AVG Training Acc 66.66 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.540 AVG Validation Loss:2.607 AVG Training Acc 78.36 % AVG Validation Acc 20.16 %\n",
      "Epoch    41: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.692 AVG Validation Loss:0.773 AVG Training Acc 51.80 % AVG Validation Acc 21.51 %\n",
      "Epoch:60/200 AVG Training Loss:0.685 AVG Validation Loss:0.779 AVG Training Acc 55.14 % AVG Validation Acc 23.25 %\n",
      "Epoch:70/200 AVG Training Loss:0.675 AVG Validation Loss:0.777 AVG Training Acc 58.59 % AVG Validation Acc 40.46 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.668 AVG Validation Loss:0.719 AVG Training Acc 59.14 % AVG Validation Acc 55.65 %\n",
      "Epoch:90/200 AVG Training Loss:0.665 AVG Validation Loss:0.695 AVG Training Acc 59.88 % AVG Validation Acc 57.53 %\n",
      "Epoch:100/200 AVG Training Loss:0.665 AVG Validation Loss:0.687 AVG Training Acc 60.49 % AVG Validation Acc 58.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.665 AVG Validation Loss:0.684 AVG Training Acc 60.12 % AVG Validation Acc 58.74 %\n",
      "Epoch:120/200 AVG Training Loss:0.663 AVG Validation Loss:0.683 AVG Training Acc 60.23 % AVG Validation Acc 58.74 %\n",
      "Epoch:130/200 AVG Training Loss:0.664 AVG Validation Loss:0.682 AVG Training Acc 60.66 % AVG Validation Acc 58.74 %\n",
      "Epoch:140/200 AVG Training Loss:0.662 AVG Validation Loss:0.683 AVG Training Acc 61.21 % AVG Validation Acc 58.47 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.661 AVG Validation Loss:0.682 AVG Training Acc 60.73 % AVG Validation Acc 58.47 %\n",
      "Epoch:160/200 AVG Training Loss:0.661 AVG Validation Loss:0.681 AVG Training Acc 60.97 % AVG Validation Acc 58.60 %\n",
      "Epoch:170/200 AVG Training Loss:0.663 AVG Validation Loss:0.680 AVG Training Acc 61.15 % AVG Validation Acc 58.87 %\n",
      "Epoch:180/200 AVG Training Loss:0.661 AVG Validation Loss:0.680 AVG Training Acc 61.33 % AVG Validation Acc 59.01 %\n",
      "Epoch:190/200 AVG Training Loss:0.662 AVG Validation Loss:0.679 AVG Training Acc 61.12 % AVG Validation Acc 59.27 %\n",
      "Epoch:200/200 AVG Training Loss:0.661 AVG Validation Loss:0.678 AVG Training Acc 61.23 % AVG Validation Acc 59.27 %\n",
      "Split 97\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d8ac2e16a594c30b1f8050a55df7165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.506 AVG Validation Loss:6.858 AVG Training Acc 80.78 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.502 AVG Validation Loss:4.001 AVG Training Acc 80.15 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.571 AVG Validation Loss:8.818 AVG Training Acc 81.41 % AVG Validation Acc 20.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.649 AVG Validation Loss:1.701 AVG Training Acc 65.73 % AVG Validation Acc 20.19 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.828 AVG Validation Loss:0.981 AVG Training Acc 50.49 % AVG Validation Acc 20.19 %\n",
      "Epoch:60/200 AVG Training Loss:0.683 AVG Validation Loss:0.759 AVG Training Acc 56.33 % AVG Validation Acc 36.20 %\n",
      "Epoch:70/200 AVG Training Loss:0.675 AVG Validation Loss:0.757 AVG Training Acc 58.39 % AVG Validation Acc 41.32 %\n",
      "Epoch:80/200 AVG Training Loss:0.675 AVG Validation Loss:0.752 AVG Training Acc 58.47 % AVG Validation Acc 42.40 %\n",
      "Epoch:90/200 AVG Training Loss:0.672 AVG Validation Loss:0.748 AVG Training Acc 59.02 % AVG Validation Acc 43.20 %\n",
      "Epoch    99: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.674 AVG Validation Loss:0.745 AVG Training Acc 58.09 % AVG Validation Acc 43.74 %\n",
      "Epoch:110/200 AVG Training Loss:0.663 AVG Validation Loss:0.694 AVG Training Acc 60.69 % AVG Validation Acc 55.85 %\n",
      "Epoch:120/200 AVG Training Loss:0.662 AVG Validation Loss:0.677 AVG Training Acc 60.51 % AVG Validation Acc 57.74 %\n",
      "Epoch:130/200 AVG Training Loss:0.659 AVG Validation Loss:0.671 AVG Training Acc 60.98 % AVG Validation Acc 59.22 %\n",
      "Epoch:140/200 AVG Training Loss:0.660 AVG Validation Loss:0.669 AVG Training Acc 60.55 % AVG Validation Acc 59.49 %\n",
      "Epoch:150/200 AVG Training Loss:0.660 AVG Validation Loss:0.667 AVG Training Acc 60.24 % AVG Validation Acc 59.62 %\n",
      "Epoch:160/200 AVG Training Loss:0.659 AVG Validation Loss:0.666 AVG Training Acc 61.09 % AVG Validation Acc 59.62 %\n",
      "Epoch:170/200 AVG Training Loss:0.659 AVG Validation Loss:0.667 AVG Training Acc 60.94 % AVG Validation Acc 59.89 %\n",
      "Epoch   175: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:180/200 AVG Training Loss:0.659 AVG Validation Loss:0.666 AVG Training Acc 61.06 % AVG Validation Acc 59.89 %\n",
      "Epoch:190/200 AVG Training Loss:0.657 AVG Validation Loss:0.665 AVG Training Acc 61.34 % AVG Validation Acc 60.16 %\n",
      "Epoch:200/200 AVG Training Loss:0.656 AVG Validation Loss:0.664 AVG Training Acc 61.32 % AVG Validation Acc 60.16 %\n",
      "Split 98\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0c60ce4e79149c78e0782bb4c119667",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.498 AVG Validation Loss:5.709 AVG Training Acc 81.56 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.590 AVG Validation Loss:2.556 AVG Training Acc 77.49 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.472 AVG Validation Loss:6.493 AVG Training Acc 79.10 % AVG Validation Acc 20.46 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.698 AVG Validation Loss:0.825 AVG Training Acc 53.05 % AVG Validation Acc 24.09 %\n",
      "Epoch:50/200 AVG Training Loss:0.684 AVG Validation Loss:0.887 AVG Training Acc 56.05 % AVG Validation Acc 22.61 %\n",
      "Epoch:60/200 AVG Training Loss:0.685 AVG Validation Loss:0.894 AVG Training Acc 56.81 % AVG Validation Acc 23.96 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.682 AVG Validation Loss:0.735 AVG Training Acc 56.15 % AVG Validation Acc 36.61 %\n",
      "Epoch:80/200 AVG Training Loss:0.674 AVG Validation Loss:0.692 AVG Training Acc 58.27 % AVG Validation Acc 47.64 %\n",
      "Epoch:90/200 AVG Training Loss:0.674 AVG Validation Loss:0.687 AVG Training Acc 58.57 % AVG Validation Acc 52.09 %\n",
      "Epoch:100/200 AVG Training Loss:0.673 AVG Validation Loss:0.684 AVG Training Acc 59.17 % AVG Validation Acc 53.43 %\n",
      "Epoch:110/200 AVG Training Loss:0.672 AVG Validation Loss:0.683 AVG Training Acc 59.10 % AVG Validation Acc 54.10 %\n",
      "Epoch:120/200 AVG Training Loss:0.673 AVG Validation Loss:0.683 AVG Training Acc 59.15 % AVG Validation Acc 54.24 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.671 AVG Validation Loss:0.683 AVG Training Acc 59.07 % AVG Validation Acc 54.37 %\n",
      "Epoch:140/200 AVG Training Loss:0.671 AVG Validation Loss:0.680 AVG Training Acc 59.50 % AVG Validation Acc 54.24 %\n",
      "Epoch:150/200 AVG Training Loss:0.670 AVG Validation Loss:0.678 AVG Training Acc 59.33 % AVG Validation Acc 55.59 %\n",
      "Epoch:160/200 AVG Training Loss:0.668 AVG Validation Loss:0.675 AVG Training Acc 59.65 % AVG Validation Acc 56.66 %\n",
      "Epoch   169: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:170/200 AVG Training Loss:0.668 AVG Validation Loss:0.675 AVG Training Acc 59.49 % AVG Validation Acc 56.93 %\n",
      "Epoch:180/200 AVG Training Loss:0.669 AVG Validation Loss:0.674 AVG Training Acc 59.43 % AVG Validation Acc 56.66 %\n",
      "Epoch:190/200 AVG Training Loss:0.669 AVG Validation Loss:0.674 AVG Training Acc 59.51 % AVG Validation Acc 56.26 %\n",
      "Epoch:200/200 AVG Training Loss:0.668 AVG Validation Loss:0.676 AVG Training Acc 59.79 % AVG Validation Acc 57.07 %\n",
      "Epoch   200: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Split 99\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "806eedeffb294f93b9eaffd7a335ab58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.483 AVG Validation Loss:5.365 AVG Training Acc 82.77 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.593 AVG Validation Loss:2.222 AVG Training Acc 72.90 % AVG Validation Acc 20.19 %\n",
      "Epoch:30/200 AVG Training Loss:0.626 AVG Validation Loss:6.633 AVG Training Acc 66.55 % AVG Validation Acc 20.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.647 AVG Validation Loss:1.700 AVG Training Acc 65.43 % AVG Validation Acc 20.19 %\n",
      "Epoch:50/200 AVG Training Loss:0.643 AVG Validation Loss:1.726 AVG Training Acc 65.50 % AVG Validation Acc 20.19 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.785 AVG Validation Loss:0.902 AVG Training Acc 47.40 % AVG Validation Acc 20.73 %\n",
      "Epoch:70/200 AVG Training Loss:0.684 AVG Validation Loss:0.775 AVG Training Acc 54.69 % AVG Validation Acc 27.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.678 AVG Validation Loss:0.784 AVG Training Acc 57.27 % AVG Validation Acc 32.44 %\n",
      "Epoch    88: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.677 AVG Validation Loss:0.770 AVG Training Acc 56.75 % AVG Validation Acc 41.45 %\n",
      "Epoch:100/200 AVG Training Loss:0.667 AVG Validation Loss:0.716 AVG Training Acc 59.58 % AVG Validation Acc 54.51 %\n",
      "Epoch:110/200 AVG Training Loss:0.666 AVG Validation Loss:0.701 AVG Training Acc 59.50 % AVG Validation Acc 58.95 %\n",
      "Epoch:120/200 AVG Training Loss:0.664 AVG Validation Loss:0.696 AVG Training Acc 59.97 % AVG Validation Acc 59.49 %\n",
      "Epoch:130/200 AVG Training Loss:0.665 AVG Validation Loss:0.695 AVG Training Acc 60.60 % AVG Validation Acc 59.62 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:140/200 AVG Training Loss:0.661 AVG Validation Loss:0.695 AVG Training Acc 60.40 % AVG Validation Acc 59.49 %\n",
      "Epoch:150/200 AVG Training Loss:0.664 AVG Validation Loss:0.694 AVG Training Acc 60.15 % AVG Validation Acc 59.49 %\n",
      "Epoch:160/200 AVG Training Loss:0.664 AVG Validation Loss:0.694 AVG Training Acc 60.16 % AVG Validation Acc 59.76 %\n",
      "Epoch:170/200 AVG Training Loss:0.662 AVG Validation Loss:0.693 AVG Training Acc 60.51 % AVG Validation Acc 59.76 %\n",
      "Epoch:180/200 AVG Training Loss:0.664 AVG Validation Loss:0.692 AVG Training Acc 60.26 % AVG Validation Acc 59.89 %\n",
      "Epoch:190/200 AVG Training Loss:0.663 AVG Validation Loss:0.691 AVG Training Acc 60.34 % AVG Validation Acc 60.03 %\n",
      "Epoch:200/200 AVG Training Loss:0.662 AVG Validation Loss:0.690 AVG Training Acc 60.44 % AVG Validation Acc 59.76 %\n",
      "Split 100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b0ce1ba505244c283487b568942bd2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.546 AVG Validation Loss:3.700 AVG Training Acc 79.78 % AVG Validation Acc 20.19 %\n",
      "Epoch:20/200 AVG Training Loss:0.627 AVG Validation Loss:1.694 AVG Training Acc 69.36 % AVG Validation Acc 20.19 %\n",
      "Epoch:30/200 AVG Training Loss:0.614 AVG Validation Loss:9.667 AVG Training Acc 67.26 % AVG Validation Acc 20.19 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.694 AVG Validation Loss:0.821 AVG Training Acc 53.95 % AVG Validation Acc 22.88 %\n",
      "Epoch:50/200 AVG Training Loss:0.685 AVG Validation Loss:0.814 AVG Training Acc 55.73 % AVG Validation Acc 23.28 %\n",
      "Epoch:60/200 AVG Training Loss:0.673 AVG Validation Loss:0.818 AVG Training Acc 58.45 % AVG Validation Acc 26.92 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.667 AVG Validation Loss:0.717 AVG Training Acc 58.21 % AVG Validation Acc 44.82 %\n",
      "Epoch:80/200 AVG Training Loss:0.659 AVG Validation Loss:0.673 AVG Training Acc 60.10 % AVG Validation Acc 55.18 %\n",
      "Epoch:90/200 AVG Training Loss:0.657 AVG Validation Loss:0.666 AVG Training Acc 60.29 % AVG Validation Acc 56.39 %\n",
      "Epoch:100/200 AVG Training Loss:0.659 AVG Validation Loss:0.664 AVG Training Acc 60.04 % AVG Validation Acc 56.39 %\n",
      "Epoch:110/200 AVG Training Loss:0.655 AVG Validation Loss:0.664 AVG Training Acc 60.52 % AVG Validation Acc 56.39 %\n",
      "Epoch:120/200 AVG Training Loss:0.654 AVG Validation Loss:0.663 AVG Training Acc 60.69 % AVG Validation Acc 56.80 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.651 AVG Validation Loss:0.662 AVG Training Acc 60.89 % AVG Validation Acc 56.53 %\n",
      "Epoch:140/200 AVG Training Loss:0.652 AVG Validation Loss:0.659 AVG Training Acc 60.76 % AVG Validation Acc 56.80 %\n",
      "Epoch:150/200 AVG Training Loss:0.652 AVG Validation Loss:0.657 AVG Training Acc 60.65 % AVG Validation Acc 57.07 %\n",
      "Epoch:160/200 AVG Training Loss:0.651 AVG Validation Loss:0.655 AVG Training Acc 61.33 % AVG Validation Acc 57.34 %\n",
      "Epoch:170/200 AVG Training Loss:0.651 AVG Validation Loss:0.654 AVG Training Acc 60.85 % AVG Validation Acc 57.60 %\n",
      "Epoch:180/200 AVG Training Loss:0.651 AVG Validation Loss:0.653 AVG Training Acc 60.90 % AVG Validation Acc 57.60 %\n",
      "Epoch:190/200 AVG Training Loss:0.653 AVG Validation Loss:0.652 AVG Training Acc 60.68 % AVG Validation Acc 57.60 %\n",
      "Epoch:200/200 AVG Training Loss:0.651 AVG Validation Loss:0.651 AVG Training Acc 61.20 % AVG Validation Acc 57.60 %\n",
      "Split 101\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd0edad6daee4c85809228943d3abc91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.521 AVG Validation Loss:2.514 AVG Training Acc 77.95 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.478 AVG Validation Loss:2.980 AVG Training Acc 80.22 % AVG Validation Acc 20.16 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.659 AVG Validation Loss:1.240 AVG Training Acc 65.02 % AVG Validation Acc 20.03 %\n",
      "Epoch:40/200 AVG Training Loss:0.685 AVG Validation Loss:0.911 AVG Training Acc 58.23 % AVG Validation Acc 20.70 %\n",
      "Epoch:50/200 AVG Training Loss:0.650 AVG Validation Loss:1.025 AVG Training Acc 64.48 % AVG Validation Acc 20.16 %\n",
      "Epoch    52: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.676 AVG Validation Loss:0.700 AVG Training Acc 58.32 % AVG Validation Acc 45.83 %\n",
      "Epoch:70/200 AVG Training Loss:0.670 AVG Validation Loss:0.680 AVG Training Acc 59.19 % AVG Validation Acc 50.81 %\n",
      "Epoch:80/200 AVG Training Loss:0.668 AVG Validation Loss:0.684 AVG Training Acc 59.87 % AVG Validation Acc 52.15 %\n",
      "Epoch    83: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.665 AVG Validation Loss:0.677 AVG Training Acc 60.25 % AVG Validation Acc 54.70 %\n",
      "Epoch:100/200 AVG Training Loss:0.664 AVG Validation Loss:0.670 AVG Training Acc 60.30 % AVG Validation Acc 56.05 %\n",
      "Epoch:110/200 AVG Training Loss:0.664 AVG Validation Loss:0.666 AVG Training Acc 60.23 % AVG Validation Acc 56.85 %\n",
      "Epoch:120/200 AVG Training Loss:0.666 AVG Validation Loss:0.663 AVG Training Acc 59.77 % AVG Validation Acc 58.06 %\n",
      "Epoch:130/200 AVG Training Loss:0.667 AVG Validation Loss:0.665 AVG Training Acc 59.85 % AVG Validation Acc 57.93 %\n",
      "Epoch:140/200 AVG Training Loss:0.665 AVG Validation Loss:0.662 AVG Training Acc 60.90 % AVG Validation Acc 57.80 %\n",
      "Epoch   147: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.665 AVG Validation Loss:0.663 AVG Training Acc 60.52 % AVG Validation Acc 59.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.666 AVG Validation Loss:0.662 AVG Training Acc 60.32 % AVG Validation Acc 58.20 %\n",
      "Epoch:170/200 AVG Training Loss:0.663 AVG Validation Loss:0.661 AVG Training Acc 60.56 % AVG Validation Acc 58.74 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.664 AVG Validation Loss:0.662 AVG Training Acc 60.64 % AVG Validation Acc 58.74 %\n",
      "Epoch:190/200 AVG Training Loss:0.663 AVG Validation Loss:0.661 AVG Training Acc 60.58 % AVG Validation Acc 58.87 %\n",
      "Epoch:200/200 AVG Training Loss:0.662 AVG Validation Loss:0.659 AVG Training Acc 61.13 % AVG Validation Acc 60.35 %\n",
      "Split 102\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f84b168e231a411e930f7caca2219e50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.498 AVG Validation Loss:5.734 AVG Training Acc 82.10 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.532 AVG Validation Loss:5.942 AVG Training Acc 78.96 % AVG Validation Acc 20.16 %\n",
      "Epoch    25: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.702 AVG Validation Loss:0.828 AVG Training Acc 50.91 % AVG Validation Acc 20.83 %\n",
      "Epoch:40/200 AVG Training Loss:0.690 AVG Validation Loss:0.806 AVG Training Acc 54.45 % AVG Validation Acc 22.18 %\n",
      "Epoch:50/200 AVG Training Loss:0.681 AVG Validation Loss:0.808 AVG Training Acc 57.23 % AVG Validation Acc 24.87 %\n",
      "Epoch    56: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.683 AVG Validation Loss:0.755 AVG Training Acc 55.18 % AVG Validation Acc 37.10 %\n",
      "Epoch:70/200 AVG Training Loss:0.671 AVG Validation Loss:0.696 AVG Training Acc 58.80 % AVG Validation Acc 55.51 %\n",
      "Epoch:80/200 AVG Training Loss:0.670 AVG Validation Loss:0.686 AVG Training Acc 59.19 % AVG Validation Acc 56.85 %\n",
      "Epoch:90/200 AVG Training Loss:0.670 AVG Validation Loss:0.685 AVG Training Acc 59.00 % AVG Validation Acc 56.72 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.666 AVG Validation Loss:0.684 AVG Training Acc 59.71 % AVG Validation Acc 56.72 %\n",
      "Epoch:110/200 AVG Training Loss:0.667 AVG Validation Loss:0.681 AVG Training Acc 60.14 % AVG Validation Acc 56.85 %\n",
      "Epoch:120/200 AVG Training Loss:0.667 AVG Validation Loss:0.679 AVG Training Acc 59.59 % AVG Validation Acc 57.39 %\n",
      "Epoch:130/200 AVG Training Loss:0.664 AVG Validation Loss:0.677 AVG Training Acc 59.53 % AVG Validation Acc 57.80 %\n",
      "Epoch:140/200 AVG Training Loss:0.667 AVG Validation Loss:0.676 AVG Training Acc 59.93 % AVG Validation Acc 57.93 %\n",
      "Epoch:150/200 AVG Training Loss:0.665 AVG Validation Loss:0.675 AVG Training Acc 59.99 % AVG Validation Acc 58.20 %\n",
      "Epoch:160/200 AVG Training Loss:0.665 AVG Validation Loss:0.674 AVG Training Acc 59.87 % AVG Validation Acc 58.47 %\n",
      "Epoch:170/200 AVG Training Loss:0.664 AVG Validation Loss:0.674 AVG Training Acc 59.50 % AVG Validation Acc 58.20 %\n",
      "Epoch:180/200 AVG Training Loss:0.665 AVG Validation Loss:0.672 AVG Training Acc 60.00 % AVG Validation Acc 58.20 %\n",
      "Epoch:190/200 AVG Training Loss:0.663 AVG Validation Loss:0.672 AVG Training Acc 60.40 % AVG Validation Acc 58.06 %\n",
      "Epoch:200/200 AVG Training Loss:0.664 AVG Validation Loss:0.672 AVG Training Acc 60.12 % AVG Validation Acc 57.80 %\n",
      "Split 103\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eb2befb412042eb88952e21050e158c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.482 AVG Validation Loss:5.566 AVG Training Acc 81.90 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.596 AVG Validation Loss:9.028 AVG Training Acc 75.56 % AVG Validation Acc 20.16 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.703 AVG Validation Loss:0.833 AVG Training Acc 50.95 % AVG Validation Acc 20.70 %\n",
      "Epoch:40/200 AVG Training Loss:0.697 AVG Validation Loss:0.812 AVG Training Acc 51.82 % AVG Validation Acc 20.83 %\n",
      "Epoch:50/200 AVG Training Loss:0.689 AVG Validation Loss:0.810 AVG Training Acc 53.99 % AVG Validation Acc 24.19 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.688 AVG Validation Loss:0.780 AVG Training Acc 55.95 % AVG Validation Acc 38.31 %\n",
      "Epoch:70/200 AVG Training Loss:0.672 AVG Validation Loss:0.705 AVG Training Acc 58.77 % AVG Validation Acc 53.76 %\n",
      "Epoch:80/200 AVG Training Loss:0.669 AVG Validation Loss:0.688 AVG Training Acc 59.63 % AVG Validation Acc 57.39 %\n",
      "Epoch:90/200 AVG Training Loss:0.667 AVG Validation Loss:0.683 AVG Training Acc 59.89 % AVG Validation Acc 58.20 %\n",
      "Epoch:100/200 AVG Training Loss:0.669 AVG Validation Loss:0.681 AVG Training Acc 59.45 % AVG Validation Acc 58.47 %\n",
      "Epoch:110/200 AVG Training Loss:0.668 AVG Validation Loss:0.680 AVG Training Acc 60.04 % AVG Validation Acc 58.47 %\n",
      "Epoch:120/200 AVG Training Loss:0.669 AVG Validation Loss:0.680 AVG Training Acc 59.89 % AVG Validation Acc 58.33 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.666 AVG Validation Loss:0.679 AVG Training Acc 60.10 % AVG Validation Acc 58.47 %\n",
      "Epoch:140/200 AVG Training Loss:0.666 AVG Validation Loss:0.677 AVG Training Acc 60.42 % AVG Validation Acc 58.60 %\n",
      "Epoch:150/200 AVG Training Loss:0.664 AVG Validation Loss:0.676 AVG Training Acc 60.65 % AVG Validation Acc 58.87 %\n",
      "Epoch:160/200 AVG Training Loss:0.667 AVG Validation Loss:0.674 AVG Training Acc 60.65 % AVG Validation Acc 59.01 %\n",
      "Epoch:170/200 AVG Training Loss:0.665 AVG Validation Loss:0.673 AVG Training Acc 60.30 % AVG Validation Acc 59.01 %\n",
      "Epoch:180/200 AVG Training Loss:0.667 AVG Validation Loss:0.672 AVG Training Acc 60.30 % AVG Validation Acc 59.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.667 AVG Validation Loss:0.672 AVG Training Acc 60.25 % AVG Validation Acc 59.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.667 AVG Validation Loss:0.671 AVG Training Acc 60.47 % AVG Validation Acc 59.14 %\n",
      "Split 104\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "523cbcd9d6284826b827e828eb8d797a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.533 AVG Validation Loss:4.890 AVG Training Acc 79.77 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.635 AVG Validation Loss:1.832 AVG Training Acc 69.34 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.526 AVG Validation Loss:9.436 AVG Training Acc 83.39 % AVG Validation Acc 20.16 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.755 AVG Validation Loss:0.906 AVG Training Acc 50.00 % AVG Validation Acc 20.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.680 AVG Validation Loss:0.769 AVG Training Acc 57.24 % AVG Validation Acc 38.04 %\n",
      "Epoch:60/200 AVG Training Loss:0.678 AVG Validation Loss:0.757 AVG Training Acc 58.38 % AVG Validation Acc 43.28 %\n",
      "Epoch:70/200 AVG Training Loss:0.677 AVG Validation Loss:0.750 AVG Training Acc 58.65 % AVG Validation Acc 45.43 %\n",
      "Epoch:80/200 AVG Training Loss:0.673 AVG Validation Loss:0.753 AVG Training Acc 59.30 % AVG Validation Acc 45.70 %\n",
      "Epoch:90/200 AVG Training Loss:0.672 AVG Validation Loss:0.751 AVG Training Acc 59.17 % AVG Validation Acc 46.24 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.669 AVG Validation Loss:0.722 AVG Training Acc 59.50 % AVG Validation Acc 50.94 %\n",
      "Epoch:110/200 AVG Training Loss:0.664 AVG Validation Loss:0.694 AVG Training Acc 60.68 % AVG Validation Acc 55.65 %\n",
      "Epoch:120/200 AVG Training Loss:0.664 AVG Validation Loss:0.683 AVG Training Acc 60.65 % AVG Validation Acc 57.12 %\n",
      "Epoch:130/200 AVG Training Loss:0.662 AVG Validation Loss:0.679 AVG Training Acc 60.93 % AVG Validation Acc 57.66 %\n",
      "Epoch:140/200 AVG Training Loss:0.662 AVG Validation Loss:0.677 AVG Training Acc 61.08 % AVG Validation Acc 58.33 %\n",
      "Epoch:150/200 AVG Training Loss:0.663 AVG Validation Loss:0.676 AVG Training Acc 60.62 % AVG Validation Acc 58.74 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:160/200 AVG Training Loss:0.662 AVG Validation Loss:0.676 AVG Training Acc 60.70 % AVG Validation Acc 58.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.660 AVG Validation Loss:0.675 AVG Training Acc 61.21 % AVG Validation Acc 58.87 %\n",
      "Epoch:180/200 AVG Training Loss:0.660 AVG Validation Loss:0.675 AVG Training Acc 61.35 % AVG Validation Acc 58.74 %\n",
      "Epoch:190/200 AVG Training Loss:0.662 AVG Validation Loss:0.674 AVG Training Acc 60.76 % AVG Validation Acc 59.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.660 AVG Validation Loss:0.674 AVG Training Acc 60.80 % AVG Validation Acc 58.87 %\n",
      "Split 105\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0cf562cd91c400ea25395ecde6c459b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.430 AVG Validation Loss:4.910 AVG Training Acc 83.98 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.539 AVG Validation Loss:4.422 AVG Training Acc 81.41 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.530 AVG Validation Loss:4.938 AVG Training Acc 79.63 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.625 AVG Validation Loss:1.796 AVG Training Acc 68.80 % AVG Validation Acc 20.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.557 AVG Validation Loss:10.647 AVG Training Acc 67.09 % AVG Validation Acc 20.30 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:1.504 AVG Validation Loss:1.609 AVG Training Acc 56.93 % AVG Validation Acc 20.30 %\n",
      "Epoch:70/200 AVG Training Loss:0.692 AVG Validation Loss:0.843 AVG Training Acc 54.83 % AVG Validation Acc 22.04 %\n",
      "Epoch:80/200 AVG Training Loss:0.681 AVG Validation Loss:0.825 AVG Training Acc 56.55 % AVG Validation Acc 23.52 %\n",
      "Epoch:90/200 AVG Training Loss:0.677 AVG Validation Loss:0.809 AVG Training Acc 58.40 % AVG Validation Acc 27.02 %\n",
      "Epoch:100/200 AVG Training Loss:0.673 AVG Validation Loss:0.803 AVG Training Acc 58.43 % AVG Validation Acc 27.69 %\n",
      "Epoch:110/200 AVG Training Loss:0.667 AVG Validation Loss:0.804 AVG Training Acc 59.71 % AVG Validation Acc 28.36 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:120/200 AVG Training Loss:0.685 AVG Validation Loss:0.784 AVG Training Acc 55.10 % AVG Validation Acc 31.85 %\n",
      "Epoch:130/200 AVG Training Loss:0.657 AVG Validation Loss:0.685 AVG Training Acc 60.15 % AVG Validation Acc 55.24 %\n",
      "Epoch:140/200 AVG Training Loss:0.657 AVG Validation Loss:0.669 AVG Training Acc 60.94 % AVG Validation Acc 57.93 %\n",
      "Epoch:150/200 AVG Training Loss:0.656 AVG Validation Loss:0.666 AVG Training Acc 60.94 % AVG Validation Acc 58.74 %\n",
      "Epoch:160/200 AVG Training Loss:0.656 AVG Validation Loss:0.665 AVG Training Acc 61.09 % AVG Validation Acc 59.01 %\n",
      "Epoch:170/200 AVG Training Loss:0.655 AVG Validation Loss:0.664 AVG Training Acc 60.39 % AVG Validation Acc 58.74 %\n",
      "Epoch   179: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:180/200 AVG Training Loss:0.652 AVG Validation Loss:0.663 AVG Training Acc 61.15 % AVG Validation Acc 59.41 %\n",
      "Epoch:190/200 AVG Training Loss:0.653 AVG Validation Loss:0.661 AVG Training Acc 60.56 % AVG Validation Acc 59.27 %\n",
      "Epoch:200/200 AVG Training Loss:0.650 AVG Validation Loss:0.660 AVG Training Acc 61.59 % AVG Validation Acc 59.14 %\n",
      "Split 106\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "083a943312a84c2ab33ce2106fbe411f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.563 AVG Validation Loss:4.594 AVG Training Acc 75.95 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.644 AVG Validation Loss:1.667 AVG Training Acc 66.37 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.643 AVG Validation Loss:1.695 AVG Training Acc 67.39 % AVG Validation Acc 20.30 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.689 AVG Validation Loss:0.771 AVG Training Acc 52.84 % AVG Validation Acc 23.79 %\n",
      "Epoch:50/200 AVG Training Loss:0.675 AVG Validation Loss:0.778 AVG Training Acc 58.34 % AVG Validation Acc 40.46 %\n",
      "Epoch:60/200 AVG Training Loss:0.672 AVG Validation Loss:0.778 AVG Training Acc 58.96 % AVG Validation Acc 42.74 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.668 AVG Validation Loss:0.726 AVG Training Acc 59.57 % AVG Validation Acc 52.82 %\n",
      "Epoch:80/200 AVG Training Loss:0.662 AVG Validation Loss:0.700 AVG Training Acc 61.08 % AVG Validation Acc 56.32 %\n",
      "Epoch:90/200 AVG Training Loss:0.664 AVG Validation Loss:0.691 AVG Training Acc 60.30 % AVG Validation Acc 56.85 %\n",
      "Epoch:100/200 AVG Training Loss:0.663 AVG Validation Loss:0.689 AVG Training Acc 60.81 % AVG Validation Acc 57.12 %\n",
      "Epoch:110/200 AVG Training Loss:0.662 AVG Validation Loss:0.688 AVG Training Acc 60.93 % AVG Validation Acc 57.66 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.665 AVG Validation Loss:0.688 AVG Training Acc 61.05 % AVG Validation Acc 57.39 %\n",
      "Epoch:130/200 AVG Training Loss:0.661 AVG Validation Loss:0.687 AVG Training Acc 61.09 % AVG Validation Acc 57.53 %\n",
      "Epoch:140/200 AVG Training Loss:0.661 AVG Validation Loss:0.686 AVG Training Acc 61.27 % AVG Validation Acc 57.66 %\n",
      "Epoch:150/200 AVG Training Loss:0.662 AVG Validation Loss:0.685 AVG Training Acc 61.24 % AVG Validation Acc 57.53 %\n",
      "Epoch:160/200 AVG Training Loss:0.661 AVG Validation Loss:0.685 AVG Training Acc 61.21 % AVG Validation Acc 57.93 %\n",
      "Epoch:170/200 AVG Training Loss:0.660 AVG Validation Loss:0.684 AVG Training Acc 61.12 % AVG Validation Acc 57.66 %\n",
      "Epoch:180/200 AVG Training Loss:0.661 AVG Validation Loss:0.684 AVG Training Acc 61.13 % AVG Validation Acc 57.93 %\n",
      "Epoch:190/200 AVG Training Loss:0.659 AVG Validation Loss:0.683 AVG Training Acc 61.30 % AVG Validation Acc 58.06 %\n",
      "Epoch:200/200 AVG Training Loss:0.662 AVG Validation Loss:0.683 AVG Training Acc 61.27 % AVG Validation Acc 57.80 %\n",
      "Split 107\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "976ec5328a7544c8986a3d0324d5ad18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.530 AVG Validation Loss:3.637 AVG Training Acc 77.75 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:1.630 AVG Training Acc 65.81 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.641 AVG Validation Loss:1.981 AVG Training Acc 65.79 % AVG Validation Acc 20.05 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.691 AVG Validation Loss:0.853 AVG Training Acc 54.78 % AVG Validation Acc 20.73 %\n",
      "Epoch:50/200 AVG Training Loss:0.683 AVG Validation Loss:0.864 AVG Training Acc 56.61 % AVG Validation Acc 22.88 %\n",
      "Epoch:60/200 AVG Training Loss:0.679 AVG Validation Loss:0.857 AVG Training Acc 56.99 % AVG Validation Acc 24.50 %\n",
      "Epoch:70/200 AVG Training Loss:0.674 AVG Validation Loss:0.866 AVG Training Acc 57.77 % AVG Validation Acc 27.99 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.676 AVG Validation Loss:0.767 AVG Training Acc 57.81 % AVG Validation Acc 45.36 %\n",
      "Epoch:90/200 AVG Training Loss:0.665 AVG Validation Loss:0.700 AVG Training Acc 60.01 % AVG Validation Acc 57.34 %\n",
      "Epoch:100/200 AVG Training Loss:0.662 AVG Validation Loss:0.689 AVG Training Acc 60.74 % AVG Validation Acc 59.08 %\n",
      "Epoch:110/200 AVG Training Loss:0.662 AVG Validation Loss:0.689 AVG Training Acc 60.17 % AVG Validation Acc 58.68 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.661 AVG Validation Loss:0.687 AVG Training Acc 60.97 % AVG Validation Acc 59.49 %\n",
      "Epoch:130/200 AVG Training Loss:0.657 AVG Validation Loss:0.684 AVG Training Acc 60.91 % AVG Validation Acc 59.76 %\n",
      "Epoch:140/200 AVG Training Loss:0.659 AVG Validation Loss:0.682 AVG Training Acc 60.79 % AVG Validation Acc 59.89 %\n",
      "Epoch:150/200 AVG Training Loss:0.660 AVG Validation Loss:0.680 AVG Training Acc 60.80 % AVG Validation Acc 60.30 %\n",
      "Epoch:160/200 AVG Training Loss:0.658 AVG Validation Loss:0.679 AVG Training Acc 61.08 % AVG Validation Acc 60.57 %\n",
      "Epoch:170/200 AVG Training Loss:0.660 AVG Validation Loss:0.678 AVG Training Acc 61.06 % AVG Validation Acc 60.70 %\n",
      "Epoch:180/200 AVG Training Loss:0.659 AVG Validation Loss:0.677 AVG Training Acc 61.30 % AVG Validation Acc 60.70 %\n",
      "Epoch:190/200 AVG Training Loss:0.661 AVG Validation Loss:0.676 AVG Training Acc 60.42 % AVG Validation Acc 60.43 %\n",
      "Epoch:200/200 AVG Training Loss:0.660 AVG Validation Loss:0.675 AVG Training Acc 60.65 % AVG Validation Acc 60.57 %\n",
      "Split 108\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ece82777ae44d6192503537d744e60a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.520 AVG Validation Loss:5.175 AVG Training Acc 81.66 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.632 AVG Validation Loss:1.783 AVG Training Acc 69.36 % AVG Validation Acc 20.19 %\n",
      "Epoch:30/200 AVG Training Loss:0.550 AVG Validation Loss:3.360 AVG Training Acc 74.89 % AVG Validation Acc 20.05 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.699 AVG Validation Loss:0.784 AVG Training Acc 50.43 % AVG Validation Acc 20.73 %\n",
      "Epoch:50/200 AVG Training Loss:0.677 AVG Validation Loss:0.790 AVG Training Acc 57.73 % AVG Validation Acc 31.49 %\n",
      "Epoch:60/200 AVG Training Loss:0.675 AVG Validation Loss:0.785 AVG Training Acc 58.59 % AVG Validation Acc 35.40 %\n",
      "Epoch    65: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.670 AVG Validation Loss:0.745 AVG Training Acc 58.44 % AVG Validation Acc 47.38 %\n",
      "Epoch:80/200 AVG Training Loss:0.664 AVG Validation Loss:0.710 AVG Training Acc 60.23 % AVG Validation Acc 55.32 %\n",
      "Epoch:90/200 AVG Training Loss:0.662 AVG Validation Loss:0.700 AVG Training Acc 60.63 % AVG Validation Acc 56.66 %\n",
      "Epoch:100/200 AVG Training Loss:0.663 AVG Validation Loss:0.696 AVG Training Acc 60.36 % AVG Validation Acc 56.66 %\n",
      "Epoch:110/200 AVG Training Loss:0.661 AVG Validation Loss:0.695 AVG Training Acc 60.56 % AVG Validation Acc 56.39 %\n",
      "Epoch:120/200 AVG Training Loss:0.661 AVG Validation Loss:0.694 AVG Training Acc 60.96 % AVG Validation Acc 56.39 %\n",
      "Epoch:130/200 AVG Training Loss:0.662 AVG Validation Loss:0.694 AVG Training Acc 60.73 % AVG Validation Acc 56.66 %\n",
      "Epoch   132: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:140/200 AVG Training Loss:0.660 AVG Validation Loss:0.693 AVG Training Acc 61.69 % AVG Validation Acc 56.39 %\n",
      "Epoch:150/200 AVG Training Loss:0.659 AVG Validation Loss:0.692 AVG Training Acc 60.99 % AVG Validation Acc 56.66 %\n",
      "Epoch:160/200 AVG Training Loss:0.661 AVG Validation Loss:0.692 AVG Training Acc 60.95 % AVG Validation Acc 56.53 %\n",
      "Epoch:170/200 AVG Training Loss:0.660 AVG Validation Loss:0.691 AVG Training Acc 61.30 % AVG Validation Acc 56.53 %\n",
      "Epoch:180/200 AVG Training Loss:0.660 AVG Validation Loss:0.690 AVG Training Acc 60.73 % AVG Validation Acc 56.66 %\n",
      "Epoch:190/200 AVG Training Loss:0.659 AVG Validation Loss:0.689 AVG Training Acc 60.79 % AVG Validation Acc 56.53 %\n",
      "Epoch:200/200 AVG Training Loss:0.659 AVG Validation Loss:0.689 AVG Training Acc 61.53 % AVG Validation Acc 56.80 %\n",
      "Split 109\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40cdcb1e713b47da8cce5c5e9f6f2e48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.531 AVG Validation Loss:4.217 AVG Training Acc 79.72 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.545 AVG Validation Loss:5.701 AVG Training Acc 78.29 % AVG Validation Acc 20.05 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.681 AVG Validation Loss:1.104 AVG Training Acc 60.63 % AVG Validation Acc 20.46 %\n",
      "Epoch:40/200 AVG Training Loss:0.675 AVG Validation Loss:0.986 AVG Training Acc 59.22 % AVG Validation Acc 20.73 %\n",
      "Epoch:50/200 AVG Training Loss:0.590 AVG Validation Loss:1.351 AVG Training Acc 71.21 % AVG Validation Acc 20.59 %\n",
      "Epoch:60/200 AVG Training Loss:0.665 AVG Validation Loss:0.960 AVG Training Acc 61.05 % AVG Validation Acc 21.40 %\n",
      "Epoch:70/200 AVG Training Loss:0.667 AVG Validation Loss:0.906 AVG Training Acc 60.62 % AVG Validation Acc 23.42 %\n",
      "Epoch:80/200 AVG Training Loss:0.662 AVG Validation Loss:0.910 AVG Training Acc 61.41 % AVG Validation Acc 23.15 %\n",
      "Epoch:90/200 AVG Training Loss:0.667 AVG Validation Loss:0.883 AVG Training Acc 61.15 % AVG Validation Acc 22.88 %\n",
      "Epoch:100/200 AVG Training Loss:0.661 AVG Validation Loss:0.916 AVG Training Acc 62.05 % AVG Validation Acc 24.50 %\n",
      "Epoch:110/200 AVG Training Loss:0.650 AVG Validation Loss:0.924 AVG Training Acc 61.86 % AVG Validation Acc 24.63 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:120/200 AVG Training Loss:0.666 AVG Validation Loss:0.757 AVG Training Acc 59.08 % AVG Validation Acc 40.92 %\n",
      "Epoch:130/200 AVG Training Loss:0.658 AVG Validation Loss:0.713 AVG Training Acc 60.69 % AVG Validation Acc 48.45 %\n",
      "Epoch:140/200 AVG Training Loss:0.657 AVG Validation Loss:0.704 AVG Training Acc 60.63 % AVG Validation Acc 49.53 %\n",
      "Epoch:150/200 AVG Training Loss:0.654 AVG Validation Loss:0.705 AVG Training Acc 61.20 % AVG Validation Acc 49.80 %\n",
      "Epoch:160/200 AVG Training Loss:0.654 AVG Validation Loss:0.709 AVG Training Acc 60.92 % AVG Validation Acc 50.20 %\n",
      "Epoch:170/200 AVG Training Loss:0.652 AVG Validation Loss:0.703 AVG Training Acc 61.10 % AVG Validation Acc 49.80 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:180/200 AVG Training Loss:0.650 AVG Validation Loss:0.701 AVG Training Acc 61.58 % AVG Validation Acc 51.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.652 AVG Validation Loss:0.695 AVG Training Acc 61.52 % AVG Validation Acc 51.95 %\n",
      "Epoch:200/200 AVG Training Loss:0.650 AVG Validation Loss:0.687 AVG Training Acc 61.61 % AVG Validation Acc 52.89 %\n",
      "Split 110\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba8cf8f1248a4293b161c5687a1c92ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.480 AVG Validation Loss:4.706 AVG Training Acc 82.75 % AVG Validation Acc 20.19 %\n",
      "Epoch:20/200 AVG Training Loss:0.649 AVG Validation Loss:1.707 AVG Training Acc 67.48 % AVG Validation Acc 20.19 %\n",
      "Epoch:30/200 AVG Training Loss:0.654 AVG Validation Loss:1.608 AVG Training Acc 66.21 % AVG Validation Acc 20.19 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.709 AVG Validation Loss:0.819 AVG Training Acc 50.65 % AVG Validation Acc 19.78 %\n",
      "Epoch:50/200 AVG Training Loss:0.680 AVG Validation Loss:0.789 AVG Training Acc 56.64 % AVG Validation Acc 26.38 %\n",
      "Epoch:60/200 AVG Training Loss:0.677 AVG Validation Loss:0.788 AVG Training Acc 57.55 % AVG Validation Acc 40.11 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.674 AVG Validation Loss:0.744 AVG Training Acc 58.17 % AVG Validation Acc 48.18 %\n",
      "Epoch:80/200 AVG Training Loss:0.666 AVG Validation Loss:0.699 AVG Training Acc 60.14 % AVG Validation Acc 56.12 %\n",
      "Epoch:90/200 AVG Training Loss:0.666 AVG Validation Loss:0.684 AVG Training Acc 60.37 % AVG Validation Acc 58.01 %\n",
      "Epoch:100/200 AVG Training Loss:0.665 AVG Validation Loss:0.681 AVG Training Acc 60.39 % AVG Validation Acc 58.14 %\n",
      "Epoch:110/200 AVG Training Loss:0.663 AVG Validation Loss:0.680 AVG Training Acc 60.76 % AVG Validation Acc 57.87 %\n",
      "Epoch:120/200 AVG Training Loss:0.663 AVG Validation Loss:0.680 AVG Training Acc 60.78 % AVG Validation Acc 58.01 %\n",
      "Epoch   128: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.663 AVG Validation Loss:0.680 AVG Training Acc 61.09 % AVG Validation Acc 57.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.663 AVG Validation Loss:0.678 AVG Training Acc 60.84 % AVG Validation Acc 57.87 %\n",
      "Epoch:150/200 AVG Training Loss:0.661 AVG Validation Loss:0.677 AVG Training Acc 61.09 % AVG Validation Acc 58.14 %\n",
      "Epoch:160/200 AVG Training Loss:0.663 AVG Validation Loss:0.676 AVG Training Acc 60.84 % AVG Validation Acc 58.28 %\n",
      "Epoch:170/200 AVG Training Loss:0.663 AVG Validation Loss:0.675 AVG Training Acc 60.95 % AVG Validation Acc 58.55 %\n",
      "Epoch:180/200 AVG Training Loss:0.662 AVG Validation Loss:0.675 AVG Training Acc 61.17 % AVG Validation Acc 58.55 %\n",
      "Epoch:190/200 AVG Training Loss:0.661 AVG Validation Loss:0.674 AVG Training Acc 61.03 % AVG Validation Acc 58.55 %\n",
      "Epoch:200/200 AVG Training Loss:0.662 AVG Validation Loss:0.673 AVG Training Acc 61.18 % AVG Validation Acc 58.68 %\n",
      "Split 111\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "829b77810d0a44ab9b1ee49040a04cee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.536 AVG Validation Loss:3.341 AVG Training Acc 79.60 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.637 AVG Validation Loss:1.746 AVG Training Acc 67.97 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.598 AVG Validation Loss:7.219 AVG Training Acc 69.17 % AVG Validation Acc 20.16 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.695 AVG Validation Loss:0.768 AVG Training Acc 50.22 % AVG Validation Acc 21.77 %\n",
      "Epoch:50/200 AVG Training Loss:0.683 AVG Validation Loss:0.816 AVG Training Acc 57.17 % AVG Validation Acc 29.30 %\n",
      "Epoch:60/200 AVG Training Loss:0.676 AVG Validation Loss:0.799 AVG Training Acc 58.31 % AVG Validation Acc 37.63 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.668 AVG Validation Loss:0.730 AVG Training Acc 59.24 % AVG Validation Acc 51.08 %\n",
      "Epoch:80/200 AVG Training Loss:0.663 AVG Validation Loss:0.699 AVG Training Acc 60.37 % AVG Validation Acc 55.38 %\n",
      "Epoch:90/200 AVG Training Loss:0.664 AVG Validation Loss:0.690 AVG Training Acc 60.05 % AVG Validation Acc 57.66 %\n",
      "Epoch:100/200 AVG Training Loss:0.663 AVG Validation Loss:0.688 AVG Training Acc 60.85 % AVG Validation Acc 57.53 %\n",
      "Epoch:110/200 AVG Training Loss:0.663 AVG Validation Loss:0.688 AVG Training Acc 60.33 % AVG Validation Acc 57.66 %\n",
      "Epoch   117: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.661 AVG Validation Loss:0.688 AVG Training Acc 60.84 % AVG Validation Acc 57.66 %\n",
      "Epoch:130/200 AVG Training Loss:0.659 AVG Validation Loss:0.686 AVG Training Acc 60.90 % AVG Validation Acc 57.26 %\n",
      "Epoch:140/200 AVG Training Loss:0.661 AVG Validation Loss:0.685 AVG Training Acc 60.69 % AVG Validation Acc 57.80 %\n",
      "Epoch:150/200 AVG Training Loss:0.662 AVG Validation Loss:0.684 AVG Training Acc 61.06 % AVG Validation Acc 58.06 %\n",
      "Epoch:160/200 AVG Training Loss:0.662 AVG Validation Loss:0.683 AVG Training Acc 60.65 % AVG Validation Acc 57.80 %\n",
      "Epoch:170/200 AVG Training Loss:0.660 AVG Validation Loss:0.682 AVG Training Acc 61.32 % AVG Validation Acc 58.33 %\n",
      "Epoch:180/200 AVG Training Loss:0.660 AVG Validation Loss:0.681 AVG Training Acc 61.32 % AVG Validation Acc 58.47 %\n",
      "Epoch:190/200 AVG Training Loss:0.659 AVG Validation Loss:0.680 AVG Training Acc 61.09 % AVG Validation Acc 58.60 %\n",
      "Epoch:200/200 AVG Training Loss:0.661 AVG Validation Loss:0.680 AVG Training Acc 60.59 % AVG Validation Acc 58.47 %\n",
      "Split 112\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9adb0890f04346a2abb14d4725d50133",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.559 AVG Validation Loss:3.631 AVG Training Acc 80.27 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.640 AVG Validation Loss:1.735 AVG Training Acc 67.75 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.644 AVG Validation Loss:1.739 AVG Training Acc 66.53 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.645 AVG Validation Loss:1.567 AVG Training Acc 65.79 % AVG Validation Acc 20.16 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.690 AVG Validation Loss:0.755 AVG Training Acc 54.12 % AVG Validation Acc 21.77 %\n",
      "Epoch:60/200 AVG Training Loss:0.680 AVG Validation Loss:0.769 AVG Training Acc 57.40 % AVG Validation Acc 38.44 %\n",
      "Epoch:70/200 AVG Training Loss:0.676 AVG Validation Loss:0.764 AVG Training Acc 58.71 % AVG Validation Acc 43.01 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.671 AVG Validation Loss:0.720 AVG Training Acc 59.12 % AVG Validation Acc 54.03 %\n",
      "Epoch:90/200 AVG Training Loss:0.666 AVG Validation Loss:0.689 AVG Training Acc 60.72 % AVG Validation Acc 58.60 %\n",
      "Epoch:100/200 AVG Training Loss:0.666 AVG Validation Loss:0.677 AVG Training Acc 60.90 % AVG Validation Acc 60.35 %\n",
      "Epoch:110/200 AVG Training Loss:0.663 AVG Validation Loss:0.675 AVG Training Acc 60.86 % AVG Validation Acc 60.48 %\n",
      "Epoch:120/200 AVG Training Loss:0.665 AVG Validation Loss:0.674 AVG Training Acc 60.59 % AVG Validation Acc 61.02 %\n",
      "Epoch:130/200 AVG Training Loss:0.665 AVG Validation Loss:0.674 AVG Training Acc 60.30 % AVG Validation Acc 61.02 %\n",
      "Epoch   132: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:140/200 AVG Training Loss:0.663 AVG Validation Loss:0.673 AVG Training Acc 61.01 % AVG Validation Acc 60.89 %\n",
      "Epoch:150/200 AVG Training Loss:0.665 AVG Validation Loss:0.673 AVG Training Acc 60.80 % AVG Validation Acc 61.02 %\n",
      "Epoch:160/200 AVG Training Loss:0.664 AVG Validation Loss:0.672 AVG Training Acc 61.02 % AVG Validation Acc 61.16 %\n",
      "Epoch:170/200 AVG Training Loss:0.664 AVG Validation Loss:0.672 AVG Training Acc 60.48 % AVG Validation Acc 61.29 %\n",
      "Epoch:180/200 AVG Training Loss:0.665 AVG Validation Loss:0.672 AVG Training Acc 60.84 % AVG Validation Acc 61.56 %\n",
      "Epoch:190/200 AVG Training Loss:0.664 AVG Validation Loss:0.671 AVG Training Acc 60.91 % AVG Validation Acc 61.29 %\n",
      "Epoch:200/200 AVG Training Loss:0.662 AVG Validation Loss:0.671 AVG Training Acc 61.07 % AVG Validation Acc 61.29 %\n",
      "Split 113\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "559ed52e68f34c09898b64b841453659",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.530 AVG Validation Loss:5.106 AVG Training Acc 78.39 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.548 AVG Validation Loss:3.968 AVG Training Acc 78.82 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.524 AVG Validation Loss:6.676 AVG Training Acc 83.40 % AVG Validation Acc 20.16 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.809 AVG Validation Loss:0.955 AVG Training Acc 50.30 % AVG Validation Acc 21.10 %\n",
      "Epoch:50/200 AVG Training Loss:0.694 AVG Validation Loss:0.776 AVG Training Acc 51.54 % AVG Validation Acc 23.39 %\n",
      "Epoch:60/200 AVG Training Loss:0.681 AVG Validation Loss:0.798 AVG Training Acc 55.87 % AVG Validation Acc 29.57 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.690 AVG Validation Loss:0.787 AVG Training Acc 55.85 % AVG Validation Acc 36.42 %\n",
      "Epoch:80/200 AVG Training Loss:0.669 AVG Validation Loss:0.703 AVG Training Acc 59.36 % AVG Validation Acc 50.13 %\n",
      "Epoch:90/200 AVG Training Loss:0.663 AVG Validation Loss:0.685 AVG Training Acc 60.38 % AVG Validation Acc 55.65 %\n",
      "Epoch:100/200 AVG Training Loss:0.664 AVG Validation Loss:0.682 AVG Training Acc 60.07 % AVG Validation Acc 56.45 %\n",
      "Epoch:110/200 AVG Training Loss:0.662 AVG Validation Loss:0.681 AVG Training Acc 60.46 % AVG Validation Acc 56.99 %\n",
      "Epoch:120/200 AVG Training Loss:0.663 AVG Validation Loss:0.679 AVG Training Acc 60.41 % AVG Validation Acc 57.80 %\n",
      "Epoch:130/200 AVG Training Loss:0.661 AVG Validation Loss:0.677 AVG Training Acc 61.06 % AVG Validation Acc 57.80 %\n",
      "Epoch:140/200 AVG Training Loss:0.662 AVG Validation Loss:0.677 AVG Training Acc 60.99 % AVG Validation Acc 57.80 %\n",
      "Epoch:150/200 AVG Training Loss:0.660 AVG Validation Loss:0.677 AVG Training Acc 60.91 % AVG Validation Acc 58.60 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:160/200 AVG Training Loss:0.658 AVG Validation Loss:0.675 AVG Training Acc 61.66 % AVG Validation Acc 59.01 %\n",
      "Epoch:170/200 AVG Training Loss:0.659 AVG Validation Loss:0.673 AVG Training Acc 61.51 % AVG Validation Acc 59.41 %\n",
      "Epoch:180/200 AVG Training Loss:0.660 AVG Validation Loss:0.671 AVG Training Acc 61.37 % AVG Validation Acc 59.54 %\n",
      "Epoch:190/200 AVG Training Loss:0.657 AVG Validation Loss:0.670 AVG Training Acc 61.55 % AVG Validation Acc 60.08 %\n",
      "Epoch:200/200 AVG Training Loss:0.658 AVG Validation Loss:0.669 AVG Training Acc 60.99 % AVG Validation Acc 60.22 %\n",
      "Split 114\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c6640c7ba864f11a16b829466ae4511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.557 AVG Validation Loss:4.136 AVG Training Acc 77.90 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.626 AVG Validation Loss:1.742 AVG Training Acc 68.20 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.652 AVG Validation Loss:1.856 AVG Training Acc 77.74 % AVG Validation Acc 20.16 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.695 AVG Validation Loss:0.767 AVG Training Acc 51.25 % AVG Validation Acc 21.64 %\n",
      "Epoch:50/200 AVG Training Loss:0.683 AVG Validation Loss:0.806 AVG Training Acc 57.25 % AVG Validation Acc 33.60 %\n",
      "Epoch:60/200 AVG Training Loss:0.673 AVG Validation Loss:0.800 AVG Training Acc 59.58 % AVG Validation Acc 40.32 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.668 AVG Validation Loss:0.730 AVG Training Acc 59.73 % AVG Validation Acc 51.88 %\n",
      "Epoch:80/200 AVG Training Loss:0.665 AVG Validation Loss:0.699 AVG Training Acc 60.62 % AVG Validation Acc 56.32 %\n",
      "Epoch:90/200 AVG Training Loss:0.664 AVG Validation Loss:0.691 AVG Training Acc 60.58 % AVG Validation Acc 57.26 %\n",
      "Epoch:100/200 AVG Training Loss:0.664 AVG Validation Loss:0.688 AVG Training Acc 60.74 % AVG Validation Acc 57.39 %\n",
      "Epoch:110/200 AVG Training Loss:0.664 AVG Validation Loss:0.687 AVG Training Acc 60.99 % AVG Validation Acc 57.53 %\n",
      "Epoch:120/200 AVG Training Loss:0.664 AVG Validation Loss:0.687 AVG Training Acc 60.70 % AVG Validation Acc 57.53 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.663 AVG Validation Loss:0.687 AVG Training Acc 60.85 % AVG Validation Acc 57.53 %\n",
      "Epoch:140/200 AVG Training Loss:0.661 AVG Validation Loss:0.686 AVG Training Acc 61.07 % AVG Validation Acc 57.53 %\n",
      "Epoch:150/200 AVG Training Loss:0.662 AVG Validation Loss:0.685 AVG Training Acc 61.16 % AVG Validation Acc 58.06 %\n",
      "Epoch:160/200 AVG Training Loss:0.660 AVG Validation Loss:0.684 AVG Training Acc 61.22 % AVG Validation Acc 58.74 %\n",
      "Epoch:170/200 AVG Training Loss:0.662 AVG Validation Loss:0.683 AVG Training Acc 60.68 % AVG Validation Acc 58.87 %\n",
      "Epoch:180/200 AVG Training Loss:0.662 AVG Validation Loss:0.682 AVG Training Acc 61.13 % AVG Validation Acc 59.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.662 AVG Validation Loss:0.682 AVG Training Acc 61.23 % AVG Validation Acc 58.87 %\n",
      "Epoch:200/200 AVG Training Loss:0.662 AVG Validation Loss:0.681 AVG Training Acc 61.04 % AVG Validation Acc 59.01 %\n",
      "Split 115\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a18104c3b2044945be04785e559f6263",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.463 AVG Validation Loss:5.471 AVG Training Acc 80.17 % AVG Validation Acc 20.16 %\n",
      "Epoch    16: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.698 AVG Validation Loss:1.114 AVG Training Acc 58.31 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.681 AVG Validation Loss:1.328 AVG Training Acc 61.96 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.610 AVG Validation Loss:1.818 AVG Training Acc 70.06 % AVG Validation Acc 20.30 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.722 AVG Validation Loss:0.843 AVG Training Acc 51.99 % AVG Validation Acc 23.66 %\n",
      "Epoch:60/200 AVG Training Loss:0.680 AVG Validation Loss:0.722 AVG Training Acc 56.54 % AVG Validation Acc 45.30 %\n",
      "Epoch:70/200 AVG Training Loss:0.678 AVG Validation Loss:0.715 AVG Training Acc 57.59 % AVG Validation Acc 49.73 %\n",
      "Epoch:80/200 AVG Training Loss:0.678 AVG Validation Loss:0.714 AVG Training Acc 57.75 % AVG Validation Acc 50.27 %\n",
      "Epoch:90/200 AVG Training Loss:0.677 AVG Validation Loss:0.713 AVG Training Acc 57.61 % AVG Validation Acc 52.15 %\n",
      "Epoch    98: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.676 AVG Validation Loss:0.709 AVG Training Acc 56.80 % AVG Validation Acc 52.15 %\n",
      "Epoch:110/200 AVG Training Loss:0.673 AVG Validation Loss:0.694 AVG Training Acc 57.73 % AVG Validation Acc 55.51 %\n",
      "Epoch:120/200 AVG Training Loss:0.671 AVG Validation Loss:0.683 AVG Training Acc 58.83 % AVG Validation Acc 56.59 %\n",
      "Epoch:130/200 AVG Training Loss:0.670 AVG Validation Loss:0.678 AVG Training Acc 58.77 % AVG Validation Acc 58.47 %\n",
      "Epoch:140/200 AVG Training Loss:0.672 AVG Validation Loss:0.677 AVG Training Acc 58.61 % AVG Validation Acc 58.47 %\n",
      "Epoch:150/200 AVG Training Loss:0.670 AVG Validation Loss:0.675 AVG Training Acc 58.86 % AVG Validation Acc 58.87 %\n",
      "Epoch:160/200 AVG Training Loss:0.672 AVG Validation Loss:0.675 AVG Training Acc 58.89 % AVG Validation Acc 58.74 %\n",
      "Epoch   168: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:170/200 AVG Training Loss:0.668 AVG Validation Loss:0.675 AVG Training Acc 59.05 % AVG Validation Acc 58.33 %\n",
      "Epoch:180/200 AVG Training Loss:0.671 AVG Validation Loss:0.674 AVG Training Acc 58.68 % AVG Validation Acc 58.60 %\n",
      "Epoch:190/200 AVG Training Loss:0.670 AVG Validation Loss:0.674 AVG Training Acc 59.05 % AVG Validation Acc 58.60 %\n",
      "Epoch:200/200 AVG Training Loss:0.669 AVG Validation Loss:0.674 AVG Training Acc 59.21 % AVG Validation Acc 58.74 %\n",
      "Split 116\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37e7215e03964f6392eb48096416413d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.522 AVG Validation Loss:8.482 AVG Training Acc 78.30 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.512 AVG Validation Loss:5.629 AVG Training Acc 83.10 % AVG Validation Acc 20.16 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.700 AVG Validation Loss:0.852 AVG Training Acc 52.22 % AVG Validation Acc 21.10 %\n",
      "Epoch:40/200 AVG Training Loss:0.688 AVG Validation Loss:0.830 AVG Training Acc 54.88 % AVG Validation Acc 30.38 %\n",
      "Epoch:50/200 AVG Training Loss:0.674 AVG Validation Loss:0.849 AVG Training Acc 57.74 % AVG Validation Acc 31.59 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.684 AVG Validation Loss:0.802 AVG Training Acc 56.46 % AVG Validation Acc 38.58 %\n",
      "Epoch:70/200 AVG Training Loss:0.663 AVG Validation Loss:0.716 AVG Training Acc 59.88 % AVG Validation Acc 50.13 %\n",
      "Epoch:80/200 AVG Training Loss:0.660 AVG Validation Loss:0.703 AVG Training Acc 60.37 % AVG Validation Acc 53.63 %\n",
      "Epoch:90/200 AVG Training Loss:0.661 AVG Validation Loss:0.702 AVG Training Acc 60.56 % AVG Validation Acc 54.30 %\n",
      "Epoch:100/200 AVG Training Loss:0.658 AVG Validation Loss:0.700 AVG Training Acc 61.00 % AVG Validation Acc 55.11 %\n",
      "Epoch:110/200 AVG Training Loss:0.658 AVG Validation Loss:0.701 AVG Training Acc 60.78 % AVG Validation Acc 55.24 %\n",
      "Epoch   111: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.660 AVG Validation Loss:0.699 AVG Training Acc 60.45 % AVG Validation Acc 55.51 %\n",
      "Epoch:130/200 AVG Training Loss:0.657 AVG Validation Loss:0.697 AVG Training Acc 60.98 % AVG Validation Acc 55.65 %\n",
      "Epoch:140/200 AVG Training Loss:0.657 AVG Validation Loss:0.695 AVG Training Acc 61.11 % AVG Validation Acc 55.65 %\n",
      "Epoch:150/200 AVG Training Loss:0.657 AVG Validation Loss:0.694 AVG Training Acc 61.05 % AVG Validation Acc 55.91 %\n",
      "Epoch:160/200 AVG Training Loss:0.655 AVG Validation Loss:0.693 AVG Training Acc 61.29 % AVG Validation Acc 56.18 %\n",
      "Epoch:170/200 AVG Training Loss:0.656 AVG Validation Loss:0.692 AVG Training Acc 60.89 % AVG Validation Acc 56.18 %\n",
      "Epoch:180/200 AVG Training Loss:0.658 AVG Validation Loss:0.691 AVG Training Acc 61.43 % AVG Validation Acc 56.45 %\n",
      "Epoch:190/200 AVG Training Loss:0.657 AVG Validation Loss:0.691 AVG Training Acc 61.31 % AVG Validation Acc 56.45 %\n",
      "Epoch:200/200 AVG Training Loss:0.656 AVG Validation Loss:0.690 AVG Training Acc 61.10 % AVG Validation Acc 56.59 %\n",
      "Split 117\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b4d829f01244deb9fac9127529c770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.544 AVG Validation Loss:2.940 AVG Training Acc 80.62 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.654 AVG Validation Loss:6.038 AVG Training Acc 74.57 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.628 AVG Validation Loss:1.660 AVG Training Acc 68.34 % AVG Validation Acc 20.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.634 AVG Validation Loss:1.583 AVG Training Acc 66.75 % AVG Validation Acc 20.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.642 AVG Validation Loss:1.630 AVG Training Acc 66.56 % AVG Validation Acc 20.05 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.684 AVG Validation Loss:0.768 AVG Training Acc 55.43 % AVG Validation Acc 23.28 %\n",
      "Epoch:70/200 AVG Training Loss:0.678 AVG Validation Loss:0.767 AVG Training Acc 57.79 % AVG Validation Acc 29.74 %\n",
      "Epoch:80/200 AVG Training Loss:0.676 AVG Validation Loss:0.769 AVG Training Acc 57.43 % AVG Validation Acc 34.45 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.670 AVG Validation Loss:0.718 AVG Training Acc 58.50 % AVG Validation Acc 51.14 %\n",
      "Epoch:100/200 AVG Training Loss:0.665 AVG Validation Loss:0.693 AVG Training Acc 59.07 % AVG Validation Acc 56.66 %\n",
      "Epoch:110/200 AVG Training Loss:0.665 AVG Validation Loss:0.685 AVG Training Acc 59.60 % AVG Validation Acc 58.68 %\n",
      "Epoch:120/200 AVG Training Loss:0.665 AVG Validation Loss:0.683 AVG Training Acc 59.62 % AVG Validation Acc 59.62 %\n",
      "Epoch:130/200 AVG Training Loss:0.666 AVG Validation Loss:0.682 AVG Training Acc 59.83 % AVG Validation Acc 59.62 %\n",
      "Epoch:140/200 AVG Training Loss:0.664 AVG Validation Loss:0.681 AVG Training Acc 59.67 % AVG Validation Acc 59.76 %\n",
      "Epoch   142: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.665 AVG Validation Loss:0.680 AVG Training Acc 59.52 % AVG Validation Acc 59.62 %\n",
      "Epoch:160/200 AVG Training Loss:0.663 AVG Validation Loss:0.679 AVG Training Acc 59.85 % AVG Validation Acc 59.49 %\n",
      "Epoch:170/200 AVG Training Loss:0.664 AVG Validation Loss:0.678 AVG Training Acc 59.86 % AVG Validation Acc 60.16 %\n",
      "Epoch:180/200 AVG Training Loss:0.662 AVG Validation Loss:0.677 AVG Training Acc 60.25 % AVG Validation Acc 60.16 %\n",
      "Epoch:190/200 AVG Training Loss:0.666 AVG Validation Loss:0.676 AVG Training Acc 59.93 % AVG Validation Acc 60.30 %\n",
      "Epoch:200/200 AVG Training Loss:0.662 AVG Validation Loss:0.676 AVG Training Acc 60.22 % AVG Validation Acc 60.16 %\n",
      "Split 118\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50c785e854514fb4bbba97d77598fc56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.435 AVG Validation Loss:5.768 AVG Training Acc 84.44 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.648 AVG Validation Loss:4.066 AVG Training Acc 64.83 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.656 AVG Validation Loss:1.751 AVG Training Acc 78.09 % AVG Validation Acc 20.05 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.689 AVG Validation Loss:0.757 AVG Training Acc 54.51 % AVG Validation Acc 26.11 %\n",
      "Epoch:50/200 AVG Training Loss:0.678 AVG Validation Loss:0.769 AVG Training Acc 57.35 % AVG Validation Acc 33.51 %\n",
      "Epoch:60/200 AVG Training Loss:0.675 AVG Validation Loss:0.759 AVG Training Acc 58.72 % AVG Validation Acc 38.76 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.671 AVG Validation Loss:0.705 AVG Training Acc 59.17 % AVG Validation Acc 56.12 %\n",
      "Epoch:80/200 AVG Training Loss:0.667 AVG Validation Loss:0.682 AVG Training Acc 59.21 % AVG Validation Acc 61.78 %\n",
      "Epoch:90/200 AVG Training Loss:0.666 AVG Validation Loss:0.675 AVG Training Acc 59.78 % AVG Validation Acc 62.72 %\n",
      "Epoch:100/200 AVG Training Loss:0.665 AVG Validation Loss:0.672 AVG Training Acc 60.04 % AVG Validation Acc 62.72 %\n",
      "Epoch:110/200 AVG Training Loss:0.664 AVG Validation Loss:0.670 AVG Training Acc 60.21 % AVG Validation Acc 62.99 %\n",
      "Epoch:120/200 AVG Training Loss:0.664 AVG Validation Loss:0.670 AVG Training Acc 60.66 % AVG Validation Acc 62.99 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.663 AVG Validation Loss:0.670 AVG Training Acc 60.82 % AVG Validation Acc 62.99 %\n",
      "Epoch:140/200 AVG Training Loss:0.665 AVG Validation Loss:0.669 AVG Training Acc 59.93 % AVG Validation Acc 62.72 %\n",
      "Epoch:150/200 AVG Training Loss:0.663 AVG Validation Loss:0.668 AVG Training Acc 60.59 % AVG Validation Acc 62.85 %\n",
      "Epoch:160/200 AVG Training Loss:0.664 AVG Validation Loss:0.667 AVG Training Acc 60.48 % AVG Validation Acc 63.12 %\n",
      "Epoch:170/200 AVG Training Loss:0.665 AVG Validation Loss:0.666 AVG Training Acc 60.36 % AVG Validation Acc 63.12 %\n",
      "Epoch:180/200 AVG Training Loss:0.664 AVG Validation Loss:0.666 AVG Training Acc 60.64 % AVG Validation Acc 63.26 %\n",
      "Epoch:190/200 AVG Training Loss:0.663 AVG Validation Loss:0.665 AVG Training Acc 61.12 % AVG Validation Acc 63.26 %\n",
      "Epoch:200/200 AVG Training Loss:0.664 AVG Validation Loss:0.664 AVG Training Acc 60.68 % AVG Validation Acc 63.26 %\n",
      "Split 119\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02817a82fd154fd8abbbec00e5333076",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.585 AVG Validation Loss:2.523 AVG Training Acc 76.92 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.656 AVG Validation Loss:1.566 AVG Training Acc 65.02 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.668 AVG Validation Loss:2.615 AVG Training Acc 77.21 % AVG Validation Acc 20.05 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.696 AVG Validation Loss:0.760 AVG Training Acc 50.07 % AVG Validation Acc 22.75 %\n",
      "Epoch:50/200 AVG Training Loss:0.692 AVG Validation Loss:0.757 AVG Training Acc 52.09 % AVG Validation Acc 26.24 %\n",
      "Epoch:60/200 AVG Training Loss:0.686 AVG Validation Loss:0.765 AVG Training Acc 54.99 % AVG Validation Acc 26.92 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.679 AVG Validation Loss:0.722 AVG Training Acc 55.88 % AVG Validation Acc 43.20 %\n",
      "Epoch:80/200 AVG Training Loss:0.675 AVG Validation Loss:0.698 AVG Training Acc 57.77 % AVG Validation Acc 54.37 %\n",
      "Epoch:90/200 AVG Training Loss:0.670 AVG Validation Loss:0.688 AVG Training Acc 58.87 % AVG Validation Acc 56.53 %\n",
      "Epoch:100/200 AVG Training Loss:0.670 AVG Validation Loss:0.686 AVG Training Acc 59.22 % AVG Validation Acc 56.93 %\n",
      "Epoch:110/200 AVG Training Loss:0.669 AVG Validation Loss:0.684 AVG Training Acc 59.61 % AVG Validation Acc 57.20 %\n",
      "Epoch:120/200 AVG Training Loss:0.669 AVG Validation Loss:0.684 AVG Training Acc 59.64 % AVG Validation Acc 57.07 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.667 AVG Validation Loss:0.684 AVG Training Acc 60.04 % AVG Validation Acc 57.07 %\n",
      "Epoch:140/200 AVG Training Loss:0.667 AVG Validation Loss:0.683 AVG Training Acc 60.51 % AVG Validation Acc 57.20 %\n",
      "Epoch:150/200 AVG Training Loss:0.666 AVG Validation Loss:0.682 AVG Training Acc 59.41 % AVG Validation Acc 57.34 %\n",
      "Epoch:160/200 AVG Training Loss:0.668 AVG Validation Loss:0.681 AVG Training Acc 59.58 % AVG Validation Acc 57.34 %\n",
      "Epoch:170/200 AVG Training Loss:0.666 AVG Validation Loss:0.681 AVG Training Acc 59.80 % AVG Validation Acc 57.34 %\n",
      "Epoch:180/200 AVG Training Loss:0.667 AVG Validation Loss:0.680 AVG Training Acc 59.71 % AVG Validation Acc 57.60 %\n",
      "Epoch:190/200 AVG Training Loss:0.665 AVG Validation Loss:0.680 AVG Training Acc 60.39 % AVG Validation Acc 57.74 %\n",
      "Epoch:200/200 AVG Training Loss:0.666 AVG Validation Loss:0.679 AVG Training Acc 60.51 % AVG Validation Acc 57.87 %\n",
      "Split 120\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b5da9372444ee3bda7fa1c709ac86b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.557 AVG Validation Loss:6.438 AVG Training Acc 75.80 % AVG Validation Acc 20.19 %\n",
      "Epoch:20/200 AVG Training Loss:0.647 AVG Validation Loss:1.602 AVG Training Acc 66.13 % AVG Validation Acc 20.19 %\n",
      "Epoch:30/200 AVG Training Loss:0.658 AVG Validation Loss:1.546 AVG Training Acc 64.83 % AVG Validation Acc 20.32 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.700 AVG Validation Loss:0.770 AVG Training Acc 48.78 % AVG Validation Acc 20.86 %\n",
      "Epoch:50/200 AVG Training Loss:0.681 AVG Validation Loss:0.751 AVG Training Acc 56.43 % AVG Validation Acc 43.88 %\n",
      "Epoch:60/200 AVG Training Loss:0.676 AVG Validation Loss:0.752 AVG Training Acc 57.57 % AVG Validation Acc 46.57 %\n",
      "Epoch:70/200 AVG Training Loss:0.676 AVG Validation Loss:0.744 AVG Training Acc 57.73 % AVG Validation Acc 46.43 %\n",
      "Epoch    77: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.674 AVG Validation Loss:0.724 AVG Training Acc 58.04 % AVG Validation Acc 50.34 %\n",
      "Epoch:90/200 AVG Training Loss:0.670 AVG Validation Loss:0.688 AVG Training Acc 59.33 % AVG Validation Acc 59.08 %\n",
      "Epoch:100/200 AVG Training Loss:0.667 AVG Validation Loss:0.674 AVG Training Acc 60.19 % AVG Validation Acc 61.37 %\n",
      "Epoch:110/200 AVG Training Loss:0.667 AVG Validation Loss:0.668 AVG Training Acc 60.57 % AVG Validation Acc 61.10 %\n",
      "Epoch:120/200 AVG Training Loss:0.666 AVG Validation Loss:0.666 AVG Training Acc 60.40 % AVG Validation Acc 61.91 %\n",
      "Epoch:130/200 AVG Training Loss:0.666 AVG Validation Loss:0.665 AVG Training Acc 60.91 % AVG Validation Acc 61.91 %\n",
      "Epoch:140/200 AVG Training Loss:0.667 AVG Validation Loss:0.665 AVG Training Acc 60.29 % AVG Validation Acc 61.64 %\n",
      "Epoch   145: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.667 AVG Validation Loss:0.664 AVG Training Acc 60.92 % AVG Validation Acc 61.78 %\n",
      "Epoch:160/200 AVG Training Loss:0.666 AVG Validation Loss:0.664 AVG Training Acc 60.93 % AVG Validation Acc 61.78 %\n",
      "Epoch:170/200 AVG Training Loss:0.664 AVG Validation Loss:0.663 AVG Training Acc 60.73 % AVG Validation Acc 61.78 %\n",
      "Epoch:180/200 AVG Training Loss:0.665 AVG Validation Loss:0.663 AVG Training Acc 60.66 % AVG Validation Acc 62.05 %\n",
      "Epoch:190/200 AVG Training Loss:0.663 AVG Validation Loss:0.662 AVG Training Acc 61.05 % AVG Validation Acc 62.05 %\n",
      "Epoch:200/200 AVG Training Loss:0.664 AVG Validation Loss:0.661 AVG Training Acc 60.97 % AVG Validation Acc 62.18 %\n",
      "Split 121\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ce0f3dfaae843008d721df57a0a0b56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.526 AVG Validation Loss:4.897 AVG Training Acc 79.80 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.648 AVG Validation Loss:1.640 AVG Training Acc 66.08 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.677 AVG Validation Loss:1.604 AVG Training Acc 67.53 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.740 AVG Validation Loss:5.494 AVG Training Acc 70.21 % AVG Validation Acc 20.16 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.690 AVG Validation Loss:0.756 AVG Training Acc 53.56 % AVG Validation Acc 25.40 %\n",
      "Epoch:60/200 AVG Training Loss:0.681 AVG Validation Loss:0.757 AVG Training Acc 56.79 % AVG Validation Acc 29.97 %\n",
      "Epoch:70/200 AVG Training Loss:0.674 AVG Validation Loss:0.760 AVG Training Acc 58.01 % AVG Validation Acc 36.29 %\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.670 AVG Validation Loss:0.718 AVG Training Acc 58.61 % AVG Validation Acc 49.46 %\n",
      "Epoch:90/200 AVG Training Loss:0.666 AVG Validation Loss:0.688 AVG Training Acc 59.95 % AVG Validation Acc 59.27 %\n",
      "Epoch:100/200 AVG Training Loss:0.667 AVG Validation Loss:0.679 AVG Training Acc 59.89 % AVG Validation Acc 61.29 %\n",
      "Epoch:110/200 AVG Training Loss:0.664 AVG Validation Loss:0.675 AVG Training Acc 60.04 % AVG Validation Acc 61.96 %\n",
      "Epoch:120/200 AVG Training Loss:0.663 AVG Validation Loss:0.673 AVG Training Acc 60.44 % AVG Validation Acc 62.37 %\n",
      "Epoch:130/200 AVG Training Loss:0.664 AVG Validation Loss:0.673 AVG Training Acc 60.28 % AVG Validation Acc 61.83 %\n",
      "Epoch   135: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:140/200 AVG Training Loss:0.661 AVG Validation Loss:0.672 AVG Training Acc 60.84 % AVG Validation Acc 61.56 %\n",
      "Epoch:150/200 AVG Training Loss:0.662 AVG Validation Loss:0.671 AVG Training Acc 60.45 % AVG Validation Acc 62.10 %\n",
      "Epoch:160/200 AVG Training Loss:0.662 AVG Validation Loss:0.670 AVG Training Acc 60.60 % AVG Validation Acc 62.10 %\n",
      "Epoch:170/200 AVG Training Loss:0.662 AVG Validation Loss:0.669 AVG Training Acc 60.88 % AVG Validation Acc 62.37 %\n",
      "Epoch:180/200 AVG Training Loss:0.661 AVG Validation Loss:0.668 AVG Training Acc 60.38 % AVG Validation Acc 62.23 %\n",
      "Epoch:190/200 AVG Training Loss:0.663 AVG Validation Loss:0.667 AVG Training Acc 60.57 % AVG Validation Acc 62.50 %\n",
      "Epoch:200/200 AVG Training Loss:0.660 AVG Validation Loss:0.666 AVG Training Acc 60.89 % AVG Validation Acc 62.63 %\n",
      "Split 122\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10f40fb181e640b5ae82b5e179336b91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.521 AVG Validation Loss:4.890 AVG Training Acc 80.81 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.579 AVG Validation Loss:4.179 AVG Training Acc 78.15 % AVG Validation Acc 20.16 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:1.671 AVG Validation Loss:1.514 AVG Training Acc 49.93 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.684 AVG Validation Loss:0.809 AVG Training Acc 56.67 % AVG Validation Acc 21.91 %\n",
      "Epoch:50/200 AVG Training Loss:0.675 AVG Validation Loss:0.802 AVG Training Acc 57.97 % AVG Validation Acc 27.82 %\n",
      "Epoch:60/200 AVG Training Loss:0.675 AVG Validation Loss:0.802 AVG Training Acc 58.88 % AVG Validation Acc 32.53 %\n",
      "Epoch:70/200 AVG Training Loss:0.671 AVG Validation Loss:0.802 AVG Training Acc 58.70 % AVG Validation Acc 38.71 %\n",
      "Epoch:80/200 AVG Training Loss:0.670 AVG Validation Loss:0.793 AVG Training Acc 59.58 % AVG Validation Acc 41.67 %\n",
      "Epoch:90/200 AVG Training Loss:0.663 AVG Validation Loss:0.795 AVG Training Acc 60.84 % AVG Validation Acc 44.62 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.659 AVG Validation Loss:0.742 AVG Training Acc 60.73 % AVG Validation Acc 53.09 %\n",
      "Epoch:110/200 AVG Training Loss:0.655 AVG Validation Loss:0.703 AVG Training Acc 61.85 % AVG Validation Acc 57.53 %\n",
      "Epoch:120/200 AVG Training Loss:0.652 AVG Validation Loss:0.692 AVG Training Acc 62.16 % AVG Validation Acc 58.33 %\n",
      "Epoch:130/200 AVG Training Loss:0.655 AVG Validation Loss:0.688 AVG Training Acc 62.22 % AVG Validation Acc 58.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.652 AVG Validation Loss:0.686 AVG Training Acc 62.13 % AVG Validation Acc 58.60 %\n",
      "Epoch:150/200 AVG Training Loss:0.649 AVG Validation Loss:0.686 AVG Training Acc 62.82 % AVG Validation Acc 58.47 %\n",
      "Epoch   151: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:160/200 AVG Training Loss:0.650 AVG Validation Loss:0.685 AVG Training Acc 62.87 % AVG Validation Acc 58.33 %\n",
      "Epoch:170/200 AVG Training Loss:0.649 AVG Validation Loss:0.684 AVG Training Acc 62.71 % AVG Validation Acc 58.33 %\n",
      "Epoch:180/200 AVG Training Loss:0.647 AVG Validation Loss:0.683 AVG Training Acc 62.98 % AVG Validation Acc 58.60 %\n",
      "Epoch:190/200 AVG Training Loss:0.649 AVG Validation Loss:0.682 AVG Training Acc 62.64 % AVG Validation Acc 58.60 %\n",
      "Epoch:200/200 AVG Training Loss:0.650 AVG Validation Loss:0.681 AVG Training Acc 62.83 % AVG Validation Acc 58.74 %\n",
      "Split 123\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69f79342ddb6442f978a15eb079586a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.559 AVG Validation Loss:5.800 AVG Training Acc 75.23 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.519 AVG Validation Loss:6.287 AVG Training Acc 80.42 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.594 AVG Validation Loss:4.393 AVG Training Acc 75.75 % AVG Validation Acc 20.16 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.820 AVG Validation Loss:1.018 AVG Training Acc 50.16 % AVG Validation Acc 20.70 %\n",
      "Epoch:50/200 AVG Training Loss:0.679 AVG Validation Loss:0.773 AVG Training Acc 57.03 % AVG Validation Acc 34.14 %\n",
      "Epoch:60/200 AVG Training Loss:0.673 AVG Validation Loss:0.771 AVG Training Acc 59.15 % AVG Validation Acc 42.34 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.672 AVG Validation Loss:0.758 AVG Training Acc 59.07 % AVG Validation Acc 48.52 %\n",
      "Epoch:80/200 AVG Training Loss:0.664 AVG Validation Loss:0.711 AVG Training Acc 60.51 % AVG Validation Acc 55.24 %\n",
      "Epoch:90/200 AVG Training Loss:0.662 AVG Validation Loss:0.693 AVG Training Acc 61.12 % AVG Validation Acc 56.85 %\n",
      "Epoch:100/200 AVG Training Loss:0.661 AVG Validation Loss:0.687 AVG Training Acc 61.28 % AVG Validation Acc 56.99 %\n",
      "Epoch:110/200 AVG Training Loss:0.661 AVG Validation Loss:0.685 AVG Training Acc 61.47 % AVG Validation Acc 57.12 %\n",
      "Epoch:120/200 AVG Training Loss:0.660 AVG Validation Loss:0.684 AVG Training Acc 61.20 % AVG Validation Acc 56.85 %\n",
      "Epoch:130/200 AVG Training Loss:0.661 AVG Validation Loss:0.683 AVG Training Acc 61.33 % AVG Validation Acc 57.12 %\n",
      "Epoch:140/200 AVG Training Loss:0.660 AVG Validation Loss:0.682 AVG Training Acc 61.34 % AVG Validation Acc 56.99 %\n",
      "Epoch:150/200 AVG Training Loss:0.659 AVG Validation Loss:0.682 AVG Training Acc 61.46 % AVG Validation Acc 57.39 %\n",
      "Epoch   152: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:160/200 AVG Training Loss:0.659 AVG Validation Loss:0.682 AVG Training Acc 61.60 % AVG Validation Acc 57.39 %\n",
      "Epoch:170/200 AVG Training Loss:0.659 AVG Validation Loss:0.681 AVG Training Acc 61.67 % AVG Validation Acc 57.26 %\n",
      "Epoch:180/200 AVG Training Loss:0.659 AVG Validation Loss:0.680 AVG Training Acc 61.55 % AVG Validation Acc 57.53 %\n",
      "Epoch:190/200 AVG Training Loss:0.660 AVG Validation Loss:0.680 AVG Training Acc 61.77 % AVG Validation Acc 57.39 %\n",
      "Epoch:200/200 AVG Training Loss:0.657 AVG Validation Loss:0.679 AVG Training Acc 61.41 % AVG Validation Acc 57.26 %\n",
      "Split 124\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa3e298d3deb482cb6fac447ad9a47f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.470 AVG Validation Loss:6.280 AVG Training Acc 82.02 % AVG Validation Acc 20.97 %\n",
      "Epoch:20/200 AVG Training Loss:0.587 AVG Validation Loss:2.261 AVG Training Acc 73.53 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.495 AVG Validation Loss:7.233 AVG Training Acc 83.15 % AVG Validation Acc 20.16 %\n",
      "Epoch    34: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.609 AVG Validation Loss:1.525 AVG Training Acc 70.24 % AVG Validation Acc 20.56 %\n",
      "Epoch:50/200 AVG Training Loss:0.671 AVG Validation Loss:1.077 AVG Training Acc 61.97 % AVG Validation Acc 21.91 %\n",
      "Epoch:60/200 AVG Training Loss:0.662 AVG Validation Loss:1.023 AVG Training Acc 61.57 % AVG Validation Acc 22.58 %\n",
      "Epoch:70/200 AVG Training Loss:0.661 AVG Validation Loss:1.010 AVG Training Acc 61.65 % AVG Validation Acc 21.91 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.719 AVG Validation Loss:0.878 AVG Training Acc 52.54 % AVG Validation Acc 24.73 %\n",
      "Epoch:90/200 AVG Training Loss:0.665 AVG Validation Loss:0.723 AVG Training Acc 59.94 % AVG Validation Acc 49.87 %\n",
      "Epoch:100/200 AVG Training Loss:0.662 AVG Validation Loss:0.716 AVG Training Acc 60.50 % AVG Validation Acc 50.94 %\n",
      "Epoch:110/200 AVG Training Loss:0.662 AVG Validation Loss:0.713 AVG Training Acc 60.72 % AVG Validation Acc 51.08 %\n",
      "Epoch:120/200 AVG Training Loss:0.661 AVG Validation Loss:0.716 AVG Training Acc 60.89 % AVG Validation Acc 52.02 %\n",
      "Epoch:130/200 AVG Training Loss:0.659 AVG Validation Loss:0.713 AVG Training Acc 61.34 % AVG Validation Acc 52.42 %\n",
      "Epoch   130: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:140/200 AVG Training Loss:0.656 AVG Validation Loss:0.703 AVG Training Acc 61.38 % AVG Validation Acc 53.09 %\n",
      "Epoch:150/200 AVG Training Loss:0.655 AVG Validation Loss:0.700 AVG Training Acc 61.71 % AVG Validation Acc 53.36 %\n",
      "Epoch:160/200 AVG Training Loss:0.655 AVG Validation Loss:0.693 AVG Training Acc 61.36 % AVG Validation Acc 54.30 %\n",
      "Epoch:170/200 AVG Training Loss:0.656 AVG Validation Loss:0.692 AVG Training Acc 61.67 % AVG Validation Acc 54.97 %\n",
      "Epoch:180/200 AVG Training Loss:0.654 AVG Validation Loss:0.690 AVG Training Acc 61.93 % AVG Validation Acc 55.24 %\n",
      "Epoch:190/200 AVG Training Loss:0.655 AVG Validation Loss:0.687 AVG Training Acc 61.24 % AVG Validation Acc 55.11 %\n",
      "Epoch:200/200 AVG Training Loss:0.655 AVG Validation Loss:0.690 AVG Training Acc 61.70 % AVG Validation Acc 54.84 %\n",
      "Split 125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd6b70b26bb473db486f559183e3b4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.500 AVG Validation Loss:4.546 AVG Training Acc 82.14 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.567 AVG Validation Loss:2.960 AVG Training Acc 79.92 % AVG Validation Acc 20.16 %\n",
      "Epoch    27: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.665 AVG Validation Loss:1.624 AVG Training Acc 69.65 % AVG Validation Acc 22.72 %\n",
      "Epoch:40/200 AVG Training Loss:0.683 AVG Validation Loss:0.997 AVG Training Acc 58.30 % AVG Validation Acc 20.56 %\n",
      "Epoch:50/200 AVG Training Loss:0.602 AVG Validation Loss:1.319 AVG Training Acc 70.07 % AVG Validation Acc 20.70 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.780 AVG Validation Loss:0.961 AVG Training Acc 51.11 % AVG Validation Acc 24.73 %\n",
      "Epoch:70/200 AVG Training Loss:0.682 AVG Validation Loss:0.724 AVG Training Acc 57.05 % AVG Validation Acc 41.53 %\n",
      "Epoch:80/200 AVG Training Loss:0.677 AVG Validation Loss:0.719 AVG Training Acc 57.46 % AVG Validation Acc 44.62 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.673 AVG Validation Loss:0.720 AVG Training Acc 57.57 % AVG Validation Acc 44.62 %\n",
      "Epoch:100/200 AVG Training Loss:0.669 AVG Validation Loss:0.698 AVG Training Acc 58.32 % AVG Validation Acc 50.00 %\n",
      "Epoch:110/200 AVG Training Loss:0.670 AVG Validation Loss:0.686 AVG Training Acc 58.73 % AVG Validation Acc 51.88 %\n",
      "Epoch:120/200 AVG Training Loss:0.668 AVG Validation Loss:0.679 AVG Training Acc 59.23 % AVG Validation Acc 53.23 %\n",
      "Epoch:130/200 AVG Training Loss:0.669 AVG Validation Loss:0.679 AVG Training Acc 58.79 % AVG Validation Acc 53.90 %\n",
      "Epoch:140/200 AVG Training Loss:0.666 AVG Validation Loss:0.676 AVG Training Acc 59.24 % AVG Validation Acc 54.03 %\n",
      "Epoch:150/200 AVG Training Loss:0.667 AVG Validation Loss:0.676 AVG Training Acc 59.08 % AVG Validation Acc 54.44 %\n",
      "Epoch:160/200 AVG Training Loss:0.667 AVG Validation Loss:0.678 AVG Training Acc 59.38 % AVG Validation Acc 54.30 %\n",
      "Epoch   163: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:170/200 AVG Training Loss:0.666 AVG Validation Loss:0.678 AVG Training Acc 59.55 % AVG Validation Acc 54.97 %\n",
      "Epoch:180/200 AVG Training Loss:0.666 AVG Validation Loss:0.676 AVG Training Acc 59.22 % AVG Validation Acc 55.24 %\n",
      "Epoch:190/200 AVG Training Loss:0.667 AVG Validation Loss:0.676 AVG Training Acc 59.09 % AVG Validation Acc 55.78 %\n",
      "Epoch   194: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:200/200 AVG Training Loss:0.665 AVG Validation Loss:0.676 AVG Training Acc 59.33 % AVG Validation Acc 55.11 %\n",
      "Split 126\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce6de867f7464c22ad964c75e1838821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.552 AVG Validation Loss:4.418 AVG Training Acc 77.65 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.596 AVG Validation Loss:1.887 AVG Training Acc 72.18 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.529 AVG Validation Loss:5.655 AVG Training Acc 82.34 % AVG Validation Acc 20.16 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.756 AVG Validation Loss:0.901 AVG Training Acc 48.50 % AVG Validation Acc 20.30 %\n",
      "Epoch:50/200 AVG Training Loss:0.667 AVG Validation Loss:1.205 AVG Training Acc 55.96 % AVG Validation Acc 20.70 %\n",
      "Epoch:60/200 AVG Training Loss:0.673 AVG Validation Loss:0.870 AVG Training Acc 58.78 % AVG Validation Acc 26.61 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.698 AVG Validation Loss:0.813 AVG Training Acc 54.40 % AVG Validation Acc 34.27 %\n",
      "Epoch:80/200 AVG Training Loss:0.666 AVG Validation Loss:0.699 AVG Training Acc 60.05 % AVG Validation Acc 53.23 %\n",
      "Epoch:90/200 AVG Training Loss:0.664 AVG Validation Loss:0.684 AVG Training Acc 60.90 % AVG Validation Acc 55.11 %\n",
      "Epoch:100/200 AVG Training Loss:0.665 AVG Validation Loss:0.685 AVG Training Acc 60.87 % AVG Validation Acc 54.97 %\n",
      "Epoch:110/200 AVG Training Loss:0.663 AVG Validation Loss:0.682 AVG Training Acc 60.87 % AVG Validation Acc 55.38 %\n",
      "Epoch:120/200 AVG Training Loss:0.661 AVG Validation Loss:0.679 AVG Training Acc 61.23 % AVG Validation Acc 55.51 %\n",
      "Epoch   120: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.660 AVG Validation Loss:0.677 AVG Training Acc 61.25 % AVG Validation Acc 55.65 %\n",
      "Epoch:140/200 AVG Training Loss:0.661 AVG Validation Loss:0.675 AVG Training Acc 61.26 % AVG Validation Acc 55.51 %\n",
      "Epoch:150/200 AVG Training Loss:0.660 AVG Validation Loss:0.673 AVG Training Acc 60.90 % AVG Validation Acc 56.18 %\n",
      "Epoch:160/200 AVG Training Loss:0.661 AVG Validation Loss:0.671 AVG Training Acc 61.36 % AVG Validation Acc 56.32 %\n",
      "Epoch:170/200 AVG Training Loss:0.660 AVG Validation Loss:0.670 AVG Training Acc 61.33 % AVG Validation Acc 56.32 %\n",
      "Epoch   173: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:180/200 AVG Training Loss:0.660 AVG Validation Loss:0.669 AVG Training Acc 61.40 % AVG Validation Acc 56.72 %\n",
      "Epoch:190/200 AVG Training Loss:0.661 AVG Validation Loss:0.669 AVG Training Acc 60.97 % AVG Validation Acc 56.45 %\n",
      "Epoch:200/200 AVG Training Loss:0.660 AVG Validation Loss:0.668 AVG Training Acc 61.06 % AVG Validation Acc 56.99 %\n",
      "Split 127\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e0fbf3bb5304d85a49e1554b043ecc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.515 AVG Validation Loss:6.266 AVG Training Acc 81.16 % AVG Validation Acc 20.05 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.733 AVG Validation Loss:1.496 AVG Training Acc 61.80 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.603 AVG Validation Loss:1.414 AVG Training Acc 69.33 % AVG Validation Acc 19.92 %\n",
      "Epoch:40/200 AVG Training Loss:0.630 AVG Validation Loss:1.377 AVG Training Acc 66.39 % AVG Validation Acc 20.05 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:50/200 AVG Training Loss:0.771 AVG Validation Loss:0.942 AVG Training Acc 52.09 % AVG Validation Acc 24.09 %\n",
      "Epoch:60/200 AVG Training Loss:0.671 AVG Validation Loss:0.721 AVG Training Acc 59.54 % AVG Validation Acc 48.72 %\n",
      "Epoch:70/200 AVG Training Loss:0.671 AVG Validation Loss:0.718 AVG Training Acc 59.45 % AVG Validation Acc 49.80 %\n",
      "Epoch:80/200 AVG Training Loss:0.669 AVG Validation Loss:0.719 AVG Training Acc 59.29 % AVG Validation Acc 51.14 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:90/200 AVG Training Loss:0.667 AVG Validation Loss:0.700 AVG Training Acc 60.19 % AVG Validation Acc 54.78 %\n",
      "Epoch:100/200 AVG Training Loss:0.663 AVG Validation Loss:0.688 AVG Training Acc 60.65 % AVG Validation Acc 57.34 %\n",
      "Epoch:110/200 AVG Training Loss:0.665 AVG Validation Loss:0.682 AVG Training Acc 60.94 % AVG Validation Acc 58.95 %\n",
      "Epoch:120/200 AVG Training Loss:0.664 AVG Validation Loss:0.679 AVG Training Acc 60.19 % AVG Validation Acc 59.49 %\n",
      "Epoch:130/200 AVG Training Loss:0.664 AVG Validation Loss:0.676 AVG Training Acc 60.93 % AVG Validation Acc 59.35 %\n",
      "Epoch:140/200 AVG Training Loss:0.663 AVG Validation Loss:0.677 AVG Training Acc 60.91 % AVG Validation Acc 60.70 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:150/200 AVG Training Loss:0.666 AVG Validation Loss:0.675 AVG Training Acc 61.05 % AVG Validation Acc 59.62 %\n",
      "Epoch:160/200 AVG Training Loss:0.664 AVG Validation Loss:0.678 AVG Training Acc 60.40 % AVG Validation Acc 60.57 %\n",
      "Epoch:170/200 AVG Training Loss:0.663 AVG Validation Loss:0.675 AVG Training Acc 60.97 % AVG Validation Acc 60.30 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:180/200 AVG Training Loss:0.662 AVG Validation Loss:0.674 AVG Training Acc 61.03 % AVG Validation Acc 62.72 %\n",
      "Epoch:190/200 AVG Training Loss:0.661 AVG Validation Loss:0.671 AVG Training Acc 60.78 % AVG Validation Acc 60.70 %\n",
      "Epoch:200/200 AVG Training Loss:0.664 AVG Validation Loss:0.675 AVG Training Acc 60.89 % AVG Validation Acc 60.16 %\n",
      "Split 128\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e69c249f8de4015b8cd11c1277dba4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.539 AVG Validation Loss:4.687 AVG Training Acc 79.00 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.639 AVG Validation Loss:1.643 AVG Training Acc 67.00 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.491 AVG Validation Loss:5.193 AVG Training Acc 78.21 % AVG Validation Acc 20.05 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.685 AVG Validation Loss:1.153 AVG Training Acc 58.42 % AVG Validation Acc 20.32 %\n",
      "Epoch:50/200 AVG Training Loss:0.670 AVG Validation Loss:1.169 AVG Training Acc 59.96 % AVG Validation Acc 20.32 %\n",
      "Epoch:60/200 AVG Training Loss:0.678 AVG Validation Loss:0.969 AVG Training Acc 58.34 % AVG Validation Acc 21.80 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.672 AVG Validation Loss:0.729 AVG Training Acc 58.33 % AVG Validation Acc 42.40 %\n",
      "Epoch:80/200 AVG Training Loss:0.670 AVG Validation Loss:0.704 AVG Training Acc 59.34 % AVG Validation Acc 52.09 %\n",
      "Epoch:90/200 AVG Training Loss:0.666 AVG Validation Loss:0.700 AVG Training Acc 60.44 % AVG Validation Acc 54.10 %\n",
      "Epoch:100/200 AVG Training Loss:0.666 AVG Validation Loss:0.700 AVG Training Acc 60.59 % AVG Validation Acc 54.37 %\n",
      "Epoch   103: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.663 AVG Validation Loss:0.692 AVG Training Acc 60.75 % AVG Validation Acc 55.99 %\n",
      "Epoch:120/200 AVG Training Loss:0.661 AVG Validation Loss:0.683 AVG Training Acc 60.95 % AVG Validation Acc 56.80 %\n",
      "Epoch:130/200 AVG Training Loss:0.662 AVG Validation Loss:0.677 AVG Training Acc 60.79 % AVG Validation Acc 57.34 %\n",
      "Epoch:140/200 AVG Training Loss:0.660 AVG Validation Loss:0.676 AVG Training Acc 61.23 % AVG Validation Acc 58.95 %\n",
      "Epoch:150/200 AVG Training Loss:0.661 AVG Validation Loss:0.674 AVG Training Acc 60.80 % AVG Validation Acc 57.60 %\n",
      "Epoch:160/200 AVG Training Loss:0.661 AVG Validation Loss:0.672 AVG Training Acc 60.86 % AVG Validation Acc 58.82 %\n",
      "Epoch:170/200 AVG Training Loss:0.661 AVG Validation Loss:0.671 AVG Training Acc 61.15 % AVG Validation Acc 59.35 %\n",
      "Epoch:180/200 AVG Training Loss:0.661 AVG Validation Loss:0.670 AVG Training Acc 60.83 % AVG Validation Acc 59.08 %\n",
      "Epoch:190/200 AVG Training Loss:0.660 AVG Validation Loss:0.671 AVG Training Acc 61.11 % AVG Validation Acc 59.35 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:200/200 AVG Training Loss:0.662 AVG Validation Loss:0.670 AVG Training Acc 60.87 % AVG Validation Acc 59.08 %\n",
      "Split 129\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bba841b0386d4b3d91beb82d254120fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.518 AVG Validation Loss:3.770 AVG Training Acc 77.02 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.480 AVG Validation Loss:3.793 AVG Training Acc 80.58 % AVG Validation Acc 20.05 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.690 AVG Validation Loss:0.941 AVG Training Acc 56.27 % AVG Validation Acc 21.27 %\n",
      "Epoch:40/200 AVG Training Loss:0.679 AVG Validation Loss:0.936 AVG Training Acc 58.07 % AVG Validation Acc 21.80 %\n",
      "Epoch:50/200 AVG Training Loss:0.681 AVG Validation Loss:0.903 AVG Training Acc 58.26 % AVG Validation Acc 23.82 %\n",
      "Epoch:60/200 AVG Training Loss:0.683 AVG Validation Loss:0.796 AVG Training Acc 56.62 % AVG Validation Acc 33.65 %\n",
      "Epoch:70/200 AVG Training Loss:0.678 AVG Validation Loss:0.793 AVG Training Acc 57.56 % AVG Validation Acc 37.15 %\n",
      "Epoch:80/200 AVG Training Loss:0.664 AVG Validation Loss:0.853 AVG Training Acc 60.83 % AVG Validation Acc 31.90 %\n",
      "Epoch:90/200 AVG Training Loss:0.677 AVG Validation Loss:0.756 AVG Training Acc 57.46 % AVG Validation Acc 43.74 %\n",
      "Epoch:100/200 AVG Training Loss:0.633 AVG Validation Loss:0.934 AVG Training Acc 65.32 % AVG Validation Acc 25.57 %\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:110/200 AVG Training Loss:0.669 AVG Validation Loss:0.711 AVG Training Acc 59.37 % AVG Validation Acc 51.14 %\n",
      "Epoch:120/200 AVG Training Loss:0.661 AVG Validation Loss:0.686 AVG Training Acc 60.28 % AVG Validation Acc 54.91 %\n",
      "Epoch:130/200 AVG Training Loss:0.661 AVG Validation Loss:0.680 AVG Training Acc 60.50 % AVG Validation Acc 58.95 %\n",
      "Epoch:140/200 AVG Training Loss:0.658 AVG Validation Loss:0.677 AVG Training Acc 60.65 % AVG Validation Acc 58.82 %\n",
      "Epoch:150/200 AVG Training Loss:0.656 AVG Validation Loss:0.670 AVG Training Acc 61.12 % AVG Validation Acc 60.43 %\n",
      "Epoch:160/200 AVG Training Loss:0.655 AVG Validation Loss:0.669 AVG Training Acc 61.18 % AVG Validation Acc 60.43 %\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:170/200 AVG Training Loss:0.653 AVG Validation Loss:0.667 AVG Training Acc 61.57 % AVG Validation Acc 60.03 %\n",
      "Epoch:180/200 AVG Training Loss:0.652 AVG Validation Loss:0.665 AVG Training Acc 61.58 % AVG Validation Acc 61.24 %\n",
      "Epoch:190/200 AVG Training Loss:0.653 AVG Validation Loss:0.663 AVG Training Acc 61.43 % AVG Validation Acc 61.64 %\n",
      "Epoch:200/200 AVG Training Loss:0.652 AVG Validation Loss:0.663 AVG Training Acc 61.66 % AVG Validation Acc 61.51 %\n",
      "Split 130\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ca47ca792db47128b2c2acc584918c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.549 AVG Validation Loss:3.210 AVG Training Acc 80.64 % AVG Validation Acc 20.19 %\n",
      "Epoch:20/200 AVG Training Loss:0.618 AVG Validation Loss:6.348 AVG Training Acc 66.34 % AVG Validation Acc 20.19 %\n",
      "Epoch:30/200 AVG Training Loss:0.626 AVG Validation Loss:3.351 AVG Training Acc 66.58 % AVG Validation Acc 20.19 %\n",
      "Epoch:40/200 AVG Training Loss:0.539 AVG Validation Loss:13.213 AVG Training Acc 69.08 % AVG Validation Acc 20.19 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.619 AVG Validation Loss:1.169 AVG Training Acc 68.77 % AVG Validation Acc 21.27 %\n",
      "Epoch:60/200 AVG Training Loss:0.686 AVG Validation Loss:0.907 AVG Training Acc 57.82 % AVG Validation Acc 21.67 %\n",
      "Epoch:70/200 AVG Training Loss:0.662 AVG Validation Loss:0.932 AVG Training Acc 60.79 % AVG Validation Acc 22.21 %\n",
      "Epoch    75: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.670 AVG Validation Loss:0.755 AVG Training Acc 57.91 % AVG Validation Acc 38.76 %\n",
      "Epoch:90/200 AVG Training Loss:0.652 AVG Validation Loss:0.695 AVG Training Acc 60.91 % AVG Validation Acc 51.95 %\n",
      "Epoch:100/200 AVG Training Loss:0.650 AVG Validation Loss:0.695 AVG Training Acc 60.78 % AVG Validation Acc 52.09 %\n",
      "Epoch:110/200 AVG Training Loss:0.649 AVG Validation Loss:0.694 AVG Training Acc 61.37 % AVG Validation Acc 50.87 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.645 AVG Validation Loss:0.693 AVG Training Acc 61.68 % AVG Validation Acc 51.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.643 AVG Validation Loss:0.687 AVG Training Acc 62.03 % AVG Validation Acc 52.22 %\n",
      "Epoch:140/200 AVG Training Loss:0.642 AVG Validation Loss:0.684 AVG Training Acc 61.92 % AVG Validation Acc 53.57 %\n",
      "Epoch:150/200 AVG Training Loss:0.643 AVG Validation Loss:0.680 AVG Training Acc 61.71 % AVG Validation Acc 53.70 %\n",
      "Epoch:160/200 AVG Training Loss:0.643 AVG Validation Loss:0.681 AVG Training Acc 61.67 % AVG Validation Acc 53.70 %\n",
      "Epoch:170/200 AVG Training Loss:0.642 AVG Validation Loss:0.678 AVG Training Acc 61.81 % AVG Validation Acc 54.10 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:180/200 AVG Training Loss:0.641 AVG Validation Loss:0.678 AVG Training Acc 61.78 % AVG Validation Acc 54.10 %\n",
      "Epoch:190/200 AVG Training Loss:0.642 AVG Validation Loss:0.679 AVG Training Acc 62.48 % AVG Validation Acc 54.37 %\n",
      "Epoch:200/200 AVG Training Loss:0.643 AVG Validation Loss:0.679 AVG Training Acc 62.16 % AVG Validation Acc 53.70 %\n",
      "Split 131\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9956d5998245490fb83d816a8228d736",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.527 AVG Validation Loss:4.228 AVG Training Acc 80.41 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.532 AVG Validation Loss:4.795 AVG Training Acc 77.32 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.445 AVG Validation Loss:5.985 AVG Training Acc 81.43 % AVG Validation Acc 20.30 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.704 AVG Validation Loss:0.767 AVG Training Acc 47.27 % AVG Validation Acc 20.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.698 AVG Validation Loss:0.759 AVG Training Acc 49.78 % AVG Validation Acc 20.70 %\n",
      "Epoch:60/200 AVG Training Loss:0.685 AVG Validation Loss:0.770 AVG Training Acc 55.94 % AVG Validation Acc 28.49 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.681 AVG Validation Loss:0.752 AVG Training Acc 56.61 % AVG Validation Acc 43.41 %\n",
      "Epoch:80/200 AVG Training Loss:0.674 AVG Validation Loss:0.708 AVG Training Acc 58.35 % AVG Validation Acc 55.78 %\n",
      "Epoch:90/200 AVG Training Loss:0.672 AVG Validation Loss:0.693 AVG Training Acc 58.26 % AVG Validation Acc 57.66 %\n",
      "Epoch:100/200 AVG Training Loss:0.671 AVG Validation Loss:0.688 AVG Training Acc 58.83 % AVG Validation Acc 58.33 %\n",
      "Epoch:110/200 AVG Training Loss:0.671 AVG Validation Loss:0.685 AVG Training Acc 59.08 % AVG Validation Acc 58.47 %\n",
      "Epoch:120/200 AVG Training Loss:0.669 AVG Validation Loss:0.685 AVG Training Acc 59.22 % AVG Validation Acc 58.74 %\n",
      "Epoch   125: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.668 AVG Validation Loss:0.684 AVG Training Acc 59.67 % AVG Validation Acc 58.74 %\n",
      "Epoch:140/200 AVG Training Loss:0.668 AVG Validation Loss:0.683 AVG Training Acc 59.53 % AVG Validation Acc 58.87 %\n",
      "Epoch:150/200 AVG Training Loss:0.670 AVG Validation Loss:0.683 AVG Training Acc 59.24 % AVG Validation Acc 58.87 %\n",
      "Epoch:160/200 AVG Training Loss:0.668 AVG Validation Loss:0.682 AVG Training Acc 60.07 % AVG Validation Acc 58.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.668 AVG Validation Loss:0.681 AVG Training Acc 59.29 % AVG Validation Acc 59.01 %\n",
      "Epoch:180/200 AVG Training Loss:0.670 AVG Validation Loss:0.681 AVG Training Acc 59.15 % AVG Validation Acc 58.87 %\n",
      "Epoch:190/200 AVG Training Loss:0.668 AVG Validation Loss:0.680 AVG Training Acc 59.65 % AVG Validation Acc 59.01 %\n",
      "Epoch:200/200 AVG Training Loss:0.669 AVG Validation Loss:0.680 AVG Training Acc 59.81 % AVG Validation Acc 58.87 %\n",
      "Split 132\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66652ec40b164c06adb99b830c21ee17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.570 AVG Validation Loss:5.042 AVG Training Acc 76.64 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.530 AVG Validation Loss:4.227 AVG Training Acc 80.28 % AVG Validation Acc 20.16 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.675 AVG Validation Loss:0.967 AVG Training Acc 58.68 % AVG Validation Acc 21.64 %\n",
      "Epoch:40/200 AVG Training Loss:0.653 AVG Validation Loss:1.059 AVG Training Acc 64.06 % AVG Validation Acc 20.30 %\n",
      "Epoch:50/200 AVG Training Loss:0.612 AVG Validation Loss:1.564 AVG Training Acc 65.31 % AVG Validation Acc 22.04 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.692 AVG Validation Loss:0.748 AVG Training Acc 55.69 % AVG Validation Acc 41.40 %\n",
      "Epoch:70/200 AVG Training Loss:0.682 AVG Validation Loss:0.739 AVG Training Acc 57.53 % AVG Validation Acc 43.41 %\n",
      "Epoch:80/200 AVG Training Loss:0.678 AVG Validation Loss:0.734 AVG Training Acc 58.14 % AVG Validation Acc 45.56 %\n",
      "Epoch:90/200 AVG Training Loss:0.675 AVG Validation Loss:0.729 AVG Training Acc 58.62 % AVG Validation Acc 46.77 %\n",
      "Epoch:100/200 AVG Training Loss:0.674 AVG Validation Loss:0.722 AVG Training Acc 59.01 % AVG Validation Acc 48.92 %\n",
      "Epoch:110/200 AVG Training Loss:0.672 AVG Validation Loss:0.715 AVG Training Acc 59.12 % AVG Validation Acc 50.00 %\n",
      "Epoch:120/200 AVG Training Loss:0.668 AVG Validation Loss:0.713 AVG Training Acc 59.70 % AVG Validation Acc 50.54 %\n",
      "Epoch:130/200 AVG Training Loss:0.668 AVG Validation Loss:0.709 AVG Training Acc 59.51 % AVG Validation Acc 52.42 %\n",
      "Epoch:140/200 AVG Training Loss:0.668 AVG Validation Loss:0.712 AVG Training Acc 59.87 % AVG Validation Acc 52.55 %\n",
      "Epoch:150/200 AVG Training Loss:0.668 AVG Validation Loss:0.712 AVG Training Acc 59.62 % AVG Validation Acc 52.69 %\n",
      "Epoch:160/200 AVG Training Loss:0.668 AVG Validation Loss:0.709 AVG Training Acc 59.59 % AVG Validation Acc 52.69 %\n",
      "Epoch:170/200 AVG Training Loss:0.665 AVG Validation Loss:0.705 AVG Training Acc 60.00 % AVG Validation Acc 54.17 %\n",
      "Epoch:180/200 AVG Training Loss:0.664 AVG Validation Loss:0.707 AVG Training Acc 60.15 % AVG Validation Acc 53.36 %\n",
      "Epoch   182: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:190/200 AVG Training Loss:0.659 AVG Validation Loss:0.689 AVG Training Acc 60.80 % AVG Validation Acc 56.59 %\n",
      "Epoch:200/200 AVG Training Loss:0.657 AVG Validation Loss:0.678 AVG Training Acc 61.28 % AVG Validation Acc 58.47 %\n",
      "Split 133\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bb64f773c6e41e1b11380dcb8543773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.505 AVG Validation Loss:3.431 AVG Training Acc 79.79 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.519 AVG Validation Loss:3.387 AVG Training Acc 79.45 % AVG Validation Acc 20.43 %\n",
      "Epoch:30/200 AVG Training Loss:0.551 AVG Validation Loss:2.354 AVG Training Acc 74.81 % AVG Validation Acc 20.30 %\n",
      "Epoch:40/200 AVG Training Loss:0.499 AVG Validation Loss:3.304 AVG Training Acc 79.19 % AVG Validation Acc 20.70 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.693 AVG Validation Loss:0.871 AVG Training Acc 54.59 % AVG Validation Acc 25.81 %\n",
      "Epoch:60/200 AVG Training Loss:0.684 AVG Validation Loss:0.870 AVG Training Acc 56.60 % AVG Validation Acc 27.42 %\n",
      "Epoch:70/200 AVG Training Loss:0.618 AVG Validation Loss:1.258 AVG Training Acc 68.59 % AVG Validation Acc 24.73 %\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.704 AVG Validation Loss:0.783 AVG Training Acc 52.49 % AVG Validation Acc 35.35 %\n",
      "Epoch:90/200 AVG Training Loss:0.684 AVG Validation Loss:0.722 AVG Training Acc 55.71 % AVG Validation Acc 44.62 %\n",
      "Epoch:100/200 AVG Training Loss:0.683 AVG Validation Loss:0.706 AVG Training Acc 55.64 % AVG Validation Acc 47.18 %\n",
      "Epoch:110/200 AVG Training Loss:0.677 AVG Validation Loss:0.700 AVG Training Acc 56.73 % AVG Validation Acc 49.33 %\n",
      "Epoch:120/200 AVG Training Loss:0.675 AVG Validation Loss:0.701 AVG Training Acc 57.06 % AVG Validation Acc 49.06 %\n",
      "Epoch   127: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.673 AVG Validation Loss:0.699 AVG Training Acc 57.14 % AVG Validation Acc 50.54 %\n",
      "Epoch:140/200 AVG Training Loss:0.674 AVG Validation Loss:0.691 AVG Training Acc 57.58 % AVG Validation Acc 52.28 %\n",
      "Epoch:150/200 AVG Training Loss:0.671 AVG Validation Loss:0.685 AVG Training Acc 57.94 % AVG Validation Acc 54.44 %\n",
      "Epoch:160/200 AVG Training Loss:0.673 AVG Validation Loss:0.681 AVG Training Acc 57.73 % AVG Validation Acc 55.65 %\n",
      "Epoch:170/200 AVG Training Loss:0.670 AVG Validation Loss:0.680 AVG Training Acc 58.52 % AVG Validation Acc 56.32 %\n",
      "Epoch:180/200 AVG Training Loss:0.672 AVG Validation Loss:0.679 AVG Training Acc 57.45 % AVG Validation Acc 56.45 %\n",
      "Epoch   180: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:190/200 AVG Training Loss:0.673 AVG Validation Loss:0.681 AVG Training Acc 58.07 % AVG Validation Acc 55.51 %\n",
      "Epoch:200/200 AVG Training Loss:0.671 AVG Validation Loss:0.677 AVG Training Acc 57.55 % AVG Validation Acc 56.99 %\n",
      "Split 134\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcc7c7cf75534253aa6412f12bfee555",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.506 AVG Validation Loss:4.658 AVG Training Acc 81.86 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.642 AVG Validation Loss:3.165 AVG Training Acc 65.84 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.645 AVG Validation Loss:1.622 AVG Training Acc 66.96 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.655 AVG Validation Loss:1.592 AVG Training Acc 65.77 % AVG Validation Acc 20.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.633 AVG Validation Loss:1.710 AVG Training Acc 70.07 % AVG Validation Acc 20.16 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.698 AVG Validation Loss:0.761 AVG Training Acc 49.84 % AVG Validation Acc 21.64 %\n",
      "Epoch:70/200 AVG Training Loss:0.685 AVG Validation Loss:0.749 AVG Training Acc 55.36 % AVG Validation Acc 23.92 %\n",
      "Epoch:80/200 AVG Training Loss:0.675 AVG Validation Loss:0.756 AVG Training Acc 58.16 % AVG Validation Acc 38.17 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.672 AVG Validation Loss:0.722 AVG Training Acc 58.31 % AVG Validation Acc 49.33 %\n",
      "Epoch:100/200 AVG Training Loss:0.668 AVG Validation Loss:0.693 AVG Training Acc 59.50 % AVG Validation Acc 55.91 %\n",
      "Epoch:110/200 AVG Training Loss:0.668 AVG Validation Loss:0.681 AVG Training Acc 59.93 % AVG Validation Acc 57.66 %\n",
      "Epoch:120/200 AVG Training Loss:0.666 AVG Validation Loss:0.677 AVG Training Acc 59.51 % AVG Validation Acc 58.47 %\n",
      "Epoch:130/200 AVG Training Loss:0.667 AVG Validation Loss:0.676 AVG Training Acc 59.87 % AVG Validation Acc 58.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.665 AVG Validation Loss:0.675 AVG Training Acc 59.75 % AVG Validation Acc 59.01 %\n",
      "Epoch   144: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.666 AVG Validation Loss:0.675 AVG Training Acc 60.02 % AVG Validation Acc 58.87 %\n",
      "Epoch:160/200 AVG Training Loss:0.665 AVG Validation Loss:0.674 AVG Training Acc 60.05 % AVG Validation Acc 59.54 %\n",
      "Epoch:170/200 AVG Training Loss:0.665 AVG Validation Loss:0.673 AVG Training Acc 60.44 % AVG Validation Acc 59.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.666 AVG Validation Loss:0.673 AVG Training Acc 60.17 % AVG Validation Acc 59.68 %\n",
      "Epoch:190/200 AVG Training Loss:0.664 AVG Validation Loss:0.673 AVG Training Acc 60.02 % AVG Validation Acc 59.81 %\n",
      "Epoch:200/200 AVG Training Loss:0.664 AVG Validation Loss:0.672 AVG Training Acc 60.23 % AVG Validation Acc 59.81 %\n",
      "Split 135\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "43d657dbc1eb49f9b312b8295bab9374",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.548 AVG Validation Loss:6.458 AVG Training Acc 78.34 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.583 AVG Validation Loss:2.109 AVG Training Acc 76.71 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.537 AVG Validation Loss:5.624 AVG Training Acc 76.34 % AVG Validation Acc 20.16 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.690 AVG Validation Loss:1.005 AVG Training Acc 57.88 % AVG Validation Acc 20.56 %\n",
      "Epoch:50/200 AVG Training Loss:0.683 AVG Validation Loss:0.887 AVG Training Acc 57.14 % AVG Validation Acc 22.45 %\n",
      "Epoch:60/200 AVG Training Loss:0.680 AVG Validation Loss:0.853 AVG Training Acc 58.44 % AVG Validation Acc 23.92 %\n",
      "Epoch:70/200 AVG Training Loss:0.673 AVG Validation Loss:0.857 AVG Training Acc 58.97 % AVG Validation Acc 26.21 %\n",
      "Epoch:80/200 AVG Training Loss:0.664 AVG Validation Loss:0.847 AVG Training Acc 61.39 % AVG Validation Acc 27.15 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.670 AVG Validation Loss:0.750 AVG Training Acc 58.69 % AVG Validation Acc 44.76 %\n",
      "Epoch:100/200 AVG Training Loss:0.657 AVG Validation Loss:0.692 AVG Training Acc 61.24 % AVG Validation Acc 52.82 %\n",
      "Epoch:110/200 AVG Training Loss:0.654 AVG Validation Loss:0.683 AVG Training Acc 61.90 % AVG Validation Acc 55.65 %\n",
      "Epoch:120/200 AVG Training Loss:0.653 AVG Validation Loss:0.681 AVG Training Acc 62.74 % AVG Validation Acc 56.18 %\n",
      "Epoch:130/200 AVG Training Loss:0.653 AVG Validation Loss:0.680 AVG Training Acc 61.82 % AVG Validation Acc 56.32 %\n",
      "Epoch   134: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:140/200 AVG Training Loss:0.649 AVG Validation Loss:0.676 AVG Training Acc 62.61 % AVG Validation Acc 56.59 %\n",
      "Epoch:150/200 AVG Training Loss:0.650 AVG Validation Loss:0.674 AVG Training Acc 62.24 % AVG Validation Acc 57.12 %\n",
      "Epoch:160/200 AVG Training Loss:0.650 AVG Validation Loss:0.672 AVG Training Acc 62.09 % AVG Validation Acc 57.66 %\n",
      "Epoch:170/200 AVG Training Loss:0.649 AVG Validation Loss:0.669 AVG Training Acc 62.83 % AVG Validation Acc 58.47 %\n",
      "Epoch   178: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:180/200 AVG Training Loss:0.649 AVG Validation Loss:0.669 AVG Training Acc 62.88 % AVG Validation Acc 58.06 %\n",
      "Epoch:190/200 AVG Training Loss:0.648 AVG Validation Loss:0.669 AVG Training Acc 62.96 % AVG Validation Acc 58.47 %\n",
      "Epoch:200/200 AVG Training Loss:0.650 AVG Validation Loss:0.667 AVG Training Acc 62.66 % AVG Validation Acc 58.33 %\n",
      "Split 136\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "537c7772adf64941866fb762a8617095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.548 AVG Validation Loss:3.347 AVG Training Acc 79.44 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.487 AVG Validation Loss:3.972 AVG Training Acc 79.31 % AVG Validation Acc 20.16 %\n",
      "Epoch    23: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.693 AVG Validation Loss:1.018 AVG Training Acc 57.20 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.683 AVG Validation Loss:0.896 AVG Training Acc 57.36 % AVG Validation Acc 20.70 %\n",
      "Epoch:50/200 AVG Training Loss:0.674 AVG Validation Loss:0.995 AVG Training Acc 59.60 % AVG Validation Acc 21.77 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.682 AVG Validation Loss:0.748 AVG Training Acc 56.03 % AVG Validation Acc 42.07 %\n",
      "Epoch:70/200 AVG Training Loss:0.673 AVG Validation Loss:0.696 AVG Training Acc 58.79 % AVG Validation Acc 55.78 %\n",
      "Epoch:80/200 AVG Training Loss:0.669 AVG Validation Loss:0.692 AVG Training Acc 59.01 % AVG Validation Acc 56.85 %\n",
      "Epoch:90/200 AVG Training Loss:0.669 AVG Validation Loss:0.691 AVG Training Acc 59.18 % AVG Validation Acc 57.66 %\n",
      "Epoch:100/200 AVG Training Loss:0.669 AVG Validation Loss:0.694 AVG Training Acc 59.65 % AVG Validation Acc 57.26 %\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.665 AVG Validation Loss:0.683 AVG Training Acc 60.02 % AVG Validation Acc 59.27 %\n",
      "Epoch:120/200 AVG Training Loss:0.664 AVG Validation Loss:0.675 AVG Training Acc 60.57 % AVG Validation Acc 61.02 %\n",
      "Epoch:130/200 AVG Training Loss:0.663 AVG Validation Loss:0.670 AVG Training Acc 60.70 % AVG Validation Acc 62.77 %\n",
      "Epoch:140/200 AVG Training Loss:0.663 AVG Validation Loss:0.667 AVG Training Acc 60.22 % AVG Validation Acc 63.71 %\n",
      "Epoch:150/200 AVG Training Loss:0.663 AVG Validation Loss:0.667 AVG Training Acc 60.22 % AVG Validation Acc 62.50 %\n",
      "Epoch:160/200 AVG Training Loss:0.663 AVG Validation Loss:0.664 AVG Training Acc 60.61 % AVG Validation Acc 63.31 %\n",
      "Epoch:170/200 AVG Training Loss:0.661 AVG Validation Loss:0.665 AVG Training Acc 60.55 % AVG Validation Acc 63.58 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:180/200 AVG Training Loss:0.660 AVG Validation Loss:0.665 AVG Training Acc 60.81 % AVG Validation Acc 63.44 %\n",
      "Epoch:190/200 AVG Training Loss:0.660 AVG Validation Loss:0.665 AVG Training Acc 60.94 % AVG Validation Acc 63.17 %\n",
      "Epoch:200/200 AVG Training Loss:0.662 AVG Validation Loss:0.663 AVG Training Acc 60.39 % AVG Validation Acc 64.25 %\n",
      "Split 137\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c16baa7fa594c0f83a76358048392eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.455 AVG Validation Loss:4.990 AVG Training Acc 83.15 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.517 AVG Validation Loss:5.013 AVG Training Acc 80.51 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.648 AVG Validation Loss:1.647 AVG Training Acc 66.42 % AVG Validation Acc 20.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.647 AVG Validation Loss:1.567 AVG Training Acc 65.47 % AVG Validation Acc 20.32 %\n",
      "Epoch    44: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.680 AVG Validation Loss:1.426 AVG Training Acc 61.49 % AVG Validation Acc 20.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.667 AVG Validation Loss:1.217 AVG Training Acc 62.03 % AVG Validation Acc 20.73 %\n",
      "Epoch:70/200 AVG Training Loss:0.670 AVG Validation Loss:1.022 AVG Training Acc 60.84 % AVG Validation Acc 20.59 %\n",
      "Epoch:80/200 AVG Training Loss:0.673 AVG Validation Loss:0.984 AVG Training Acc 60.39 % AVG Validation Acc 20.59 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.677 AVG Validation Loss:0.735 AVG Training Acc 57.03 % AVG Validation Acc 44.82 %\n",
      "Epoch:100/200 AVG Training Loss:0.668 AVG Validation Loss:0.693 AVG Training Acc 59.99 % AVG Validation Acc 55.72 %\n",
      "Epoch:110/200 AVG Training Loss:0.665 AVG Validation Loss:0.694 AVG Training Acc 60.53 % AVG Validation Acc 55.45 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.663 AVG Validation Loss:0.688 AVG Training Acc 60.37 % AVG Validation Acc 56.80 %\n",
      "Epoch:130/200 AVG Training Loss:0.662 AVG Validation Loss:0.680 AVG Training Acc 60.26 % AVG Validation Acc 58.41 %\n",
      "Epoch:140/200 AVG Training Loss:0.662 AVG Validation Loss:0.675 AVG Training Acc 60.75 % AVG Validation Acc 58.68 %\n",
      "Epoch:150/200 AVG Training Loss:0.661 AVG Validation Loss:0.671 AVG Training Acc 60.75 % AVG Validation Acc 59.62 %\n",
      "Epoch:160/200 AVG Training Loss:0.661 AVG Validation Loss:0.669 AVG Training Acc 60.39 % AVG Validation Acc 59.35 %\n",
      "Epoch:170/200 AVG Training Loss:0.662 AVG Validation Loss:0.668 AVG Training Acc 60.56 % AVG Validation Acc 59.35 %\n",
      "Epoch:180/200 AVG Training Loss:0.660 AVG Validation Loss:0.667 AVG Training Acc 61.00 % AVG Validation Acc 59.76 %\n",
      "Epoch:190/200 AVG Training Loss:0.661 AVG Validation Loss:0.666 AVG Training Acc 60.64 % AVG Validation Acc 59.22 %\n",
      "Epoch:200/200 AVG Training Loss:0.660 AVG Validation Loss:0.666 AVG Training Acc 60.95 % AVG Validation Acc 59.76 %\n",
      "Epoch   200: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Split 138\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f03483090874b96b83ce7786c0c7a48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.536 AVG Validation Loss:6.536 AVG Training Acc 79.16 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.539 AVG Validation Loss:4.255 AVG Training Acc 80.62 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.636 AVG Validation Loss:1.673 AVG Training Acc 67.27 % AVG Validation Acc 20.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.630 AVG Validation Loss:1.667 AVG Training Acc 69.22 % AVG Validation Acc 20.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.635 AVG Validation Loss:1.766 AVG Training Acc 66.35 % AVG Validation Acc 20.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.589 AVG Validation Loss:2.474 AVG Training Acc 73.70 % AVG Validation Acc 20.05 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:70/200 AVG Training Loss:0.684 AVG Validation Loss:0.781 AVG Training Acc 55.37 % AVG Validation Acc 25.30 %\n",
      "Epoch:80/200 AVG Training Loss:0.675 AVG Validation Loss:0.794 AVG Training Acc 58.02 % AVG Validation Acc 38.49 %\n",
      "Epoch:90/200 AVG Training Loss:0.670 AVG Validation Loss:0.788 AVG Training Acc 59.06 % AVG Validation Acc 40.11 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.665 AVG Validation Loss:0.709 AVG Training Acc 59.59 % AVG Validation Acc 58.68 %\n",
      "Epoch:110/200 AVG Training Loss:0.661 AVG Validation Loss:0.683 AVG Training Acc 60.24 % AVG Validation Acc 61.24 %\n",
      "Epoch:120/200 AVG Training Loss:0.660 AVG Validation Loss:0.677 AVG Training Acc 60.45 % AVG Validation Acc 61.64 %\n",
      "Epoch:130/200 AVG Training Loss:0.657 AVG Validation Loss:0.676 AVG Training Acc 61.06 % AVG Validation Acc 61.78 %\n",
      "Epoch:140/200 AVG Training Loss:0.657 AVG Validation Loss:0.674 AVG Training Acc 61.13 % AVG Validation Acc 61.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.654 AVG Validation Loss:0.675 AVG Training Acc 61.02 % AVG Validation Acc 61.78 %\n",
      "Epoch   154: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:160/200 AVG Training Loss:0.655 AVG Validation Loss:0.674 AVG Training Acc 61.37 % AVG Validation Acc 61.64 %\n",
      "Epoch:170/200 AVG Training Loss:0.654 AVG Validation Loss:0.672 AVG Training Acc 61.29 % AVG Validation Acc 61.78 %\n",
      "Epoch:180/200 AVG Training Loss:0.653 AVG Validation Loss:0.671 AVG Training Acc 61.58 % AVG Validation Acc 61.64 %\n",
      "Epoch:190/200 AVG Training Loss:0.656 AVG Validation Loss:0.671 AVG Training Acc 60.94 % AVG Validation Acc 61.91 %\n",
      "Epoch:200/200 AVG Training Loss:0.654 AVG Validation Loss:0.670 AVG Training Acc 61.78 % AVG Validation Acc 62.05 %\n",
      "Split 139\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28771a57ef6a44debababec1f2381d3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.518 AVG Validation Loss:7.048 AVG Training Acc 80.72 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.644 AVG Validation Loss:1.754 AVG Training Acc 69.19 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.659 AVG Validation Loss:1.553 AVG Training Acc 65.14 % AVG Validation Acc 20.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.480 AVG Validation Loss:7.087 AVG Training Acc 80.02 % AVG Validation Acc 20.05 %\n",
      "Epoch    42: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.702 AVG Validation Loss:1.038 AVG Training Acc 61.31 % AVG Validation Acc 20.05 %\n",
      "Epoch:60/200 AVG Training Loss:0.640 AVG Validation Loss:1.548 AVG Training Acc 63.71 % AVG Validation Acc 20.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.689 AVG Validation Loss:0.842 AVG Training Acc 56.18 % AVG Validation Acc 26.92 %\n",
      "Epoch:80/200 AVG Training Loss:0.676 AVG Validation Loss:0.847 AVG Training Acc 57.78 % AVG Validation Acc 23.28 %\n",
      "Epoch    87: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.689 AVG Validation Loss:0.789 AVG Training Acc 55.03 % AVG Validation Acc 32.57 %\n",
      "Epoch:100/200 AVG Training Loss:0.666 AVG Validation Loss:0.700 AVG Training Acc 60.20 % AVG Validation Acc 49.39 %\n",
      "Epoch:110/200 AVG Training Loss:0.664 AVG Validation Loss:0.691 AVG Training Acc 60.38 % AVG Validation Acc 52.09 %\n",
      "Epoch:120/200 AVG Training Loss:0.665 AVG Validation Loss:0.687 AVG Training Acc 60.40 % AVG Validation Acc 53.16 %\n",
      "Epoch:130/200 AVG Training Loss:0.661 AVG Validation Loss:0.684 AVG Training Acc 60.87 % AVG Validation Acc 53.97 %\n",
      "Epoch:140/200 AVG Training Loss:0.662 AVG Validation Loss:0.682 AVG Training Acc 61.07 % AVG Validation Acc 54.24 %\n",
      "Epoch:150/200 AVG Training Loss:0.661 AVG Validation Loss:0.682 AVG Training Acc 60.92 % AVG Validation Acc 54.24 %\n",
      "Epoch   156: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:160/200 AVG Training Loss:0.660 AVG Validation Loss:0.679 AVG Training Acc 61.19 % AVG Validation Acc 55.32 %\n",
      "Epoch:170/200 AVG Training Loss:0.658 AVG Validation Loss:0.676 AVG Training Acc 60.95 % AVG Validation Acc 55.72 %\n",
      "Epoch:180/200 AVG Training Loss:0.658 AVG Validation Loss:0.674 AVG Training Acc 60.88 % AVG Validation Acc 56.12 %\n",
      "Epoch:190/200 AVG Training Loss:0.657 AVG Validation Loss:0.671 AVG Training Acc 61.09 % AVG Validation Acc 56.26 %\n",
      "Epoch:200/200 AVG Training Loss:0.657 AVG Validation Loss:0.671 AVG Training Acc 61.50 % AVG Validation Acc 56.26 %\n",
      "Split 140\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e8eeccb96246f08232c2cfb326c006",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.539 AVG Validation Loss:4.595 AVG Training Acc 80.98 % AVG Validation Acc 20.19 %\n",
      "Epoch:20/200 AVG Training Loss:0.631 AVG Validation Loss:2.547 AVG Training Acc 66.77 % AVG Validation Acc 20.19 %\n",
      "Epoch:30/200 AVG Training Loss:0.643 AVG Validation Loss:4.715 AVG Training Acc 72.68 % AVG Validation Acc 20.19 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.697 AVG Validation Loss:0.770 AVG Training Acc 50.25 % AVG Validation Acc 21.27 %\n",
      "Epoch:50/200 AVG Training Loss:0.677 AVG Validation Loss:0.758 AVG Training Acc 58.03 % AVG Validation Acc 39.84 %\n",
      "Epoch:60/200 AVG Training Loss:0.672 AVG Validation Loss:0.764 AVG Training Acc 59.93 % AVG Validation Acc 44.01 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.666 AVG Validation Loss:0.726 AVG Training Acc 60.33 % AVG Validation Acc 55.59 %\n",
      "Epoch:80/200 AVG Training Loss:0.660 AVG Validation Loss:0.694 AVG Training Acc 61.53 % AVG Validation Acc 58.55 %\n",
      "Epoch:90/200 AVG Training Loss:0.660 AVG Validation Loss:0.684 AVG Training Acc 61.44 % AVG Validation Acc 59.76 %\n",
      "Epoch:100/200 AVG Training Loss:0.656 AVG Validation Loss:0.681 AVG Training Acc 61.84 % AVG Validation Acc 60.16 %\n",
      "Epoch:110/200 AVG Training Loss:0.658 AVG Validation Loss:0.680 AVG Training Acc 61.92 % AVG Validation Acc 60.03 %\n",
      "Epoch:120/200 AVG Training Loss:0.657 AVG Validation Loss:0.680 AVG Training Acc 61.81 % AVG Validation Acc 59.76 %\n",
      "Epoch:130/200 AVG Training Loss:0.655 AVG Validation Loss:0.680 AVG Training Acc 62.06 % AVG Validation Acc 60.03 %\n",
      "Epoch:140/200 AVG Training Loss:0.657 AVG Validation Loss:0.680 AVG Training Acc 61.53 % AVG Validation Acc 59.62 %\n",
      "Epoch   143: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.656 AVG Validation Loss:0.679 AVG Training Acc 62.22 % AVG Validation Acc 60.30 %\n",
      "Epoch:160/200 AVG Training Loss:0.653 AVG Validation Loss:0.679 AVG Training Acc 62.03 % AVG Validation Acc 60.43 %\n",
      "Epoch:170/200 AVG Training Loss:0.654 AVG Validation Loss:0.677 AVG Training Acc 62.46 % AVG Validation Acc 60.70 %\n",
      "Epoch:180/200 AVG Training Loss:0.654 AVG Validation Loss:0.677 AVG Training Acc 62.16 % AVG Validation Acc 60.43 %\n",
      "Epoch:190/200 AVG Training Loss:0.653 AVG Validation Loss:0.676 AVG Training Acc 62.18 % AVG Validation Acc 60.57 %\n",
      "Epoch:200/200 AVG Training Loss:0.654 AVG Validation Loss:0.675 AVG Training Acc 61.90 % AVG Validation Acc 60.57 %\n",
      "Split 141\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be0f3fc28f74accb9d2ca5962c836a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.574 AVG Validation Loss:7.962 AVG Training Acc 72.84 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.633 AVG Validation Loss:1.767 AVG Training Acc 68.01 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.629 AVG Validation Loss:3.588 AVG Training Acc 72.77 % AVG Validation Acc 20.16 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.699 AVG Validation Loss:0.778 AVG Training Acc 50.45 % AVG Validation Acc 23.25 %\n",
      "Epoch:50/200 AVG Training Loss:0.687 AVG Validation Loss:0.789 AVG Training Acc 55.35 % AVG Validation Acc 25.81 %\n",
      "Epoch:60/200 AVG Training Loss:0.682 AVG Validation Loss:0.788 AVG Training Acc 56.99 % AVG Validation Acc 29.03 %\n",
      "Epoch    64: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.677 AVG Validation Loss:0.731 AVG Training Acc 56.33 % AVG Validation Acc 43.55 %\n",
      "Epoch:80/200 AVG Training Loss:0.671 AVG Validation Loss:0.691 AVG Training Acc 58.39 % AVG Validation Acc 57.66 %\n",
      "Epoch:90/200 AVG Training Loss:0.670 AVG Validation Loss:0.682 AVG Training Acc 58.80 % AVG Validation Acc 59.41 %\n",
      "Epoch:100/200 AVG Training Loss:0.671 AVG Validation Loss:0.680 AVG Training Acc 59.16 % AVG Validation Acc 59.95 %\n",
      "Epoch:110/200 AVG Training Loss:0.667 AVG Validation Loss:0.678 AVG Training Acc 59.44 % AVG Validation Acc 60.08 %\n",
      "Epoch:120/200 AVG Training Loss:0.668 AVG Validation Loss:0.679 AVG Training Acc 59.06 % AVG Validation Acc 59.68 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.667 AVG Validation Loss:0.678 AVG Training Acc 59.32 % AVG Validation Acc 60.08 %\n",
      "Epoch:140/200 AVG Training Loss:0.666 AVG Validation Loss:0.676 AVG Training Acc 59.76 % AVG Validation Acc 60.35 %\n",
      "Epoch:150/200 AVG Training Loss:0.666 AVG Validation Loss:0.675 AVG Training Acc 59.50 % AVG Validation Acc 60.75 %\n",
      "Epoch:160/200 AVG Training Loss:0.666 AVG Validation Loss:0.674 AVG Training Acc 59.79 % AVG Validation Acc 61.42 %\n",
      "Epoch:170/200 AVG Training Loss:0.666 AVG Validation Loss:0.673 AVG Training Acc 60.20 % AVG Validation Acc 61.42 %\n",
      "Epoch:180/200 AVG Training Loss:0.665 AVG Validation Loss:0.672 AVG Training Acc 59.78 % AVG Validation Acc 61.29 %\n",
      "Epoch:190/200 AVG Training Loss:0.665 AVG Validation Loss:0.672 AVG Training Acc 59.55 % AVG Validation Acc 61.42 %\n",
      "Epoch:200/200 AVG Training Loss:0.666 AVG Validation Loss:0.671 AVG Training Acc 59.33 % AVG Validation Acc 61.42 %\n",
      "Split 142\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "924ab2175e4947b4ad3feab72822d12b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.515 AVG Validation Loss:4.887 AVG Training Acc 81.52 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.659 AVG Validation Loss:1.537 AVG Training Acc 64.67 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.636 AVG Validation Loss:1.735 AVG Training Acc 67.90 % AVG Validation Acc 20.16 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.684 AVG Validation Loss:0.770 AVG Training Acc 55.35 % AVG Validation Acc 29.03 %\n",
      "Epoch:50/200 AVG Training Loss:0.681 AVG Validation Loss:0.756 AVG Training Acc 55.90 % AVG Validation Acc 37.63 %\n",
      "Epoch:60/200 AVG Training Loss:0.674 AVG Validation Loss:0.765 AVG Training Acc 58.46 % AVG Validation Acc 42.88 %\n",
      "Epoch    63: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.669 AVG Validation Loss:0.725 AVG Training Acc 59.72 % AVG Validation Acc 54.30 %\n",
      "Epoch:80/200 AVG Training Loss:0.664 AVG Validation Loss:0.700 AVG Training Acc 61.03 % AVG Validation Acc 56.72 %\n",
      "Epoch:90/200 AVG Training Loss:0.665 AVG Validation Loss:0.691 AVG Training Acc 61.06 % AVG Validation Acc 56.72 %\n",
      "Epoch:100/200 AVG Training Loss:0.664 AVG Validation Loss:0.687 AVG Training Acc 61.05 % AVG Validation Acc 57.93 %\n",
      "Epoch:110/200 AVG Training Loss:0.662 AVG Validation Loss:0.686 AVG Training Acc 61.32 % AVG Validation Acc 57.12 %\n",
      "Epoch:120/200 AVG Training Loss:0.660 AVG Validation Loss:0.685 AVG Training Acc 61.36 % AVG Validation Acc 57.26 %\n",
      "Epoch   124: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.659 AVG Validation Loss:0.685 AVG Training Acc 61.77 % AVG Validation Acc 57.12 %\n",
      "Epoch:140/200 AVG Training Loss:0.658 AVG Validation Loss:0.684 AVG Training Acc 61.87 % AVG Validation Acc 57.66 %\n",
      "Epoch:150/200 AVG Training Loss:0.660 AVG Validation Loss:0.684 AVG Training Acc 61.86 % AVG Validation Acc 56.99 %\n",
      "Epoch:160/200 AVG Training Loss:0.659 AVG Validation Loss:0.683 AVG Training Acc 61.51 % AVG Validation Acc 57.80 %\n",
      "Epoch:170/200 AVG Training Loss:0.661 AVG Validation Loss:0.682 AVG Training Acc 62.06 % AVG Validation Acc 57.66 %\n",
      "Epoch:180/200 AVG Training Loss:0.660 AVG Validation Loss:0.682 AVG Training Acc 61.81 % AVG Validation Acc 57.93 %\n",
      "Epoch:190/200 AVG Training Loss:0.659 AVG Validation Loss:0.682 AVG Training Acc 62.20 % AVG Validation Acc 58.06 %\n",
      "Epoch:200/200 AVG Training Loss:0.662 AVG Validation Loss:0.682 AVG Training Acc 61.56 % AVG Validation Acc 57.26 %\n",
      "Split 143\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90299dbe69d74be282a34dbd0372c68e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.553 AVG Validation Loss:4.295 AVG Training Acc 77.75 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.549 AVG Validation Loss:4.630 AVG Training Acc 82.21 % AVG Validation Acc 20.16 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.695 AVG Validation Loss:0.891 AVG Training Acc 54.56 % AVG Validation Acc 21.91 %\n",
      "Epoch:40/200 AVG Training Loss:0.684 AVG Validation Loss:0.881 AVG Training Acc 56.54 % AVG Validation Acc 24.73 %\n",
      "Epoch:50/200 AVG Training Loss:0.677 AVG Validation Loss:0.883 AVG Training Acc 58.13 % AVG Validation Acc 28.23 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.672 AVG Validation Loss:0.714 AVG Training Acc 58.61 % AVG Validation Acc 48.92 %\n",
      "Epoch:70/200 AVG Training Loss:0.665 AVG Validation Loss:0.690 AVG Training Acc 59.92 % AVG Validation Acc 53.90 %\n",
      "Epoch:80/200 AVG Training Loss:0.663 AVG Validation Loss:0.686 AVG Training Acc 60.22 % AVG Validation Acc 54.70 %\n",
      "Epoch:90/200 AVG Training Loss:0.662 AVG Validation Loss:0.687 AVG Training Acc 60.07 % AVG Validation Acc 55.24 %\n",
      "Epoch    95: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:100/200 AVG Training Loss:0.659 AVG Validation Loss:0.684 AVG Training Acc 60.59 % AVG Validation Acc 55.65 %\n",
      "Epoch:110/200 AVG Training Loss:0.657 AVG Validation Loss:0.680 AVG Training Acc 60.66 % AVG Validation Acc 56.32 %\n",
      "Epoch:120/200 AVG Training Loss:0.659 AVG Validation Loss:0.677 AVG Training Acc 60.85 % AVG Validation Acc 56.85 %\n",
      "Epoch:130/200 AVG Training Loss:0.659 AVG Validation Loss:0.674 AVG Training Acc 60.60 % AVG Validation Acc 56.99 %\n",
      "Epoch:140/200 AVG Training Loss:0.659 AVG Validation Loss:0.673 AVG Training Acc 60.60 % AVG Validation Acc 57.39 %\n",
      "Epoch:150/200 AVG Training Loss:0.656 AVG Validation Loss:0.671 AVG Training Acc 60.43 % AVG Validation Acc 57.53 %\n",
      "Epoch:160/200 AVG Training Loss:0.658 AVG Validation Loss:0.670 AVG Training Acc 60.37 % AVG Validation Acc 57.80 %\n",
      "Epoch:170/200 AVG Training Loss:0.659 AVG Validation Loss:0.669 AVG Training Acc 60.63 % AVG Validation Acc 57.93 %\n",
      "Epoch:180/200 AVG Training Loss:0.659 AVG Validation Loss:0.669 AVG Training Acc 60.45 % AVG Validation Acc 58.06 %\n",
      "Epoch:190/200 AVG Training Loss:0.657 AVG Validation Loss:0.668 AVG Training Acc 60.61 % AVG Validation Acc 58.20 %\n",
      "Epoch:200/200 AVG Training Loss:0.657 AVG Validation Loss:0.668 AVG Training Acc 60.89 % AVG Validation Acc 58.20 %\n",
      "Split 144\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec5fde8a8a84b7bad2f7b212ab5905b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.565 AVG Validation Loss:2.854 AVG Training Acc 76.71 % AVG Validation Acc 20.30 %\n",
      "Epoch:20/200 AVG Training Loss:0.621 AVG Validation Loss:3.127 AVG Training Acc 69.64 % AVG Validation Acc 20.16 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:1.393 AVG Validation Loss:1.197 AVG Training Acc 48.98 % AVG Validation Acc 20.43 %\n",
      "Epoch:40/200 AVG Training Loss:0.684 AVG Validation Loss:0.828 AVG Training Acc 55.80 % AVG Validation Acc 26.88 %\n",
      "Epoch:50/200 AVG Training Loss:0.675 AVG Validation Loss:0.844 AVG Training Acc 57.72 % AVG Validation Acc 32.39 %\n",
      "Epoch:60/200 AVG Training Loss:0.672 AVG Validation Loss:0.841 AVG Training Acc 58.83 % AVG Validation Acc 36.02 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.665 AVG Validation Loss:0.717 AVG Training Acc 59.89 % AVG Validation Acc 54.70 %\n",
      "Epoch:80/200 AVG Training Loss:0.660 AVG Validation Loss:0.694 AVG Training Acc 60.97 % AVG Validation Acc 57.39 %\n",
      "Epoch:90/200 AVG Training Loss:0.660 AVG Validation Loss:0.688 AVG Training Acc 60.80 % AVG Validation Acc 58.06 %\n",
      "Epoch:100/200 AVG Training Loss:0.660 AVG Validation Loss:0.686 AVG Training Acc 60.83 % AVG Validation Acc 58.60 %\n",
      "Epoch:110/200 AVG Training Loss:0.660 AVG Validation Loss:0.685 AVG Training Acc 61.41 % AVG Validation Acc 58.47 %\n",
      "Epoch:120/200 AVG Training Loss:0.658 AVG Validation Loss:0.683 AVG Training Acc 61.50 % AVG Validation Acc 59.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.659 AVG Validation Loss:0.682 AVG Training Acc 60.93 % AVG Validation Acc 59.01 %\n",
      "Epoch:140/200 AVG Training Loss:0.657 AVG Validation Loss:0.682 AVG Training Acc 61.45 % AVG Validation Acc 58.33 %\n",
      "Epoch:150/200 AVG Training Loss:0.655 AVG Validation Loss:0.682 AVG Training Acc 61.64 % AVG Validation Acc 58.20 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:160/200 AVG Training Loss:0.652 AVG Validation Loss:0.682 AVG Training Acc 62.11 % AVG Validation Acc 58.33 %\n",
      "Epoch:170/200 AVG Training Loss:0.654 AVG Validation Loss:0.679 AVG Training Acc 62.10 % AVG Validation Acc 58.60 %\n",
      "Epoch:180/200 AVG Training Loss:0.652 AVG Validation Loss:0.678 AVG Training Acc 62.07 % AVG Validation Acc 58.87 %\n",
      "Epoch:190/200 AVG Training Loss:0.653 AVG Validation Loss:0.676 AVG Training Acc 62.23 % AVG Validation Acc 59.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.654 AVG Validation Loss:0.675 AVG Training Acc 61.96 % AVG Validation Acc 59.01 %\n",
      "Split 145\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d60c6271f7b14a369f8269fbe6af0c7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.525 AVG Validation Loss:5.492 AVG Training Acc 80.82 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.546 AVG Validation Loss:5.661 AVG Training Acc 80.53 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.541 AVG Validation Loss:4.495 AVG Training Acc 74.43 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.637 AVG Validation Loss:1.928 AVG Training Acc 67.42 % AVG Validation Acc 20.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.651 AVG Validation Loss:3.584 AVG Training Acc 64.97 % AVG Validation Acc 20.16 %\n",
      "Epoch    57: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.729 AVG Validation Loss:0.856 AVG Training Acc 49.29 % AVG Validation Acc 20.97 %\n",
      "Epoch:70/200 AVG Training Loss:0.683 AVG Validation Loss:0.805 AVG Training Acc 56.52 % AVG Validation Acc 28.36 %\n",
      "Epoch:80/200 AVG Training Loss:0.680 AVG Validation Loss:0.802 AVG Training Acc 56.93 % AVG Validation Acc 34.41 %\n",
      "Epoch:90/200 AVG Training Loss:0.677 AVG Validation Loss:0.795 AVG Training Acc 57.55 % AVG Validation Acc 38.17 %\n",
      "Epoch:100/200 AVG Training Loss:0.679 AVG Validation Loss:0.771 AVG Training Acc 57.73 % AVG Validation Acc 41.13 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:110/200 AVG Training Loss:0.677 AVG Validation Loss:0.758 AVG Training Acc 57.14 % AVG Validation Acc 45.83 %\n",
      "Epoch:120/200 AVG Training Loss:0.664 AVG Validation Loss:0.705 AVG Training Acc 59.70 % AVG Validation Acc 56.85 %\n",
      "Epoch:130/200 AVG Training Loss:0.663 AVG Validation Loss:0.688 AVG Training Acc 59.78 % AVG Validation Acc 59.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.664 AVG Validation Loss:0.683 AVG Training Acc 60.48 % AVG Validation Acc 59.41 %\n",
      "Epoch:150/200 AVG Training Loss:0.662 AVG Validation Loss:0.682 AVG Training Acc 59.96 % AVG Validation Acc 59.68 %\n",
      "Epoch:160/200 AVG Training Loss:0.660 AVG Validation Loss:0.679 AVG Training Acc 60.42 % AVG Validation Acc 59.68 %\n",
      "Epoch:170/200 AVG Training Loss:0.663 AVG Validation Loss:0.680 AVG Training Acc 60.14 % AVG Validation Acc 59.68 %\n",
      "Epoch:180/200 AVG Training Loss:0.661 AVG Validation Loss:0.679 AVG Training Acc 60.35 % AVG Validation Acc 59.68 %\n",
      "Epoch   189: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:190/200 AVG Training Loss:0.660 AVG Validation Loss:0.680 AVG Training Acc 60.64 % AVG Validation Acc 59.27 %\n",
      "Epoch:200/200 AVG Training Loss:0.660 AVG Validation Loss:0.679 AVG Training Acc 60.50 % AVG Validation Acc 59.27 %\n",
      "Split 146\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80709824b4134cd68c4a210f61e9173f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.486 AVG Validation Loss:5.161 AVG Training Acc 82.84 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.587 AVG Validation Loss:4.331 AVG Training Acc 75.46 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.624 AVG Validation Loss:3.525 AVG Training Acc 77.47 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.634 AVG Validation Loss:5.757 AVG Training Acc 78.66 % AVG Validation Acc 20.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.649 AVG Validation Loss:1.572 AVG Training Acc 65.47 % AVG Validation Acc 20.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.668 AVG Validation Loss:1.819 AVG Training Acc 67.14 % AVG Validation Acc 20.16 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:70/200 AVG Training Loss:0.680 AVG Validation Loss:0.747 AVG Training Acc 57.46 % AVG Validation Acc 39.25 %\n",
      "Epoch:80/200 AVG Training Loss:0.677 AVG Validation Loss:0.743 AVG Training Acc 58.32 % AVG Validation Acc 42.61 %\n",
      "Epoch:90/200 AVG Training Loss:0.671 AVG Validation Loss:0.744 AVG Training Acc 59.23 % AVG Validation Acc 43.41 %\n",
      "Epoch    93: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.667 AVG Validation Loss:0.713 AVG Training Acc 59.33 % AVG Validation Acc 53.76 %\n",
      "Epoch:110/200 AVG Training Loss:0.664 AVG Validation Loss:0.690 AVG Training Acc 60.86 % AVG Validation Acc 57.53 %\n",
      "Epoch:120/200 AVG Training Loss:0.661 AVG Validation Loss:0.681 AVG Training Acc 61.10 % AVG Validation Acc 59.81 %\n",
      "Epoch:130/200 AVG Training Loss:0.661 AVG Validation Loss:0.677 AVG Training Acc 61.09 % AVG Validation Acc 60.08 %\n",
      "Epoch:140/200 AVG Training Loss:0.661 AVG Validation Loss:0.675 AVG Training Acc 61.10 % AVG Validation Acc 60.35 %\n",
      "Epoch:150/200 AVG Training Loss:0.661 AVG Validation Loss:0.674 AVG Training Acc 60.82 % AVG Validation Acc 60.08 %\n",
      "Epoch:160/200 AVG Training Loss:0.662 AVG Validation Loss:0.673 AVG Training Acc 61.11 % AVG Validation Acc 60.08 %\n",
      "Epoch:170/200 AVG Training Loss:0.661 AVG Validation Loss:0.673 AVG Training Acc 61.32 % AVG Validation Acc 60.35 %\n",
      "Epoch:180/200 AVG Training Loss:0.661 AVG Validation Loss:0.673 AVG Training Acc 61.77 % AVG Validation Acc 59.81 %\n",
      "Epoch:190/200 AVG Training Loss:0.659 AVG Validation Loss:0.672 AVG Training Acc 61.52 % AVG Validation Acc 60.08 %\n",
      "Epoch:200/200 AVG Training Loss:0.659 AVG Validation Loss:0.672 AVG Training Acc 61.01 % AVG Validation Acc 59.95 %\n",
      "Split 147\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2bce993ac3c4404bc55f934c33d7352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.525 AVG Validation Loss:6.901 AVG Training Acc 79.68 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.536 AVG Validation Loss:2.741 AVG Training Acc 77.61 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.493 AVG Validation Loss:3.996 AVG Training Acc 80.23 % AVG Validation Acc 20.05 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.701 AVG Validation Loss:0.932 AVG Training Acc 53.84 % AVG Validation Acc 20.19 %\n",
      "Epoch:50/200 AVG Training Loss:0.673 AVG Validation Loss:1.040 AVG Training Acc 59.25 % AVG Validation Acc 20.59 %\n",
      "Epoch:60/200 AVG Training Loss:0.682 AVG Validation Loss:0.904 AVG Training Acc 56.95 % AVG Validation Acc 22.48 %\n",
      "Epoch    62: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.677 AVG Validation Loss:0.724 AVG Training Acc 57.64 % AVG Validation Acc 44.28 %\n",
      "Epoch:80/200 AVG Training Loss:0.670 AVG Validation Loss:0.703 AVG Training Acc 58.82 % AVG Validation Acc 48.86 %\n",
      "Epoch:90/200 AVG Training Loss:0.671 AVG Validation Loss:0.693 AVG Training Acc 59.71 % AVG Validation Acc 52.36 %\n",
      "Epoch:100/200 AVG Training Loss:0.668 AVG Validation Loss:0.690 AVG Training Acc 59.43 % AVG Validation Acc 53.84 %\n",
      "Epoch:110/200 AVG Training Loss:0.668 AVG Validation Loss:0.689 AVG Training Acc 59.81 % AVG Validation Acc 54.10 %\n",
      "Epoch   116: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.666 AVG Validation Loss:0.687 AVG Training Acc 60.31 % AVG Validation Acc 55.32 %\n",
      "Epoch:130/200 AVG Training Loss:0.666 AVG Validation Loss:0.681 AVG Training Acc 60.27 % AVG Validation Acc 56.93 %\n",
      "Epoch:140/200 AVG Training Loss:0.663 AVG Validation Loss:0.678 AVG Training Acc 60.02 % AVG Validation Acc 57.34 %\n",
      "Epoch:150/200 AVG Training Loss:0.665 AVG Validation Loss:0.677 AVG Training Acc 59.95 % AVG Validation Acc 58.95 %\n",
      "Epoch:160/200 AVG Training Loss:0.662 AVG Validation Loss:0.675 AVG Training Acc 60.49 % AVG Validation Acc 58.95 %\n",
      "Epoch:170/200 AVG Training Loss:0.663 AVG Validation Loss:0.675 AVG Training Acc 60.68 % AVG Validation Acc 59.08 %\n",
      "Epoch   170: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:180/200 AVG Training Loss:0.663 AVG Validation Loss:0.673 AVG Training Acc 60.91 % AVG Validation Acc 59.22 %\n",
      "Epoch:190/200 AVG Training Loss:0.663 AVG Validation Loss:0.675 AVG Training Acc 60.41 % AVG Validation Acc 58.68 %\n",
      "Epoch:200/200 AVG Training Loss:0.665 AVG Validation Loss:0.676 AVG Training Acc 60.20 % AVG Validation Acc 59.22 %\n",
      "Split 148\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be7b9da4eb05489ea312d6bb848b0dda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.504 AVG Validation Loss:5.709 AVG Training Acc 81.52 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.653 AVG Validation Loss:1.623 AVG Training Acc 65.91 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.620 AVG Validation Loss:2.413 AVG Training Acc 79.41 % AVG Validation Acc 20.05 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.695 AVG Validation Loss:0.768 AVG Training Acc 51.16 % AVG Validation Acc 23.15 %\n",
      "Epoch:50/200 AVG Training Loss:0.682 AVG Validation Loss:0.784 AVG Training Acc 56.49 % AVG Validation Acc 29.34 %\n",
      "Epoch:60/200 AVG Training Loss:0.677 AVG Validation Loss:0.771 AVG Training Acc 58.10 % AVG Validation Acc 35.80 %\n",
      "Epoch:70/200 AVG Training Loss:0.671 AVG Validation Loss:0.770 AVG Training Acc 59.08 % AVG Validation Acc 40.24 %\n",
      "Epoch    73: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.666 AVG Validation Loss:0.723 AVG Training Acc 59.55 % AVG Validation Acc 54.51 %\n",
      "Epoch:90/200 AVG Training Loss:0.661 AVG Validation Loss:0.694 AVG Training Acc 60.37 % AVG Validation Acc 59.62 %\n",
      "Epoch:100/200 AVG Training Loss:0.660 AVG Validation Loss:0.686 AVG Training Acc 60.91 % AVG Validation Acc 60.70 %\n",
      "Epoch:110/200 AVG Training Loss:0.660 AVG Validation Loss:0.684 AVG Training Acc 60.87 % AVG Validation Acc 60.57 %\n",
      "Epoch:120/200 AVG Training Loss:0.659 AVG Validation Loss:0.683 AVG Training Acc 61.06 % AVG Validation Acc 60.57 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.657 AVG Validation Loss:0.683 AVG Training Acc 61.60 % AVG Validation Acc 60.57 %\n",
      "Epoch:140/200 AVG Training Loss:0.658 AVG Validation Loss:0.682 AVG Training Acc 61.06 % AVG Validation Acc 60.57 %\n",
      "Epoch:150/200 AVG Training Loss:0.657 AVG Validation Loss:0.681 AVG Training Acc 61.09 % AVG Validation Acc 60.83 %\n",
      "Epoch:160/200 AVG Training Loss:0.656 AVG Validation Loss:0.679 AVG Training Acc 61.73 % AVG Validation Acc 60.83 %\n",
      "Epoch:170/200 AVG Training Loss:0.656 AVG Validation Loss:0.677 AVG Training Acc 61.64 % AVG Validation Acc 60.97 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:180/200 AVG Training Loss:0.657 AVG Validation Loss:0.679 AVG Training Acc 61.26 % AVG Validation Acc 60.97 %\n",
      "Epoch:190/200 AVG Training Loss:0.658 AVG Validation Loss:0.678 AVG Training Acc 61.11 % AVG Validation Acc 60.83 %\n",
      "Epoch:200/200 AVG Training Loss:0.657 AVG Validation Loss:0.678 AVG Training Acc 61.42 % AVG Validation Acc 60.97 %\n",
      "Split 149\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "63b163e499b14ff1b1746e7cf824fa53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.533 AVG Validation Loss:3.341 AVG Training Acc 80.59 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.471 AVG Validation Loss:5.082 AVG Training Acc 80.66 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.573 AVG Validation Loss:6.711 AVG Training Acc 77.33 % AVG Validation Acc 20.05 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.713 AVG Validation Loss:0.896 AVG Training Acc 56.16 % AVG Validation Acc 22.48 %\n",
      "Epoch:50/200 AVG Training Loss:0.692 AVG Validation Loss:0.907 AVG Training Acc 55.49 % AVG Validation Acc 24.63 %\n",
      "Epoch:60/200 AVG Training Loss:0.689 AVG Validation Loss:0.910 AVG Training Acc 56.47 % AVG Validation Acc 21.00 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.685 AVG Validation Loss:0.723 AVG Training Acc 54.89 % AVG Validation Acc 42.40 %\n",
      "Epoch:80/200 AVG Training Loss:0.680 AVG Validation Loss:0.694 AVG Training Acc 56.76 % AVG Validation Acc 51.82 %\n",
      "Epoch:90/200 AVG Training Loss:0.675 AVG Validation Loss:0.694 AVG Training Acc 58.24 % AVG Validation Acc 52.76 %\n",
      "Epoch:100/200 AVG Training Loss:0.672 AVG Validation Loss:0.694 AVG Training Acc 58.75 % AVG Validation Acc 52.89 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.670 AVG Validation Loss:0.680 AVG Training Acc 58.84 % AVG Validation Acc 55.72 %\n",
      "Epoch:120/200 AVG Training Loss:0.668 AVG Validation Loss:0.670 AVG Training Acc 58.94 % AVG Validation Acc 58.82 %\n",
      "Epoch:130/200 AVG Training Loss:0.667 AVG Validation Loss:0.664 AVG Training Acc 59.37 % AVG Validation Acc 60.16 %\n",
      "Epoch:140/200 AVG Training Loss:0.666 AVG Validation Loss:0.662 AVG Training Acc 59.06 % AVG Validation Acc 60.97 %\n",
      "Epoch:150/200 AVG Training Loss:0.665 AVG Validation Loss:0.659 AVG Training Acc 59.98 % AVG Validation Acc 61.64 %\n",
      "Epoch:160/200 AVG Training Loss:0.666 AVG Validation Loss:0.659 AVG Training Acc 59.26 % AVG Validation Acc 61.91 %\n",
      "Epoch:170/200 AVG Training Loss:0.664 AVG Validation Loss:0.658 AVG Training Acc 59.67 % AVG Validation Acc 62.31 %\n",
      "Epoch:180/200 AVG Training Loss:0.668 AVG Validation Loss:0.658 AVG Training Acc 59.17 % AVG Validation Acc 62.58 %\n",
      "Epoch   185: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:190/200 AVG Training Loss:0.666 AVG Validation Loss:0.659 AVG Training Acc 59.06 % AVG Validation Acc 61.64 %\n",
      "Epoch:200/200 AVG Training Loss:0.666 AVG Validation Loss:0.658 AVG Training Acc 59.46 % AVG Validation Acc 63.26 %\n",
      "Split 150\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33fe54d8ca994ff08729b758af0b10a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.511 AVG Validation Loss:6.132 AVG Training Acc 79.22 % AVG Validation Acc 20.19 %\n",
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:1.529 AVG Validation Loss:1.425 AVG Training Acc 57.38 % AVG Validation Acc 21.40 %\n",
      "Epoch:30/200 AVG Training Loss:0.660 AVG Validation Loss:1.187 AVG Training Acc 61.92 % AVG Validation Acc 20.32 %\n",
      "Epoch:40/200 AVG Training Loss:0.638 AVG Validation Loss:1.263 AVG Training Acc 63.89 % AVG Validation Acc 20.46 %\n",
      "Epoch:50/200 AVG Training Loss:0.668 AVG Validation Loss:0.998 AVG Training Acc 58.55 % AVG Validation Acc 20.86 %\n",
      "Epoch:60/200 AVG Training Loss:0.663 AVG Validation Loss:0.967 AVG Training Acc 59.26 % AVG Validation Acc 21.67 %\n",
      "Epoch:70/200 AVG Training Loss:0.623 AVG Validation Loss:1.069 AVG Training Acc 66.00 % AVG Validation Acc 22.48 %\n",
      "Epoch    70: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.659 AVG Validation Loss:0.699 AVG Training Acc 59.41 % AVG Validation Acc 47.24 %\n",
      "Epoch:90/200 AVG Training Loss:0.656 AVG Validation Loss:0.689 AVG Training Acc 60.34 % AVG Validation Acc 50.47 %\n",
      "Epoch:100/200 AVG Training Loss:0.653 AVG Validation Loss:0.688 AVG Training Acc 60.58 % AVG Validation Acc 48.99 %\n",
      "Epoch:110/200 AVG Training Loss:0.650 AVG Validation Loss:0.686 AVG Training Acc 60.57 % AVG Validation Acc 49.13 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.648 AVG Validation Loss:0.675 AVG Training Acc 61.00 % AVG Validation Acc 51.55 %\n",
      "Epoch:130/200 AVG Training Loss:0.646 AVG Validation Loss:0.663 AVG Training Acc 61.25 % AVG Validation Acc 53.57 %\n",
      "Epoch:140/200 AVG Training Loss:0.645 AVG Validation Loss:0.662 AVG Training Acc 61.23 % AVG Validation Acc 53.84 %\n",
      "Epoch:150/200 AVG Training Loss:0.646 AVG Validation Loss:0.655 AVG Training Acc 61.63 % AVG Validation Acc 53.57 %\n",
      "Epoch:160/200 AVG Training Loss:0.645 AVG Validation Loss:0.656 AVG Training Acc 61.77 % AVG Validation Acc 54.10 %\n",
      "Epoch:170/200 AVG Training Loss:0.644 AVG Validation Loss:0.656 AVG Training Acc 61.63 % AVG Validation Acc 54.24 %\n",
      "Epoch   174: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:180/200 AVG Training Loss:0.643 AVG Validation Loss:0.657 AVG Training Acc 61.58 % AVG Validation Acc 54.10 %\n",
      "Epoch:190/200 AVG Training Loss:0.643 AVG Validation Loss:0.656 AVG Training Acc 61.46 % AVG Validation Acc 54.37 %\n",
      "Epoch:200/200 AVG Training Loss:0.644 AVG Validation Loss:0.653 AVG Training Acc 61.78 % AVG Validation Acc 54.78 %\n",
      "Split 151\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aefc2ca576c34b24a972a342d976bdd6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.560 AVG Validation Loss:4.465 AVG Training Acc 79.83 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.443 AVG Validation Loss:6.088 AVG Training Acc 80.96 % AVG Validation Acc 20.16 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.710 AVG Validation Loss:1.107 AVG Training Acc 52.05 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.682 AVG Validation Loss:0.938 AVG Training Acc 57.73 % AVG Validation Acc 20.43 %\n",
      "Epoch:50/200 AVG Training Loss:0.679 AVG Validation Loss:0.928 AVG Training Acc 57.02 % AVG Validation Acc 21.64 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.715 AVG Validation Loss:0.856 AVG Training Acc 52.95 % AVG Validation Acc 25.27 %\n",
      "Epoch:70/200 AVG Training Loss:0.671 AVG Validation Loss:0.714 AVG Training Acc 58.49 % AVG Validation Acc 46.91 %\n",
      "Epoch:80/200 AVG Training Loss:0.668 AVG Validation Loss:0.703 AVG Training Acc 59.29 % AVG Validation Acc 51.21 %\n",
      "Epoch:90/200 AVG Training Loss:0.667 AVG Validation Loss:0.697 AVG Training Acc 59.71 % AVG Validation Acc 51.75 %\n",
      "Epoch:100/200 AVG Training Loss:0.664 AVG Validation Loss:0.699 AVG Training Acc 60.07 % AVG Validation Acc 52.02 %\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.663 AVG Validation Loss:0.694 AVG Training Acc 59.59 % AVG Validation Acc 52.55 %\n",
      "Epoch:120/200 AVG Training Loss:0.661 AVG Validation Loss:0.691 AVG Training Acc 60.34 % AVG Validation Acc 52.96 %\n",
      "Epoch:130/200 AVG Training Loss:0.662 AVG Validation Loss:0.689 AVG Training Acc 60.02 % AVG Validation Acc 53.90 %\n",
      "Epoch:140/200 AVG Training Loss:0.663 AVG Validation Loss:0.687 AVG Training Acc 60.20 % AVG Validation Acc 53.76 %\n",
      "Epoch:150/200 AVG Training Loss:0.663 AVG Validation Loss:0.686 AVG Training Acc 60.57 % AVG Validation Acc 54.97 %\n",
      "Epoch:160/200 AVG Training Loss:0.661 AVG Validation Loss:0.685 AVG Training Acc 60.81 % AVG Validation Acc 54.30 %\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:170/200 AVG Training Loss:0.662 AVG Validation Loss:0.684 AVG Training Acc 60.57 % AVG Validation Acc 54.30 %\n",
      "Epoch:180/200 AVG Training Loss:0.662 AVG Validation Loss:0.683 AVG Training Acc 60.45 % AVG Validation Acc 54.03 %\n",
      "Epoch:190/200 AVG Training Loss:0.662 AVG Validation Loss:0.685 AVG Training Acc 60.43 % AVG Validation Acc 54.70 %\n",
      "Epoch:200/200 AVG Training Loss:0.663 AVG Validation Loss:0.683 AVG Training Acc 60.45 % AVG Validation Acc 54.84 %\n",
      "Split 152\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb9eee2b497147a3a8fa43b477bfe195",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.424 AVG Validation Loss:9.922 AVG Training Acc 83.98 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.552 AVG Validation Loss:8.377 AVG Training Acc 73.51 % AVG Validation Acc 20.16 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:1.460 AVG Validation Loss:1.285 AVG Training Acc 52.28 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.657 AVG Validation Loss:1.122 AVG Training Acc 60.47 % AVG Validation Acc 23.79 %\n",
      "Epoch:50/200 AVG Training Loss:0.609 AVG Validation Loss:1.403 AVG Training Acc 68.36 % AVG Validation Acc 21.64 %\n",
      "Epoch:60/200 AVG Training Loss:0.636 AVG Validation Loss:1.127 AVG Training Acc 65.24 % AVG Validation Acc 23.12 %\n",
      "Epoch:70/200 AVG Training Loss:0.647 AVG Validation Loss:1.056 AVG Training Acc 63.64 % AVG Validation Acc 22.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.660 AVG Validation Loss:0.946 AVG Training Acc 61.37 % AVG Validation Acc 24.46 %\n",
      "Epoch:90/200 AVG Training Loss:0.651 AVG Validation Loss:0.937 AVG Training Acc 62.04 % AVG Validation Acc 24.19 %\n",
      "Epoch    92: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.655 AVG Validation Loss:0.703 AVG Training Acc 60.51 % AVG Validation Acc 49.87 %\n",
      "Epoch:110/200 AVG Training Loss:0.648 AVG Validation Loss:0.673 AVG Training Acc 61.96 % AVG Validation Acc 56.85 %\n",
      "Epoch:120/200 AVG Training Loss:0.648 AVG Validation Loss:0.670 AVG Training Acc 61.94 % AVG Validation Acc 57.80 %\n",
      "Epoch:130/200 AVG Training Loss:0.643 AVG Validation Loss:0.670 AVG Training Acc 62.68 % AVG Validation Acc 56.99 %\n",
      "Epoch:140/200 AVG Training Loss:0.641 AVG Validation Loss:0.671 AVG Training Acc 62.93 % AVG Validation Acc 56.72 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.641 AVG Validation Loss:0.664 AVG Training Acc 63.07 % AVG Validation Acc 57.53 %\n",
      "Epoch:160/200 AVG Training Loss:0.639 AVG Validation Loss:0.660 AVG Training Acc 63.62 % AVG Validation Acc 59.01 %\n",
      "Epoch:170/200 AVG Training Loss:0.638 AVG Validation Loss:0.658 AVG Training Acc 63.30 % AVG Validation Acc 59.01 %\n",
      "Epoch:180/200 AVG Training Loss:0.638 AVG Validation Loss:0.656 AVG Training Acc 63.25 % AVG Validation Acc 59.54 %\n",
      "Epoch:190/200 AVG Training Loss:0.638 AVG Validation Loss:0.656 AVG Training Acc 63.39 % AVG Validation Acc 59.95 %\n",
      "Epoch:200/200 AVG Training Loss:0.637 AVG Validation Loss:0.653 AVG Training Acc 63.68 % AVG Validation Acc 60.62 %\n",
      "Split 153\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "436a017181bf45ec84773b9bcd83cb6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.501 AVG Validation Loss:4.428 AVG Training Acc 81.58 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.585 AVG Validation Loss:6.865 AVG Training Acc 71.35 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.568 AVG Validation Loss:5.584 AVG Training Acc 80.00 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.662 AVG Validation Loss:1.495 AVG Training Acc 64.11 % AVG Validation Acc 20.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.639 AVG Validation Loss:8.828 AVG Training Acc 65.96 % AVG Validation Acc 20.16 %\n",
      "Epoch    54: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.699 AVG Validation Loss:0.765 AVG Training Acc 49.43 % AVG Validation Acc 20.83 %\n",
      "Epoch:70/200 AVG Training Loss:0.686 AVG Validation Loss:0.764 AVG Training Acc 55.67 % AVG Validation Acc 36.56 %\n",
      "Epoch:80/200 AVG Training Loss:0.680 AVG Validation Loss:0.772 AVG Training Acc 57.04 % AVG Validation Acc 40.19 %\n",
      "Epoch    85: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.676 AVG Validation Loss:0.734 AVG Training Acc 57.75 % AVG Validation Acc 51.08 %\n",
      "Epoch:100/200 AVG Training Loss:0.669 AVG Validation Loss:0.698 AVG Training Acc 59.26 % AVG Validation Acc 59.01 %\n",
      "Epoch:110/200 AVG Training Loss:0.669 AVG Validation Loss:0.686 AVG Training Acc 59.26 % AVG Validation Acc 61.69 %\n",
      "Epoch:120/200 AVG Training Loss:0.669 AVG Validation Loss:0.683 AVG Training Acc 59.47 % AVG Validation Acc 62.50 %\n",
      "Epoch:130/200 AVG Training Loss:0.670 AVG Validation Loss:0.681 AVG Training Acc 59.53 % AVG Validation Acc 62.10 %\n",
      "Epoch:140/200 AVG Training Loss:0.668 AVG Validation Loss:0.680 AVG Training Acc 59.58 % AVG Validation Acc 61.56 %\n",
      "Epoch:150/200 AVG Training Loss:0.667 AVG Validation Loss:0.680 AVG Training Acc 59.64 % AVG Validation Acc 61.56 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:160/200 AVG Training Loss:0.666 AVG Validation Loss:0.680 AVG Training Acc 60.07 % AVG Validation Acc 61.96 %\n",
      "Epoch:170/200 AVG Training Loss:0.667 AVG Validation Loss:0.679 AVG Training Acc 60.37 % AVG Validation Acc 61.56 %\n",
      "Epoch:180/200 AVG Training Loss:0.667 AVG Validation Loss:0.678 AVG Training Acc 60.33 % AVG Validation Acc 62.10 %\n",
      "Epoch:190/200 AVG Training Loss:0.666 AVG Validation Loss:0.678 AVG Training Acc 60.22 % AVG Validation Acc 61.96 %\n",
      "Epoch:200/200 AVG Training Loss:0.666 AVG Validation Loss:0.677 AVG Training Acc 60.74 % AVG Validation Acc 62.23 %\n",
      "Split 154\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9aa26d75c5f444afb869922a71c40a75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.572 AVG Validation Loss:2.627 AVG Training Acc 76.07 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.537 AVG Validation Loss:3.627 AVG Training Acc 76.03 % AVG Validation Acc 20.16 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.666 AVG Validation Loss:1.290 AVG Training Acc 61.06 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.643 AVG Validation Loss:1.250 AVG Training Acc 64.12 % AVG Validation Acc 20.30 %\n",
      "Epoch:50/200 AVG Training Loss:0.655 AVG Validation Loss:1.079 AVG Training Acc 62.37 % AVG Validation Acc 20.56 %\n",
      "Epoch:60/200 AVG Training Loss:0.661 AVG Validation Loss:1.033 AVG Training Acc 61.80 % AVG Validation Acc 20.70 %\n",
      "Epoch:70/200 AVG Training Loss:0.666 AVG Validation Loss:0.978 AVG Training Acc 61.93 % AVG Validation Acc 21.10 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.668 AVG Validation Loss:0.731 AVG Training Acc 59.09 % AVG Validation Acc 48.25 %\n",
      "Epoch:90/200 AVG Training Loss:0.661 AVG Validation Loss:0.695 AVG Training Acc 61.62 % AVG Validation Acc 55.65 %\n",
      "Epoch:100/200 AVG Training Loss:0.659 AVG Validation Loss:0.693 AVG Training Acc 61.30 % AVG Validation Acc 55.38 %\n",
      "Epoch   108: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.655 AVG Validation Loss:0.690 AVG Training Acc 61.84 % AVG Validation Acc 56.45 %\n",
      "Epoch:120/200 AVG Training Loss:0.655 AVG Validation Loss:0.683 AVG Training Acc 62.01 % AVG Validation Acc 57.39 %\n",
      "Epoch:130/200 AVG Training Loss:0.655 AVG Validation Loss:0.678 AVG Training Acc 62.00 % AVG Validation Acc 57.66 %\n",
      "Epoch:140/200 AVG Training Loss:0.654 AVG Validation Loss:0.676 AVG Training Acc 62.39 % AVG Validation Acc 58.06 %\n",
      "Epoch:150/200 AVG Training Loss:0.654 AVG Validation Loss:0.676 AVG Training Acc 62.26 % AVG Validation Acc 58.06 %\n",
      "Epoch:160/200 AVG Training Loss:0.654 AVG Validation Loss:0.674 AVG Training Acc 61.96 % AVG Validation Acc 58.47 %\n",
      "Epoch   167: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:170/200 AVG Training Loss:0.655 AVG Validation Loss:0.673 AVG Training Acc 62.10 % AVG Validation Acc 58.87 %\n",
      "Epoch:180/200 AVG Training Loss:0.653 AVG Validation Loss:0.674 AVG Training Acc 62.04 % AVG Validation Acc 58.60 %\n",
      "Epoch:190/200 AVG Training Loss:0.653 AVG Validation Loss:0.674 AVG Training Acc 62.18 % AVG Validation Acc 58.47 %\n",
      "Epoch   198: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:200/200 AVG Training Loss:0.654 AVG Validation Loss:0.672 AVG Training Acc 62.25 % AVG Validation Acc 58.74 %\n",
      "Split 155\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "644a146704334a2d9aa8386c4aba061c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.517 AVG Validation Loss:4.456 AVG Training Acc 82.05 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.498 AVG Validation Loss:6.239 AVG Training Acc 80.36 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.637 AVG Validation Loss:1.656 AVG Training Acc 68.27 % AVG Validation Acc 20.16 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.701 AVG Validation Loss:0.817 AVG Training Acc 50.72 % AVG Validation Acc 21.37 %\n",
      "Epoch:50/200 AVG Training Loss:0.677 AVG Validation Loss:0.815 AVG Training Acc 56.94 % AVG Validation Acc 24.33 %\n",
      "Epoch:60/200 AVG Training Loss:0.673 AVG Validation Loss:0.811 AVG Training Acc 58.02 % AVG Validation Acc 32.93 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.674 AVG Validation Loss:0.760 AVG Training Acc 58.24 % AVG Validation Acc 42.88 %\n",
      "Epoch:80/200 AVG Training Loss:0.659 AVG Validation Loss:0.694 AVG Training Acc 60.62 % AVG Validation Acc 55.65 %\n",
      "Epoch:90/200 AVG Training Loss:0.660 AVG Validation Loss:0.683 AVG Training Acc 60.60 % AVG Validation Acc 57.26 %\n",
      "Epoch:100/200 AVG Training Loss:0.655 AVG Validation Loss:0.682 AVG Training Acc 60.91 % AVG Validation Acc 57.53 %\n",
      "Epoch:110/200 AVG Training Loss:0.654 AVG Validation Loss:0.680 AVG Training Acc 61.11 % AVG Validation Acc 57.66 %\n",
      "Epoch   114: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.657 AVG Validation Loss:0.680 AVG Training Acc 60.94 % AVG Validation Acc 58.06 %\n",
      "Epoch:130/200 AVG Training Loss:0.652 AVG Validation Loss:0.676 AVG Training Acc 61.44 % AVG Validation Acc 58.60 %\n",
      "Epoch:140/200 AVG Training Loss:0.654 AVG Validation Loss:0.674 AVG Training Acc 60.83 % AVG Validation Acc 58.87 %\n",
      "Epoch:150/200 AVG Training Loss:0.655 AVG Validation Loss:0.675 AVG Training Acc 60.76 % AVG Validation Acc 59.27 %\n",
      "Epoch:160/200 AVG Training Loss:0.652 AVG Validation Loss:0.673 AVG Training Acc 61.01 % AVG Validation Acc 59.01 %\n",
      "Epoch:170/200 AVG Training Loss:0.653 AVG Validation Loss:0.671 AVG Training Acc 60.65 % AVG Validation Acc 59.68 %\n",
      "Epoch:180/200 AVG Training Loss:0.653 AVG Validation Loss:0.671 AVG Training Acc 61.14 % AVG Validation Acc 59.27 %\n",
      "Epoch:190/200 AVG Training Loss:0.651 AVG Validation Loss:0.672 AVG Training Acc 61.69 % AVG Validation Acc 59.41 %\n",
      "Epoch:200/200 AVG Training Loss:0.656 AVG Validation Loss:0.670 AVG Training Acc 61.18 % AVG Validation Acc 59.68 %\n",
      "Split 156\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60596cacfb6247049754b379d9f4f41f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.579 AVG Validation Loss:2.747 AVG Training Acc 75.36 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.509 AVG Validation Loss:5.186 AVG Training Acc 76.46 % AVG Validation Acc 20.16 %\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.689 AVG Validation Loss:0.860 AVG Training Acc 55.45 % AVG Validation Acc 21.64 %\n",
      "Epoch:40/200 AVG Training Loss:0.680 AVG Validation Loss:0.849 AVG Training Acc 57.57 % AVG Validation Acc 27.69 %\n",
      "Epoch:50/200 AVG Training Loss:0.674 AVG Validation Loss:0.818 AVG Training Acc 58.49 % AVG Validation Acc 33.33 %\n",
      "Epoch:60/200 AVG Training Loss:0.670 AVG Validation Loss:0.812 AVG Training Acc 59.45 % AVG Validation Acc 32.80 %\n",
      "Epoch:70/200 AVG Training Loss:0.666 AVG Validation Loss:0.807 AVG Training Acc 60.14 % AVG Validation Acc 32.12 %\n",
      "Epoch    76: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.668 AVG Validation Loss:0.760 AVG Training Acc 58.73 % AVG Validation Acc 45.70 %\n",
      "Epoch:90/200 AVG Training Loss:0.657 AVG Validation Loss:0.711 AVG Training Acc 60.67 % AVG Validation Acc 54.17 %\n",
      "Epoch:100/200 AVG Training Loss:0.655 AVG Validation Loss:0.702 AVG Training Acc 61.28 % AVG Validation Acc 54.57 %\n",
      "Epoch:110/200 AVG Training Loss:0.654 AVG Validation Loss:0.699 AVG Training Acc 61.23 % AVG Validation Acc 55.51 %\n",
      "Epoch:120/200 AVG Training Loss:0.651 AVG Validation Loss:0.697 AVG Training Acc 61.96 % AVG Validation Acc 55.65 %\n",
      "Epoch:130/200 AVG Training Loss:0.651 AVG Validation Loss:0.697 AVG Training Acc 61.18 % AVG Validation Acc 55.65 %\n",
      "Epoch:140/200 AVG Training Loss:0.647 AVG Validation Loss:0.698 AVG Training Acc 61.79 % AVG Validation Acc 55.65 %\n",
      "Epoch   141: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.647 AVG Validation Loss:0.696 AVG Training Acc 61.87 % AVG Validation Acc 55.65 %\n",
      "Epoch:160/200 AVG Training Loss:0.646 AVG Validation Loss:0.694 AVG Training Acc 62.02 % AVG Validation Acc 56.45 %\n",
      "Epoch:170/200 AVG Training Loss:0.647 AVG Validation Loss:0.693 AVG Training Acc 61.83 % AVG Validation Acc 56.45 %\n",
      "Epoch:180/200 AVG Training Loss:0.645 AVG Validation Loss:0.692 AVG Training Acc 62.10 % AVG Validation Acc 56.59 %\n",
      "Epoch:190/200 AVG Training Loss:0.645 AVG Validation Loss:0.692 AVG Training Acc 62.23 % AVG Validation Acc 56.59 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:200/200 AVG Training Loss:0.645 AVG Validation Loss:0.692 AVG Training Acc 62.14 % AVG Validation Acc 56.45 %\n",
      "Split 157\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b136b4c18d1047399b56824fd89cf494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.566 AVG Validation Loss:3.904 AVG Training Acc 77.02 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:1.643 AVG Training Acc 65.44 % AVG Validation Acc 20.05 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:1.041 AVG Validation Loss:1.264 AVG Training Acc 50.00 % AVG Validation Acc 20.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.684 AVG Validation Loss:0.763 AVG Training Acc 55.38 % AVG Validation Acc 33.92 %\n",
      "Epoch:50/200 AVG Training Loss:0.678 AVG Validation Loss:0.779 AVG Training Acc 56.59 % AVG Validation Acc 42.40 %\n",
      "Epoch:60/200 AVG Training Loss:0.673 AVG Validation Loss:0.789 AVG Training Acc 58.30 % AVG Validation Acc 45.76 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.668 AVG Validation Loss:0.710 AVG Training Acc 59.92 % AVG Validation Acc 55.45 %\n",
      "Epoch:80/200 AVG Training Loss:0.668 AVG Validation Loss:0.689 AVG Training Acc 60.11 % AVG Validation Acc 59.62 %\n",
      "Epoch:90/200 AVG Training Loss:0.664 AVG Validation Loss:0.681 AVG Training Acc 60.15 % AVG Validation Acc 60.57 %\n",
      "Epoch:100/200 AVG Training Loss:0.664 AVG Validation Loss:0.679 AVG Training Acc 60.44 % AVG Validation Acc 60.57 %\n",
      "Epoch:110/200 AVG Training Loss:0.665 AVG Validation Loss:0.678 AVG Training Acc 60.35 % AVG Validation Acc 60.83 %\n",
      "Epoch:120/200 AVG Training Loss:0.663 AVG Validation Loss:0.678 AVG Training Acc 60.25 % AVG Validation Acc 60.03 %\n",
      "Epoch:130/200 AVG Training Loss:0.662 AVG Validation Loss:0.678 AVG Training Acc 60.23 % AVG Validation Acc 59.22 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:140/200 AVG Training Loss:0.662 AVG Validation Loss:0.678 AVG Training Acc 60.69 % AVG Validation Acc 58.95 %\n",
      "Epoch:150/200 AVG Training Loss:0.661 AVG Validation Loss:0.677 AVG Training Acc 61.14 % AVG Validation Acc 59.08 %\n",
      "Epoch:160/200 AVG Training Loss:0.661 AVG Validation Loss:0.676 AVG Training Acc 60.94 % AVG Validation Acc 59.08 %\n",
      "Epoch:170/200 AVG Training Loss:0.659 AVG Validation Loss:0.675 AVG Training Acc 61.05 % AVG Validation Acc 59.22 %\n",
      "Epoch:180/200 AVG Training Loss:0.661 AVG Validation Loss:0.674 AVG Training Acc 60.76 % AVG Validation Acc 59.22 %\n",
      "Epoch:190/200 AVG Training Loss:0.661 AVG Validation Loss:0.674 AVG Training Acc 60.89 % AVG Validation Acc 59.22 %\n",
      "Epoch:200/200 AVG Training Loss:0.661 AVG Validation Loss:0.673 AVG Training Acc 60.94 % AVG Validation Acc 59.35 %\n",
      "Split 158\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b34b7273eb94eac8fed902d75b5ed58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.538 AVG Validation Loss:4.562 AVG Training Acc 80.74 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.551 AVG Validation Loss:4.079 AVG Training Acc 76.85 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.462 AVG Validation Loss:4.438 AVG Training Acc 81.09 % AVG Validation Acc 20.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.605 AVG Validation Loss:9.828 AVG Training Acc 66.84 % AVG Validation Acc 20.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.593 AVG Validation Loss:3.083 AVG Training Acc 74.99 % AVG Validation Acc 20.05 %\n",
      "Epoch    50: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.687 AVG Validation Loss:0.801 AVG Training Acc 55.29 % AVG Validation Acc 26.11 %\n",
      "Epoch:70/200 AVG Training Loss:0.681 AVG Validation Loss:0.779 AVG Training Acc 57.46 % AVG Validation Acc 36.47 %\n",
      "Epoch:80/200 AVG Training Loss:0.678 AVG Validation Loss:0.776 AVG Training Acc 57.90 % AVG Validation Acc 37.95 %\n",
      "Epoch:90/200 AVG Training Loss:0.675 AVG Validation Loss:0.769 AVG Training Acc 58.69 % AVG Validation Acc 38.90 %\n",
      "Epoch:100/200 AVG Training Loss:0.667 AVG Validation Loss:0.769 AVG Training Acc 59.26 % AVG Validation Acc 40.65 %\n",
      "Epoch:110/200 AVG Training Loss:0.662 AVG Validation Loss:0.767 AVG Training Acc 61.09 % AVG Validation Acc 38.09 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:120/200 AVG Training Loss:0.668 AVG Validation Loss:0.751 AVG Training Acc 58.69 % AVG Validation Acc 43.07 %\n",
      "Epoch:130/200 AVG Training Loss:0.651 AVG Validation Loss:0.690 AVG Training Acc 61.74 % AVG Validation Acc 56.39 %\n",
      "Epoch:140/200 AVG Training Loss:0.647 AVG Validation Loss:0.674 AVG Training Acc 61.93 % AVG Validation Acc 59.76 %\n",
      "Epoch:150/200 AVG Training Loss:0.649 AVG Validation Loss:0.673 AVG Training Acc 61.82 % AVG Validation Acc 59.89 %\n",
      "Epoch:160/200 AVG Training Loss:0.648 AVG Validation Loss:0.674 AVG Training Acc 62.01 % AVG Validation Acc 60.16 %\n",
      "Epoch:170/200 AVG Training Loss:0.648 AVG Validation Loss:0.674 AVG Training Acc 62.17 % AVG Validation Acc 59.89 %\n",
      "Epoch   176: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:180/200 AVG Training Loss:0.646 AVG Validation Loss:0.674 AVG Training Acc 62.28 % AVG Validation Acc 59.49 %\n",
      "Epoch:190/200 AVG Training Loss:0.647 AVG Validation Loss:0.673 AVG Training Acc 62.20 % AVG Validation Acc 60.30 %\n",
      "Epoch:200/200 AVG Training Loss:0.643 AVG Validation Loss:0.672 AVG Training Acc 62.59 % AVG Validation Acc 60.03 %\n",
      "Split 159\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6e70b201bee48f8aa2b8df18238c787",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.498 AVG Validation Loss:6.441 AVG Training Acc 80.52 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.657 AVG Validation Loss:1.582 AVG Training Acc 65.40 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.629 AVG Validation Loss:2.038 AVG Training Acc 68.62 % AVG Validation Acc 20.05 %\n",
      "Epoch    33: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.698 AVG Validation Loss:0.763 AVG Training Acc 50.72 % AVG Validation Acc 20.86 %\n",
      "Epoch:50/200 AVG Training Loss:0.679 AVG Validation Loss:0.751 AVG Training Acc 57.56 % AVG Validation Acc 42.93 %\n",
      "Epoch:60/200 AVG Training Loss:0.677 AVG Validation Loss:0.748 AVG Training Acc 58.37 % AVG Validation Acc 46.43 %\n",
      "Epoch:70/200 AVG Training Loss:0.677 AVG Validation Loss:0.744 AVG Training Acc 58.48 % AVG Validation Acc 47.78 %\n",
      "Epoch:80/200 AVG Training Loss:0.673 AVG Validation Loss:0.740 AVG Training Acc 59.42 % AVG Validation Acc 48.72 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.673 AVG Validation Loss:0.736 AVG Training Acc 59.02 % AVG Validation Acc 50.47 %\n",
      "Epoch:100/200 AVG Training Loss:0.665 AVG Validation Loss:0.694 AVG Training Acc 60.66 % AVG Validation Acc 55.72 %\n",
      "Epoch:110/200 AVG Training Loss:0.664 AVG Validation Loss:0.677 AVG Training Acc 60.69 % AVG Validation Acc 58.41 %\n",
      "Epoch:120/200 AVG Training Loss:0.663 AVG Validation Loss:0.670 AVG Training Acc 61.03 % AVG Validation Acc 59.08 %\n",
      "Epoch:130/200 AVG Training Loss:0.661 AVG Validation Loss:0.667 AVG Training Acc 60.61 % AVG Validation Acc 59.08 %\n",
      "Epoch:140/200 AVG Training Loss:0.661 AVG Validation Loss:0.666 AVG Training Acc 60.90 % AVG Validation Acc 59.22 %\n",
      "Epoch:150/200 AVG Training Loss:0.663 AVG Validation Loss:0.665 AVG Training Acc 60.35 % AVG Validation Acc 59.62 %\n",
      "Epoch:160/200 AVG Training Loss:0.661 AVG Validation Loss:0.665 AVG Training Acc 60.73 % AVG Validation Acc 59.62 %\n",
      "Epoch:170/200 AVG Training Loss:0.662 AVG Validation Loss:0.664 AVG Training Acc 60.40 % AVG Validation Acc 59.22 %\n",
      "Epoch:180/200 AVG Training Loss:0.659 AVG Validation Loss:0.664 AVG Training Acc 61.19 % AVG Validation Acc 59.35 %\n",
      "Epoch:190/200 AVG Training Loss:0.660 AVG Validation Loss:0.664 AVG Training Acc 60.92 % AVG Validation Acc 59.35 %\n",
      "Epoch:200/200 AVG Training Loss:0.659 AVG Validation Loss:0.664 AVG Training Acc 60.86 % AVG Validation Acc 59.35 %\n",
      "Split 160\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff1e121ad9fe449eb043b4c6e880b06e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.421 AVG Validation Loss:5.150 AVG Training Acc 83.21 % AVG Validation Acc 20.19 %\n",
      "Epoch:20/200 AVG Training Loss:0.521 AVG Validation Loss:5.609 AVG Training Acc 81.21 % AVG Validation Acc 20.19 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.692 AVG Validation Loss:0.911 AVG Training Acc 55.32 % AVG Validation Acc 20.59 %\n",
      "Epoch:40/200 AVG Training Loss:0.673 AVG Validation Loss:1.090 AVG Training Acc 58.69 % AVG Validation Acc 21.80 %\n",
      "Epoch:50/200 AVG Training Loss:0.669 AVG Validation Loss:0.965 AVG Training Acc 60.19 % AVG Validation Acc 22.88 %\n",
      "Epoch    51: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.666 AVG Validation Loss:0.714 AVG Training Acc 59.67 % AVG Validation Acc 52.76 %\n",
      "Epoch:70/200 AVG Training Loss:0.661 AVG Validation Loss:0.698 AVG Training Acc 60.93 % AVG Validation Acc 55.72 %\n",
      "Epoch:80/200 AVG Training Loss:0.660 AVG Validation Loss:0.693 AVG Training Acc 61.32 % AVG Validation Acc 55.18 %\n",
      "Epoch:90/200 AVG Training Loss:0.659 AVG Validation Loss:0.692 AVG Training Acc 61.41 % AVG Validation Acc 54.64 %\n",
      "Epoch:100/200 AVG Training Loss:0.659 AVG Validation Loss:0.695 AVG Training Acc 61.49 % AVG Validation Acc 54.78 %\n",
      "Epoch   101: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.656 AVG Validation Loss:0.688 AVG Training Acc 62.16 % AVG Validation Acc 56.53 %\n",
      "Epoch:120/200 AVG Training Loss:0.654 AVG Validation Loss:0.685 AVG Training Acc 61.94 % AVG Validation Acc 56.66 %\n",
      "Epoch:130/200 AVG Training Loss:0.655 AVG Validation Loss:0.681 AVG Training Acc 61.82 % AVG Validation Acc 58.41 %\n",
      "Epoch:140/200 AVG Training Loss:0.654 AVG Validation Loss:0.678 AVG Training Acc 62.16 % AVG Validation Acc 57.60 %\n",
      "Epoch:150/200 AVG Training Loss:0.652 AVG Validation Loss:0.677 AVG Training Acc 62.29 % AVG Validation Acc 57.47 %\n",
      "Epoch:160/200 AVG Training Loss:0.654 AVG Validation Loss:0.676 AVG Training Acc 62.30 % AVG Validation Acc 57.34 %\n",
      "Epoch:170/200 AVG Training Loss:0.655 AVG Validation Loss:0.673 AVG Training Acc 61.89 % AVG Validation Acc 58.14 %\n",
      "Epoch:180/200 AVG Training Loss:0.652 AVG Validation Loss:0.674 AVG Training Acc 62.27 % AVG Validation Acc 57.87 %\n",
      "Epoch:190/200 AVG Training Loss:0.653 AVG Validation Loss:0.676 AVG Training Acc 62.28 % AVG Validation Acc 57.87 %\n",
      "Epoch   193: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:200/200 AVG Training Loss:0.653 AVG Validation Loss:0.676 AVG Training Acc 61.93 % AVG Validation Acc 58.14 %\n",
      "Split 161\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c5fae6f0bfa46979630d3cb7dfc509e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.502 AVG Validation Loss:4.563 AVG Training Acc 83.01 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.532 AVG Validation Loss:4.454 AVG Training Acc 82.26 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.628 AVG Validation Loss:1.678 AVG Training Acc 67.28 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.632 AVG Validation Loss:4.642 AVG Training Acc 70.53 % AVG Validation Acc 20.16 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.749 AVG Validation Loss:0.895 AVG Training Acc 50.07 % AVG Validation Acc 20.83 %\n",
      "Epoch:60/200 AVG Training Loss:0.680 AVG Validation Loss:0.771 AVG Training Acc 57.86 % AVG Validation Acc 30.65 %\n",
      "Epoch:70/200 AVG Training Loss:0.674 AVG Validation Loss:0.770 AVG Training Acc 58.87 % AVG Validation Acc 37.37 %\n",
      "Epoch    78: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.672 AVG Validation Loss:0.754 AVG Training Acc 58.03 % AVG Validation Acc 42.61 %\n",
      "Epoch:90/200 AVG Training Loss:0.666 AVG Validation Loss:0.705 AVG Training Acc 60.47 % AVG Validation Acc 56.05 %\n",
      "Epoch:100/200 AVG Training Loss:0.663 AVG Validation Loss:0.688 AVG Training Acc 60.96 % AVG Validation Acc 57.39 %\n",
      "Epoch:110/200 AVG Training Loss:0.661 AVG Validation Loss:0.683 AVG Training Acc 61.09 % AVG Validation Acc 58.60 %\n",
      "Epoch:120/200 AVG Training Loss:0.661 AVG Validation Loss:0.680 AVG Training Acc 61.17 % AVG Validation Acc 58.74 %\n",
      "Epoch:130/200 AVG Training Loss:0.660 AVG Validation Loss:0.679 AVG Training Acc 61.13 % AVG Validation Acc 58.87 %\n",
      "Epoch:140/200 AVG Training Loss:0.661 AVG Validation Loss:0.678 AVG Training Acc 61.40 % AVG Validation Acc 58.74 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.660 AVG Validation Loss:0.678 AVG Training Acc 61.26 % AVG Validation Acc 58.47 %\n",
      "Epoch:160/200 AVG Training Loss:0.660 AVG Validation Loss:0.677 AVG Training Acc 61.12 % AVG Validation Acc 58.47 %\n",
      "Epoch:170/200 AVG Training Loss:0.658 AVG Validation Loss:0.677 AVG Training Acc 61.96 % AVG Validation Acc 58.47 %\n",
      "Epoch:180/200 AVG Training Loss:0.660 AVG Validation Loss:0.676 AVG Training Acc 61.22 % AVG Validation Acc 58.74 %\n",
      "Epoch:190/200 AVG Training Loss:0.661 AVG Validation Loss:0.675 AVG Training Acc 61.36 % AVG Validation Acc 59.14 %\n",
      "Epoch:200/200 AVG Training Loss:0.658 AVG Validation Loss:0.675 AVG Training Acc 61.62 % AVG Validation Acc 59.14 %\n",
      "Split 162\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8114ff283cab4784b721069fa4345087",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.538 AVG Validation Loss:4.561 AVG Training Acc 80.84 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.649 AVG Validation Loss:1.588 AVG Training Acc 65.88 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.647 AVG Validation Loss:2.877 AVG Training Acc 65.24 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.644 AVG Validation Loss:5.489 AVG Training Acc 79.67 % AVG Validation Acc 20.16 %\n",
      "Epoch    47: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.806 AVG Validation Loss:0.976 AVG Training Acc 51.92 % AVG Validation Acc 20.30 %\n",
      "Epoch:60/200 AVG Training Loss:0.711 AVG Validation Loss:0.876 AVG Training Acc 55.67 % AVG Validation Acc 22.18 %\n",
      "Epoch:70/200 AVG Training Loss:0.678 AVG Validation Loss:0.876 AVG Training Acc 58.55 % AVG Validation Acc 22.85 %\n",
      "Epoch:80/200 AVG Training Loss:0.677 AVG Validation Loss:0.932 AVG Training Acc 57.13 % AVG Validation Acc 21.91 %\n",
      "Epoch    89: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.693 AVG Validation Loss:0.805 AVG Training Acc 55.03 % AVG Validation Acc 30.38 %\n",
      "Epoch:100/200 AVG Training Loss:0.666 AVG Validation Loss:0.717 AVG Training Acc 59.67 % AVG Validation Acc 51.75 %\n",
      "Epoch:110/200 AVG Training Loss:0.663 AVG Validation Loss:0.692 AVG Training Acc 60.36 % AVG Validation Acc 57.26 %\n",
      "Epoch:120/200 AVG Training Loss:0.661 AVG Validation Loss:0.692 AVG Training Acc 61.00 % AVG Validation Acc 56.32 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.655 AVG Validation Loss:0.685 AVG Training Acc 62.42 % AVG Validation Acc 56.85 %\n",
      "Epoch:140/200 AVG Training Loss:0.657 AVG Validation Loss:0.685 AVG Training Acc 61.61 % AVG Validation Acc 57.66 %\n",
      "Epoch:150/200 AVG Training Loss:0.655 AVG Validation Loss:0.680 AVG Training Acc 61.83 % AVG Validation Acc 58.20 %\n",
      "Epoch:160/200 AVG Training Loss:0.657 AVG Validation Loss:0.679 AVG Training Acc 61.18 % AVG Validation Acc 58.06 %\n",
      "Epoch:170/200 AVG Training Loss:0.656 AVG Validation Loss:0.678 AVG Training Acc 61.96 % AVG Validation Acc 57.39 %\n",
      "Epoch:180/200 AVG Training Loss:0.656 AVG Validation Loss:0.678 AVG Training Acc 61.76 % AVG Validation Acc 58.06 %\n",
      "Epoch:190/200 AVG Training Loss:0.657 AVG Validation Loss:0.676 AVG Training Acc 62.11 % AVG Validation Acc 59.01 %\n",
      "Epoch:200/200 AVG Training Loss:0.658 AVG Validation Loss:0.673 AVG Training Acc 61.87 % AVG Validation Acc 58.87 %\n",
      "Split 163\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f063fe618d9242a1bf5c8f9b2340ce5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.425 AVG Validation Loss:5.148 AVG Training Acc 82.42 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.549 AVG Validation Loss:6.948 AVG Training Acc 79.92 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.550 AVG Validation Loss:10.151 AVG Training Acc 71.07 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.623 AVG Validation Loss:2.028 AVG Training Acc 67.75 % AVG Validation Acc 20.16 %\n",
      "Epoch    48: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.667 AVG Validation Loss:1.322 AVG Training Acc 65.75 % AVG Validation Acc 22.85 %\n",
      "Epoch:60/200 AVG Training Loss:0.680 AVG Validation Loss:0.943 AVG Training Acc 58.11 % AVG Validation Acc 22.98 %\n",
      "Epoch:70/200 AVG Training Loss:0.672 AVG Validation Loss:0.872 AVG Training Acc 59.25 % AVG Validation Acc 21.91 %\n",
      "Epoch    79: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.713 AVG Validation Loss:0.872 AVG Training Acc 52.22 % AVG Validation Acc 23.66 %\n",
      "Epoch:90/200 AVG Training Loss:0.665 AVG Validation Loss:0.712 AVG Training Acc 60.54 % AVG Validation Acc 56.05 %\n",
      "Epoch:100/200 AVG Training Loss:0.660 AVG Validation Loss:0.695 AVG Training Acc 61.29 % AVG Validation Acc 57.93 %\n",
      "Epoch:110/200 AVG Training Loss:0.661 AVG Validation Loss:0.693 AVG Training Acc 61.10 % AVG Validation Acc 57.39 %\n",
      "Epoch   119: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.657 AVG Validation Loss:0.693 AVG Training Acc 61.33 % AVG Validation Acc 57.26 %\n",
      "Epoch:130/200 AVG Training Loss:0.658 AVG Validation Loss:0.689 AVG Training Acc 61.48 % AVG Validation Acc 57.80 %\n",
      "Epoch:140/200 AVG Training Loss:0.658 AVG Validation Loss:0.686 AVG Training Acc 61.85 % AVG Validation Acc 58.33 %\n",
      "Epoch:150/200 AVG Training Loss:0.657 AVG Validation Loss:0.684 AVG Training Acc 61.35 % AVG Validation Acc 58.47 %\n",
      "Epoch:160/200 AVG Training Loss:0.657 AVG Validation Loss:0.683 AVG Training Acc 61.64 % AVG Validation Acc 58.60 %\n",
      "Epoch:170/200 AVG Training Loss:0.659 AVG Validation Loss:0.681 AVG Training Acc 61.75 % AVG Validation Acc 59.01 %\n",
      "Epoch:180/200 AVG Training Loss:0.658 AVG Validation Loss:0.680 AVG Training Acc 61.38 % AVG Validation Acc 59.01 %\n",
      "Epoch:190/200 AVG Training Loss:0.656 AVG Validation Loss:0.680 AVG Training Acc 61.72 % AVG Validation Acc 59.27 %\n",
      "Epoch:200/200 AVG Training Loss:0.656 AVG Validation Loss:0.678 AVG Training Acc 61.52 % AVG Validation Acc 59.14 %\n",
      "Split 164\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623e4b549896408686c6de02d43e35de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.431 AVG Validation Loss:4.807 AVG Training Acc 82.98 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.500 AVG Validation Loss:3.736 AVG Training Acc 77.77 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.577 AVG Validation Loss:11.374 AVG Training Acc 67.98 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.631 AVG Validation Loss:1.697 AVG Training Acc 70.35 % AVG Validation Acc 20.16 %\n",
      "Epoch    49: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:1.165 AVG Validation Loss:2.018 AVG Training Acc 59.41 % AVG Validation Acc 20.56 %\n",
      "Epoch:60/200 AVG Training Loss:0.649 AVG Validation Loss:1.542 AVG Training Acc 63.97 % AVG Validation Acc 20.30 %\n",
      "Epoch:70/200 AVG Training Loss:0.683 AVG Validation Loss:1.190 AVG Training Acc 60.53 % AVG Validation Acc 20.16 %\n",
      "Epoch:80/200 AVG Training Loss:0.695 AVG Validation Loss:1.169 AVG Training Acc 62.11 % AVG Validation Acc 20.16 %\n",
      "Epoch:90/200 AVG Training Loss:0.681 AVG Validation Loss:1.132 AVG Training Acc 60.22 % AVG Validation Acc 20.16 %\n",
      "Epoch:100/200 AVG Training Loss:0.682 AVG Validation Loss:1.097 AVG Training Acc 59.45 % AVG Validation Acc 20.43 %\n",
      "Epoch:110/200 AVG Training Loss:0.676 AVG Validation Loss:1.071 AVG Training Acc 59.67 % AVG Validation Acc 20.83 %\n",
      "Epoch:120/200 AVG Training Loss:0.674 AVG Validation Loss:1.137 AVG Training Acc 59.53 % AVG Validation Acc 20.97 %\n",
      "Epoch:130/200 AVG Training Loss:0.680 AVG Validation Loss:1.015 AVG Training Acc 59.31 % AVG Validation Acc 20.70 %\n",
      "Epoch   137: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:140/200 AVG Training Loss:0.724 AVG Validation Loss:0.853 AVG Training Acc 51.89 % AVG Validation Acc 23.92 %\n",
      "Epoch:150/200 AVG Training Loss:0.682 AVG Validation Loss:0.711 AVG Training Acc 55.35 % AVG Validation Acc 45.16 %\n",
      "Epoch:160/200 AVG Training Loss:0.682 AVG Validation Loss:0.708 AVG Training Acc 55.83 % AVG Validation Acc 47.72 %\n",
      "Epoch:170/200 AVG Training Loss:0.683 AVG Validation Loss:0.705 AVG Training Acc 55.72 % AVG Validation Acc 46.91 %\n",
      "Epoch:180/200 AVG Training Loss:0.682 AVG Validation Loss:0.705 AVG Training Acc 55.62 % AVG Validation Acc 47.45 %\n",
      "Epoch:190/200 AVG Training Loss:0.680 AVG Validation Loss:0.707 AVG Training Acc 56.20 % AVG Validation Acc 47.72 %\n",
      "Epoch   190: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:200/200 AVG Training Loss:0.680 AVG Validation Loss:0.696 AVG Training Acc 56.15 % AVG Validation Acc 50.81 %\n",
      "Split 165\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29fc335717e64992a890a70446b0f694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.540 AVG Validation Loss:8.868 AVG Training Acc 76.34 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.644 AVG Validation Loss:1.690 AVG Training Acc 67.22 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.643 AVG Validation Loss:1.641 AVG Training Acc 66.59 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.580 AVG Validation Loss:3.276 AVG Training Acc 75.82 % AVG Validation Acc 20.16 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.699 AVG Validation Loss:0.766 AVG Training Acc 49.34 % AVG Validation Acc 23.79 %\n",
      "Epoch:60/200 AVG Training Loss:0.689 AVG Validation Loss:0.751 AVG Training Acc 54.03 % AVG Validation Acc 23.12 %\n",
      "Epoch:70/200 AVG Training Loss:0.680 AVG Validation Loss:0.760 AVG Training Acc 56.70 % AVG Validation Acc 32.80 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.674 AVG Validation Loss:0.724 AVG Training Acc 56.90 % AVG Validation Acc 49.60 %\n",
      "Epoch:90/200 AVG Training Loss:0.670 AVG Validation Loss:0.694 AVG Training Acc 59.06 % AVG Validation Acc 57.26 %\n",
      "Epoch:100/200 AVG Training Loss:0.671 AVG Validation Loss:0.683 AVG Training Acc 58.52 % AVG Validation Acc 60.08 %\n",
      "Epoch:110/200 AVG Training Loss:0.669 AVG Validation Loss:0.680 AVG Training Acc 59.01 % AVG Validation Acc 60.89 %\n",
      "Epoch:120/200 AVG Training Loss:0.670 AVG Validation Loss:0.678 AVG Training Acc 59.32 % AVG Validation Acc 61.02 %\n",
      "Epoch:130/200 AVG Training Loss:0.669 AVG Validation Loss:0.677 AVG Training Acc 59.24 % AVG Validation Acc 61.56 %\n",
      "Epoch:140/200 AVG Training Loss:0.666 AVG Validation Loss:0.677 AVG Training Acc 59.67 % AVG Validation Acc 62.10 %\n",
      "Epoch   140: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.666 AVG Validation Loss:0.676 AVG Training Acc 59.65 % AVG Validation Acc 61.83 %\n",
      "Epoch:160/200 AVG Training Loss:0.665 AVG Validation Loss:0.675 AVG Training Acc 59.93 % AVG Validation Acc 62.10 %\n",
      "Epoch:170/200 AVG Training Loss:0.666 AVG Validation Loss:0.674 AVG Training Acc 60.34 % AVG Validation Acc 62.10 %\n",
      "Epoch:180/200 AVG Training Loss:0.666 AVG Validation Loss:0.674 AVG Training Acc 59.93 % AVG Validation Acc 62.37 %\n",
      "Epoch:190/200 AVG Training Loss:0.665 AVG Validation Loss:0.674 AVG Training Acc 59.44 % AVG Validation Acc 62.10 %\n",
      "Epoch:200/200 AVG Training Loss:0.665 AVG Validation Loss:0.673 AVG Training Acc 59.58 % AVG Validation Acc 62.37 %\n",
      "Split 166\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a100c6334d1d4ef4a13755a1df96b514",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.481 AVG Validation Loss:5.140 AVG Training Acc 82.92 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.590 AVG Validation Loss:4.174 AVG Training Acc 73.38 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.593 AVG Validation Loss:9.836 AVG Training Acc 67.10 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.646 AVG Validation Loss:1.568 AVG Training Acc 65.76 % AVG Validation Acc 20.56 %\n",
      "Epoch:50/200 AVG Training Loss:0.671 AVG Validation Loss:2.101 AVG Training Acc 74.67 % AVG Validation Acc 20.56 %\n",
      "Epoch    53: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:60/200 AVG Training Loss:0.681 AVG Validation Loss:0.881 AVG Training Acc 57.66 % AVG Validation Acc 29.70 %\n",
      "Epoch:70/200 AVG Training Loss:0.666 AVG Validation Loss:0.912 AVG Training Acc 60.30 % AVG Validation Acc 34.27 %\n",
      "Epoch:80/200 AVG Training Loss:0.666 AVG Validation Loss:0.879 AVG Training Acc 60.74 % AVG Validation Acc 36.69 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.662 AVG Validation Loss:0.743 AVG Training Acc 61.77 % AVG Validation Acc 50.00 %\n",
      "Epoch:100/200 AVG Training Loss:0.656 AVG Validation Loss:0.704 AVG Training Acc 62.65 % AVG Validation Acc 55.24 %\n",
      "Epoch:110/200 AVG Training Loss:0.658 AVG Validation Loss:0.697 AVG Training Acc 62.69 % AVG Validation Acc 55.91 %\n",
      "Epoch:120/200 AVG Training Loss:0.655 AVG Validation Loss:0.697 AVG Training Acc 63.12 % AVG Validation Acc 56.05 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.654 AVG Validation Loss:0.696 AVG Training Acc 62.86 % AVG Validation Acc 56.32 %\n",
      "Epoch:140/200 AVG Training Loss:0.654 AVG Validation Loss:0.693 AVG Training Acc 62.58 % AVG Validation Acc 56.85 %\n",
      "Epoch:150/200 AVG Training Loss:0.655 AVG Validation Loss:0.692 AVG Training Acc 62.63 % AVG Validation Acc 56.85 %\n",
      "Epoch:160/200 AVG Training Loss:0.655 AVG Validation Loss:0.690 AVG Training Acc 62.63 % AVG Validation Acc 56.99 %\n",
      "Epoch:170/200 AVG Training Loss:0.654 AVG Validation Loss:0.689 AVG Training Acc 62.63 % AVG Validation Acc 57.26 %\n",
      "Epoch:180/200 AVG Training Loss:0.654 AVG Validation Loss:0.688 AVG Training Acc 62.96 % AVG Validation Acc 56.85 %\n",
      "Epoch:190/200 AVG Training Loss:0.654 AVG Validation Loss:0.687 AVG Training Acc 63.12 % AVG Validation Acc 57.80 %\n",
      "Epoch:200/200 AVG Training Loss:0.654 AVG Validation Loss:0.687 AVG Training Acc 63.20 % AVG Validation Acc 57.39 %\n",
      "Split 167\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfc0e7b147354298a2b6d4c7a5e6c596",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.504 AVG Validation Loss:4.688 AVG Training Acc 81.92 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.609 AVG Validation Loss:5.231 AVG Training Acc 81.75 % AVG Validation Acc 20.05 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:1.218 AVG Validation Loss:1.311 AVG Training Acc 50.06 % AVG Validation Acc 20.46 %\n",
      "Epoch:40/200 AVG Training Loss:0.682 AVG Validation Loss:0.810 AVG Training Acc 55.86 % AVG Validation Acc 25.84 %\n",
      "Epoch:50/200 AVG Training Loss:0.676 AVG Validation Loss:0.788 AVG Training Acc 57.61 % AVG Validation Acc 32.30 %\n",
      "Epoch:60/200 AVG Training Loss:0.669 AVG Validation Loss:0.790 AVG Training Acc 59.47 % AVG Validation Acc 34.99 %\n",
      "Epoch:70/200 AVG Training Loss:0.667 AVG Validation Loss:0.777 AVG Training Acc 59.72 % AVG Validation Acc 40.38 %\n",
      "Epoch:80/200 AVG Training Loss:0.661 AVG Validation Loss:0.774 AVG Training Acc 60.72 % AVG Validation Acc 42.66 %\n",
      "Epoch:90/200 AVG Training Loss:0.658 AVG Validation Loss:0.774 AVG Training Acc 61.08 % AVG Validation Acc 41.72 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.656 AVG Validation Loss:0.742 AVG Training Acc 60.73 % AVG Validation Acc 47.91 %\n",
      "Epoch:110/200 AVG Training Loss:0.646 AVG Validation Loss:0.694 AVG Training Acc 63.04 % AVG Validation Acc 56.66 %\n",
      "Epoch:120/200 AVG Training Loss:0.646 AVG Validation Loss:0.685 AVG Training Acc 62.48 % AVG Validation Acc 57.87 %\n",
      "Epoch:130/200 AVG Training Loss:0.641 AVG Validation Loss:0.680 AVG Training Acc 62.93 % AVG Validation Acc 58.01 %\n",
      "Epoch:140/200 AVG Training Loss:0.643 AVG Validation Loss:0.678 AVG Training Acc 62.92 % AVG Validation Acc 57.74 %\n",
      "Epoch:150/200 AVG Training Loss:0.639 AVG Validation Loss:0.677 AVG Training Acc 63.58 % AVG Validation Acc 58.41 %\n",
      "Epoch   157: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:160/200 AVG Training Loss:0.637 AVG Validation Loss:0.677 AVG Training Acc 63.70 % AVG Validation Acc 57.34 %\n",
      "Epoch:170/200 AVG Training Loss:0.641 AVG Validation Loss:0.676 AVG Training Acc 63.46 % AVG Validation Acc 58.01 %\n",
      "Epoch:180/200 AVG Training Loss:0.637 AVG Validation Loss:0.675 AVG Training Acc 63.45 % AVG Validation Acc 58.28 %\n",
      "Epoch:190/200 AVG Training Loss:0.639 AVG Validation Loss:0.674 AVG Training Acc 63.26 % AVG Validation Acc 58.68 %\n",
      "Epoch:200/200 AVG Training Loss:0.637 AVG Validation Loss:0.673 AVG Training Acc 63.33 % AVG Validation Acc 58.82 %\n",
      "Split 168\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e45405ebdf074beca46d069795585650",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.548 AVG Validation Loss:3.895 AVG Training Acc 78.71 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.586 AVG Validation Loss:3.617 AVG Training Acc 75.95 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.557 AVG Validation Loss:5.769 AVG Training Acc 79.74 % AVG Validation Acc 20.05 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.711 AVG Validation Loss:0.818 AVG Training Acc 48.92 % AVG Validation Acc 22.34 %\n",
      "Epoch:50/200 AVG Training Loss:0.679 AVG Validation Loss:0.831 AVG Training Acc 57.35 % AVG Validation Acc 33.24 %\n",
      "Epoch:60/200 AVG Training Loss:0.673 AVG Validation Loss:0.829 AVG Training Acc 59.86 % AVG Validation Acc 37.55 %\n",
      "Epoch    68: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.678 AVG Validation Loss:0.777 AVG Training Acc 58.08 % AVG Validation Acc 45.36 %\n",
      "Epoch:80/200 AVG Training Loss:0.660 AVG Validation Loss:0.696 AVG Training Acc 61.02 % AVG Validation Acc 56.12 %\n",
      "Epoch:90/200 AVG Training Loss:0.657 AVG Validation Loss:0.681 AVG Training Acc 61.38 % AVG Validation Acc 58.41 %\n",
      "Epoch:100/200 AVG Training Loss:0.657 AVG Validation Loss:0.678 AVG Training Acc 61.18 % AVG Validation Acc 58.68 %\n",
      "Epoch:110/200 AVG Training Loss:0.656 AVG Validation Loss:0.676 AVG Training Acc 60.74 % AVG Validation Acc 58.82 %\n",
      "Epoch:120/200 AVG Training Loss:0.658 AVG Validation Loss:0.677 AVG Training Acc 61.49 % AVG Validation Acc 58.55 %\n",
      "Epoch   121: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.653 AVG Validation Loss:0.674 AVG Training Acc 61.95 % AVG Validation Acc 59.35 %\n",
      "Epoch:140/200 AVG Training Loss:0.656 AVG Validation Loss:0.673 AVG Training Acc 61.51 % AVG Validation Acc 59.08 %\n",
      "Epoch:150/200 AVG Training Loss:0.653 AVG Validation Loss:0.671 AVG Training Acc 61.41 % AVG Validation Acc 59.62 %\n",
      "Epoch:160/200 AVG Training Loss:0.654 AVG Validation Loss:0.670 AVG Training Acc 61.70 % AVG Validation Acc 59.89 %\n",
      "Epoch:170/200 AVG Training Loss:0.656 AVG Validation Loss:0.669 AVG Training Acc 61.42 % AVG Validation Acc 60.16 %\n",
      "Epoch:180/200 AVG Training Loss:0.655 AVG Validation Loss:0.668 AVG Training Acc 61.20 % AVG Validation Acc 60.03 %\n",
      "Epoch:190/200 AVG Training Loss:0.653 AVG Validation Loss:0.667 AVG Training Acc 61.26 % AVG Validation Acc 60.03 %\n",
      "Epoch:200/200 AVG Training Loss:0.654 AVG Validation Loss:0.667 AVG Training Acc 61.31 % AVG Validation Acc 60.16 %\n",
      "Split 169\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81c1bc2d12c34fe9a49df22e06686a18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.574 AVG Validation Loss:3.635 AVG Training Acc 76.58 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.644 AVG Validation Loss:1.686 AVG Training Acc 66.91 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.601 AVG Validation Loss:2.239 AVG Training Acc 72.50 % AVG Validation Acc 20.05 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.688 AVG Validation Loss:0.806 AVG Training Acc 54.02 % AVG Validation Acc 22.88 %\n",
      "Epoch:50/200 AVG Training Loss:0.681 AVG Validation Loss:0.794 AVG Training Acc 57.20 % AVG Validation Acc 38.63 %\n",
      "Epoch:60/200 AVG Training Loss:0.676 AVG Validation Loss:0.796 AVG Training Acc 58.42 % AVG Validation Acc 43.74 %\n",
      "Epoch:70/200 AVG Training Loss:0.673 AVG Validation Loss:0.794 AVG Training Acc 59.26 % AVG Validation Acc 44.68 %\n",
      "Epoch:80/200 AVG Training Loss:0.670 AVG Validation Loss:0.796 AVG Training Acc 59.52 % AVG Validation Acc 44.15 %\n",
      "Epoch    80: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.661 AVG Validation Loss:0.706 AVG Training Acc 61.13 % AVG Validation Acc 56.93 %\n",
      "Epoch:100/200 AVG Training Loss:0.660 AVG Validation Loss:0.685 AVG Training Acc 61.21 % AVG Validation Acc 59.35 %\n",
      "Epoch:110/200 AVG Training Loss:0.660 AVG Validation Loss:0.680 AVG Training Acc 61.21 % AVG Validation Acc 59.49 %\n",
      "Epoch:120/200 AVG Training Loss:0.659 AVG Validation Loss:0.678 AVG Training Acc 61.22 % AVG Validation Acc 59.89 %\n",
      "Epoch:130/200 AVG Training Loss:0.658 AVG Validation Loss:0.677 AVG Training Acc 61.75 % AVG Validation Acc 60.43 %\n",
      "Epoch   134: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:140/200 AVG Training Loss:0.656 AVG Validation Loss:0.677 AVG Training Acc 61.41 % AVG Validation Acc 60.03 %\n",
      "Epoch:150/200 AVG Training Loss:0.657 AVG Validation Loss:0.676 AVG Training Acc 61.52 % AVG Validation Acc 60.30 %\n",
      "Epoch:160/200 AVG Training Loss:0.654 AVG Validation Loss:0.675 AVG Training Acc 61.84 % AVG Validation Acc 60.57 %\n",
      "Epoch:170/200 AVG Training Loss:0.654 AVG Validation Loss:0.674 AVG Training Acc 61.27 % AVG Validation Acc 60.83 %\n",
      "Epoch:180/200 AVG Training Loss:0.655 AVG Validation Loss:0.673 AVG Training Acc 61.95 % AVG Validation Acc 60.70 %\n",
      "Epoch:190/200 AVG Training Loss:0.654 AVG Validation Loss:0.673 AVG Training Acc 61.61 % AVG Validation Acc 61.10 %\n",
      "Epoch:200/200 AVG Training Loss:0.655 AVG Validation Loss:0.672 AVG Training Acc 61.72 % AVG Validation Acc 61.10 %\n",
      "Split 170\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33704244cc2a4ba38ab540c780963185",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.516 AVG Validation Loss:4.602 AVG Training Acc 81.27 % AVG Validation Acc 20.19 %\n",
      "Epoch:20/200 AVG Training Loss:0.514 AVG Validation Loss:7.049 AVG Training Acc 81.60 % AVG Validation Acc 20.19 %\n",
      "Epoch:30/200 AVG Training Loss:0.586 AVG Validation Loss:2.552 AVG Training Acc 76.39 % AVG Validation Acc 20.19 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.812 AVG Validation Loss:0.953 AVG Training Acc 50.28 % AVG Validation Acc 20.86 %\n",
      "Epoch:50/200 AVG Training Loss:0.695 AVG Validation Loss:0.771 AVG Training Acc 50.54 % AVG Validation Acc 21.80 %\n",
      "Epoch:60/200 AVG Training Loss:0.686 AVG Validation Loss:0.774 AVG Training Acc 54.82 % AVG Validation Acc 26.51 %\n",
      "Epoch:70/200 AVG Training Loss:0.685 AVG Validation Loss:0.764 AVG Training Acc 55.33 % AVG Validation Acc 36.61 %\n",
      "Epoch:80/200 AVG Training Loss:0.680 AVG Validation Loss:0.763 AVG Training Acc 57.09 % AVG Validation Acc 41.05 %\n",
      "Epoch:90/200 AVG Training Loss:0.678 AVG Validation Loss:0.758 AVG Training Acc 57.65 % AVG Validation Acc 44.41 %\n",
      "Epoch:100/200 AVG Training Loss:0.674 AVG Validation Loss:0.756 AVG Training Acc 58.01 % AVG Validation Acc 44.95 %\n",
      "Epoch:110/200 AVG Training Loss:0.669 AVG Validation Loss:0.751 AVG Training Acc 59.08 % AVG Validation Acc 46.43 %\n",
      "Epoch:120/200 AVG Training Loss:0.665 AVG Validation Loss:0.750 AVG Training Acc 59.39 % AVG Validation Acc 47.11 %\n",
      "Epoch:130/200 AVG Training Loss:0.661 AVG Validation Loss:0.751 AVG Training Acc 59.91 % AVG Validation Acc 47.11 %\n",
      "Epoch   131: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:140/200 AVG Training Loss:0.655 AVG Validation Loss:0.711 AVG Training Acc 60.39 % AVG Validation Acc 57.20 %\n",
      "Epoch:150/200 AVG Training Loss:0.651 AVG Validation Loss:0.694 AVG Training Acc 60.91 % AVG Validation Acc 59.76 %\n",
      "Epoch:160/200 AVG Training Loss:0.653 AVG Validation Loss:0.687 AVG Training Acc 61.08 % AVG Validation Acc 60.70 %\n",
      "Epoch:170/200 AVG Training Loss:0.651 AVG Validation Loss:0.686 AVG Training Acc 61.06 % AVG Validation Acc 60.57 %\n",
      "Epoch:180/200 AVG Training Loss:0.651 AVG Validation Loss:0.687 AVG Training Acc 61.44 % AVG Validation Acc 61.24 %\n",
      "Epoch:190/200 AVG Training Loss:0.649 AVG Validation Loss:0.685 AVG Training Acc 61.05 % AVG Validation Acc 61.10 %\n",
      "Epoch   198: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:200/200 AVG Training Loss:0.649 AVG Validation Loss:0.692 AVG Training Acc 61.23 % AVG Validation Acc 61.37 %\n",
      "Split 171\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d012a034ad14f069741819c345a3615",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.481 AVG Validation Loss:5.882 AVG Training Acc 80.97 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.599 AVG Validation Loss:2.937 AVG Training Acc 73.77 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.647 AVG Validation Loss:1.781 AVG Training Acc 66.17 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.701 AVG Validation Loss:6.303 AVG Training Acc 75.29 % AVG Validation Acc 20.16 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.698 AVG Validation Loss:0.770 AVG Training Acc 50.37 % AVG Validation Acc 20.97 %\n",
      "Epoch:60/200 AVG Training Loss:0.679 AVG Validation Loss:0.761 AVG Training Acc 57.27 % AVG Validation Acc 35.08 %\n",
      "Epoch:70/200 AVG Training Loss:0.676 AVG Validation Loss:0.766 AVG Training Acc 58.70 % AVG Validation Acc 34.95 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.671 AVG Validation Loss:0.730 AVG Training Acc 58.44 % AVG Validation Acc 50.81 %\n",
      "Epoch:90/200 AVG Training Loss:0.669 AVG Validation Loss:0.700 AVG Training Acc 59.64 % AVG Validation Acc 55.78 %\n",
      "Epoch:100/200 AVG Training Loss:0.665 AVG Validation Loss:0.691 AVG Training Acc 59.75 % AVG Validation Acc 56.72 %\n",
      "Epoch:110/200 AVG Training Loss:0.664 AVG Validation Loss:0.688 AVG Training Acc 60.30 % AVG Validation Acc 56.85 %\n",
      "Epoch:120/200 AVG Training Loss:0.664 AVG Validation Loss:0.688 AVG Training Acc 60.48 % AVG Validation Acc 57.12 %\n",
      "Epoch:130/200 AVG Training Loss:0.664 AVG Validation Loss:0.688 AVG Training Acc 60.33 % AVG Validation Acc 57.12 %\n",
      "Epoch   134: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:140/200 AVG Training Loss:0.662 AVG Validation Loss:0.687 AVG Training Acc 60.59 % AVG Validation Acc 57.26 %\n",
      "Epoch:150/200 AVG Training Loss:0.662 AVG Validation Loss:0.686 AVG Training Acc 60.70 % AVG Validation Acc 57.12 %\n",
      "Epoch:160/200 AVG Training Loss:0.662 AVG Validation Loss:0.685 AVG Training Acc 60.74 % AVG Validation Acc 57.12 %\n",
      "Epoch:170/200 AVG Training Loss:0.662 AVG Validation Loss:0.684 AVG Training Acc 60.94 % AVG Validation Acc 57.12 %\n",
      "Epoch:180/200 AVG Training Loss:0.661 AVG Validation Loss:0.683 AVG Training Acc 60.92 % AVG Validation Acc 57.39 %\n",
      "Epoch:190/200 AVG Training Loss:0.661 AVG Validation Loss:0.683 AVG Training Acc 60.44 % AVG Validation Acc 57.53 %\n",
      "Epoch:200/200 AVG Training Loss:0.663 AVG Validation Loss:0.682 AVG Training Acc 60.70 % AVG Validation Acc 57.39 %\n",
      "Split 172\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f199d2d007646da92da1aa894ac2de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.557 AVG Validation Loss:7.474 AVG Training Acc 71.08 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.613 AVG Validation Loss:2.911 AVG Training Acc 71.96 % AVG Validation Acc 20.16 %\n",
      "Epoch    20: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.698 AVG Validation Loss:0.834 AVG Training Acc 52.81 % AVG Validation Acc 22.45 %\n",
      "Epoch:40/200 AVG Training Loss:0.677 AVG Validation Loss:0.816 AVG Training Acc 58.19 % AVG Validation Acc 24.06 %\n",
      "Epoch:50/200 AVG Training Loss:0.673 AVG Validation Loss:0.799 AVG Training Acc 59.63 % AVG Validation Acc 27.42 %\n",
      "Epoch:60/200 AVG Training Loss:0.669 AVG Validation Loss:0.796 AVG Training Acc 59.88 % AVG Validation Acc 35.08 %\n",
      "Epoch:70/200 AVG Training Loss:0.664 AVG Validation Loss:0.789 AVG Training Acc 60.68 % AVG Validation Acc 38.98 %\n",
      "Epoch:80/200 AVG Training Loss:0.660 AVG Validation Loss:0.816 AVG Training Acc 61.43 % AVG Validation Acc 34.81 %\n",
      "Epoch    82: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.656 AVG Validation Loss:0.703 AVG Training Acc 61.72 % AVG Validation Acc 53.90 %\n",
      "Epoch:100/200 AVG Training Loss:0.652 AVG Validation Loss:0.680 AVG Training Acc 62.25 % AVG Validation Acc 56.85 %\n",
      "Epoch:110/200 AVG Training Loss:0.651 AVG Validation Loss:0.675 AVG Training Acc 62.27 % AVG Validation Acc 56.85 %\n",
      "Epoch:120/200 AVG Training Loss:0.649 AVG Validation Loss:0.671 AVG Training Acc 62.00 % AVG Validation Acc 57.53 %\n",
      "Epoch:130/200 AVG Training Loss:0.648 AVG Validation Loss:0.671 AVG Training Acc 62.07 % AVG Validation Acc 56.85 %\n",
      "Epoch   133: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:140/200 AVG Training Loss:0.649 AVG Validation Loss:0.671 AVG Training Acc 62.38 % AVG Validation Acc 57.53 %\n",
      "Epoch:150/200 AVG Training Loss:0.649 AVG Validation Loss:0.667 AVG Training Acc 62.66 % AVG Validation Acc 58.20 %\n",
      "Epoch:160/200 AVG Training Loss:0.647 AVG Validation Loss:0.664 AVG Training Acc 62.83 % AVG Validation Acc 58.47 %\n",
      "Epoch:170/200 AVG Training Loss:0.646 AVG Validation Loss:0.661 AVG Training Acc 62.40 % AVG Validation Acc 58.33 %\n",
      "Epoch:180/200 AVG Training Loss:0.647 AVG Validation Loss:0.661 AVG Training Acc 62.67 % AVG Validation Acc 59.14 %\n",
      "Epoch   181: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:190/200 AVG Training Loss:0.647 AVG Validation Loss:0.663 AVG Training Acc 62.70 % AVG Validation Acc 58.33 %\n",
      "Epoch:200/200 AVG Training Loss:0.646 AVG Validation Loss:0.661 AVG Training Acc 62.94 % AVG Validation Acc 58.47 %\n",
      "Split 173\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5401aa40fba24ca68ecfa518a2dca504",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.502 AVG Validation Loss:4.700 AVG Training Acc 81.79 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.552 AVG Validation Loss:4.355 AVG Training Acc 81.24 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.638 AVG Validation Loss:2.378 AVG Training Acc 70.04 % AVG Validation Acc 20.16 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.632 AVG Validation Loss:1.846 AVG Training Acc 69.16 % AVG Validation Acc 20.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.643 AVG Validation Loss:1.580 AVG Training Acc 66.32 % AVG Validation Acc 20.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.643 AVG Validation Loss:1.522 AVG Training Acc 65.62 % AVG Validation Acc 20.16 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.862 AVG Validation Loss:1.101 AVG Training Acc 50.18 % AVG Validation Acc 20.30 %\n",
      "Epoch:80/200 AVG Training Loss:0.676 AVG Validation Loss:0.730 AVG Training Acc 58.40 % AVG Validation Acc 49.87 %\n",
      "Epoch:90/200 AVG Training Loss:0.671 AVG Validation Loss:0.730 AVG Training Acc 59.49 % AVG Validation Acc 50.81 %\n",
      "Epoch:100/200 AVG Training Loss:0.669 AVG Validation Loss:0.731 AVG Training Acc 59.92 % AVG Validation Acc 51.21 %\n",
      "Epoch   100: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.664 AVG Validation Loss:0.712 AVG Training Acc 60.58 % AVG Validation Acc 52.96 %\n",
      "Epoch:120/200 AVG Training Loss:0.662 AVG Validation Loss:0.701 AVG Training Acc 60.72 % AVG Validation Acc 55.51 %\n",
      "Epoch:130/200 AVG Training Loss:0.665 AVG Validation Loss:0.695 AVG Training Acc 60.55 % AVG Validation Acc 56.72 %\n",
      "Epoch:140/200 AVG Training Loss:0.665 AVG Validation Loss:0.690 AVG Training Acc 60.10 % AVG Validation Acc 57.12 %\n",
      "Epoch:150/200 AVG Training Loss:0.663 AVG Validation Loss:0.689 AVG Training Acc 60.86 % AVG Validation Acc 57.12 %\n",
      "Epoch:160/200 AVG Training Loss:0.665 AVG Validation Loss:0.687 AVG Training Acc 60.76 % AVG Validation Acc 57.66 %\n",
      "Epoch:170/200 AVG Training Loss:0.663 AVG Validation Loss:0.686 AVG Training Acc 60.83 % AVG Validation Acc 57.53 %\n",
      "Epoch:180/200 AVG Training Loss:0.664 AVG Validation Loss:0.686 AVG Training Acc 61.23 % AVG Validation Acc 57.93 %\n",
      "Epoch:190/200 AVG Training Loss:0.666 AVG Validation Loss:0.685 AVG Training Acc 60.35 % AVG Validation Acc 57.93 %\n",
      "Epoch   199: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:200/200 AVG Training Loss:0.662 AVG Validation Loss:0.686 AVG Training Acc 60.46 % AVG Validation Acc 57.66 %\n",
      "Split 174\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897605e94e1b49c2a5db42d9c7e34bf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.545 AVG Validation Loss:4.044 AVG Training Acc 79.38 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.616 AVG Validation Loss:1.880 AVG Training Acc 70.39 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.616 AVG Validation Loss:7.151 AVG Training Acc 80.26 % AVG Validation Acc 20.16 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.787 AVG Validation Loss:0.960 AVG Training Acc 49.25 % AVG Validation Acc 20.30 %\n",
      "Epoch:50/200 AVG Training Loss:0.680 AVG Validation Loss:0.783 AVG Training Acc 57.44 % AVG Validation Acc 26.08 %\n",
      "Epoch:60/200 AVG Training Loss:0.677 AVG Validation Loss:0.763 AVG Training Acc 57.60 % AVG Validation Acc 32.93 %\n",
      "Epoch:70/200 AVG Training Loss:0.675 AVG Validation Loss:0.761 AVG Training Acc 57.88 % AVG Validation Acc 35.08 %\n",
      "Epoch:80/200 AVG Training Loss:0.671 AVG Validation Loss:0.749 AVG Training Acc 58.61 % AVG Validation Acc 41.26 %\n",
      "Epoch:90/200 AVG Training Loss:0.668 AVG Validation Loss:0.761 AVG Training Acc 59.09 % AVG Validation Acc 37.90 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.662 AVG Validation Loss:0.691 AVG Training Acc 59.62 % AVG Validation Acc 57.39 %\n",
      "Epoch:110/200 AVG Training Loss:0.659 AVG Validation Loss:0.667 AVG Training Acc 60.14 % AVG Validation Acc 61.56 %\n",
      "Epoch:120/200 AVG Training Loss:0.658 AVG Validation Loss:0.662 AVG Training Acc 60.33 % AVG Validation Acc 62.10 %\n",
      "Epoch   129: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.655 AVG Validation Loss:0.661 AVG Training Acc 61.01 % AVG Validation Acc 62.23 %\n",
      "Epoch:140/200 AVG Training Loss:0.654 AVG Validation Loss:0.659 AVG Training Acc 60.64 % AVG Validation Acc 62.63 %\n",
      "Epoch:150/200 AVG Training Loss:0.654 AVG Validation Loss:0.657 AVG Training Acc 60.85 % AVG Validation Acc 62.90 %\n",
      "Epoch:160/200 AVG Training Loss:0.655 AVG Validation Loss:0.657 AVG Training Acc 60.62 % AVG Validation Acc 63.17 %\n",
      "Epoch:170/200 AVG Training Loss:0.656 AVG Validation Loss:0.656 AVG Training Acc 60.81 % AVG Validation Acc 63.31 %\n",
      "Epoch:180/200 AVG Training Loss:0.656 AVG Validation Loss:0.654 AVG Training Acc 60.63 % AVG Validation Acc 63.31 %\n",
      "Epoch:190/200 AVG Training Loss:0.654 AVG Validation Loss:0.654 AVG Training Acc 60.88 % AVG Validation Acc 63.31 %\n",
      "Epoch:200/200 AVG Training Loss:0.653 AVG Validation Loss:0.653 AVG Training Acc 60.82 % AVG Validation Acc 63.44 %\n",
      "Split 175\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65678a84fe9a48f98783d4c48a3f0fab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.549 AVG Validation Loss:2.879 AVG Training Acc 78.80 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.587 AVG Validation Loss:8.601 AVG Training Acc 68.03 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.600 AVG Validation Loss:1.782 AVG Training Acc 74.57 % AVG Validation Acc 20.16 %\n",
      "Epoch    30: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.682 AVG Validation Loss:0.770 AVG Training Acc 56.39 % AVG Validation Acc 28.36 %\n",
      "Epoch:50/200 AVG Training Loss:0.679 AVG Validation Loss:0.769 AVG Training Acc 58.16 % AVG Validation Acc 32.12 %\n",
      "Epoch:60/200 AVG Training Loss:0.672 AVG Validation Loss:0.772 AVG Training Acc 59.02 % AVG Validation Acc 35.62 %\n",
      "Epoch    61: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.669 AVG Validation Loss:0.709 AVG Training Acc 59.17 % AVG Validation Acc 52.82 %\n",
      "Epoch:80/200 AVG Training Loss:0.665 AVG Validation Loss:0.684 AVG Training Acc 60.28 % AVG Validation Acc 57.66 %\n",
      "Epoch:90/200 AVG Training Loss:0.662 AVG Validation Loss:0.677 AVG Training Acc 61.12 % AVG Validation Acc 59.27 %\n",
      "Epoch:100/200 AVG Training Loss:0.663 AVG Validation Loss:0.676 AVG Training Acc 60.91 % AVG Validation Acc 59.01 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.662 AVG Validation Loss:0.675 AVG Training Acc 60.73 % AVG Validation Acc 59.14 %\n",
      "Epoch:120/200 AVG Training Loss:0.659 AVG Validation Loss:0.673 AVG Training Acc 61.37 % AVG Validation Acc 59.27 %\n",
      "Epoch:130/200 AVG Training Loss:0.661 AVG Validation Loss:0.672 AVG Training Acc 60.79 % AVG Validation Acc 59.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.661 AVG Validation Loss:0.671 AVG Training Acc 61.02 % AVG Validation Acc 59.27 %\n",
      "Epoch:150/200 AVG Training Loss:0.660 AVG Validation Loss:0.670 AVG Training Acc 61.11 % AVG Validation Acc 59.27 %\n",
      "Epoch:160/200 AVG Training Loss:0.660 AVG Validation Loss:0.670 AVG Training Acc 61.15 % AVG Validation Acc 59.27 %\n",
      "Epoch:170/200 AVG Training Loss:0.662 AVG Validation Loss:0.669 AVG Training Acc 61.28 % AVG Validation Acc 59.27 %\n",
      "Epoch:180/200 AVG Training Loss:0.660 AVG Validation Loss:0.668 AVG Training Acc 61.52 % AVG Validation Acc 59.41 %\n",
      "Epoch:190/200 AVG Training Loss:0.660 AVG Validation Loss:0.668 AVG Training Acc 61.08 % AVG Validation Acc 59.41 %\n",
      "Epoch:200/200 AVG Training Loss:0.662 AVG Validation Loss:0.668 AVG Training Acc 60.61 % AVG Validation Acc 59.41 %\n",
      "Split 176\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "242c996e766548cbb4ba33f1928f58b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.521 AVG Validation Loss:5.054 AVG Training Acc 79.56 % AVG Validation Acc 20.16 %\n",
      "Epoch    17: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:20/200 AVG Training Loss:0.711 AVG Validation Loss:0.895 AVG Training Acc 51.71 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.680 AVG Validation Loss:0.926 AVG Training Acc 57.47 % AVG Validation Acc 25.81 %\n",
      "Epoch:40/200 AVG Training Loss:0.678 AVG Validation Loss:0.858 AVG Training Acc 58.55 % AVG Validation Acc 28.09 %\n",
      "Epoch:50/200 AVG Training Loss:0.676 AVG Validation Loss:0.863 AVG Training Acc 58.64 % AVG Validation Acc 34.95 %\n",
      "Epoch    58: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.771 AVG Validation Loss:0.892 AVG Training Acc 51.88 % AVG Validation Acc 27.55 %\n",
      "Epoch:70/200 AVG Training Loss:0.673 AVG Validation Loss:0.741 AVG Training Acc 58.14 % AVG Validation Acc 44.09 %\n",
      "Epoch:80/200 AVG Training Loss:0.672 AVG Validation Loss:0.727 AVG Training Acc 58.16 % AVG Validation Acc 47.45 %\n",
      "Epoch:90/200 AVG Training Loss:0.669 AVG Validation Loss:0.727 AVG Training Acc 59.06 % AVG Validation Acc 48.25 %\n",
      "Epoch:100/200 AVG Training Loss:0.668 AVG Validation Loss:0.721 AVG Training Acc 59.25 % AVG Validation Acc 48.92 %\n",
      "Epoch:110/200 AVG Training Loss:0.666 AVG Validation Loss:0.720 AVG Training Acc 60.14 % AVG Validation Acc 49.19 %\n",
      "Epoch   112: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.664 AVG Validation Loss:0.706 AVG Training Acc 60.37 % AVG Validation Acc 51.61 %\n",
      "Epoch:130/200 AVG Training Loss:0.661 AVG Validation Loss:0.690 AVG Training Acc 60.14 % AVG Validation Acc 53.49 %\n",
      "Epoch:140/200 AVG Training Loss:0.661 AVG Validation Loss:0.683 AVG Training Acc 60.36 % AVG Validation Acc 55.51 %\n",
      "Epoch:150/200 AVG Training Loss:0.661 AVG Validation Loss:0.677 AVG Training Acc 60.20 % AVG Validation Acc 56.32 %\n",
      "Epoch:160/200 AVG Training Loss:0.662 AVG Validation Loss:0.675 AVG Training Acc 60.54 % AVG Validation Acc 57.53 %\n",
      "Epoch:170/200 AVG Training Loss:0.661 AVG Validation Loss:0.677 AVG Training Acc 60.36 % AVG Validation Acc 56.99 %\n",
      "Epoch:180/200 AVG Training Loss:0.660 AVG Validation Loss:0.675 AVG Training Acc 60.52 % AVG Validation Acc 57.53 %\n",
      "Epoch:190/200 AVG Training Loss:0.662 AVG Validation Loss:0.674 AVG Training Acc 60.77 % AVG Validation Acc 56.59 %\n",
      "Epoch   192: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:200/200 AVG Training Loss:0.660 AVG Validation Loss:0.675 AVG Training Acc 60.68 % AVG Validation Acc 56.85 %\n",
      "Split 177\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b0029231695447bb34d93dcce1406fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.516 AVG Validation Loss:6.738 AVG Training Acc 81.66 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.517 AVG Validation Loss:3.102 AVG Training Acc 77.89 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.516 AVG Validation Loss:5.895 AVG Training Acc 81.38 % AVG Validation Acc 20.05 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.647 AVG Validation Loss:1.544 AVG Training Acc 65.93 % AVG Validation Acc 20.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.673 AVG Validation Loss:0.984 AVG Training Acc 60.07 % AVG Validation Acc 20.59 %\n",
      "Epoch:60/200 AVG Training Loss:0.653 AVG Validation Loss:1.079 AVG Training Acc 63.75 % AVG Validation Acc 20.46 %\n",
      "Epoch    67: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.696 AVG Validation Loss:0.799 AVG Training Acc 54.19 % AVG Validation Acc 34.59 %\n",
      "Epoch:80/200 AVG Training Loss:0.663 AVG Validation Loss:0.706 AVG Training Acc 59.46 % AVG Validation Acc 53.03 %\n",
      "Epoch:90/200 AVG Training Loss:0.663 AVG Validation Loss:0.703 AVG Training Acc 60.40 % AVG Validation Acc 52.89 %\n",
      "Epoch:100/200 AVG Training Loss:0.664 AVG Validation Loss:0.699 AVG Training Acc 59.86 % AVG Validation Acc 53.70 %\n",
      "Epoch:110/200 AVG Training Loss:0.661 AVG Validation Loss:0.699 AVG Training Acc 60.39 % AVG Validation Acc 53.97 %\n",
      "Epoch:120/200 AVG Training Loss:0.660 AVG Validation Loss:0.699 AVG Training Acc 60.40 % AVG Validation Acc 53.84 %\n",
      "Epoch:130/200 AVG Training Loss:0.660 AVG Validation Loss:0.697 AVG Training Acc 60.43 % AVG Validation Acc 53.43 %\n",
      "Epoch:140/200 AVG Training Loss:0.660 AVG Validation Loss:0.699 AVG Training Acc 60.74 % AVG Validation Acc 53.57 %\n",
      "Epoch   146: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.658 AVG Validation Loss:0.691 AVG Training Acc 60.67 % AVG Validation Acc 54.51 %\n",
      "Epoch:160/200 AVG Training Loss:0.655 AVG Validation Loss:0.682 AVG Training Acc 61.22 % AVG Validation Acc 56.93 %\n",
      "Epoch:170/200 AVG Training Loss:0.655 AVG Validation Loss:0.675 AVG Training Acc 61.48 % AVG Validation Acc 58.01 %\n",
      "Epoch:180/200 AVG Training Loss:0.655 AVG Validation Loss:0.673 AVG Training Acc 61.24 % AVG Validation Acc 58.68 %\n",
      "Epoch:190/200 AVG Training Loss:0.655 AVG Validation Loss:0.671 AVG Training Acc 61.23 % AVG Validation Acc 58.41 %\n",
      "Epoch:200/200 AVG Training Loss:0.654 AVG Validation Loss:0.672 AVG Training Acc 61.63 % AVG Validation Acc 58.82 %\n",
      "Split 178\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "945b3a938b144011af392c14982b8837",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.561 AVG Validation Loss:3.825 AVG Training Acc 76.33 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.641 AVG Validation Loss:1.708 AVG Training Acc 67.23 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.483 AVG Validation Loss:4.658 AVG Training Acc 78.04 % AVG Validation Acc 20.05 %\n",
      "Epoch    31: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.699 AVG Validation Loss:0.911 AVG Training Acc 53.73 % AVG Validation Acc 20.86 %\n",
      "Epoch:50/200 AVG Training Loss:0.670 AVG Validation Loss:0.990 AVG Training Acc 60.07 % AVG Validation Acc 22.07 %\n",
      "Epoch:60/200 AVG Training Loss:0.678 AVG Validation Loss:0.909 AVG Training Acc 58.55 % AVG Validation Acc 27.05 %\n",
      "Epoch:70/200 AVG Training Loss:0.677 AVG Validation Loss:0.863 AVG Training Acc 59.17 % AVG Validation Acc 33.38 %\n",
      "Epoch:80/200 AVG Training Loss:0.677 AVG Validation Loss:0.885 AVG Training Acc 59.43 % AVG Validation Acc 31.36 %\n",
      "Epoch    86: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.677 AVG Validation Loss:0.764 AVG Training Acc 58.96 % AVG Validation Acc 46.97 %\n",
      "Epoch:100/200 AVG Training Loss:0.658 AVG Validation Loss:0.688 AVG Training Acc 61.34 % AVG Validation Acc 57.07 %\n",
      "Epoch:110/200 AVG Training Loss:0.656 AVG Validation Loss:0.677 AVG Training Acc 61.47 % AVG Validation Acc 58.01 %\n",
      "Epoch:120/200 AVG Training Loss:0.654 AVG Validation Loss:0.673 AVG Training Acc 61.56 % AVG Validation Acc 57.74 %\n",
      "Epoch:130/200 AVG Training Loss:0.656 AVG Validation Loss:0.673 AVG Training Acc 61.62 % AVG Validation Acc 57.87 %\n",
      "Epoch   138: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:140/200 AVG Training Loss:0.652 AVG Validation Loss:0.673 AVG Training Acc 62.24 % AVG Validation Acc 58.01 %\n",
      "Epoch:150/200 AVG Training Loss:0.650 AVG Validation Loss:0.669 AVG Training Acc 61.98 % AVG Validation Acc 57.87 %\n",
      "Epoch:160/200 AVG Training Loss:0.652 AVG Validation Loss:0.665 AVG Training Acc 62.42 % AVG Validation Acc 58.14 %\n",
      "Epoch:170/200 AVG Training Loss:0.650 AVG Validation Loss:0.663 AVG Training Acc 62.29 % AVG Validation Acc 58.41 %\n",
      "Epoch:180/200 AVG Training Loss:0.650 AVG Validation Loss:0.660 AVG Training Acc 62.19 % AVG Validation Acc 58.55 %\n",
      "Epoch:190/200 AVG Training Loss:0.651 AVG Validation Loss:0.660 AVG Training Acc 61.99 % AVG Validation Acc 58.82 %\n",
      "Epoch:200/200 AVG Training Loss:0.652 AVG Validation Loss:0.659 AVG Training Acc 62.15 % AVG Validation Acc 58.82 %\n",
      "Split 179\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64fc2763cd1f4b55b76f1991f22fd999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.422 AVG Validation Loss:6.092 AVG Training Acc 81.84 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.542 AVG Validation Loss:9.247 AVG Training Acc 77.61 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.478 AVG Validation Loss:3.867 AVG Training Acc 79.64 % AVG Validation Acc 20.05 %\n",
      "Epoch    36: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.702 AVG Validation Loss:1.275 AVG Training Acc 57.59 % AVG Validation Acc 20.05 %\n",
      "Epoch:50/200 AVG Training Loss:0.680 AVG Validation Loss:0.913 AVG Training Acc 58.15 % AVG Validation Acc 25.30 %\n",
      "Epoch:60/200 AVG Training Loss:0.676 AVG Validation Loss:0.849 AVG Training Acc 58.99 % AVG Validation Acc 30.55 %\n",
      "Epoch:70/200 AVG Training Loss:0.679 AVG Validation Loss:0.839 AVG Training Acc 58.05 % AVG Validation Acc 29.21 %\n",
      "Epoch:80/200 AVG Training Loss:0.669 AVG Validation Loss:0.863 AVG Training Acc 60.77 % AVG Validation Acc 29.34 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.669 AVG Validation Loss:0.733 AVG Training Acc 58.72 % AVG Validation Acc 48.05 %\n",
      "Epoch:100/200 AVG Training Loss:0.659 AVG Validation Loss:0.687 AVG Training Acc 60.57 % AVG Validation Acc 55.18 %\n",
      "Epoch:110/200 AVG Training Loss:0.660 AVG Validation Loss:0.684 AVG Training Acc 60.53 % AVG Validation Acc 56.53 %\n",
      "Epoch   118: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.657 AVG Validation Loss:0.684 AVG Training Acc 60.54 % AVG Validation Acc 56.12 %\n",
      "Epoch:130/200 AVG Training Loss:0.658 AVG Validation Loss:0.679 AVG Training Acc 60.81 % AVG Validation Acc 55.85 %\n",
      "Epoch:140/200 AVG Training Loss:0.657 AVG Validation Loss:0.676 AVG Training Acc 60.89 % AVG Validation Acc 56.66 %\n",
      "Epoch:150/200 AVG Training Loss:0.656 AVG Validation Loss:0.673 AVG Training Acc 61.12 % AVG Validation Acc 56.80 %\n",
      "Epoch:160/200 AVG Training Loss:0.657 AVG Validation Loss:0.673 AVG Training Acc 60.85 % AVG Validation Acc 57.20 %\n",
      "Epoch:170/200 AVG Training Loss:0.659 AVG Validation Loss:0.668 AVG Training Acc 60.72 % AVG Validation Acc 57.34 %\n",
      "Epoch:180/200 AVG Training Loss:0.657 AVG Validation Loss:0.667 AVG Training Acc 61.12 % AVG Validation Acc 58.01 %\n",
      "Epoch:190/200 AVG Training Loss:0.657 AVG Validation Loss:0.667 AVG Training Acc 60.94 % AVG Validation Acc 58.28 %\n",
      "Epoch   191: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:200/200 AVG Training Loss:0.655 AVG Validation Loss:0.669 AVG Training Acc 60.86 % AVG Validation Acc 58.01 %\n",
      "Split 180\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ec11729adbe4a27a4792c806005ea27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.543 AVG Validation Loss:3.988 AVG Training Acc 77.48 % AVG Validation Acc 20.19 %\n",
      "Epoch:20/200 AVG Training Loss:0.624 AVG Validation Loss:1.816 AVG Training Acc 70.67 % AVG Validation Acc 20.19 %\n",
      "Epoch:30/200 AVG Training Loss:0.645 AVG Validation Loss:1.668 AVG Training Acc 67.07 % AVG Validation Acc 20.19 %\n",
      "Epoch:40/200 AVG Training Loss:0.584 AVG Validation Loss:2.311 AVG Training Acc 75.46 % AVG Validation Acc 20.19 %\n",
      "Epoch    43: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:50/200 AVG Training Loss:0.691 AVG Validation Loss:0.767 AVG Training Acc 53.74 % AVG Validation Acc 22.07 %\n",
      "Epoch:60/200 AVG Training Loss:0.681 AVG Validation Loss:0.771 AVG Training Acc 57.17 % AVG Validation Acc 29.61 %\n",
      "Epoch:70/200 AVG Training Loss:0.676 AVG Validation Loss:0.776 AVG Training Acc 58.49 % AVG Validation Acc 37.15 %\n",
      "Epoch    74: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.672 AVG Validation Loss:0.738 AVG Training Acc 58.34 % AVG Validation Acc 47.78 %\n",
      "Epoch:90/200 AVG Training Loss:0.666 AVG Validation Loss:0.709 AVG Training Acc 59.85 % AVG Validation Acc 54.24 %\n",
      "Epoch:100/200 AVG Training Loss:0.664 AVG Validation Loss:0.698 AVG Training Acc 60.22 % AVG Validation Acc 55.32 %\n",
      "Epoch:110/200 AVG Training Loss:0.666 AVG Validation Loss:0.695 AVG Training Acc 60.33 % AVG Validation Acc 55.99 %\n",
      "Epoch:120/200 AVG Training Loss:0.665 AVG Validation Loss:0.694 AVG Training Acc 60.33 % AVG Validation Acc 55.99 %\n",
      "Epoch:130/200 AVG Training Loss:0.664 AVG Validation Loss:0.692 AVG Training Acc 60.02 % AVG Validation Acc 56.12 %\n",
      "Epoch:140/200 AVG Training Loss:0.666 AVG Validation Loss:0.692 AVG Training Acc 60.11 % AVG Validation Acc 56.53 %\n",
      "Epoch:150/200 AVG Training Loss:0.664 AVG Validation Loss:0.691 AVG Training Acc 60.05 % AVG Validation Acc 56.66 %\n",
      "Epoch:160/200 AVG Training Loss:0.664 AVG Validation Loss:0.691 AVG Training Acc 60.59 % AVG Validation Acc 56.53 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:170/200 AVG Training Loss:0.661 AVG Validation Loss:0.691 AVG Training Acc 61.03 % AVG Validation Acc 56.66 %\n",
      "Epoch:180/200 AVG Training Loss:0.662 AVG Validation Loss:0.690 AVG Training Acc 61.15 % AVG Validation Acc 56.93 %\n",
      "Epoch:190/200 AVG Training Loss:0.663 AVG Validation Loss:0.689 AVG Training Acc 60.55 % AVG Validation Acc 56.66 %\n",
      "Epoch:200/200 AVG Training Loss:0.662 AVG Validation Loss:0.689 AVG Training Acc 60.66 % AVG Validation Acc 56.93 %\n",
      "Split 181\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e137717baea4213ab61063b3abe345f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.531 AVG Validation Loss:3.293 AVG Training Acc 80.39 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.596 AVG Validation Loss:2.367 AVG Training Acc 76.13 % AVG Validation Acc 20.16 %\n",
      "Epoch    24: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.704 AVG Validation Loss:0.788 AVG Training Acc 49.30 % AVG Validation Acc 22.98 %\n",
      "Epoch:40/200 AVG Training Loss:0.686 AVG Validation Loss:0.779 AVG Training Acc 54.81 % AVG Validation Acc 25.13 %\n",
      "Epoch:50/200 AVG Training Loss:0.679 AVG Validation Loss:0.774 AVG Training Acc 57.87 % AVG Validation Acc 36.83 %\n",
      "Epoch:60/200 AVG Training Loss:0.674 AVG Validation Loss:0.774 AVG Training Acc 59.12 % AVG Validation Acc 40.73 %\n",
      "Epoch:70/200 AVG Training Loss:0.668 AVG Validation Loss:0.782 AVG Training Acc 60.40 % AVG Validation Acc 40.59 %\n",
      "Epoch    72: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:80/200 AVG Training Loss:0.662 AVG Validation Loss:0.707 AVG Training Acc 61.52 % AVG Validation Acc 57.80 %\n",
      "Epoch:90/200 AVG Training Loss:0.659 AVG Validation Loss:0.682 AVG Training Acc 61.15 % AVG Validation Acc 59.01 %\n",
      "Epoch:100/200 AVG Training Loss:0.655 AVG Validation Loss:0.675 AVG Training Acc 62.04 % AVG Validation Acc 59.27 %\n",
      "Epoch:110/200 AVG Training Loss:0.656 AVG Validation Loss:0.672 AVG Training Acc 61.82 % AVG Validation Acc 59.41 %\n",
      "Epoch:120/200 AVG Training Loss:0.656 AVG Validation Loss:0.672 AVG Training Acc 61.70 % AVG Validation Acc 59.14 %\n",
      "Epoch:130/200 AVG Training Loss:0.654 AVG Validation Loss:0.671 AVG Training Acc 61.96 % AVG Validation Acc 59.14 %\n",
      "Epoch:140/200 AVG Training Loss:0.653 AVG Validation Loss:0.671 AVG Training Acc 62.17 % AVG Validation Acc 59.41 %\n",
      "Epoch:150/200 AVG Training Loss:0.652 AVG Validation Loss:0.671 AVG Training Acc 62.33 % AVG Validation Acc 59.68 %\n",
      "Epoch   158: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:160/200 AVG Training Loss:0.650 AVG Validation Loss:0.671 AVG Training Acc 62.57 % AVG Validation Acc 59.68 %\n",
      "Epoch:170/200 AVG Training Loss:0.648 AVG Validation Loss:0.669 AVG Training Acc 62.39 % AVG Validation Acc 59.68 %\n",
      "Epoch:180/200 AVG Training Loss:0.648 AVG Validation Loss:0.668 AVG Training Acc 62.73 % AVG Validation Acc 59.14 %\n",
      "Epoch:190/200 AVG Training Loss:0.650 AVG Validation Loss:0.666 AVG Training Acc 62.31 % AVG Validation Acc 59.68 %\n",
      "Epoch:200/200 AVG Training Loss:0.649 AVG Validation Loss:0.666 AVG Training Acc 62.68 % AVG Validation Acc 60.08 %\n",
      "Split 182\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f39a6e34495446d6aece620a688c682d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.465 AVG Validation Loss:5.292 AVG Training Acc 80.51 % AVG Validation Acc 20.30 %\n",
      "Epoch:20/200 AVG Training Loss:0.506 AVG Validation Loss:4.582 AVG Training Acc 81.84 % AVG Validation Acc 20.16 %\n",
      "Epoch    22: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.690 AVG Validation Loss:1.157 AVG Training Acc 61.00 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.660 AVG Validation Loss:1.066 AVG Training Acc 61.90 % AVG Validation Acc 21.37 %\n",
      "Epoch:50/200 AVG Training Loss:0.664 AVG Validation Loss:1.022 AVG Training Acc 61.24 % AVG Validation Acc 21.51 %\n",
      "Epoch:60/200 AVG Training Loss:0.684 AVG Validation Loss:0.879 AVG Training Acc 58.08 % AVG Validation Acc 24.46 %\n",
      "Epoch:70/200 AVG Training Loss:0.681 AVG Validation Loss:0.869 AVG Training Acc 56.68 % AVG Validation Acc 25.81 %\n",
      "Epoch:80/200 AVG Training Loss:0.673 AVG Validation Loss:0.836 AVG Training Acc 59.07 % AVG Validation Acc 27.28 %\n",
      "Epoch    84: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:90/200 AVG Training Loss:0.676 AVG Validation Loss:0.740 AVG Training Acc 57.86 % AVG Validation Acc 45.03 %\n",
      "Epoch:100/200 AVG Training Loss:0.664 AVG Validation Loss:0.688 AVG Training Acc 60.76 % AVG Validation Acc 54.57 %\n",
      "Epoch:110/200 AVG Training Loss:0.661 AVG Validation Loss:0.676 AVG Training Acc 61.32 % AVG Validation Acc 56.72 %\n",
      "Epoch:120/200 AVG Training Loss:0.663 AVG Validation Loss:0.673 AVG Training Acc 61.46 % AVG Validation Acc 57.12 %\n",
      "Epoch:130/200 AVG Training Loss:0.660 AVG Validation Loss:0.671 AVG Training Acc 61.58 % AVG Validation Acc 57.39 %\n",
      "Epoch:140/200 AVG Training Loss:0.660 AVG Validation Loss:0.671 AVG Training Acc 61.52 % AVG Validation Acc 57.12 %\n",
      "Epoch:150/200 AVG Training Loss:0.657 AVG Validation Loss:0.672 AVG Training Acc 61.58 % AVG Validation Acc 56.85 %\n",
      "Epoch   155: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:160/200 AVG Training Loss:0.658 AVG Validation Loss:0.666 AVG Training Acc 61.76 % AVG Validation Acc 57.93 %\n",
      "Epoch:170/200 AVG Training Loss:0.657 AVG Validation Loss:0.664 AVG Training Acc 62.00 % AVG Validation Acc 58.60 %\n",
      "Epoch:180/200 AVG Training Loss:0.657 AVG Validation Loss:0.662 AVG Training Acc 61.76 % AVG Validation Acc 59.01 %\n",
      "Epoch:190/200 AVG Training Loss:0.657 AVG Validation Loss:0.662 AVG Training Acc 61.85 % AVG Validation Acc 59.01 %\n",
      "Epoch:200/200 AVG Training Loss:0.656 AVG Validation Loss:0.660 AVG Training Acc 61.79 % AVG Validation Acc 59.27 %\n",
      "Split 183\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7611c703ee714696879e3cd0804e2da5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.499 AVG Validation Loss:5.267 AVG Training Acc 80.33 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.607 AVG Validation Loss:2.885 AVG Training Acc 77.90 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.639 AVG Validation Loss:5.245 AVG Training Acc 69.76 % AVG Validation Acc 20.16 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.815 AVG Validation Loss:0.925 AVG Training Acc 49.20 % AVG Validation Acc 20.70 %\n",
      "Epoch:50/200 AVG Training Loss:0.681 AVG Validation Loss:0.807 AVG Training Acc 56.74 % AVG Validation Acc 29.30 %\n",
      "Epoch:60/200 AVG Training Loss:0.675 AVG Validation Loss:0.804 AVG Training Acc 57.62 % AVG Validation Acc 31.99 %\n",
      "Epoch    69: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.680 AVG Validation Loss:0.790 AVG Training Acc 55.77 % AVG Validation Acc 34.95 %\n",
      "Epoch:80/200 AVG Training Loss:0.663 AVG Validation Loss:0.716 AVG Training Acc 60.13 % AVG Validation Acc 52.55 %\n",
      "Epoch:90/200 AVG Training Loss:0.659 AVG Validation Loss:0.696 AVG Training Acc 60.63 % AVG Validation Acc 56.05 %\n",
      "Epoch:100/200 AVG Training Loss:0.660 AVG Validation Loss:0.690 AVG Training Acc 60.24 % AVG Validation Acc 56.18 %\n",
      "Epoch:110/200 AVG Training Loss:0.659 AVG Validation Loss:0.689 AVG Training Acc 60.39 % AVG Validation Acc 56.32 %\n",
      "Epoch:120/200 AVG Training Loss:0.661 AVG Validation Loss:0.688 AVG Training Acc 60.60 % AVG Validation Acc 56.05 %\n",
      "Epoch:130/200 AVG Training Loss:0.657 AVG Validation Loss:0.689 AVG Training Acc 60.58 % AVG Validation Acc 55.65 %\n",
      "Epoch   132: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:140/200 AVG Training Loss:0.654 AVG Validation Loss:0.688 AVG Training Acc 60.70 % AVG Validation Acc 55.91 %\n",
      "Epoch:150/200 AVG Training Loss:0.657 AVG Validation Loss:0.686 AVG Training Acc 60.96 % AVG Validation Acc 55.91 %\n",
      "Epoch:160/200 AVG Training Loss:0.655 AVG Validation Loss:0.685 AVG Training Acc 61.18 % AVG Validation Acc 56.05 %\n",
      "Epoch:170/200 AVG Training Loss:0.655 AVG Validation Loss:0.684 AVG Training Acc 60.72 % AVG Validation Acc 55.91 %\n",
      "Epoch:180/200 AVG Training Loss:0.657 AVG Validation Loss:0.684 AVG Training Acc 60.60 % AVG Validation Acc 56.05 %\n",
      "Epoch:190/200 AVG Training Loss:0.656 AVG Validation Loss:0.683 AVG Training Acc 61.17 % AVG Validation Acc 56.18 %\n",
      "Epoch:200/200 AVG Training Loss:0.656 AVG Validation Loss:0.682 AVG Training Acc 61.07 % AVG Validation Acc 55.91 %\n",
      "Split 184\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c61de16ab8154e7bb1b69e944c07a24b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.506 AVG Validation Loss:4.267 AVG Training Acc 80.83 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.482 AVG Validation Loss:3.214 AVG Training Acc 80.28 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.505 AVG Validation Loss:5.238 AVG Training Acc 78.15 % AVG Validation Acc 20.16 %\n",
      "Epoch:40/200 AVG Training Loss:0.493 AVG Validation Loss:3.911 AVG Training Acc 77.63 % AVG Validation Acc 20.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.655 AVG Validation Loss:3.129 AVG Training Acc 63.99 % AVG Validation Acc 20.16 %\n",
      "Epoch:60/200 AVG Training Loss:0.556 AVG Validation Loss:2.747 AVG Training Acc 76.79 % AVG Validation Acc 20.16 %\n",
      "Epoch    60: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:70/200 AVG Training Loss:0.685 AVG Validation Loss:0.861 AVG Training Acc 56.53 % AVG Validation Acc 26.08 %\n",
      "Epoch:80/200 AVG Training Loss:0.680 AVG Validation Loss:0.870 AVG Training Acc 57.86 % AVG Validation Acc 26.21 %\n",
      "Epoch:90/200 AVG Training Loss:0.676 AVG Validation Loss:0.871 AVG Training Acc 58.19 % AVG Validation Acc 27.02 %\n",
      "Epoch    91: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.671 AVG Validation Loss:0.722 AVG Training Acc 59.04 % AVG Validation Acc 51.34 %\n",
      "Epoch:110/200 AVG Training Loss:0.667 AVG Validation Loss:0.696 AVG Training Acc 59.32 % AVG Validation Acc 54.97 %\n",
      "Epoch:120/200 AVG Training Loss:0.666 AVG Validation Loss:0.692 AVG Training Acc 59.92 % AVG Validation Acc 55.65 %\n",
      "Epoch:130/200 AVG Training Loss:0.662 AVG Validation Loss:0.692 AVG Training Acc 60.43 % AVG Validation Acc 55.38 %\n",
      "Epoch   139: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:140/200 AVG Training Loss:0.663 AVG Validation Loss:0.692 AVG Training Acc 60.00 % AVG Validation Acc 55.78 %\n",
      "Epoch:150/200 AVG Training Loss:0.664 AVG Validation Loss:0.689 AVG Training Acc 60.48 % AVG Validation Acc 56.05 %\n",
      "Epoch:160/200 AVG Training Loss:0.663 AVG Validation Loss:0.687 AVG Training Acc 60.70 % AVG Validation Acc 56.45 %\n",
      "Epoch:170/200 AVG Training Loss:0.664 AVG Validation Loss:0.686 AVG Training Acc 60.76 % AVG Validation Acc 56.59 %\n",
      "Epoch:180/200 AVG Training Loss:0.661 AVG Validation Loss:0.685 AVG Training Acc 60.55 % AVG Validation Acc 56.85 %\n",
      "Epoch:190/200 AVG Training Loss:0.661 AVG Validation Loss:0.684 AVG Training Acc 61.20 % AVG Validation Acc 57.12 %\n",
      "Epoch:200/200 AVG Training Loss:0.664 AVG Validation Loss:0.683 AVG Training Acc 60.51 % AVG Validation Acc 57.66 %\n",
      "Split 185\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0d35c59e21547eba014e65eec16dbf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.593 AVG Validation Loss:2.410 AVG Training Acc 73.41 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.634 AVG Validation Loss:2.038 AVG Training Acc 67.74 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.611 AVG Validation Loss:7.016 AVG Training Acc 66.74 % AVG Validation Acc 20.16 %\n",
      "Epoch    38: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:1.304 AVG Validation Loss:3.160 AVG Training Acc 63.77 % AVG Validation Acc 20.16 %\n",
      "Epoch:50/200 AVG Training Loss:0.626 AVG Validation Loss:1.678 AVG Training Acc 68.44 % AVG Validation Acc 20.56 %\n",
      "Epoch:60/200 AVG Training Loss:0.634 AVG Validation Loss:1.520 AVG Training Acc 66.88 % AVG Validation Acc 20.56 %\n",
      "Epoch:70/200 AVG Training Loss:0.640 AVG Validation Loss:1.398 AVG Training Acc 66.01 % AVG Validation Acc 20.56 %\n",
      "Epoch:80/200 AVG Training Loss:0.637 AVG Validation Loss:1.375 AVG Training Acc 65.59 % AVG Validation Acc 20.70 %\n",
      "Epoch:90/200 AVG Training Loss:0.632 AVG Validation Loss:1.337 AVG Training Acc 65.84 % AVG Validation Acc 20.56 %\n",
      "Epoch:100/200 AVG Training Loss:0.623 AVG Validation Loss:1.338 AVG Training Acc 66.26 % AVG Validation Acc 20.56 %\n",
      "Epoch   107: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:110/200 AVG Training Loss:0.693 AVG Validation Loss:0.820 AVG Training Acc 57.00 % AVG Validation Acc 33.74 %\n",
      "Epoch:120/200 AVG Training Loss:0.644 AVG Validation Loss:0.692 AVG Training Acc 62.83 % AVG Validation Acc 54.70 %\n",
      "Epoch:130/200 AVG Training Loss:0.642 AVG Validation Loss:0.691 AVG Training Acc 63.21 % AVG Validation Acc 54.30 %\n",
      "Epoch:140/200 AVG Training Loss:0.637 AVG Validation Loss:0.690 AVG Training Acc 63.58 % AVG Validation Acc 54.70 %\n",
      "Epoch:150/200 AVG Training Loss:0.639 AVG Validation Loss:0.688 AVG Training Acc 63.19 % AVG Validation Acc 55.38 %\n",
      "Epoch:160/200 AVG Training Loss:0.637 AVG Validation Loss:0.691 AVG Training Acc 63.88 % AVG Validation Acc 54.57 %\n",
      "Epoch   160: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:170/200 AVG Training Loss:0.633 AVG Validation Loss:0.674 AVG Training Acc 63.82 % AVG Validation Acc 56.45 %\n",
      "Epoch:180/200 AVG Training Loss:0.631 AVG Validation Loss:0.666 AVG Training Acc 64.32 % AVG Validation Acc 57.93 %\n",
      "Epoch:190/200 AVG Training Loss:0.632 AVG Validation Loss:0.662 AVG Training Acc 64.16 % AVG Validation Acc 59.54 %\n",
      "Epoch:200/200 AVG Training Loss:0.629 AVG Validation Loss:0.659 AVG Training Acc 64.48 % AVG Validation Acc 60.08 %\n",
      "Split 186\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6c5a80a609742d7a3bda9f7a93bd53b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.529 AVG Validation Loss:4.952 AVG Training Acc 79.28 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.572 AVG Validation Loss:4.019 AVG Training Acc 75.76 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.599 AVG Validation Loss:5.460 AVG Training Acc 71.75 % AVG Validation Acc 20.16 %\n",
      "Epoch    37: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.741 AVG Validation Loss:0.877 AVG Training Acc 48.67 % AVG Validation Acc 21.24 %\n",
      "Epoch:50/200 AVG Training Loss:0.693 AVG Validation Loss:0.789 AVG Training Acc 52.96 % AVG Validation Acc 22.85 %\n",
      "Epoch:60/200 AVG Training Loss:0.683 AVG Validation Loss:0.789 AVG Training Acc 56.79 % AVG Validation Acc 25.54 %\n",
      "Epoch:70/200 AVG Training Loss:0.676 AVG Validation Loss:0.784 AVG Training Acc 57.64 % AVG Validation Acc 32.80 %\n",
      "Epoch:80/200 AVG Training Loss:0.671 AVG Validation Loss:0.774 AVG Training Acc 59.18 % AVG Validation Acc 38.71 %\n",
      "Epoch:90/200 AVG Training Loss:0.669 AVG Validation Loss:0.772 AVG Training Acc 59.54 % AVG Validation Acc 41.67 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.671 AVG Validation Loss:0.743 AVG Training Acc 58.76 % AVG Validation Acc 50.94 %\n",
      "Epoch:110/200 AVG Training Loss:0.659 AVG Validation Loss:0.690 AVG Training Acc 61.03 % AVG Validation Acc 61.16 %\n",
      "Epoch:120/200 AVG Training Loss:0.655 AVG Validation Loss:0.677 AVG Training Acc 61.17 % AVG Validation Acc 62.63 %\n",
      "Epoch:130/200 AVG Training Loss:0.655 AVG Validation Loss:0.674 AVG Training Acc 61.31 % AVG Validation Acc 62.77 %\n",
      "Epoch:140/200 AVG Training Loss:0.654 AVG Validation Loss:0.674 AVG Training Acc 61.68 % AVG Validation Acc 62.63 %\n",
      "Epoch   149: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:150/200 AVG Training Loss:0.653 AVG Validation Loss:0.674 AVG Training Acc 61.96 % AVG Validation Acc 62.90 %\n",
      "Epoch:160/200 AVG Training Loss:0.651 AVG Validation Loss:0.672 AVG Training Acc 61.89 % AVG Validation Acc 62.77 %\n",
      "Epoch:170/200 AVG Training Loss:0.654 AVG Validation Loss:0.671 AVG Training Acc 61.81 % AVG Validation Acc 63.17 %\n",
      "Epoch:180/200 AVG Training Loss:0.650 AVG Validation Loss:0.670 AVG Training Acc 61.92 % AVG Validation Acc 63.04 %\n",
      "Epoch:190/200 AVG Training Loss:0.650 AVG Validation Loss:0.670 AVG Training Acc 62.21 % AVG Validation Acc 63.04 %\n",
      "Epoch:200/200 AVG Training Loss:0.651 AVG Validation Loss:0.669 AVG Training Acc 61.89 % AVG Validation Acc 63.04 %\n",
      "Split 187\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96f11a334a9f492097d3a9e0b3585595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.457 AVG Validation Loss:5.750 AVG Training Acc 83.78 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.563 AVG Validation Loss:4.987 AVG Training Acc 71.25 % AVG Validation Acc 20.05 %\n",
      "Epoch    29: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:1.881 AVG Validation Loss:1.427 AVG Training Acc 48.08 % AVG Validation Acc 20.05 %\n",
      "Epoch:40/200 AVG Training Loss:0.689 AVG Validation Loss:0.833 AVG Training Acc 55.30 % AVG Validation Acc 22.34 %\n",
      "Epoch:50/200 AVG Training Loss:0.679 AVG Validation Loss:0.810 AVG Training Acc 57.88 % AVG Validation Acc 23.01 %\n",
      "Epoch:60/200 AVG Training Loss:0.673 AVG Validation Loss:0.800 AVG Training Acc 59.09 % AVG Validation Acc 28.40 %\n",
      "Epoch:70/200 AVG Training Loss:0.672 AVG Validation Loss:0.791 AVG Training Acc 59.36 % AVG Validation Acc 34.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.668 AVG Validation Loss:0.790 AVG Training Acc 59.95 % AVG Validation Acc 35.67 %\n",
      "Epoch:90/200 AVG Training Loss:0.665 AVG Validation Loss:0.782 AVG Training Acc 60.27 % AVG Validation Acc 39.97 %\n",
      "Epoch    97: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:100/200 AVG Training Loss:0.667 AVG Validation Loss:0.756 AVG Training Acc 59.22 % AVG Validation Acc 46.84 %\n",
      "Epoch:110/200 AVG Training Loss:0.656 AVG Validation Loss:0.706 AVG Training Acc 61.40 % AVG Validation Acc 55.32 %\n",
      "Epoch:120/200 AVG Training Loss:0.654 AVG Validation Loss:0.694 AVG Training Acc 61.94 % AVG Validation Acc 57.87 %\n",
      "Epoch:130/200 AVG Training Loss:0.654 AVG Validation Loss:0.691 AVG Training Acc 61.87 % AVG Validation Acc 58.01 %\n",
      "Epoch:140/200 AVG Training Loss:0.652 AVG Validation Loss:0.690 AVG Training Acc 61.96 % AVG Validation Acc 57.74 %\n",
      "Epoch:150/200 AVG Training Loss:0.652 AVG Validation Loss:0.690 AVG Training Acc 62.11 % AVG Validation Acc 57.47 %\n",
      "Epoch:160/200 AVG Training Loss:0.652 AVG Validation Loss:0.688 AVG Training Acc 62.40 % AVG Validation Acc 57.87 %\n",
      "Epoch:170/200 AVG Training Loss:0.652 AVG Validation Loss:0.688 AVG Training Acc 62.12 % AVG Validation Acc 57.87 %\n",
      "Epoch   172: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:180/200 AVG Training Loss:0.649 AVG Validation Loss:0.687 AVG Training Acc 62.33 % AVG Validation Acc 57.60 %\n",
      "Epoch:190/200 AVG Training Loss:0.650 AVG Validation Loss:0.685 AVG Training Acc 62.74 % AVG Validation Acc 58.01 %\n",
      "Epoch:200/200 AVG Training Loss:0.648 AVG Validation Loss:0.685 AVG Training Acc 62.54 % AVG Validation Acc 58.01 %\n",
      "Split 188\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa5a2d5bad9d4f9e8c643e07e6b5d84f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.486 AVG Validation Loss:5.505 AVG Training Acc 83.11 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.581 AVG Validation Loss:4.134 AVG Training Acc 79.06 % AVG Validation Acc 20.05 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.812 AVG Validation Loss:0.970 AVG Training Acc 49.94 % AVG Validation Acc 19.92 %\n",
      "Epoch:40/200 AVG Training Loss:0.686 AVG Validation Loss:0.806 AVG Training Acc 55.80 % AVG Validation Acc 22.88 %\n",
      "Epoch:50/200 AVG Training Loss:0.682 AVG Validation Loss:0.807 AVG Training Acc 56.64 % AVG Validation Acc 29.07 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.688 AVG Validation Loss:0.793 AVG Training Acc 55.21 % AVG Validation Acc 36.61 %\n",
      "Epoch:70/200 AVG Training Loss:0.671 AVG Validation Loss:0.714 AVG Training Acc 59.07 % AVG Validation Acc 49.93 %\n",
      "Epoch:80/200 AVG Training Loss:0.669 AVG Validation Loss:0.694 AVG Training Acc 59.74 % AVG Validation Acc 52.76 %\n",
      "Epoch:90/200 AVG Training Loss:0.667 AVG Validation Loss:0.692 AVG Training Acc 59.20 % AVG Validation Acc 54.37 %\n",
      "Epoch:100/200 AVG Training Loss:0.666 AVG Validation Loss:0.692 AVG Training Acc 59.90 % AVG Validation Acc 54.37 %\n",
      "Epoch:110/200 AVG Training Loss:0.667 AVG Validation Loss:0.690 AVG Training Acc 59.99 % AVG Validation Acc 55.32 %\n",
      "Epoch   115: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:120/200 AVG Training Loss:0.664 AVG Validation Loss:0.690 AVG Training Acc 60.74 % AVG Validation Acc 55.18 %\n",
      "Epoch:130/200 AVG Training Loss:0.664 AVG Validation Loss:0.688 AVG Training Acc 60.34 % AVG Validation Acc 55.45 %\n",
      "Epoch:140/200 AVG Training Loss:0.665 AVG Validation Loss:0.687 AVG Training Acc 60.11 % AVG Validation Acc 55.85 %\n",
      "Epoch:150/200 AVG Training Loss:0.664 AVG Validation Loss:0.685 AVG Training Acc 59.98 % AVG Validation Acc 56.26 %\n",
      "Epoch:160/200 AVG Training Loss:0.664 AVG Validation Loss:0.683 AVG Training Acc 60.34 % AVG Validation Acc 56.39 %\n",
      "Epoch:170/200 AVG Training Loss:0.664 AVG Validation Loss:0.683 AVG Training Acc 60.50 % AVG Validation Acc 56.26 %\n",
      "Epoch:180/200 AVG Training Loss:0.665 AVG Validation Loss:0.683 AVG Training Acc 60.31 % AVG Validation Acc 56.53 %\n",
      "Epoch:190/200 AVG Training Loss:0.666 AVG Validation Loss:0.682 AVG Training Acc 60.09 % AVG Validation Acc 57.20 %\n",
      "Epoch:200/200 AVG Training Loss:0.666 AVG Validation Loss:0.682 AVG Training Acc 59.98 % AVG Validation Acc 56.80 %\n",
      "Split 189\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5c18bc2263646b0901013269671a1b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.528 AVG Validation Loss:5.228 AVG Training Acc 80.65 % AVG Validation Acc 20.05 %\n",
      "Epoch:20/200 AVG Training Loss:0.652 AVG Validation Loss:1.580 AVG Training Acc 65.14 % AVG Validation Acc 20.05 %\n",
      "Epoch:30/200 AVG Training Loss:0.652 AVG Validation Loss:1.582 AVG Training Acc 65.68 % AVG Validation Acc 20.05 %\n",
      "Epoch    32: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.635 AVG Validation Loss:1.121 AVG Training Acc 66.69 % AVG Validation Acc 20.73 %\n",
      "Epoch:50/200 AVG Training Loss:0.678 AVG Validation Loss:0.993 AVG Training Acc 60.04 % AVG Validation Acc 20.59 %\n",
      "Epoch:60/200 AVG Training Loss:0.662 AVG Validation Loss:0.992 AVG Training Acc 62.39 % AVG Validation Acc 20.59 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:70/200 AVG Training Loss:0.695 AVG Validation Loss:0.794 AVG Training Acc 53.52 % AVG Validation Acc 27.99 %\n",
      "Epoch:80/200 AVG Training Loss:0.670 AVG Validation Loss:0.708 AVG Training Acc 59.06 % AVG Validation Acc 45.22 %\n",
      "Epoch:90/200 AVG Training Loss:0.667 AVG Validation Loss:0.703 AVG Training Acc 58.52 % AVG Validation Acc 48.32 %\n",
      "Epoch:100/200 AVG Training Loss:0.664 AVG Validation Loss:0.701 AVG Training Acc 60.15 % AVG Validation Acc 50.34 %\n",
      "Epoch:110/200 AVG Training Loss:0.662 AVG Validation Loss:0.700 AVG Training Acc 60.13 % AVG Validation Acc 51.82 %\n",
      "Epoch:120/200 AVG Training Loss:0.662 AVG Validation Loss:0.701 AVG Training Acc 59.78 % AVG Validation Acc 51.28 %\n",
      "Epoch   126: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:130/200 AVG Training Loss:0.659 AVG Validation Loss:0.697 AVG Training Acc 60.60 % AVG Validation Acc 53.43 %\n",
      "Epoch:140/200 AVG Training Loss:0.658 AVG Validation Loss:0.685 AVG Training Acc 60.51 % AVG Validation Acc 53.70 %\n",
      "Epoch:150/200 AVG Training Loss:0.657 AVG Validation Loss:0.678 AVG Training Acc 60.70 % AVG Validation Acc 55.18 %\n",
      "Epoch:160/200 AVG Training Loss:0.656 AVG Validation Loss:0.676 AVG Training Acc 60.81 % AVG Validation Acc 55.05 %\n",
      "Epoch   165: reducing learning rate of group 0 to 1.0000e-06.\n",
      "Epoch:170/200 AVG Training Loss:0.657 AVG Validation Loss:0.674 AVG Training Acc 60.54 % AVG Validation Acc 56.39 %\n",
      "Epoch:180/200 AVG Training Loss:0.657 AVG Validation Loss:0.674 AVG Training Acc 61.10 % AVG Validation Acc 56.93 %\n",
      "Epoch:190/200 AVG Training Loss:0.657 AVG Validation Loss:0.675 AVG Training Acc 61.25 % AVG Validation Acc 56.26 %\n",
      "Epoch   196: reducing learning rate of group 0 to 1.0000e-07.\n",
      "Epoch:200/200 AVG Training Loss:0.658 AVG Validation Loss:0.675 AVG Training Acc 60.81 % AVG Validation Acc 55.72 %\n",
      "Split 190\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af187b8385904b928963ec4fb5fcd869",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.589 AVG Validation Loss:8.056 AVG Training Acc 71.56 % AVG Validation Acc 20.19 %\n",
      "Epoch:20/200 AVG Training Loss:0.556 AVG Validation Loss:8.481 AVG Training Acc 73.40 % AVG Validation Acc 20.19 %\n",
      "Epoch    28: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:30/200 AVG Training Loss:0.741 AVG Validation Loss:0.885 AVG Training Acc 49.00 % AVG Validation Acc 20.19 %\n",
      "Epoch:40/200 AVG Training Loss:0.684 AVG Validation Loss:0.850 AVG Training Acc 56.62 % AVG Validation Acc 20.73 %\n",
      "Epoch:50/200 AVG Training Loss:0.674 AVG Validation Loss:0.842 AVG Training Acc 58.54 % AVG Validation Acc 25.71 %\n",
      "Epoch    59: reducing learning rate of group 0 to 1.0000e-04.\n",
      "Epoch:60/200 AVG Training Loss:0.690 AVG Validation Loss:0.822 AVG Training Acc 55.13 % AVG Validation Acc 29.88 %\n",
      "Epoch:70/200 AVG Training Loss:0.661 AVG Validation Loss:0.709 AVG Training Acc 60.53 % AVG Validation Acc 55.05 %\n",
      "Epoch:80/200 AVG Training Loss:0.660 AVG Validation Loss:0.694 AVG Training Acc 60.77 % AVG Validation Acc 57.74 %\n",
      "Epoch:90/200 AVG Training Loss:0.655 AVG Validation Loss:0.690 AVG Training Acc 60.86 % AVG Validation Acc 57.74 %\n",
      "Epoch:100/200 AVG Training Loss:0.657 AVG Validation Loss:0.690 AVG Training Acc 61.13 % AVG Validation Acc 57.34 %\n",
      "Epoch   102: reducing learning rate of group 0 to 1.0000e-05.\n",
      "Epoch:110/200 AVG Training Loss:0.652 AVG Validation Loss:0.688 AVG Training Acc 61.92 % AVG Validation Acc 57.60 %\n",
      "Epoch:120/200 AVG Training Loss:0.654 AVG Validation Loss:0.685 AVG Training Acc 61.05 % AVG Validation Acc 58.01 %\n",
      "Epoch:130/200 AVG Training Loss:0.652 AVG Validation Loss:0.683 AVG Training Acc 61.22 % AVG Validation Acc 58.28 %\n",
      "Epoch:140/200 AVG Training Loss:0.654 AVG Validation Loss:0.682 AVG Training Acc 61.38 % AVG Validation Acc 58.41 %\n",
      "Epoch:150/200 AVG Training Loss:0.650 AVG Validation Loss:0.680 AVG Training Acc 61.86 % AVG Validation Acc 58.41 %\n",
      "Epoch:160/200 AVG Training Loss:0.654 AVG Validation Loss:0.679 AVG Training Acc 61.64 % AVG Validation Acc 58.41 %\n",
      "Epoch:170/200 AVG Training Loss:0.650 AVG Validation Loss:0.679 AVG Training Acc 61.66 % AVG Validation Acc 58.55 %\n",
      "Epoch:180/200 AVG Training Loss:0.652 AVG Validation Loss:0.678 AVG Training Acc 61.68 % AVG Validation Acc 58.68 %\n",
      "Epoch:190/200 AVG Training Loss:0.652 AVG Validation Loss:0.677 AVG Training Acc 61.19 % AVG Validation Acc 58.55 %\n",
      "Epoch:200/200 AVG Training Loss:0.651 AVG Validation Loss:0.677 AVG Training Acc 61.10 % AVG Validation Acc 58.82 %\n",
      "Split 191\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c818d0166fa447afada754c69b941074",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/200 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:10/200 AVG Training Loss:0.532 AVG Validation Loss:4.075 AVG Training Acc 79.59 % AVG Validation Acc 20.16 %\n",
      "Epoch:20/200 AVG Training Loss:0.566 AVG Validation Loss:2.911 AVG Training Acc 79.39 % AVG Validation Acc 20.16 %\n",
      "Epoch:30/200 AVG Training Loss:0.505 AVG Validation Loss:5.833 AVG Training Acc 81.66 % AVG Validation Acc 20.16 %\n",
      "Epoch    35: reducing learning rate of group 0 to 1.0000e-03.\n",
      "Epoch:40/200 AVG Training Loss:0.702 AVG Validation Loss:0.836 AVG Training Acc 51.69 % AVG Validation Acc 21.37 %\n",
      "Epoch:50/200 AVG Training Loss:0.693 AVG Validation Loss:0.813 AVG Training Acc 53.13 % AVG Validation Acc 21.77 %\n",
      "Epoch:60/200 AVG Training Loss:0.686 AVG Validation Loss:0.837 AVG Training Acc 55.77 % AVG Validation Acc 25.00 %\n",
      "Epoch    66: reducing learning rate of group 0 to 1.0000e-04.\n"
     ]
    }
   ],
   "source": [
    "for i in tqdm(course_programs.keys()):\n",
    "    \n",
    "    print(i)\n",
    "    threshold_dict = {} #dict to store information in for each threshold\n",
    "    data = deepcopy(course_programs[i])\n",
    "    \n",
    "    data.set_index(['course_encoding', 'userid'], drop = True, inplace = True)\n",
    "    data.fillna(0, inplace = True)\n",
    "    \n",
    "    #set X and Y columns\n",
    "    X = data[data.columns[:25]] #different timesteps\n",
    "    y = data[data.columns[-4:]] #the 4 different putative targets\n",
    "    \n",
    "    for k in tqdm(targets):\n",
    "        print(k)\n",
    "        \n",
    "        #Start with train test split\n",
    "        X_train_val, X_test, y_train_val, y_test, = train_test_split(\n",
    "                                    X,\n",
    "                                   y[k], #replace when going for multi-target \n",
    "                                   test_size = 0.20,\n",
    "                                   random_state = 15,\n",
    "                                   shuffle=True,\n",
    "                                   stratify = y[k] #replace when going for multi-target\n",
    "                                    )\n",
    "        \n",
    "        #create dict to store fold performance\n",
    "        foldperf={}\n",
    "        \n",
    "        #reset \"best accuracy for treshold i and target k\"\n",
    "        best_accuracy = 0\n",
    "\n",
    "        #make train_val split\n",
    "        for fold, (train_idx,val_idx) in tqdm(enumerate(splits.split(X_train_val, y_train_val))):\n",
    "\n",
    "            print('Split {}'.format(fold + 1))\n",
    "            \n",
    "            #make split between train and Val\n",
    "            X_train, y_train = X_train_val.iloc[train_idx], y_train_val.iloc[train_idx]\n",
    "            X_val, y_val = X_train_val.iloc[val_idx], y_train_val.iloc[val_idx]\n",
    "            \n",
    "            #apply SMOTE to training split\n",
    "            over = SMOTE()\n",
    "            X_train, y_train = over.fit_resample(X_train, y_train)\n",
    "            \n",
    "            #apply scaling after \n",
    "            X_train, X_val = normalize(X_train, X_val, 'Standard')\n",
    "            \n",
    "            #second, convert everything to pytorch tensor - we will convert to tensor dataset and \n",
    "            X_train_tensors = Variable(torch.Tensor(X_train.values))\n",
    "            X_val_tensors = Variable(torch.Tensor(X_val.values))\n",
    "\n",
    "            y_train_tensors = Variable(torch.Tensor(y_train.values))\n",
    "            y_val_tensors = Variable(torch.Tensor(y_val.values)) \n",
    "\n",
    "            #reshaping to rows, timestamps, features \n",
    "            X_train_tensors = torch.reshape(X_train_tensors,   (X_train_tensors.shape[0], X_train_tensors.shape[1], 1))\n",
    "            X_val_tensors = torch.reshape(X_val_tensors,  (X_val_tensors.shape[0], X_val_tensors.shape[1], 1))\n",
    "        \n",
    "            #convert y tensors to format longtensor\n",
    "            y_train_tensors = y_train_tensors.type(torch.cuda.LongTensor)\n",
    "            y_val_tensors = y_val_tensors.type(torch.cuda.LongTensor)\n",
    "            \n",
    "            #create Tensor Datasets and dataloaders for both Train and Val\n",
    "            train_dataset = TensorDataset(X_train_tensors, y_train_tensors)\n",
    "            val_dataset = TensorDataset(X_val_tensors, y_val_tensors)\n",
    "            train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "            val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "    \n",
    "            #creates new model for each \n",
    "            model = LSTM_Uni(num_classes, input_size, hidden_size, num_layers, X_train_tensors.shape[1]).to('cuda') #our lstm class\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) \n",
    "            scheduler = ReduceLROnPlateau(optimizer, \n",
    "                                  'min', \n",
    "                                  patience = 10,\n",
    "                                  cooldown = 20,\n",
    "                                 verbose = True)\n",
    "    \n",
    "            history = {'train_loss': [], 'val_loss': [],'train_acc':[],'val_acc':[], 'precision': [],\n",
    "                      'recall' : [], 'auroc': []}\n",
    "\n",
    "            for epoch in tqdm(range(num_epochs)):\n",
    "                train_loss, train_correct=train_epoch(model,train_loader,criterion,optimizer)\n",
    "                val_loss, val_correct, precision, recall, auroc = valid_epoch(model,val_loader,criterion)\n",
    "\n",
    "                train_loss = train_loss / len(train_loader.sampler)\n",
    "                train_acc = train_correct / len(train_loader.sampler) * 100\n",
    "                val_loss = val_loss / len(val_loader.sampler)\n",
    "                val_acc = val_correct / len(val_loader.sampler) * 100\n",
    "        \n",
    "        \n",
    "                if (epoch+1) % 10 == 0: \n",
    "                    print(\"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Validation Loss:{:.3f} AVG Training Acc {:.2f} % AVG Validation Acc {:.2f} %\".format(epoch + 1,\n",
    "                                                                                                             num_epochs,\n",
    "                                                                                                             train_loss,\n",
    "                                                                                                             val_loss,\n",
    "                                                                                                             train_acc,\n",
    "                                                                                                             val_acc))\n",
    "                history['train_loss'].append(train_loss)\n",
    "                history['val_loss'].append(val_loss)\n",
    "                history['train_acc'].append(train_acc)\n",
    "                history['val_acc'].append(val_acc)\n",
    "                history['precision'].append(precision)\n",
    "                history['recall'].append(recall)\n",
    "                history['auroc'].append(auroc)\n",
    "                scheduler.step(val_loss)\n",
    "    \n",
    "                if val_acc > best_accuracy:\n",
    "            \n",
    "                #replace best accuracy and save best model\n",
    "                    print(f'New Best Accuracy found: {val_acc:.2f}%\\nEpoch: {epoch + 1}')\n",
    "                    best_accuracy = val_acc\n",
    "                    best = deepcopy(model)\n",
    "                    curr_epoch = epoch + 1\n",
    "                    \n",
    "            #store fold performance\n",
    "            foldperf['fold{}'.format(fold+1)] = history\n",
    "        \n",
    "        #saves fold performance for target \n",
    "        threshold_dict[k] = pd.DataFrame.from_dict(foldperf, orient='index') # convert dict to dataframe\n",
    "        \n",
    "        #explode to get eacxh epoch as a row\n",
    "        threshold_dict[k] = threshold_dict[k].explode(list(threshold_dict[k].columns))\n",
    "        torch.save(best,f\"../Models/{i}/SMOTE_Nova_IMS_best_{k}_{curr_epoch}_epochs.h\")\n",
    "        \n",
    "    # from pandas.io.parsers import ExcelWriter\n",
    "    with pd.ExcelWriter(f\"../Data/Modeling Stage/Results/IMS/Clicks per % duration/SMOTE_25_splits_{i}_{replicas}_replicas.xlsx\") as writer:  \n",
    "        for sheet in targets:\n",
    "                threshold_dict[sheet].to_excel(writer, sheet_name=str(sheet))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
